<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-00369</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004471</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>An Adapting Auditory-motor Feedback Loop Can Contribute to Generating Vocal Repetition</article-title>
<alt-title alt-title-type="running-head">Adapting Auditory Feedback and Vocal Repetition</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Wittenbach</surname> <given-names>Jason D.</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Bouchard</surname> <given-names>Kristofer E.</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="fn" rid="currentaff001"><sup>¤</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Brainard</surname> <given-names>Michael S.</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Jin</surname> <given-names>Dezhe Z.</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Department of Physics and Center for Neural Engineering, the Pennsylvania State University, University Park, Pennsylvania, United States of America</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Physiology and Center for Integrative Neuroscience, University of California at San Francisco, San Francisco, California, United States of America</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Department of Neurosurgery and Center for Neural Engineering and Prosthesis, University of California at San Francisco, San Francisco, California, United States of America</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>Howard Hughes Medical Institute, San Francisco, California, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Theunissen</surname> <given-names>Frédéric E.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University of California at Berkeley, United States of America</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: DZJ MSB JDW KEB. Performed the experiments: JDW KEB. Analyzed the data: KEB. Wrote the paper: DZJ KEB JDW MSB. Computational model: JDW DZJ. Experiments: KEB MSB.</p>
</fn>
<fn fn-type="current-aff" id="currentaff001">
<label>¤</label>
<p>Current address: Biological and Engineering Division, Lawrence Berkeley National Laboratory, Berkeley, California, USA</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">dzj2@psu.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>10</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>8</day>
<month>10</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>10</issue>
<elocation-id>e1004471</elocation-id>
<history>
<date date-type="received">
<day>13</day>
<month>3</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>21</day>
<month>7</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Wittenbach et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004471" xlink:type="simple"/>
<abstract>
<p>Consecutive repetition of actions is common in behavioral sequences. Although integration of sensory feedback with internal motor programs is important for sequence generation, if and how feedback contributes to repetitive actions is poorly understood. Here we study how auditory feedback contributes to generating repetitive syllable sequences in songbirds. We propose that auditory signals provide positive feedback to ongoing motor commands, but this influence decays as feedback weakens from response adaptation during syllable repetitions. Computational models show that this mechanism explains repeat distributions observed in Bengalese finch song. We experimentally confirmed two predictions of this mechanism in Bengalese finches: removal of auditory feedback by deafening reduces syllable repetitions; and neural responses to auditory playback of repeated syllable sequences gradually adapt in sensory-motor nucleus HVC. Together, our results implicate a positive auditory-feedback loop with adaptation in generating repetitive vocalizations, and suggest sensory adaptation is important for feedback control of motor sequences.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Repetitions are common in animal vocalizations. Songs of many songbirds contain syllables that repeat a variable number of times, with non-Markovian distributions of repeat counts. The neural mechanism underlying such syllable repetitions is unknown. In this work, we show that auditory feedback plays an important role in sustaining syllable repetitions in the Bengalese finch. Deafening reduces syllable repetitions and skews the repeat number distribution towards short repeats. These effects are explained with our computational model, which suggests that syllable repeats are initially sustained by auditory feedback to the neural networks that drive the syllable production. The feedback strength weakens as the syllable repeats, increasing the likelihood that the syllable repetition stops. Neural recordings confirm such adaptation of auditory feedback to the auditory-motor circuit in the Bengalese finch. Our results suggests that sensory feedback can directly impact repetitions in motor sequences, and may provide insights into neural mechanisms of speech disorders such as stuttering.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by the National Science Foundation <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://www.nsf.gov/">http://www.nsf.gov/</ext-link>, IOS-0827731 (DZJ); The Huck Institute of the Life Sciences at the Pennsylvania State University, <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="https://www.huck.psu.edu/">https://www.huck.psu.edu/</ext-link>, (DZJ); National Institutes of Health, <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://www.nih.gov/">http://www.nih.gov/</ext-link>, R01 DC006636 (MSB); National Science Foundation, <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://www.nsf.gov/">http://www.nsf.gov/</ext-link>, IOS-0951348 (MSB); The Howard Hughes Medical Institute, <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="https://www.hhmi.org/">https://www.hhmi.org/</ext-link>, (MSB); and the National Science Foundation, <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://www.nsf.gov/">http://www.nsf.gov/</ext-link>, Graduate Research Fellowship Program (KEB). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="0"/>
<page-count count="29"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>The authors confirm that all data underlying the findings are fully available without restriction. The data can be downloaded from <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://users.phys.psu.edu/~djin/SharedData/KrisBouchard/">http://users.phys.psu.edu/~djin/SharedData/KrisBouchard/</ext-link>. Questions about the data should be addressed to KEB.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Many complex behaviors—human speech, playing a piano, or birdsong—consist of a set of discrete actions that can be flexibly organized into variable sequences [<xref ref-type="bibr" rid="pcbi.1004471.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref003">3</xref>]. A feature of many variably sequenced behaviors is the occurrence of repetitive sub-sequences of the same action. Examples include trills in music, repeated syllables in birdsong, and syllable/sound repetitions in stuttered speech. A central issue in understanding how nervous systems generate complex sequences is the role of sensory feedback versus internal motor programs [<xref ref-type="bibr" rid="pcbi.1004471.ref004">4</xref>] (<xref ref-type="fig" rid="pcbi.1004471.g001">Fig 1a</xref>). At one extreme (the serial chaining framework), the sensory feedback from one action initiates the next action in the sequence; therefore sensory feedback is critical for sequencing the actions [<xref ref-type="bibr" rid="pcbi.1004471.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref006">6</xref>]. However, because of the delays in both motor and sensory processing in nervous systems, it has been argued that a sequence generation mechanism relying solely on sensory feedback would be too slow to account for the execution of fast sequences such as typing and speech [<xref ref-type="bibr" rid="pcbi.1004471.ref001">1</xref>]. At the other extreme, sequences are generated by internal motor programs controlling sequence production without the use of sensory feedback [<xref ref-type="bibr" rid="pcbi.1004471.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref009">9</xref>]. However, there is ample evidence that sensory feedback can affect action sequences [<xref ref-type="bibr" rid="pcbi.1004471.ref010">10</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref014">14</xref>]. Despite the ubiquity of sequencing in behavior, the neural mechanisms of how sensory feedback interacts with internal motor programs to influence discrete actions remain largely unexplored.</p>
<fig id="pcbi.1004471.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004471.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Bengalese finch song and the generation of sequences.</title>
<p>a: Diagram of sensory-motor circuit for sequence generation. An internal motor program generates transitions between actions (‘a’, ‘b’, ‘c’, etc) while sensory feedback from the actions (motor outputs) impinges on the motor program. b: Example of Bengalese finch song. Spectrogram (power at frequency vs. time) of an adult Bengalese finch song, which consists of several syllables (denoted with letters) produced in probabilistic sequences. A prominent feature of Bengalese finch songs is the presence of syllable repetitions, some with long repeat sequences (e.g. syllable ‘b’). c: Probability distribution of repeat counts for syllable ‘b’ from an individual Bengalese finch (red), and the predicted probability distribution for a Markov process using first order transition probabilities.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004471.g001"/>
</fig>
<p>Here, we study the role of sensory feedback in the production of repetitive vocal sequences using the Bengalese finch as a model system. The Bengalese finch produces songs composed of discrete acoustic events, termed syllables, organized into variable sequences (<xref ref-type="fig" rid="pcbi.1004471.g001">Fig 1b</xref>). However, sequence production is not random [<xref ref-type="bibr" rid="pcbi.1004471.ref015">15</xref>], as the transition probabilities between syllables are statistically reproducible across time [<xref ref-type="bibr" rid="pcbi.1004471.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref016">16</xref>]. A prominent feature of the songs of several songbird species, including the Bengalese finch, is syllable repetition [<xref ref-type="bibr" rid="pcbi.1004471.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref017">17</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref021">21</xref>] (e.g. ‘b’ in <xref ref-type="fig" rid="pcbi.1004471.g001">Fig 1b</xref>). For a given repeated syllable, the number of consecutively produced repeats (the repeat number) varies. The first order Markov process, in which the probability of repeating a syllable is constant, is a simple model for generating syllable repetitions. Such a process produces a monotonically decreasing distribution of repeat numbers, with the most probable repeat number (peak repeat number) being one (<xref ref-type="fig" rid="pcbi.1004471.g001">Fig 1c</xref>, black curve). Indeed, many repeated syllables in the songs of the Bengalese finch do have such distributions [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>]. However, there are also repeated syllables that violate the predictions of the Markov process. These syllables are typically long repeated, and their distributions of repeat numbers are peaked, with the most probable repeat number being much greater than one [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref023">23</xref>] (<xref ref-type="fig" rid="pcbi.1004471.g001">Fig 1c</xref>, red curve). In the songs of the Bengalese finch, the transition probabilities between syllables are altered shortly after deafening [<xref ref-type="bibr" rid="pcbi.1004471.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref025">25</xref>] or in real-time by delayed auditory feedback [<xref ref-type="bibr" rid="pcbi.1004471.ref013">13</xref>], demonstrating that disturbing auditory feedback can disturb sequence generation.</p>
<p>Songbirds are prominent models for studying the neural basis of complex sequence production. Experimental data from sensory-motor song nucleus HVC (proper name) of singing zebra finches have led to neural network models of the internal motor program for sequence generation that instantiate first-order Markov processes [<xref ref-type="bibr" rid="pcbi.1004471.ref026">26</xref>]. This suggests that additional mechanisms contribute to the generation of non-Markovian distributions of repeat numbers [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref026">26</xref>]. One possibility is that, because of sensory-motor delays, auditory feedback from the previous syllable interacts with the internal motor program to contribute to the transition dynamics for subsequent syllables [<xref ref-type="bibr" rid="pcbi.1004471.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref028">28</xref>]. For repeated syllables, we hypothesized that the interaction of auditory-feedback and ongoing motor activity forms a positive-feedback loop that contributes to sustaining syllable repetition beyond the predictions of a Markov process (<xref ref-type="fig" rid="pcbi.1004471.g001">Fig 1a</xref>). However, such positive-feedback architectures are inherently unstable, prone to indefinite repetition (i.e. perseveration). Across sensory modalities, a common feature of sensory responses to repeated presentations of identical physical stimuli is a gradual decrease of response magnitude (i.e. response adaptation) [<xref ref-type="bibr" rid="pcbi.1004471.ref029">29</xref>]. We therefore hypothesized that auditory inputs are subject to response adaptation, which gradually reduces the strength of the positive feedback loop over time. Thus, an auditory-motor feedback loop with response adaptation is predicted to contribute to the generation of non-Makovian repeated syllable sequences by both pushing repeat counts beyond the expectations of a Markov process and simultaneously preventing indefinite repetitions of the syllable. We tested these hypotheses using computational modeling combined with behavioral and electrophysiological experiments.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>A network model with adapting auditory feedback</title>
<p>The critical features of our framework for repeat generation are: (1) the population of neurons generating a repeated syllable receives a source of excitatory input in addition to the recurrent excitation from the sequencing network, and (2) the strength of this input adapts over time during repeat generation. For concreteness, we instantiate this framework as a ‘branched-chain’ network with adapting auditory feedback, and place this network in nucleus HVC. In songbirds, HVC has been proposed to contain an internal motor program for the generation of song sequences [<xref ref-type="bibr" rid="pcbi.1004471.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref030">30</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref035">35</xref>]. HVC sends descending motor commands for song timing to nucleus RA (the robust nucleus of the arcopallium), which in turn projects to brainstem areas controlling the vocal organs [<xref ref-type="bibr" rid="pcbi.1004471.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref037">37</xref>] (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2a</xref>). HVC also receives input through internal feedback loops from the brainstem [<xref ref-type="bibr" rid="pcbi.1004471.ref038">38</xref>], via Uva (nucleus uvaeformis) and NIf (the interfacial nucleus of the nidopallium) [<xref ref-type="bibr" rid="pcbi.1004471.ref039">39</xref>]. Experiments in the zebra finch have shown sparse sequential firing of the RA projecting HVC neurons (HVC<sub>RA</sub>) during singing [<xref ref-type="bibr" rid="pcbi.1004471.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref035">35</xref>]. This has led to the hypothesis that the motor program for sequence production in HVC includes sequential “chaining” of activity, in which populations of HVC<sub>RA</sub> neurons responsible for generating a syllable drive the neuronal populations that generate subsequent syllables either directly within HVC or through the internal feedback loop [<xref ref-type="bibr" rid="pcbi.1004471.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref034">34</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref041">41</xref>] (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2b</xref>).</p>
<fig id="pcbi.1004471.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004471.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Avian song system and branched chain network with adapting auditory feedback.</title>
<p>a: Diagram of the avian song system. HVC is a sensory-motor integration area that receives auditory input from high-level auditory nuclei such as NIf (nucleus interfacealus), and sends temporally precise motor controls signals to nucleus RA (robust nucleus of the arcopallium), which projects to the vocal brainstem areas. There is a pre-motor latency of 30–50 ms (Δ<italic>T</italic> Motor) between activity in HVC and subsequent vocalization. Additionally, there is a latency of 15–20 ms (Δ<italic>T</italic> Auditory) for auditory activity to reach HVC. This makes for a total auditory-motor latency between pre-motor activity and resulting auditory feedback of 45–70 ms. b: Example of a branch point in a probabilistic sequence (left). Syllable ‘a’ can transition to either syllable ‘b’ or ‘c’. Such probabilistic sequences can be produced by a branched chain network (right). Here, each syllable is produced by a syllable-chain, in which groups of HVC<sub>RA</sub> neurons (grey dots in red ovals, grouped in grey rectangles for a given syllable) are connected unidirectionally in a feed-forward chain (black lines with triangles are excitatory connections). The end of chain-a connects to the beginning of chain-b and chain-c. Spike activity propagates through chain-a and drives downstream neurons in RA to produce syllable a. At the end of chain-a, the activity continues to chain-b or chain-c via the branched connections. Only one syllable chain can be active at a time, as enforced by winner-take-all mechanisms mediated through local feedback inhibition from the HVC<sub>I</sub> neurons (red lines are inhibitory connections). c: The branched chain network with adapting auditory feedback for generating repeating sequences of syllable ‘b’. The end of chain-b reconnects to its beginning and to chain-c. Auditory feedback from syllable ‘b’ is applied to chain-b, and biases the repeat probability when the activity propagates to the branching point. The feedback is weakened as syllable ‘b’ repeats due to use-dependent synaptic depression which models stimulus-specific adaptation of the auditory signal.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004471.g002"/>
</fig>
<p>Our model for generating syllable sequences starts with such a synaptic chain framework. The details of this model have been described previously [<xref ref-type="bibr" rid="pcbi.1004471.ref026">26</xref>] and are summarized in Materials and Methods. In synaptic chain models, each syllable is encoded in a chain network of HVC<sub>RA</sub> neurons (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2b</xref>). Spike propagation through the chain produces the encoded syllable by driving appropriate RA neurons. To generate variable syllable transitions, the syllable-chains are connected into branching patterns. At a branch point, syllable-chains compete with each other through a winner-take all mechanism mediated by the inhibitory HVC interneurons (HVC<sub>I</sub>), allowing only one branch to continue the spike propagation. The selection is probabilistic due to intrinsic neuronal noise, which provides a source of stochasticity in the winner-take-all competition (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2b</xref>). In this model, syllable repetition is generated by connecting the syllable-chains to themselves at the branching points [<xref ref-type="bibr" rid="pcbi.1004471.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref034">34</xref>]. In branched chain networks, the transitions between the syllable-chains are largely Markovian, and for repeating syllables this implies that repeat number distributions should be a decreasing function of the repeat number—in particular, the most probable (or “peak”) repeat number will be one [<xref ref-type="bibr" rid="pcbi.1004471.ref026">26</xref>] (<xref ref-type="fig" rid="pcbi.1004471.g001">Fig 1c</xref>). However, many repeated syllables in Bengalese finch song have repeat distributions that are highly non-Markovian, with peak repeat numbers much larger than one [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref023">23</xref>]. This implies additional processes beyond synaptic chains contribute to generating non-Markovian repeated sequences.</p>
<p>Here we incorporate auditory feedback into the branching chain network model and show that, when this feedback is strong and adapting, non-Markovian repeat distributions emerge. In HVC, as in many sensory-motor systems, including the human speech system [<xref ref-type="bibr" rid="pcbi.1004471.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref043">43</xref>], the same neuronal populations that are responsible for the generation of the behavior also respond to the sensory consequences of that behavior, i.e. the bird’s own song (BOS) [<xref ref-type="bibr" rid="pcbi.1004471.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref044">44</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref046">46</xref>]. HVC receives much of its auditory input from NIf [<xref ref-type="bibr" rid="pcbi.1004471.ref047">47</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref050">50</xref>], which can provide real-time auditory feedback during singing (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2a</xref>) [<xref ref-type="bibr" rid="pcbi.1004471.ref051">51</xref>]. However, because of the time it takes to propagate motor commands to the periphery (30–50 ms) and process the subsequent auditory signals (15–20 ms) (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2a</xref>), auditory feedback is necessarily delayed relative to the motor activity that generated it [<xref ref-type="bibr" rid="pcbi.1004471.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref028">28</xref>]. This sensory-motor delay for HVC (45–70 ms) is on the order of the duration of a syllable, making it possible for auditory feedback to influence HVC motor programs and the transition dynamics between syllables [<xref ref-type="bibr" rid="pcbi.1004471.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref027">27</xref>] (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2a</xref>).</p>
<p>We first tested the feasibility of this mechanism using biophysically detailed neural network models. To illustrate this model, we focus on generating sequences of the form ‘ab<sup>n</sup>c’, where syllable ‘a’ transitions to syllable ‘b’, ‘b’ repeats a variable number of times (n), and transitions to ‘c’ (e.g. ‘abbbbbbbc’). For concreteness, we model the adapting input as an auditory feedback signal to the network, though in principle this adapting input could reflect recurrent circuit-activity that is non-sensory. To incorporate auditory feedback into the previous model, each HVC<sub>RA</sub> neuron in chain-b is contacted by excitatory synapses carrying auditory inputs triggered by the production of syllable ‘b’ (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2c</xref>). We assume that the auditory synapses are made by axons from NIf, which is a major source of auditory input to HVC [<xref ref-type="bibr" rid="pcbi.1004471.ref047">47</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref050">50</xref>] and is selective to BOS [<xref ref-type="bibr" rid="pcbi.1004471.ref049">49</xref>]. When auditory feedback is present, the auditory synapses receive spikes from a Poisson process, assumed to be from the population of NIf neurons responding to syllable ‘b’ (Materials and Methods) (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2c</xref>). The auditory synapses are subject to short-term synaptic depression, resulting in gradual adaptation of responses to repeated inputs [<xref ref-type="bibr" rid="pcbi.1004471.ref052">52</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref053">53</xref>]. Specifically, due to the synaptic depression, the average strength of the auditory inputs to chain-b decreases exponentially during the repeats of syllable ‘b’ (Materials and Methods).</p>
<p>In <xref ref-type="fig" rid="pcbi.1004471.g003">Fig 3</xref>, we show results from an example network in which the auditory input to chain-b is strong and the spiking dynamics produce repeats of syllable ‘b’ with large repeat numbers. A spike raster for a standard single run of the network is shown in <xref ref-type="fig" rid="pcbi.1004471.g003">Fig 3a</xref>. Once spiking was initiated in chain-a (through external current injection), spikes propagated through chain-a, and activated chain-b. Chain-b repeated a variable number of times before the spike activity exited to chain-c and stopped once it reached the end of chain-c. As chain-b continued to repeat, the synapses carrying the feedback signal weakened over time due to adaptation (<xref ref-type="fig" rid="pcbi.1004471.g003">Fig 3b</xref>).</p>
<fig id="pcbi.1004471.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004471.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Strong, adapting auditory feedback produces peaked repeat distributions in branching chain neural networks.</title>
<p>a. Raster plot of the spikes of the neurons in the network model. Neurons are ordered according their positions in the chains. Each dot represents the spike time of a neuron. Spikes are subsampled and the image is smoothed so that darker areas represent stronger activity at a particular location/time. Spikes propagate from chain-a to chain-b. Chain-b repeats a variable number of times (in this case, 6) before activity exits to chain-c. b. The average strength of auditory synapses decreases once they are activated by auditory feedback input. The red line is the fit to an exponential function with a decay time constant <italic>τ</italic> = 148 ms. There is auditory feedback from syllable-b to HVC<sub>RA</sub> neurons in chain-b during the times indicated by white areas. c. The probability of chain-b repeating decreases as the repeat number increases. d. The repeat probability of chain-b as a function of the average synaptic strength of the auditory inputs that the chain receives at the transition time. The bars are 90% confidence intervals (Wilson score with continuity correction). The red line is a fit with a sigmoidal function. e. The probability distribution of the repeat numbers of syllable ‘b’. All probabilities computed over 1,000 simulations.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004471.g003"/>
</fig>
<p>Analyzing multiple trials, we find that the probability of chain-b transitioning to itself (repeat probability) also decreases over time, though the repeat probability is only meaningful at the transition times—i.e. when the activity reaches the end of chain-b (<xref ref-type="fig" rid="pcbi.1004471.g003">Fig 3c</xref>). Examining the feedback strength at these transition times across the same trials allowed us to understand how the instantaneous feedback strength affects the repeat probability (<xref ref-type="fig" rid="pcbi.1004471.g003">Fig 3d</xref>). Not surprisingly, we found that the repeat probability increases with the strengths of the auditory synapses. Repeat probability <italic>p</italic><sub><italic>r</italic></sub> as a function of the feedback strength could be well fit with the sigmoidal function (<xref ref-type="fig" rid="pcbi.1004471.g003">Fig 3d</xref>, red curve)
<disp-formula id="pcbi.1004471.e001"><alternatives><graphic id="pcbi.1004471.e001g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e001"/><mml:math id="M1" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>p</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>A</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:msup><mml:mi>A</mml:mi> <mml:mi>ν</mml:mi></mml:msup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>A</italic> &gt; 0 represents the strength of the auditory synapses, <italic>η</italic>, <italic>ν</italic> &gt; 0 are parameters controlling the shape of the curve, and 0 &lt; <italic>c</italic> &lt; 1 is a parameter for the repeat probability when there is no auditory feedback (i.e. <italic>A</italic> = 0), which is determined by the connection strengths of the network at the branching point. Note that, when the auditory input <italic>A</italic> = 0, the repeat probability is <italic>p</italic><sub><italic>r</italic></sub> = 1 − <italic>c</italic>, and conversely, as <italic>A</italic> is large, <italic>p</italic><sub><italic>r</italic></sub> approaches 1.</p>
<p>Initially, the strong auditory feedback biases the network toward repeating and so the repeat probability is close to 1. If the strong excitatory input resulting from auditory feedback were constant, the network would perseverate on repeating syllable ‘b’ indefinitely (a result of the positive feedback loop). However, because of the short-term synaptic depression, the auditory input to chain-b when syllable ‘b’ repeats decreases exponentially over time (<xref ref-type="fig" rid="pcbi.1004471.g003">Fig 3b</xref>, red line; time-constant of <italic>τ</italic> = 148 ms for this particular network). Even so, the repeat probability stays close to 1 as long as the auditory input is strong enough. Further weakening of the feedback reduces the repeat probability more significantly, making repeat-ending transitions to chain-c more likely. For this network, this process produced a repeat number distribution peaked at 6, as shown in <xref ref-type="fig" rid="pcbi.1004471.g003">Fig 3e</xref>. These results demonstrate that branched-chain networks receiving adapting excitatory inputs can generate repeat distributions that are non-Markovian.</p>
</sec>
<sec id="sec004">
<title>Statistical model for the repeat number distributions</title>
<p>The repeat number distributions from our network model can be described using a simple statistical model with a small number of parameters. In our network model, the gradual reduction of excitatory drive from auditory feedback as a syllable is repeated reduces the probability that the syllable transitions to itself, and thus reduces the repeat probability. <xref ref-type="disp-formula" rid="pcbi.1004471.e001">Eq (1)</xref> describes the dependence of the repeat probability <italic>p</italic><sub><italic>r</italic></sub> on the auditory input strength, <italic>A</italic>. The synaptic depression model tells us how <italic>A</italic> changes with time. Sampling this at the transition times describes how <italic>A</italic> changes with the repeat number, <italic>n</italic>. At the end of the <italic>n</italic>th repeat of the syllable, <italic>A</italic> reduces to
<disp-formula id="pcbi.1004471.e002"><alternatives><graphic id="pcbi.1004471.e002g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e002"/><mml:math id="M2" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>n</mml:mi> <mml:mi>T</mml:mi> <mml:mo>/</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
where <italic>a</italic><sub>0</sub> is the initial strength of the auditory feedback, <italic>τ</italic> is the time constant of the input decay, and <italic>T</italic> is the duration of the syllable. Combining this with the dependence of the repeat probability on <italic>A</italic>, shown in <xref ref-type="disp-formula" rid="pcbi.1004471.e001">Eq (1)</xref>, we find that the repeat probability after the <italic>n</italic>th repetition of the syllable is given by
<disp-formula id="pcbi.1004471.e003"><alternatives><graphic id="pcbi.1004471.e003g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e003"/><mml:math id="M3" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>p</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:msubsup><mml:mi>a</mml:mi> <mml:mn>0</mml:mn> <mml:mi>ν</mml:mi></mml:msubsup> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>n</mml:mi> <mml:mi>ν</mml:mi> <mml:mi>T</mml:mi> <mml:mo>/</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>c</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>a</mml:mi> <mml:msup><mml:mi>b</mml:mi> <mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where <inline-formula id="pcbi.1004471.e004"><alternatives><graphic id="pcbi.1004471.e004g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e004"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mrow><mml:mi>a</mml:mi> <mml:mo>=</mml:mo> <mml:mi>η</mml:mi> <mml:msubsup><mml:mi>a</mml:mi> <mml:mn>0</mml:mn> <mml:mi>ν</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <italic>b</italic> = <italic>e</italic><sup>−<italic>νT</italic>/<italic>τ</italic></sup>. Therefore, there are effectively three parameters (<italic>a</italic>, <italic>b</italic> and <italic>c</italic>) for how <italic>p</italic><sub><italic>r</italic></sub> depends on <italic>n</italic>. We call <xref ref-type="disp-formula" rid="pcbi.1004471.e003">Eq (3)</xref> the sigmoidal adaptation model of repeat probability.</p>
<p>The network sequence dynamics can be represented with a state transition model, in which a single state corresponds to the repeating chain. The state can transition to itself with a probability <italic>p</italic><sub><italic>r</italic></sub>(<italic>n</italic>) given by <xref ref-type="disp-formula" rid="pcbi.1004471.e003">Eq (3)</xref>, or exit the state with probability 1 − <italic>p</italic><sub><italic>r</italic></sub>(<italic>n</italic>). This single state transition model can accurately fit the repeat number distributions generated by the network simulations with varying parameters, as shown in <xref ref-type="fig" rid="pcbi.1004471.g004">Fig 4a</xref> (all fit errors below their respective benchmark errors, which characterize the fitting errors expected from the finiteness of the data set—see <xref ref-type="sec" rid="sec010">Materials and Methods</xref>).</p>
<fig id="pcbi.1004471.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004471.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Sigmoidal adaptation model of repeats and model predictions.</title>
<p>a: Six example repeat count histograms (black bars) from the neural network simulations with adapting auditory feedback and the best fit distributions from the sigmoidal adaptation model (red lines). The decay constants of the auditory feedback and the syllable lengths are varied to produce different repeat number distributions. Syllable lengths are changed by altering the number of groups per chain. All fit errors are smaller than benchmark errors. b: Best fit geometric adaptation models for the first histogram in a. With geometric adaptation, the probably of a state repeating is decreased by a constant factor with each consecutive repeat (Materials and Methods): (i) single state; (ii) two-states, both repeating; (iii) multiple-states, only final state repeating. In all cases, numbers on arrows are initial transition probabilities while the number in parenthesis is the constant adaptation factor. c: Comparison of model fits. Red is the best fit of the sigmoidal adaptation model with one state. Other colors are best fits of the corresponding models in b. The sigmoidal adaptation model provides a superior fit while only requiring a single state. d: Peak repeat number as a function of the initial auditory feedback strength and the adaptation strength generated using the sigmoidal adaptation model. The peak repeat number increases for increasing initial feedback strength and decreases for increasing adaptation strength. For a given adaptation strength, there is a threshold feedback strength at which repeat distributions become non-Markovian (i.e. peak repeat number &gt; 1).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004471.g004"/>
</fig>
<p>This model contains the Markov model and a previously described ‘geometric adaptation’ model [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>] as special cases (Materials and Methods). Both of these models fail to fit the simulated data, even when a large number of states/parameters are used (<xref ref-type="fig" rid="pcbi.1004471.g004">Fig 4b and 4c</xref>). On the other hand, we have shown that the sigmoidal model provides an accurate fit with a single state and a small number of parameters. Therefore, relative to other statistical models, the single-state transition model with sigmoidal adaptation parsimoniously and accurately replicates the syllable repetition statistics of our network model.</p>
<p>Using the single state transition model with sigmoidal adaptation, we explored how peak repeat numbers depend on the initial feedback strength and the adaptation strength (defined by the related parameter, <italic>α</italic>, in the synaptic depression model, Materials and Methods) (<xref ref-type="fig" rid="pcbi.1004471.g004">Fig 4d</xref>). Here we see that, for a given adaptation strength, there is a threshold feedback strength at which the peak repeat number is greater than 1, and this threshold increases with increasing adaptation strength. This demarcates the transition between Markovian (peak repeat number = 1) and non-Markovian (peak repeat number &gt; 1) repeat distributions (black-to-red transition in (<xref ref-type="fig" rid="pcbi.1004471.g004">Fig 4d</xref>)). Further increases in the feedback strength result in larger peak repeat numbers. Conversely, for a given feedback strength, increasing the adaptation strength results in a reduction of the peak repeat number. Together, these results demonstrate that a large range of peak repeat numbers can be generated through various combinations of feedback and adaptation strengths, and suggest that there is a threshold feedback strength required to produce non-Markovian repeat distributions.</p>
</sec>
<sec id="sec005">
<title>Sigmoidal adaptation model fits diverse repeat number distributions of Bengalese finch songs</title>
<p>To see whether the non-Markovian repeat distributions generated with our network model can accurately describe syllable repeat number distributions of actual Bengalese finch songs, we recorded and analyzed the songs of 32 Bengalese finches. We identified the song syllables and obtained the syllable sequences (Materials and Methods). Our data set contains more than 82,000 instances of 281 unique syllables, of which 71 are repeating syllables. Since the simulations of the network model are slow, we used the single state transition model with sigmoidal adaptation to fit the repeat number distributions for these syllables. As demonstrated above, the statistical model (<xref ref-type="disp-formula" rid="pcbi.1004471.e003">Eq (3)</xref>) captures the essential features of our network model, and succinctly represents the repeat number distributions produced by the network simulations.</p>
<p>In <xref ref-type="fig" rid="pcbi.1004471.g005">Fig 5a</xref>, we show six examples of Bengalese finch repeat count histograms (grey bars) with different peak repeat counts (peak repeat count increases across plots i-vi.), and the best-fit model distributions (red lines). These examples show a range of distribution peaks and shapes, from small peak numbers with long rightward tails (i), to large peak numbers with tight, symmetric tails. Interestingly, we found that three repeated syllables (out of 71) had clear double-peaked distributions, with a prominent peak at repeat number 1 and another peak far away (two of which are displayed in panels ii and vi). These double peaked distributions cannot be explained with a single state transition model. A simple explanation is that the single peak and the broad peak are generated by two separate states (or neural substrate), as postulated in Jin &amp; Kozhevinov (the “many-to-one mapping” from multiple chains in HVC to the same syllable type) [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>]. Here we removed the single peak at repeat number 1 for these three syllables and only analyzed the longer repeat parts. The state transition with sigmoidal adaptation model does an excellent job of fitting the wide variety of peaks and shapes of the repeat distributions found in the Bengalese finches.</p>
<fig id="pcbi.1004471.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004471.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Sigmoidal adaptation model fits diverse repeat number distributions of Bengalese finch songs.</title>
<p>a: Six example Bengalese finch repeat count histograms (grey bars) and the best-fit model distributions (red lines). Peak repeat count increases from left-to-right and down columns. Distribution marked with (*) provide two examples of repeat distributions that have clear double peaks. For these cases, the peaks at repeat number 1 are excluded. b: Scatter plot of fit error vs. benchmark error. Each red circle corresponds to the distribution for one repeated syllable from the song database. The fit errors are smaller than the benchmark errors in the vast majority of cases (86%).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004471.g005"/>
</fig>
<p>The results comparing the fit errors from the sigmoidal adaption model to benchmark errors across all 71 repeating syllables are shown in <xref ref-type="fig" rid="pcbi.1004471.g005">Fig 5b</xref> (Materials and Methods; see also [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>]). The vast majority of fit errors from the feedback adaptation model are below their respective benchmark errors (86% of fit errors below the benchmark error), demonstrating that the model does an excellent job of fitting the diverse shapes of Bengalese finch song repeat number distributions. Therefore, the single state transition model with sigmoidal adaptation, and by extension the branched-chain model with adaptive auditory feedback, can successfully describe the syllable repeat number distributions in Bengalese finch songs.</p>
</sec>
<sec id="sec006">
<title>Removal of auditory feedback in Bengalese finches by deafening reduces peak repeat numbers</title>
<p>In our framework, auditory feedback from the previous syllable arrives in HVC at a time appropriate to provide driving excitatory input to HVC neurons that generate the upcoming syllable. For repeated syllables, this creates a positive feedback loop which is responsible for generating peak repeat numbers greater than 1 (adaptation drives the process to extinction). Therefore, a key prediction is that without auditory-feedback driven excitatory input, the peak-repeat number should shift toward 1. To test this prediction, we deafened six Bengalese finches by bilateral removal of the cochlea, and analyzed the songs before and soon after they were deafened (2–4 days) (Materials and Methods).</p>
<p>We found that deafening greatly reduces the peak repeat-counts. For example, in <xref ref-type="fig" rid="pcbi.1004471.g006">Fig 6a</xref>, we display spectrograms and rectified amplitude waveforms of the song from one bird prior to deafening (top) and soon after deafening (2–3 days post-deafening). We see that deafening reduces the number of times that the syllable (red-dashed box) is repeated. The time course of repeat generation from this bird is examined in more detail in <xref ref-type="fig" rid="pcbi.1004471.g006">Fig 6b</xref>, where we plot the median repeat counts per song of the syllable from <xref ref-type="fig" rid="pcbi.1004471.g006">Fig 6a</xref> before deafening (black) and after deafening (red). Here we see that, even in the first songs recorded post-deafening, there is a marked decrease in the produced number of repeats. This data further exemplifies that repeat counts per song is generally stable across bouts of singing within a day both before and after deafening. Across days, repeat counts continued to slowly decline with time since deafening, though the co-occurrence of acoustic degradation of syllables makes these later effects difficult to interpret [<xref ref-type="bibr" rid="pcbi.1004471.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref054">54</xref>]. Nonetheless, the rapidity of the effect of deafening underscores the acute function of auditory feedback in the generation of repeated syllables.</p>
<fig id="pcbi.1004471.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004471.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Removal of auditory feedback in Bengalese finches by deafening reduces peak repeat counts.</title>
<p>a: Example spectrograms and rectified amplitude waveforms (blue traces) for the song of one bird before (top) and after (bottom) deafening. Red dashed boxes demarcate the repeated syllables. b: Median repeat counts per song of the syllable from before deafening (black) and after deafening (red). Rotated probability distributions at the right hand side display the repeat counts across all recorded songs before (black) and after (red) deafening. c: Additional examples of repeat distributions pre- (black) and post- (red) deafening. For syllables that were repeated many times, deafening caused sharp reductions in repetitions, resulting in repeat number distributions that are more Markovian (upper graphs). Deafening had less of an effect on syllables that were repeated fewer times (lower graphs). d: Deafening results in a significant decrease in the peak repeat numbers. Individual syllables are in black (overlapping points are vertically shifted for visual clarity), median across syllables is in red. (Wilcoxon sign-rank test, <italic>p</italic> &lt; 10<sup>−2</sup>, <italic>N</italic> = 19). e: Peak repeat numbers before deafening vs. the differences in peak repeat numbers before and after deafening. Red dots correspond to syllables and black line is from linear regression. Larger decreases in peak repeat numbers for syllables that were repeated many times before deafening (<italic>R</italic><sup>2</sup> = 0.81, <italic>p</italic> &lt; 10<sup>−7</sup>, <italic>N</italic> = 19).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004471.g006"/>
</fig>
<p>Similar results were seen across the other repeated syllables. <xref ref-type="fig" rid="pcbi.1004471.g006">Fig 6c</xref> shows the repeat number distributions for two additional birds before (black) and after (red) deafening. In these cases, deafening resulted in repeat number distributions that monotonically decayed. The peak repeat numbers pre and post deafening for all 19 syllables in our data set are presented in <xref ref-type="fig" rid="pcbi.1004471.g006">Fig 6d</xref>. Across the 19 repeated syllables from 6 birds, deafening significantly reduced the number of consecutively produced repeated syllables (<xref ref-type="fig" rid="pcbi.1004471.g006">Fig 6d</xref>, <italic>p</italic> &lt; 0.01, sign-rank test, <italic>N</italic> = 19, medians demarcated in red, overlapping points are vertically shifted), although there was variability in the effect magnitude: the effect of deafening appeared larger for the repeat with larger initial repeat number (compare upper and lower panels of <xref ref-type="fig" rid="pcbi.1004471.g006">Fig 6c</xref>). This suggests that the degree to which deafening reduces peak repeat number depends on the initial repeat number. We examined the change in peak repeat number resulting from deafening as a function of the peak repeat number before deafening (<xref ref-type="fig" rid="pcbi.1004471.g006">Fig 6e</xref>, red dots correspond to data from individual syllables, overlapping points are horizontally offset for visual display). We found that the magnitude of decrease in peak repeat numbers after deafening grows progressively larger for syllables with greater peak repeat numbers before deafening (<italic>R</italic><sup>2</sup> = 0.81, <italic>p</italic> &lt; 10<sup>−7</sup>, <italic>N</italic> = 19). This suggests that repeated syllables with larger repeat numbers are progressively more dependent upon auditory feedback for repeat production. Interestingly, after two days of hearing loss, one of the deafened Bengalese finches in our experiments had a repeat that was minimally affected by deafening, and several birds retained peak repeat number around 2, not all the way to 1 as predicted for a Markov process (<xref ref-type="fig" rid="pcbi.1004471.g006">Fig 6d</xref>). None-the-less, these deafening results are consistent with the hypothesis that the generation of repeated syllables is driven, in-part, by a positive-feedback loop caused by excitatory auditory input during singing.</p>
</sec>
<sec id="sec007">
<title>HVC auditory responses to repeated syllables gradually adapt</title>
<p>A key prediction of the adaptive feedback model for repeat generation is that auditory responses of HVC neurons should decline over the course of repeated presentations of the same syllable. To test this hypothesis, we examined the properties of HVC auditory responses to repeated syllables in sedated birds (Materials and Methods). An example recording from an HVC multi-unit site in response to playback of the bird’s own song (BOS) stimulus is presented in <xref ref-type="fig" rid="pcbi.1004471.g007">Fig 7a</xref>, which displays the stimulus oscillogram (top), and the average spike rate in response to the stimulus (bottom). Multiple renditions of the repeated syllable are demarcated by red-dashed boxes, and we see that the evoked HVC auditory responses to repeated versions of the same syllable gradually declined.</p>
<fig id="pcbi.1004471.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004471.g007</object-id>
<label>Fig 7</label>
<caption>
<title>HVC auditory responses to repeated syllables gradually adapt.</title>
<p>a: Example auditory recording from an HVC multi-unit site in response to playback of the BOS (bird’s own song) stimulus. Top panel is the song oscillogram. Bottom plot is the average response rate across trials. Adaptation of HVC auditory responses to a repeated syllable (demarcated by red-dashed lines) is observed. b: Responses to the last syllable in a repeat as a function of the repeat number. Data are presented as mean ± s.e. of normalized auditory responses across sites for a given repeated syllable (11 sites in 4 birds, 6 repeated syllables). Data are colored from grey-to-red with increasing peak repeat number. Across syllables and sites, the response to the last syllable in a repeat declines with increasing repeat number. Black line is from linear regression (<italic>R</italic><sup>2</sup> = 0.523, <italic>p</italic> &lt; 10<sup>−10</sup>, <italic>N</italic> = 24, slope = -5%).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004471.g007"/>
</fig>
<p>The example presented above suggests that auditory responses to repeated presentations of the same syllable adapt over time. However, in the context of BOS stimuli, the natural variations that occur in syllable acoustics, inter-syllable gap timing, and in the identity of the preceding sequence, make it difficult to directly compare responses to different syllables in a repeated sequence. Therefore, to examine how responses to repeated syllables are affected by the length and identity of the preceding sequence, for each bird we constructed a stimulus set of long, pseudo-randomly ordered sequences of syllables (10,000 syllables in the stimulus, one prototype per unique syllable, median of all inter-syllable gaps used for each inter-syllable gap, derived from the corpus of each bird’s songs, Materials and Methods). This stimulus allows a systematic investigation of how auditory responses to acoustically identical syllables depend on the length and syllabic composition of the preceding sequence [<xref ref-type="bibr" rid="pcbi.1004471.ref028">28</xref>]. Auditory responses at 18 multi-unit recordings sites in HVC from 6 birds were collected for this data set, which contained 40 unique syllables. Of these 40 syllables, 6 syllables in 4 birds (with 11 recording sites) were found to naturally repeat.</p>
<p>We used these stimuli to systematically examine how auditory responses to a repeated syllable depend on the number of preceding repeated syllables. We found that HVC auditory responses gradually declined to repeated presentations of the same syllable. In <xref ref-type="fig" rid="pcbi.1004471.g007">Fig 7b</xref>, for each uniquely repeated syllable (different syllables are colored from grey-to-red with increasing max repeat number), we plot the average normalized auditory response (mean ±s.e. across sites) to that syllable (e.g. ‘b’) as a function of the repeat number (e.g. repeat number 5 corresponds to the last ‘b’ in ‘bbbbb’). Across HVC recordings sites and repeated syllables, the response to the last syllable declined as the number of preceding repeated syllables increased (<italic>R</italic><sup>2</sup> = 0.523, <italic>p</italic> &lt; 10<sup>−10</sup>, <italic>N</italic> = 24, slope = -5%).</p>
<p>Thus, auditory responses to repeated syllables gradually adapt as the number of preceding repeated syllables increases, providing confirmation of a key functional mechanism of the network model.</p>
</sec>
<sec id="sec008">
<title>Non-Markovian repeated syllables are loudest and evoke the largest HVC auditory responses</title>
<p>To generate non-Markovian repeat distributions, we have proposed that the sequence generation circuitry is driven, in part, by auditory feedback that provides excitatory drive to sensory-motor neurons that control sequencing. Specifically, auditory feedback from the previous syllable arrives in HVC at a time appropriate to provide driving excitatory input to neurons that generate the upcoming syllable. This predicts that if HVC auditory responses are positively modulated by sound amplitude, feedback associated with louder syllables should provide stronger drive to the motor units, and thus generate longer strings of repeated syllables for a given rate of adaptation. This logic is supported by the sigmoidal adaptation model, which predicts a threshold auditory feedback strength at which the peak repeat number becomes greater than one (i.e. non-Markovian, <xref ref-type="fig" rid="pcbi.1004471.g004">Fig 4b</xref>). Behaviorally, this predicts that non-Markovian sequences of repeated syllables should be composed of the loudest syllables in the bird’s repertoire.</p>
<p>We tested this behavioral prediction by comparing the amplitudes of Bengalese finch vocalizations based on their repeat structure. <xref ref-type="fig" rid="pcbi.1004471.g008">Fig 8a</xref> plots the rectified amplitude waveforms (mean ±s.d.) of a few consecutively produced repetitions of a non-Markovian repeated syllable (black), a Markovian repeated syllable (red), and ‘introductory’ note (grey) from one bird. The non-Markovian repeated syllable is qualitatively louder than the other repeated vocalizations in the birds’ repertoire. To quantitatively test this prediction, we measured the peak amplitude of the 281 unique syllables in our data set, and normalized this to the minimum peak amplitude across syllables (Materials and Methods). We categorized each syllable in our data set according to whether it was an introductory note (Intro), a non-repeated syllable (NR: repeats = 0), a Markovian repeated syllable (MR: peak repeat number = 1), or a non-Markovian repeated syllable (nMR: peak repeat number &gt; 1). In <xref ref-type="fig" rid="pcbi.1004471.g008">Fig 8b</xref>, we plot the mean ±s.e. of the normalized peak amplitudes of these syllable groups across the data set. As exemplified by the data in <xref ref-type="fig" rid="pcbi.1004471.g008">Fig 8a</xref>, we found that non-Markovian repeated syllables were significantly louder than the other vocalizations in a bird’s repertoire (***: <italic>p</italic> &lt; 10<sup>−3</sup>, **: <italic>p</italic> &lt; 10<sup>−2</sup>, sign-rank test, Bonferroni corrected for <italic>m</italic> = 3 comparisons). Therefore, syllables with non-Markovian repeat distributions are typically the loudest vocalizations produced by a bird.</p>
<fig id="pcbi.1004471.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004471.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Non-Markovian repeated syllables are loudest and evoke the largest HVC auditory responses.</title>
<p>a: Mean ±s.d. amplitude waveforms for a non-Markovian repeated syllable (black), a Markov repeated syllable (red), and an intro note (grey) from the songs of one bird. b: Mean ±s.e. normalized peak amplitudes of song vocal elements. Intro notes (Intro), non-repeated syllables (NR), Markov-repeated syllables (MR, peak repeat number = 1), and non-Markovian repeated syllables (nMR, peak repeat number &gt; 1). non-Markovian repeated syllables are significantly louder than other vocalizations (<italic>p</italic> &lt; 10<sup>−3</sup>, <italic>p</italic> &lt; 0.01, Wilcoxon sign-rank test, Bonferroni corrected for <italic>m</italic> = 3 comparisons). c: Scatter plot of normalized auditory responses to a syllable as a function of the normalized amplitude of that syllable. Black line is from regression (<italic>R</italic><sup>2</sup> = 0.30;<italic>p</italic> &lt; 10<sup>−3</sup>, <italic>N</italic> = 40 syllables). d: Paired comparison of normalized auditory responses to non-repeated syllables (NR) and non-Markovian repeated syllables (nMR). Repeated syllables illicit larger auditory responses. (<italic>p</italic> &lt; 0.01, Wilcoxon sign-rank test, <italic>N</italic> = 11 sites). Circles: data; square: median.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004471.g008"/>
</fig>
<p>If amplitude is a contributing factor to repeat generation, then HVC auditory responses should be positively modulated by syllable amplitude. However, previous work in the avian primary auditory system has found a population of neurons that is insensitive to sound intensity [<xref ref-type="bibr" rid="pcbi.1004471.ref055">55</xref>], and amplitude normalized auditory responses have been utilized in previous models of sequence encoding in HVC auditory responses [<xref ref-type="bibr" rid="pcbi.1004471.ref056">56</xref>]. Therefore, we first examined whether auditory responses were positively modulated by syllable amplitude. To make recordings from different sites/birds comparable, we normalized both the syllable amplitudes (relative to mean) and auditory responses (relative to minimum). The scatter plot in <xref ref-type="fig" rid="pcbi.1004471.g008">Fig 8c</xref> plots the normalized syllable amplitudes vs. the normalized auditory responses (averaged across sites within a bird), for the 40 syllables in in our data set [<xref ref-type="bibr" rid="pcbi.1004471.ref028">28</xref>]. We found a modest but significant positive correlation between auditory responses and syllable amplitude (<italic>R</italic><sup>2</sup> = 0.30;<italic>p</italic> &lt; 10<sup>−3</sup>, <italic>N</italic> = 40 syllables). We next examined whether the increased amplitude of repeated syllables resulted in increased HVC auditory response to these syllables. We performed a paired comparison of normalized auditory responses to non-repeated syllables (NR) and non-Markovian repeated syllables (nMR) at the 11 sites where auditory responses to repeated syllables were collected (<xref ref-type="fig" rid="pcbi.1004471.g008">Fig 8d</xref>). We found that repeated syllables had significantly larger auditory responses than non-repeated syllables (<italic>p</italic> &lt; 0.01, sign-rank test, <italic>N</italic> = 11 sites). Thus, HVC auditory responses are sensitive to syllable amplitude, and repeated syllables elicit larger auditory responses than non-repeated syllables, likely due to being the loudest syllables that a bird sings. Therefore, the strong auditory feedback associated with these loud repeated syllables may be a key contributor to their non-Markovian repeat distributions.</p>
</sec>
</sec>
<sec id="sec009" sec-type="conclusions">
<title>Discussion</title>
<p>We have provided converging evidence that adapting auditory feedback directly contributes to the generation of long repetitive vocal sequences with non-Markovian repeat number distributions in the Bengalese finch. A branching chain network model with adapting auditory feedback to the repeating syllable-chains produces repeat number distributions similar to those observed in the Bengalese finch songs. From the network model we derive the sigmoidal adaptation model for repeat probability, and show that it reproduces the repeat distributions of both the branching chain network and Bengalese finch data. Removal of auditory feedback by deafening reduced the peak repeat number, confirming one of the key features of the proposed mechanism. Furthermore, recordings in the Bengalese finch HVC show that auditory responses of HVC adapt to repeated presentations of the same syllable, providing evidence for another key feature of the proposed mechanism. Finally, we found that non-Markovian repeated syllables are louder than other syllables and elicit stronger auditory responses, suggesting that a threshold auditory feedback magnitude is required to generate long strings of repeated syllables, in agreement with modeling results. Together, these results implicate an adapting, positive auditory-feedback loop in the generation of long repeated syllable sequences, and suggest that animals may directly use normal sensory-feedback signals to guide behavioral sequence generation with sensory adaptation preventing behaviorally deleterious perseveration.</p>
<p>In our framework, a positive feedback loop to a repeating syllable provides strong excitatory drive to that syllable and sustains high repeat probability. The strength of this feedback gradually reduces while the syllable repeats, preventing the network from perseverating on the repeated syllable. The combination of strong, positive feedback and gradual adaptation allows the production of non-Markovian repeat number distributions in the branching chain networks. It should be emphasized that this feedback mechanism is not necessary for repeat syllables with Markovian repeat number distributions [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>]. Such Markovian repeats are short, and can be simply generated with self connections in the branching chain network model without auditory feedback [<xref ref-type="bibr" rid="pcbi.1004471.ref026">26</xref>].</p>
<p>We have conceptualized the adapting feedback as short-term synaptic depression of the NIf to HVC synapses resulting from auditory feedback. However, neither the exact source of the feedback nor the mechanism generating the adaptation is critical for our model. Indeed, the adaptation of auditory responses could arise from a variety of pre- and/or post-synaptic mechanisms anywhere in the auditory pathway, such as in the auditory forebrain [<xref ref-type="bibr" rid="pcbi.1004471.ref057">57</xref>], the auditory responses of NIf [<xref ref-type="bibr" rid="pcbi.1004471.ref047">47</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref050">50</xref>] or other auditory inputs to HVC such CM (caudal mesopallium) [<xref ref-type="bibr" rid="pcbi.1004471.ref058">58</xref>], or within HVC itself. The biophysical origin of the auditory adaptation in HVC observed in our experiments remains to be determined. Our experiments showing the adaptation of auditory feedback for the repeated syllables were performed on passively listening birds. Future experiments on singing birds are required to see whether such adaptation occurs in the singing state.</p>
<p>Previous experiments that deafened Bengalese finches showed that removal of auditory feedback has immediate impact on the song syntax of the Bengalese finch [<xref ref-type="bibr" rid="pcbi.1004471.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref054">54</xref>]. The main effect reported was the increased randomness in the syllable sequences. However, the impacts on syllable repeats was not analyzed. Our own deafening experiments showed that long repeated syllables are particularly vulnerable to loss of hearing, and their repeat number distributions shift close to Markov distributions two days after deafening. The Markovian repeats, on the other hand, were not affected as much. These new observations supports the idea that non-Markovian repeats rely more on auditory feedback than Markovian ones, as suggested by our computational model. However, it should be noted that the deafening results are consistent with our model but do not prove it. There could be alternative explanations, including possible systematic changes in the stress level, the arousal states, the neural circuits in the auditory and motor areas during the recovery from deafening. Future experiments that directly manipulate auditory feedback online in intact brain will help to further test our model.</p>
<p>After two days of hearing loss, one of the deafened Bengalese finches in our experiments maintained peaked repeat number distributions, and several birds retained peaked repeat numbers around 2, not all the way to 1 as predicted for a Markov process. One possible explanation is the existence of multiple chains that produce syllables with similar acoustic features [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>]. Such a “many-to-one mapping” could produce residual non-Markovian features in the repeat number distribution after deafening. Another possibility is that there are several internal feedback loops to HVC within the song system that could contribute to repeating syllables. For example, there are direct anatomical projections from RA back to HVC [<xref ref-type="bibr" rid="pcbi.1004471.ref059">59</xref>] as well as through the medial portion of MAN (mMAN) [<xref ref-type="bibr" rid="pcbi.1004471.ref060">60</xref>]. Furthermore, there are connections from vocal brainstem nuclei to HVC through Uva and NIf [<xref ref-type="bibr" rid="pcbi.1004471.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref061">61</xref>]. Although the signals transmitted through these internal feedback loops are poorly understood, they are likely to contribute to the temporal/sequential structure of song [<xref ref-type="bibr" rid="pcbi.1004471.ref062">62</xref>]. These internal feedback loops may also contribute to, or even be the main routes of connecting the syllable encoding chains in HVC, rather than the direct connections between the chains within HVC as assumed in our network model. Furthermore, such internal feedback loops could be one site of adapting excitatory drive that contributes to the generation of non-Markovian repeats. However, our deafening results suggest that auditory feedback is a primary source of excitatory drive for repeat generation. Our modeling results will not change if such internal feedback loops are used instead of the direct connections for sequence generation, or instead of auditory feedback as the route of adapting positive feedback.</p>
<p>The feedback delay time plays an important role in our model, as the feedback signal must return to HVC in time to exert an influence on the selection of the next syllable. We have hypothesized a simple scenario where these feedback signals are auditory in nature. Each is tuned to a specific syllable in the bird’s repertoire and targets entire chains within HVC. In this case, there is a simple constraint on the delay time for the auditory feedback to exert its influence on the song sequence: the total delay time must be less than the duration of the syllable under examination. Different delay times conforming to this constraint would lead to slight changes in the repeat distribution due to small differences in the initial amount of adaptation experienced on the first repetition, but with no qualitative differences. This constraint could be pushed beyond its limit by very short syllables that terminate before the auditory feedback would return to HVC, precluding the ability of auditory feedback to influence the subsequent transition. If non-auditory internal feedback loops were to carry such a signal, the delay time—and thus the corresponding constraint—could be significantly shorter than predicted for the auditory case. Another possibility is that the delay makes the auditory feedback effective only after the syllable has repeated once or twice. The initial repeats could be sustained by the intrinsic self-connections of the chain network encoding the repeated syllable (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2c</xref>). The auditory feedback can then arrive to sustain a long repetition. If the self-connections are weak, the syllable tends to stop at one or two repetitions; but once it repeats more than once or twice, the arriving auditory feedback can take over and sustain a long repetition. This could be another mechanism for the double peaked repeat number distributions we have observed (<xref ref-type="fig" rid="pcbi.1004471.g005">Fig 5a</xref>), in addition to the possibility of a “many-to-one” mapping from HVC to the syllable types. It will be interesting to distinguish these possibilities in future studies.</p>
<p>We observed that non-Markovian repeated syllables are typically the loudest syllables in a bird’s repertoire. Furthermore, HVC responses to repeated syllables were significantly greater than responses to non-repeated syllables. Together, these results suggest that louder syllables provide stronger auditory feedback to HVC. This is consistent with our model, in which non-Markovian repeats are strongly influenced by auditory feedback to HVC, though by no means does our model predict such a result. The relationship between the syllable amplitude and repeat length can be further tested with experiments that manipulate syllable amplitudes online with realtime auditory feedback [<xref ref-type="bibr" rid="pcbi.1004471.ref022">22</xref>]. It should be noted, however, we are not suggesting that a syllable is loud because of a strong auditory input to HVC. The control of syllable amplitude could depend on multiple neural mechanisms. It remains to be investigated why the non-Markovian repeated syllables are louder than other syllables.</p>
<p>Our framework can be extended to allow auditory feedback to influence transition probabilities beyond repeated syllables. In general, because the auditory-motor delay in HVC due to neural processing is on the order of a syllable duration (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2a</xref>), auditory feedback from the previous syllable arrives in HVC at a time to contribute to the motor activity for the current syllable [<xref ref-type="bibr" rid="pcbi.1004471.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref028">28</xref>]. For a diverging transition of syllable ‘a’ to either ‘b’ or to ‘c’, as shown in <xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2b</xref>, auditory feedback from syllable ‘a’ can be applied to chain-b and chain-c. Depending on the amount of feedback on each chain, the transition probability to ‘b’ or ‘c’ can be enhanced or reduced by the feedback. Our model for repeating syllables (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2c</xref>) can be thought of as a special case of this general scenario, in which the repeating syllable-chain receives much stronger auditory input than the competing chain. The strong auditory feedback for repeated syllables may in part reflect synaptic weights that have been facilitated by Hebbian mechanisms operating on the repeated coincidence of auditory feedback with motor activity [<xref ref-type="bibr" rid="pcbi.1004471.ref028">28</xref>]. This framework is consistent with the observations that manipulating auditory feedback experimentally can change the transition probabilities [<xref ref-type="bibr" rid="pcbi.1004471.ref013">13</xref>]. Auditory feedback plays a secondary role in determining the song syntax in our proposed mechanism. The allowed syllable transitions are encoded by the branching patterns of the chain networks. Auditory feedback biases the transition probabilities, to varying degrees for different syllable transitions. The secondary role of auditory feedback on the syntax could be the reason for the individual variations seen in a previous deafening experiment [<xref ref-type="bibr" rid="pcbi.1004471.ref024">24</xref>]. Indeed, it was observed that one Bengalese finch maintained its song syntax 30 days after deafening [<xref ref-type="bibr" rid="pcbi.1004471.ref024">24</xref>]. The secondary role of feedback in our model is in contrast to the model of Hanuschkin et al, who relied entirely on auditory feedback for determining syllable transitions [<xref ref-type="bibr" rid="pcbi.1004471.ref027">27</xref>]. However, as in the Hanuschkin model, our model emphasizes the role of auditory feedback in shaping song syntax.</p>
<p>We have theorized that auditory feedback provides direct inputs to HVC<sub>RA</sub> neurons in controlling syllable repetitions in the Bengalese finch. Whether auditory feedback can reach HVC<sub>RA</sub> neurons in the Bengalese finch is not yet known. Recent experiments that recorded projection neurons intracellularly in HVC of the zebra finch, whose song consists of fixed sequences of syllables, demonstrated that auditory feedback is gated off and does not provide inputs to the projection neurons during singing [<xref ref-type="bibr" rid="pcbi.1004471.ref063">63</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref064">64</xref>]. On the other hand, it was shown that the firing rates in HVC of the Bengalese finch changed during singing when the auditory feedback was manipulated [<xref ref-type="bibr" rid="pcbi.1004471.ref014">14</xref>], suggesting that auditory feedback can influence HVC during singing in this species. It is possible that the differences in sequence complexity between these species may in part be due to different online sensitivities to auditory feedback [<xref ref-type="bibr" rid="pcbi.1004471.ref024">24</xref>]. Syllable repetitions are common in many other songbird species, including the canary [<xref ref-type="bibr" rid="pcbi.1004471.ref019">19</xref>]. It remains to be seen whether auditory feedback plays an important role in syllable repetitions in species other than the Bengalese finch. The differences of sensory-motor integration during singing in different species of songbirds need further investigations.</p>
<p>Probabilistic state transition models have been used for describing variable birdsong syntax with high accuracy [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>]. Multiple states for a single syllable are often required for the state transition model to capture the statistical properties of the syllable sequences, resulting in the partially observable Markov model with adaptation (POMMA) [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>]. Such many-to-one mapping manifests as multiple peaks in the repeat number distributions in our data (<xref ref-type="fig" rid="pcbi.1004471.g005">Fig 5a</xref>). However, some of the multiple states in POMMA could also be due to the inaccurate description of history-dependence of the transition probabilities. The geometric adaptation model for the repeat probability, used in the previous work [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>], often leads to multiple states to accurately capture the non-Markovian repeat number distributions, as shown in <xref ref-type="fig" rid="pcbi.1004471.g004">Fig 4b and 4c</xref>. In contrast, the sigmoidal adaptation model for the repeat probability, derived from our network model, enables accurate description of such distributions using a single state. Thus the sigmoidal adaptation model should reduce the complexity of POMMA for the Bengalese finch song syntax.</p>
<p>For motor control with continuous trajectories, such as reaching movements or articulation of single speech phonemes, it has been proposed that internal models estimate sensory consequences of motor commands, compare these estimates to actual sensory feedback, and use the difference as error signals to correct ongoing motor commands [<xref ref-type="bibr" rid="pcbi.1004471.ref065">65</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref068">68</xref>]. Along these lines, recent recordings in the auditory areas Field-L and CLM (caudolateral medopallium) of the zebra finch showed that, during singing, a subset of neurons exhibit activity that is similar to, but precedes, the activity induced by playback of the birds own song [<xref ref-type="bibr" rid="pcbi.1004471.ref069">69</xref>]. These data have led to the hypothesis that the songbird auditory system encodes a prediction of the expected auditory feedback (“forward model”) used to cancel expected incoming auditory feedback signals [<xref ref-type="bibr" rid="pcbi.1004471.ref039">39</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref065">65</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref069">69</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref070">70</xref>]. According to such a forward model interpretation, as long as feedback matches expectation, auditory feedback does not reach HVC and therefore does not contribute to song generation during singing [<xref ref-type="bibr" rid="pcbi.1004471.ref064">64</xref>]. At the surface, this seems at odds with our framework in which auditory feedback has a direct role in song generation, in particular for repeats. One possible resolution is that due to the probabilistic syllable transitions, auditory feedback cannot be fully predicted and canceled by the forward model since the motor actions themselves are not entirely predictable. Such imperfect cancelation allows direct influence of auditory feedback on syllable sequences. Another possibility is that due to the increased loudness of non-Markovian repeated syllables, residual auditory input reaches HVC and contributes to song generation.</p>
<p>Some similarities between non-Markovian syllable repetitions in birdsong and sound/syllable repetitions in stuttered speech have been observed in the past [<xref ref-type="bibr" rid="pcbi.1004471.ref071">71</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref073">73</xref>]. In persons who stutter, repeating syllables within words (‘to-to-to-today’, for example) is a prominent type of speech disfluency [<xref ref-type="bibr" rid="pcbi.1004471.ref074">74</xref>–<xref ref-type="bibr" rid="pcbi.1004471.ref076">76</xref>]. Auditory feedback plays an important, but poorly understood, role in stuttered speech. For example, altering auditory feedback, including deafening [<xref ref-type="bibr" rid="pcbi.1004471.ref074">74</xref>], noise masking [<xref ref-type="bibr" rid="pcbi.1004471.ref077">77</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref078">78</xref>], changing frequency [<xref ref-type="bibr" rid="pcbi.1004471.ref079">79</xref>], and delaying auditory feedback reduces stuttering [<xref ref-type="bibr" rid="pcbi.1004471.ref080">80</xref>]. Conversely, delayed feedback can induce stuttering in people with normal speech [<xref ref-type="bibr" rid="pcbi.1004471.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref011">11</xref>]. Auditory processing may be abnormal both in zebra finches with abnormal syllable repetitions and in persons who stutter [<xref ref-type="bibr" rid="pcbi.1004471.ref071">71</xref>]. Our observation that deafening reduces syllable repetitions in Bengalese finch songs echoes the reduction of stuttering after deafening in persons who stutter [<xref ref-type="bibr" rid="pcbi.1004471.ref074">74</xref>]. In general agreement with our proposed role of auditory feedback in repeat generation, some theories suggest that persons who stutter have weak feed-forward control and overly rely on auditory feedback for speech production [<xref ref-type="bibr" rid="pcbi.1004471.ref067">67</xref>]. It will be interesting to see whether further quantitative analysis of the statistics of stuttered speech would reveal additional behavioral similarities, such as non-Markovian distributions and increased amplitude; to our knowledge no such examination exists. Such similarities could point to shared neural mechanisms with syllable repetition in birdsong, especially the possibility that auditory feedback plays a key role. However, our study also provides a cautionary note to the interpretation of repeated syllables in birdsong as ‘stutters’. Our analysis shows that syllables with non-Markovian repeat distributions are loud and require strong auditory feedback. In contrast, syllables with Markovian repeat distributions are quieter and are less reliant on auditory feedback for their generation. We propose that it is the former type of syllable repetition that shares similarity to stuttering in humans.</p>
</sec>
<sec id="sec010" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="sec011">
<title>Ethics Statement</title>
<p>All procedures involving animals were performed in accordance with established animal care protocols approved by the University of California, San Francisco Institutional Animal Care and Use Committee (IACUC).</p>
</sec>
<sec id="sec012">
<title>Model neurons</title>
<p>The model neurons for the network simulations are a reproduction of those in previous works [<xref ref-type="bibr" rid="pcbi.1004471.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref035">35</xref>]. Below, we summarize the key aspects of these models. The reader is referred to these papers for exact details on the equations and constants. Since detailed information about the ion channels of HVC neurons is unavailable, we model both HVC<sub>RA</sub> and HVC<sub>I</sub> neurons as simple Hodgkin-Huxley type neurons, adding extra features to match available electrophysiological data. HVC<sub>I</sub> neurons exhibit prolonged tonic spiking during [<xref ref-type="bibr" rid="pcbi.1004471.ref035">35</xref>]. To simulate this we use a single-compartment model with the standard sodium-potassium mechanism for action potential generation along with an additional high-threshold potassium current that allows for rapid spike generation.</p>
<p>A distinctive feature of HVC<sub>RA</sub> neurons is that their activity comes in the form of precise bursts during song production [<xref ref-type="bibr" rid="pcbi.1004471.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref035">35</xref>]. This bursting activity increases the robustness of signal propagation along chains of these neurons [<xref ref-type="bibr" rid="pcbi.1004471.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref035">35</xref>]. A study of the subthreshold dynamics of HVC<sub>RA</sub> neurons during singing suggests that this bursting is an intrinsic property of these cells [<xref ref-type="bibr" rid="pcbi.1004471.ref035">35</xref>]. We generate this intrinsic bursting behavior with a two-compartment model [<xref ref-type="bibr" rid="pcbi.1004471.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref035">35</xref>]. A dendritic compartment contains a calcium current as well as a calcium-gated potassium current. When driven above threshold, these currents produce a stereotyped calcium spike in the form of a sustained (roughly 5 ms) depolarization of the dendritic compartment. A somatic compartment contains the standard sodium-potassium currents for generating action potentials. These compartments are ohmically coupled so that a calcium spike in the dendrite drives a burst of spikes in the soma.</p>
<p>All compartments also contain excitatory and inhibitory synaptic currents. Action potentials obey kick-and-decay dynamics. All synaptic conductances start at 0. When an excitatory or inhibitory action potential is delivered to a compartment, the corresponding synaptic conductance is immediately augmented by an amount equal to the strength of the synapse. In between spikes, the synaptic conductances decay exponentially toward zero.</p>
</sec>
<sec id="sec013">
<title>Branching synfire chain model</title>
<p>The network topology underlying all of the more advanced models below is the branching synfire chain network for HVC [<xref ref-type="bibr" rid="pcbi.1004471.ref026">26</xref>]. HVC<sub>RA</sub> neurons are grouped into pools of 60 neurons. 20 pools are then sequentially ordered to form a chain. Except for the final pool, all neurons in a pool make an excitatory connection to every neuron in the next pool (<xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2b</xref>). The strengths of these synapses are randomly generated from a uniform random distribution between 0 and <italic>G</italic><sub><italic>EE</italic>, <italic>max</italic></sub> = 0.09 mS/cm<sup>2</sup>. Because of this setup, activating the neurons in the first group sets off a chain reaction where each group activates the subsequent group, leading to a signal of neural activity propagating down the chain with a precise timing. There is one chain for every syllable in the repertoire of the bird. Activity flowing down a given chain drives production of the corresponding syllable through the precise temporal activation of different connections from the HVC<sub>RA</sub> neurons to RA (not explicitly modeled). To begin to impose a syntax on the song, the neurons in the final pool of one chain make connections to the initial pool of any chain whose syllable could follow its own. This branching pattern encodes the basic syllable transitions that are possible.</p>
<p>When the activity in an active chain reaches a branching point, all subsequent chains are activated, however only one should stay active—the syllable chosen next. This selection is achieved through lateral inhibition between the chains intermediated by HVC<sub>I</sub> neurons. There is a group of 1,000 HVC<sub>I</sub> neurons. Each HVC<sub>RA</sub> neuron has a chance of making an excitatory connection to each HVC<sub>I</sub> neuron with a probability <italic>p</italic><sub><italic>EI</italic></sub> = 0.05. Each of these connections has a strength randomly drawn from a uniform distribution between 0 and <italic>G</italic><sub><italic>EI</italic>, <italic>max</italic></sub> = 0.5 mS/cm<sup>2</sup>. In turn, each HVC<sub>I</sub> neuron has a chance of making an inhibitory connection to each HVC<sub>RA</sub> neuron with a probability <italic>p</italic><sub><italic>IE</italic></sub> = 0.1. The strengths of these connections are randomly drawn from a uniform distribution between 0 and <italic>G</italic><sub><italic>IE</italic>, <italic>max</italic></sub> = 0.7 mS/cm<sup>2</sup>. This setup gives a rough approximation of global inhibition on the HVC<sub>RA</sub> neurons which is what leads to the lateral inhibition between the chains that they comprise.</p>
<p>Noise is added to the network to make switching between chains a stochastic process. This noise is modeled as a Poisson process of spikes incident on each compartment of every neuron. The strength of each spike is randomly selected from a uniform distribution from 0 to <italic>G</italic><sub><italic>noise</italic></sub> and every spike has an equal chance of being excitatory or inhibitory. Both compartments of HVC<sub>RA</sub> neurons receive noise at a frequency of 500 Hz; at the soma <italic>G</italic><sub><italic>noise</italic></sub> = 0.045 mS/cm<sup>2</sup>, while at the dendrite <italic>G</italic><sub><italic>noise</italic></sub> = 0.035 mS/cm<sup>2</sup>. The single compartment of the HVC<sub>I</sub> neurons receive noise at a frequency of 500 Hz with <italic>G</italic><sub><italic>noise</italic></sub> = 0.45 mS/cm<sup>2</sup>. In HVC<sub>RA</sub> neurons, this leads to subthreshold membrane fluctuations of ∼ 3 mV; in the HVC<sub>I</sub> neurons, the results is a baseline firing rate of ∼ 10 Hz.</p>
<p>Each HVC<sub>RA</sub> neuron also receives an external drive that facilitates robust propagation of signals through the chains. This takes the form of a purely excitatory spike train modeled by a Poisson process with frequency 1,000 Hz. The strength of each spike is chosen from a uniform random distribution from 0 to 0.05 mS/cm<sup>2</sup>.</p>
</sec>
<sec id="sec014">
<title>Auditory feedback model</title>
<p>We incorporate auditory feedback into the branching synfire chain model in a manner similar to the external drive used in [<xref ref-type="bibr" rid="pcbi.1004471.ref026">26</xref>]. When a syllable is being produced and heard by the bird, some amount of auditory feedback can be delivered to any of the chains in the network in the form of external drives. The relative strength of this feedback drive between chains then biases transition probabilities so that auditory feedback plays an important role in determining song syntax.</p>
<p>The first piece in our model for auditory feedback is determining when auditory feedback from a specific syllable is active. We assume that the first few pools in every chain encode for the silence between syllables. Furthermore, once a syllable is being produced, there is a delay before auditory feedback begins that represents how long it takes for the bird to hear the syllable and process the auditory information. In our simulations, the activity of the 4th pool of every chain is monitored (by keeping track of the number of spikes in the previous 5 ms), with syllable production onset determined by when the population rate crosses a threshold of 43 Hz/neuron. After a delay of 40 ms, auditory feedback from that chain’s syllable begins.</p>
<p>The auditory feedback takes the form of an external drive to all of the HVC<sub>RA</sub> neurons in a chain. Every chain can provide auditory feedback to every other chain, including itself. Thus, if there are <italic>N</italic> chains, then there are <italic>N</italic><sup>2</sup> auditory feedback pathways. Denote the strength of the auditory feedback from chain <italic>i</italic> to chain <italic>j</italic> as <italic>G</italic><sub><italic>ij</italic></sub>. Every neuron in a chain will have <italic>N</italic> synapses, each one carrying the auditory feedback from one of the <italic>N</italic> chains in the network. The synapses carrying the auditory feedback from chain <italic>i</italic> to chain <italic>j</italic> have strengths drawn from a uniform random distribution between 0 and <italic>G</italic><sub><italic>ij</italic></sub>. Setting <italic>G</italic><sub><italic>ij</italic></sub> = 0 implies that there is no auditory feedback from chain <italic>i</italic> to chain <italic>j</italic>. When auditory feedback from a chain is active, the corresponding synapses are driven with Poisson processes at a frequency <italic>f</italic><sub><italic>fdbk</italic></sub>.</p>
<p>The model that each neuron receives only one synapse for each auditory feedback source is unrealistic. However, for computational simplicity, we model the feedback this way and consider each high-frequency synapse to be carrying spike trains from multiple sources. Since the kick-and-decay synapse model does not separate sources, this induces no real approximation. Auditory feedback parameters for <xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2</xref> were tuned to <italic>f</italic><sub><italic>fdbk</italic></sub> = 1,340 Hz and <italic>G</italic><sub><italic>bb</italic></sub> = 1.9 mS/cm<sup>2</sup>.</p>
</sec>
<sec id="sec015">
<title>Synaptic depression model</title>
<p>To implement synaptic depression, we follow a simple phenomenological model used in Abbott et al. [<xref ref-type="bibr" rid="pcbi.1004471.ref053">53</xref>]. Whenever a synapse is used to transmit a spike, its strength <italic>g</italic> is decreased by a constant fraction <italic>α</italic>, so that <italic>g</italic> → (1 − <italic>α</italic>)<italic>g</italic>. The parameter <italic>α</italic> is referred to as the depression strength. In between spikes, the synaptic strength recovers toward its base strength <italic>g</italic><sub>0</sub> with first order dynamics:
<disp-formula id="pcbi.1004471.e005"><alternatives><graphic id="pcbi.1004471.e005g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e005"/><mml:math id="M5" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:mi>g</mml:mi></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>g</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
The parameter <italic>τ</italic><sub><italic>R</italic></sub> is called the synaptic depression recovery time constant. If such a depressing synapse carries a spike train with a constant frequency <italic>f</italic>, the large-scale effect is an exponential decay to a steady-state strength where recovery and depression are balanced. The time constant of this decay as well as the steady-state strength can be expressed as functions of the model parameters: <italic>τ</italic>(<italic>τ</italic><sub><italic>R</italic></sub>, <italic>α</italic>, <italic>f</italic>) and <italic>g</italic><sub>∞</sub>(<italic>τ</italic><sub><italic>R</italic></sub>, <italic>α</italic>, <italic>f</italic>). See below for a derivation of the exact forms.</p>
<p>In our simulations with synaptic depression on the synapses carrying auditory feedback (in particular <xref ref-type="fig" rid="pcbi.1004471.g002">Fig 2</xref>), we use <italic>τ</italic><sub><italic>R</italic></sub> = 3.25 s and <italic>α</italic> = 0.006. It should be noted that, since these synapses actually represent the combined effect of multiple synapses (see above), these model parameters should not be taken as biologically representative. However, by matching the large-scale dynamics (<italic>τ</italic> and <italic>g</italic><sub>∞</sub>) of the lower-frequency constituent synapses to that of the model synapse, one can find the more biologically relevant underlying depression parameters. Assume that each auditory feedback synapse represents the combined input of <italic>N</italic> constituent synapses, each carrying a spike train with a frequency <italic>f</italic>/<italic>N</italic> so that the model synapse carries a spike train with frequency <italic>f</italic>. Matching the large-scale dynamics is then expressed as (primes representing biologically relevant parameters)
<disp-formula id="pcbi.1004471.e006"><alternatives><graphic id="pcbi.1004471.e006g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e006"/><mml:math id="M6" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>τ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>α</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:mi>f</mml:mi> <mml:mo>/</mml:mo> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>τ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula> <disp-formula id="pcbi.1004471.e007"><alternatives><graphic id="pcbi.1004471.e007g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e007"/><mml:math id="M7" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>g</mml:mi> <mml:mi>∞</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>α</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:mi>f</mml:mi> <mml:mo>/</mml:mo> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>∞</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
Since <italic>α</italic>, <italic>τ</italic><sub><italic>R</italic></sub>, and <italic>f</italic> are known from the model, we can solve for <italic>α</italic>′ and <inline-formula id="pcbi.1004471.e008"><alternatives><graphic id="pcbi.1004471.e008g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e008"/><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi> <mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. With <italic>N</italic> = 50 this gives <italic>α</italic>′ ≈ 0.26 and <inline-formula id="pcbi.1004471.e009"><alternatives><graphic id="pcbi.1004471.e009g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e009"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>≈</mml:mo> <mml:mn>3</mml:mn> <mml:mo>.</mml:mo> <mml:mn>75</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> s—reasonable values for short-term depression in cortex [<xref ref-type="bibr" rid="pcbi.1004471.ref053">53</xref>].</p>
</sec>
<sec id="sec016">
<title>Computational implementation</title>
<p>Both the neural and synaptic depression models take the form of a large system of differential equations. A fourth-order Runge-Kutta scheme is used to numerically integrate these equations with custom code written in C++. When action potentials are generated during a time-step, synaptic conductances and synaptic depression dynamics are immediately updated before the next time-step is taken. All analysis is done with custom code in the MATLAB (The Mathworks, Natick, MA) environment.</p>
</sec>
<sec id="sec017">
<title>Statistical model</title>
<p>To systematically examine how the repeat number distribution depends on the strength <italic>a</italic><sub>0</sub> of the auditory feedback and the adaptation strength <italic>α</italic>, we used the sigmoidal adaptation model, Eqs (<xref ref-type="disp-formula" rid="pcbi.1004471.e002">2</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004471.e003">3</xref>), to generate repeat number distributions with combinations of these parameters. The decay time constant of the auditory feedback due to synaptic adaptation was set to
<disp-formula id="pcbi.1004471.e010"><alternatives><graphic id="pcbi.1004471.e010g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e010"/><mml:math id="M10" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>τ</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mi>f</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>α</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
where <italic>τ</italic><sub><italic>R</italic></sub> is the recovery time constant and <italic>f</italic> is the firing rate of NIf neurons during auditory feedback (see below). Besides <italic>a</italic><sub>0</sub> and <italic>α</italic>, all other parameters are set using those from the network simulations shown in <xref ref-type="fig" rid="pcbi.1004471.g003">Fig 3</xref> with <italic>T</italic> = 100 ms (approximately the length observed in the simulations). To simulate a repeat bout, we sequentially generate random numbers <italic>x</italic><sub><italic>k</italic></sub> from a uniform distribution between 0 and 1 and compare each number to <italic>p</italic><sub><italic>r</italic></sub>(<italic>k</italic>). The first time that <italic>x</italic><sub><italic>k</italic></sub> &gt; <italic>p</italic><sub><italic>r</italic></sub>(<italic>k</italic>) signifies that a further repeat does not occur, so the bout contains <italic>k</italic> repeats. A distribution of repeats for a given (<italic>a</italic><sub>0</sub>, <italic>α</italic>) combination is produced by simulating the repeat bouts 10,000 times, and the results are shown in <xref ref-type="fig" rid="pcbi.1004471.g004">Fig 4b</xref>, where we plot the peak repeat numbers for the distributions. Because the peak repeat number can go to infinity as adaptation strength goes to 0, for numerical stability we use a minimum adaptation strength of 0.001.</p>
</sec>
<sec id="sec018">
<title>Special cases of the sigmoidal adaptation model</title>
<p>The sigmoidal adaptation contains two interesting special cases: (1) If we set the adaptation constant <italic>τ</italic> → ∞, which is equivalent to no adaptation of the auditory synapses, we have <italic>b</italic> → 1 and the repeat probability becomes a constant, a hallmark of the Markov model for repeats. (2) If <italic>c</italic> = 1, which means the repeat probability is zero when the repeat number is large, and the initial auditory input is small such that when <italic>ab</italic> ≪ 1, we have <italic>p</italic><sub><italic>r</italic></sub>(<italic>n</italic>) ≈ <italic>ab</italic><sup><italic>n</italic></sup>, i.e. the repeat probability decreases by a constant factor with the repeat number. This the geometric adaptation of repeat probability. It was used to describe the repeating syllables in a previous work on the song syntax of the Bengalese finch [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>].</p>
<p>Any of these models can be extended to provide better fits to data by allowing multiple states. In these extended models, a repeated syllable is represented by multiple repeating states that all produce that syllable and are connected in series (<xref ref-type="fig" rid="pcbi.1004471.g004">Fig 4b</xref>).</p>
</sec>
<sec id="sec019">
<title>Fitting repeat number distributions</title>
<p>The probability of the syllable repeating N times is given by
<disp-formula id="pcbi.1004471.e011"><alternatives><graphic id="pcbi.1004471.e011g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e011"/><mml:math id="M11" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mo>Π</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msub><mml:mi>p</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
The observed repeat number probability <italic>P</italic><sub><italic>o</italic></sub>(<italic>N</italic>) is computed by normalizing the histogram of the repeat numbers. The parameters <italic>a</italic>, <italic>b</italic>, <italic>c</italic> are determined by minimizing the sum of the errors
<disp-formula id="pcbi.1004471.e012"><alternatives><graphic id="pcbi.1004471.e012g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e012"/><mml:math id="M12" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>E</mml:mi> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>N</mml:mi></mml:munder> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo></mml:mrow> <mml:msub><mml:mi>P</mml:mi> <mml:mi>o</mml:mi></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
while constraining the parameters ranges 0 &lt; <italic>a</italic> &lt; 10<sup>8</sup>, 0 &lt; <italic>b</italic> &lt; 1, and 0 &lt; <italic>c</italic> &lt; 1, using the nonlinear least square fitting function ‘lsqcurvefit’ in MATLAB. To avoid local minima in the search, 20 random sets of the initial values of the parameters were used for the minimization, and the best solution with the minimal square error was chosen.</p>
</sec>
<sec id="sec020">
<title>Comparing two probability distributions</title>
<p>The difference between two probability distributions <italic>p</italic><sub>1</sub>(<italic>n</italic>) and <italic>p</italic><sub>2</sub>(<italic>n</italic>) is defined as
<disp-formula id="pcbi.1004471.e013"><alternatives><graphic id="pcbi.1004471.e013g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e013"/><mml:math id="M13" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>d</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mo movablelimits="true" form="prefix">max</mml:mo> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msub><mml:mo movablelimits="true" form="prefix">max</mml:mo> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
i.e. the maximum absolute differences between the two distributions normalized by the maximum of the two distributions [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>].</p>
<p>When fitting a functional form to a probability distribution, the difference between the empirical distribution and the fit is compared to a benchmark difference that represents the amount of error expected from the finiteness of data. For a given empirical distribution, the benchmark difference is computed by first randomly splitting the full data set into two groups of equal size and then computing the difference between the distributions resulting from each group. This process is repeated 1,000 times to produce a distribution of differences from simple resampling. The benchmark error is set at the 80th percentile of this bootstrapped distribution. The method of benchmark error was explained in detail previously [<xref ref-type="bibr" rid="pcbi.1004471.ref020">20</xref>].</p>
</sec>
<sec id="sec021">
<title>Slow-scale depression dynamics</title>
<p>Our model of synaptic depression characterizes the temporal dynamics of synaptic strength, <italic>g</italic>. Each synapse has a base strength, <italic>g</italic><sub>0</sub>. The depression model has two parameters: (1) depression strength, <italic>α</italic>: fraction of strength lost at each spike; (2) recovery time constant, <italic>τ</italic><sub><italic>R</italic></sub>: rate of exponential recovery toward <italic>g</italic><sub>0</sub>. Mathematically it can be described by two rules: 1. at a spike: <italic>g</italic> → (1 − <italic>α</italic>)<italic>g</italic>; 2. between spikes: <italic>τ</italic><sub><italic>R</italic></sub><italic>dg</italic>/<italic>dt</italic> = −(<italic>g</italic> − <italic>g</italic><sub>0</sub>). We would like to characterize how this synapse will behave when transmitting a spike train that takes the form of a Poisson process. The analysis is simpler if we consider a regular spike train with frequency <italic>f</italic> as an approximation. Fortunately, this should still give the average behavior for the Poisson process case. We begin by deriving an iterative map that takes the strength right before one spike and gives the strength right before the next.</p>
<p>Let the strength of the synapse right before a spike be <italic>g</italic>. Immediately after the spike, the strength will then be (1 − <italic>α</italic>)<italic>g</italic>. Integrating the equation for recovery (from an initial condition (<italic>t</italic><sub><italic>i</italic></sub>, <italic>g</italic><sub><italic>i</italic></sub>) to (<italic>t</italic><sub><italic>f</italic></sub>, <italic>g</italic><sub><italic>f</italic></sub>)) yields:
<disp-formula id="pcbi.1004471.e014"><alternatives><graphic id="pcbi.1004471.e014g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e014"/><mml:math id="M14" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>g</mml:mi> <mml:mi>f</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>f</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
Since the spike train is assumed to be regular, we have <italic>t</italic><sub><italic>f</italic></sub> − <italic>t</italic><sub><italic>i</italic></sub> = 1/<italic>f</italic>. And since the recovery starts from <italic>g</italic><sub><italic>i</italic></sub> = (1 − <italic>α</italic>)<italic>g</italic>, the complete spike-to-spike iterative map is
<disp-formula id="pcbi.1004471.e015"><alternatives><graphic id="pcbi.1004471.e015g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e015"/><mml:math id="M15" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>g</mml:mi> <mml:mo>→</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>α</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>g</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
Using synaptic strength relative to <italic>g</italic><sub>0</sub>, i.e. <italic>g</italic> = <italic>Ag</italic><sub>0</sub> gives:
<disp-formula id="pcbi.1004471.e016"><alternatives><graphic id="pcbi.1004471.e016g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e016"/><mml:math id="M16" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>A</mml:mi> <mml:mo>→</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>α</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mi>A</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula>
This iterative map has the form <italic>A</italic> → <italic>a</italic>+<italic>bA</italic>, with <italic>a</italic> = 1 − <italic>e</italic><sup>−1/(<italic>τ</italic><sub><italic>R</italic></sub> <italic>f</italic>)</sup> and <italic>b</italic> = (1 − <italic>α</italic>)<italic>e</italic><sup>−1/(<italic>τ</italic><sub><italic>R</italic></sub> <italic>f</italic>)</sup>. If we start with <italic>A</italic> = 1, then this map has a closed-form solution:
<disp-formula id="pcbi.1004471.e017"><alternatives><graphic id="pcbi.1004471.e017g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e017"/><mml:math id="M17" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>A</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mi>a</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>b</mml:mi></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>a</mml:mi> <mml:mo>-</mml:mo> <mml:mi>b</mml:mi></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>b</mml:mi></mml:mrow></mml:mfrac> <mml:msup><mml:mi>b</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula>
This is a geometric decrease toward a steady-state value of <italic>a</italic>/(1 − <italic>b</italic>) with a ratio of <italic>r</italic> = <italic>b</italic>. In terms of our model parameters, this is
<disp-formula id="pcbi.1004471.e018"><alternatives><graphic id="pcbi.1004471.e018g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e018"/><mml:math id="M18" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>g</mml:mi> <mml:mi>∞</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mfrac><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>α</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula> <disp-formula id="pcbi.1004471.e019"><alternatives><graphic id="pcbi.1004471.e019g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e019"/><mml:math id="M19" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>α</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
This discrete geometric decrease should be well-approximated by continuous exponential decay. The number of spikes needed to produce a fractional decrease of <italic>e</italic><sup>−1</sup> is given by <italic>r</italic><sup><italic>n</italic></sup> = <italic>e</italic><sup>−1</sup>, so that <italic>n</italic> = −1/log<italic>r</italic>. Since the inter-spike interval is 1/<italic>f</italic>, the time constant of the continuous decay will thus be given by
<disp-formula id="pcbi.1004471.e020"><alternatives><graphic id="pcbi.1004471.e020g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004471.e020"/><mml:math id="M20" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>τ</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mi>n</mml:mi> <mml:mi>f</mml:mi></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>f</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mo>[</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>α</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>]</mml:mo></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mi>f</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>α</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula>
While this derivation is for a regular spike train, simulations (not shown) verify that it is also fits the large-scale dynamics of a Poisson spike train with the same mean frequency.</p>
</sec>
<sec id="sec022">
<title>Animals</title>
<p>32 birds were used in this study. All 32 birds contributed to the behavioral analysis (<xref ref-type="fig" rid="pcbi.1004471.g005">Fig 5</xref>). Of these 32 birds, six birds were used in the deafening studies. A different subset of six birds were used in the electrophysiology experiments. During the experiments, birds were housed individually in sound-attenuating chambers (Acoustic Systems, Austin, TX), and food and water were provided ad libitum. 14:10 light:dark photo-cycles were maintained during development and throughout all experiments.</p>
</sec>
<sec id="sec023">
<title>Song collection and analysis</title>
<p>All behavioral analyses, as well as stimulus creation, were done using custom code written in MATLAB. Individual adult male Bengalese finchs were placed in a sound-attenuating chamber (Acoustic Systems, Austin, Tx) to collect audio recordings. An automated triggering procedure was used to record and digitize (44,100 Hz) several hours of the bird’s singing. These recordings were then scanned to ensure that more than 50 bouts were obtained. Bouts were defined as continuous periods of singing separated by at least 2 seconds of silence. Bengalese finch songs typically consist of between 5–12 distinct acoustic events, termed syllables, organized into probabilistic sequences. Each bout of singing consists of several renditions of sequences, with each sequence containing between 1 and approximately 40 examples of a particular syllable. The syllables from 15–50 bouts were hand labeled for subsequent analysis.</p>
</sec>
<sec id="sec024">
<title>Deafening</title>
<p>Birds were deafened by bilateral cochlear removal [<xref ref-type="bibr" rid="pcbi.1004471.ref081">81</xref>, <xref ref-type="bibr" rid="pcbi.1004471.ref082">82</xref>]. Complete removal of the cochlea, including the distal end of the auditory nerve, was visually confirmed using a dissecting microscope. After cochlear removal, some birds showed signs of vestibular disturbance that usually resolved in the first few days after surgery. Extra care was taken to ensure that such birds had easy access to seed and maintained full crops. Birds did not exhibit difficulty in perching, feeding, or interacting with other birds after returning to their home cages.</p>
</sec>
<sec id="sec025">
<title>Electrophysiology</title>
<p>The electrophysiological results presented in this study were collected as part of a larger study investigating how sequences and syllable features are encoded in HVC auditory responses. The data used in this study and the associated methods have been described previously [<xref ref-type="bibr" rid="pcbi.1004471.ref028">28</xref>]. Briefly, for neural recordings, birds were placed in a large sound-attenuating chamber (Acoustic Systems, Austin, TX) and stereotaxically fixed via a previously implanted pin. During electrophysiological recordings, birds were sedated by titrating various concentrations of isoflurane in O2 using a non-rebreathing anesthesia machine (VetEquip, Pleasanton, CA). Throughout the experiment, the state of the bird was gauged by visually monitoring the eyes and respiration rate using an IR camera. Sites within HVC were at least 100 <italic>μ</italic>m apart and were identified based on stereotaxic coordinates, baseline neural activity, and auditory response properties. Experiments were controlled and neural data were amplified with an AM Systems amplifier (x1000), filtered (300–10,000 Hz), and digitized at 32,000 Hz.</p>
</sec>
<sec id="sec026">
<title>Playback of auditory stimuli</title>
<p>Stimuli were band-pass filtered between 300-8,000 Hz and normalized such that BOS playback through a speaker placed 90 cm from the head had an average sound pressure level of 80 dB at the head (A scale). Each stimulus was preceded and followed by 0.5-1 s of silence and a cosine modulated ramp was used to transition from silence to sounds. The power spectrum varied less than 5 dB across 300-8,000 Hz for white-noise stimuli. All stimuli were presented pseudo-randomly.</p>
</sec>
<sec id="sec027">
<title>Creation of pseudo-random stimuli</title>
<p>To probe how repeated syllables are encoded in the population of HVC neurons, we used a stimulus set that consisted of 10 strings of 1000 pseudo-randomly ordered syllables was constructed. The details of this stimulus are described previously [<xref ref-type="bibr" rid="pcbi.1004471.ref028">28</xref>]. Briefly, for each bird, natural sequences (i.e. sequences produced by a given bird) and non-natural sequences (i.e. sequences that were never produced by a bird) of length 1 through 10 were concatenated with equal probability into 10 strings of 1000 syllables. For each syllable in the birds repertoire occurring in these stimuli, a single ‘prototype’ syllable was used based on the distributions of acoustic features of that syllable. The median of all inter-syllable gaps was used for each gap. BOS stimuli created with these elements (synthesized BOS, prototype syllables and median gaps) elicit HVC auditory responses of comparable magnitude to normal BOS stimuli. Additionally, responses to single syllables preceded by the same long sequences in the pseudo-random stimuli are not significantly different from responses in synthesized BOS. Thus, these stimuli isolate sequence variability from other sources of variability in song, and allow investigating how HVC auditory responses to individual syllables are modulated by the preceding sequence.</p>
</sec>
<sec id="sec028">
<title>Spike sorting, calculation of instantaneous firing rates, and responses to individual syllables</title>
<p>Single units were identified events exceeding 6 standard deviations from the mean and/or were spike sorted using in house software based on a Bayesian inference algorithm. Multi-unit neural data were thresholded to detect spikes more than 3 standard deviations away from the mean. Both single and multi-unit spike times were binned into 5 ms compartments and then smoothed using a truncated Gaussian kernel with a standard deviation of 2.5 ms and total width of 5 ms. To characterize the responses to individual target syllables, we defined a response window, which started 15 ms after the onset of the syllable and extended 15 ms after the offset of that same syllable.</p>
</sec>
<sec id="sec029">
<title>Statistics</title>
<p>All statistical tests were performed using either paired sign-rank tests or unpaired rank-sum tests. Throughout the paper, results were considered significant if the probability of Type I errors was <italic>α</italic> &lt; 0.05. Bonferroni corrections were used to adjust <italic>α</italic>-values when multiple comparisons were performed.</p>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1004471.ref001">
<label>1</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Lashley</surname> <given-names>KS</given-names></name>. <chapter-title>The problem of serial order in behavior</chapter-title>. In: <name name-style="western"><surname>Jeffres</surname> <given-names>LA</given-names></name>, editor. <source>Cerebral Mechanisms in Behaviour</source>. <publisher-loc>Oxford, England</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>1951</year>. p. <fpage>112</fpage>–<lpage>136</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref002">
<label>2</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Doupe</surname> <given-names>aJ</given-names></name>, <name name-style="western"><surname>Kuhl</surname> <given-names>PK</given-names></name>. <article-title>Birdsong and human speech: common themes and mechanisms</article-title>. <source>Annual review of neuroscience</source>. <year>1999</year>;<volume>22</volume>:<fpage>567</fpage>–<lpage>631</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.22.1.567" xlink:type="simple">10.1146/annurev.neuro.22.1.567</ext-link></comment> <object-id pub-id-type="pmid">10202549</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref003">
<label>3</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rhodes</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Bullock</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Verwey</surname> <given-names>WB</given-names></name>, <name name-style="western"><surname>Averbeck</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Page</surname> <given-names>MPa</given-names></name>. <article-title>Learning and production of movement sequences: Behavioral, neurophysiological, and modeling perspectives</article-title>. <source>Human Movement Science</source>. <year>2004</year>;<volume>23</volume>:<fpage>699</fpage>–<lpage>746</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.humov.2004.10.008" xlink:type="simple">10.1016/j.humov.2004.10.008</ext-link></comment> <object-id pub-id-type="pmid">15589629</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref004">
<label>4</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Grossberg</surname> <given-names>S</given-names></name>. <chapter-title>The adaptive self-organization of serial order in behavior: speech, language, and motor control</chapter-title>. In: <name name-style="western"><surname>Schwab</surname> <given-names>EC</given-names></name>, <name name-style="western"><surname>Nusbaum</surname> <given-names>HC</given-names></name>, editors. <source>Pattern Recognition by Humans and Machines: Speech Perception</source>. <publisher-name>Academic Press</publisher-name>; <year>1986</year>. p. <fpage>187</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref005">
<label>5</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>James</surname> <given-names>W</given-names></name>. <source>The Principles of Psychology</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Dover</publisher-name>; <year>1890</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref006">
<label>6</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hull</surname> <given-names>CL</given-names></name>. <article-title>Knowledge and purpose as habit mechanisms</article-title>. <source>Psychological Review</source>. <year>1930</year>;<volume>37</volume>(<issue>6</issue>):<fpage>511</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/h0072212" xlink:type="simple">10.1037/h0072212</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref007">
<label>7</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Grossberg</surname> <given-names>S</given-names></name>. <article-title>Some networks that can learn, remember, and reproduce any number of complicated space-time patterns. I</article-title>. <source>Journal of Mathematics and Mechanics</source>. <year>1969</year>;<volume>19</volume>(<issue>1</issue>):<fpage>53</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref008">
<label>8</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rosenbaum</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Kenny</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Derr</surname> <given-names>MA</given-names></name>. <article-title>Hierarchical control of rapid movement sequences</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>. <year>1983</year>;<volume>9</volume>(<issue>1</issue>):<fpage>86</fpage>. <object-id pub-id-type="pmid">6220126</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref009">
<label>9</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Summers</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Anson</surname> <given-names>JG</given-names></name>. <article-title>Current status of the motor program: Revisited</article-title>. <source>Human Movement Science</source>. <year>2009</year>;<volume>28</volume>(<issue>5</issue>):<fpage>566</fpage>–<lpage>577</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.humov.2009.01.002" xlink:type="simple">10.1016/j.humov.2009.01.002</ext-link></comment> <object-id pub-id-type="pmid">19230995</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref010">
<label>10</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lee</surname> <given-names>BS</given-names></name>. <article-title>Effects of delayed speech feedback</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>1950</year>;<volume>22</volume>(<issue>6</issue>):<fpage>824</fpage>–<lpage>826</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1121/1.1906696" xlink:type="simple">10.1121/1.1906696</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref011">
<label>11</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>MacKay</surname> <given-names>DG</given-names></name>. <article-title>Self-inhibition and the disruptive effects of internal and external feedback in skilled behavior</article-title>. <source>Generation and modulation of action patterns</source>. <year>1986</year>;p. <fpage>174</fpage>–<lpage>186</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref012">
<label>12</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Pfordresher</surname> <given-names>PQ</given-names></name>, <name name-style="western"><surname>Palmer</surname> <given-names>C</given-names></name>. <article-title>Effects of hearing the past, present, or future during music performance</article-title>. <source>Perception &amp; Psychophysics</source>. <year>2006</year>;<volume>68</volume>(<issue>3</issue>):<fpage>362</fpage>–<lpage>376</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3758/BF03193683" xlink:type="simple">10.3758/BF03193683</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref013">
<label>13</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Sakata</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Brainard</surname> <given-names>MS</given-names></name>. <article-title>Real-time contributions of auditory feedback to avian vocal motor control</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2006</year> <month>Sep</month>;<volume>26</volume>(<issue>38</issue>):<fpage>9619</fpage>–<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2027-06.2006" xlink:type="simple">10.1523/JNEUROSCI.2027-06.2006</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref014">
<label>14</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Sakata</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Brainard</surname> <given-names>MS</given-names></name>. <article-title>Online contributions of auditory feedback to neural activity in avian song control circuitry</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>44</issue>):<fpage>11378</fpage>–<lpage>11390</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3254-08.2008" xlink:type="simple">10.1523/JNEUROSCI.3254-08.2008</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref015">
<label>15</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Okanoya</surname> <given-names>K</given-names></name>. <article-title>The Bengalese finch: A window on the behavioral neurobiology of birdsong syntax</article-title>. <source>Annals of the New York Academy of Sciences</source>. <year>2004</year>;<volume>1016</volume>:<fpage>724</fpage>–<lpage>735</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1196/annals.1298.026" xlink:type="simple">10.1196/annals.1298.026</ext-link></comment> <object-id pub-id-type="pmid">15313802</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref016">
<label>16</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Warren</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Charlesworth</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Tumer</surname> <given-names>EC</given-names></name>, <name name-style="western"><surname>Brainard</surname> <given-names>MS</given-names></name>. <article-title>Variable Sequencing Is Actively Maintained in a Well Learned Motor Skill</article-title>. <source>Journal of Neuroscience</source>. <year>2012</year>;<volume>32</volume>(<issue>44</issue>):<fpage>15414</fpage>–<lpage>15425</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1254-12.2012" xlink:type="simple">10.1523/JNEUROSCI.1254-12.2012</ext-link></comment> <object-id pub-id-type="pmid">23115179</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref017">
<label>17</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Marler</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Peters</surname> <given-names>S</given-names></name>. <article-title>Selective Vocal Learning in a Sparrow</article-title>. <source>Science</source>. <year>1977</year>;<volume>198</volume>(<issue>4316</issue>):<fpage>519</fpage>–<lpage>521</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.198.4316.519" xlink:type="simple">10.1126/science.198.4316.519</ext-link></comment> <object-id pub-id-type="pmid">17842140</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref018">
<label>18</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Boughey</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Thompson</surname> <given-names>NS</given-names></name>. <article-title>Song variety in the brown thrasher (Toxostoma rufum)</article-title>. <source>Zeitschrift fur Tierpsychologie</source>. <year>1981</year>;<volume>56</volume>(<issue>1</issue>):<fpage>47</fpage>–<lpage>58</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref019">
<label>19</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gardner</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Naef</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Nottebohm</surname> <given-names>F</given-names></name>. <article-title>Freedom and rules: the acquisition and reprogramming of a bird’s learned song</article-title>. <source>Science (New York, NY)</source>. <year>2005</year>;<volume>308</volume>(<issue>2005</issue>):<fpage>1046</fpage>–<lpage>1049</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1108214" xlink:type="simple">10.1126/science.1108214</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref020">
<label>20</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Jin</surname> <given-names>DZ</given-names></name>, <name name-style="western"><surname>Kozhevnikov</surname> <given-names>AA</given-names></name>. <article-title>A compact statistical model of the song syntax in Bengalese finch</article-title>. <source>PLoS Computational Biology</source>. <year>2011</year>;<volume>7</volume>(<issue>3</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1001108" xlink:type="simple">10.1371/journal.pcbi.1001108</ext-link></comment> <object-id pub-id-type="pmid">21445230</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref021">
<label>21</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Markowitz</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Ivie</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Kligler</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Gardner</surname> <given-names>TJ</given-names></name>. <article-title>Long-range Order in Canary Song</article-title>. <source>PLoS Computational Biology</source>. <year>2013</year>;<volume>9</volume>(<issue>5</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003052" xlink:type="simple">10.1371/journal.pcbi.1003052</ext-link></comment> <object-id pub-id-type="pmid">23658509</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref022">
<label>22</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hampton</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Sakata</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Brainard</surname> <given-names>MS</given-names></name>. <article-title>An avian basal ganglia-forebrain circuit contributes differentially to syllable versus sequence variability of adult Bengalese finch song</article-title>. <source>Journal of neurophysiology</source>. <year>2009</year> <month>Jun</month>;<volume>101</volume>(<issue>6</issue>):<fpage>3235</fpage>–<lpage>45</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.91089.2008" xlink:type="simple">10.1152/jn.91089.2008</ext-link></comment> <object-id pub-id-type="pmid">19357331</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref023">
<label>23</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Fujimoto</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Hasegawa</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Watanabe</surname> <given-names>D</given-names></name>. <article-title>Neural coding of syntactic structure in learned vocalizations in the songbird</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>27</issue>):<fpage>10023</fpage>–<lpage>10033</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1606-11.2011" xlink:type="simple">10.1523/JNEUROSCI.1606-11.2011</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref024">
<label>24</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Okanoya</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Yamaguchi</surname> <given-names>A</given-names></name>. <article-title>Adult Bengalese finches (Lonchura striata var. domestica) require real- time auditory feedback to produce normal song syntax</article-title>. <source>Journal of Neurobiology</source>. <year>1997</year>;<volume>33</volume>:<fpage>343</fpage>–<lpage>356</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/(SICI)1097-4695(199710)33:4%3C343::AID-NEU1%3E3.0.CO;2-A" xlink:type="simple">10.1002/(SICI)1097-4695(199710)33:4%3C343::AID-NEU1%3E3.0.CO;2-A</ext-link></comment> <object-id pub-id-type="pmid">9322153</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref025">
<label>25</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Woolley</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Rubel</surname> <given-names>EW</given-names></name>. <article-title>Bengalese finches Lonchura Striata domestica depend upon auditory feedback for the maintenance of adult song</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>1997</year>;<volume>17</volume>(<issue>16</issue>):<fpage>6380</fpage>–<lpage>6390</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref026">
<label>26</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Jin</surname> <given-names>DZ</given-names></name>. <article-title>Generating variable birdsong syllable sequences with branching chain networks in avian premotor nucleus HVC</article-title>. <source>Physical Review E—Statistical, Nonlinear, and Soft Matter Physics</source>. <year>2009</year>;<volume>80</volume>:<fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref027">
<label>27</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hanuschkin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Morrison</surname> <given-names>A</given-names></name>. <article-title>A reafferent and feed-forward model of song syntax generation in the Bengalese finch</article-title>. <source>Journal of Computational Neuroscience</source>. <year>2011</year>;<volume>31</volume>:<fpage>509</fpage>–<lpage>532</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-011-0318-z" xlink:type="simple">10.1007/s10827-011-0318-z</ext-link></comment> <object-id pub-id-type="pmid">21404048</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref028">
<label>28</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bouchard</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Brainard</surname> <given-names>MS</given-names></name>. <article-title>Neural encoding and integration of learned probabilistic sequences in avian sensorymotor circuitry</article-title>. <source>Journal of Neuroscience</source>. <year>2013</year>; <volume>33</volume>(<issue>45</issue>):<fpage>17710</fpage>–<lpage>23</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2181-13.2013" xlink:type="simple">10.1523/JNEUROSCI.2181-13.2013</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref029">
<label>29</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ulanovsky</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Las</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Farkas</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Nelken</surname> <given-names>I</given-names></name>. <article-title>Multiple time scales of adaptation in auditory cortex neurons</article-title>. <source>The Journal of Neuroscience</source>. <year>2004</year>;<volume>24</volume>(<issue>46</issue>):<fpage>10440</fpage>–<lpage>10453</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1905-04.2004" xlink:type="simple">10.1523/JNEUROSCI.1905-04.2004</ext-link></comment> <object-id pub-id-type="pmid">15548659</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref030">
<label>30</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hahnloser</surname> <given-names>RHR</given-names></name>, <name name-style="western"><surname>Kozhevnikov</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Fee</surname> <given-names>MS</given-names></name>. <article-title>An ultra-sparse code underlies the generation of neural sequences in a songbird</article-title>. <source>Nature</source>. <year>2002</year>;<volume>419</volume>(<issue>1989</issue>):<fpage>65</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature00974" xlink:type="simple">10.1038/nature00974</ext-link></comment> <object-id pub-id-type="pmid">12214232</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref031">
<label>31</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Fee</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Kozhevnikov</surname> <given-names>Aa</given-names></name>, <name name-style="western"><surname>Hahnloser</surname> <given-names>RHR</given-names></name>. <article-title>Neural mechanisms of vocal sequence: Generation in the songbird</article-title>. <source>Annals of the New York Academy of Sciences</source>. <year>2004</year>;<volume>1016</volume>:<fpage>153</fpage>–<lpage>170</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1196/annals.1298.022" xlink:type="simple">10.1196/annals.1298.022</ext-link></comment> <object-id pub-id-type="pmid">15313774</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref032">
<label>32</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Jin</surname> <given-names>DZ</given-names></name>, <name name-style="western"><surname>Ramazanoglu</surname> <given-names>FM</given-names></name>, <name name-style="western"><surname>Seung</surname> <given-names>HS</given-names></name>. <article-title>Intrinsic bursting enhances the robustness of a neural network model of sequence generation by avian brain area HVC</article-title>. <source>Journal of Computational Neuroscience</source>. <year>2007</year>;<volume>23</volume>:<fpage>283</fpage>–<lpage>299</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-007-0032-z" xlink:type="simple">10.1007/s10827-007-0032-z</ext-link></comment> <object-id pub-id-type="pmid">17440800</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref033">
<label>33</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Long</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Fee</surname> <given-names>MS</given-names></name>. <article-title>Using temperature to analyse temporal dynamics in the songbird motor pathway</article-title>. <source>Nature</source>. <year>2008</year>;<volume>456</volume>(<issue>November</issue>):<fpage>189</fpage>–<lpage>194</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07448" xlink:type="simple">10.1038/nature07448</ext-link></comment> <object-id pub-id-type="pmid">19005546</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref034">
<label>34</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Chang</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Jin</surname> <given-names>DZ</given-names></name>. <article-title>Spike propagation in driven chain networks with dominant global inhibition</article-title>. <source>Physical Review E—Statistical, Nonlinear, and Soft Matter Physics</source>. <year>2009</year>;<volume>79</volume>:<fpage>1</fpage>–<lpage>5</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref035">
<label>35</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Long</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Jin</surname> <given-names>DZ</given-names></name>, <name name-style="western"><surname>Fee</surname> <given-names>MS</given-names></name>. <article-title>Support for a synaptic chain model of neuronal sequence generation</article-title>. <source>Nature</source>. <year>2010</year>;<volume>468</volume>(<issue>7322</issue>):<fpage>394</fpage>–<lpage>399</lpage>. <comment>Available from: <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://dx.doi.org/10.1038/nature09514">http://dx.doi.org/10.1038/nature09514</ext-link></comment> <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature09514" xlink:type="simple">10.1038/nature09514</ext-link></comment> <object-id pub-id-type="pmid">20972420</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref036">
<label>36</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Nottebohm</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Stokes</surname> <given-names>TM</given-names></name>, <name name-style="western"><surname>Leonard</surname> <given-names>CM</given-names></name>. <article-title>Central control of song in the canary, Serinus canarius</article-title>. <source>The Journal of comparative neurology</source>. <year>1976</year>;<volume>165</volume>:<fpage>457</fpage>–<lpage>486</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/cne.901650405" xlink:type="simple">10.1002/cne.901650405</ext-link></comment> <object-id pub-id-type="pmid">1262540</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref037">
<label>37</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Nottebohm</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Paton</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Kelley</surname> <given-names>DB</given-names></name>. <article-title>Connections of vocal control nuclei in the canary telencephalon</article-title>. <source>Journal of Comparative Neurology</source>. <year>1982</year>;<volume>207</volume>(<issue>4</issue>):<fpage>344</fpage>–<lpage>357</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/cne.902070406" xlink:type="simple">10.1002/cne.902070406</ext-link></comment> <object-id pub-id-type="pmid">7119147</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref038">
<label>38</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Schmidt</surname> <given-names>MF</given-names></name>. <article-title>Pattern of interhemispheric synchronization in HVc during singing correlates with key transitions in the song pattern</article-title>. <source>Journal of neurophysiology</source>. <year>2003</year>;<volume>90</volume>(<issue>August 2003</issue>):<fpage>3931</fpage>–<lpage>3949</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00003.2003" xlink:type="simple">10.1152/jn.00003.2003</ext-link></comment> <object-id pub-id-type="pmid">12944542</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref039">
<label>39</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lewandowski</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Vyssotski</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hahnloser</surname> <given-names>RH</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>M</given-names></name>. <article-title>At the interface of the auditory and vocal motor systems: NIf and its role in vocal processing, production and learning</article-title>. <source>Journal of Physiology-Paris</source>. <year>2013</year>;<volume>107</volume>(<issue>3</issue>):<fpage>178</fpage>–<lpage>192</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jphysparis.2013.04.001" xlink:type="simple">10.1016/j.jphysparis.2013.04.001</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref040">
<label>40</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Abeles</surname> <given-names>M</given-names></name>. <source>Corticonics: Neural circuits of the cerebral cortex</source>. <publisher-name>Cambridge University Press</publisher-name>; <year>1991</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref041">
<label>41</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gibb</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Gentner</surname> <given-names>TQ</given-names></name>, <name name-style="western"><surname>Abarbanel</surname> <given-names>HDI</given-names></name>. <article-title>Brain stem feedback in a computational model of birdsong sequencing</article-title>. <source>Journal of neurophysiology</source>. <year>2009</year>;<volume>102</volume>(<issue>June 2009</issue>):<fpage>1763</fpage>–<lpage>1778</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.91154.2008" xlink:type="simple">10.1152/jn.91154.2008</ext-link></comment> <object-id pub-id-type="pmid">19553477</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref042">
<label>42</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wilson</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Saygin</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Sereno</surname> <given-names>MI</given-names></name>, <name name-style="western"><surname>Iacoboni</surname> <given-names>M</given-names></name>. <article-title>Listening to speech activates motor areas involved in speech production</article-title>. <source>Nature neuroscience</source>. <year>2004</year>;<volume>7</volume>(<issue>7</issue>):<fpage>701</fpage>–<lpage>702</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1263" xlink:type="simple">10.1038/nn1263</ext-link></comment> <object-id pub-id-type="pmid">15184903</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref043">
<label>43</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Edwards</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Nagarajan</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Dalal</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Canolty</surname> <given-names>RT</given-names></name>, <name name-style="western"><surname>Kirsch</surname> <given-names>HE</given-names></name>, <name name-style="western"><surname>Barbaro</surname> <given-names>NM</given-names></name>, <etal>et al</etal>. <article-title>Spatiotemporal imaging of cortical activation during verb generation and picture naming</article-title>. <source>Neuroimage</source>. <year>2010</year>;<volume>50</volume>(<issue>1</issue>):<fpage>291</fpage>–<lpage>301</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2009.12.035" xlink:type="simple">10.1016/j.neuroimage.2009.12.035</ext-link></comment> <object-id pub-id-type="pmid">20026224</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref044">
<label>44</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Margoliash</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Fortune</surname> <given-names>ES</given-names></name>. <article-title>Temporal and harmonic combination-sensitive neurons in the zebra finch’s HVc</article-title>. <source>The Journal of Neuroscience</source>. <year>1992</year>;<volume>12</volume>(<issue>November</issue>):<fpage>4309</fpage>–<lpage>4326</lpage>. <object-id pub-id-type="pmid">1432096</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref045">
<label>45</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lewicki</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Konishi</surname> <given-names>M</given-names></name>. <article-title>Mechanisms underlying the sensitivity of songbird forebrain neurons to temporal order</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>1995</year>;<volume>92</volume>(<issue>June</issue>):<fpage>5582</fpage>–<lpage>5586</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.92.12.5582" xlink:type="simple">10.1073/pnas.92.12.5582</ext-link></comment> <object-id pub-id-type="pmid">7777552</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref046">
<label>46</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Prather</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Peters</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Nowicki</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Mooney</surname> <given-names>R</given-names></name>. <article-title>Precise auditory-vocal mirroring in neurons for learned vocal communication</article-title>. <source>Nature</source>. <year>2008</year>;<volume>451</volume>(<issue>January</issue>):<fpage>305</fpage>–<lpage>310</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature06492" xlink:type="simple">10.1038/nature06492</ext-link></comment> <object-id pub-id-type="pmid">18202651</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref047">
<label>47</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Fortune</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Margoliash</surname> <given-names>D</given-names></name>. <article-title>Parallel pathways and convergence onto HVc and adjacent neostriatum of adult zebra finches (Taeniopygia guttata)</article-title>. <source>Journal of Comparative Neurology</source>. <year>1995</year>;<volume>360</volume>:<fpage>413</fpage>–<lpage>441</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/cne.903600305" xlink:type="simple">10.1002/cne.903600305</ext-link></comment> <object-id pub-id-type="pmid">8543649</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref048">
<label>48</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Vates</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Broome</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Mello</surname> <given-names>CV</given-names></name>, <name name-style="western"><surname>Nottebohm</surname> <given-names>F</given-names></name>. <article-title>Auditory pathways of caudal telencephalon and their relation to the song system of adult male zebra finches (Taenopygia guttata)</article-title>. <source>Journal of Comparative Neurology</source>. <year>1996</year>;<volume>366</volume>:<fpage>613</fpage>–<lpage>642</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/(SICI)1096-9861(19960318)366:4%3C613::AID-CNE5%3E3.0.CO;2-7" xlink:type="simple">10.1002/(SICI)1096-9861(19960318)366:4%3C613::AID-CNE5%3E3.0.CO;2-7</ext-link></comment> <object-id pub-id-type="pmid">8833113</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref049">
<label>49</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Coleman</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Mooney</surname> <given-names>R</given-names></name>. <article-title>Synaptic transformations underlying highly selective auditory representations of learned birdsong</article-title>. <source>The Journal of neuroscience</source>. <year>2004</year>;<volume>24</volume>(<issue>33</issue>):<fpage>7251</fpage>–<lpage>7265</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0947-04.2004" xlink:type="simple">10.1523/JNEUROSCI.0947-04.2004</ext-link></comment> <object-id pub-id-type="pmid">15317851</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref050">
<label>50</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Cardin</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Raksin</surname> <given-names>JN</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>MF</given-names></name>. <article-title>Sensorimotor nucleus NIf is necessary for auditory processing but not vocal motor output in the avian song system</article-title>. <source>Journal of neurophysiology</source>. <year>2005</year> <month>Apr</month>;<volume>93</volume>(<issue>4</issue>):<fpage>2157</fpage>–<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.01001.2004" xlink:type="simple">10.1152/jn.01001.2004</ext-link></comment> <object-id pub-id-type="pmid">15590726</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref051">
<label>51</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lei</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Mooney</surname> <given-names>R</given-names></name>. <article-title>Manipulation of a Central Auditory Representation Shapes Learned Vocal Output</article-title>. <source>Neuron</source>. <year>2010</year>;<volume>65</volume>(<issue>1</issue>):<fpage>122</fpage>–<lpage>134</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2009.12.008" xlink:type="simple">10.1016/j.neuron.2009.12.008</ext-link></comment> <object-id pub-id-type="pmid">20152118</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref052">
<label>52</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Markram</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Redistribution of synaptic efficacy between neocortical pyramidal neurons</article-title>. <source>Nature</source>. <year>1996</year>;<volume>382</volume>(<issue>6594</issue>):<fpage>807</fpage>–<lpage>810</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/382807a0" xlink:type="simple">10.1038/382807a0</ext-link></comment> <object-id pub-id-type="pmid">8752273</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref053">
<label>53</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Abbott</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Varela</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>S</given-names></name>. <article-title>Synaptic depression and cortical gain control</article-title>. <source>Science</source>. <year>1997</year>;<volume>275</volume>(<issue>5297</issue>):<fpage>221</fpage>–<lpage>224</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.275.5297.221" xlink:type="simple">10.1126/science.275.5297.221</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref054">
<label>54</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Woolley</surname> <given-names>SMN</given-names></name>, <name name-style="western"><surname>Rubel</surname> <given-names>EW</given-names></name>. <article-title>Vocal memory and learning in adult Bengalese Finches with regenerated hair cells</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2002</year>;<volume>22</volume>(<issue>17</issue>):<fpage>7774</fpage>–<lpage>7787</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref055">
<label>55</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Billimoria</surname> <given-names>CP</given-names></name>, <name name-style="western"><surname>Kraus</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Narayan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Maddox</surname> <given-names>RK</given-names></name>, <name name-style="western"><surname>Sen</surname> <given-names>K</given-names></name>. <article-title>Invariance and sensitivity to intensity in neural discrimination of natural sounds</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>25</issue>):<fpage>6304</fpage>–<lpage>6308</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0961-08.2008" xlink:type="simple">10.1523/JNEUROSCI.0961-08.2008</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref056">
<label>56</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Drew</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>. <article-title>Model of song selectivity and sequence generation in area HVc of the songbird</article-title>. <source>Journal of neurophysiology</source>. <year>2003</year>;<volume>89</volume>:<fpage>2697</fpage>–<lpage>2706</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00801.2002" xlink:type="simple">10.1152/jn.00801.2002</ext-link></comment> <object-id pub-id-type="pmid">12612042</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref057">
<label>57</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Beckers</surname> <given-names>GJL</given-names></name>, <name name-style="western"><surname>Gahr</surname> <given-names>M</given-names></name>. <article-title>Neural processing of short-term recurrence in songbird vocal communication</article-title>. <source>PLoS ONE</source>. <year>2010</year>;<volume>5</volume>(<issue>6</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0011129" xlink:type="simple">10.1371/journal.pone.0011129</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref058">
<label>58</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Roy</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Mooney</surname> <given-names>R</given-names></name>. <article-title>Song decrystallization in adult zebra finches does not require the song nucleus NIf</article-title>. <source>Journal of neurophysiology</source>. <year>2009</year>;<volume>102</volume>(<issue>June 2009</issue>):<fpage>979</fpage>–<lpage>991</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00293.2009" xlink:type="simple">10.1152/jn.00293.2009</ext-link></comment> <object-id pub-id-type="pmid">19515953</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref059">
<label>59</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Roberts</surname> <given-names>TF</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Kubke</surname> <given-names>MF</given-names></name>, <name name-style="western"><surname>Wild</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Mooney</surname> <given-names>R</given-names></name>. <article-title>Telencephalic neurons monosynaptically link brainstem and forebrain premotor networks necessary for song</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>13</issue>):<fpage>3479</fpage>–<lpage>3489</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0177-08.2008" xlink:type="simple">10.1523/JNEUROSCI.0177-08.2008</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref060">
<label>60</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Foster</surname> <given-names>EF</given-names></name>, <name name-style="western"><surname>Mehta</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Bottjer</surname> <given-names>SW</given-names></name>. <article-title>Axonal connections of the medial magnocellular nucleus of the anterior neostriatum in zebra finches</article-title>. <source>The Journal of comparative neurology</source>. <year>1997</year>;<volume>382</volume>(<issue>December 1996</issue>):<fpage>364</fpage>–<lpage>381</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/cne.903820305" xlink:type="simple">10.1002/cne.903820305</ext-link></comment> <object-id pub-id-type="pmid">9183699</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref061">
<label>61</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wild</surname> <given-names>JM</given-names></name>. <article-title>Neural pathways for the control of birdsong production</article-title>. <source>Journal of Neurobiology</source>. <year>1997</year>;<volume>33</volume>(<issue>June</issue>):<fpage>653</fpage>–<lpage>670</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/(SICI)1097-4695(19971105)33:5%3C653::AID-NEU11%3E3.0.CO;2-A" xlink:type="simple">10.1002/(SICI)1097-4695(19971105)33:5%3C653::AID-NEU11%3E3.0.CO;2-A</ext-link></comment> <object-id pub-id-type="pmid">9369465</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref062">
<label>62</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ashmore</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Wild</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>MF</given-names></name>. <article-title>Brainstem and forebrain contributions to the generation of learned motor behaviors for song</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2005</year>;<volume>25</volume>(<issue>37</issue>):<fpage>8543</fpage>–<lpage>8554</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1668-05.2005" xlink:type="simple">10.1523/JNEUROSCI.1668-05.2005</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref063">
<label>63</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hamaguchi</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Tschida</surname> <given-names>Ka</given-names></name>, <name name-style="western"><surname>Yoon</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Donald</surname> <given-names>BR</given-names></name>, <name name-style="western"><surname>Mooney</surname> <given-names>R</given-names></name>. <article-title>Auditory synapses to song premotor neurons are gated off during vocalization in zebra finches</article-title>. <source>eLife</source>. <year>2014</year>;<volume>2014</volume>:<fpage>1</fpage>–<lpage>21</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref064">
<label>64</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Vallentin</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Long</surname> <given-names>MA</given-names></name>. <article-title>Motor Origin of Precise Synaptic Inputs onto Forebrain Neurons Driving a Skilled Behavior</article-title>. <source>Journal of Neuroscience</source>. <year>2015</year>;<volume>35</volume>(<issue>1</issue>):<fpage>299</fpage>–<lpage>307</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3698-14.2015" xlink:type="simple">10.1523/JNEUROSCI.3698-14.2015</ext-link></comment> <object-id pub-id-type="pmid">25568122</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref065">
<label>65</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>. <article-title>Computational aspects of motor control and motor learning</article-title>. <source>Handbook of perception and action: motor skills</source>. <year>1996</year>;<volume>2</volume>:<fpage>71</fpage>–<lpage>118</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S1874-5822(06)80005-8" xlink:type="simple">10.1016/S1874-5822(06)80005-8</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref066">
<label>66</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Desmurget</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Grafton</surname> <given-names>S</given-names></name>. <article-title>Forward modeling allows feedback control for fast reaching movements</article-title>. <source>Trends in cognitive sciences</source>. <year>2000</year>;<volume>4</volume>(<issue>11</issue>):<fpage>423</fpage>–<lpage>431</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S1364-6613(00)01537-0" xlink:type="simple">10.1016/S1364-6613(00)01537-0</ext-link></comment> <object-id pub-id-type="pmid">11058820</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref067">
<label>67</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Civier</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Tasko</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Guenther</surname> <given-names>FH</given-names></name>. <article-title>Overreliance on auditory feedback may lead to sound/syllable repetitions: simulations of stuttering and fluency-inducing conditions with a neural model of speech production</article-title>. <source>Journal of fluency disorders</source>. <year>2010</year>;<volume>35</volume>(<issue>3</issue>):<fpage>246</fpage>–<lpage>279</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jfludis.2010.05.002" xlink:type="simple">10.1016/j.jfludis.2010.05.002</ext-link></comment> <object-id pub-id-type="pmid">20831971</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref068">
<label>68</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Houde</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Nagarajan</surname> <given-names>SS</given-names></name>. <article-title>Speech production as state feedback control</article-title>. <source>Frontiers in human neuroscience</source>. <year>2011</year>;<volume>5</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnhum.2011.00082" xlink:type="simple">10.3389/fnhum.2011.00082</ext-link></comment> <object-id pub-id-type="pmid">22046152</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref069">
<label>69</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Keller</surname> <given-names>GB</given-names></name>, <name name-style="western"><surname>Hahnloser</surname> <given-names>RHR</given-names></name>. <article-title>Neural processing of auditory feedback during vocal practice in a songbird</article-title>. <source>Nature</source>. <year>2009</year>;<volume>457</volume>(<issue>January</issue>):<fpage>187</fpage>–<lpage>190</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07467" xlink:type="simple">10.1038/nature07467</ext-link></comment> <object-id pub-id-type="pmid">19005471</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref070">
<label>70</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Ghahramani</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>. <article-title>An internal model for sensorimotor integration</article-title>. <source>Science</source>. <year>1995</year>;<volume>269</volume>(<issue>5232</issue>):<fpage>1880</fpage>–<lpage>1882</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.7569931" xlink:type="simple">10.1126/science.7569931</ext-link></comment> <object-id pub-id-type="pmid">7569931</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref071">
<label>71</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Helekar</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Espino</surname> <given-names>GG</given-names></name>, <name name-style="western"><surname>Botas</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rosenfield</surname> <given-names>DB</given-names></name>. <article-title>Development and adult phase plasticity of syllable repetitions in the birdsong of captive zebra finches (Taeniopygia guttata)</article-title>. <source>Behavioral neuroscience</source>. <year>2003</year>;<volume>117</volume>(<issue>5</issue>):<fpage>939</fpage>–<lpage>951</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0735-7044.117.5.939" xlink:type="simple">10.1037/0735-7044.117.5.939</ext-link></comment> <object-id pub-id-type="pmid">14570544</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref072">
<label>72</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kent</surname> <given-names>RD</given-names></name>. <article-title>Research on speech motor control and its disorders: A review and prospective</article-title>. <source>Journal of Communication disorders</source>. <year>2000</year>;<volume>33</volume>(<issue>5</issue>):<fpage>391</fpage>–<lpage>428</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0021-9924(00)00023-X" xlink:type="simple">10.1016/S0021-9924(00)00023-X</ext-link></comment> <object-id pub-id-type="pmid">11081787</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref073">
<label>73</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Voss</surname> <given-names>HU</given-names></name>, <name name-style="western"><surname>Salgado-Commissariat</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Helekar</surname> <given-names>Sa</given-names></name>. <article-title>Altered auditory BOLD response to conspecific birdsong in zebra finches with stuttered syllables</article-title>. <source>PLoS ONE</source>. <year>2010</year>;<volume>5</volume>(<issue>12</issue>):<fpage>e4415</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0014415" xlink:type="simple">10.1371/journal.pone.0014415</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref074">
<label>74</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Van Riper</surname> <given-names>C</given-names></name>. <source>The nature of stuttering</source>. <publisher-name>Prentice Hall</publisher-name>; <year>1982</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004471.ref075">
<label>75</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Zebrowski</surname> <given-names>PM</given-names></name>. <article-title>Duration of Sound Prolongation and Sound/Syllable Repetition in Children Who StutterPreliminary Observations</article-title>. <source>Journal of Speech, Language, and Hearing Research</source>. <year>1994</year>;<volume>37</volume>(<issue>2</issue>):<fpage>254</fpage>–<lpage>263</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1044/jshr.3702.254" xlink:type="simple">10.1044/jshr.3702.254</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref076">
<label>76</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Boey</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Wuyts</surname> <given-names>FL</given-names></name>, <name name-style="western"><surname>Van de Heyning</surname> <given-names>PH</given-names></name>, <name name-style="western"><surname>De Bodt</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Heylen</surname> <given-names>L</given-names></name>. <article-title>Characteristics of stuttering-like disfluencies in Dutch-speaking children</article-title>. <source>Journal of fluency disorders</source>. <year>2007</year>;<volume>32</volume>(<issue>4</issue>):<fpage>310</fpage>–<lpage>329</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jfludis.2007.07.003" xlink:type="simple">10.1016/j.jfludis.2007.07.003</ext-link></comment> <object-id pub-id-type="pmid">17963939</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref077">
<label>77</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Martin</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Haroldson</surname> <given-names>SK</given-names></name>. <article-title>Effects of five experimental treatments on stuttering</article-title>. <source>Journal of Speech, Language, and Hearing Research</source>. <year>1979</year>;<volume>22</volume>(<issue>1</issue>):<fpage>132</fpage>–<lpage>146</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1044/jshr.2201.132" xlink:type="simple">10.1044/jshr.2201.132</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref078">
<label>78</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Postma</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kolk</surname> <given-names>H</given-names></name>. <article-title>The effects of noise masking and required accuracy on speech errors, disfluencies, and self-repairs</article-title>. <source>Journal of Speech, Language, and Hearing Research</source>. <year>1992</year>;<volume>35</volume>(<issue>3</issue>):<fpage>537</fpage>–<lpage>544</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1044/jshr.3503.537" xlink:type="simple">10.1044/jshr.3503.537</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref079">
<label>79</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Stuart</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Frazier</surname> <given-names>CL</given-names></name>, <name name-style="western"><surname>Kalinowski</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Vos</surname> <given-names>PW</given-names></name>. <article-title>The effect of frequency altered feedback on stuttering duration and type</article-title>. <source>Journal of Speech, Language, and Hearing Research</source>. <year>2008</year>;<volume>51</volume>(<issue>4</issue>):<fpage>889</fpage>–<lpage>897</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1044/1092-4388(2008/065)" xlink:type="simple">10.1044/1092-4388(2008/065)</ext-link></comment> <object-id pub-id-type="pmid">18658059</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref080">
<label>80</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lane</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Tranel</surname> <given-names>B</given-names></name>. <article-title>The Lombard sign and the role of hearing in speech</article-title>. <source>Journal of Speech, Language, and Hearing Research</source>. <year>1971</year>;<volume>14</volume>(<issue>4</issue>):<fpage>677</fpage>–<lpage>709</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1044/jshr.1404.677" xlink:type="simple">10.1044/jshr.1404.677</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref081">
<label>81</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Konishi</surname> <given-names>M</given-names></name>. <article-title>The role of auditory feedback in the control of vocalization in the white-crowned sparrow</article-title>. <source>Zeitschrift fur Tierpsychologie</source>. <year>1965</year>;<volume>22</volume>:<fpage>770</fpage>–<lpage>783</lpage>. <object-id pub-id-type="pmid">5874921</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004471.ref082">
<label>82</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Brainard</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Doupe</surname> <given-names>AJ</given-names></name>. <article-title>Postlearning consolidation of birdsong: stabilizing effects of age and anterior forebrain lesions</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2001</year>;<volume>21</volume>(<issue>7</issue>):<fpage>2501</fpage>–<lpage>2517</lpage>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
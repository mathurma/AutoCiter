<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006604</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-01831</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Signal processing</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Eukaryota</subject><subj-group><subject>Animals</subject><subj-group><subject>Vertebrates</subject><subj-group><subject>Amniotes</subject><subj-group><subject>Mammals</subject><subj-group><subject>Primates</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Network analysis</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>Learning to synchronize: How biological agents can couple neural task modules for dealing with the stability-plasticity dilemma</article-title>
<alt-title alt-title-type="running-head">Learning to synchronize</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2919-1528</contrib-id>
<name name-style="western">
<surname>Verbeke</surname>
<given-names>Pieter</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7783-4754</contrib-id>
<name name-style="western">
<surname>Verguts</surname>
<given-names>Tom</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Department of Experimental Psychology, Ghent University, Ghent, Belgium</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Franklin</surname>
<given-names>Nicholas T.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Harvard University, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">pjverbek.verbeke@ugent.be</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>20</day>
<month>8</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<month>8</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>8</issue>
<elocation-id>e1006604</elocation-id>
<history>
<date date-type="received">
<day>26</day>
<month>10</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>18</day>
<month>7</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Verbeke, Verguts</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006604"/>
<abstract>
<p>We provide a novel computational framework on how biological and artificial agents can learn to flexibly couple and decouple neural task modules for cognitive processing. In this way, they can address the stability-plasticity dilemma. For this purpose, we combine two prominent computational neuroscience principles, namely Binding by Synchrony and Reinforcement Learning. The model learns to synchronize task-relevant modules, while also learning to desynchronize currently task-irrelevant modules. As a result, old (but currently task-irrelevant) information is protected from overwriting (stability) while new information can be learned quickly in currently task-relevant modules (plasticity). We combine learning to synchronize with task modules that learn via one of several classical learning algorithms (Rescorla-Wagner, backpropagation, Boltzmann machines). The resulting combined model is tested on a reversal learning paradigm where it must learn to switch between three different task rules. We demonstrate that our combined model has significant computational advantages over the original network without synchrony, in terms of both stability and plasticity. Importantly, the resulting models’ processing dynamics are also consistent with empirical data and provide empirically testable hypotheses for future MEG/EEG studies.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Artificial and biological agents alike face a critical trade-off between being sufficiently adaptive to acquiring novel information (plasticity) and retaining older information (stability); this is known as the stability-plasticity dilemma. Previous work on this dilemma has focused either on computationally efficient solutions for artificial agents or on biologically plausible frameworks for biological agents. What is lacking is a solution that is both computationally efficient and empirically testable on biological agents. Therefore, the current work proposes a computational framework on the stability-plasticity dilemma that provides empirically testable hypotheses on both neural and behavioral levels. In this framework, neural task modules can be flexibly coupled and decoupled depending on the task at hand. Testing this framework will allow us to gain more insight in how biological agents deal with the stability-plasticity dilemma.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100003130</institution-id>
<institution>Fonds Wetenschappelijk Onderzoek</institution>
</institution-wrap>
</funding-source>
<award-id>1102519N</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2919-1528</contrib-id>
<name name-style="western">
<surname>Verbeke</surname>
<given-names>Pieter</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100004385</institution-id>
<institution>Universiteit Gent</institution>
</institution-wrap>
</funding-source>
<award-id>BOF17/GOA/004</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7783-4754</contrib-id>
<name name-style="western">
<surname>Verguts</surname>
<given-names>Tom</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>The current work was supported by grant BOF17/GOA/004 from the Ghent University Research Council. PV was also supported by grant 1102519N from Research Foundation Flanders.The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="0"/>
<page-count count="25"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-08-30</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Matlab codes that were used for both the model simulations and data analyses are available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/CogComNeuroSci/PieterV_public" xlink:type="simple">https://github.com/CogComNeuroSci/PieterV_public</ext-link>).</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Humans and other primates are remarkably flexible in adapting to constantly changing environments. Additionally, they excel at integrating information in the long run to detect regularities in the environment and generalize across contexts. In contrast, artificial neural networks (ANN), despite being used as models of the primate brain, experience significant problems in these respects. In ANNs, extracting regularities requires slow, distributed learning, which does not allow strong flexibility. Moreover, fast sequential learning of different tasks typically leads to (catastrophic) forgetting of previous information (for an overview see [<xref ref-type="bibr" rid="pcbi.1006604.ref001">1</xref>]). Thus, ANNs are typically unable to find a trade-off between being sufficiently adaptive to novel information (plasticity) and retaining older information (stability), a problem known as the stability-plasticity dilemma.</p>
<p>In recent years, a wide variety of solutions have been provided for this stability-plasticity dilemma. These solutions can broadly be divided in two classes. The first class is based on the fact that catastrophic forgetting does not occur when tasks are intermixed. Thus, one solution is to keep on mixing old and new information [<xref ref-type="bibr" rid="pcbi.1006604.ref002">2</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref005">5</xref>]. [<xref ref-type="bibr" rid="pcbi.1006604.ref003">3</xref>] suggested that new information is temporarily retained in hippocampus. During sleep (and other offline periods), this information is gradually intermixed with old information stored in cortex. This framework inspired subsequent computational and empirical work on cortical-hippocampal interactions [<xref ref-type="bibr" rid="pcbi.1006604.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref008">8</xref>].</p>
<p>The second class of solutions is based on the protection of old information from being overwritten. Protection can occur, first, at the level of synapses. For example, [<xref ref-type="bibr" rid="pcbi.1006604.ref009">9</xref>] combined a slow and fast learning system, with slow and fast weights reflecting long- and short-time-scale contingencies, respectively. This allows the network to both extract stable regularities (slow learning system) and flexibly adapt to fast changes in the environment (fast learning system). Another recent idea is to let synapses (meta-)learn their own importance for a certain task [<xref ref-type="bibr" rid="pcbi.1006604.ref010">10</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref011">11</xref>]. Weights that are very important for some task are not allowed to (and thus protected from) change. Hence, information encoded in those weights is preserved. Second, protection can also be implemented at the level of (neural) activation. The most straightforward approach to implement such protection is to orthogonalize input patterns for the relevant tasks [<xref ref-type="bibr" rid="pcbi.1006604.ref012">12</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref013">13</xref>]. Another approach to achieve protection at the level of neural activation, is gating. This means that only a selected number of network nodes can be activated. Because weight change depends on co-activation of relevant neurons [<xref ref-type="bibr" rid="pcbi.1006604.ref014">14</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref015">15</xref>], this approach protects the weights from changing. For example, [<xref ref-type="bibr" rid="pcbi.1006604.ref016">16</xref>] proposes that in each of several tasks a (randomly selected) 80% of nodes is gated out, thus effectively orthogonalizing different contexts. They showed that synaptic gating allowed a multi-layer network to deal with several computationally demanding tasks without catastrophic forgetting.</p>
<p>Crucially, it remains unknown how biological agents deal with this dilemma. The current study aims to provide a novel computational framework focused on biological agents that makes empirically testable predictions at MEG/EEG level. For this purpose, we combine two prominent principles of computational neuroscience, namely Binding by Synchrony [<xref ref-type="bibr" rid="pcbi.1006604.ref017">17</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref020">20</xref>]) and Reinforcement Learning (RL; [<xref ref-type="bibr" rid="pcbi.1006604.ref021">21</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref022">22</xref>]). In BBS, neurons are flexibly bound together by synchronizing them via oscillations. This implements selective gating (e.g., [<xref ref-type="bibr" rid="pcbi.1006604.ref023">23</xref>]) in which synchronization enhances the communication between neuronal groups (gates are opened) and desynchronization disrupts the communication between neural groups (gates are closed). In sum, BBS allows the model to flexibly alter communication efficiency on a fast time scale. By using RL principles, the model can learn autonomously when neurons need to be (de)synchronized.</p>
<p>In the modeling framework, BBS binds relevant neural groups, called (neural task) modules, and unbinds irrelevant modules. This causes both efficient processing and learning between synchronized modules; and inefficient processing and absence of learning between desynchronized modules. The resulting model deals with the stability-plasticity dilemma by flexibly switching between task-relevant modules and by retaining information in task-irrelevant modules. An RL unit [<xref ref-type="bibr" rid="pcbi.1006604.ref024">24</xref>] uses reward prediction errors to evaluate whether the model is synchronizing the correct task modules.</p>
<p>In order to test the generalizability of our framework, we apply it to networks containing modules that learn via three classic synaptic learning algorithms, namely Rescorla-Wagner (RW; [<xref ref-type="bibr" rid="pcbi.1006604.ref015">15</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref025">25</xref>]), backpropagation (BP; [<xref ref-type="bibr" rid="pcbi.1006604.ref026">26</xref>]) and Restricted Boltzmann machines (RBM; [<xref ref-type="bibr" rid="pcbi.1006604.ref027">27</xref>]). The RW algorithm [<xref ref-type="bibr" rid="pcbi.1006604.ref025">25</xref>] is one of the most well-known and basic supervised-learning algorithms in cognitive neuroscience. Here, on each trial, an error term is computed based on the discrepancy between a model-generated output pattern and some target output pattern. Learning consists of using this error term for finding a weight configuration that minimizes the average error across trials. This algorithm is typically fast and efficient for learning simple (i.e., linearly separable) input-output associations. Hence, it has no problems with plasticity. However, while learning one set of input-output associations (set B), the algorithm may unlearn another, currently irrelevant set of input-output associations (set A). Thus, when set A becomes relevant again, it will have to relearn it. In sum, the RW algorithm does suffer from a lack of stability, but due to its high plasticity it might have only minor problems with respect to the stability-plasticity dilemma, especially when the learning rate is high. In this case, it might relearn the forgotten information (set A) so fast that also the stability problem is negligible. Nevertheless, the RW algorithm suffers from some severe limitations on the complexity of problems that it can solve. It is very efficient in dealing with linearly separable input-output associations, but cannot deal with more complex, not linearly separable, problems.</p>
<p>This limitation of the RW algorithm is solved in BP [<xref ref-type="bibr" rid="pcbi.1006604.ref026">26</xref>]. Similar to RW, learning with BP consists of using the error term for finding a weight configuration that minimizes the average error across trials. Relative to RW, this algorithm is able to solve a much wider range of problems. In particular, it can also solve nonlinearly separable problems. It does this by adding hidden layers between input and output. For training the weights toward the hidden layers, BP propagates the error term backwards from output toward the hidden (i.e., deeper) layers in the network. Crucially, sequential learning of input-output associations poses severe computational problems on the BP algorithm. Because the number of (interdependent) weights that should be adjusted to solve a problem is much higher, the algorithm learns much slower. Hence, if the learning rate is low, new learning can be very slow, causing a lack of plasticity. If the learning rate is very fast, on the other hand, this problem is mitigated but there is no stability in the model. This is because, similar to RW, the learning algorithm will adapt all available weights and therefore overwrite previous information.</p>
<p>An algorithm that can also learn with hidden layers (and thus solve more complex problems) is RBM. Despite the algorithmic differences, RBM suffers from the same stability-plasticity dilemma as BP. To further illustrate the generality of our framework, <xref ref-type="supplementary-material" rid="pcbi.1006604.s001">S1 Text</xref> show that our framework can also be applied to networks with modules that learn via RBM. For brevity, the main text restricts attention to RW and BP.</p>
<p>The full model consists of three units (<xref ref-type="fig" rid="pcbi.1006604.g001">Fig 1A</xref>). The Processing unit contains a network consisting of a number of task-specific modules; the two learning algorithms (RW or BP) are implemented between modules of the Processing unit. In addition, RL and Control units together form an hierarchically higher network modeled after basal ganglia/primate prefrontal cortex [<xref ref-type="bibr" rid="pcbi.1006604.ref028">28</xref>]. The RL unit (modeling ventral striatum/ anterior medial frontal cortex (aMFC)) evaluates behavior. More specifically, it learns to assign a value to a specific task module (how much reward it receives by using this module) and compares this value with the externally received reward to compute prediction errors. Additionally, the RL unit has a Switch neuron (see <xref ref-type="fig" rid="pcbi.1006604.g002">Fig 2A</xref>). This Switch neuron computes a weighted sum of negative prediction errors across trials. When this sum reaches a threshold of .5, it signals the need for a strategy switch to the Control unit (see <xref ref-type="sec" rid="sec021">Methods</xref> for details). This Control unit drives neural synchronization in the Processing unit. One part of the Control unit (modeling lateral frontal cortex (LFC)) contains task neurons that point to task modules in the Processing unit [<xref ref-type="bibr" rid="pcbi.1006604.ref029">29</xref>]; another part (modeling posterior medial frontal cortex (pMFC)) synchronizes task modules based on those task neurons [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>]. Crucially, LFC and pMFC both use prediction error information, but on different time scales. The pMFC uses prediction errors on a fast time scale to enhance control over the synchronization process as soon as a negative prediction error occurs. In contrast, the LFC uses prediction errors on a slow time scale to know when the task rule has changed and a switch of modules is needed.</p>
<fig id="pcbi.1006604.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006604.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Model and task overview.</title>
<p><bold>A:</bold> General model overview. The model consists of 3 units. A Processing unit contains a classic neural network that learns the (reversal learning) task. The Control and RL units constitute a hierarchically higher network. Putative brain areas are shown in italic font. The Control unit drives synchronization of oscillations in the Processing unit. The RL unit evaluates current behavior in order to signal to the Control unit what should be synchronized in the Processing unit. <bold>B:</bold> Reversal learning task. The task alternates between 3 task rules (A, B, C) across 6 task blocks with task sequence ABCABC. Plasticity is measured during the first 5 trial bins of the first task block in which a task rule is presented (green bars). Stability is measured as the difference between the last 5 trial bins of the first task block in which a task rule is presented, and the first 5 trial bins of the second task block in which a task rule is presented.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006604.g001" xlink:type="simple"/>
</fig>
<fig id="pcbi.1006604.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006604.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Detailed overview of the model.</title>
<p><bold>A:</bold> The model. A detailed version of the model in <xref ref-type="fig" rid="pcbi.1006604.g001">Fig 1A</xref> is shown. The model consists of 3 units. A Processing unit is localized in posterior processing areas and contains a classic neural network. This network contains 3 layers (of nodes) for the BP model and 2 layers for the RW model. Layer 1 contains nodes that are activated by external input. At layer 2, modularity is implemented. This layer is divided in 3 task modules, one for each task the model has to execute. In the BP model, the nodes in these task modules represent hidden nodes; for the RW model these nodes represent response options. Layer 3 only occurs in the BP model and contains three response options. The Control unit consists of two parts. Here, the LFC contains 4 task neurons; 3 neurons point to a specific task module in the Processing unit that should be synchronized or desynchronized. A fourth neuron points to layer 1 and 3, to indicate that task modules should be (de)synchronized with these layers. The pMFC of the Control unit contains one single node that sends bursts in order to (de)synchronize modules in the Processing unit in line with the pointers sent by the LFC. The RL unit contains four neurons. One neuron (<italic>V</italic>) learns to assign a value to the task modules. Two other neurons (<italic>δ—</italic>, <italic>δ</italic> <sup><bold><italic>+</italic></bold></sup>) compare this value to external reward, in order to compute prediction errors. Negative prediction errors are accumulated in the Switch neuron in order to make a stay/switch decision, which it signals to the LFC. Additionally, the negative prediction error neuron signals to the pMFC (by giving bursts) that it should increase control. <bold>B:</bold> Neuronal triplet. Every square node in A consists of a triplet of neurons. Each such node consists of a phase-code pair (<italic>E</italic>, <italic>I</italic>) which, because of its excitatory (<italic>E</italic>)—inhibitory (<italic>I</italic>) coupling, oscillates at a certain frequency. These oscillations modulate the excitability of their rate code neuron (<italic>x</italic>) in line with the BBS hypothesis.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006604.g002" xlink:type="simple"/>
</fig>
<p>In order to drive neural synchronization between task modules in the Processing unit, we rely on the idea of binding by random bursts [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref032">32</xref>]. Here, applying positively correlated noise to two oscillating signals reduces their phase difference. In addition to implementing binding by random bursts, the current work also implements unbinding by random bursts. In particular, applying negatively correlated bursts increases the phase difference between oscillating signals and thus unbinds (i.e., dephases) the two signals.</p>
<p>We test our model on a (cognitive control) reversal learning task. Here, each hierarchically lower algorithm (RW or BP; in the Processing unit) sequentially learns different task rules. The relevant task rule changes across task blocks (<xref ref-type="fig" rid="pcbi.1006604.g001">Fig 1B</xref>). The model must detect when task rules have changed, and flexibly switch between different rules without forgetting what has been learned before. We divide the task in six equally long task blocks. In the first three blocks, the model should learn three different new task rules (rule A, B and C in blocks 1, 2 and 3 respectively). In the second half, the model has to switch back to the previously learned rules (rule A, B and C in blocks 4, 5 and 6 respectively; see also <xref ref-type="fig" rid="pcbi.1006604.g001">Fig 1B</xref>).</p>
<p>For the RW network, we use a one-dimensional task. Here, on each trial one out of three stimulus features is activated. For every task rule we link a stimulus feature to a response option. More specifically, in task rule A, feature 1 (F1) is associated to response 1 (R1), feature 2 (F2) to response 2 (R2) and feature 3 (F3) response 3 (R3). In task rule B, F1 is associated to R2, F2 to R3 and F3 to R1. Task rule C associates F1 to R3, F2 to R1 and F3 to R2. For the BP network, a multi-dimensional task is used. Here, on each trial multiple stimulus features are activated. More specifically, the task utilizes four dimensions. Every dimension has three features. One of the dimensions represents a cue that indicates which out of the other three (stimulus) dimensions is relevant on the current trial. In line with the one-dimensional task, the 3 stimulus features of each dimension are within each task rule linked to one response option.</p>
<p>The one-dimensional task (for RW) consists of 360 trials; the multi-dimensional task (for BP) consisted of 3600 trials. For comparison, we divided each task sequence in 120 trial bins for analysis and plotting. <xref ref-type="fig" rid="pcbi.1006604.g002">Fig 2A</xref> illustrates the detailed model for both tasks. We compare our combined (henceforth, full) models with models that use no synchronization (i.e., only contain the Processing unit; called no-synchrony models). We evaluate plasticity as the ability to learn a new task; and stability as the interference from learning a new task toward performance on the old task (see <xref ref-type="fig" rid="pcbi.1006604.g001">Fig 1B</xref> and <xref ref-type="sec" rid="sec021">Methods</xref>).</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Model architecture</title>
<sec id="sec004">
<title>Overview</title>
<p>An overview of the model is given in <xref ref-type="fig" rid="pcbi.1006604.g002">Fig 2A</xref>. In line with <xref ref-type="fig" rid="pcbi.1006604.g001">Fig 1A</xref>, a Processing unit, a Control unit and an RL unit are shown. The Processing unit contains a classic network with 2 layers (RW) or 3 layers (BP). At the second layer, each module groups all nodes that are relevant for one task rule.</p>
<p>The Control unit consists of the LFC and pMFC. The LFC holds pointers that indicate which modules should be (de)synchronized. This synchronization process is then executed by the binding by random burst principle [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref032">32</xref>]. In the model, a theta-frequency-paced signal produced in the pMFC is responsible for sending these bursts.</p>
<p>The RL unit (adopted from an earlier RL model [<xref ref-type="bibr" rid="pcbi.1006604.ref024">24</xref>]) computes an expected reward (<italic>value</italic>, <italic>V</italic>) for the currently used task module. This value is then compared to an external <italic>Reward</italic> signal in order to compute prediction errors (<italic>δ</italic> <sup><bold><italic>-</italic></bold></sup>, <italic>δ</italic> <sup><italic>+</italic></sup>). The negative prediction error signal is then propagated to both the Switch neuron and to the pMFC. A single negative prediction error increases the control signal in the pMFC (see Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e009">8</xref>)). Instead, the Switch neuron evaluates the prediction error signal on a slower time scale (see Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e013">12</xref>)). When activation in the Switch neuron reaches a threshold, it signals the need for a switch to the LFC in the Control unit, and resets its own activation to zero. Correspondingly, the LFC will change the signal to the Processing unit, and synchronize another task module (see <xref ref-type="sec" rid="sec021">Methods</xref>). We elaborate on this Switch neuron in the Model dynamics and performance section.</p>
</sec>
<sec id="sec005">
<title>Neuronal triplets</title>
<p>In the Processing unit and the pMFC part of the Control unit, all processing happens in oscillatory nodes. As presented in <xref ref-type="fig" rid="pcbi.1006604.g002">Fig 2B</xref>, each oscillatory node contains one neuronal triplet. Each triplet contains one classical rate code neuron (with activation <italic>x</italic><sub><italic>i</italic></sub>) which receives, processes and transmits information; and one pair of phase code neurons (<italic>E</italic><sub><italic>i</italic></sub>, <italic>I</italic><sub><italic>i</italic></sub>) which organizes processing in the rate code neurons. In line with previous work [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>], excitatory neurons are updated by
<disp-formula id="pcbi.1006604.e001">
<alternatives>
<graphic id="pcbi.1006604.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:msub><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>J</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mo>×</mml:mo><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where Δ<italic>E</italic>(<italic>t</italic>) = <italic>E</italic>(<italic>t</italic> + Δ<italic>t</italic>)–<italic>E</italic>(<italic>t</italic>); and inhibitory neurons are updated by
<disp-formula id="pcbi.1006604.e002">
<alternatives>
<graphic id="pcbi.1006604.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:msub><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>J</mml:mi><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mo>×</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
The E and I neurons are thus coupled by a parameter <italic>C</italic>, causing them to oscillate. The strength of the coupling (<italic>C</italic>) determines the frequency of the oscillations, <italic>C</italic>/(2π) [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref033">33</xref>]. Task-relevant modules in the Processing unit must be bound together. Previous research has proposed that such binding is supported by oscillations in the gamma-frequency band (30–70 Hz; [<xref ref-type="bibr" rid="pcbi.1006604.ref019">19</xref>]). We therefore chose a value for <italic>C</italic> corresponding to a frequency of ~40 Hz. In the pMFC, which executes top-down control, the value of <italic>C</italic> is such that oscillations are at a 5Hz (theta-) frequency, in line with suggestions of previous empirical work [<xref ref-type="bibr" rid="pcbi.1006604.ref034">34</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref035">35</xref>]. The variable <italic>t</italic> refers to time, and Δt refers to a time step of 2 msec. The radius (<italic>r</italic><sup>2</sup> = <italic>E</italic><sup>2</sup><italic>+I</italic><sup>2</sup>) of the oscillations in the Processing unit are attracted towards the value <italic>r</italic><sub>min</sub> = 1. This is implemented by the terms <italic>Damp</italic>×<italic>J</italic>(<italic>r&gt;r</italic><sub>min</sub>)×<italic>E</italic><sub><italic>i</italic></sub>(<italic>t</italic>) in Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e001">1</xref>) and <italic>Damp</italic>×<italic>J</italic>(<italic>r&gt;r</italic><sub>min</sub>)×<italic>I</italic><sub><italic>i</italic></sub>(<italic>t</italic>) in Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e002">2</xref>). Here, <italic>J</italic>(.) is an indicator function, returning 1 when the radius is higher than the value of <italic>r</italic><sub>min</sub>, and 0 otherwise. The damping parameter, <italic>Damp</italic> = .3, determines the strength of attraction. Since a constant high pMFC power is computationally suboptimal and empirically implausible [<xref ref-type="bibr" rid="pcbi.1006604.ref036">36</xref>], the radius of the pMFC was attracted towards a smaller radius, <italic>r</italic><sub>min</sub> = .05. The damping parameter was set to <italic>Damp</italic> = .003, in order to let the amplitude of the pMFC oscillations decay slowly across trials. We elaborate on these parameters in the Results and Discussion section.</p>
<p>Excitatory neurons additionally receive a burst <italic>B</italic><sub><italic>i</italic></sub>(<italic>t</italic>). For the nodes in the Processing unit, these bursts were determined by a combination of the LFC and pMFC signal, multiplied with standardized-Gaussian noise (<italic>U</italic>):
<disp-formula id="pcbi.1006604.e003">
<alternatives>
<graphic id="pcbi.1006604.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>p</mml:mi><mml:mi>M</mml:mi><mml:mi>F</mml:mi><mml:mi>C</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:mi>U</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula>
As can be observed in <xref ref-type="fig" rid="pcbi.1006604.g003">Fig 3B</xref>, these bursts lead to synchronization between modules (and hence nodes) that are relevant (which receive the same LFC signal); and desynchronization between modules (and hence nodes) that are irrelevant (which receive opposite LFC signals). Note that bursts also introduce noise, hence it is optimal to limit the number of bursts. This is one of the reasons why the amplitude of the pMFC decays slowly over trials.</p>
<fig id="pcbi.1006604.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006604.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Neuronal triplets.</title>
<p><bold>A:</bold> The pMFC. In the pMFC, the phase code neurons oscillate at a 5 Hz frequency. The rate code neuron of the pMFC gives bursts to the Processing unit. Every time the E-neuron reaches a high amplitude, the probability of a burst becomes high. <bold>B:</bold> E-neurons of the Processing unit. In the Processing unit, the phase code neurons oscillate at a faster gamma-frequency. It is illustrated how a burst leads to (de)synchronization of oscillations that at first were not (de)synchronized. <bold>C:</bold> Rate code neurons in the Processing unit. Consequences of synchronization between the phase code neurons can be observed in the rate code neurons. At first, only the neuron of layer 1 is activated because it receives a constant external input signal. Importantly, this activation is modulated by <italic>G</italic>(<italic>Ei</italic>) in Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e004">4</xref>). As a consequence, as long as the E-neurons are not synchronized, communication between the corresponding rate code neurons is very inefficient; but when the E-neurons are synchronized, communication between the corresponding rate code neurons is efficient.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006604.g003" xlink:type="simple"/>
</fig>
<p>The rate code neurons in the Processing unit are updated by
<disp-formula id="pcbi.1006604.e004">
<alternatives>
<graphic id="pcbi.1006604.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:mi>G</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
The term -<italic>x</italic><sub><italic>i</italic></sub>(<italic>t</italic>) will cause fast decay of activation in absence of input. According to this equation, the activation of the rate code neuron at every time step is a function of the net input (<italic>net</italic><sub><italic>i</italic></sub>) for that neuron, multiplied by a function of the excitatory phase code neuron [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>],
<disp-formula id="pcbi.1006604.e005">
<alternatives>
<graphic id="pcbi.1006604.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mi>G</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>5</mml:mn><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mo>.</mml:mo><mml:mn>6</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula>
How this function affects the rate code neurons (<italic>x</italic>) is illustrated in <xref ref-type="fig" rid="pcbi.1006604.g003">Fig 3C</xref>. In the BP network, the rate code neurons have a sigmoid activation function <italic>f</italic>(<italic>net</italic><sub><italic>i</italic></sub><italic>-bias</italic>) = <inline-formula id="pcbi.1006604.e006"><alternatives><graphic id="pcbi.1006604.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>. Additionally, these rate code neurons receive a <italic>bias</italic> = 5 to set activation to (approximately) zero in absence of input. In the RW network, the rate code neurons have no bias and follow a linear activation function; <italic>f</italic>(<italic>net</italic><sub><italic>i</italic></sub><italic>—bias</italic>) <italic>= net</italic><sub><italic>i</italic></sub>.</p>
<p>As described in Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e003">3</xref>), the synchronizing bursts that are sent to the Processing unit are a combination of an LFC and a pMFC signal. Here, LFC represents a pointer that takes on a value of 1 for the module that should be synchronized and -1 for modules that should be desynchronized. The pMFC-part of the equation corresponds to the rate code neuron of the pMFC triplet, which follows
<disp-formula id="pcbi.1006604.e007">
<alternatives>
<graphic id="pcbi.1006604.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:mi>p</mml:mi><mml:mi>M</mml:mi><mml:mi>F</mml:mi><mml:mi>C</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>∼</mml:mo><mml:mi>B</mml:mi><mml:mi>e</mml:mi><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula>
This equation represents a Bernoulli process <italic>Be</italic>(<italic>p</italic>) which is 1 with probability <italic>p</italic>. The probability
<disp-formula id="pcbi.1006604.e008">
<alternatives>
<graphic id="pcbi.1006604.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>10</mml:mn><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>M</mml:mi><mml:mi>F</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula>
is a sigmoid function which has its greatest value when the <italic>E</italic><sub><italic>pMFC</italic></sub> is near its top and its amplitude is sufficiently strong. Hence, every time the oscillation of the <italic>E</italic><sub><italic>pMFC</italic></sub>-neuron reaches its top, the probability of a burst becomes high. Thus, bursts are phase-locked to the theta oscillation (see [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>] for more details). An illustration of the processes in the neuronal triplets of both the pMFC and Processing unit is presented in <xref ref-type="fig" rid="pcbi.1006604.g003">Fig 3</xref>.</p>
<p>The pMFC not only sends burst but also receives bursts. Here, the burst signal received by the pMFC is determined by the negative prediction error signal of the previous trial,
<disp-formula id="pcbi.1006604.e009">
<alternatives>
<graphic id="pcbi.1006604.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>M</mml:mi><mml:mi>F</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:mo>∼</mml:mo><mml:mi>B</mml:mi><mml:mi>e</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo>−</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>200</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>25</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula>
Here, the burst signal at one time point in one trial (<italic>n</italic>) is determined by the size of the negative prediction error at the previous (<italic>n</italic>—1) trial, by a Bernoulli process Be(<italic>P</italic>(<italic>t</italic>)) which is 1 with probability <italic>P</italic>(t) (and 0 otherwise). The probability <italic>P</italic>(<italic>t</italic>) is shaped like a Gaussian distribution that peaks at 200 ms with a standard deviation of 25 ms, representing a communication delay between the RL unit and the pMFC. This delay does not necessarily represent the time of a direct information transfer between the pMFC and <italic>δ</italic> <sup>-</sup>, but is rather set to this value in order to connect with empirical data showing feedback-related EEG-activity at approximately 200 ms after feedback presentation [<xref ref-type="bibr" rid="pcbi.1006604.ref037">37</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref039">39</xref>]. Hence, when a trial elicited a negative prediction error, bursts are sent to the excitatory neuron of the pMFC. Consequently, these bursts have the size of the negative prediction error and are most likely to occur at 200 ms after feedback. This burst signal will increase the amplitude of the pMFC phase code neurons when a negative prediction occurs, after which it will decay towards <italic>r</italic><sub><italic>min</italic></sub>.</p>
</sec>
</sec>
<sec id="sec006">
<title>Model dynamics and performance</title>
<p>In <xref ref-type="fig" rid="pcbi.1006604.g004">Fig 4A</xref>, the accuracy evolution across all task blocks is plotted for both the full and no-synchrony RW model with a slow learning rate, β = .2, for the simple (linearly separable) task. The full model is marginally slower in learning new task rules. However, when the model needs to switch back to a previously learned rule (task blocks 4–6) we observe a minor advantage for the full model in the first trials, since it does not have to relearn the task.</p>
<fig id="pcbi.1006604.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006604.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Model data.</title>
<p>Model dynamics are shown for simulations with a learning rate of .2. In column 1 (panels A and D) binned accuracy is shown for the full (in blue) and no-synchrony (in orange) model. The horizontal dashed black line indicates accuracy at chance level. In column 2 (panels B and E), brown lines represent synchronization values for the initially (randomly) chosen task module, magenta lines for the module that was chosen secondly, and green lines for the third module. In column 3 (panels C and F), activity of the Switch neuron (see <xref ref-type="fig" rid="pcbi.1006604.g002">Fig 2A</xref>) is shown for one selected simulation of the model (in black). Blue horizontal dashed lines indicate the threshold of the Switch neuron and the yellow arrows mark data points above the threshold. In all panels, red vertical transparent lines indicate task switches and shades indicate 95% confidence intervals.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006604.g004" xlink:type="simple"/>
</fig>
<p>A very different picture emerges for the complex (nonlinearly separable) task. <xref ref-type="fig" rid="pcbi.1006604.g004">Fig 4D</xref> shows the accuracy of the full and no-synchrony BP model. During the first task block, the no-synchrony and full model perform similarly. When the task rule switches for the first time (i.e., after the first task block), the drop in accuracy is slightly larger for the no-synchrony model than for the full model. This is caused by the fact that the no-synchrony model has to learn task rule B with weights that were pushed in a direction opposite to those that are optimal for task rule A. Instead, the full model switches to another task module and starts learning from a random weight space. A similar phenomenon occurs after the second rule switch.</p>
<p>For the following task switches, the model has to switch back to rules it already learned before; it is here that the full potential of the full model emerges. The full model can switch back to a previous module, where all old information was retained. Instead, the no-synchrony model has catastrophically forgotten the first task rule and must hence relearn it.</p>
<sec id="sec007">
<title>Synchronization of modules</title>
<p><xref ref-type="fig" rid="pcbi.1006604.g004">Fig 4B</xref> represents the synchronization between the input layer and different task modules for the RW model. Here, we see that the model performs quite well in synchronizing task-relevant and in desynchronizing task-irrelevant modules. Additionally, the model is able to flexibly switch between modules at the correct point in time. As is illustrated by the broader confidence intervals, the model needs some time to switch back to a previously used module. Nevertheless, in general it does succeed in finding the correct task module. A similar pattern is observed in <xref ref-type="fig" rid="pcbi.1006604.g004">Fig 4E</xref>, where the synchronization of the BP model is shown.</p>
</sec>
<sec id="sec008">
<title>The switch neuron</title>
<p><xref ref-type="fig" rid="pcbi.1006604.g004">Fig 4C</xref> shows activation in the Switch neuron for the RW model. Here, two crucial observations can be made. First, when the model has to learn a task for the first time there is more activity in the Switch neuron. This reflects the learning process where many (negative prediction) errors occur. When the network has learned the task, activity in the Switch neuron decays towards zero because less errors are made. Hence, the fact that there is almost no activity in the Switch neuron when the model performs an already learned task, also demonstrates the stability of the model. Second, the Switch threshold of .5 is only reached during the first trials after a rule switch. This is because at this moment, many large prediction errors occur and accumulate. Once the Switch threshold is reached, activity in the Switch neuron decays towards zero. A similar process can be observed in <xref ref-type="fig" rid="pcbi.1006604.g004">Fig 4F</xref> where data for the BP model is shown.</p>
</sec>
<sec id="sec009">
<title>Parameter exploration</title>
<p>Parameters in the current model were mainly set based on previous work [<xref ref-type="bibr" rid="pcbi.1006604.ref019">19</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref034">34</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref036">36</xref>]. We performed an additional simulation (see <xref ref-type="sec" rid="sec021">Methods</xref> for details) in which we explored the importance of the frequencies in the Processing unit and pMFC, and the decaying amplitude in pMFC. Results are shown in <xref ref-type="fig" rid="pcbi.1006604.g005">Fig 5</xref>. We observe that accuracy dramatically declines when the Controller frequency, determined by the <italic>C</italic> parameter in Eqs (<xref ref-type="disp-formula" rid="pcbi.1006604.e001">1</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1006604.e002">2</xref>) for the pMFC, is too fast. Additionally, the model performs best when the <italic>Damp</italic> parameter is high and the <italic>r</italic><sub><italic>min</italic></sub> parameter is low (again, see Eqs (<xref ref-type="disp-formula" rid="pcbi.1006604.e001">1</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1006604.e002">2</xref>)). Note that this does not mean that pMFC amplitude is always low because it still receives bursts (Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e009">8</xref>)) when it makes errors. Nevertheless, performance is optimal when pMFC amplitude decays fast. The reason for this is the fact that bursts introduce noise to the system (see also <xref ref-type="fig" rid="pcbi.1006604.g003">Fig 3C</xref>). Therefore, the model performs better when the oscillation driving the bursts is slower and less strong, so that fewer bursts are given. We elaborate on these results in the Discussion.</p>
<fig id="pcbi.1006604.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006604.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Parameter exploration.</title>
<p>The first row (A-B) shows results for the combination of the Controller frequency and the Processing frequency. The second row (C-D) shows results for the combination of the <italic>Damp</italic> and <italic>r</italic><sub><italic>min</italic></sub> parameters. In the first column we show results where the other two parameters where kept constant at the original values that we used for other simulations (i.e., we slice parameter space in these two parameters). In the second row, results are shown where we average over all values used for the remaining parameters. Colors indicate mean accuracy over the whole task. The white dashed lines indicate the original parameter values.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006604.g005" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec010">
<title>The stability-plasticity dilemma</title>
<p><xref ref-type="fig" rid="pcbi.1006604.g006">Fig 6</xref> shows the overall accuracy, stability and plasticity of our full model and of the no-synchrony model for the two task structures discussed in the previous section (1- and 3-dimensional tasks). In order to gain more insight in how the model performance is affected by task complexity, we also show overall results for the BP model on a 2-dimensional task. Thus, we show results for tasks of increasing complexity, namely for 1 dimension (RW model), 2 dimensions (BP model) and 3 dimensions (BP model). Results of the RBM model are discussed in <xref ref-type="supplementary-material" rid="pcbi.1006604.s001">S1 Text</xref>.</p>
<fig id="pcbi.1006604.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006604.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Performance of models on reversal learning task.</title>
<p>Overall accuracy (A, D, G), plasticity (B, E, H) and stability (C, F, I) is shown across all learning rates for three tasks of increasing complexity (see <xref ref-type="sec" rid="sec021">Methods</xref> for details). Blue lines show means for the full model and orange lines represent the mean values for the no-synchrony models. The shades indicate the corresponding 95% confidence intervals. The horizontal black dashed line in A and D indicates chance level accuracy.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006604.g006" xlink:type="simple"/>
</fig>
<sec id="sec011">
<title>RW</title>
<p><xref ref-type="fig" rid="pcbi.1006604.g006">Fig 6A–6C</xref> shows similar overall accuracy for the full and no-synchrony RW models. When synaptic learning rates are slow (β = .1-.3), the full model has a better stability than the no-synchrony model. However, this advantage disappears for higher learning rates and the no-synchrony model shows a higher plasticity than the full RW model. In sum, when the task is very easy and the learning rate is very high, synchronization is not required.</p>
</sec>
<sec id="sec012">
<title>BP</title>
<p><xref ref-type="fig" rid="pcbi.1006604.g006">Fig 6D–6I</xref> show a clear advantage for the full relative to the no-synchrony BP model in overall accuracy as well as plasticity and stability. This advantage was present across all learning rates and for both tasks (i.e., with 2 and 3 dimensions). This advantage appears because the synchronization supports modularity, thus protecting information from being overwritten.</p>
</sec>
</sec>
<sec id="sec013">
<title>Connecting to empirical data</title>
<p>As a model of how the brain controls its own processing, we next aimed at describing the relation between our model and previous empirical data, and provide testable hypotheses for future empirical work.</p>
<sec id="sec014">
<title>Theta power</title>
<p>As described before, theta power in the pMFC gradually decayed during the task. However, when a negative prediction error occurred, the pMFC network node received a burst (from <italic>δ</italic> <sup><italic>-</italic></sup>; see Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e009">8</xref>)), which increased pMFC amplitude again. In order to illustrate this process, we performed time-frequency decomposition of the signal produced by the pMFC node. More specifically, we were interested in theta power after feedback. We computed the contrast of power in the inter-trial interval after error and after correct trials in the time-frequency domain (see <xref ref-type="sec" rid="sec021">Methods</xref> for details). In accordance with previous empirical work (e.g., [<xref ref-type="bibr" rid="pcbi.1006604.ref035">35</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref037">37</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref039">39</xref>]), we observe increasing theta power, starting 200 ms after negative feedback, both for the RW (<xref ref-type="fig" rid="pcbi.1006604.g007">Fig 7A</xref>) and BP (<xref ref-type="fig" rid="pcbi.1006604.g007">Fig 7C</xref>) model.</p>
<fig id="pcbi.1006604.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006604.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Connecting to empirical data.</title>
<p>A, C: Contrast of error–correct trials is shown for post-feedback pMFC power in time-frequency spectrum. B, D: phase-amplitude coupling between pMFC theta-phase and gamma-amplitude in the Processing unit is shown. White vertical dashed lines indicate the moment of reward feedback. Red vertical transparent lines indicate task switches. Shades illustrate 95% confidence intervals.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006604.g007" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec015">
<title>Phase-amplitude coupling</title>
<p><xref ref-type="fig" rid="pcbi.1006604.g007">Fig 7B and 7D</xref> illustrate the coupling between the phase of theta oscillations in the pMFC and gamma amplitude in the Processing unit. Again consistent with empirical data [<xref ref-type="bibr" rid="pcbi.1006604.ref034">34</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref040">40</xref>], these plots show a clear increase in phase-amplitude coupling after a task rule switch. This is mainly caused by the fact that there are many negative prediction errors in these trials. These prediction errors increase theta power in the pMFC, which in turn increases the number of bursts received by the gamma oscillations in the Processing unit. This combination of events results in an increase of theta-gamma phase-amplitude coupling (PAC). Once performance of the model improves, less (negative prediction) errors occur. Hence, theta power slowly decreases, which decreases bursts to the processing unit and thus also PAC.</p>
</sec>
</sec>
</sec>
<sec id="sec016" sec-type="conclusions">
<title>Discussion</title>
<p>We described a computationally efficient and empirically testable framework on how biological and artificial agents may deal with the stability-plasticity dilemma. We combined two neurocomputational frameworks, BBS [<xref ref-type="bibr" rid="pcbi.1006604.ref017">17</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref019">19</xref>] and RL [<xref ref-type="bibr" rid="pcbi.1006604.ref021">21</xref>]. BBS flexibly (un)binds (ir)relevant neural modules; RL autonomously discovers when modules need to be (un)bound. Thus, the model could flexibly switch between different tasks (plasticity) without catastrophically forgetting older information (stability). We demonstrated that the model was consistent with several behavioral and electrophysiological (e.g., MEG/EEG) data. In the remainder, we first summarize the main model components, and point to plausible neural origins of each. Second, we discuss specific empirical predictions that are made by the model. Third, we discuss limitations and possible extensions. As a fourth and last point, we describe how the current work relates to previous computational modelling work.</p>
<p>Plausible neural origins for all three model units are summarized in <xref ref-type="fig" rid="pcbi.1006604.g008">Fig 8</xref>. The Processing unit contains a task-processing network, trained by a classical learning rule (RW, BP, or RBM). Anatomically, its nodes can be localized in several posterior (neo-)cortical processing areas, depending on the task at hand (e.g., fusiform face area in a face-processing task). Its activity is strongly stimulus-dependent and synaptic strengths change slowly. The RL unit learns to attach value to specific task modules, based on prediction errors. Previous work with fMRI [<xref ref-type="bibr" rid="pcbi.1006604.ref024">24</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref041">41</xref>] already used a probabilistic reversal learning paradigm to localize the brain areas involved in such value learning. This work localized the RL unit in MFC, which (with brainstem and striatum) is generally considered as an RL circuit [<xref ref-type="bibr" rid="pcbi.1006604.ref024">24</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref042">42</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref043">43</xref>]. Importantly, computations in this unit are not used for driving task-related actions, but for driving hierarchically-higher actions, namely to (de)synchronize task modules. This is in line with recent considerations of MFC as a meta-learner [<xref ref-type="bibr" rid="pcbi.1006604.ref044">44</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref047">47</xref>]. We tentatively call this unit aMFC, given this region’s prominent anatomical connectivity to autonomous regions [<xref ref-type="bibr" rid="pcbi.1006604.ref048">48</xref>]. There was also a Switch neuron in our model. Previous work on stay/switch decisions has proposed they originate from frontopolar cortex [<xref ref-type="bibr" rid="pcbi.1006604.ref049">49</xref>]. Hence, processes in the RL unit might be best explained by a neural circuit between brainstem, aMFC and frontopolar cortex.</p>
<fig id="pcbi.1006604.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006604.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Suggestion of neural origins of three model units.</title>
<p>The Processing unit (in blue) is situated at posterior cortical sites. In the case of a task in which stimuli are visually presented, and responses are hand movements, the Processing unit would consist of visual cortex and pre-motor (and intermediate) areas. The RL unit (in red) could be localized in aMFC (in combination with brainstem and frontopolar cortex (not depicted). The Control unit (in grey) consists of LFC and pMFC.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006604.g008" xlink:type="simple"/>
</fig>
<p>The Control unit was adopted from [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>]. Its first part contains units that point to specific posterior processing areas, indicating which neurons should be (un)bound. Thus, this area stores the task demands. We labeled this part LFC, given the prominent role of LFC in this regard [<xref ref-type="bibr" rid="pcbi.1006604.ref050">50</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref051">51</xref>]. The second part of the Control unit sends random bursts to posterior processing areas to synchronize currently active areas. Given the prominent anatomical connectivity of pMFC to motor control and several posterior processing areas [<xref ref-type="bibr" rid="pcbi.1006604.ref048">48</xref>], we tentatively label this part pMFC. The efficiency of this controlling process is largely determined by pMFC theta power: More power leads to more and longer bursts [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>]. This is consistent with empirical work linking high MFC theta power to efficient cognitive control [<xref ref-type="bibr" rid="pcbi.1006604.ref034">34</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref035">35</xref>]. Power in the model pMFC is itself modulated by the occurrence of negative prediction errors. More specifically, when a negative prediction error occurs, the pMFC node will receive bursts, which will increase pMFC theta power. In absence of negative prediction errors, this theta power will slowly decrease across trials. This is consistent with the idea that a constant high MFC power might be computationally suboptimal and empirically implausible. For instance, MFC projects to locus coeruleus (LC;[<xref ref-type="bibr" rid="pcbi.1006604.ref052">52</xref>]); LC firing is thought to be cognitively costly, perhaps because it leads to waste product in the cortex that needs to be disposed [<xref ref-type="bibr" rid="pcbi.1006604.ref036">36</xref>]. In sum, in the Control unit, LFC and pMFC jointly align neural synchronization in modules of the Processing unit to meet current task demands [<xref ref-type="bibr" rid="pcbi.1006604.ref053">53</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref054">54</xref>]. The LFC indicates which modules should be (de)synchronized, and the pMFC exerts control over the oscillations in the Processing unit by (de)synchronizing them via random bursts.</p>
<p>Crucially, both parts of the Control unit use prediction errors, but at a different time scale. More specifically, the pMFC uses an evaluation of the last prediction error to evaluate the amount of control that should be exerted (fast time scale). Hence, when an error occurs, the model will initially exert more control on the currently used task module/strategy. The LFC on the other hand, is guided by processes in the Switch neuron of the RL unit which evaluates prediction errors on a slow time scale by integrating them over multiple trials, in order to decide between staying with the current task module or switching to another. Therefore, if negative prediction errors keep on occurring after the model increased control, it will switch modules/strategies.</p>
<sec id="sec017">
<title>Experimental predictions</title>
<p>Importantly, our model makes several predictions for empirical data. First, it predicts significant changes in the phase coupling between different posterior neo-cortical brain areas after a task switch. Here, we suggest that desynchronization may be important to disengage from the current task. Consistently, [<xref ref-type="bibr" rid="pcbi.1006604.ref055">55</xref>] found that strong desynchronization marked the period from the moment of disambiguation of ambiguous stimuli to motor responses. Additionally, Parkinson disease patients, often characterized by extreme cognitive rigidity, show abnormally synchronized oscillatory activity [<xref ref-type="bibr" rid="pcbi.1006604.ref056">56</xref>]. Thus, we suggest that neural synchronization between task-relevant brain areas is crucial for implementing task rules. Additionally, desynchronization is necessary for disengaging from a task.</p>
<p>Second, we explored midfrontal theta-activation in the time-frequency domain by wavelet convolution. These analyses showed an increase of theta power after an error. This was caused by bursts that were sent from the RL unit as described in Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e009">8</xref>). Hence, the model predicts an increase of theta amplitude in the MFC after negative prediction errors in tasks where these prediction errors signal the need for increased cognitive control [<xref ref-type="bibr" rid="pcbi.1006604.ref034">34</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref035">35</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref037">37</xref>].</p>
<p>Third, we connected the model to research demonstrating theta/gamma interactions where faster gamma frequencies, which implement bottom-up processes, are typically embedded in, and modulated by, slower theta-oscillations, in order to implement top-down processes [<xref ref-type="bibr" rid="pcbi.1006604.ref040">40</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref057">57</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref059">59</xref>]. For this purpose, we considered coupling between pMFC theta phase and gamma amplitude in the Processing unit. Our model predicts a strong PAC increase in the first trial(s) after a task switch, which decays slowly after the switch. This reflects the binding by random bursts control process which is increased after task switches, and decays once a task rule is sufficiently implemented. Hence, the model predicts a strong coupling between frontal theta phase and posterior gamma amplitude when new task rules need to be implemented.</p>
</sec>
<sec id="sec018">
<title>Limitations and extensions</title>
<p>The model contained several limitations, and consequently also possibilities for future extensions. First, the RL unit currently learns to assign a value to some task module. It can determine when a task switch occurred, and then make a binary switch assessment; to switch or not to switch to another task module. Thus, when the model realizes that the current task module/strategy is incompatible with the current task/environment, it has to change its behavior. It will attempt random strategies until an appropriate one is found. Learning <italic>when</italic> to switch can be considered as a type of meta-learning. However, the full model would benefit significantly from more advanced meta-learning mechanisms. Future work will address this issue by adding second level (contextual) features which allow the LFC to (learn to) infer <italic>which</italic> of multiple task modules should be synchronized. One useful application of such second level features would be task set clustering, which allows to generalize quickly over multiple contexts. Specifically, if a novel second-level feature becomes connected to an earlier learned task set (in LFC), all the task-specific mappings of this task set would immediately generalize to the novel second-level feature. This is consistent with immediate generalization seen in humans [<xref ref-type="bibr" rid="pcbi.1006604.ref060">60</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref062">62</xref>].</p>
<p>Second, several parameters of the model were fixed, but might more generally be controllable (learnable) as well. For example, the time scale of the Switch neuron is controllable by the <italic>σ</italic> parameter in Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e013">12</xref>). In a very stable environment, a low <italic>σ</italic> is adaptive, which slows down the time scale, decreasing the weight of more recent prediction errors. Instead, if the environment is unstable, a less conservative strategy is in order (high <italic>σ</italic>), in which case the model accumulates evidence across less trials in order to make a switch decision. Earlier models already described how switching between hypotheses could depend on environmental stability and noise [<xref ref-type="bibr" rid="pcbi.1006604.ref063">63</xref>]; such manipulation (here, of parameter <italic>σ</italic>) might be usefully implemented in future developments of the current model too.</p>
<p>Third, although using negative prediction errors to modulate the control amplitude of the pMFC is efficient in the current context, this might not be ideal in more complex environments. Thus, another future challenge is broadening the control signal (i.e., beyond negative prediction errors) that the model uses to optimally adapt to the environment’s reward and cost structure [<xref ref-type="bibr" rid="pcbi.1006604.ref045">45</xref>].</p>
<p>Fourth, the node architecture of neuronal triplets is an oversimplification of how oscillations are produced in the human brain. Several neural models propose that interacting excitatory (E) cells and inhibitory (I) cells generate oscillations [<xref ref-type="bibr" rid="pcbi.1006604.ref033">33</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref064">64</xref>]. These oscillatory neurons are grouped with stimulus-driven neurons in cortical columns; oscillatory neurons modulate the activation of the stimulus-driven neurons [<xref ref-type="bibr" rid="pcbi.1006604.ref065">65</xref>]. In the current model, these assumptions are implemented in the simplest way, namely where each column consists of just three neurons (<italic>E</italic>, <italic>I</italic>, and <italic>x</italic>), and the oscillatory activity modulates the stimulus-driven activity. Furthermore, our implementation of processing within a neuronal triplet is perhaps biologically implausible, in the sense that the neuron that processes stimuli (<italic>x</italic>) is distinct from the neurons that generate the oscillations (<italic>E</italic>, <italic>I</italic>) which do not process any stimulus information. Future work will determine whether the current approach can be scaled to more biologically plausible architectures.</p>
<p>Fifth, the model ignored some aspects of oscillatory dynamics. For instance, our model only implements neural synchronization between Processing unit neurons with the same (gamma-band) frequencies. This scenario might be unrealistic in a typically noisy human brain. However, the problem of noise can be efficiently solved by employing rhythmic bursts, such as the theta-frequency we implemented here. Specifically, one-shot synchronizing bursts would cause oscillations with (slightly) different (gamma-band) frequencies to gradually drift apart after the burst. With rhythmically paced bursts, the gamma oscillations have no time to drift apart since the next burst occurs before the drift becomes substantial. In line with this idea, previous work has demonstrated how the model can deal with gamma frequency differences of at least around 2% [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>]. Moreover, one might wonder if it would be optimal to send bursts at a frequency much faster than theta, thus providing no opportunity for noisy oscillations to drift apart. However, the current work showed that accuracy of the model dramatically declines if the pMFC sends bursts at a faster frequency than theta. The reason is that bursts given by the pMFC to the Processing unit introduce noise to the system. This can be clearly observed in <xref ref-type="fig" rid="pcbi.1006604.g003">Fig 3C</xref>, in which there are short periods of irrelevant neuronal activation during the bursts. Hence, an optimal agent would want to limit the bursts as much as possible. Since these bursts are phase locked to the pMFC oscillation and rely on its amplitude, the model performs best with slower pMFC frequencies that are rapidly attracted (high <italic>Damp</italic>) towards a small amplitude (low <italic>r</italic><sub><italic>min</italic></sub>). Again, the oscillations in the Processing unit of the current model all have the exact same frequency. When Processing unit activations do not have the same frequency, we thus conjecture that there is an optimal, intermediate (theta) bursting frequency, depending on the Processing unit (gamma) frequency. Future work should explore such an optimal balance between a Controller/ bursting (theta) frequency and a Processing (gamma) frequency in more noisy systems. Another aspect of oscillatory dynamics we ignored is that BBS may be more biologically plausible, and more efficient, with small inter-areal delays [<xref ref-type="bibr" rid="pcbi.1006604.ref066">66</xref>]. Future work will consider an additional (meta-) learning mechanism that learns to synchronize nodes with an optimal phase delay between task modules.</p>
</sec>
<sec id="sec019">
<title>Related work</title>
<p>The current work relies heavily on previous modeling work of cognitive control processes. For instance, in the current model the LFC functions as a holder of task sets which bias lower-level processing pathways [<xref ref-type="bibr" rid="pcbi.1006604.ref029">29</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref067">67</xref>]. It does this in cooperation with the MFC. Here, the aMFC determines when to switch between lower-level task modules. Additionally, also the amount of control/ effort that is exerted in the model is determined by the RL processes in the aMFC[<xref ref-type="bibr" rid="pcbi.1006604.ref044">44</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref046">46</xref>]. More specifically, negative prediction errors will determine the amount of control that is needed by strongly increasing the pMFC signal [<xref ref-type="bibr" rid="pcbi.1006604.ref042">42</xref>]. This is consistent with earlier work proposing a key role of MFC in effort allocation [<xref ref-type="bibr" rid="pcbi.1006604.ref044">44</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref045">45</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref068">68</xref>].</p>
<p>In the current model, the MFC, together with the LFC, functions as a hierarchically higher network that uses RL to estimate its own task-solving proficiency. Based on its estimate of the value of a module, and the reward that accumulates across trials, it evaluates whether the current task strategy is suited for the current environment. Based on this evaluation, it will decide to stay with the current strategy or switch to another. More specifically, the value learned by the RL unit acts as measure of confidence that the model has in its own accuracy. The model uses this measure of confidence to adjust future behavior, a process that has been labeled as meta-cognition [<xref ref-type="bibr" rid="pcbi.1006604.ref069">69</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref070">70</xref>].This is in line with previous modeling work that described the prefrontal cortex as a reinforcement meta-learner [<xref ref-type="bibr" rid="pcbi.1006604.ref043">43</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref046">46</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref048">48</xref>].</p>
<p>One problem we addressed in this work was the stability-plasticity dilemma. As we described before, previous work on this dilemma can broadly be divided in two classes of solutions. The first class is based on mixing old and new information [<xref ref-type="bibr" rid="pcbi.1006604.ref002">2</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref005">5</xref>]. The second class is based on protection of old information. Our solution also exploited the principle of protection. Future work must develop biologically plausible implementations of the mixing principle too, and investigate to what extent mixing and protection scale up to larger problems.</p>
</sec>
<sec id="sec020">
<title>Summary</title>
<p>We provided a computationally efficient and empirically testable framework on how the primate brain can address the tradeoff between being sufficiently adaptive to novel information, while retaining valuable earlier regularities (stability-plasticity dilemma). We demonstrated how this problem can be solved by adding fast BBS and RL on top of a classic slow synaptic learning network. RL is used to synchronize task-relevant and desynchronize task-irrelevant modules. This allows high plasticity in task-relevant modules while retaining stability in task-irrelevant modules. Furthermore, we connected the model with empirical findings and provided predictions for future empirical work.</p>
</sec>
</sec>
<sec id="sec021" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec022">
<title>The models</title>
<p>As mentioned before and is shown in <xref ref-type="fig" rid="pcbi.1006604.g001">Fig 1A</xref>, our model consists of three units. First, the Processing unit includes the task-related neural network, which is trained with a classical learning rule (RW, BP or RBM). On top of this classical network, an extra hierarchical layer is added consisting of two units [<xref ref-type="bibr" rid="pcbi.1006604.ref028">28</xref>]. The RL unit, adopted from the RVPM [<xref ref-type="bibr" rid="pcbi.1006604.ref024">24</xref>], evaluates whether the Processing unit is synchronizing the correct task modules. This evaluation is used by the Control unit [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>] to drive neural synchronization in the Processing unit. Thus, this hierarchically higher network allows the models to implement BBS in an unsupervised manner.</p>
<sec id="sec023">
<title>The processing unit</title>
<p>An important feature of the current model is that all nodes in the Processing unit consist of triplets of neurons (<xref ref-type="fig" rid="pcbi.1006604.g002">Fig 2B</xref>), as in [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>]. The mechanisms of these nodes are illustrated in the Results section and described by Eqs (<xref ref-type="disp-formula" rid="pcbi.1006604.e001">1</xref>)–(<xref ref-type="disp-formula" rid="pcbi.1006604.e009">8</xref>). Importantly, all weights (<italic>W</italic>) in the Processing unit are subject to learning. Here, learning is done according to one of the three classic learning rules; RW, BP or RBM [<xref ref-type="bibr" rid="pcbi.1006604.ref025">25</xref>–<xref ref-type="bibr" rid="pcbi.1006604.ref027">27</xref>]. A new learning step was executed at the end of every trial. Because activation in the rate code neurons is modulated by <italic>G</italic>(<italic>E</italic><sub><italic>i</italic></sub>) (see Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e005">5</xref>)), the activation patterns <italic>x</italic><sub><italic>i</italic></sub> also oscillate (see <xref ref-type="fig" rid="pcbi.1006604.g003">Fig 3C</xref>). For simplicity, we use their maximum activation across one trial as input for the learning rules, <italic>X</italic><sub><italic>i</italic></sub> = max(<italic>x</italic><sub><italic>i</italic></sub>). Importantly, the standard formulation of the Rescorla-Wagner rule does not combine well with the full model because, in this combination also non-active units would be able learn. To remedy this, a small adjustment was made to the learning rule [<xref ref-type="bibr" rid="pcbi.1006604.ref025">25</xref>] for the full model. Specifically, we added one term to the classic rule in order to only make co-activated neurons eligible for learning, resulting in
<disp-formula id="pcbi.1006604.e010">
<alternatives>
<graphic id="pcbi.1006604.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub>
</mml:math>
</alternatives>
<label>(9)</label>
</disp-formula>
in which β is the learning rate parameter. Importantly, this adjustment of the learning rule also results in a plasticity cost. More specifically, plasticity decreases because the added term (<italic>X</italic><sub><italic>O</italic></sub>) represents the activation of the output unit, which is typically lower than 1 and hence slows down learning. Because the no-synchrony model obtains no advantage of this adjusted learning rule and we aimed to give the classic model the best chances for competing with the full model, we only used the adjusted learning rule (Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e010">9</xref>)) for the full model.</p>
<p>For the RW and BP networks, a trial ended after 500 time steps (1 sec). Here, the first 250 time steps (500 msec) were simulated as an inter-trial interval in which the Rate code neurons (<italic>x</italic>) did not receive input. In the next 250 time steps, input was presented to the networks. The RBM network also started a trial with 250 time steps without stimulation of the Rate code neurons. After this inter-trial interval the network employs iterations of bidirectional information flow to estimate the necessary synaptic change [<xref ref-type="bibr" rid="pcbi.1006604.ref027">27</xref>]. We used 5 iterations. Every iteration step (2 in one iteration; one step for each direction of information flow) lasted for 250 time steps. The RBM algorithm also employs stochastic binarization of activation levels at each iteration step. Also here, we used the maximum activation over all time steps (<italic>X</italic><sub><italic>i</italic></sub>) to extract a binary input for that neuron in the next iteration step.</p>
<p>As mentioned in the main text, we compare our new (full) models to models that only use synaptic learning and hence do not use synchronization (no-synchrony models). Thus, those no-synchrony models only have a Processing unit. Here, all used equations and parameters are the same as described above, except for the no-synchrony RW model where we use the classic learning rule instead of the one described in Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e010">9</xref>). The only difference is that they do not have phase code neurons and by consequence, <italic>G</italic>(<italic>E</italic><sub><italic>i</italic></sub>(<italic>t</italic>)) = 1 in Eq (<xref ref-type="disp-formula" rid="pcbi.1006604.e005">5</xref>).</p>
</sec>
<sec id="sec024">
<title>The RL unit</title>
<p>As RL unit, we implemented the Reward Value Prediction Model (RVPM; 9). Here, there is one expected reward neuron, <italic>V</italic>, which holds an estimation of the reward the model will receive given the task module it used. This estimation is made by
<disp-formula id="pcbi.1006604.e011">
<alternatives>
<graphic id="pcbi.1006604.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">Z</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn>
</mml:math>
</alternatives>
<label>(10)</label>
</disp-formula>
In this equation, <bold><italic>Z</italic></bold> is a (column) vector representing the synaptic connections from LFC neurons to the <italic>V</italic> neuron as presented in <xref ref-type="fig" rid="pcbi.1006604.g002">Fig 2A</xref>. This vector holds information about the value of specific task modules. Superscript <italic>T</italic> indicates that we transposed the <bold><italic>Z</italic></bold> vector. The <bold><italic>LFC</italic></bold>-term is a vector of LFC values representing which task module drove network behavior on the current trial. These values are normalized, controlling for the fact that LFC neurons can take on negative values. Hence, <italic>V</italic> will represent the expected value of the task module that is synchronized by the LFC represented in the <bold><italic>Z</italic></bold> vector. These weights are updated by the RVPM learning rule [<xref ref-type="bibr" rid="pcbi.1006604.ref024">24</xref>],
<disp-formula id="pcbi.1006604.e012">
<alternatives>
<graphic id="pcbi.1006604.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e012" xlink:type="simple"/>
<mml:math display="block" id="M12">
<mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(11)</label>
</disp-formula>
which is a reinforcement-modulated Hebbian learning rule from the broader class of RL algorithms. Here, <italic>n</italic> represents the current trial. The learning rate, <italic>α</italic>, is set to .01 for the BP and RBM models and to .1 for the RW model. All neurons in the RL unit, are rate code neurons which have no time index because they only take one value per trial.</p>
<p>Two prediction error neurons in the RL unit compare the estimated reward (<italic>V</italic>) with the actual received reward. This leads to a negative prediction error <italic>δ—</italic>&gt; 0 if the reward is smaller than predicted, <italic>δ</italic> <sup><bold>+</bold></sup> &gt; 0 if the reward is larger than predicted, and <italic>δ— = δ</italic> <sup><bold><italic>+</italic></bold></sup> = 0 if the prediction matches the actual reward (see [<xref ref-type="bibr" rid="pcbi.1006604.ref024">24</xref>] for more details). In the current model, the Switch neuron will accumulate this prediction error signal in order to evaluate whether the task rule has changed or not. For this purpose, it follows,
<disp-formula id="pcbi.1006604.e013">
<alternatives>
<graphic id="pcbi.1006604.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>σ</mml:mi><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:msubsup><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup>
</mml:math>
</alternatives>
<label>(12)</label>
</disp-formula>
Here, the value of <italic>σ</italic> is set to .8 for the multi-layer models and .5 for the RW model. When activation in this neuron reaches a threshold of .5, it signals the need for a switch to the LFC in the Control unit and resets its own activation to zero. In the equation, <italic>n</italic> refers to the trial number. Hence, a sequence of big negative prediction errors will cause activation in the Switch neuron to reach the threshold.</p>
</sec>
<sec id="sec025">
<title>The control unit</title>
<p><italic>A</italic>s in previous work [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>], the Control unit consists of two parts, corresponding to posterior medial (pMFC) and lateral (LFC) parts of the primate prefrontal cortex.</p>
<p>The modelled pMFC represents one node (<xref ref-type="fig" rid="pcbi.1006604.g002">Fig 2</xref>) consisting of one phase code pair (<italic>E</italic><sub>pMFC</sub>, <italic>I</italic><sub>pMFC</sub>) and a rate code neuron (<italic>pMFC</italic>). The specifics of this pMFC node are described in the Results section and illustrated in <xref ref-type="fig" rid="pcbi.1006604.g003">Fig 3A</xref>.</p>
<p>In general, the model implements a “win stay, lose shift” strategy, shifting attention in LFC when reward appears less than expected. As shown in <xref ref-type="fig" rid="pcbi.1006604.g002">Fig 2A</xref>, the LFC consists of four rate code neurons that each have a pointer to one (or two) of the different modules in the Processing unit. Three of these LFC neurons are each connected to one of the three task modules in layer 2. For these LFC neurons, at trial <italic>n</italic> = 1 a random choice is made where one neuron is set to 1 and the others to -1. These activations remain until activation in the Switch neuron, S, reaches the threshold. At this point, a new choice is made where one LFC neuron is set to 1 and all others are set to -1. This choice is based on a softmax decision rule,
<disp-formula id="pcbi.1006604.e014">
<alternatives>
<graphic id="pcbi.1006604.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e014" xlink:type="simple"/>
<mml:math display="block" id="M14">
<mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.25em"/><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
<label>(13)</label>
</disp-formula>
Here, <italic>Q</italic><sub><italic>i</italic></sub> is the value associated with that LFC neuron/ task module and <italic>Inh</italic><sub><italic>i</italic></sub> is an inhibition signal. At the moment the switch threshold is reached, <italic>Inh</italic><sub><italic>i</italic></sub> is set to -2 for the currently synchronized module. This value decays by 10% on every trial afterwards. This inhibition is implemented to avoid that the model would constantly switch between two modules. Because non-chosen LFC neurons are set to -1, the network always synchronizes one task module with layer 1 for the RW model and with layers 1 and 3 for the BP and RBM models, and desynchronizes the other task modules. When it realizes that the task rule has switched, it will select a new task module. For this selection it will prioritize task modules that have a high value assigned to it (encoded in <italic>Q</italic><sub><italic>i</italic></sub>), except when this task module was presented recently; in that case, the task module is inhibited (<italic>Inh</italic><sub><italic>i</italic></sub>). The remaining LFC neuron is connected (constant value of 1) to the other layers (1 and 3) of the network that must be synchronized.</p>
</sec>
</sec>
<sec id="sec026">
<title>The task</title>
<p>We test our model on a reversal learning task [<xref ref-type="bibr" rid="pcbi.1006604.ref071">71</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref072">72</xref>]. We divide the task in six equally long task blocks. In the first three blocks, the model should learn three different new task rules (rule A, B and C in blocks 1, 2 and 3 respectively). In the second half, the model has to switch back to the previously learned rules (rule A, B and C in blocks 4, 5 and 6 respectively).</p>
<p>For the RW network, we use a one-dimensional task. This task consisted of 360 trials. Here, on each trial one out of three stimulus features is activated. For every task rule we link a stimulus-feature to a response option. More specifically, in task rule A, feature 1 (F1) is associated to response (R1), feature 2 (F2) to response 2 (R2) and feature 3 (F3) response 3 (R3). In task rule B, F1 is associated to R2, F2 to R3 and F3 to R1. Task rule C associates F1 to R3, F2 to R1 and F3 to R2. All stimuli are presented equally often in random order.</p>
<p>For the BP and RBM networks, a multi-dimensional task is used consisting of 3600 trials. In order to gain insight in how the complexity of the task affects our model, we implemented a task with two stimulus dimensions (two-dimensional task) and one with three stimulus dimensions (three-dimensional task). For the RBM model, we only implemented the three-dimensional task. Every stimulus dimension has three features. In total, a task consists of <italic>N</italic> + 1 dimensions, in which <italic>N</italic> is the number of stimulus dimensions and the extra dimension is a cue dimension (with <italic>N</italic> features), indicating which of the <italic>N</italic> stimulus dimensions is relevant on the current trial. On each trial one feature of every dimension is activated. In line with the one-dimensional task, the <italic>N</italic> = 3 task features of the stimulus dimensions are, within each task rule, linked to one response option. Again, in each block, each possible stimulus is presented equally often, in a random order.</p>
</sec>
<sec id="sec027">
<title>Simulations</title>
<p>To test the generality of our findings, we varied the synaptic learning rate. This parameter was varied from 0 to 1 in 11 steps of .1. For each value, we performed 10 replications of the simulation. In every simulation, the strength of synaptic connections at trial 1 was a random number drawn from the uniform distribution, multiplied by half the bias value (and 1 for the RW based model).</p>
<p>The effects of other model parameters were already demonstrated in previous work [<xref ref-type="bibr" rid="pcbi.1006604.ref024">24</xref>], [<xref ref-type="bibr" rid="pcbi.1006604.ref030">30</xref>], but we again validated that the model shows qualitatively similar patterns when we varied some of the parameters. A table of all parameter values used in both the original simulations and parameter explorations is provided in the <xref ref-type="supplementary-material" rid="pcbi.1006604.s001">S1 Text</xref>. Specifically, we explored different frequencies (<italic>C</italic> in Eqs (<xref ref-type="disp-formula" rid="pcbi.1006604.e001">1</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1006604.e002">2</xref>)) in the Processing unit and the pMFC. Additionally, we also explored the <italic>Damp</italic> and <italic>r</italic><sub><italic>min</italic></sub> parameters in the pMFC (again Eqs (<xref ref-type="disp-formula" rid="pcbi.1006604.e001">1</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1006604.e002">2</xref>)). For this simulation we used the RW model with β = .2. We fully crossed all parameter values for <italic>C</italic>, <italic>Damp</italic> and <italic>r</italic><sub><italic>min</italic>.</sub> and performed 5 replications. In a separate set of explorations, we varied <italic>σ</italic> and <italic>α</italic> in the RL unit (see Eqs (<xref ref-type="disp-formula" rid="pcbi.1006604.e012">11</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1006604.e013">12</xref>)) for both the RW and BP algorithm, for both a slow and a fast-synaptic learning rate (β). Again, we performed 5 replications for each parameter combination. Results of the latter parameter exploration are described in the <xref ref-type="supplementary-material" rid="pcbi.1006604.s001">S1 Text</xref>.</p>
</sec>
<sec id="sec028">
<title>Statistical analyses</title>
<p>For the purpose of comparison, we divided the trials of the task for every model into 120 bins. For the RW model, bin size equals 3 trials; for the BP and RBM models, bin size equals 30 trials. We evaluate the performance of our model on several levels. First, we evaluate overall task accuracy. Second, we evaluate plasticity. For this purpose, we explore the performance of the model during the first 5 bins of the first 3 blocks. Hence, we test how quickly a model can learn a new task rule. Third, we evaluate stability. In particular, we explore the interference of learning other task rules in between two periods of performing the same task rule. For this purpose, we compare the accuracy during the first 5 trial bins of block 4, 5 and 6 with the last 5 trial bins of block 1, 2 and 3. If the model saved what was learned, this difference should be zero. If the model displays catastrophic forgetting, it would have a negative stability score.</p>
<p>Importantly, we also connect with empirical data and describe testable hypotheses for future empirical work. As a measure of phase synchronization between excitatory neurons in the Processing unit, we compute the correlation at phase lag zero. A correlation of 1 indicates complete synchronization and -1 indicates complete desynchronization. Phase-amplitude coupling (PAC) is computed as the debiased phase-amplitude coupling measure (dPAC; [<xref ref-type="bibr" rid="pcbi.1006604.ref073">73</xref>]) in each trial. Here,
<disp-formula id="pcbi.1006604.e015">
<alternatives>
<graphic id="pcbi.1006604.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e015" xlink:type="simple"/>
<mml:math display="block" id="M15">
<mml:mi>d</mml:mi><mml:mi>P</mml:mi><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>Φ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(14)</label>
</disp-formula>
in which
<disp-formula id="pcbi.1006604.e016">
<alternatives>
<graphic id="pcbi.1006604.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e016" xlink:type="simple"/>
<mml:math display="block" id="M16">
<mml:msup><mml:mrow><mml:mi>Φ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>φ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(15)</label>
</disp-formula>
In these equations, <italic>t</italic> represents one time step in a trial, <italic>h</italic> is the number of time steps in a trial, <italic>a</italic> is the amplitude, <italic>φ</italic> is the phase of a signal, and <italic>i</italic><sup>2</sup> = -1. In the current paper, we are interested in the coupling between the phase of the theta oscillation in the pMFC node of the Control unit and the gamma amplitude in the Processing unit. Phase was extracted by taking the analytical phase after a Hilbert transform. The gamma amplitude was derived as the mean of the excitatory phase code activation of all nodes in the Processing unit by
<disp-formula id="pcbi.1006604.e017">
<alternatives>
<graphic id="pcbi.1006604.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e017" xlink:type="simple"/>
<mml:math display="block" id="M17">
<mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(16)</label>
</disp-formula>
with <italic>I</italic> being the number of nodes in the Processing unit, <italic>t</italic> referring to time and <italic>E</italic><sub><italic>i</italic></sub> being the respective excitatory phase code neuron.</p>
<p>For all measures, we represent the mean value over <italic>Nrep</italic> = 10 replications and error bars or shades show the confidence interval computed by mean± 2×(SD/√<italic>Nrep</italic>).</p>
<p>Additionally, we evaluated the pMFC theta activation. More specifically, time–frequency signal decomposition was performed by convolving the signal of <italic>E</italic><sub>pMFC</sub> by complex Morlet wavelets, <inline-formula id="pcbi.1006604.e018"><alternatives><graphic id="pcbi.1006604.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006604.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>, where <italic>i</italic><sup>2</sup> = -1, <italic>t</italic> is time, <italic>f</italic> is frequency, ranging from 1 to 10 in 10 linearly spaced steps, and σ = 4/(2πf) is the “width” of the wavelet. Power at time step <italic>t</italic> was then computed as the squared magnitude of the complex signal at time t and frequency f. We averaged this power over all simulations and all replications of our simulations. This power was evaluated by taking the contrast between the inter-trial intervals following correct (1) and error (0) reward feedback.</p>
</sec>
<sec id="sec029">
<title>Data and software availability</title>
<p>Matlab codes that were used for both the model simulations and data analysis are available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/CogComNeuroSci/PieterV_public" xlink:type="simple">https://github.com/CogComNeuroSci/PieterV_public</ext-link>).</p>
</sec>
</sec>
<sec id="sec030">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006604.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006604.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Supplementary materials.</title>
<p>We present results for the RBM model simulation and exploration of the parameters in the RL unit. Additionally, we provide tables of all parameter values that were used for our simulations.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006604.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006604.s002" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>The RBM model.</title>
<p>The first row (A-C) gives a deeper insight into the model dynamics. In A, orange lines represent the synaptic model and blue lines the full model. In E, brown lines represent the first chosen task module, magenta lines the secondly chosen module and green lines the remaining task module. In F, the horizontal blue line indicates the Switch threshold and the yellow arrows mark the moment the activation reached the threshold. The second row (D-F), shows the mean accuracy, plasticity and stability for the RBM model across learning rates. Again, orange represents the synaptic model and blue the full model Overall, red vertical dashed lines indicate task switches, black horizontal dashed lines indicate chance level of accuracy, and shades represent 95% confidence intervals.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006604.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006604.s003" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>RL unit parameter exploration.</title>
<p>Mean accuracy is shown for all simulations with a certain parameter value. The first row (A-D) shows results for the RW model and the second row (E-H) for the BP model. The first two columns (A, B, E, F) show data for simulations with a small synaptic learning rate (β = .2) for different values of <italic>α</italic> and <italic>σ</italic> respectively. The last two columns (C, D, G, H) show the same data for a faster synaptic learning rate (β = .8). Black vertical dashed lines indicate the parameter values that were used for the original simulations described in the main text.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Daniele Marinazzo, Cristian Buc Calderon, and Sebastian Musslick for helpful comments.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006604.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>French</surname> <given-names>R. M.</given-names></name>, “<article-title>Catastrophic forgetting in connectionist networks</article-title>,” <source><italic>Trends Cogn</italic>. <italic>Sci</italic>.</source>, vol. <volume>6613</volume>, no. <month>April</month>, pp. <fpage>128</fpage>–<lpage>135</lpage>, <year>1999</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Norman</surname> <given-names>K. A.</given-names></name>, “<article-title>How hippocampus and cortex contribute to recognition memory: Revisiting the complementary learning systems model</article-title>,” <source><italic>Hippocampus</italic></source>, vol. <volume>20</volume>, no. <issue>11</issue>, pp. <fpage>1217</fpage>–<lpage>1227</lpage>, <year>2010</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hipo.20855" xlink:type="simple">10.1002/hipo.20855</ext-link></comment> <object-id pub-id-type="pmid">20857486</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McClelland</surname> <given-names>J. L.</given-names></name>, <name name-style="western"><surname>McNaughton</surname> <given-names>B. L.</given-names></name>, and <name name-style="western"><surname>O’Reilly</surname> <given-names>R. C.</given-names></name>, “<article-title>Why There Are Complementary Learning Systems in the Hippocampus and Neo-cortex: Insights from the Successes and Failures of Connectionists Models of Learning and Memory</article-title>,” <source><italic>Psychol</italic>. <italic>Rev</italic>.</source>, vol. <volume>102</volume>, no. <issue>3</issue>, pp. <fpage>419</fpage>–<lpage>457</lpage>, <year>1995</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.102.3.419" xlink:type="simple">10.1037/0033-295X.102.3.419</ext-link></comment> <object-id pub-id-type="pmid">7624455</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O’Reilly</surname> <given-names>R. C.</given-names></name> and <name name-style="western"><surname>Norman</surname> <given-names>K. A.</given-names></name>, “<article-title>Hippocampal and neocortical contributions to memory: Advances in the complementary learning systems framework</article-title>,” <source><italic>Trends Cogn</italic>. <italic>Sci</italic>.</source>, vol. <volume>6</volume>, no. <issue>12</issue>, pp. <fpage>505</fpage>–<lpage>510</lpage>, <year>2002</year>. <object-id pub-id-type="pmid">12475710</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Robins</surname> <given-names>A.</given-names></name> and <name name-style="western"><surname>McCallum</surname> <given-names>S.</given-names></name>, “<article-title>Catastrophic Forgetting and the Pseudorehearsal Solution in Hopfield-type Networks</article-title>,” <source><italic>Conn</italic>. <italic>Sci</italic>.</source>, vol. <volume>10</volume>, no. <issue>2</issue>, pp. <fpage>121</fpage>–<lpage>135</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meeter</surname> <given-names>M.</given-names></name>, <name name-style="western"><surname>Murre</surname> <given-names>J. M. J.</given-names></name>, and <name name-style="western"><surname>Talamini</surname> <given-names>L. M.</given-names></name>, “<article-title>Mode shifting between storage and recall based on novelty detection in oscillating hippocampal circuits</article-title>,” <source><italic>Hippocampus</italic></source>, vol. <volume>14</volume>, no. <issue>6</issue>, pp. <fpage>722</fpage>–<lpage>741</lpage>, <year>2004</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hipo.10214" xlink:type="simple">10.1002/hipo.10214</ext-link></comment> <object-id pub-id-type="pmid">15318331</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lindsay</surname> <given-names>S.</given-names></name> and <name name-style="western"><surname>Gaskell</surname> <given-names>M. G.</given-names></name>, “<article-title>A complementary systems account of word learning in L1 and L2</article-title>,” <source><italic>Lang</italic>. <italic>Learn</italic>.</source>, vol. <volume>60</volume>, no. <issue>SUPPL. 2</issue>, pp. <fpage>45</fpage>–<lpage>63</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mayberry</surname> <given-names>E. J.</given-names></name>, <name name-style="western"><surname>Sage</surname> <given-names>K.</given-names></name>, <name name-style="western"><surname>Ehsan</surname> <given-names>S.</given-names></name>, and <name name-style="western"><surname>Lambon Ralph</surname> <given-names>M. A.</given-names></name>, “<article-title>Relearning in semantic dementia reflects contributions from both medial temporal lobe episodic and degraded neocortical semantic systems: Evidence in support of the complementary learning systems theory</article-title>,” <source><italic>Neuropsychologia</italic></source>, vol. <volume>49</volume>, no. <issue>13</issue>, pp. <fpage>3591</fpage>–<lpage>3598</lpage>, <year>2011</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuropsychologia.2011.09.010" xlink:type="simple">10.1016/j.neuropsychologia.2011.09.010</ext-link></comment> <object-id pub-id-type="pmid">21939679</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fusi</surname> <given-names>S.</given-names></name>, <name name-style="western"><surname>Drew</surname> <given-names>P. J.</given-names></name>, and <name name-style="western"><surname>Abbott</surname> <given-names>L. F.</given-names></name>, “<article-title>Cascade models of synaptically stored memories</article-title>,” <source><italic>Neuron</italic></source>, vol. <volume>45</volume>, no. <issue>4</issue>, pp. <fpage>599</fpage>–<lpage>611</lpage>, <year>2005</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2005.02.001" xlink:type="simple">10.1016/j.neuron.2005.02.001</ext-link></comment> <object-id pub-id-type="pmid">15721245</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kirkpatrick</surname> <given-names>J.</given-names></name> <etal>et al.</etal>, “<article-title>Overcoming Catastrophic Forgetting in Neural Networks</article-title>,” <source><italic>Proc</italic>. <italic>Natl</italic>. <italic>Acad</italic>. <italic>Sci</italic>.</source>, vol. <volume>114</volume>, no. <issue>13</issue>, pp. <fpage>3521</fpage>–<lpage>3526</lpage>, <year>2017</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1611835114" xlink:type="simple">10.1073/pnas.1611835114</ext-link></comment> <object-id pub-id-type="pmid">28292907</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zenke</surname> <given-names>F.</given-names></name>, <name name-style="western"><surname>Poole</surname> <given-names>B.</given-names></name>, and <name name-style="western"><surname>Ganguli</surname> <given-names>S.</given-names></name>, “<article-title>Continual Learning Through Synaptic Intelligence</article-title>,” <year>2017</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kortge</surname> <given-names>C.</given-names></name>, “<article-title>Episodic memory in connectionist networks</article-title>,” in <source><italic>12th Annual meeting of the Cognitive Science Society</italic></source>, <year>1990</year>, pp. <fpage>764</fpage>–<lpage>771</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>French</surname> <given-names>R. M.</given-names></name>, “<article-title>Semi-distributed Representations and Catastrophic Forgetting in Connectionist Networks</article-title>,” <source><italic>Conn</italic>. <italic>Sci</italic>.</source>, vol. <volume>4</volume>, no. <issue>3–4</issue>, pp. <fpage>365</fpage>–<lpage>377</lpage>, <year>1992</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hebb</surname> <given-names>D. O.</given-names></name>, “<article-title>The Organization of Behavior. A neuropsychological theory</article-title>,” <source><italic>Organ</italic>. <italic>Behav</italic>.</source>, vol. <volume>911</volume>, no. <issue>1</issue>, p. <fpage>335</fpage>, <year>1949</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rescorla</surname> <given-names>R. A.</given-names></name> and <name name-style="western"><surname>Wagner</surname> <given-names>A. R.</given-names></name>, “<article-title>A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</article-title>,” <source><italic>Class</italic>. <italic>Cond</italic>. <italic>II Curr</italic>. <italic>Res</italic>. <italic>Theory</italic></source>, vol. <volume>21</volume>, no. <issue>6</issue>, pp. <fpage>64</fpage>–<lpage>99</lpage>, <year>1972</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Masse</surname> <given-names>N. Y.</given-names></name>, <name name-style="western"><surname>Grant</surname> <given-names>G. D.</given-names></name>, and <name name-style="western"><surname>Freedman</surname> <given-names>D. J.</given-names></name>, “<article-title>Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization</article-title>,” <italic>arXiv</italic>:<italic>1802</italic>.<italic>01569</italic>, pp. <fpage>1</fpage>–<lpage>12</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fries</surname> <given-names>P.</given-names></name>, “<article-title>Rhythms for Cognition: Communication through Coherence</article-title>,” <source><italic>Neuron</italic></source>, vol. <volume>88</volume>, no. <issue>1</issue>, pp. <fpage>220</fpage>–<lpage>235</lpage>, <year>2015</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.09.034" xlink:type="simple">10.1016/j.neuron.2015.09.034</ext-link></comment> <object-id pub-id-type="pmid">26447583</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fries</surname> <given-names>P.</given-names></name>, “<article-title>A mechanism for cognitive dynamics: neuronal communication through neuronal coherence</article-title>,” <source><italic>Trends Cogn</italic>. <italic>Sci</italic>.</source>, vol. <volume>9</volume>, no. <issue>10</issue>, pp. <fpage>474</fpage>–<lpage>480</lpage>, <month>Oct</month>. <year>2005</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2005.08.011" xlink:type="simple">10.1016/j.tics.2005.08.011</ext-link></comment> <object-id pub-id-type="pmid">16150631</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gray</surname> <given-names>C. M.</given-names></name> and <name name-style="western"><surname>Singer</surname> <given-names>W.</given-names></name>, “<article-title>Stimulus-specific neuronal oscillations in orientation columns of cat visual cortex.</article-title>,” <source><italic>Proc</italic>. <italic>Natl</italic>. <italic>Acad</italic>. <italic>Sci</italic>. <italic>U</italic>. <italic>S</italic>. <italic>A</italic>.</source>, vol. <volume>86</volume>, no. <issue>5</issue>, pp. <fpage>1698</fpage>–<lpage>1702</lpage>, <year>1989</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.86.5.1698" xlink:type="simple">10.1073/pnas.86.5.1698</ext-link></comment> <object-id pub-id-type="pmid">2922407</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Womelsdorf</surname> <given-names>T.</given-names></name>, <name name-style="western"><surname>Schoffelen</surname> <given-names>J.</given-names></name>, <name name-style="western"><surname>Oostenveld</surname> <given-names>R.</given-names></name>, and <name name-style="western"><surname>Singer</surname> <given-names>W.</given-names></name>, “<article-title>Modulation of Neuronal Interactions Through Neuronal Synchronization</article-title>,” <source><italic>Science</italic></source> <italic>(80-</italic>. <italic>)</italic>., vol. <volume>316</volume>, no. <month>June</month>, pp. <fpage>1609</fpage>–<lpage>1612</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref021"><label>21</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Sutton</surname> <given-names>R.</given-names></name> and <name name-style="western"><surname>Barto</surname> <given-names>A. G.</given-names></name>, <source><italic>Reinforcement learning</italic>: <italic>an introduction</italic></source>, <edition>28th ed</edition>. <publisher-name>MIT Press</publisher-name>, <year>1998</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Frank</surname> <given-names>M. J.</given-names></name> and <name name-style="western"><surname>Badre</surname> <given-names>D.</given-names></name>, “<article-title>Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: Computational analysis</article-title>,” <source><italic>Cereb</italic>. <italic>Cortex</italic></source>, vol. <volume>22</volume>, no. <issue>3</issue>, pp. <fpage>509</fpage>–<lpage>526</lpage>, <year>2012</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhr114" xlink:type="simple">10.1093/cercor/bhr114</ext-link></comment> <object-id pub-id-type="pmid">21693490</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hochreiter</surname> <given-names>S.</given-names></name> and <name name-style="western"><surname>Schmidhuber</surname> <given-names>J.</given-names></name>, “<article-title>Long Short-Term Memory</article-title>,” <source><italic>Neural Comput</italic>.</source>, vol. <volume>9</volume>, no. <issue>8</issue>, pp. <fpage>1735</fpage>–<lpage>1780</lpage>, <year>1997</year>. <object-id pub-id-type="pmid">9377276</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Silvetti</surname> <given-names>M.</given-names></name>, <name name-style="western"><surname>Seurinck</surname> <given-names>R.</given-names></name>, and <name name-style="western"><surname>Verguts</surname> <given-names>T.</given-names></name>, “<article-title>Value and Prediction Error in Medial Frontal Cortex: Integrating the Single-Unit and Systems Levels of Analysis</article-title>,” <source><italic>Front</italic>. <italic>Hum</italic>. <italic>Neurosci</italic>.</source>, vol. <volume>5</volume>, no. <month>August</month>, p. <fpage>75</fpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Widrow</surname> <given-names>B.</given-names></name> and <name name-style="western"><surname>Hoff</surname> <given-names>M.</given-names></name>, “<article-title>Adaptive switching circuits.</article-title>,” <source><italic>IRE WESCON Conv</italic>. <italic>Rec</italic>.</source>, vol. <volume>4</volume>, no. <issue>1</issue>, pp. <fpage>96</fpage>–<lpage>104</lpage>, <year>1960</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rumelhart</surname> <given-names>D. E.</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>G. E.</given-names></name>, and <name name-style="western"><surname>Williams</surname> <given-names>R. J.</given-names></name>, “<article-title>Learning representations by back-propagating errors</article-title>,” <source><italic>Nature</italic></source>, vol. <volume>323</volume>, no. <month>October</month>, pp. <fpage>533</fpage>–<lpage>536</lpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hinton</surname> <given-names>G.</given-names></name>, “<article-title>A Practical Guide to Training Restricted Boltzmann Machines</article-title>,” in <source><italic>Neural Networks</italic>: <italic>Tricks of the Trade</italic></source>, 2nd ed., <name name-style="western"><surname>Montavon</surname> <given-names>G.</given-names></name>, <name name-style="western"><surname>Orr</surname> <given-names>G. B.</given-names></name>, and <name name-style="western"><surname>Müller</surname> <given-names>K.-R.</given-names></name>, Eds. <year>2012</year>, pp. <fpage>599</fpage>–<lpage>619</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Houk</surname> <given-names>J. C.</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>J. L.</given-names></name>, and <name name-style="western"><surname>Barto</surname> <given-names>A. G.</given-names></name>, “<article-title>A model of how the basal ganglia generate and use neural signals that predict reinforcement</article-title>,” <source><italic>Model</italic>. <italic>Inf</italic>. <italic>Process</italic>. <italic>Basal Ganglia</italic></source>, vol. <volume>13</volume>, no. <month>July</month> 1995, pp. <fpage>249</fpage>–<lpage>270</lpage>, <year>1995</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Botvinick</surname> <given-names>M. M.</given-names></name>, <name name-style="western"><surname>Braver</surname> <given-names>T. S.</given-names></name>, <name name-style="western"><surname>Barch</surname> <given-names>D. M.</given-names></name>, <name name-style="western"><surname>Carter</surname> <given-names>C. S.</given-names></name>, and <name name-style="western"><surname>Cohen</surname> <given-names>J. D.</given-names></name>, “<article-title>Conflict monitoring and cognitive control.</article-title>,” <source><italic>Psychological review</italic></source>, vol. <volume>108</volume>, no. <issue>3</issue>. pp. <fpage>624</fpage>–<lpage>652</lpage>, <year>2001</year>. <object-id pub-id-type="pmid">11488380</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Verguts</surname> <given-names>T.</given-names></name>, “<article-title>Binding by random bursts: A computational model of cognitive control</article-title>,” <source><italic>J</italic>. <italic>Cogn</italic>. <italic>Neurosci</italic>.</source>, vol. <volume>29</volume>, no. <issue>6</issue>, pp. <fpage>1103</fpage>–<lpage>1118</lpage>, <year>2017</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn_a_01117" xlink:type="simple">10.1162/jocn_a_01117</ext-link></comment> <object-id pub-id-type="pmid">28253078</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Springer</surname> <given-names>M.</given-names></name> and <name name-style="western"><surname>Paulsson</surname> <given-names>J.</given-names></name>, “<article-title>Harmonies from noise</article-title>,” <source><italic>Nature</italic></source>, vol. <volume>439</volume>, no. <month>January</month>, pp. <fpage>27</fpage>–<lpage>29</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhou</surname> <given-names>T.</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>L.</given-names></name>, and <name name-style="western"><surname>Aihara</surname> <given-names>K.</given-names></name>, “<article-title>Molecular Communication through Stochastic Synchronization Induced by Extracellular Fluctuations</article-title>,” <source><italic>Phys</italic>. <italic>Rev</italic>. <italic>Lett</italic>.</source>, vol. <volume>178103</volume>, no. October, pp. <fpage>2</fpage>–<lpage>5</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>Z.</given-names></name> and <name name-style="western"><surname>Hopfield</surname> <given-names>J. J.</given-names></name>, “<article-title>Modeling the olfactory bulb and its neural oscillatory processings</article-title>,” <source><italic>Biol</italic>. <italic>Cybern</italic>.</source>, vol. <volume>61</volume>, pp. <fpage>379</fpage>–<lpage>392</lpage>, <year>1989</year>. <object-id pub-id-type="pmid">2551392</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Womelsdorf</surname> <given-names>T.</given-names></name>, <name name-style="western"><surname>Johnston</surname> <given-names>K.</given-names></name>, <name name-style="western"><surname>Vinck</surname> <given-names>M.</given-names></name>, and <name name-style="western"><surname>Everling</surname> <given-names>S.</given-names></name>, “<article-title>Theta-activity in anterior cingulate cortex predicts task rules and their adjustments following errors</article-title>,” <source><italic>Proc</italic>. <italic>Natl</italic>. <italic>Acad</italic>. <italic>Sci</italic>.</source>, vol. <volume>107</volume>, no. <issue>11</issue>, pp. <fpage>5248</fpage>–<lpage>5253</lpage>, <year>2010</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0906194107" xlink:type="simple">10.1073/pnas.0906194107</ext-link></comment> <object-id pub-id-type="pmid">20194767</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cavanagh</surname> <given-names>J. F.</given-names></name> and <name name-style="western"><surname>Frank</surname> <given-names>M. J.</given-names></name>, “<article-title>Frontal theta as a mechanism for cognitive control</article-title>,” <source><italic>Trends Cogn</italic>. <italic>Sci</italic>.</source>, vol. <volume>18</volume>, no. <issue>8</issue>, pp. <fpage>414</fpage>–<lpage>421</lpage>, <year>2014</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2014.04.012" xlink:type="simple">10.1016/j.tics.2014.04.012</ext-link></comment> <object-id pub-id-type="pmid">24835663</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref036"><label>36</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Holroyd</surname> <given-names>C. B.</given-names></name>, “<chapter-title>The waste disposal problem of effortful control</chapter-title>,” in <source><italic>Motivation and cognitive control</italic></source>, <name name-style="western"><surname>Braver</surname> <given-names>T. S.</given-names></name>, Ed. <publisher-loc>Hove, UK</publisher-loc>: <publisher-name>Psychology Press</publisher-name>, <year>2016</year>, pp. <fpage>235</fpage>–<lpage>260</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cavanagh</surname> <given-names>J. F.</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>M. J.</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>T. J.</given-names></name>, and <name name-style="western"><surname>Allen</surname> <given-names>J. J. B.</given-names></name>, “<article-title>Frontal theta links prediction errors to behavioral adaptation in reinforcement learning</article-title>,” <source><italic>Neuroimage</italic></source>, vol. <volume>49</volume>, no. <issue>4</issue>, pp. <fpage>3198</fpage>–<lpage>3209</lpage>, <year>2010</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2009.11.080" xlink:type="simple">10.1016/j.neuroimage.2009.11.080</ext-link></comment> <object-id pub-id-type="pmid">19969093</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bellebaum</surname> <given-names>C.</given-names></name> and <name name-style="western"><surname>Daum</surname> <given-names>I.</given-names></name>, “<article-title>Learning-related changes in reward expectancy are reflected in the feedback-related negativity</article-title>,” <source><italic>Eur</italic>. <italic>J</italic>. <italic>Neurosci</italic>.</source>, vol. <volume>27</volume>, no. <issue>7</issue>, pp. <fpage>1823</fpage>–<lpage>1835</lpage>, <year>2008</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1460-9568.2008.06138.x" xlink:type="simple">10.1111/j.1460-9568.2008.06138.x</ext-link></comment> <object-id pub-id-type="pmid">18380674</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>M. X.</given-names></name>, <name name-style="western"><surname>Elger</surname> <given-names>C. E.</given-names></name>, and <name name-style="western"><surname>Ranganath</surname> <given-names>C.</given-names></name>, “<article-title>Reward expectation modulates feedback-related negativity and EEG spectra</article-title>,” <source><italic>Neuroimage</italic></source>, vol. <volume>35</volume>, no. <issue>2</issue>, pp. <fpage>968</fpage>–<lpage>978</lpage>, <year>2007</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2006.11.056" xlink:type="simple">10.1016/j.neuroimage.2006.11.056</ext-link></comment> <object-id pub-id-type="pmid">17257860</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Voloh</surname> <given-names>B.</given-names></name>, <name name-style="western"><surname>Valiante</surname> <given-names>T. A.</given-names></name>, <name name-style="western"><surname>Everling</surname> <given-names>S.</given-names></name>, and <name name-style="western"><surname>Womelsdorf</surname> <given-names>T.</given-names></name>, “<article-title>Theta-gamma coordination between anterior cingulate and prefrontal cortex indexes correct attention shifts.</article-title>,” <source><italic>Proc</italic>. <italic>Natl</italic>. <italic>Acad</italic>. <italic>Sci</italic>.</source>, vol. <volume>112</volume>, no. <issue>27</issue>, pp. <fpage>8457</fpage>–<lpage>62</lpage>, <year>2015</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1500438112" xlink:type="simple">10.1073/pnas.1500438112</ext-link></comment> <object-id pub-id-type="pmid">26100868</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Silvetti</surname> <given-names>M.</given-names></name>, <name name-style="western"><surname>Seurinck</surname> <given-names>R.</given-names></name>, and <name name-style="western"><surname>Verguts</surname> <given-names>T.</given-names></name>, “<article-title>Value and prediction error estimation account for volatility effects in ACC: A model-based fMRI study</article-title>,” <source><italic>Cortex</italic></source>, vol. <volume>49</volume>, no. <issue>6</issue>, pp. <fpage>1627</fpage>–<lpage>1635</lpage>, <year>2013</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cortex.2012.05.008" xlink:type="simple">10.1016/j.cortex.2012.05.008</ext-link></comment> <object-id pub-id-type="pmid">22717205</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holroyd</surname> <given-names>C. B.</given-names></name> and <name name-style="western"><surname>Coles</surname> <given-names>M. G. H.</given-names></name>, “<article-title>The neural basis of human error processing: Reinforcement learning, dopamine, and the error-related negativity</article-title>,” <source><italic>Psychol</italic>. <italic>Rev</italic>.</source>, vol. <volume>109</volume>, no. <issue>4</issue>, pp. <fpage>679</fpage>–<lpage>709</lpage>, <year>2002</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.109.4.679" xlink:type="simple">10.1037/0033-295X.109.4.679</ext-link></comment> <object-id pub-id-type="pmid">12374324</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alexander</surname> <given-names>W.</given-names></name> and <name name-style="western"><surname>Brown</surname> <given-names>J. W.</given-names></name>, “<article-title>Hierarchical error representation: A computational model of anterior cingulate and dorsolateral prefrontal cortex</article-title>,” <source><italic>Neural Comput</italic>.</source>, vol. <volume>27</volume>, pp. <fpage>2354</fpage>–<lpage>2410</lpage>, <year>2015</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/NECO_a_00779" xlink:type="simple">10.1162/NECO_a_00779</ext-link></comment> <object-id pub-id-type="pmid">26378874</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holroyd</surname> <given-names>C. B.</given-names></name> and <name name-style="western"><surname>McClure</surname> <given-names>S. M.</given-names></name>, “<article-title>Hierarchical control over effortful behavior by rodent medial frontal cortex: A computational model</article-title>,” <source><italic>Psychol</italic>. <italic>Rev</italic>.</source>, vol. <volume>122</volume>, no. <issue>1</issue>, pp. <fpage>54</fpage>–<lpage>83</lpage>, <year>2015</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0038339" xlink:type="simple">10.1037/a0038339</ext-link></comment> <object-id pub-id-type="pmid">25437491</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Verguts</surname> <given-names>T.</given-names></name>, <name name-style="western"><surname>Vassena</surname> <given-names>E.</given-names></name>, and <name name-style="western"><surname>Silvetti</surname> <given-names>M.</given-names></name>, “<article-title>Adaptive effort investment in cognitive and physical tasks: a neurocomputational model</article-title>,” <source><italic>Front</italic>. <italic>Behav</italic>. <italic>Neurosci</italic>.</source>, vol. <volume>9</volume>, no. <month>March</month>, pp. <fpage>1</fpage>–<lpage>17</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Silvetti</surname> <given-names>M.</given-names></name>, <name name-style="western"><surname>Vassena</surname> <given-names>E.</given-names></name>, <name name-style="western"><surname>Abrahamse</surname> <given-names>E.</given-names></name>, and <name name-style="western"><surname>Verguts</surname> <given-names>T.</given-names></name>, “<article-title>Dorsal anterior cingulate-brainstem ensemble as a reinforcement meta-learner</article-title>,” <source><italic>PLoS Comput</italic>. <italic>Biol</italic>.</source>, vol. <volume>14</volume>, no. <issue>8</issue>, pp. <fpage>1</fpage>–<lpage>32</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>J. X.</given-names></name> <etal>et al.</etal>, “<article-title>Prefrontal cortex as a meta-reinforcement learning system</article-title>,” <source><italic>Nat</italic>. <italic>Neurosci</italic>.</source>, vol. <volume>21</volume>, no. <month>June</month>, <year>2018</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Silvetti</surname> <given-names>M.</given-names></name>, <name name-style="western"><surname>Alexander</surname> <given-names>W.</given-names></name>, <name name-style="western"><surname>Verguts</surname> <given-names>T.</given-names></name>, and <name name-style="western"><surname>Brown</surname> <given-names>J. W.</given-names></name>, “<article-title>From conflict management to reward-based decision making: Actors and critics in primate medial frontal cortex</article-title>,” <source><italic>Neurosci</italic>. <italic>Biobehav</italic>. <italic>Rev</italic>.</source>, vol. <volume>46</volume>, no. <issue>P1</issue>, pp. <fpage>44</fpage>–<lpage>57</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boorman</surname> <given-names>E. D.</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>T. E. J.</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>M. W.</given-names></name>, and <name name-style="western"><surname>Rushworth</surname> <given-names>M. F. S.</given-names></name>, “<article-title>How Green Is the Grass on the Other Side? Frontopolar Cortex and the Evidence in Favor of Alternative Courses of Action</article-title>,” <source><italic>Neuron</italic></source>, vol. <volume>62</volume>, no. <issue>5</issue>, pp. <fpage>733</fpage>–<lpage>743</lpage>, <year>2009</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2009.05.014" xlink:type="simple">10.1016/j.neuron.2009.05.014</ext-link></comment> <object-id pub-id-type="pmid">19524531</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Braver</surname> <given-names>T. S.</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>J. D.</given-names></name>, <name name-style="western"><surname>Nystrom</surname> <given-names>L. E.</given-names></name>, <name name-style="western"><surname>Jonides</surname> <given-names>J.</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>E. E.</given-names></name>, and <name name-style="western"><surname>Noll</surname> <given-names>D. C.</given-names></name>, “<article-title>A parametric study of prefrontal cortex involvement in human working memory.</article-title>,” <source><italic>Neuroimage</italic></source>, vol. <volume>5</volume>, no. <issue>1</issue>, pp. <fpage>49</fpage>–<lpage>62</lpage>, <year>1997</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/nimg.1996.0247" xlink:type="simple">10.1006/nimg.1996.0247</ext-link></comment> <object-id pub-id-type="pmid">9038284</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mac Donald</surname> <given-names>A. W.</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>J. D.</given-names></name>, <name name-style="western"><surname>Stenger</surname> <given-names>A. V.</given-names></name>, and <name name-style="western"><surname>Carter</surname> <given-names>C. S.</given-names></name>, “<article-title>Dissociating the Role of the Dorsolateral Prefrontal and Anterior Cingulate Cortex in Cognitive Control</article-title>,” <source><italic>Science</italic></source> <italic>(80-</italic>. <italic>)</italic>., vol. <volume>288</volume>, no. <month>June</month>, pp. <fpage>1835</fpage>–<lpage>1838</lpage>, <year>2000</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aston-Jones</surname> <given-names>G.</given-names></name> and <name name-style="western"><surname>Cohen</surname> <given-names>J. D.</given-names></name>, “<article-title>An Integrative Theory of Locus Coeruleus-Norepinephrine function: Adaptive Gain and Optimal Performance</article-title>,” <source><italic>Annu</italic>. <italic>Rev</italic>. <italic>Neurosci</italic>.</source>, vol. <volume>28</volume>, no. <issue>1</issue>, pp. <fpage>403</fpage>–<lpage>450</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>E. K.</given-names></name> and <name name-style="western"><surname>Cohen</surname> <given-names>J. D.</given-names></name>, “<article-title>An Integrative Theory of Prefrontal Cortex Function</article-title>,” <source><italic>Annu</italic>. <italic>Rev</italic>. <italic>Neurosci</italic>.</source>, vol. <volume>24</volume>, pp. <fpage>167</fpage>–<lpage>202</lpage>, <year>2001</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.neuro.24.1.167" xlink:type="simple">10.1146/annurev.neuro.24.1.167</ext-link></comment> <object-id pub-id-type="pmid">11283309</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kondo</surname> <given-names>H.</given-names></name>, <name name-style="western"><surname>Osaka</surname> <given-names>N.</given-names></name>, and <name name-style="western"><surname>Osaka</surname> <given-names>M.</given-names></name>, “<article-title>Cooperation of the anterior cingulate cortex and dorsolateral prefrontal cortex for attention shifting</article-title>,” <source><italic>Neuroimage</italic></source>, vol. <volume>23</volume>, no. <issue>2</issue>, pp. <fpage>670</fpage>–<lpage>679</lpage>, <year>2004</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2004.06.014" xlink:type="simple">10.1016/j.neuroimage.2004.06.014</ext-link></comment> <object-id pub-id-type="pmid">15488417</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rodriguez</surname> <given-names>E.</given-names></name>, <name name-style="western"><surname>George</surname> <given-names>N.</given-names></name>, <name name-style="western"><surname>Lachaux</surname> <given-names>J.-P.</given-names></name>, <name name-style="western"><surname>Martinerie</surname> <given-names>J.</given-names></name>, <name name-style="western"><surname>Renault</surname> <given-names>B.</given-names></name>, and <name name-style="western"><surname>Varela</surname> <given-names>F. J.</given-names></name>, “<article-title>Perception ‘ s shadow: long- distance synchronization of human brain activity</article-title>,” <source><italic>Nature</italic></source>, vol. <volume>397</volume>, no. <month>February</month>, pp. <fpage>430</fpage>–<lpage>433</lpage>, <year>1999</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hammond</surname> <given-names>C.</given-names></name>, <name name-style="western"><surname>Bergman</surname> <given-names>H.</given-names></name>, and <name name-style="western"><surname>Brown</surname> <given-names>P.</given-names></name>, “<article-title>Pathological synchronization in Parkinson’s disease: networks, models and treatments</article-title>,” <source><italic>Trends Neurosci</italic>.</source>, vol. <volume>30</volume>, no. <issue>7</issue>, pp. <fpage>357</fpage>–<lpage>364</lpage>, <year>2007</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2007.05.004" xlink:type="simple">10.1016/j.tins.2007.05.004</ext-link></comment> <object-id pub-id-type="pmid">17532060</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Canolty</surname> <given-names>R. T.</given-names></name> <etal>et al.</etal>, “<article-title>High Gamma Power is Phase-Locked to Theta Oscillations in Human Neocortex</article-title>,” <source><italic>Science</italic></source>, vol. <volume>313</volume>, no. <issue>5793</issue>, pp. <fpage>1626</fpage>–<lpage>1628</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jensen</surname> <given-names>O.</given-names></name> and <name name-style="western"><surname>Colgin</surname> <given-names>L. L.</given-names></name>, “<article-title>Cross-frequency coupling between neuronal oscillations</article-title>,” <source><italic>Trends Cogn</italic>. <italic>Sci</italic>.</source>, vol. <volume>11</volume>, no. <issue>7</issue>, pp. <fpage>267</fpage>–<lpage>269</lpage>, <year>2007</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2007.05.003" xlink:type="simple">10.1016/j.tics.2007.05.003</ext-link></comment> <object-id pub-id-type="pmid">17548233</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lisman</surname> <given-names>J. E.</given-names></name> and <name name-style="western"><surname>Jensen</surname> <given-names>O.</given-names></name>, “<article-title>The Theta-Gamma Neural Code</article-title>,” <source><italic>Neuron</italic></source>, vol. <volume>77</volume>, no. <issue>6</issue>, pp. <fpage>1002</fpage>–<lpage>1016</lpage>, <year>2013</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.03.007" xlink:type="simple">10.1016/j.neuron.2013.03.007</ext-link></comment> <object-id pub-id-type="pmid">23522038</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Franklin</surname> <given-names>N. T.</given-names></name> and <name name-style="western"><surname>Frank</surname> <given-names>M. J.</given-names></name>, “<article-title>Compositional clustering in task structure learning</article-title>,” <source><italic>PLoS Comput</italic>. <italic>Biol</italic>.</source>, vol. <volume>14</volume>, no. <issue>4</issue>, pp. <fpage>1</fpage>–<lpage>25</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Collins</surname> <given-names>A.</given-names></name> and <name name-style="western"><surname>Frank</surname> <given-names>M. J.</given-names></name>, “<article-title>Within and across-trial dynamics of human EEG reveal cooperative interplay between reinforcement learning and working memory</article-title>,” <source><italic>Proc</italic>. <italic>Natl</italic>. <italic>Acad</italic>. <italic>Sci</italic>.</source>, p. <fpage>184812</fpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Collins</surname> <given-names>A. G. E.</given-names></name>, <name name-style="western"><surname>Cavanagh</surname> <given-names>J. F.</given-names></name>, and <name name-style="western"><surname>Frank</surname> <given-names>M. J.</given-names></name>, “<article-title>Human EEG Uncovers Latent Generalizable Rule Structure during Learning</article-title>,” <source><italic>J</italic>. <italic>Neurosci</italic>.</source>, vol. <volume>34</volume>, no. <issue>13</issue>, pp. <fpage>4677</fpage>–<lpage>4685</lpage>, <year>2014</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3900-13.2014" xlink:type="simple">10.1523/JNEUROSCI.3900-13.2014</ext-link></comment> <object-id pub-id-type="pmid">24672013</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yu</surname> <given-names>A. J.</given-names></name> and <name name-style="western"><surname>Dayan</surname> <given-names>P.</given-names></name>, “<article-title>Uncertainty, neuromodulation, and attention.</article-title>,” <source><italic>Neuron</italic></source>, vol. <volume>46</volume>, no. <issue>4</issue>, pp. <fpage>681</fpage>–<lpage>92</lpage>, <month>May</month> <year>2005</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2005.04.026" xlink:type="simple">10.1016/j.neuron.2005.04.026</ext-link></comment> <object-id pub-id-type="pmid">15944135</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bastos</surname> <given-names>A. M.</given-names></name>, <name name-style="western"><surname>Usrey</surname> <given-names>W. M.</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>R. A.</given-names></name>, <name name-style="western"><surname>Mangun</surname> <given-names>G. R.</given-names></name>, <name name-style="western"><surname>Fries</surname> <given-names>P.</given-names></name>, and <name name-style="western"><surname>Friston</surname> <given-names>K. J.</given-names></name>, “<article-title>Canonical Microcircuits for Predictive Coding</article-title>,” <source><italic>Neuron</italic></source>, vol. <volume>76</volume>, no. <issue>4</issue>, pp. <fpage>695</fpage>–<lpage>711</lpage>, <year>2012</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2012.10.038" xlink:type="simple">10.1016/j.neuron.2012.10.038</ext-link></comment> <object-id pub-id-type="pmid">23177956</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Giraud</surname> <given-names>A.</given-names></name> and <name name-style="western"><surname>Poeppel</surname> <given-names>D.</given-names></name>, “<article-title>Cortical oscillations and speech processing: emerging computational principles and operations</article-title>,” <source><italic>Nat</italic>. <italic>Neurosci</italic>.</source>, vol. <volume>15</volume>, no. <issue>4</issue>, pp. <fpage>511</fpage>–<lpage>517</lpage>, <year>2012</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3063" xlink:type="simple">10.1038/nn.3063</ext-link></comment> <object-id pub-id-type="pmid">22426255</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bastos</surname> <given-names>A. M.</given-names></name>, <name name-style="western"><surname>Vezoli</surname> <given-names>J.</given-names></name>, and <name name-style="western"><surname>Fries</surname> <given-names>P.</given-names></name>, “<article-title>Communication through coherence with inter-areal delays</article-title>,” <source><italic>Curr</italic>. <italic>Opin</italic>. <italic>Neurobiol</italic>.</source>, vol. <volume>31</volume>, no. <issue>31</issue>, pp. <fpage>173</fpage>–<lpage>180</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>J. D.</given-names></name>, <name name-style="western"><surname>Dunbar</surname> <given-names>K.</given-names></name>, and <name name-style="western"><surname>McClelland</surname> <given-names>J. L.</given-names></name>, “<article-title>On the control of automatic processes: a parallel distributed processing account of the Stroop effect.</article-title>,” <source><italic>Psychol</italic>. <italic>Rev</italic>.</source>, vol. <volume>97</volume>, no. <issue>3</issue>, pp. <fpage>332</fpage>–<lpage>61</lpage>, <year>1990</year>. <object-id pub-id-type="pmid">2200075</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shenhav</surname> <given-names>A.</given-names></name>, <name name-style="western"><surname>Botvinick</surname> <given-names>M. M.</given-names></name>, and <name name-style="western"><surname>Cohen</surname> <given-names>J. D.</given-names></name>, “<article-title>The expected value of control: An integrative theory of anterior cingulate cortex function</article-title>,” <source><italic>Neuron</italic></source>, vol. <volume>79</volume>, no. <issue>2</issue>, pp. <fpage>217</fpage>–<lpage>240</lpage>, <year>2013</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.07.007" xlink:type="simple">10.1016/j.neuron.2013.07.007</ext-link></comment> <object-id pub-id-type="pmid">23889930</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Desender</surname> <given-names>K.</given-names></name>, <name name-style="western"><surname>Boldt</surname> <given-names>A.</given-names></name>, and <name name-style="western"><surname>Yeung</surname> <given-names>N.</given-names></name>, “<article-title>Subjective Confidence Predicts Information Seeking in Decision Making</article-title>,” <source><italic>Psychol</italic>. <italic>Sci</italic>.</source>, pp. <fpage>1</fpage>–<lpage>18</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yeung</surname> <given-names>N.</given-names></name> and <name name-style="western"><surname>Summerfield</surname> <given-names>C.</given-names></name>, “<article-title>Metacognition in human decision-making: confidence and error monitoring</article-title>,” <source><italic>Philos</italic>. <italic>Trans</italic>. <italic>R</italic>. <italic>Soc</italic>.</source>, no. <issue>367</issue>, pp. <fpage>1310</fpage>–<lpage>1321</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="pcbi.1006604.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Izquierdo</surname> <given-names>A.</given-names></name> and <name name-style="western"><surname>Jentsch</surname> <given-names>J. D.</given-names></name>, “<article-title>Reversal learning as a measure of impulsive and compulsive behavior in addictions</article-title>,” <source><italic>Psychopharmacology</italic></source> <italic>(Berl)</italic>., vol. <volume>219</volume>, no. <issue>2</issue>, pp. <fpage>607</fpage>–<lpage>620</lpage>, <year>2012</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00213-011-2579-7" xlink:type="simple">10.1007/s00213-011-2579-7</ext-link></comment> <object-id pub-id-type="pmid">22134477</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Clark</surname> <given-names>L.</given-names></name>, <name name-style="western"><surname>Cools</surname> <given-names>R.</given-names></name>, and <name name-style="western"><surname>Robbins</surname> <given-names>T. W.</given-names></name>, “<article-title>The neuropsychology of ventral prefrontal cortex: Decision-making and reversal learning</article-title>,” <source><italic>Brain Cogn</italic>.</source>, vol. <volume>55</volume>, no. <issue>1</issue>, pp. <fpage>41</fpage>–<lpage>53</lpage>, <year>2004</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0278-2626(03)00284-7" xlink:type="simple">10.1016/S0278-2626(03)00284-7</ext-link></comment> <object-id pub-id-type="pmid">15134842</object-id></mixed-citation></ref>
<ref id="pcbi.1006604.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Driel</surname> <given-names>J.</given-names></name>, <name name-style="western"><surname>Cox</surname> <given-names>R.</given-names></name>, and <name name-style="western"><surname>Cohen</surname> <given-names>M. X.</given-names></name>, “<article-title>Phase-clustering bias in phase-amplitude cross-frequency coupling and its removal</article-title>,” <source><italic>J</italic>. <italic>Neurosci</italic>. <italic>Methods</italic></source>, vol. <volume>254</volume>, pp. <fpage>60</fpage>–<lpage>72</lpage>, <year>2015</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jneumeth.2015.07.014" xlink:type="simple">10.1016/j.jneumeth.2015.07.014</ext-link></comment> <object-id pub-id-type="pmid">26231622</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
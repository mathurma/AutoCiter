<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="other" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.1002195</article-id>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-15-00301</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Perspective</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Big Data: Astronomical or Genomical?</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Stephens</surname>
<given-names>Zachary D.</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Lee</surname>
<given-names>Skylar Y.</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Faghri</surname>
<given-names>Faraz</given-names>
</name>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Campbell</surname>
<given-names>Roy H.</given-names>
</name>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Zhai</surname>
<given-names>Chengxiang</given-names>
</name>
<xref rid="aff003" ref-type="aff"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Efron</surname>
<given-names>Miles J.</given-names>
</name>
<xref rid="aff004" ref-type="aff"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Iyer</surname>
<given-names>Ravishankar</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Schatz</surname>
<given-names>Michael C.</given-names>
</name>
<xref rid="aff005" ref-type="aff"><sup>5</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Sinha</surname>
<given-names>Saurabh</given-names>
</name>
<xref rid="aff003" ref-type="aff"><sup>3</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Robinson</surname>
<given-names>Gene E.</given-names>
</name>
<xref rid="aff006" ref-type="aff"><sup>6</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Coordinated Science Laboratory and Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, Illinois, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, United States of America</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Carl R. Woese Institute for Genomic Biology &amp; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, United States of America</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>School of Library and Information Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, United States of America</addr-line></aff>
<aff id="aff005"><label>5</label> <addr-line>Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory, Cold Spring Harbor, New York, United States of America</addr-line></aff>
<aff id="aff006"><label>6</label> <addr-line>Carl R. Woese Institute for Genomic Biology, Department of Entomology, and Neuroscience Program, University of Illinois at Urbana-Champaign, Urbana, Illinois, United States of America</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">mschatz@cshl.edu</email> (MCS); <email xlink:type="simple">sinhas@illinois.edu</email> (SS); <email xlink:type="simple">generobi@illinois.edu</email> (GER)</corresp>
</author-notes>
<pub-date pub-type="epub">
<day>7</day>
<month>7</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="collection">
<month>7</month>
<year>2015</year>
</pub-date>
<volume>13</volume>
<issue>7</issue>
<elocation-id>e1002195</elocation-id>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Stephens et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.1002195" xlink:type="simple"/>
<abstract>
<p>Genomics is a Big Data science and is going to get much bigger, very soon, but it is not known whether the needs of genomics will exceed other Big Data domains. Projecting to the year 2025, we compared genomics with three other major generators of Big Data: astronomy, YouTube, and Twitter. Our estimates show that genomics is a “four-headed beast”—it is either on par with or the most demanding of the domains analyzed here in terms of data acquisition, storage, distribution, and analysis. We discuss aspects of new technologies that will need to be developed to rise up and meet the computational challenges that genomics poses for the near future. Now is the time for concerted, community-wide planning for the “genomical” challenges of the next decade.</p>
</abstract>
<abstract abstract-type="toc">
<p>This perspective considers the growth of genomics over the next ten years and assesses the computational needs that we will face relative to other "Big Data" activities such as astronomy, YouTube, and Twitter.</p>
</abstract>
<funding-group>
<funding-statement>This research was supported, in part, by grant 1U54GM114838 awarded by NIGMS to SS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative and by National Institutes of Health award (R01-HG006677) to MCS. ZDS and RKI were supported by NSF grant MRI13-37732 (S.S. Lumetta, PI). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="1"/>
<table-count count="1"/>
<page-count count="11"/>
</counts>
</article-meta>
</front>
<body>
<p>We compared genomics with three other major generators of Big Data: astronomy, YouTube, and Twitter. Astronomy has faced the challenges of Big Data for over 20 years and continues with ever-more ambitious studies of the universe. YouTube burst on the scene in 2005 and has sparked extraordinary worldwide interest in creating and sharing huge numbers of videos. Twitter, created in 2006, has become the poster child of the burgeoning movement in computational social science [<xref rid="pbio.1002195.ref006" ref-type="bibr">6</xref>], with unprecedented opportunities for new insights by mining the enormous and ever-growing amount of textual data [<xref rid="pbio.1002195.ref007" ref-type="bibr">7</xref>]. Particle physics also produces massive quantities of raw data, although the footprint is surprisingly limited since the vast majority of data are discarded soon after acquisition using the processing power that is coupled to the sensors [<xref rid="pbio.1002195.ref008" ref-type="bibr">8</xref>]. Consequently, we do not include the domain in full detail here, although that model of rapid filtering and analysis will surely play an increasingly important role in genomics as the field matures.</p>
<p>To compare these four disparate domains, we considered the four components that comprise the “life cycle” of a dataset: acquisition, storage, distribution, and analysis (<xref rid="pbio.1002195.t001" ref-type="table">Table 1</xref>).</p>
<table-wrap id="pbio.1002195.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002195.t001</object-id>
<label>Table 1</label> <caption><title>Four domains of Big Data in 2025.</title> <p>In each of the four domains, the projected annual storage and computing needs are presented across the data lifecycle.</p></caption>
<alternatives>
<graphic id="pbio.1002195.t001g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002195.t001" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"><underline>Data Phase</underline></th>
<th align="left" rowspan="1" colspan="1"><underline>Astronomy</underline></th>
<th align="left" rowspan="1" colspan="1"><underline>Twitter</underline></th>
<th align="left" rowspan="1" colspan="1"><underline>YouTube</underline></th>
<th align="left" rowspan="1" colspan="1"><underline>Genomics</underline></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Acquisition</bold></td>
<td align="left" rowspan="1" colspan="1">25 zetta-bytes/year</td>
<td align="left" rowspan="1" colspan="1">0.5–15 billion tweets/year</td>
<td align="left" rowspan="1" colspan="1">500–900 million hours/year</td>
<td align="left" rowspan="1" colspan="1">1 zetta-bases/year</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Storage</bold></td>
<td align="left" rowspan="1" colspan="1">1 EB/year</td>
<td align="left" rowspan="1" colspan="1">1–17 PB/year</td>
<td align="left" rowspan="1" colspan="1">1–2 EB/year</td>
<td align="left" rowspan="1" colspan="1">2–40 EB/year</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Analysis</bold></td>
<td align="left" rowspan="1" colspan="1">In situ data reduction</td>
<td align="left" rowspan="1" colspan="1">Topic and sentiment mining</td>
<td align="left" rowspan="1" colspan="1">Limited requirements</td>
<td align="left" rowspan="1" colspan="1">Heterogeneous data and analysis</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Real-time processing</td>
<td align="left" rowspan="1" colspan="1">Metadata analysis</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Variant calling, ~2 trillion central processing unit (CPU) hours</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Massive volumes</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">All-pairs genome alignments, ~10,000 trillion CPU hours</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Distribution</bold></td>
<td align="left" rowspan="1" colspan="1">Dedicated lines from antennae to server (600 TB/s)</td>
<td align="left" rowspan="1" colspan="1">Small units of distribution</td>
<td align="left" rowspan="1" colspan="1">Major component of modern user’s bandwidth (10 MB/s)</td>
<td align="left" rowspan="1" colspan="1">Many small (10 MB/s) and fewer massive (10 TB/s) data movement</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<sec id="sec001">
<title>Data Acquisition</title>
<p>The four Big Data domains differ sharply in how data are acquired. Most astronomy data are acquired from a few highly centralized facilities [<xref rid="pbio.1002195.ref009" ref-type="bibr">9</xref>]. By contrast, YouTube and Twitter acquire data in a highly distributed manner, but under a few standardized protocols. Astronomy, YouTube, and Twitter are expected to show continued dramatic growth in the volume of data to be acquired. For example, the Australian Square Kilometre Array Pathfinder (ASKAP) project currently acquires 7.5 terabytes/second of sample image data, a rate projected to increase 100-fold to 750 terabytes/second (~25 zettabytes per year) by 2025 [<xref rid="pbio.1002195.ref009" ref-type="bibr">9</xref>,<xref rid="pbio.1002195.ref010" ref-type="bibr">10</xref>]. YouTube currently has 300 hours of video being uploaded every minute, and this could grow to 1,000–1,700 hours per minute (1–2 exabytes of video data per year) by 2025 if we extrapolate from current trends (<xref rid="pbio.1002195.s002" ref-type="supplementary-material">S1 Note</xref>). Today, Twitter generates 500 million tweets/day, each about 3 kilobytes including metadata (<xref rid="pbio.1002195.s003" ref-type="supplementary-material">S2 Note</xref>). While this figure is beginning to plateau, a projected logarithmic growth rate would suggest a 2.4-fold growth by 2025, to 1.2 billion tweets per day, 1.36 petabytes/year. In short, data acquisition in these domains is expected to grow by up to two orders of magnitude in the next decade.</p>
<p>For genomics, data acquisition is highly distributed and involves heterogeneous formats. The rate of growth over the last decade has also been truly astonishing, with the total amount of sequence data produced doubling approximately every seven months (<xref rid="pbio.1002195.g001" ref-type="fig">Fig 1</xref>). The OmicsMaps catalog of all known sequencing instruments in the world [<xref rid="pbio.1002195.ref011" ref-type="bibr">11</xref>] reports that currently there are more than 2,500 high-throughput instruments, manufactured by several different companies, located in nearly 1,000 sequencing centers in 55 countries in universities, hospitals, and other research laboratories. These centers range in size from small laboratories with a few instruments generating a few terabases per year to large dedicated facilities producing several petabases a year. (An approximate conversion factor to use in interpreting these numbers is 4 bases = 1 byte, though we will revisit this below.)</p>
<fig id="pbio.1002195.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002195.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Growth of DNA sequencing.</title>
<p>The plot shows the growth of DNA sequencing both in the total number of human genomes sequenced (left axis) as well as the worldwide annual sequencing capacity (right axis: Tera-basepairs (Tbp), Peta-basepairs (Pbp), Exa-basepairs (Ebp), Zetta-basepairs (Zbps)). The values through 2015 are based on the historical publication record, with selected milestones in sequencing (first Sanger through first PacBio human genome published) as well as three exemplar projects using large-scale sequencing: the 1000 Genomes Project, aggregating hundreds of human genomes by 2012 [<xref rid="pbio.1002195.ref003" ref-type="bibr">3</xref>]; The Cancer Genome Atlas (TCGA), aggregating over several thousand tumor/normal genome pairs [<xref rid="pbio.1002195.ref004" ref-type="bibr">4</xref>]; and the Exome Aggregation Consortium (ExAC), aggregating over 60,000 human exomes [<xref rid="pbio.1002195.ref005" ref-type="bibr">5</xref>]. Many of the genomes sequenced to date have been whole exome rather than whole genome, but we expect the ratio to be increasingly favored towards whole genome in the future. The values beyond 2015 represent our projection under three possible growth curves as described in the main text.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002195.g001" position="float" xlink:type="simple"/>
</fig>
<p>The raw sequencing reads used in most published studies are archived at either the Sequence Read Archive (SRA) maintained by the United States National Institutes of Health National Center for Biotechnology Information (NIH/NCBI) or one of the international counterparts. The SRA currently contains more than 3.6 petabases of raw sequence data (<xref rid="pbio.1002195.s001" ref-type="supplementary-material">S1 Fig</xref>), which reflects the ~32,000 microbial genomes, ~5,000 plant and animal genomes, and ~250,000 individual human genomes that have been sequenced or are in progress thus far [<xref rid="pbio.1002195.ref012" ref-type="bibr">12</xref>]. However, the 3.6 petabases represent a small fraction of the total produced; most of it is not yet in these archives. Based on manufacturer specifications of the instruments, we estimate the current worldwide sequencing capacity to exceed 35 petabases per year, including the sixteen Illumina X-Ten systems that have been sold so far [<xref rid="pbio.1002195.ref013" ref-type="bibr">13</xref>], each with a capacity of ~2 petabases per year [<xref rid="pbio.1002195.ref014" ref-type="bibr">14</xref>].</p>
<p>Over the next ten years, we expect sequencing capacities will continue to grow very rapidly, although the project growth becomes more unpredictable the further out we consider. If the growth continues at the current rate by doubling every seven months, then we should reach more than one exabase of sequence per year in the next five years and approach one zettabase of sequence per year by 2025 (<xref rid="pbio.1002195.g001" ref-type="fig">Fig 1</xref>, <xref rid="pbio.1002195.t001" ref-type="table">Table 1</xref>). Interestingly, even at the more conservative estimates of doubling every 12 months (Illumina’s current own estimate [<xref rid="pbio.1002195.ref012" ref-type="bibr">12</xref>]) or every 18 months (equivalent to Moore’s law), we should reach exabase-scale genomics well within the next decade. We anticipate this sequencing will encompass genome sequences for most of the approximately 1.2 million described species of plants and animals [<xref rid="pbio.1002195.ref015" ref-type="bibr">15</xref>]. With these genomes, plus those of thousands of individuals of “high value” species for energy, environmental, and agricultural reasons, we estimate that there will be at least 2.5 million plant and animal genome sequences by 2025. For example, the genomics powerhouse BGI, in conjunction with the International Rice Research Institute and the Chinese Academy of Agricultural Sciences, has already sequenced 3,000 varieties of rice [<xref rid="pbio.1002195.ref016" ref-type="bibr">16</xref>] and announced a massive project of their own to sequence one million plant and animal genomes [<xref rid="pbio.1002195.ref017" ref-type="bibr">17</xref>]. The Smithsonian Institute also has similar plans to “capture and catalog all the DNA from the world’s flora and fauna.” There also will be genomes for several millions of microbes, with explosive growth projected for both medical and environmental microbe metagenomic sequencing [<xref rid="pbio.1002195.ref018" ref-type="bibr">18</xref>,<xref rid="pbio.1002195.ref019" ref-type="bibr">19</xref>].</p>
<p>These estimates, however, are dwarfed by the very reasonable possibility that a significant fraction of the world’s human population will have their genomes sequenced. The leading driver of this trend is the promise of genomic medicine to revolutionize the diagnosis and treatment of disease, with some countries contemplating sequencing large portions of their populations: both England [<xref rid="pbio.1002195.ref020" ref-type="bibr">20</xref>] and Saudi Arabia [<xref rid="pbio.1002195.ref021" ref-type="bibr">21</xref>] have announced plans to sequence 100,000 of their citizens, one-third of Iceland’s 320,000 citizens have donated blood for genetic testing [<xref rid="pbio.1002195.ref022" ref-type="bibr">22</xref>], and researchers in both the US [<xref rid="pbio.1002195.ref023" ref-type="bibr">23</xref>] and China [<xref rid="pbio.1002195.ref017" ref-type="bibr">17</xref>] both aim to sequence 1 million genomes in the next few years. With the world’s population projected to top 8 billion by 2025, it is possible that as many as 25% of the population in developed nations and half of that in less-developed nations will have their genomes sequenced (comparable to the current worldwide distribution of Internet users [<xref rid="pbio.1002195.ref024" ref-type="bibr">24</xref>]).</p>
<p>We therefore estimate between 100 million and as many as 2 billion human genomes could be sequenced by 2025, representing four to five orders of magnitude growth in ten years and far exceeding the growth for the three other Big Data domains. Indeed, this number could grow even larger, especially since new single-cell genome sequencing technologies are starting to reveal previously unimagined levels of variation, especially in cancers, necessitating sequencing the genomes of thousands of separate cells in a single tumor [<xref rid="pbio.1002195.ref010" ref-type="bibr">10</xref>].</p>
<p>Moreover, the technology used to sequence DNA is deployed creatively for other applications (e.g., transcriptome, epigenome, proteome, metabolome, and microbiome sequencing) necessitating generating new sequencing data multiple times per person to monitor molecular activity [<xref rid="pbio.1002195.ref025" ref-type="bibr">25</xref>]. These applications require precise quantitative counts of sequencing reads to capture diversity of expression or diversity of abundances, thus requiring millions of reads to accurately estimate underlying distributions as they change over time. For medicine, just having the genome will not be sufficient: for each individual, it will need to be coupled with other relevant ‘omics data sets, some collected periodically and from different tissues, to compare healthy and diseased states [<xref rid="pbio.1002195.ref026" ref-type="bibr">26</xref>]. Computational challenges will increase because of dramatic increases in the total volume of genomic data per person, as will the complexities of integrating these diverse data sources to improve health and cure diseases. Genomics thus appears to pose the greatest challenges for data acquisition of the four Big Data domains.</p>
</sec>
<sec id="sec002">
<title>Data Storage</title>
<p>Data storage requirements for all four domains are projected to be enormous. Today, the largest astronomy data center devotes ~100 petabytes to storage, and the completion of the Square Kilometre Array (SKA) project is expected to lead to a storage demand of 1 exabyte per year. YouTube currently requires from 100 petabytes to 1 exabyte for storage and may be projected to require between 1 and 2 exabytes additional storage per year by 2025. Twitter’s storage needs today are estimated at 0.5 petabytes per year, which may increase to 1.5 petabytes in the next ten years. (Our estimates here ignore the “replication factor” that multiplies storage needs by ~4, for redundancy.) For genomics, we have determined more than 100 petabytes of storage are currently used by only 20 of the largest institutions (<xref rid="pbio.1002195.s006" ref-type="supplementary-material">S1 Table</xref>).</p>
<p>Projections of storage requirements for sequence data depend on the accuracy and application of the sequencing. For every 3 billion bases of human genome sequence, 30-fold more data (~100 gigabases) must be collected because of errors in sequencing, base calling, and genome alignment. This means that as much as 2–40 exabytes of storage capacity will be needed by 2025 just for the human genomes (<xref rid="pbio.1002195.s004" ref-type="supplementary-material">S3 Note</xref>). These needs can be diminished with effective data compression [<xref rid="pbio.1002195.ref027" ref-type="bibr">27</xref>], but decompression times and fidelity are a major concern in compressive genomics [<xref rid="pbio.1002195.ref028" ref-type="bibr">28</xref>].</p>
<p>Are the emerging “third-generation” single-molecule sequencing technologies with much longer reads, such as those from Pacific Biosciences and Oxford Nanopore, a computational panacea? Though error rates currently are higher and throughput lower than short-read technologies, as they mature, these technologies are starting to be used to sequence and assemble nearly entire chromosomes [<xref rid="pbio.1002195.ref029" ref-type="bibr">29</xref>]. This will minimize the need to oversample as much, and eventually, the raw sequence data may not need to be stored at all. However, eliminating the need to store raw sequence data and only retaining complete genomes will have relatively little impact overall—perhaps one or two orders of magnitude less data storage. More significant reductions in storage demand will come when improvements in sequencing accuracy and database comprehensiveness reach the point at which genome sequences themselves do not need to be stored, just the list of variants relative to a reference collection (“delta encoding”) [<xref rid="pbio.1002195.ref030" ref-type="bibr">30</xref>]. This works well for cataloging the simplest variants in a human genome, but it may not be as useful for complex samples, such as cancer genomes, that have many novel rearrangements and mutations. While certainly helpful, we thus do not expect long-read sequencing technology or delta encoding to solve the storage challenges for genome sequencing in 2025.</p>
<p>In contrast, we do see great opportunities for data reduction and real-time analysis of other ‘omics analysis. For example, once sequencing becomes fast enough and the methods mature enough to correctly infer transcript expression levels in real time, we anticipate that raw RNA-seq reads will no longer be stored, except for specific research purposes. Already several such “streaming” algorithms have been published for this purpose, performing as well as or superior to their nonstreaming counterparts [<xref rid="pbio.1002195.ref031" ref-type="bibr">31</xref>]. For RNA-seq and other ‘omics applications, genomics will benefit greatly from the lessons learned in particle physics, in which in most cases raw data are discarded almost as fast as they are generated in favor of higher level and greatly compressed summaries.</p>
<p>Altogether, we anticipate the development of huge genomics archives used for storing millions of genomes along with the associated ‘omics measurements over time. Ideally, these archives will also collect or be linked to the patient phenotypic data, especially disease outcomes and treatments provided to support retrospective analysis as new relationships are discovered. To make it practical to search and query through such vast collections, the data will be stored in hierarchical systems that make data and their statistical summaries available at different levels of compression and latency, as used in astronomy [<xref rid="pbio.1002195.ref032" ref-type="bibr">32</xref>] and text analysis [<xref rid="pbio.1002195.ref033" ref-type="bibr">33</xref>]. Thus, although total genomic data could far exceed the demands for the others, with the right new innovations the net requirements could be similar to the domains of astronomy and YouTube.</p>
</sec>
<sec id="sec003">
<title>Data Distribution</title>
<p>Astronomy, YouTube, Twitter, and genomics also differ greatly in data distribution patterns. The major bandwidth requirement of the SKA project is to get data from its 3,000 antennae to a central server, requiring as much as 600 terabytes/second [<xref rid="pbio.1002195.ref034" ref-type="bibr">34</xref>]. The bandwidth usage of YouTube is relatively small for a single download and well supported by the average consumer’s 10 Mbps connection, but aggregate needs worldwide are enormous, with estimates up to 240 petabytes/day (<xref rid="pbio.1002195.s005" ref-type="supplementary-material">S4 Note</xref>) [<xref rid="pbio.1002195.ref035" ref-type="bibr">35</xref>]. The distribution patterns of genomics data are much more heterogeneous, involving elements of both situations [<xref rid="pbio.1002195.ref036" ref-type="bibr">36</xref>].</p>
<p>Genomic data are distributed in units spanning a wide range of sizes, from comparisons of a few bases or gene sequences to large multiterabyte bulk downloads from central repositories. For large-scale analysis, cloud computing is particularly suited to decreasing the bandwidth for distribution of genomic data [<xref rid="pbio.1002195.ref037" ref-type="bibr">37</xref>] so that applications can run on remote machines that already have data [<xref rid="pbio.1002195.ref038" ref-type="bibr">38</xref>]. Only small segments of code are uploaded and highly processed outputs are downloaded, thus significantly reducing the computing resources necessary for distribution.</p>
<p>But in addition to tailoring genomics applications for the cloud, new methods of data reliability and security are required to ensure privacy, much more so than for the other three domains. A serious breach of medically sensitive genomic data would have permanent consequences and could seriously hinder the development of genomic medicine. Homomorphic encryption systems, in which encrypted data can be analyzed and manipulated for certain controlled queries without disclosing the raw data, are currently too computationally expensive for widespread use, but these and related cryptographic techniques are promising areas of research [<xref rid="pbio.1002195.ref039" ref-type="bibr">39</xref>].</p>
</sec>
<sec id="sec004">
<title>Data Analysis</title>
<p>Astronomy, YouTube, Twitter, and genomics differ most in computational requirements for data analysis. Astronomy data require extensive specialized analysis, but the bulk of this requirement is for in situ processing and reduction of data by computers located near the telescopes [<xref rid="pbio.1002195.ref040" ref-type="bibr">40</xref>]. This initial analysis is daunting because of its real-time nature and huge data volumes but can often be effectively performed in parallel on thousands of cores. YouTube videos are primarily meant to be viewed, along with some automated analysis for advertisements or copyright infringements. Twitter data are the subject of intense research in the social sciences [<xref rid="pbio.1002195.ref041" ref-type="bibr">41</xref>], especially for topic and sentiment mining, which is performed chiefly on textual “tweets” in the context of associated metadata (e.g., user demographics and temporal information).</p>
<p>Analysis of genomic data involves a more diverse range of approaches because of the variety of steps involved in reading a genome sequence and deriving useful information from it. For population and medical genomics, identifying the genomic variants in each individual genome is currently one of the most computationally complex phases. Variant calling on 2 billion genomes per year, with 100,000 CPUs in parallel, would require methods that process 2 genomes per CPU-hour, three-to-four orders of magnitude faster than current capabilities [<xref rid="pbio.1002195.ref042" ref-type="bibr">42</xref>]. Whole genome alignment is another important form of genomic data analysis, used for a variety of goals, from phylogeny reconstruction to genome annotation via comparative methodologies. Just a single whole genome alignment between human and mouse consumes ~100 CPU hours [<xref rid="pbio.1002195.ref043" ref-type="bibr">43</xref>]. Aligning all pairs of the ~2.5 million species expected to be available by 2025 amounts to 50–100 trillion such whole genome alignments, which would need to be six orders of magnitude faster than possible today.</p>
<p>Improvements to CPU capabilities, as anticipated by Moore’s Law, should help close the gap, but trends in computing power are often geared towards floating point operations and do not necessarily provide improvements in genome analysis, in which string operations and memory management often pose the most significant challenges. Moreover, the bigger bottleneck of Big Data analysis in the future may not be in CPU capabilities but in the input/output (I/O) hardware that shuttles data between storage and processors [<xref rid="pbio.1002195.ref044" ref-type="bibr">44</xref>], a problem requiring research into new parallel I/O hardware and algorithms that can effectively utilize them.</p>
</sec>
<sec id="sec005">
<title>The Long Road Ahead</title>
<p>Genomics clearly poses some of the most severe computational challenges facing us in the next decade. Genomics is a “four-headed beast”; considering the computational demands across the lifecycle of a dataset—acquisition, storage, distribution, and analysis—genomics is either on par with or the most demanding of the Big Data domains. New integrative approaches need to be developed that take into account the challenges in all four aspects: it is unlikely that a single advance or technology will solve the genomics data problem. Several key technologies that are most critically needed to support future solutions are discussed in Box <xref rid="sec006" ref-type="sec">1</xref>.</p>
<p>In human health, the major needs are driven by the realization that for precision medicine and similar efforts to be most effective, genomes and related ‘omics data need to be shared and compared in huge numbers. If we do not commit as a scientific community to sharing now, we run the risk of establishing thousands of isolated, private data collections, each too underpowered to allow subtle signals to be extracted. More than anything else, connecting these resources requires trust among institutions, scientists, and the public to ensure the collections will be used for medical purposes and not to discriminate or penalize individuals because of their genetic makeup.</p>
<p>Finally, the exascale data and computing centers that are emerging today to meet Big Data challenges in several domains (YouTube [<xref rid="pbio.1002195.ref050" ref-type="bibr">50</xref>], Google [<xref rid="pbio.1002195.ref051" ref-type="bibr">51</xref>], Facebook [<xref rid="pbio.1002195.ref051" ref-type="bibr">51</xref>], and the National Security Agency [<xref rid="pbio.1002195.ref052" ref-type="bibr">52</xref>]), are the result of far-sighted planning and commitment by the respective organizations. Now is the time for concerted, community-wide planning for the “genomical” challenges of the next decade.</p>
<boxed-text id="pbio.1002195.box001" position="float">
<sec id="sec006">
<title>Box 1. Key Technological Needs for Big Data Genomics</title>
<sec id="sec007">
<title>(1) Acquisition</title>
<p>The most important need to sustain the explosive growth in genomic data acquisition is continued advances in sequencing technologies to reduce costs, improve throughput, and achieve very high accuracy. The current costs of ~US$1,000 per human genome begin to make it practical to sequence human genomes in large numbers, especially for critical medical treatments, but to scale to populations of hundreds of millions to billions of genomes, costs must be reduced by at least another one to two orders of magnitude or more. For many medical applications, the time for sequencing must also be reduced so that it can be completed in near real time, especially to rapidly diagnosis acute infections and conditions. Finally, to make a genome sequence most useful, it must be paired with automated methods to collect metadata and phenotype data, all according to appropriate standards so that data collected in one environment can be compared to those collected in another.</p>
</sec>
<sec id="sec008">
<title>(2) Storage</title>
<p>The community needs to start designing and constructing data centers with fast, tiered storage systems to query and aggregate over large collections of genomes and ‘omics data. There are new technologies on the horizon that will help support these needs, including 3-D memory, integrated computing technologies that overcome the I/O bottleneck, and networks that are two-to-five orders of magnitude faster because of optical switching [<xref rid="pbio.1002195.ref045" ref-type="bibr">45</xref>,<xref rid="pbio.1002195.ref046" ref-type="bibr">46</xref>]. Similarly, efficient compression and indexing systems are critical to make the best use out of each available byte while making the data highly accessible. We also expect algorithmic developments that can represent large collections of personal genomes as a compact graph, making it more efficient and robust to compare one genome to many others. Beyond these approaches, we see the rise of streaming approaches to make on-the-fly comparisons that will allow us to rapidly discard data, especially for sequencing applications that use the sequence data as a means to infer abundances or other molecular activity.</p>
</sec>
<sec id="sec009">
<title>(3) Distribution</title>
<p>The most practical, and perhaps only, solution for distributing genome sequences at a population scale is to use cloud-computing systems that minimize data movement and maximize code federation [<xref rid="pbio.1002195.ref047" ref-type="bibr">47</xref>]. New developments from companies such as Google, Amazon, and Facebook that include applications built to fit the frameworks of distributed computing efficient data centers and distributed storage and cloud computing paradigms will be part of the solution. Already, large cloud-based genomic resources are being developed using these technologies, especially to support the needs of the largest sequencing centers or to support the needs of large communities (BGI-cloud, TCGA, the International Cancer Genome Consortium [ICGC], etc.). To make these online systems most useful, the community needs to develop application programming interfaces (APIs) for discovering and querying large datasets on remote systems. The Global Alliance for Genomics and Health [<xref rid="pbio.1002195.ref048" ref-type="bibr">48</xref>] and others are beginning to develop such standards for human genomic data, and we expect other communities to follow. Finally, authentication, encryption, and other security safeguards must be developed to ensure that genomic data remain private.</p>
</sec>
<sec id="sec010">
<title>(4) Analysis</title>
<p>Our ultimate goal is to be able to interpret genomic sequences and answer how DNA mutations, expression changes, or other molecular measurements relate to disease, development, behavior, or evolution. Accomplishing this goal will clearly require integration of biological domain expertise, large-scale machine learning systems, and a computing infrastructure that can support flexible and dynamic queries to search for patterns over very large collections in very high dimensions. A number of “data science technologies,” including R, Mahout, and other machine learning systems powered by Hadoop and other highly scalable systems, are a start, but the current offerings are still difficult and expensive to use. The community would also benefit from libraries of highly optimized algorithms within a simple interface that can be combined and reused in many contexts as the problems emerge. Data science companies as well as open-source initiatives are already starting to develop such components, such as Amazon’s recent “Amazon Machine Learning” prediction system. But because genomics poses unique challenges in terms of data acquisition, distribution, storage, and especially analysis, waiting for innovations from outside our field is unlikely to be sufficient. We must face these challenges ourselves, starting with integrating data science into graduate, undergraduate, and high-school curricula to train the next generations of quantitative biologists, bioinformaticians, and computer scientists and engineers [<xref rid="pbio.1002195.ref049" ref-type="bibr">49</xref>].</p>
</sec>
</sec>
</boxed-text>
</sec>
<sec id="sec011">
<title>Supporting Information</title>
<supplementary-material id="pbio.1002195.s001" xlink:href="info:doi/10.1371/journal.pbio.1002195.s001" mimetype="image/tiff" position="float" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Growth of GenBank.</title>
<p>The <italic>y</italic>-axis shows the total sequence in bp. (Blue = GenBank, red = whole genome shotgun [WGS] sequences.) Each line is double of the previous. The <italic>x</italic>-axis indicates time. Each line is 6 months after the previous. Source: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/genbank/statistics" xlink:type="simple">http://www.ncbi.nlm.nih.gov/genbank/statistics</ext-link>.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002195.s002" xlink:href="info:doi/10.1371/journal.pbio.1002195.s002" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S1 Note</label>
<caption>
<title>YouTube data estimates.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002195.s003" xlink:href="info:doi/10.1371/journal.pbio.1002195.s003" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S2 Note</label>
<caption>
<title>Twitter data estimates.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002195.s004" xlink:href="info:doi/10.1371/journal.pbio.1002195.s004" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S3 Note</label>
<caption>
<title>Human genomic data storage estimates for 2025.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002195.s005" xlink:href="info:doi/10.1371/journal.pbio.1002195.s005" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S4 Note</label>
<caption>
<title>YouTube distribution statistics (current).</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002195.s006" xlink:href="info:doi/10.1371/journal.pbio.1002195.s006" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Capacities of 20 major genomics institutions.</title>
<p>The number of sequencers as listed from OmicsMaps.com and their storage capacities from the listed citation. These 20 institutions alone collectively have more than 100 PB of storage available.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank V. Jongeneel, M. Baker, and the anonymous reviewers for comments that improved the manuscript and the Illinois CompGen Initiative for providing the collaborative structure that fostered the idea for this analysis. We would also like to thank all of the participants of the 2014 Keystone Symposium on “Big Data in Biology” (organized by Lincoln D. Stein, Doreen Ware, and MCS) for their inspiration for this analysis.</p>
</ack>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>API</term>
<def><p>application programming interface</p></def>
</def-item>
<def-item><term>ASKAP</term>
<def><p>Australian Square Kilometre Array Pathfinder</p></def>
</def-item>
<def-item><term>CPU</term>
<def><p>central processing unit</p></def>
</def-item>
<def-item><term>ExAC</term>
<def><p>Exome Aggregation Consortium</p></def>
</def-item>
<def-item><term>ICGC</term>
<def><p>International Cancer Genome Consortium</p></def>
</def-item>
<def-item><term>I/O</term>
<def><p>input/output</p></def>
</def-item>
<def-item><term>NIH/NCBI</term>
<def><p>National Institutes of Health National Center for Biotechnology Information</p></def>
</def-item>
<def-item><term>SKA</term>
<def><p>Square Kilometre Array</p></def>
</def-item>
<def-item><term>SRA</term>
<def><p>Sequence Read Archive</p></def>
</def-item>
<def-item><term>TCGA</term>
<def><p>The Cancer Genome Atlas</p></def>
</def-item>
<def-item><term>WGS</term>
<def><p>whole genome shotgun</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.1002195.ref001"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Mole, B. The gene sequencing future is here. 2014; <ext-link ext-link-type="uri" xlink:href="http://www.sciencenews.org/article/gene-sequencing-future-here" xlink:type="simple">http://www.sciencenews.org/article/gene-sequencing-future-here</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Robinson</surname> <given-names>G.E.</given-names></name>, <etal>et al</etal>., <article-title>Creating a Buzz About Insect Genomes</article-title>. <source>Science</source>, <year>2011</year>. <volume>18</volume>: <fpage>1386</fpage>.</mixed-citation></ref>
<ref id="pbio.1002195.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abecasis</surname> <given-names>G.R.</given-names></name>, <etal>et al</etal>., <article-title>An integrated map of genetic variation from 1,092 human genomes</article-title>. <source>Nature</source>, <year>2012</year>. <volume>491</volume>(<issue>7422</issue>): <fpage>56</fpage>–<lpage>65</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature11632" xlink:type="simple">10.1038/nature11632</ext-link></comment> <object-id pub-id-type="pmid">23128226</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chin</surname> <given-names>L.</given-names></name>, <name name-style="western"><surname>Andersen</surname> <given-names>J.N.</given-names></name>, and <name name-style="western"><surname>Futreal</surname> <given-names>P.A.</given-names></name>, <article-title>Cancer genomics: from discovery science to personalized medicine</article-title>. <source>Nature medicine</source>, <year>2011</year>. <volume>17</volume>(<issue>3</issue>): <fpage>297</fpage>–<lpage>303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nm.2323" xlink:type="simple">10.1038/nm.2323</ext-link></comment> <object-id pub-id-type="pmid">21383744</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref005"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Exome Aggregation Consortium. Exome Aggregation Consortium ExAC Browser. 2015; <ext-link ext-link-type="uri" xlink:href="http://exac.broadinstitute.org/" xlink:type="simple">http://exac.broadinstitute.org/</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Giles</surname> <given-names>J.</given-names></name>, <article-title>Computational social science: Making the links</article-title>. <source>Nature</source>, <year>2012</year>. <volume>488</volume>(<issue>7412</issue>): <fpage>448</fpage>–<lpage>50</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/488448a" xlink:type="simple">10.1038/488448a</ext-link></comment> <object-id pub-id-type="pmid">22914149</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref007"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Pak, A. and P. Paroubek, Twitter as a Corpus for Sentiment Analysis and Opinion Mining, in LREC. 2010. p. 1320–1326.</mixed-citation></ref>
<ref id="pbio.1002195.ref008"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">O'Luanaigh, C. Animation shows LHC data processing. 2013; <ext-link ext-link-type="uri" xlink:href="http://home.web.cern.ch/about/updates/2013/04/animation-shows-lhc-data-processing" xlink:type="simple">http://home.web.cern.ch/about/updates/2013/04/animation-shows-lhc-data-processing</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref009"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Newman, R. and J. Tseng. Cloud Computing and the Square Kilometre Array. 2011; <ext-link ext-link-type="uri" xlink:href="http://www.skatelescope.org/uploaded/8762_134_Memo_Newman.pdf" xlink:type="simple">http://www.skatelescope.org/uploaded/8762_134_Memo_Newman.pdf</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref010"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">IBM Research. Square Kilometer Array: Ultimate Big Data Challenge. 2013; <ext-link ext-link-type="uri" xlink:href="http://www.skatelescope.org/uploaded/8762_134_Memo_Newman.pdf" xlink:type="simple">http://www.skatelescope.org/uploaded/8762_134_Memo_Newman.pdf</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref011"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Omicsmap. Next Generation Genomics: World Map of High-throughput Sequencers. 2015; <ext-link ext-link-type="uri" xlink:href="http://omicsmaps.com/" xlink:type="simple">http://omicsmaps.com/</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref012"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Regalado, A. EmTech: Illumina Says 228,000 Human Genomes Will Be Sequenced This Year. MIT Technology Review 2014 [cited 2015 April 28, 2015]; <ext-link ext-link-type="uri" xlink:href="http://www.technologyreview.com/news/531091/emtech-illumina-says-228000-human-genomes-will-be-sequenced-this-year/" xlink:type="simple">http://www.technologyreview.com/news/531091/emtech-illumina-says-228000-human-genomes-will-be-sequenced-this-year/</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref013"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">AllSeq. HiSeq X Ten. 2015 [cited 2015 April 1, 2015]; <ext-link ext-link-type="uri" xlink:href="http://allseq.com/x-ten" xlink:type="simple">http://allseq.com/x-ten</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref014"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Illumina. HiSeq X Series of Sequencing Systems. 2015 [cited April 28, 2015]; <ext-link ext-link-type="uri" xlink:href="http://www.illumina.com/content/dam/illumina-marketing/documents/products/datasheets/datasheet-hiseq-x-ten.pdf" xlink:type="simple">http://www.illumina.com/content/dam/illumina-marketing/documents/products/datasheets/datasheet-hiseq-x-ten.pdf</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mora</surname> <given-names>C.</given-names></name>, <etal>et al</etal>., <article-title>How Many Species Are There on Earth and in the Ocean?</article-title> <source>PLoS Biology</source>, <year>2011</year>; <volume>9</volume>: <fpage>e1001127</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1001127" xlink:type="simple">10.1371/journal.pbio.1001127</ext-link></comment> <object-id pub-id-type="pmid">21886479</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>J.Y.</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>J.</given-names></name>, and <name name-style="western"><surname>Zeigler</surname> <given-names>R.S.</given-names></name>, <article-title>The 3,000 rice genomes project: new opportunities and challenges for future rice research</article-title>. <source>GigaScience</source>, <year>2014</year>. <volume>3</volume>: <fpage>8</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/2047-217X-3-8" xlink:type="simple">10.1186/2047-217X-3-8</ext-link></comment> <object-id pub-id-type="pmid">24872878</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhu</surname> <given-names>J.</given-names></name>, <article-title>A year of great leaps in genome research</article-title>. <source>Genome medicine</source>, <year>2012</year>. <volume>4</volume>(<issue>1</issue>): <fpage>4</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/gm303" xlink:type="simple">10.1186/gm303</ext-link></comment> <object-id pub-id-type="pmid">22293069</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eisen</surname> <given-names>J.A.</given-names></name>, <article-title>Environmental shotgun sequencing: its potential and challenges for studying the hidden world of microbes</article-title>. <source>PLoS Biology</source>, <year>2007</year>. <volume>5</volume>(<issue>3</issue>): <fpage>e82</fpage>. <object-id pub-id-type="pmid">17355177</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gevers</surname> <given-names>D.</given-names></name>, <etal>et al</etal>., <article-title>The Human Microbiome Project: a community resource for the healthy human microbiome</article-title>. <source>PLoS Biology</source>, <year>2012</year>. <volume>10</volume>(<issue>8</issue>): <fpage>e1001377</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1001377" xlink:type="simple">10.1371/journal.pbio.1001377</ext-link></comment> <object-id pub-id-type="pmid">22904687</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref020"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Genomics England. The 100,000 Genomes Project. 2015; <ext-link ext-link-type="uri" xlink:href="http://www.genomicsengland.co.uk/the-100000-genomes-project/" xlink:type="simple">http://www.genomicsengland.co.uk/the-100000-genomes-project/</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref021"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Briggs, H (2013) Hundred thousand genomes to be mapped in Saudi Arabia. BBC News. <ext-link ext-link-type="uri" xlink:href="http://www.bbc.com/news/health-25216135" xlink:type="simple">http://www.bbc.com/news/health-25216135</ext-link></mixed-citation></ref>
<ref id="pbio.1002195.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sulem</surname> <given-names>P.</given-names></name>, <etal>et al</etal>., <article-title>Identification of a large set of rare complete human knockouts</article-title>. <source>Nature genetics</source>, <year>2015</year>; <volume>47</volume>: <fpage>448</fpage>–<lpage>452</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/ng.3243" xlink:type="simple">10.1038/ng.3243</ext-link></comment> <object-id pub-id-type="pmid">25807282</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref023"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">Kaiser, J. White House fleshes out Obama’s $215 million plan for precision medicine. Science Insider 2015; <ext-link ext-link-type="uri" xlink:href="http://news.sciencemag.org/biology/2015/01/white-house-fleshes-out-obama-s-215-million-plan-precision-medicine" xlink:type="simple">http://news.sciencemag.org/biology/2015/01/white-house-fleshes-out-obama-s-215-million-plan-precision-medicine</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref024"><label>24</label><mixed-citation publication-type="other" xlink:type="simple">Internet World Stats. 2015; <ext-link ext-link-type="uri" xlink:href="http://www.internetworldstats.com/stats.htm" xlink:type="simple">http://www.internetworldstats.com/stats.htm</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Soon</surname> <given-names>W.W.</given-names></name>, <name name-style="western"><surname>Hariharan</surname> <given-names>M.</given-names></name>, and <name name-style="western"><surname>Snyder</surname> <given-names>M.P.</given-names></name>, <article-title>High-throughput sequencing for biology and medicine</article-title>. <source>Molecular systems biology</source>, <year>2013</year>. <volume>9</volume>: <fpage>640</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/msb.2012.61" xlink:type="simple">10.1038/msb.2012.61</ext-link></comment> <object-id pub-id-type="pmid">23340846</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname> <given-names>R.</given-names></name>, <etal>et al</etal>., <article-title>Personal omics profiling reveals dynamic molecular and medical phenotypes</article-title>. <source>Cell</source>, <year>2012</year>. <volume>148</volume>(<issue>6</issue>): <fpage>1293</fpage>–<lpage>307</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cell.2012.02.009" xlink:type="simple">10.1016/j.cell.2012.02.009</ext-link></comment> <object-id pub-id-type="pmid">22424236</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hsi-Yang Fritz</surname> <given-names>M.</given-names></name>, <etal>et al</etal>., <article-title>Efficient storage of high throughput DNA sequencing data using reference-based compression</article-title>. <source>Genome research</source>, <year>2011</year>. <volume>21</volume>(<issue>5</issue>): <fpage>734</fpage>–<lpage>40</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1101/gr.114819.110" xlink:type="simple">10.1101/gr.114819.110</ext-link></comment> <object-id pub-id-type="pmid">21245279</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Loh</surname> <given-names>P.-R.</given-names></name>, <name name-style="western"><surname>Baym</surname> <given-names>M.</given-names></name>, and <name name-style="western"><surname>Berger</surname> <given-names>B.</given-names></name>, Compressive genomics. <source>Nature Biotechnology</source>, <year>2012</year>. <volume>30</volume>: <fpage>627</fpage>–<lpage>630</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nbt.2241" xlink:type="simple">10.1038/nbt.2241</ext-link></comment> <object-id pub-id-type="pmid">22781691</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koren</surname> <given-names>S.</given-names></name> and <name name-style="western"><surname>Phillippy</surname> <given-names>A.M.</given-names></name>, <article-title>One chromosome, one contig: complete microbial genomes from long-read sequencing and assembly</article-title>. <source>Current opinion in microbiology</source>, <year>2015</year>. <volume>23C</volume>: <fpage>110</fpage>–<lpage>120</lpage>.</mixed-citation></ref>
<ref id="pbio.1002195.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Christley</surname> <given-names>S.</given-names></name>, <etal>et al</etal>., <article-title>Human genomes as email attachments</article-title>. <source>Bioinformatics</source>, <year>2009</year>. <volume>25</volume>(<issue>2</issue>): <fpage>274</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/btn582" xlink:type="simple">10.1093/bioinformatics/btn582</ext-link></comment> <object-id pub-id-type="pmid">18996942</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Patro</surname> <given-names>R.</given-names></name>, <name name-style="western"><surname>Mount</surname> <given-names>S.M.</given-names></name>, and <name name-style="western"><surname>Kingsford</surname> <given-names>C.</given-names></name>, <article-title>Sailfish enables alignment-free isoform quantification from RNA-seq reads using lightweight algorithms</article-title>. <source>Nature biotechnology</source>, <year>2014</year>. <volume>32</volume>(<issue>5</issue>): <fpage>462</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nbt.2862" xlink:type="simple">10.1038/nbt.2862</ext-link></comment> <object-id pub-id-type="pmid">24752080</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Golden</surname> <given-names>A.</given-names></name>, <name name-style="western"><surname>Djorgovski</surname> <given-names>S.</given-names></name>, and <name name-style="western"><surname>Greally</surname> <given-names>J.</given-names></name>, <article-title>Astrogenomics: big data, old problems, old solutions?</article-title> <source>Genome Biology</source>, <year>2013</year>. <volume>8</volume>: <fpage>129</fpage>.</mixed-citation></ref>
<ref id="pbio.1002195.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Djoerd Hiemstra</surname> <given-names>C.H.</given-names></name>, <article-title>Brute Force Information Retrieval Experiments using MapReduce'</article-title>. <source>ERCIM News</source>, <year>2012</year>. <volume>89</volume>: <fpage>31</fpage>–<lpage>32</lpage>.</mixed-citation></ref>
<ref id="pbio.1002195.ref034"><label>34</label><mixed-citation publication-type="other" xlink:type="simple">Smith, B., Data Transport for the Square Kilometre Array, in UbuntuNet Alliance Annual Conference. 2012. 15–22.</mixed-citation></ref>
<ref id="pbio.1002195.ref035"><label>35</label><mixed-citation publication-type="other" xlink:type="simple">Global Internet Phenomena Report. 2013; <ext-link ext-link-type="uri" xlink:href="http://www.sandvine.com/downloads/general/global-internet-phenomena/2013/2h-2013-global-internet-phenomena-report.pdf" xlink:type="simple">http://www.sandvine.com/downloads/general/global-internet-phenomena/2013/2h-2013-global-internet-phenomena-report.pdf</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sboner</surname> <given-names>A.</given-names></name>, <etal>et al</etal>., <article-title>The real cost of sequencing: higher than you think!</article-title> <source>Genome Biology</source>, <year>2011</year>. <volume>12</volume>: <fpage>125</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/gb-2011-12-8-125" xlink:type="simple">10.1186/gb-2011-12-8-125</ext-link></comment> <object-id pub-id-type="pmid">21867570</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref037"><label>37</label><mixed-citation publication-type="other" xlink:type="simple">Marx, V., Drilling into big cancer-genome data. Nature Methods, 2013. 10: p. 293–297.</mixed-citation></ref>
<ref id="pbio.1002195.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baker</surname> <given-names>M.</given-names></name>, <article-title>Next-generation sequencing: adjusting to data overload</article-title>. <source>Nature Methods</source>, <year>2010</year>. <volume>7</volume>: <fpage>495</fpage>–<lpage>499</lpage>.</mixed-citation></ref>
<ref id="pbio.1002195.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Erlich</surname> <given-names>Y.</given-names></name> and <name name-style="western"><surname>Narayanan</surname> <given-names>A.</given-names></name>, <article-title>Routes for breaching and protecting genetic privacy. Nature reviews</article-title>. <source>Genetics</source>, <year>2014</year>. <volume>15</volume>(<issue>6</issue>): <fpage>409</fpage>–<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrg3723" xlink:type="simple">10.1038/nrg3723</ext-link></comment> <object-id pub-id-type="pmid">24805122</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref040"><label>40</label><mixed-citation publication-type="other" xlink:type="simple">Norris, R.P., Data Challenges for Next-generation Radio Telescopes. 2011.</mixed-citation></ref>
<ref id="pbio.1002195.ref041"><label>41</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Kumar</surname> <given-names>S.</given-names></name>, <name name-style="western"><surname>Morstatter</surname> <given-names>F.</given-names></name>, and <name name-style="western"><surname>Liu</surname> <given-names>H.</given-names></name>, <chapter-title>Twitter Data Analytics</chapter-title>. <year>2014</year>: <publisher-name>Springer</publisher-name>.</mixed-citation></ref>
<ref id="pbio.1002195.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Langmead</surname> <given-names>B.</given-names></name>, <etal>et al</etal>., <article-title>Searching for SNPs with cloud computing</article-title>. <source>Genome Biol</source>, <year>2009</year>. <volume>10</volume>(<issue>11</issue>): <fpage>R134</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/gb-2009-10-11-r134" xlink:type="simple">10.1186/gb-2009-10-11-r134</ext-link></comment> <object-id pub-id-type="pmid">19930550</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kurtz</surname> <given-names>S.</given-names></name>, <etal>et al</etal>., <article-title>Versatile and open software for comparing large genomes</article-title>. <source>Genome Biol</source>, <year>2004</year>. <volume>5</volume>(<issue>2</issue>): <fpage>R12</fpage>. <object-id pub-id-type="pmid">14759262</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Trelles</surname> <given-names>O.</given-names></name>, <etal>et al</etal>., <article-title>Big data, but are we ready? Nature reviews</article-title>. <source>Genetics</source>, <year>2011</year>. <volume>12</volume>(<issue>3</issue>): <fpage>224</fpage>.</mixed-citation></ref>
<ref id="pbio.1002195.ref045"><label>45</label><mixed-citation publication-type="other" xlink:type="simple">Loh, G.H. 3D-stacked memory architectures for multi-core processors. in ACM SIGARCH. 2008.</mixed-citation></ref>
<ref id="pbio.1002195.ref046"><label>46</label><mixed-citation publication-type="other" xlink:type="simple">Chan, V.W., et al. Optical flow switching: An end-to-end “UltraFlow” architecture. in 15th International Conference on Transparent Optical Networks (ICTON). 2013. IEEE. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/ICTON.2013.6602704" xlink:type="simple">10.1109/ICTON.2013.6602704</ext-link></comment></mixed-citation></ref>
<ref id="pbio.1002195.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schatz</surname> <given-names>M.C.</given-names></name>, <name name-style="western"><surname>Langmead</surname> <given-names>B.</given-names></name>, and <name name-style="western"><surname>Salzberg</surname> <given-names>S.L.</given-names></name>, <article-title>Cloud computing and the DNA data race</article-title>. <source>Nature biotechnology</source>, <year>2010</year>. <volume>28</volume>(<issue>7</issue>): <fpage>691</fpage>–<lpage>3</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nbt0710-691" xlink:type="simple">10.1038/nbt0710-691</ext-link></comment> <object-id pub-id-type="pmid">20622843</object-id></mixed-citation></ref>
<ref id="pbio.1002195.ref048"><label>48</label><mixed-citation publication-type="other" xlink:type="simple">Global Alliance for Genomics and Health. Global Alliance for Genomics and Health. 2015 April 28, 2015]; <ext-link ext-link-type="uri" xlink:href="http://genomicsandhealth.org/" xlink:type="simple">http://genomicsandhealth.org/</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref049"><label>49</label><mixed-citation publication-type="other" xlink:type="simple">Schatz, M.C., Computational thinking in the era of big data biology. Genome Biology, 2012. 13(11): 177.</mixed-citation></ref>
<ref id="pbio.1002195.ref050"><label>50</label><mixed-citation publication-type="other" xlink:type="simple">Hollis, C. EMC's Record Breaking Product Launch. 2011 April 28, 2015]; <ext-link ext-link-type="uri" xlink:href="http://chucksblog.emc.com/chucks_blog/2011/01/emcs-record-breaking-product-launch.html" xlink:type="simple">http://chucksblog.emc.com/chucks_blog/2011/01/emcs-record-breaking-product-launch.html</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref051"><label>51</label><mixed-citation publication-type="other" xlink:type="simple">Hoff, T. How Google Backs up the Internet along with Exabytes of other data. 2014; <ext-link ext-link-type="uri" xlink:href="http://highscalability.com/blog/2014/2/3/how-google-backs-up-the-internet-along-with-exabytes-of-othe.html" xlink:type="simple">http://highscalability.com/blog/2014/2/3/how-google-backs-up-the-internet-along-with-exabytes-of-othe.html</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002195.ref052"><label>52</label><mixed-citation publication-type="other" xlink:type="simple">Daily Kos. Utah Data Center stores data between 1 exabyte and 1 yottabyte. 2013; <ext-link ext-link-type="uri" xlink:href="http://www.dailykos.com/story/2013/08/05/1228923/-Utah-Data-Center-stores-data-between-1-exabyte-and-1-yottabyte" xlink:type="simple">http://www.dailykos.com/story/2013/08/05/1228923/-Utah-Data-Center-stores-data-between-1-exabyte-and-1-yottabyte</ext-link>.</mixed-citation></ref>
</ref-list>
</back>
</article>
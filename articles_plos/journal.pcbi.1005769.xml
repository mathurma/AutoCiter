<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005769</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-00884</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Decision theory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Decision theory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Addiction</subject><subj-group><subject>Behavioral addiction</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Addiction</subject><subj-group><subject>Behavioral addiction</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Bayesian statistics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Bayesian statistics</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Addiction</subject><subj-group><subject>Gambling addiction</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Addiction</subject><subj-group><subject>Gambling addiction</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Mental health and psychiatry</subject><subj-group><subject>Gambling addiction</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory cues</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory cues</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory cues</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>A unifying Bayesian account of contextual effects in value-based choice</article-title>
<alt-title alt-title-type="running-head">Bayesian account of contextual effects</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2233-934X</contrib-id>
<name name-style="western">
<surname>Rigoli</surname>
<given-names>Francesco</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4079-5453</contrib-id>
<name name-style="western">
<surname>Mathys</surname>
<given-names>Christoph</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Friston</surname>
<given-names>Karl J.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Dolan</surname>
<given-names>Raymond J.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>The Wellcome Trust Centre for Neuroimaging, UCL, 12 Queen Square, London, United Kingdom</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>City, University of London, Northampton Square, London, United Kingdom</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Scuola Internazionale Superiore di Studi Avanzati (SISSA), Trieste, Italy</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Max Planck UCL Centre for Computational Psychiatry and Ageing Research, London, United Kingdom</addr-line></aff>
<aff id="aff005"><label>5</label> <addr-line>Translational Neuromodeling Unit (TNU), Institute for Biomedical Engineering, University of Zurich and ETH Zurich, Zurich, Switzerland</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Maloney</surname>
<given-names>Laurence T.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>New York University, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">f.rigoli@ucl.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>5</day>
<month>10</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="collection">
<month>10</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>10</issue>
<elocation-id>e1005769</elocation-id>
<history>
<date date-type="received">
<day>2</day>
<month>6</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>11</day>
<month>9</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Rigoli et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005769"/>
<abstract>
<p>Empirical evidence suggests the incentive value of an option is affected by other options available during choice and by options presented in the past. These contextual effects are hard to reconcile with classical theories and have inspired accounts where contextual influences play a crucial role. However, each account only addresses one or the other of the empirical findings and a unifying perspective has been elusive. Here, we offer a unifying theory of context effects on incentive value attribution and choice based on normative Bayesian principles. This formulation assumes that incentive value corresponds to a precision-weighted prediction error, where predictions are based upon expectations about reward. We show that this scheme explains a wide range of contextual effects, such as those elicited by other options available during choice (or within-choice context effects). These include both conditions in which choice requires an integration of multiple attributes and conditions where a multi-attribute integration is not necessary. Moreover, the same scheme explains context effects elicited by options presented in the past or between-choice context effects. Our formulation encompasses a wide range of contextual influences (comprising both within- and between-choice effects) by calling on Bayesian principles, without invoking <italic>ad-hoc</italic> assumptions. This helps clarify the contextual nature of incentive value and choice behaviour and may offer insights into psychopathologies characterized by dysfunctional decision-making, such as addiction and pathological gambling.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Research has shown that decision-making is dramatically influenced by context. Two types of influence have been identified, one dependent on options presented in the past (between-choice effects) and the other dependent on options currently available (within-choice effects). Whether these two types of effects arise from similar mechanisms remain unclear. Here we offer a theory based on Bayesian inference which provides a unifying explanation of both between and within-choice context effect. The core idea of the theory is that the value of an option corresponds to a precision-weighted prediction error, where predictions are based upon expectations about reward. An important feature of the theory is that it is based on minimal assumptions derived from Bayesian principles. This helps clarify the contextual nature of incentive value and choice behaviour and may offer insights into psychopathologies characterized by dysfunctional decision-making, such as addiction and pathological gambling.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>098362/Z/12/Z</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Dolan</surname>
<given-names>Ray J.</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>088130/Z/09/Z</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Friston</surname>
<given-names>Karl J.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by the Wellcome Trust (<ext-link ext-link-type="uri" xlink:href="http://wellcome.ac.uk" xlink:type="simple">wellcome.ac.uk</ext-link>): Karl J Friston is funded by a Wellcome Trust Principal Research Fellowship (088130/Z/09/Z). Raymond J Dolan is funded by a Senior Investigator Award (098362/Z/12/Z) and the Max Planck Society. The Wellcome Trust Centre for Neuroimaging is supported by core funding from the Wellcome Trust 091593/Z/10/Z. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="9"/>
<table-count count="0"/>
<page-count count="28"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2017-10-17</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Standard theories of decision-making assume that the incentive value of an option should be independent of options presented in the past and options available during choice [<xref ref-type="bibr" rid="pcbi.1005769.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref004">4</xref>]. These theories are fundamentally challenged by empirical evidence showing that expectations (derived from past experience) about upcoming options change value attribution and choice behaviour [<xref ref-type="bibr" rid="pcbi.1005769.ref005">5</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref014">14</xref>]. For example, in a series of recent experiments from our lab [<xref ref-type="bibr" rid="pcbi.1005769.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref010">10</xref>], participants made choices in blocks (i.e. contexts) associated with one of two distinct, but partially overlapping, reward distributions. Participants’ choices were consistent with attributing a larger incentive value to rewards (common to both contexts) in blocks associated with low compared to high average reward. In other words, the incentive value of a reward increased when the average was lower. In addition to the average reward of a context, evidence from a similar task indicated that reward variance within a given context also exerts an influence on incentive value [<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>]. These findings highlight contextual effects exerted by expectations about options (induced, for example, by options available during previous choices); namely, <italic>between-choice</italic> contextual effects.</p>
<p>In addition, the empirical literature has highlighted contextual influences elicited by options available during choice; namely, <italic>within-choice</italic> context effects [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref020">20</xref>]. Standard theories of decision-making assume that the incentive value of an option should be independent of other options available during choice [<xref ref-type="bibr" rid="pcbi.1005769.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref004">4</xref>]. This implies that the choice proportion between two options, comprising a more valuable and a less valuable option, should be unaffected by the introduction of a third [<xref ref-type="bibr" rid="pcbi.1005769.ref002">2</xref>]. However, a recent study [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>] has shown that this choice proportion follows a U-shape function, which diminishes as the value of a third option approaches the value of the target options–and starts increasing thereafter (<xref ref-type="fig" rid="pcbi.1005769.g001">Fig 1A</xref>). This is hard to reconcile with standard theories and represents a form of within-choice context effect, whereby the value of an option is affected by other options available during choice.</p>
<fig id="pcbi.1005769.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005769.g001</object-id>
<label>Fig 1</label>
<caption>
<title/>
<p><bold>A:</bold> Empirical evidence concerning contextual effects elicited by multiple options available during choice (within-choice context effects). <bold>A:</bold> Single-attribute choice, where there is no need to integrate multiple attributes to make a decision. Here a better target option associated with reward <italic>R</italic><sub><italic>H</italic></sub> and a worse target option associated with reward <italic>R</italic><sub><italic>L</italic></sub> are available together with a third option associated with reward <italic>R</italic><sub>3</sub>. The graph plots empirical findings [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>] in terms of the ratio between the probability of choosing the better target option (<italic>P</italic>[<italic>R</italic><sub><italic>H</italic></sub>|<italic>R</italic><sub><italic>H</italic></sub>,<italic>R</italic><sub><italic>L</italic></sub>,<italic>R</italic><sub>3</sub>]) and the probability of choosing the worse target option (<italic>P</italic>[<italic>R</italic><sub><italic>L</italic></sub>|<italic>R</italic><sub><italic>H</italic></sub>,<italic>R</italic><sub><italic>L</italic></sub>,<italic>R</italic><sub>3</sub>]) as a function of the (normalized) reward of a third options <italic>R</italic><sub>3</sub> (see Fig 5C in [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>]). <bold>B:</bold> Multiattribute choice, where multiple attributes need to be integrated to make a decision. Here, we consider the difference in choice probability between a high-quality and high-price car A and a low-quality and low-price car B. Although during binary choice this difference is zero, empirical evidence has shown this difference can be non-zero when a third option is also available. A similarity effect favours car A over car B when a low-quality and low-price car C (similar to car B) is available. An attraction effect favours car A over car B when a medium-quality and high-price car D is available. A compromise effect consists in favouring a medium-quality and medium-price car E over both car A and car B during choices in which all three cars are available, despite the fact these cars are equally chosen when they are available in pairs during binary choices.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005769.g001" xlink:type="simple"/>
</fig>
<p>In this task, it is unnecessary to compare options across different attributes (single-attribute decisions; [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>]). However, other forms of within-choice context effect have been observed when options are defined by the same set of attributes that have to be traded of against each other (multiattribute decisions; [<xref ref-type="bibr" rid="pcbi.1005769.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref020">20</xref>]. For example, consider a binary choice between a high-quality and expensive car A versus a low-quality and cheap car B (<xref ref-type="fig" rid="pcbi.1005769.g001">Fig 1B</xref>). Imagine the values of the attributes are such that an agent is indifferent about the two options (i.e., the higher price of car A is exactly compensated by its quality), resulting in the same probability of choosing options A and B. What happens if a third option is also available? Standard models (based on the assumption that values are independent of other options) predict that the choice probability difference will remain zero, independent of a third option. However, empirical data highlight a so-called <italic>similarity effect</italic> [<xref ref-type="bibr" rid="pcbi.1005769.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref023">23</xref>], whereby preference for an option over a second option–which is equally preferable during binary decisions–increases if a third option is available that is similar to the second option (<xref ref-type="fig" rid="pcbi.1005769.g001">Fig 1B</xref>). In our example, the choice probability difference between car A and car B will be positive when a third low-quality and cheap (similar to car B) car C is also available. A form of influence called the <italic>attraction effect</italic> [<xref ref-type="bibr" rid="pcbi.1005769.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref024">24</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref026">26</xref>] has also been found with the availability of a third option that is characterized by a low score for one attribute and an intermediate score for the other (<xref ref-type="fig" rid="pcbi.1005769.g001">Fig 1B</xref>). The presence of such a third option favours the option with a high score for the attribute for which the third option has an intermediate score. In our example, the choice probability difference between car A and car B will be positive when a third medium-quality and expensive car D is also available. Finally, empirical data are consistent with a so-called <italic>compromise effect</italic> [<xref ref-type="bibr" rid="pcbi.1005769.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref027">27</xref>]. This applies when the choice set includes two options scoring high in one attribute and low in another plus a third option characterized by intermediate scores for both attributes. While the three options are equally preferred (i.e., are chosen an equal amount of times) if presented in pairs during binary choices, when they are all available, a preference for the option characterized by intermediate scores is observed (<xref ref-type="fig" rid="pcbi.1005769.g001">Fig 1B</xref>). For instance, although during binary choices an average-price and average-quality car E is not preferred over car A or over car B, car E will be favoured when presented together with both car A and car B.</p>
<p>Several explanations have been proposed to account for contextual effects on incentive value and choice, with most models focusing on within-choice context effects during multiattribute decisions [<xref ref-type="bibr" rid="pcbi.1005769.ref016">16</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref028">28</xref>]. Other theories have been proposed to explain between-choice context effects [<xref ref-type="bibr" rid="pcbi.1005769.ref029">29</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref031">31</xref>], and disregard within-choice effects. We are aware of a single attempt to encompass both between-choice and within-choice effects, though restricted to non-multiattribute decisions for the latter type of effects [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>]. Whether models developed to explain a certain class of context effects generalise to other effects remains unclear–and a unifying account encompassing all known context effects is lacking. Developing a parsimonious account would represent an important theoretical advance, as it would explain diverse empirical phenomena with the same underlying principles.</p>
<p>The goal of the present paper is to describe a unifying theory, referred to as Bayesian model of context sensitive value (BCV) that explains between-context and within-context effects, in single and multiattribute decisions. This theory represents a generalization of a recent model developed to explain between-choice contextual effects [<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>]. The key idea is that agents build a generative model of reward within a context and, every time a new reward or option is presented, use Bayesian inference to invert this model to form a posterior belief about the underlying reward distribution. Incentive value is computed during this belief update and corresponds to a precision-weighted reward prediction error. The advantage of this theory relies on its grounding upon simple normative principles of Bayesian statistics. In addition, the model can explain between-choice context effects [<xref ref-type="bibr" rid="pcbi.1005769.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>] and makes specific predictions that have been confirmed empirically.</p>
<p>In brief, BCV proposes that the incentive value of a stimulus (or option) corresponds to the change in reward expected (in any given context) when the stimulus is presented. This makes precise predictions about choice under ideal (Bayesian) observer assumptions (with a minimal number of free parameters). Crucially, predictions include specific forms of context effects, and raise a question of whether these predicted effects are consistent with empirical findings.</p>
<p>In this paper, we applied BCV to multi-alternative choice (considering both single and multiattribute decisions) and ask whether the model predicts the context-effects found empirically. We first present a theoretical extension of BCV applicable to decisions in which multiple options are available and can be characterized by multiple attributes. We show that predictions derived from the model are remarkably similar to empirical findings on within-choice contextual effects, both during non-multiattribute and multiattribute decisions. We next review BCV in relation to between-choice context effects and describe how the model can also explain these empirical findings. On this basis, we offer the model as a principled description of between and within-choice context effects.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Within-choice context effects</title>
<p>The idea behind BCV is to establish a link between theories of value and normative accounts of brain functioning based on Bayesian statistics [<xref ref-type="bibr" rid="pcbi.1005769.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref037">37</xref>]. The Bayesian brain framework rests on the idea that an agent builds a model of the processes generating sensory cues. The generative model comprises a set of random variables (i.e., hidden states or causes of sensory outcomes) and their causal links (i.e., probabilistic contingencies). The variables can be separated into hidden and observable variables, the former representing the latent causes of observations, and the latter representing sensory evidence or cues. Sensory evidence conveyed by observable variables is combined with prior beliefs about hidden causes to produce a posterior belief about the causes of observations. The application of this logic has proved effective in explaining several empirical phenomena in perception [<xref ref-type="bibr" rid="pcbi.1005769.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref037">37</xref>]. For instance, psychophysical data indicate that human perception depends on integrating different perceptual modalities (e.g., visual and tactile) in a manner consistent with Bayesian principles [<xref ref-type="bibr" rid="pcbi.1005769.ref038">38</xref>], where evidence is weighted by the precision of sensory information. Furthermore, process theories that mediate Bayesian inference (e.g., predictive coding) have a large explanatory scope in terms of neuroanatomy and physiology [<xref ref-type="bibr" rid="pcbi.1005769.ref039">39</xref>].</p>
<p>Inspired by a recent framework that conceptualises planning and choice as active inference [<xref ref-type="bibr" rid="pcbi.1005769.ref040">40</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref045">45</xref>], our core proposal is that Bayesian inference drives the attribution of incentive value to reward, and this in turn determines choice.</p>
<p>In a previous work, we have developed a version of BCV applicable to conditions where past options elicit context effects by shaping expectancies before a reward is presented ([<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>]; see below). However, our previous formulation did not consider conditions where multiple options (potentially characterized by multiple attributes) are available. Here we generalize BCV to encompass conditions in which multiple options are available and options can be characterized by multiple attributes. We define a multi-attribute <italic>option u</italic><sub><italic>n</italic></sub> (e.g., car A or car B) as a contract that yields <italic>reward amount R</italic><sub><italic>i</italic>,<italic>n</italic></sub> relative to each attribute <italic>i</italic> (e.g., price or quality):
<disp-formula id="pcbi.1005769.e001">
<alternatives>
<graphic id="pcbi.1005769.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mspace width="2em"/><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mspace width="2em"/><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula></p>
<p>An option set <italic>u</italic> is the set of options currently available:
<disp-formula id="pcbi.1005769.e002">
<alternatives>
<graphic id="pcbi.1005769.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mspace width="2em"/><mml:mi mathvariant="normal">with</mml:mi><mml:mspace width="3em"/><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="0.25em"/><mml:mo>∀</mml:mo><mml:mspace width="0.25em"/><mml:mi>n</mml:mi>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula></p>
<p>The expected value (EV) of an option <italic>u</italic><sub><italic>n</italic></sub> corresponds to:
<disp-formula id="pcbi.1005769.e003">
<alternatives>
<graphic id="pcbi.1005769.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>For example, the total reward for car A is equal to the reward associated with price plus the reward associated with quality. BCV assumes that an agent builds a generative model of the reward amounts <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> (<xref ref-type="fig" rid="pcbi.1005769.g002">Fig 2</xref>). Specifically, an agent believes that, for each attribute <italic>i</italic>, reward amounts <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> across options are sampled from the same population. To distinguish among attributes, we assume that an agent believes that an independent population of reward amounts is associated to each attribute. For example, if two attributes characterize options, two independent populations of reward amounts are considered by the agent (<xref ref-type="fig" rid="pcbi.1005769.g002">Fig 2</xref>).</p>
<fig id="pcbi.1005769.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005769.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Example of a basic generative model underlying BCV.</title>
<p>This is a directed acyclic graph or Bayesian network. Circles represent random variables (shaded and white circles refer to observed and non-observed variables respectively). An arrow denotes a conditional dependence–in which one random variable supplies the mean of the probability distribution of its children. For each attribute i, a hidden variable <italic>C</italic><sub><italic>i</italic></sub> represents the belief about the average reward amount across options for the attribute i. This generates the mean for Gaussian observable variables <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub>, corresponding to reward amounts associated with options available during choice. In this example, three options are available and options are characterized by two attributes. Note that attributes are independent in the generative model, as there is no arrow connecting variables associated with different attributes. Inverting this model, given observations, furnishes posterior beliefs over the mean reward amount across options for each attribute i. This inference is performed sequentially integrating one reward amount observation at each inference step. When a reward observation is considered, its incentive value is conceived as (precision-weighted) reward prediction error.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005769.g002" xlink:type="simple"/>
</fig>
<p>Formally, for each attribute <italic>i</italic>, the average of the population of the reward amounts <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> is represented by a random variable <italic>C</italic><sub><italic>i</italic></sub>, which is assumed to be sampled from a Gaussian distribution with prior mean <italic>μ</italic><sub><italic>Ci</italic></sub> and uncertainty (variance) <inline-formula id="pcbi.1005769.e004"><alternatives><graphic id="pcbi.1005769.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>:
<disp-formula id="pcbi.1005769.e005">
<alternatives>
<graphic id="pcbi.1005769.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula></p>
<p>The agent assumes that <italic>μ</italic><sub><italic>Ci</italic></sub> and <inline-formula id="pcbi.1005769.e006"><alternatives><graphic id="pcbi.1005769.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> are known but that <italic>C</italic><sub><italic>i</italic></sub> is not directly observable and therefore needs to be inferred from observing the different instances of reward amounts <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> of options for the attribute <italic>i</italic>. This is realized in the generative model by treating <italic>C</italic><sub><italic>i</italic></sub> as a hidden cause of Gaussian variables <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> with mean <italic>C</italic><sub><italic>i</italic></sub> and uncertainty <inline-formula id="pcbi.1005769.e007"><alternatives><graphic id="pcbi.1005769.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>:
<disp-formula id="pcbi.1005769.e008">
<alternatives>
<graphic id="pcbi.1005769.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula></p>
<p>On the basis of the generative model, for each attribute <italic>i</italic>, the agent can estimate <inline-formula id="pcbi.1005769.e009"><alternatives><graphic id="pcbi.1005769.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">R</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">R</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, namely the posterior belief about the variable <italic>C</italic><sub><italic>i</italic></sub> (i.e., the average reward amount relative to the attribute <italic>i</italic>; the hat symbol indicates estimates of unknown quantities), given the observation of all reward amounts of all options available for the attribute <italic>i</italic>, represented by the set <bold><italic>R</italic></bold><sub><italic>i</italic></sub>. In other words, an agent assumes that there is an average reward for each attribute which is unknown but can be estimated based on the reward amounts.</p>
<p>According to Bayes’ rule, the posterior belief of <italic>C</italic><sub><italic>i</italic></sub> can be calculated by considering the associated <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> sequentially in any order. We propose such sequential belief updating for BCV, even if options (and the associated reward amounts) are presented simultaneously, and we assume that the order of options considered is random (with potentially different orders for different attributes). For example, when three options characterized by two attributes are available (represented by <italic>R</italic><sub>1,1</sub>, <italic>R</italic><sub>1,2</sub> and <italic>R</italic><sub>1,3</sub> for attribute one, and <italic>R</italic><sub>2,1</sub>, <italic>R</italic><sub>2,2</sub> and <italic>R</italic><sub>2,3</sub> for attribute two), inference can involve computing, in order, <italic>P</italic>(<italic>C</italic><sub>1</sub>|<italic>R</italic><sub>1,1</sub>), <italic>P</italic>(<italic>C</italic><sub>1</sub>|<italic>R</italic><sub>1,1</sub>, <italic>R</italic><sub>1,3</sub>) and <italic>P</italic>(<italic>C</italic><sub>1</sub>|<italic>R</italic><sub>1,1</sub>, <italic>R</italic><sub>1,2</sub> <italic>R</italic><sub>1,3</sub>) for attribute one, and <italic>P</italic>(<italic>C</italic><sub>2</sub>|<italic>R</italic><sub>2,3</sub>), <italic>P</italic>(<italic>C</italic><sub>2</sub>|<italic>R</italic><sub>2,1</sub>, <italic>R</italic><sub>2,3</sub>) and <italic>P</italic>(<italic>C</italic><sub>2</sub>|<italic>R</italic><sub>2,1</sub>, <italic>R</italic><sub>2,2</sub> <italic>R</italic><sub>2,3</sub>) for attribute two. In the example above, an agent may consider first car A and next car B when estimating the average reward for price, and first car B and next car A when estimating the average reward for quality.</p>
<p>The rationale behind sequential belief updating is that the brain is equipped with a limited computational capacity, which precludes the instantaneous (and parallel) evidence accumulation, and hence requires the processing of one option after another. A similar evidence accumulation process is implicit in some theories of perceptual and value-based decision-making (e.g., [<xref ref-type="bibr" rid="pcbi.1005769.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref047">47</xref>]). Below, we will show that this evidence accumulation, in the form of sequential Bayesian belief updating, endows agents with the right sort of sensitivity to context. Formally, if <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> is the reward amount considered first during belief updating, in relation to attribute <italic>i</italic>, the posterior mean <inline-formula id="pcbi.1005769.e010"><alternatives><graphic id="pcbi.1005769.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is [<xref ref-type="bibr" rid="pcbi.1005769.ref048">48</xref>]:
<disp-formula id="pcbi.1005769.e011">
<alternatives>
<graphic id="pcbi.1005769.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula></p>
<p>The posterior uncertainty <inline-formula id="pcbi.1005769.e012"><alternatives><graphic id="pcbi.1005769.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is:
<disp-formula id="pcbi.1005769.e013">
<alternatives>
<graphic id="pcbi.1005769.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula></p>
<p>The crucial proposal we advance is that the incentive value <italic>V</italic><sub><italic>i</italic></sub>(<italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub>)–attributed to a reward amount <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> in relation to the attribute <italic>i</italic> and associated with option <italic>u</italic><sub><italic>n</italic></sub>–is central to belief updating (see <xref ref-type="disp-formula" rid="pcbi.1005769.e011">Eq 6</xref>) and corresponds to a <italic>precision-weighted prediction error</italic> [<xref ref-type="bibr" rid="pcbi.1005769.ref049">49</xref>]; namely, to the difference between <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> and the prior mean μ<sub>Ci,</sub> multiplied by a gain term which depends on the uncertainty of that attribute <inline-formula id="pcbi.1005769.e014"><alternatives><graphic id="pcbi.1005769.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and the prior uncertainty <inline-formula id="pcbi.1005769.e015"><alternatives><graphic id="pcbi.1005769.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>:
<disp-formula id="pcbi.1005769.e016">
<alternatives>
<graphic id="pcbi.1005769.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e016" xlink:type="simple"/>
<mml:math display="block" id="M16">
<mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mover accent="false"><mml:mo>⇒</mml:mo><mml:mrow/></mml:mover></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mtd></mml:mtr></mml:mtable>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula></p>
<p>Within BCV, incentive value imbues reward and associated options with behavioural relevance, by favouring either approach to (for positive incentive values) or avoidance of (for negative incentive values) these reward amounts and options.</p>
<p>This implies two fundamental forms of contextual normalization. First, a subtractive normalization is exerted when <italic>μ</italic><sub><italic>Ci</italic></sub> is different from zero. For example, if we assign positive and negative numbers to rewards (i.e., <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> &gt; 0) and punishments (i.e., <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> &lt; 0) respectively, their corresponding incentive values will change in sign, depending on whether punishment (i.e., <italic>μ</italic><sub><italic>Ci</italic></sub> &lt; 0) or reward (i.e., <italic>μ</italic><sub><italic>Ci</italic></sub> &gt; 0) is expected a priori. Small rewards may appear as losses in contexts where large rewards are expected. Second, a divisive normalization depends on considering the gain term <inline-formula id="pcbi.1005769.e017"><alternatives><graphic id="pcbi.1005769.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>. This implies that the positive and negative value of profits (i.e., <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> &gt; <italic>μ</italic><sub><italic>Ci</italic></sub>) and losses (i.e., <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> &lt; <italic>μ</italic><sub><italic>Ci</italic></sub>) are magnified by a large gain term, when we have precise beliefs about the average reward of the population.</p>
<p>Sequential Bayesian belief updating means that inference proceeds by considering one reward amount at a time. If <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub> is considered at step <italic>t+1</italic> and <bold><italic>R</italic></bold><sub><italic>i</italic>,<italic>t</italic></sub> is a set containing all reward amounts already seen up until step <italic>t</italic> for attribute <italic>i</italic>, then a posterior mean <inline-formula id="pcbi.1005769.e018"><alternatives><graphic id="pcbi.1005769.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is obtained at step <italic>t+1</italic> equivalent to (Bishop, 2006):
<disp-formula id="pcbi.1005769.e019">
<alternatives>
<graphic id="pcbi.1005769.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e019" xlink:type="simple"/>
<mml:math display="block" id="M19">
<mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(9)</label>
</disp-formula></p>
<p>Implying a value for the reward amount <italic>R</italic><sub><italic>i</italic>,<italic>n</italic></sub>:
<disp-formula id="pcbi.1005769.e020">
<alternatives>
<graphic id="pcbi.1005769.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e020" xlink:type="simple"/>
<mml:math display="block" id="M20">
<mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(10)</label>
</disp-formula></p>
<p>For each attribute <italic>i</italic>, incentive values are accumulated in memory until inference is completed (i.e., all reward amounts have been considered). We can assume that inference proceeds in sequence or in parallel across attributes; however, this has no impact on incentive values, as the agent believes that attributes are associated with independent reward populations (formally: <italic>P</italic>(<italic>C</italic><sub>1</sub>,<italic>C</italic><sub>2</sub>,…,<italic>C</italic><sub><italic>I</italic></sub>|<bold><italic>R</italic></bold>) = <italic>P</italic>(<italic>C</italic><sub>1</sub>|<bold><italic>R</italic></bold><sub><bold>1</bold></sub>), <italic>P</italic>(<italic>C</italic><sub>2</sub>|<bold><italic>R</italic></bold><sub><bold>2</bold></sub>),…,<italic>P</italic>(<italic>C</italic><sub><italic>I</italic></sub>|<bold><italic>R</italic></bold><sub><bold><italic>I</italic></bold></sub>)).</p>
<p>When all attributes for an option <italic>u</italic><sub><italic>n</italic></sub> have been considered, we assume that the incentive value of the option corresponds to the sum of the incentive values of associated reward amounts:
<disp-formula id="pcbi.1005769.e021">
<alternatives>
<graphic id="pcbi.1005769.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e021" xlink:type="simple"/>
<mml:math display="block" id="M21">
<mml:mi>V</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(11)</label>
</disp-formula></p>
<p>Inference proceeds until, for all attributes <italic>i</italic>, the posterior expectation about rewards <inline-formula id="pcbi.1005769.e022"><alternatives><graphic id="pcbi.1005769.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">R</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is evaluated and, at this point, a choice is realized following a softmax rule based on the incentive values of the available options [<xref ref-type="bibr" rid="pcbi.1005769.ref002">2</xref>].</p>
<p>In summary, BCV is based on the following assumptions:</p>
<list list-type="order">
<list-item><p>Each attribute is associated with an average reward (which is a hidden variable).</p></list-item>
<list-item><p>Average rewards for different attributes are independent.</p></list-item>
<list-item><p>For each attribute, the rewards offered (or observed rewards) are treated as samples that depend on the average reward.</p></list-item>
<list-item><p>The observed rewards are used to invert the model and infer the average reward.</p></list-item>
<list-item><p>During inference, observed rewards are considered sequentially.</p></list-item>
<list-item><p>During inference, an incentive value is calculated for each observed reward that corresponds to a precision-weighted prediction error.</p></list-item>
<list-item><p>Incentive values are summed across observed rewards and attributes, and choice follows a softmax rule.</p></list-item>
</list>
<p>Below these assumptions are discussed in detail. Assumptions (i), (iii), and (iv) are implicit in adopting a Bayesian scheme. Assumption (vii) is based on a standard approach in which incentive values are summed and a softmax choice rule is adopted. Assumption (ii) captures the notion of multiple attributes, in other words it enables an agent to link rewards to their attributes. Assumption (vi) (sequential belief updating or evidence accumulation) reflects the real world constraint that people have to evaluate available options and rewards one by one. In other words, agents cannot magically and instantaneously assimilate all the options on offer–they have to accumulate evidence for the underlying payoffs by evaluating each in turn. This notion plays a central role since we will see that context effects emerge because a reward is contextualized by previous rewards encountered during inference. This underlies assumption (v) that associates incentive value with a precision-weighted prediction error–a central construct in Bayesian inference. Heuristically, this scheme implies that an option is more likely to be selected if it increases expectations of reward, and will be avoided if it decreases expectations. In other words, an option is more likely to be selected if it suggests the situation is better than indicated by options considered previously during belief updating.</p>
<p>Note that a Bayesian perspective may suggest that incentive value corresponds to a posterior belief–rather than a precision-weighted prediction error. As an example, this would imply that the value of the same dish will be perceived as ‘higher’ in a ‘better’ restaurant. However, empirical data are consistent with the opposite notion that (adopting the same example) the value of the same dish is perceived as lower in a better restaurant [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref014">14</xref>]. This evidence motivated our proposal that incentive value corresponds to a precision-weighted prediction error, and not to a posterior belief.</p>
<p>In sum, BCV provides a principled explanation for how Bayesian inference, assigning a key role to prior expectation and uncertainty, might underlie value computation and choice. The key role of uncertainty is reflected in the precision-weighting of prediction errors. The hypothesis we entertain here is that the mechanisms postulated by BCV may be general and explain multiple forms of context effects. We have previously applied BCV to explain between-choice context effects; namely, those elicited by options presented in the past [<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>]. Here, we explore the possibility of applying the same model to within-choice effects, which arise when multiple options are available. In what follows, we will consider single and multiattribute choices under this Bayesian formalism.</p>
</sec>
<sec id="sec004">
<title>Single attribute decisions</title>
<p>Here, we apply BCV to explain within-choice contextual influences during non-multiattribute decisions. These comprise choices in which trading-off different attribute is not required, as for instance when options are defined by a single attribute. Consider first how different prior expectations <italic>μ</italic><sub><italic>C</italic></sub> (i.e., the prior expectation over the average reward of the attribute) and reward uncertainty <inline-formula id="pcbi.1005769.e023"><alternatives><graphic id="pcbi.1005769.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> affect the choice between two options characterized by a single attribute (<xref ref-type="fig" rid="pcbi.1005769.g003">Fig 3</xref>). We can examine the predicted proportion of choosing a better option (associated with high reward <italic>R</italic><sub><italic>H</italic></sub>) compared to a worse option (associated with low reward <italic>R</italic><sub><italic>L</italic></sub>), as a function of prior expectation <italic>μ</italic><sub><italic>C</italic></sub> and reward uncertainty <inline-formula id="pcbi.1005769.e024"><alternatives><graphic id="pcbi.1005769.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. Classical theories predict a flat function because they do not model an influence of the prior mean <italic>μ</italic><sub><italic>C</italic></sub> and reward uncertainty <inline-formula id="pcbi.1005769.e025"><alternatives><graphic id="pcbi.1005769.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> [<xref ref-type="bibr" rid="pcbi.1005769.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref004">4</xref>]. In contrast, BCV predicts bell-shape functions over prior expectations, that peak at the prior mean of <italic>μ</italic><sub><italic>C</italic></sub> = (<italic>R</italic><sub><italic>H</italic></sub>–<italic>R</italic><sub><italic>L</italic></sub>)/2 (<xref ref-type="fig" rid="pcbi.1005769.g003">Fig 3</xref>). In this setting, the reward uncertainty <inline-formula id="pcbi.1005769.e026"><alternatives><graphic id="pcbi.1005769.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> determines the width of the function (larger uncertainties produce narrower functions). Below, we analyse conditions where more than two options are available–and within-choice context effects come into play.</p>
<fig id="pcbi.1005769.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005769.g003</object-id>
<label>Fig 3</label>
<caption>
<title/>
<p><bold>A:</bold> Generative model involved during choice between two options (characterized by a single attribute), one associated with high reward (<italic>R</italic><sub><italic>H</italic></sub> = 10) and the other with low reward (<italic>R</italic><sub><italic>L</italic></sub> = 6). <bold>B:</bold> Proportion of choices of the better over choices of the worse option predicted by BCV (<italic>P</italic>[<italic>R</italic><sub><italic>H</italic></sub>|<italic>R</italic><sub><italic>H</italic></sub>,<italic>R</italic><sub><italic>L</italic></sub>]/<italic>P</italic>[<italic>R</italic><sub><italic>L</italic></sub>|<italic>R</italic><sub><italic>H</italic></sub>,<italic>R</italic><sub><italic>L</italic></sub>], as a function of prior expectation μ<sub><italic>C</italic></sub> and reward uncertainty <inline-formula id="pcbi.1005769.e027"><alternatives><graphic id="pcbi.1005769.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> (100000 trials are simulated for each condition; <inline-formula id="pcbi.1005769.e028"><alternatives><graphic id="pcbi.1005769.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = 1 for simulations). BCV assumes a softmax choice rule (with inverse temperature parameter equal to one for all simulations) and an equal probability for each option of being considered during the first inference step. This shows bell-shape functions where peaks correspond to a prior mean expectation of (<italic>R</italic><sub><italic>H</italic></sub>–<italic>R</italic><sub><italic>L</italic></sub>)/2 and where the reward uncertainty <inline-formula id="pcbi.1005769.e029"><alternatives><graphic id="pcbi.1005769.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> determines the width of the function (smaller uncertainties are connected with narrower functions).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005769.g003" xlink:type="simple"/>
</fig>
<p>Classical decision-making models predict that, during choice, the choice ratio between two options should not be affected by the reward associated with a third option [<xref ref-type="bibr" rid="pcbi.1005769.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref004">4</xref>]. However, a recent study has challenged this hypothesis, highlighting within-choice context effects [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>]. Adopting a choice task in which three options were available during choice, this study showed that the choice proportion between a more valuable and a less valuable target option diminished as a third option value increased towards the value of the target options (<xref ref-type="fig" rid="pcbi.1005769.g001">Fig 1A</xref>). After this point, the choice proportion started increasing (<xref ref-type="fig" rid="pcbi.1005769.g001">Fig 1A</xref>).</p>
<p>Here, we examine the implications of applying BCV in this scenario. <xref ref-type="fig" rid="pcbi.1005769.g004">Fig 4</xref> illustrates the predictions of BCV of the ratio of choices of the two target options (a better target option <italic>R</italic><sub><italic>H</italic></sub> and a worse target option <italic>R</italic><sub><italic>L</italic></sub>) as a function of the reward of a third option <italic>R</italic><sub>3</sub> and as a function of the agent’s prior belief about the average option reward <italic>μ</italic><sub><italic>C</italic></sub> and about the reward uncertainty <inline-formula id="pcbi.1005769.e030"><alternatives><graphic id="pcbi.1005769.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. This figure shows that all these variables exert an influence. First, for certain values of reward uncertainty <inline-formula id="pcbi.1005769.e031"><alternatives><graphic id="pcbi.1005769.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and prior mean <italic>μ</italic><sub><italic>C</italic></sub>, the reward of a third option <italic>R</italic><sub>3</sub> influences the choice proportion between the two target options according to a U-shape function, in a way that is consistent with empirical findings (<xref ref-type="fig" rid="pcbi.1005769.g001">Fig 1A</xref>). Second, the impact exerted by the reward of a third option <italic>R</italic><sub>3</sub> decreases as the reward uncertainty <inline-formula id="pcbi.1005769.e032"><alternatives><graphic id="pcbi.1005769.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> increases. In other words, within-choice context effects emerge only with small reward uncertainty <inline-formula id="pcbi.1005769.e033"><alternatives><graphic id="pcbi.1005769.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. This can be explained by the fact that a small <inline-formula id="pcbi.1005769.e034"><alternatives><graphic id="pcbi.1005769.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> magnifies reward prediction error (RPE), enabling contextual effects to emerge. Third, when the reward uncertainty <inline-formula id="pcbi.1005769.e035"><alternatives><graphic id="pcbi.1005769.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is sufficiently small, the prior mean <italic>μ</italic><sub><italic>C</italic></sub> comes into play. Overall, a larger prior mean <italic>μ</italic><sub><italic>C</italic></sub> increases the choice proportion between the two target options (independently of the reward of a third option <italic>R</italic><sub>3</sub>). Furthermore, the prior mean <italic>μ</italic><sub><italic>C</italic></sub> exerts a modulatory influence on the effect of the reward of a third option <italic>R</italic><sub>3</sub>, as the effect exerted by <italic>R</italic><sub>3</sub> is enhanced with a larger prior mean <italic>μ</italic><sub><italic>C</italic></sub>. Note that context effects exerted by <italic>R</italic><sub>3</sub> are obtained with <italic>μ</italic><sub><italic>C</italic></sub> = 0, which can be considered a default value for this parameter.</p>
<fig id="pcbi.1005769.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005769.g004</object-id>
<label>Fig 4</label>
<caption>
<title/>
<p><bold>A:</bold> Generative model involved during choice between two options, one associated with high reward (<italic>R</italic><sub><italic>H</italic></sub> = 10) and the other with low reward (<italic>R</italic><sub><italic>L</italic></sub> = 6) when a third option (associated with reward <italic>R</italic><sub>3</sub>) is also available [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>]. <bold>B:</bold> Proportion of choices of the better over choices of the worse option predicted by BCV (<italic>P</italic>[<italic>R</italic><sub><italic>H</italic></sub>|<italic>R</italic><sub><italic>H</italic></sub>,<italic>R</italic><sub><italic>L</italic></sub>,<italic>R</italic><sub>3</sub>]/<italic>P</italic>[<italic>R</italic><sub><italic>L</italic></sub>|<italic>R</italic><sub><italic>H</italic></sub>,<italic>R</italic><sub><italic>L</italic></sub>,<italic>R</italic><sub>3</sub>]), as a function of the third option reward <italic>R</italic><sub>3</sub> and prior expectation μ<sub><italic>C</italic></sub> (100000 trials are simulated for each condition; <inline-formula id="pcbi.1005769.e036"><alternatives><graphic id="pcbi.1005769.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = 1 for simulations). Here, the reward uncertainty <inline-formula id="pcbi.1005769.e037"><alternatives><graphic id="pcbi.1005769.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> was set to 0.1; <bold>C:</bold> The same simulation is reported except that the reward uncertainty <inline-formula id="pcbi.1005769.e038"><alternatives><graphic id="pcbi.1005769.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> was set to one. <bold>D</bold>: The same simulation is reported except that the reward uncertainty <inline-formula id="pcbi.1005769.e039"><alternatives><graphic id="pcbi.1005769.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> was set to ten.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005769.g004" xlink:type="simple"/>
</fig>
<p>Collectively, these simulations provide proof of principle that BCV can explain within-choice contextual effects in single-attribute decisions that are remarkably similar to those seen in empirical studies [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>]. In what follows, we now extend the explanatory scope of BCV to multiattribute problems.</p>
</sec>
<sec id="sec005">
<title>Multiattribute decisions</title>
<p>Empirical studies of multi-attribute decisions have highlighted three forms of effects, including the <italic>similarity</italic> [<xref ref-type="bibr" rid="pcbi.1005769.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref023">23</xref>], <italic>attraction</italic> [<xref ref-type="bibr" rid="pcbi.1005769.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref024">24</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref027">27</xref>], and <italic>compromise</italic> effect [<xref ref-type="bibr" rid="pcbi.1005769.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref027">27</xref>]. Here, we apply BCV to multi-attribute decisions and ask whether the predictions that emerge from the model reproduce the context effects found empirically. To this aim, we consider two options (e.g., the two cars A and B described above) defined by two attributes (e.g., price <italic>p</italic> and quality <italic>q</italic>). Considering the reward amounts of car A, we assign <italic>R</italic><sub><italic>p</italic>,<italic>A</italic></sub> = 1 to price (low scores indicate high price) and <italic>R</italic><sub><italic>q</italic>,<italic>A</italic></sub> = 10 to quality. Conversely, when considering the reward amounts of car B, we assign <italic>R</italic><sub><italic>p</italic>,<italic>B</italic></sub> = 10 to price and <italic>R</italic><sub><italic>q</italic>,<italic>B</italic></sub> = 1 to quality. We now consider the choice probability difference between option A and option B as a function of the reward amounts <italic>R</italic><sub><italic>p</italic>,<italic>K</italic></sub> and <italic>R</italic><sub><italic>q</italic>,<italic>K</italic></sub> of a third option K.</p>
<p>Empirical evidence is hard to reconcile with standard models of choice, which predict that the choice probability difference between option A and option B should not depend on the value of a third option K. <xref ref-type="fig" rid="pcbi.1005769.g005">Fig 5A</xref> summarises the empirical findings by plotting the probability of choosing A minus the probability of choosing B as a function of the attributes of a third option K. This graph shows conditions in which the choice probability difference is bigger or smaller than zero, illustrating both a similarity and an attraction effect. Specifically, a similarity effect favours option A when option K is good in price and bad in quality (top-left of the graph), and favours option B when option K is bad in price and good in quality (bottom-right of the graph). An attraction effect favours option A when option K is bad in price and has an average quality (bottom-middle of the graph), and favours option B when option K has an average price and is bad in quality (middle-left of the graph).</p>
<fig id="pcbi.1005769.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005769.g005</object-id>
<label>Fig 5</label>
<caption>
<title/>
<p><bold>A:</bold> Empirical evidence (derived from integrating data from available studies as in [<xref ref-type="bibr" rid="pcbi.1005769.ref019">19</xref>]) concerning the difference in probability between choosing option A and option B when a third option K is available (<italic>P</italic>[<italic>A</italic>|<italic>A</italic>,<italic>B</italic>,<italic>K</italic>] − <italic>P</italic>[<italic>B</italic>|<italic>A</italic>,<italic>B</italic>,<italic>K</italic>]). Here options are characterized by two attributes (price <italic>p</italic> and quality <italic>q</italic>). For car A, we assign <italic>R</italic><sub><italic>p</italic>,<italic>A</italic></sub> = 1 to price (low scores indicate high price) and <italic>R</italic><sub><italic>q</italic>,<italic>A</italic></sub> = 10 to quality. For car B, we assign <italic>R</italic><sub><italic>p</italic>,<italic>B</italic></sub> = 10 to price and <italic>R</italic><sub><italic>q</italic>,<italic>B</italic></sub> = 1 to quality. The graph considers the choice probability difference between option A and option B as a function of the reward amounts <italic>R</italic><sub><italic>q</italic>,<italic>K</italic></sub> (for quality; x axis) and <italic>R</italic><sub><italic>p</italic>,<italic>K</italic></sub> (for price; y axis) of a third option K. Green areas indicate values for which no difference is expected based on empirical evidence; orange and blue areas indicates values for which a positive and negative difference is expected, respectively. <bold>B:</bold> The same analysis is performed with data simulated using BCV (100000 trials are simulated for each condition; μ<sub><italic>C</italic></sub> = 0; <inline-formula id="pcbi.1005769.e040"><alternatives><graphic id="pcbi.1005769.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math></alternatives></inline-formula>; <inline-formula id="pcbi.1005769.e041"><alternatives><graphic id="pcbi.1005769.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = 1 for simulations).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005769.g005" xlink:type="simple"/>
</fig>
<p>We can now apply BCV to model choices in this scenario by analysing the influence on the choice probability (difference between option A and option B) of the prior mean <italic>μ</italic><sub><italic>C</italic></sub> (we use an equal prior mean for both attributes price and quality; formally: <italic>μ</italic><sub><italic>Cp</italic></sub> = <italic>μ</italic><sub><italic>Cq</italic></sub>), the reward uncertainty <inline-formula id="pcbi.1005769.e042"><alternatives><graphic id="pcbi.1005769.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> (we use an equal reward uncertainty for both attributes price and quality; formally: <inline-formula id="pcbi.1005769.e043"><alternatives><graphic id="pcbi.1005769.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>), and the reward amounts <italic>R</italic><sub><italic>p</italic>,<italic>K</italic></sub> and <italic>R</italic><sub><italic>q</italic>,<italic>K</italic></sub>, associated with price and quality respectively, of option K.</p>
<p><xref ref-type="fig" rid="pcbi.1005769.g005">Fig 5B</xref> illustrates the choice probability difference (between option A and option B) with prior mean <italic>μ</italic><sub><italic>C</italic></sub> = 0 and reward uncertainty <inline-formula id="pcbi.1005769.e044"><alternatives><graphic id="pcbi.1005769.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math></alternatives></inline-formula>. Focusing on areas of the graph where a similarity effect can be tested (i.e., top-left and bottom-right), we see that the similarity effect is reproduced by BCV. Moreover, focusing on areas of the graphs where an attraction effect can be tested (i.e., bottom-middle and middle-left), we can see that this effect can also be explained by BCV. Collectively, these simulations provide proof of principle that, for some sets of values of the prior mean <italic>μ</italic><sub><italic>C</italic></sub> and of the reward uncertainty <inline-formula id="pcbi.1005769.e045"><alternatives><graphic id="pcbi.1005769.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, BCV explains both a similarity and an attraction effect. Note that these effects are obtained with <italic>μ</italic><sub><italic>C</italic></sub> = 0, which can be considered a default value for this parameter.</p>
<p><xref ref-type="fig" rid="pcbi.1005769.g006">Fig 6A and 6B</xref> examines the effects of adopting other values of the prior mean <italic>μ</italic><sub><italic>C</italic></sub> (fixing the reward uncertainty <inline-formula id="pcbi.1005769.e046"><alternatives><graphic id="pcbi.1005769.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> to 0.1) in this scenario. This figure shows that an attraction effect is obtained when the prior mean <italic>μ</italic><sub><italic>C</italic></sub> is smaller (<italic>μ</italic><sub><italic>C</italic></sub> = −2 in our simulation), but no similarity effect emerges. Conversely, a similarity effect is evident when the prior mean <italic>μ</italic><sub><italic>C</italic></sub> is larger (<italic>μ</italic><sub><italic>C</italic></sub> = 2 in our simulation), but the attraction effect vanishes.</p>
<fig id="pcbi.1005769.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005769.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Predictions of BCV about the difference in probability between choosing option A and option B when a third option K is available (<italic>P</italic>[<italic>A</italic>|<italic>A</italic>,<italic>B</italic>,<italic>K</italic>] − <italic>P</italic>[<italic>B</italic>|<italic>A</italic>,<italic>B</italic>,<italic>K</italic>]).</title>
<p>Here options are characterized by two attributes (price <italic>p</italic> and quality <italic>q</italic>). For car A, we assign <italic>R</italic><sub><italic>p</italic>,<italic>A</italic></sub> = 1 to price (low scores indicate high price) and <italic>R</italic><sub><italic>q</italic>,<italic>A</italic></sub> = 10 to quality. For car B, we assign <italic>R</italic><sub><italic>p</italic>,<italic>B</italic></sub> = 10 to price and <italic>R</italic><sub><italic>q</italic>,<italic>B</italic></sub> = 1 to quality. The graph considers the choice probability difference between option A and option B as a function of the reward amounts <italic>R</italic><sub><italic>q</italic>,<italic>K</italic></sub> (for quality; x axis) and <italic>R</italic><sub><italic>p</italic>,<italic>K</italic></sub> (for price; y axis) of a third option K (100000 trials are simulated for each condition; <inline-formula id="pcbi.1005769.e047"><alternatives><graphic id="pcbi.1005769.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e047" xlink:type="simple"/><mml:math display="inline" id="M47"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = 1 for simulations). Different parameter sets are shown. <bold>A:</bold> Simulation using μ<sub><italic>C</italic></sub> = −2 and <inline-formula id="pcbi.1005769.e048"><alternatives><graphic id="pcbi.1005769.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e048" xlink:type="simple"/><mml:math display="inline" id="M48"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math></alternatives></inline-formula>. <bold>B:</bold> Simulation using μ<sub><italic>C</italic></sub> = 2 and <inline-formula id="pcbi.1005769.e049"><alternatives><graphic id="pcbi.1005769.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e049" xlink:type="simple"/><mml:math display="inline" id="M49"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math></alternatives></inline-formula>. <bold>C:</bold> Simulation using μ<sub><italic>C</italic></sub> = 0 and <inline-formula id="pcbi.1005769.e050"><alternatives><graphic id="pcbi.1005769.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e050" xlink:type="simple"/><mml:math display="inline" id="M50"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></alternatives></inline-formula>. <bold>D:</bold> Simulation using μ<sub><italic>C</italic></sub> = 0 and <inline-formula id="pcbi.1005769.e051"><alternatives><graphic id="pcbi.1005769.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math></alternatives></inline-formula>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005769.g006" xlink:type="simple"/>
</fig>
<p><xref ref-type="fig" rid="pcbi.1005769.g006">Fig 6C and 6D</xref> illustrates the choice probability difference (between option A and option B) for different values of the reward uncertainty <inline-formula id="pcbi.1005769.e052"><alternatives><graphic id="pcbi.1005769.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e052" xlink:type="simple"/><mml:math display="inline" id="M52"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> (the prior mean <italic>μ</italic><sub><italic>C</italic></sub> was fixed to zero). We can see that both similarity and attraction effects are not detectable when reward uncertainty <inline-formula id="pcbi.1005769.e053"><alternatives><graphic id="pcbi.1005769.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e053" xlink:type="simple"/><mml:math display="inline" id="M53"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is high. For smaller values of uncertainty, a similarity effect emerges but there is no attraction effect. Both effects can be obtained only when the reward uncertainty <inline-formula id="pcbi.1005769.e054"><alternatives><graphic id="pcbi.1005769.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e054" xlink:type="simple"/><mml:math display="inline" id="M54"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is sufficiently low (<xref ref-type="fig" rid="pcbi.1005769.g005">Fig 5B</xref>). This highlights the role of the reward uncertainty <inline-formula id="pcbi.1005769.e055"><alternatives><graphic id="pcbi.1005769.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e055" xlink:type="simple"/><mml:math display="inline" id="M55"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> in determining the degree of contextual effects.</p>
<p>In summary, our analyses show that, when simulating multi-attribute decisions with BCV, similarity and attraction effects emerge for appropriate values of the prior mean <italic>μ</italic><sub><italic>C</italic></sub> and the reward uncertainty <inline-formula id="pcbi.1005769.e056"><alternatives><graphic id="pcbi.1005769.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. The first parameter regulates the balance of the two effects, as an attraction effect (but no similarity effect) is obtained when the prior mean <italic>μ</italic><sub><italic>C</italic></sub> is small, while a similarity effect (but no attraction effect) is obtained when the prior mean <italic>μ</italic><sub><italic>C</italic></sub> is large. Both effects emerge for intermediate values of the prior mean <italic>μ</italic><sub><italic>C</italic></sub>, including a prior mean <italic>μ</italic><sub><italic>C</italic></sub> = 0, which is a default value for this parameter. The reward uncertainty <inline-formula id="pcbi.1005769.e057"><alternatives><graphic id="pcbi.1005769.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e057" xlink:type="simple"/><mml:math display="inline" id="M57"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> plays a key role too, because context effects vanish when this parameter is high. Decreasing levels of reward uncertainty <inline-formula id="pcbi.1005769.e058"><alternatives><graphic id="pcbi.1005769.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e058" xlink:type="simple"/><mml:math display="inline" id="M58"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> reveal a similarity effect first and then an attraction effect. These results indicate that the similarity and attraction effects arise naturally from BCV, without any <italic>ad-hoc</italic> assumptions–and under natural values of model parameters (prior mean <italic>μ</italic><sub><italic>C</italic></sub> reward uncertainty <inline-formula id="pcbi.1005769.e059"><alternatives><graphic id="pcbi.1005769.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e059" xlink:type="simple"/><mml:math display="inline" id="M59"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>).</p>
<p>A compromise effect [<xref ref-type="bibr" rid="pcbi.1005769.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref027">27</xref>] has been observed when the choice set includes two options scoring high in one attribute and low in another, in addition to a third option with intermediate scores for both attributes. Crucially, the three options are equally preferred (i.e., are chosen an equal amount of times) if presented in pairs during binary choices. However, when they are available altogether, a preference for the option characterized by intermediate scores is seen. We model this scenario by manipulating the distance between attributes for two options A and B, namely assigning <italic>R</italic><sub><italic>p</italic>,<italic>A</italic></sub> = 5 − <italic>d</italic> and <italic>R</italic><sub><italic>q</italic>,<italic>A</italic></sub> = 5 + <italic>d</italic> for option A, and <italic>R</italic><sub><italic>p</italic>,<italic>B</italic></sub> = 5 + <italic>d</italic> and <italic>R</italic><sub><italic>q</italic>,<italic>B</italic></sub> = 5 − <italic>d</italic> for option B, where the <italic>proximity parameter d</italic> varies (across simulations) from zero to four. To represent the option with intermediate scores for both the two attributes, we assign <italic>R</italic><sub><italic>p</italic>,<italic>K</italic></sub> = 5 and <italic>R</italic><sub><italic>q</italic>,<italic>K</italic></sub> = 5.</p>
<p><xref ref-type="fig" rid="pcbi.1005769.g007">Fig 7A, 7B and 7C</xref> shows the prediction of BCV using these settings during binary choices between option K and option A, using different parameters for the prior mean <italic>μ</italic><sub><italic>C</italic></sub> and the reward uncertainty <inline-formula id="pcbi.1005769.e060"><alternatives><graphic id="pcbi.1005769.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e060" xlink:type="simple"/><mml:math display="inline" id="M60"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. The results indicate that the choice probability difference is always zero, irrespective of the values of the proximity parameter <italic>d</italic> or the parameters of the model (prior mean <italic>μ</italic><sub><italic>C</italic></sub> and reward uncertainty <inline-formula id="pcbi.1005769.e061"><alternatives><graphic id="pcbi.1005769.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e061" xlink:type="simple"/><mml:math display="inline" id="M61"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>). <xref ref-type="fig" rid="pcbi.1005769.g007">Fig 7D, 7E and 7F</xref> shows the choice probability difference between option K and option A, when option B is also available. For certain values of the parameters (prior mean <italic>μ</italic><sub><italic>C</italic></sub> and reward uncertainty <inline-formula id="pcbi.1005769.e062"><alternatives><graphic id="pcbi.1005769.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e062" xlink:type="simple"/><mml:math display="inline" id="M62"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>), this difference is zero with <italic>d</italic> = 0 and increases with the proximity parameter <italic>d</italic>. This effect disappears when reward uncertainty <inline-formula id="pcbi.1005769.e063"><alternatives><graphic id="pcbi.1005769.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e063" xlink:type="simple"/><mml:math display="inline" id="M63"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is too large or when the prior mean <italic>μ</italic><sub><italic>C</italic></sub> is too small. Overall, these results show that the compromise effect emerges naturally from BCV, without any <italic>ad-hoc</italic> assumptions and under default values of the parameters (prior mean <italic>μ</italic><sub><italic>C</italic></sub> and reward uncertainty <inline-formula id="pcbi.1005769.e064"><alternatives><graphic id="pcbi.1005769.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e064" xlink:type="simple"/><mml:math display="inline" id="M64"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>). Interestingly, these simulations predict a correlation between the compromise effect and the proximity parameter <italic>d</italic>, reflecting differences between the intermediate and extreme options. This phenomenon is predicted by another model of the compromise effect [<xref ref-type="bibr" rid="pcbi.1005769.ref019">19</xref>] but remains to be validated empirically.</p>
<fig id="pcbi.1005769.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005769.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Predictions of BCV related to the compromise effect, involving option A, B and K.</title>
<p>Here, in relation with option A, we assign <italic>R</italic><sub><italic>p</italic>,<italic>A</italic></sub> = 5 − <italic>d</italic> for price and <italic>R</italic><sub><italic>q</italic>,<italic>A</italic></sub> = 5 + <italic>d</italic> for quality; in relation with option B, we assign <italic>R</italic><sub><italic>p</italic>,<italic>B</italic></sub> = 5 + <italic>d</italic> for price and <italic>R</italic><sub><italic>q</italic>,<italic>B</italic></sub> = 5 − <italic>d</italic> for quality. The proximity parameter <italic>d</italic> varies across simulations from zero to four. To represent the option K with intermediate scores for both the two attributes, we assign <italic>R</italic><sub><italic>p</italic>,<italic>K</italic></sub> = 5 and <italic>R</italic><sub><italic>q</italic>,<italic>K</italic></sub> = 5 (100000 trials are simulated for each condition; <inline-formula id="pcbi.1005769.e065"><alternatives><graphic id="pcbi.1005769.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e065" xlink:type="simple"/><mml:math display="inline" id="M65"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = 1 for simulations). <bold>A</bold>: The difference in probability between choosing option K and option A during binary choice (<italic>P</italic>[<italic>K</italic>|<italic>A</italic>,<italic>K</italic>] − <italic>P</italic>[<italic>A</italic>|<italic>A</italic>,<italic>K</italic>]). The reward uncertainty <inline-formula id="pcbi.1005769.e066"><alternatives><graphic id="pcbi.1005769.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e066" xlink:type="simple"/><mml:math display="inline" id="M66"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is set to 0.1 and different values of the prior mean μ<sub><italic>C</italic></sub> are considered. <bold>B:</bold> The same simulation is reported except that the reward uncertainty <inline-formula id="pcbi.1005769.e067"><alternatives><graphic id="pcbi.1005769.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e067" xlink:type="simple"/><mml:math display="inline" id="M67"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> was set to one. <bold>C:</bold> The same simulation is reported except that the reward uncertainty <inline-formula id="pcbi.1005769.e068"><alternatives><graphic id="pcbi.1005769.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e068" xlink:type="simple"/><mml:math display="inline" id="M68"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> was set to ten. <bold>D</bold>: The difference in probability between choosing option K and option A during choices in which option B is also available (<italic>P</italic>[<italic>K</italic>|<italic>A</italic>,<italic>B</italic>,<italic>K</italic>] − <italic>P</italic>[<italic>A</italic>|<italic>A</italic>,<italic>B</italic>,<italic>K</italic>]). The reward uncertainty <inline-formula id="pcbi.1005769.e069"><alternatives><graphic id="pcbi.1005769.e069g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e069" xlink:type="simple"/><mml:math display="inline" id="M69"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is set to 0.1 and different values of the prior mean μ<sub><italic>C</italic></sub> are considered. <bold>E:</bold> The same simulation is reported except that the reward uncertainty <inline-formula id="pcbi.1005769.e070"><alternatives><graphic id="pcbi.1005769.e070g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e070" xlink:type="simple"/><mml:math display="inline" id="M70"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> was set to one. <bold>F:</bold> The same simulation is reported except that the reward uncertainty <inline-formula id="pcbi.1005769.e071"><alternatives><graphic id="pcbi.1005769.e071g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e071" xlink:type="simple"/><mml:math display="inline" id="M71"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> was set to ten.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005769.g007" xlink:type="simple"/>
</fig>
<p>In summary, these simulations provide proof of principle that BCV predicts within-choice contextual effects during multiattribute decisions that are remarkably similar to those seen in empirical studies. In other words, the similarity, attraction and compromise effects seen empirically are all emergent properties of BCV. In the next section, we turn from within choice effects and consider between-choice context effects.</p>
</sec>
<sec id="sec006">
<title>Between-choice context effects</title>
<p>To characterize between-choice context-effects [<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>], BCV uses the same generative model as above, characterized by a prior belief <italic>μ</italic><sub><italic>C</italic></sub> (here we consider only options defined by a single attribute) over reward (with uncertainty <inline-formula id="pcbi.1005769.e072"><alternatives><graphic id="pcbi.1005769.e072g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e072" xlink:type="simple"/><mml:math display="inline" id="M72"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) and by an observation of reward amount <italic>R</italic> (with uncertainty <inline-formula id="pcbi.1005769.e073"><alternatives><graphic id="pcbi.1005769.e073g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e073" xlink:type="simple"/><mml:math display="inline" id="M73"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>). Here, the generative model is extended to include a Gaussian observation variable O that reflects contextual information provided before an option is presented (<xref ref-type="fig" rid="pcbi.1005769.g008">Fig 8A</xref>). This depends on the hidden cause <italic>C</italic> and is endowed with uncertainty <inline-formula id="pcbi.1005769.e074"><alternatives><graphic id="pcbi.1005769.e074g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e074" xlink:type="simple"/><mml:math display="inline" id="M74"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> (as for the reward amount):
<disp-formula id="pcbi.1005769.e075">
<alternatives>
<graphic id="pcbi.1005769.e075g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e075" xlink:type="simple"/>
<mml:math display="block" id="M75">
<mml:mi>O</mml:mi><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(12)</label>
</disp-formula></p>
<fig id="pcbi.1005769.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005769.g008</object-id>
<label>Fig 8</label>
<caption>
<title/>
<p><bold>A:</bold> Generative model where a contextual variable C reflects a prior expectancy of zero over the reward mean, and a noisy observation O of the context value is provided. <bold>B:</bold> Generative model where context is organized hierarchically and comprises a high level (HC; e.g., a neighbourhood) and a low level (LC; e.g., a restaurant), both associated with noisy observations (HO and LO respectively).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005769.g008" xlink:type="simple"/>
</fig>
<p>As above, we assume that an agent infers the posterior expected reward of options afforded by a given context, based on the reward amount but also now on contextual information (i.e., <inline-formula id="pcbi.1005769.e076"><alternatives><graphic id="pcbi.1005769.e076g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e076" xlink:type="simple"/><mml:math display="inline" id="M76"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>). Since the latter is provided before the option, we assume that the agent infers <inline-formula id="pcbi.1005769.e077"><alternatives><graphic id="pcbi.1005769.e077g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e077" xlink:type="simple"/><mml:math display="inline" id="M77"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> first and then <inline-formula id="pcbi.1005769.e078"><alternatives><graphic id="pcbi.1005769.e078g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e078" xlink:type="simple"/><mml:math display="inline" id="M78"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, when the option is presented. Assuming a prior mean equal to zero <italic>μ</italic><sub><italic>C</italic></sub> = 0, then:
<disp-formula id="pcbi.1005769.e079">
<alternatives>
<graphic id="pcbi.1005769.e079g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e079" xlink:type="simple"/>
<mml:math display="block" id="M79">
<mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mi>O</mml:mi>
</mml:math>
</alternatives>
<label>(13)</label>
</disp-formula></p>
<p>And the posterior uncertainty:
<disp-formula id="pcbi.1005769.e080">
<alternatives>
<graphic id="pcbi.1005769.e080g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e080" xlink:type="simple"/>
<mml:math display="block" id="M80">
<mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup>
</mml:math>
</alternatives>
<label>(14)</label>
</disp-formula></p>
<p>The mean of the posterior distribution P(C|O,R) corresponds to:
<disp-formula id="pcbi.1005769.e081">
<alternatives>
<graphic id="pcbi.1005769.e081g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e081" xlink:type="simple"/>
<mml:math display="block" id="M81">
<mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(15)</label>
</disp-formula></p>
<p>Implying the following incentive value for the option:
<disp-formula id="pcbi.1005769.e082">
<alternatives>
<graphic id="pcbi.1005769.e082g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e082" xlink:type="simple"/>
<mml:math display="block" id="M82">
<mml:mi>V</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(16)</label>
</disp-formula></p>
<p>This shows that, other things being equal, information about context (reflected in the value of O) induces subtractive value normalization. For instance, when contextual cues O supports a larger reward, <inline-formula id="pcbi.1005769.e083"><alternatives><graphic id="pcbi.1005769.e083g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e083" xlink:type="simple"/><mml:math display="inline" id="M83"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> will be larger and hence the reward prediction error (i.e., <inline-formula id="pcbi.1005769.e084"><alternatives><graphic id="pcbi.1005769.e084g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e084" xlink:type="simple"/><mml:math display="inline" id="M84"><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>) will be smaller.</p>
<p>An extension of this generative model is illustrated in <xref ref-type="fig" rid="pcbi.1005769.g008">Fig 8B</xref>, where contexts are organized hierarchically. Combining the influence of reward expectancies within a hierarchy allows the generative model to explain the impact of context at multiple levels. For instance, the value attributed to a certain dish may depend on the reward distribution associated with a restaurant (a more specific context), integrated with the reward distribution associated with a city (a more general context). In detail, a higher-level prior belief about the average reward amount of options (e.g., at the level of the neighbourhood) is represented by a Gaussian distribution with mean <italic>μ</italic><sub><italic>HC</italic></sub> equal to zero and uncertainty <inline-formula id="pcbi.1005769.e085"><alternatives><graphic id="pcbi.1005769.e085g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e085" xlink:type="simple"/><mml:math display="inline" id="M85"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, from which a value HC is sampled. Contextual information about HC is provided and represented by HO that is sampled from a Gaussian distribution with mean HC and uncertainty <inline-formula id="pcbi.1005769.e086"><alternatives><graphic id="pcbi.1005769.e086g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e086" xlink:type="simple"/><mml:math display="inline" id="M86"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. A lower-level belief about the average reward amount of options (e.g., the restaurant) is represented by a (Gaussian) distribution with mean HC and uncertainty <inline-formula id="pcbi.1005769.e087"><alternatives><graphic id="pcbi.1005769.e087g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e087" xlink:type="simple"/><mml:math display="inline" id="M87"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, from which a value LC is sampled. Contextual information about LC is provided and represented by LO, which is sampled from a Gaussian distribution with mean LC and uncertainty <inline-formula id="pcbi.1005769.e088"><alternatives><graphic id="pcbi.1005769.e088g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e088" xlink:type="simple"/><mml:math display="inline" id="M88"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. A reward is obtained and sampled from a Gaussian distribution with mean LC and uncertainty <inline-formula id="pcbi.1005769.e089"><alternatives><graphic id="pcbi.1005769.e089g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e089" xlink:type="simple"/><mml:math display="inline" id="M89"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>.</p>
<p>We propose that agents infer the posterior expectation <inline-formula id="pcbi.1005769.e090"><alternatives><graphic id="pcbi.1005769.e090g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e090" xlink:type="simple"/><mml:math display="inline" id="M90"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> P(LC|HO,LO,R) sequentially by estimating <inline-formula id="pcbi.1005769.e091"><alternatives><graphic id="pcbi.1005769.e091g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e091" xlink:type="simple"/><mml:math display="inline" id="M91"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005769.e092"><alternatives><graphic id="pcbi.1005769.e092g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e092" xlink:type="simple"/><mml:math display="inline" id="M92"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005769.e093"><alternatives><graphic id="pcbi.1005769.e093g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e093" xlink:type="simple"/><mml:math display="inline" id="M93"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and finally <inline-formula id="pcbi.1005769.e094"><alternatives><graphic id="pcbi.1005769.e094g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e094" xlink:type="simple"/><mml:math display="inline" id="M94"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>. This produces an equation for incentive value with the following form (see <xref ref-type="sec" rid="sec011">Materials and Methods</xref> for derivation):
<disp-formula id="pcbi.1005769.e095">
<alternatives>
<graphic id="pcbi.1005769.e095g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e095" xlink:type="simple"/>
<mml:math display="block" id="M95">
<mml:mi>V</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>K</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mi>O</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(17)</label>
</disp-formula></p>
<p>Three normalization factors are implicit here. The first (<italic>τ</italic><sub><italic>LO</italic></sub><italic>LO</italic>) is a subtractive normalization factor proportional to the value LO observed at the low contextual level. The second (<italic>τ</italic><sub><italic>HO</italic></sub><italic>HO</italic>) is a subtractive normalization factor proportional to the value HO observed at the high contextual level. The terms τ represent gain-dependent effects and describe the relative precision of information conveyed by the low-level (<italic>τ</italic><sub><italic>LO</italic></sub>) and high-level (<italic>τ</italic><sub><italic>HO</italic></sub>) observations. Finally, a third factor (K) implements divisive normalization and depends on a gain term which includes reward uncertainty (see <xref ref-type="sec" rid="sec011">Materials and Methods</xref> for details).</p>
<p>In recent studies [<xref ref-type="bibr" rid="pcbi.1005769.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>], we have investigated the nature of contextual influence on incentive value that depends on reward expectations established before choice presentation (between-choice effects). In these studies, we have used a simple decision-making task, where participants had to repeatedly choose between a sure monetary reward and a fifty-fifty gamble. These options comprised double the sure monetary reward and a zero outcome, ensuring that the two options had equivalent expected reward or value (EV). Across blocks, we manipulated the distribution of EVs, such that these distributions overlapped. We analysed choice behaviour with EVs common to both contexts to examine whether incentive value attributed to the objective EV changed according to BCV predictions.</p>
<p>In one experiment (<xref ref-type="fig" rid="pcbi.1005769.g009">Fig 9A and 9B</xref>; [<xref ref-type="bibr" rid="pcbi.1005769.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref009">9</xref>]), in different blocks, the sure monetary gain was drawn from one of two distinct, but partially overlapping, distributions of rewards (low-average and high-average context). Choice behaviour was consistent with attributing a larger incentive value to common EVs in the low average compared to high-average context. This and similar evidence [<xref ref-type="bibr" rid="pcbi.1005769.ref005">5</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref050">50</xref>] suggests that incentive values are, to some extent, rescaled to the average reward expected in a given context, such that they increase (resp. decrease) with smaller (resp. larger) average reward expectations.</p>
<fig id="pcbi.1005769.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005769.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Between-choice effects (predicted by BCV) that depend on contexts with different averages.</title>
<p>Contexts are associated with certain distribution of rewards presented sequentially over trials (arranged in blocks for each context). <bold>A:</bold> Example with a single hierarchical level, where two contexts have different average rewards. In blocks associated with a low-average context (LA; in lighter grey), possible rewards are x, x+1 and x+2; in blocks associated with a high-average context (HA; in darker grey), possible rewards are x+1, x+2 and x+3. <bold>B:</bold> BCV prediction of the incentive value attributed to rewards depending on these contexts. Larger values are predicted in the LA compared to the HA for amounts common to both contexts. <bold>C:</bold> Effects predicted by BCV dependent on contexts with different variance. In blocks associated with a high-variance context (HV; in lighter grey), possible rewards are x, x+1 x+2 and x+3; in blocks associated with a low-variance context (LV; in darker grey), possible rewards are x+1 and x+2. <bold>D:</bold> BCV prediction of the incentive value attributed to rewards depending on these contexts. Considering rewards common to both contexts, BCV predicts higher incentive value for x+1 in the high-variance context and for x+2 in the low-variance context. <bold>E:</bold> Example with two hierarchical levels (low-level (LL) contexts, represented by filled rectangles, and high-level (HL) contexts, represented by frames). Blocks associated with HL contexts comprise several sub-blocks associated with LL contexts having specific average reward. In the HL context with low-value (HL-LA; light frame), a LL context with low average (LL-LA, where rewards are x, x+1 and x+2) and a LL context with medium average (LL-MA, where rewards are x+1, x+2 and x+3) alternate. In the HL context with high-value (HL-HA; dark frame), a LL-MA context and a LL context with high average (LL-HA, where rewards are x+2, x+3 and x+4) alternate. <bold>F:</bold> BCV prediction of the incentive value attributed to rewards depending on these contexts. The fill colour of bars represent the LL context condition, the outline colour represent the HL context condition. BCV predicts that incentive values derive from integrating both hierarchical levels, with larger values emerging when average reward is lower at both context levels.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005769.g009" xlink:type="simple"/>
</fig>
<p>These data fit within predictions of BCV. In addition, BCV postulates a between-choice influence of expected reward variance on incentive values (<xref ref-type="fig" rid="pcbi.1005769.g009">Fig 9C and 9D</xref>). In a recent study [<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>], we used the same gambling task described above and manipulated contextual variance on two levels; one associated with blocks where two target trial EVs were presented (low-variance context), and another with blocks where the same two target trial EVs plus a larger and a smaller EV were presented (high-variance context). Crucially, this ensured that the two contexts had equivalent average reward but different variance. BCV predicts that the incentive value of the smaller target trial EV will be lower in the low-variance compared to the high-variance context, and the incentive value of the larger target trial EV will be higher in the low-variance compared to the high-variance context. In other words, BCV predicts a larger value difference between the two target trial EV in the low compared to high-variance context. This derives from the gain term, which depends on contextual reward variance. Specifically, low variance magnifies the reward prediction error and hence further reduces the value of rewards that are lower than expected and enhances the value of rewards that are larger than expected. We have previously provided data that are consistent with this prediction [<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>].</p>
<p>This latter study supports the hypothesis that between-choice reward variance influences incentive value consistent with BCV. In the same study (<xref ref-type="fig" rid="pcbi.1005769.g009">Fig 9E and 9F</xref>; [<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>]), we also reported that between-choice context effects can be expressed at different hierarchical levels, in line with predictions of BCV. Participants played a computer-based task, where two decks of cards (representing a low-level context) appeared. Each card was associated with a monetary reward, and decks contained cards with different average rewards. A card was drawn from a selected deck and participants had to choose between half of the card reward for sure and a gamble between the full reward and a zero outcome, each with 50% chance. Two sets of decks (representing a high-level context) alternated in a pseudo-random way. The empirical data showed that the lowest incentive values were attributed when both high-value decks and deck-sets were simultaneously presented, while the highest incentive values were attributed when low-value decks and deck-sets were simultaneously presented. Intermediate incentive values were attributed when decks and deck-sets had one high value and the other low value.</p>
<p>Collectively, these empirical studies provide evidence consistent with between-choice contextual effects on incentive value that depends on beliefs about the average reward and variance expected across choices at multiple hierarchical levels. Furthermore, the empirical findings endorse the predictions derived from BCV.</p>
</sec>
</sec>
<sec id="sec007" sec-type="conclusions">
<title>Discussion</title>
<p>We advance BCV as a unifying theory of contextual effects in value-based choice under the normative principles of Bayesian statistics. BCV assumes that the brain calls on Bayesian inference to invert a generative model and compute (independently for each attribute) the average reward based on observing different reward amounts of options that are available in a given context. Our key proposal is that incentive value emerges during this inferential process, and corresponds to a precision-weighted reward prediction error. Here, we show that these principles are sufficient to explain a wide range of between-choice and within-choice contextual influences; in the latter case encompassing both single and multiattribute effects. To our knowledge, this is the first time a theory has been applied to the full range of context effects.</p>
<p>An important advantage of BCV is its grounding in normative principles of Bayesian statistics [<xref ref-type="bibr" rid="pcbi.1005769.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref037">37</xref>]. Several arguments have been made in support of a Bayesian approach. These are based on a formal and clear definition of the functions that motivate cognitive processes, which are formulated as Bayesian inference and learning. This allows BCV to establish a direct link with Bayesian schemes in other domains–a step towards formulating a unifying theory of brain function. Remarkably, we show that the same basic processes postulated by BCV can be applied to a wide range of conditions in which contextual effects on value and choice are involved. Beyond explaining the available empirical evidence, this scheme can generate new hypotheses (see below). Indeed one of our previous studies [<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>] was motivated by testing predictions arising out of our initial formulations of BCV.</p>
<p>BCV is associated with planning as inference and active inference [<xref ref-type="bibr" rid="pcbi.1005769.ref040">40</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref045">45</xref>]. The basic idea is that an agent considers the rewards on offer as samples drawn from a population. The latter is not known directly, but can be inferred based on the rewards on offer. Heuristically, agents are interested in inferring how much reward is available on a given trial, which they estimate by combining prior expectations with observations of available rewards. On this view, agents primarily aim to <italic>infer</italic>–and not maximize–the reward; implying that utility-maximization is an emergent process. We argue that an advantage of this perspective is that it offers a normative interpretation of contextual effects, which emerge from the inferential treatment offered here.</p>
<p>Although our theoretical treatment is grounded in Bayesian inference one might argue that the Bayesian gloss is unnecessary to understand the particular inferential mechanisms we have called upon [<xref ref-type="bibr" rid="pcbi.1005769.ref051">51</xref>]. To a certain extent, there is tautology in Bayesian explanations for behaviour. This follows from the complete class theorem (i.e., for every loss function and behaviour there is a prior belief that renders the behaviour Bayes optimal) [<xref ref-type="bibr" rid="pcbi.1005769.ref052">52</xref>]. In other words, in principle, everything is Bayes optimal under some priors. This means that the interesting questions reduce to the form of prior beliefs that constitute a subject’s generative model. Our focus has been on the form of these models and the particular role of precision weighting in belief updating and choice. The results of our analysis are consistent with empirical data on several forms of context effect, and hence may contribute to a clarification of the computational principles at play.</p>
<p>In BCV incentive value, and in turn choice behaviour, emerges from Bayesian belief updating. Under continuous state space models of the hidden causes of reward values, belief updates and incentive value can be cast as precision-weighted (reward) prediction error. A possibility consistent with BCV is that action is steered by (precision-weighted) prediction errors and is oriented to error cancellation, with approach and avoidance responses elicited by positive and negative prediction errors, respectively. The crucial role of prediction error highlights a perspective in which incentive value is inherently <italic>relative</italic> with respect to reward expectation. Eliciting approach and avoidance behaviour in response to positive and negative prediction errors can be conceived as a basic error-cancellation process (crystallized during evolution of biological organisms), which is a core tenet of active inference schemes.</p>
<p>BCV postulates that the two fundamental determinants of incentive value are prediction error and relative precision. A prediction error is determined by the difference between the observed and expected reward which, in BCV, derives from integrating different expectations under contextual uncertainty. Relative precision depends on the (relative) precision or prior confidence–and ensures that the prediction error is normalised and (Bayes) optimally weighted in relation to uncertainty about both context and reward cues. BCV predicts precision exerts an influence in two ways. First, at high hierarchical levels, precision determines the optimal integration of multiple contextual representations–as it mandates that contexts characterized by a high precision (greater reliability) will exert more influence on reward expectancy. For instance, if we assume that subjects have very precise beliefs about the low-level context (e.g., the card deck in the final experiment on between-choice context effects), then the effect of the high-level (e.g., the deck set) will disappear. Formally, this is because in the hierarchical model the low-level context constitutes a Markov blanket for the posterior expectation about the reward option (Bishop, 2006). In other words, the effect of the high-level context tells us that if subjects are using a hierarchical model, there must be posterior uncertainty about the low-level context. Heuristically, even though they can see which deck they are currently playing with, they still nuance their expectations about this deck based upon the deck-set from which it came. Second, at the lowest hierarchical level, precision determines the gain assigned to the prediction error and hence is a direct determinant of incentive value.</p>
<p>Within BCV, the ratio between reward uncertainty and prior uncertainty determines the gain term (or relative precision) which is used for belief updating (see <xref ref-type="disp-formula" rid="pcbi.1005769.e011">Eq 6</xref>). This means that manipulating the prior uncertainty produces exactly opposite effects compared to manipulating the reward uncertainty, meaning that varying one during simulations is sufficient for testing the predictions of the model (above, we manipulated reward uncertainty and kept the prior uncertainty constant). Thus BCV has only two parameters; namely, the prior mean and reward uncertainty. The role of the latter is straightforward, as context effects are allowed only with small reward uncertainty, and the size of these effects decreases with this reward uncertainty. The role of the prior mean is more complex: for instance, a large prior mean permits a similarity effect but interferes with an attraction effect, while a small prior mean allows an attraction effect but interferes with a similarity effect. Notably, all contextual effects are expressed when setting the prior reward expectation to zero, which can be considered the default value. In short, relying on only two parameters endows BCV with simplicity and constrains the predictions that can be derived, making BCV easy to validate or falsify (see below).</p>
<sec id="sec008">
<title>Comparison with other models</title>
<p>We have shown that the principles underlying BCV can explain a wide range of empirical findings on the context sensitivity of value-based choice. Several previous accounts have focused on a single context effect, especially during multiattribute decisions. Some models have been developed explicitly for explaining the similarity effect [<xref ref-type="bibr" rid="pcbi.1005769.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref053">53</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref055">55</xref>], other models for explaining the attraction effect [<xref ref-type="bibr" rid="pcbi.1005769.ref056">56</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref057">57</xref>], and other models for the compromise effect [<xref ref-type="bibr" rid="pcbi.1005769.ref027">27</xref>]. However, a shortcoming of these models is their inability to explain all three effects within a single formal framework. More recently, adopting connectionist architectures, the multi-alternative decision field theory [<xref ref-type="bibr" rid="pcbi.1005769.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref058">58</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref059">59</xref>] and the leaky competing accumulator [<xref ref-type="bibr" rid="pcbi.1005769.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref059">59</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref060">60</xref>] have been able to reproduce all three effects (see also [<xref ref-type="bibr" rid="pcbi.1005769.ref061">61</xref>]). The first model [<xref ref-type="bibr" rid="pcbi.1005769.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref058">58</xref>] is based on a process modelling attentional switches across attributes and a comparator mechanism which, for the attribute under attention, computes the difference between the reward of each option and the mean reward across options. The second model [<xref ref-type="bibr" rid="pcbi.1005769.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref059">59</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref060">60</xref>] is similar, except that the comparator applies a non-linear asymmetric (loss-averse) value function to the difference. Although these models fit remarkably with empirical literature and shed light on the neural mechanisms underlying choice, we argue that BCV presents several advantages. First, it is based on normative principles of Bayesian inference. This constrains the model in terms of empirical predictions. In other words, the similarity, attraction and compromise effect are implicit in the way the model works. In fact, these effects arise when defaults parameters are used. Second, BCV is a more parsimonious model; as the number of free parameters is much lower (essentially, the prior mean and the reward uncertainty). Third, without any further assumptions, BCV applies to a wider range of phenomena including single-attribute decisions and also accounts for between-context effects. Overall, while previous connectionist models are informative especially at the implementation level, BCV helps clarify context sensitivity at the algorithmic and computational level.</p>
<p>The concept of <italic>wealth</italic> in expected utility theory [<xref ref-type="bibr" rid="pcbi.1005769.ref003">3</xref>] and <italic>status quo</italic> in prospect theory [<xref ref-type="bibr" rid="pcbi.1005769.ref062">62</xref>] have been recently re-casted in terms of average expected reward [<xref ref-type="bibr" rid="pcbi.1005769.ref029">29</xref>]. This formulation opens the possibility of context effects dependent on changes in reward expectation. In line with this view, empirical evidence indicates a between-choice context effect that depends on the average contextual reward (as for example inferred from past choices), consisting in attributing larger incentive values in contexts characterized by lower reward. A similar idea has inspired decision by sampling theory [<xref ref-type="bibr" rid="pcbi.1005769.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref031">31</xref>], which evokes a few basic cognitive processes to explain choice behaviour. According to this model, each choice option elicits retrieval from memory (in the form of random sampling) of stimuli encountered in the past, especially those associated with the current context. A set of binary comparisons follows between the option and the samples, and the number of comparisons in which the option is favoured over each sample is recorded. This number corresponds to the incentive value of the option and is computed for all options available, hence determining their relative preference. Since samples are drawn from memory, they depend on past experience and therefore reflect the distribution of options and outcomes characterizing the environment of an agent. This model can account for an attribution of larger incentive value to the same reward in contexts where lower compared to higher reward is expected before options are provided. This effect is explained by a decreased likelihood, in the former compared to the latter context, of sampling stimuli from memory that are preferred to rewards common to both contexts (assuming a recency effect in memory sampling; [<xref ref-type="bibr" rid="pcbi.1005769.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref031">31</xref>]. BCV extends these views by appealing explicitly to Bayesian principles (i.e. Bayesian belief updating and evidence accumulation), with implications for empirical predictions. For instance, contrary to BCV and empirical findings, it remains unclear whether these previous models can account for between-choice contextual influence of reward variance or any within-choice contextual effects.</p>
<p>Divisive normalization theory [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref063">63</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref068">68</xref>] has been proposed recently to explain both between-choice and within-choice contextual effects during single attribute decisions. Divisive normalisation was first proposed in the sensory domain to explain phenomena such as neural adaptation within the retina to stimuli of varying intensity [<xref ref-type="bibr" rid="pcbi.1005769.ref063">63</xref>]. There is evidence that similar principles can explain higher-order cognitive processes, such as selective attention and perceptual decision-making [<xref ref-type="bibr" rid="pcbi.1005769.ref063">63</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref069">69</xref>]. Recently, divisive normalisation has been extended to contextual adaptation effects in value-guided choice [<xref ref-type="bibr" rid="pcbi.1005769.ref006">6</xref>], and proposes that incentive value corresponds to the reward divided by the average reward of past or current choices. This can explain contextual influences elicited both within-choice effects during non-multiattribute decisions and between-choice effects that depend on the average contextual reward. Though this scheme relies on a normalization scheme similar to BCV, different empirical predictions arise. It remains unclear whether this divisive normalization scheme is able to explain between-choice effects deriving from reward variance, and can explain data on multi-attribute choices. In addition, BCV, but not divisive normalization theory, is based on normative principles of Bayesian statistics. However, an attractive aspect of divisive normalization theory is the explicit connection with mechanisms characterizing biological neural processes [<xref ref-type="bibr" rid="pcbi.1005769.ref063">63</xref>]. A similar connection can be motivated for BCV, given several proposals showing how Bayesian inference (the framework of BCV) is compatible with neuronal processes [<xref ref-type="bibr" rid="pcbi.1005769.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref070">70</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref071">71</xref>].</p>
<p>The manner in which BCV conceptualizes incentive value is similar to recent economic models that postulate incentive value is adapted to the statistics of the expected reward distribution [<xref ref-type="bibr" rid="pcbi.1005769.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref030">30</xref>]. These theories can be broadly classified into those based on subtractive normalization, which assume that incentive value corresponds to the reward minus a reference value [<xref ref-type="bibr" rid="pcbi.1005769.ref029">29</xref>], and those based on divisive normalization, assuming that incentive value corresponds to the reward divided (or multiplied) by the range of an expected distribution of rewards [<xref ref-type="bibr" rid="pcbi.1005769.ref030">30</xref>]. An important difference between BCV and these theories is the derivation of the former but not the latter from normative assumptions of Bayesian inference. From Bayesian belief updating, BCV derives the proposition that incentive value corresponds to precision-weighted prediction error, hence implying both a subtractive normalization to the expected reward and a divisive normalization with respect to the reward uncertainty. Importantly, these predictions are not <italic>ad hoc</italic> but derive from Bayesian assumptions, distinguish BCV from other models, and have been recently supported empirically [<xref ref-type="bibr" rid="pcbi.1005769.ref011">11</xref>]. In addition, while these recent economic models focus on between-choice context effects, BCV is more general as it can reproduce within-choice effects in both single and multiattribute decisions.</p>
<p>Like BCV, a recent proposal has interpreted multi-attribute within-choice effects based on the notion that perception of reward is stochastic [<xref ref-type="bibr" rid="pcbi.1005769.ref072">72</xref>]. The idea is that, for each attribute, an agent forms noisy observations of reward amounts and of the ordinal positions of the reward amounts. Multi-attribute effects can then be obtained by integrating these two observations [<xref ref-type="bibr" rid="pcbi.1005769.ref072">72</xref>]. Though there are analogies between BCV and the model of Howes et al. [<xref ref-type="bibr" rid="pcbi.1005769.ref072">72</xref>], we emphasize several important differences. First, the latter does not employ a Bayesian framework, since it is not based on integrating prior beliefs and observations, nor it is based on optimal weighting of different sources of information (as in multi-sensory integration). Second, the model of Howes et al. [<xref ref-type="bibr" rid="pcbi.1005769.ref072">72</xref>] has been applied to aspects of multi-attribute effects (such as the impact on reaction times), which remain to be explored with BCV. On the other hand, the model of Howes et al., [<xref ref-type="bibr" rid="pcbi.1005769.ref072">72</xref>] remains to be explored in relation to within-choice effects involving a single attribute and in relation to between-choice effects.</p>
</sec>
<sec id="sec009">
<title>Predictions and limitations of BCV</title>
<p>Specific empirical predictions can be derived from BCV, and here we highlight some of these. Standard economic theories assume that choice should be independent of whether options are presented simultaneously or sequentially. However, the latter case remains largely to be investigated. BCV may inspire this investigation, as it predicts that a higher value will be attributed to an option after presentation of lower value options. This because BCV proposes a sequential belief updating in which options considered so far contextualize the option observed now. Other predictions involve interactions regarding between- and within-choice effects. For example, consider the example above in which an agent usually evaluates equally car A (expensive and high quality) and car B (cheap and low quality). One may design an experiment where participants are first exposed to a set of cars having a fixed level of quality and varying on price. BCV predicts that this manipulation would determine a lower reward uncertainty for quality compared to price. In other words, quality would become more salient than price, predicting a preference for car A over car B. In addition, BCV predicts other forms of interactions regarding between- and within-choice effects dependent on manipulations of the reward uncertainty and the prior mean (see above), which also remain to be explored empirically. Finally, BCV may be relevant for research on the neural underpinnings of decision-making. A main aspect of this theory is the idea that incentive value corresponds to a precision-weighted reward prediction error. Interestingly, reward prediction error is reflected in activity of brain regions involved in reward processing [<xref ref-type="bibr" rid="pcbi.1005769.ref073">73</xref>]. BCV raises the possibility that a stimulus which elicits a stronger prediction error response in the brain will be attributed a higher incentive value.</p>
<p>There are shortcomings to BCV, though we argue that the same framework may be fruitfully used to address some of these shortcomings. A shortcoming of our current formulation assumes that model parameters are given. In reality, these parameters need to be learned in the first place. Questions about the mechanisms that might underpin learning of generative models adopted for Bayesian inference are still largely open, though substantial contributions exist, particularly in the context of structure learning [<xref ref-type="bibr" rid="pcbi.1005769.ref074">74</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref080">80</xref>]. A second shortcoming is that here we have assumed that choices occur after inference has considered all observations. An important extension of BCV is a consideration that action tendencies actually develop during evidence accumulation, and this speaks to models of choice that focus on action dynamics, sequential policy optimisation and reaction times [<xref ref-type="bibr" rid="pcbi.1005769.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref047">47</xref>]. Another important extension of BCV would be to generalize to domains outside incentive value computation. Context effects similar to those observed in value-based decision-making have been reported in many other conditions during perception and judgement [<xref ref-type="bibr" rid="pcbi.1005769.ref081">81</xref>–<xref ref-type="bibr" rid="pcbi.1005769.ref084">84</xref>]. Notably, multi-attribute context effects have been recently shown outside incentive value computation [<xref ref-type="bibr" rid="pcbi.1005769.ref085">85</xref>, <xref ref-type="bibr" rid="pcbi.1005769.ref086">86</xref>], suggesting that they may derive from a general way in which the brain works [<xref ref-type="bibr" rid="pcbi.1005769.ref061">61</xref>].</p>
</sec>
<sec id="sec010">
<title>Conclusions</title>
<p>We offer BCV as a unifying theory of contextual effects during choice behaviour based on Bayesian normative principles. BCV predictions are in line with available empirical evidence about context sensitivity seen empirically both within and between-choice. These different effects are explained using the same simple set of principles, invoking minimal assumptions. We argue that strengths of this model are its foundation on normative principles, simplicity, the link with other influential models of brain function, and the ability to explain a wide range of empirical data. This theory may help clarify the nature of incentive value attribution and choice behaviour. This is particularly prescient when trying to understand ecological phenomena and psychopathologies characterized by dysfunctional choice, such as addiction.</p>
</sec>
</sec>
<sec id="sec011" sec-type="materials|methods">
<title>Materials and methods</title>
<p>Here we derive <xref ref-type="disp-formula" rid="pcbi.1005769.e095">Eq 17</xref> from the generative model shown in <xref ref-type="fig" rid="pcbi.1005769.g009">Fig 9B</xref>. A higher-level contextual variable (e.g., a neighbourhood containing several restaurants) is represented by a Gaussian distribution with mean <italic>μ</italic><sub><italic>HC</italic></sub> equal to zero and uncertainty <inline-formula id="pcbi.1005769.e096"><alternatives><graphic id="pcbi.1005769.e096g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e096" xlink:type="simple"/><mml:math display="inline" id="M96"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, from which a value HC is sampled. Sensory evidence about HC is provided and represented by HO which is sampled from a Gaussian distribution with mean HC and uncertainty <inline-formula id="pcbi.1005769.e097"><alternatives><graphic id="pcbi.1005769.e097g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e097" xlink:type="simple"/><mml:math display="inline" id="M97"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. A lower-level contextual variable (e.g., one of the restaurants) is represented by a (Gaussian) distribution with mean HC and uncertainty <inline-formula id="pcbi.1005769.e098"><alternatives><graphic id="pcbi.1005769.e098g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e098" xlink:type="simple"/><mml:math display="inline" id="M98"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, from which a value LC is sampled. Sensory evidence about LC is provided and represented by LO, which is sampled from a Gaussian distribution with mean LC and uncertainty <inline-formula id="pcbi.1005769.e099"><alternatives><graphic id="pcbi.1005769.e099g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e099" xlink:type="simple"/><mml:math display="inline" id="M99"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. A reward is obtained and sampled from a Gaussian distribution with mean LC and uncertainty <inline-formula id="pcbi.1005769.e100"><alternatives><graphic id="pcbi.1005769.e100g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e100" xlink:type="simple"/><mml:math display="inline" id="M100"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. The posterior distribution P(LC|HO,LO,R) can be inferred sequentially in the order P(HC|HO), P(LC|HO), P(LC|HO,LO), and P(LC|HO,LO,R). The posterior mean of P(HC|HO) is:
<disp-formula id="pcbi.1005769.e101">
<alternatives>
<graphic id="pcbi.1005769.e101g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e101" xlink:type="simple"/>
<mml:math display="block" id="M101">
<mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mi>H</mml:mi><mml:mi>O</mml:mi>
</mml:math>
</alternatives>
<label>(18)</label>
</disp-formula></p>
<p>And the posterior uncertainty:
<disp-formula id="pcbi.1005769.e102">
<alternatives>
<graphic id="pcbi.1005769.e102g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e102" xlink:type="simple"/>
<mml:math display="block" id="M102">
<mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup>
</mml:math>
</alternatives>
<label>(19)</label>
</disp-formula></p>
<p>The posterior mean of P(LC|HO) is equal to <inline-formula id="pcbi.1005769.e103"><alternatives><graphic id="pcbi.1005769.e103g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e103" xlink:type="simple"/><mml:math display="inline" id="M103"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> (<inline-formula id="pcbi.1005769.e104"><alternatives><graphic id="pcbi.1005769.e104g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e104" xlink:type="simple"/><mml:math display="inline" id="M104"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>), while the posterior uncertainty is:
<disp-formula id="pcbi.1005769.e105">
<alternatives>
<graphic id="pcbi.1005769.e105g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e105" xlink:type="simple"/>
<mml:math display="block" id="M105">
<mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup>
</mml:math>
</alternatives>
<label>(20)</label>
</disp-formula></p>
<p>The posterior mean of P(LC|HO,PO) is:
<disp-formula id="pcbi.1005769.e106">
<alternatives>
<graphic id="pcbi.1005769.e106g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e106" xlink:type="simple"/>
<mml:math display="block" id="M106">
<mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(21)</label>
</disp-formula></p>
<p>And the posterior uncertainty:
<disp-formula id="pcbi.1005769.e107">
<alternatives>
<graphic id="pcbi.1005769.e107g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e107" xlink:type="simple"/>
<mml:math display="block" id="M107">
<mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup>
</mml:math>
</alternatives>
<label>(22)</label>
</disp-formula></p>
<p>The posterior mean of P(LC|HO,LO,R) is:
<disp-formula id="pcbi.1005769.e108">
<alternatives>
<graphic id="pcbi.1005769.e108g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e108" xlink:type="simple"/>
<mml:math display="block" id="M108">
<mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(23)</label>
</disp-formula></p>
<p>Finally, with few rearrangements, we obtain the following incentive value for a reward offer:
<disp-formula id="pcbi.1005769.e109">
<alternatives>
<graphic id="pcbi.1005769.e109g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e109" xlink:type="simple"/>
<mml:math display="block" id="M109">
<mml:mi>V</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mi>L</mml:mi><mml:mi>O</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(24)</label>
</disp-formula></p>
<p>This equation implements three normalization factors: (i) a subtractive normalization factor <inline-formula id="pcbi.1005769.e110"><alternatives><graphic id="pcbi.1005769.e110g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e110" xlink:type="simple"/><mml:math display="inline" id="M110"><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mi>L</mml:mi><mml:mi>O</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> proportional to the value LO observed at the low contextual level, (ii) a subtractive normalization factor <inline-formula id="pcbi.1005769.e111"><alternatives><graphic id="pcbi.1005769.e111g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e111" xlink:type="simple"/><mml:math display="inline" id="M111"><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> proportional to the value HO observed at the high contextual level, (iii) a divisive normalization factor <inline-formula id="pcbi.1005769.e112"><alternatives><graphic id="pcbi.1005769.e112g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005769.e112" xlink:type="simple"/><mml:math display="inline" id="M112"><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> that captures the weighting dependent on the (relative) reward uncertainty. If we define the three factors as <italic>τ</italic><sub><italic>LO</italic></sub> and <italic>τ</italic><sub><italic>HO</italic></sub> and K respectively, we obtain <xref ref-type="disp-formula" rid="pcbi.1005769.e095">Eq 17</xref>.</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1005769.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bernoulli</surname> <given-names>D</given-names></name>. <article-title>Specimen theoriae novae de mensura sortis (Exposition of a new theory on the measurement of risk)</article-title>. <source>Comentarii Acad. Scient. Petropolis</source> (translated in Econometrica). <year>1738</year>; <volume>5</volume>: <fpage>23</fpage>–<lpage>36</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Luce</surname> <given-names>RD</given-names></name>. <article-title>On the possible psychophysical laws</article-title>. <source>Psychol Rev</source>. <year>1959</year>; <volume>66</volume>: <fpage>81</fpage>. <object-id pub-id-type="pmid">13645853</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref003"><label>3</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>von Neumann</surname> <given-names>J</given-names></name>, <chapter-title>Morgenstern 0</chapter-title>. <source>Theory of Games and Economic Behavior</source>. <year>1944</year>; <publisher-loc>Princeton</publisher-loc>: <publisher-name>Princeton UP</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vlaev</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Stewart</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>GD</given-names></name>. <article-title>Does the brain calculate value?</article-title>. <source>Trends Cogn Sci</source>, <year>2011</year>, <volume>15</volume>: <fpage>546</fpage>–<lpage>554</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2011.09.008" xlink:type="simple">10.1016/j.tics.2011.09.008</ext-link></comment> <object-id pub-id-type="pmid">21983149</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ludvig</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Madan</surname> <given-names>CR</given-names></name>, <name name-style="western"><surname>Spetch</surname> <given-names>ML</given-names></name>. <article-title>Extreme outcomes sway risky decisions from experience</article-title>. <source>J Behav Decis Mak</source>. <year>2013</year>;</mixed-citation></ref>
<ref id="pcbi.1005769.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Louie</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Khaw</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>. <article-title>Normalization is a general neural mechanism for context-dependent decision making</article-title>. <source>Proc Natl Acad Sci U S</source>. <year>2013</year>; <volume>110</volume>: <fpage>6139</fpage>–<lpage>6144</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Morgan</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Hurly</surname> <given-names>TA</given-names></name>, <name name-style="western"><surname>Bateson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Asher</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Healy</surname> <given-names>SD</given-names></name>. <article-title>Context-dependent decisions among options varying in a single dimension</article-title>. <source>Behav Process</source>. <year>2012</year>; <volume>89</volume>:, <fpage>115</fpage>–<lpage>120</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Rutledge</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>The influence of contextual reward statistics on risk preference</article-title>. <source>NeuroImage</source>. <year>2016</year>; <volume>128</volume>: <fpage>74</fpage>–<lpage>84</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2015.12.016" xlink:type="simple">10.1016/j.neuroimage.2015.12.016</ext-link></comment> <object-id pub-id-type="pmid">26707890</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Rutledge</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Chew</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Ousdal</surname> <given-names>OT</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Dopamine Increases a Value-Independent Gambling Propensity</article-title>. <source>Neuropsychopharmacolog</source>. <year>2016</year>; <volume>41</volume>: <fpage>2658</fpage>–<lpage>2667</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Neural processes mediating contextual influences on human choice behaviour</article-title>. <source>Nat Commun</source>. <year>2016</year>; <volume>7</volume>, <fpage>12416</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ncomms12416" xlink:type="simple">10.1038/ncomms12416</ext-link></comment> <object-id pub-id-type="pmid">27535770</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Martinelli</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Selaković</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Shergill</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>A Bayesian model of context-sensitive value attribution</article-title>. <source>eLife</source>. <year>2016</year>; <volume>5</volume>, <fpage>e16127</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.16127" xlink:type="simple">10.7554/eLife.16127</ext-link></comment> <object-id pub-id-type="pmid">27328323</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simonsohn</surname> <given-names>U</given-names></name>. <article-title>New Yorkers commute more everywhere: contrast effects in the field</article-title>. <source>Rev Econ Stat</source>. <year>2006</year>; <volume>88</volume>: <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simonsohn</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Loewenstein</surname> <given-names>G</given-names></name>. <article-title>Mistake# 37: The Effect of Previously Encountered Prices on Current Housing Demand*</article-title>. <source>Econ J</source>. <year>2006</year>; <volume>116</volume>: <fpage>175</fpage>–<lpage>199</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stewart</surname> <given-names>N</given-names></name>. <article-title>Decision by sampling: The role of the decision environment in risky choice</article-title>. <source>Q J Exp Psychol</source>. <year>2009</year>; <volume>62</volume>: <fpage>1041</fpage>–<lpage>1062</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huber</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Payne</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Puto</surname> <given-names>C</given-names></name>. <article-title>Adding asymmetrically dominated alternatives: Violations of regularity and the similarity hypothesis</article-title>. <source>J Cons Res</source>. <year>1982</year>; <volume>43</volume>: <fpage>90</fpage>–<lpage>98</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Roe</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Busemeyer</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Townsend</surname> <given-names>JT</given-names></name>. <article-title>Multialternative decision field theory: A dynamic connectionst model of decision making</article-title>. <source>Psychol Rev</source>. <year>2001</year>; <volume>108</volume>: <fpage>370</fpage>. <object-id pub-id-type="pmid">11381834</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simonson</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Tversky</surname> <given-names>A</given-names></name>. <article-title>Choice in context: Tradeoff contrast and extremeness aversion</article-title>. <source>J Mark Res</source>, <year>1992</year>; <volume>29</volume>: <fpage>281</fpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Soltani</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>De Martino</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Camerer</surname> <given-names>C</given-names></name>. <article-title>A range-normalization model of context-dependent choice: a new model and evidence</article-title>. <source>PLoS Comput Biol</source>. <year>2012</year>; <volume>8</volume>, <fpage>e1002607</fpage>–<lpage>e1002607</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002607" xlink:type="simple">10.1371/journal.pcbi.1002607</ext-link></comment> <object-id pub-id-type="pmid">22829761</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsetsos</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Usher</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>. <article-title>Preference reversal in multiattribute choice</article-title>. <source>Psychol Rev</source>, <year>2010</year>; <volume>117</volume>: <fpage>1275</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0020580" xlink:type="simple">10.1037/a0020580</ext-link></comment> <object-id pub-id-type="pmid">21038979</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tversky</surname> <given-names>A</given-names></name>. <article-title>Elimination by aspects: A theory of choice</article-title>. <source>Psychol Rev</source>. <year>1972</year>; <volume>79</volume>: <fpage>281</fpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Batsell</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Polking</surname> <given-names>JC</given-names></name>. <article-title>A new class of market share models</article-title>. <source>Mark Sci</source>. <year>1985</year>; <volume>4</volume>: <fpage>177</fpage>–<lpage>198</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lehmann</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Pan</surname> <given-names>Y</given-names></name>. <article-title>Context effects, new brand entry, and consideration sets</article-title>. <year>1994</year>; <source>J Mark Res</source>, <fpage>364</fpage>–<lpage>374</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sjöberg</surname> <given-names>L</given-names></name>. <article-title>Choice frequency and similarity</article-title>. <source>Scand J Psychol</source>. <year>1977</year>; <volume>18</volume>: <fpage>103</fpage>–<lpage>115</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ratneshwar</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Shocker</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Stewart</surname> <given-names>DW</given-names></name>. <article-title>Toward understanding the attraction effect: The implications of product stimulus meaningfulness and familiarity</article-title>. <source>J Cons Res</source>. <year>1987</year>; <volume>13</volume>: <fpage>520</fpage>–<lpage>533</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simonson</surname> <given-names>I</given-names></name>. <article-title>Choice based on reasons: The case of attraction and compromise effects</article-title>. <source>J Cons Res</source>. <year>1989</year>; <volume>16</volume>: <fpage>158</fpage>–<lpage>174</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wedell</surname> <given-names>DH</given-names></name>. <article-title>Distinguishing among models of contextually induced preference reversals</article-title>. <source>J Exp Psychol Learni Mem Cogn</source>. <year>1991</year>; <volume>17</volume>: <fpage>767</fpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tversky</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Simonson</surname> <given-names>I</given-names></name>. <article-title>Context-dependent preferences</article-title>. <source>Manag Sci</source>. <year>1993</year>; <volume>39</volume>: <fpage>1179</fpage>–<lpage>1189</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pettibone</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Wedell</surname> <given-names>DH</given-names></name>. <article-title>Testing alternative explanations of phantom decoy effects</article-title>. <source>J Behav Dec Mak</source>. <year>2007</year>; <volume>20</volume>: <fpage>323</fpage>–<lpage>341</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kőszegi</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Rabin</surname> <given-names>M</given-names></name>. <article-title>A model of reference-dependent preferences</article-title>. <source>Q J Econ</source>. <year>2006</year>; <volume>20</volume>: <fpage>1133</fpage>–<lpage>1165</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kőszegi</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Szeidl</surname> <given-names>A</given-names></name>. <article-title>A model of focusing in economic choice</article-title>. <source>Q J Econ</source>. <year>2013</year>; <volume>128</volume>: <fpage>53</fpage>–<lpage>104</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stewart</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>GD</given-names></name>. <article-title>Decision by sampling</article-title>. <source>Cogn Psychol</source>. <year>2006</year>; <volume>53</volume>: <fpage>1</fpage>–<lpage>26</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cogpsych.2005.10.003" xlink:type="simple">10.1016/j.cogpsych.2005.10.003</ext-link></comment> <object-id pub-id-type="pmid">16438947</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Tenenbaum</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Yuille</surname> <given-names>A</given-names></name>. <article-title>Probabilistic models of cognition: Conceptual foundations</article-title>. <source>Trends Cogn Sci</source>. <year>2006</year>; <volume>10</volume>: <fpage>287</fpage>–<lpage>291</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2006.05.007" xlink:type="simple">10.1016/j.tics.2006.05.007</ext-link></comment> <object-id pub-id-type="pmid">16807064</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Clark</surname> <given-names>A</given-names></name>. <article-title>Whatever next? Predictive brains, situated agents, and the future of cognitive science</article-title>. <source>Behav Brain Sci</source>. <year>2013</year>; <volume>36</volume>: <fpage>181</fpage>–<lpage>204</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1017/S0140525X12000477" xlink:type="simple">10.1017/S0140525X12000477</ext-link></comment> <object-id pub-id-type="pmid">23663408</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref034"><label>34</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Oaksford</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>. <source>Bayesian rationality: The probabilistic approach to human reasoning</source>. <year>2007</year>; <publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oaksford</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>. <article-title>Précis of Bayesian rationality: The probabilistic approach to human reasoning</article-title>. <source>Behav Brain Sci</source>. <year>2009</year>; <volume>32</volume>: <fpage>69</fpage>–<lpage>84</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1017/S0140525X09000284" xlink:type="simple">10.1017/S0140525X09000284</ext-link></comment> <object-id pub-id-type="pmid">19210833</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Neal</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Zemel</surname> <given-names>RS</given-names></name>. <article-title>The Helmholtz machine</article-title>. <source>Neural Comput</source>. <year>1995</year>; <volume>7</volume>: <fpage>889</fpage>–<lpage>904</lpage>. <object-id pub-id-type="pmid">7584891</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>. <article-title>The free-energy principle: a unified brain theory?</article-title>. <source>Nature Rev Neurosci</source>. <year>2010</year>; <volume>11</volume>: <fpage>127</fpage>–<lpage>138</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>. <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title>. <source>Nature</source>. <year>2002</year>; <volume>415</volume>: <fpage>429</fpage>–<lpage>43</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/415429a" xlink:type="simple">10.1038/415429a</ext-link></comment> <object-id pub-id-type="pmid">11807554</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bastos</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Vezoli</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bosman</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Schoffelen</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Oostenveld</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Dowdall</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>De Weerd</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Kennedy</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>. <article-title>Visual areas exert feedforward and feedback influences through distinct frequency channels</article-title>. <source>Neuron</source>. <year>2015</year>; <volume>85</volume>: <fpage>390</fpage>–<lpage>401</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2014.12.018" xlink:type="simple">10.1016/j.neuron.2014.12.018</ext-link></comment> <object-id pub-id-type="pmid">25556836</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Botvinick</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Toussaint</surname> <given-names>M</given-names></name>. <article-title>Planning as inference</article-title>. <source>Trends Cogn Sci</source>. <year>2012</year>; <volume>16</volume>: <fpage>485</fpage>–<lpage>488</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2012.08.006" xlink:type="simple">10.1016/j.tics.2012.08.006</ext-link></comment> <object-id pub-id-type="pmid">22940577</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Schwartenbeck</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>FitzGerald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Moutoussis</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>The anatomy of choice: active inference and agency</article-title>. <source>Front Hum Neurosci</source>. <year>2013</year>; <volume>7</volume>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Ognibene</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fitzgerald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Pezzulo</surname> <given-names>G</given-names></name>. <article-title>Active inference and epistemic value</article-title>. <source>Cogn Neurosci</source>. <year>2015</year>; <volume>2</volume>: <fpage>1</fpage>–<lpage>28</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pezzulo</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>. <article-title>The value of foresight: how prospection affects decision-making</article-title>. <source>Front Neurosci</source>. <year>2011</year>; <volume>5</volume>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pezzulo</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Active Inference, homeostatic regulation and adaptive behavioural control</article-title>. <source>Prog Neurobiol</source>. <year>2015</year>; <volume>134</volume>: <fpage>17</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.pneurobio.2015.09.001" xlink:type="simple">10.1016/j.pneurobio.2015.09.001</ext-link></comment> <object-id pub-id-type="pmid">26365173</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Solway</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Botvinick</surname> <given-names>M</given-names></name>. <article-title>Goal-directed decision making as probabilistic inference: a computational framework and potential neural correlates</article-title>. <source>Psychol Rev</source>. <year>2012</year>; <volume>119</volume>: <fpage>120</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0026435" xlink:type="simple">10.1037/a0026435</ext-link></comment> <object-id pub-id-type="pmid">22229491</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johnson</surname> <given-names>JG</given-names></name>, <name name-style="western"><surname>Busemeyer</surname> <given-names>JR</given-names></name>. <article-title>A dynamic, stochastic, computational model of preference reversal phenomena</article-title>. <source>Psychol Rev</source>. <year>2005</year>; <volume>112</volume>: <fpage>841</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.112.4.841" xlink:type="simple">10.1037/0033-295X.112.4.841</ext-link></comment> <object-id pub-id-type="pmid">16262470</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>McKoon</surname> <given-names>G</given-names></name>. <article-title>The diffusion decision model: theory and data for two-choice decision tasks</article-title>. <source>Neural Comput</source>. <year>2008</year>; <volume>20</volume>: <fpage>873</fpage>–<lpage>922</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/neco.2008.12-06-420" xlink:type="simple">10.1162/neco.2008.12-06-420</ext-link></comment> <object-id pub-id-type="pmid">18085991</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref048"><label>48</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Bishop</surname> <given-names>CM</given-names></name>. <source>Pattern recognition and machine learning</source>. <year>2006</year>; <publisher-name>Springer</publisher-name>: <publisher-loc>New York</publisher-loc>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>A theory of cortical responses</article-title>. <source>Phil Trans Royal Soc B</source>. <year>2005</year>; <volume>360</volume>: <fpage>815</fpage>–<lpage>836</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stewart</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Stott</surname> <given-names>HP</given-names></name>, <name name-style="western"><surname>Reimers</surname> <given-names>S</given-names></name>. <article-title>Prospect relativity: how choice options influence decision under risk</article-title>. <source>J Exp Psychol Gen</source>. <year>2003</year>; <volume>132</volume>: <fpage>23</fpage>. <object-id pub-id-type="pmid">12656296</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bowers</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>CJ</given-names></name>. <article-title>Bayesian just-so stories in psychology and neuroscience</article-title>. <source>Psychol Bull</source>. <year>2012</year>; <volume>138</volume>: <fpage>389</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0026450" xlink:type="simple">10.1037/a0026450</ext-link></comment> <object-id pub-id-type="pmid">22545686</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brown</surname> <given-names>LD</given-names></name>. <article-title>A complete class theorem for statistical problems with finite sample spaces</article-title>. <source>Ann Stat</source>. <year>1981</year>; <fpage>1289</fpage>–<lpage>1300</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Candel</surname> <given-names>MJ</given-names></name>. <article-title>A probabilistic feature model for unfolding tested for perfect and imperfect nestings</article-title>. <source>J Math Psychol</source>. <year>1997</year>; <volume>41</volume>: <fpage>414</fpage>–<lpage>430</lpage>. <object-id pub-id-type="pmid">9473403</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Edgell</surname> <given-names>SE</given-names></name>, <name name-style="western"><surname>Geisler</surname> <given-names>WS</given-names></name>. <article-title>A set-theoretic random utility model of choice behavior</article-title>. <source>J Math Psychol</source>. <year>1980</year>; <volume>21</volume>: <fpage>265</fpage>–<lpage>278</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mellers</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Biagini</surname> <given-names>K</given-names></name>. <article-title>Similarity and choice</article-title>. <source>Psychol Rev</source>. <year>1994</year>; <volume>101</volume>: <fpage>505</fpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ariely</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Wallsten</surname> <given-names>TS</given-names></name>. <article-title>Seeking subjective dominance in multidimensional space: An explanation of the asymmetric dominance effect</article-title>. <source>Organ Behav Hum Decis Process</source>. <year>1995</year>; <volume>63</volume>: <fpage>223</fpage>–<lpage>232</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dhar</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Glazer</surname> <given-names>R</given-names></name>. <article-title>Similarity in context: Cognitive representation and violation of preference and perceptual invariance in consumer choice</article-title>. <source>Organ Behav Hum Decis Process</source>. <year>1996</year>; <volume>67</volume>: <fpage>280</fpage>–<lpage>293</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hotaling</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Busemeyer</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>J</given-names></name>. <article-title>Theoretical developments in decision field theory: comment on Tsetsos, Usher, and Chater (2010)</article-title>. <source>Psychol Rev</source>. <year>2010</year>; <volume>117</volume>: <fpage>1294</fpage>–<lpage>1298</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0020401" xlink:type="simple">10.1037/a0020401</ext-link></comment> <object-id pub-id-type="pmid">21038981</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Usher</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Tsetsos</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>. <article-title>Postscript: Contrasting predictions for preference reversal</article-title>. <source>Psychol Rev</source>. <year>2010</year>; <volume>117</volume>: <fpage>1291</fpage>–<lpage>1293</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Usher</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>McClelland</surname> <given-names>JL</given-names></name>. <article-title>Loss aversion and inhibition in dynamical models of multialternative choice</article-title>. <source>Psychol Rev</source>. <year>2004</year>; <volume>111</volume>: <fpage>757</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.111.3.757" xlink:type="simple">10.1037/0033-295X.111.3.757</ext-link></comment> <object-id pub-id-type="pmid">15250782</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Trueblood</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Heathcote</surname> <given-names>A</given-names></name>. <article-title>The multiattribute linear ballistic accumulator model of context effects in multialternative choice</article-title>. <source>Psychol Rev</source>. <year>2014</year>; <volume>121</volume>: <fpage>179</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0036137" xlink:type="simple">10.1037/a0036137</ext-link></comment> <object-id pub-id-type="pmid">24730597</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kahneman</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tversky</surname> <given-names>A</given-names></name>. <article-title>Prospect theory: An analysis of decision under risk</article-title>. <source>Econometrica</source>. <year>1979</year>; <fpage>263</fpage>–<lpage>291</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>. <article-title>Normalization as a canonical neural computation</article-title>. <source>Nat Rev Neurosci</source>. <year>2012</year>; <volume>13</volume>: <fpage>51</fpage>–<lpage>62</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Louie</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>LoFaro</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Webb</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>. <article-title>Dynamic divisive normalization predicts time-varying value coding in decision-related circuits</article-title>. <source>J Neurosci</source>. <year>2014</year>; <volume>34</volume>: <fpage>16046</fpage>–<lpage>16057</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2851-14.2014" xlink:type="simple">10.1523/JNEUROSCI.2851-14.2014</ext-link></comment> <object-id pub-id-type="pmid">25429145</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Louie</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>, <name name-style="western"><surname>Webb</surname> <given-names>R</given-names></name>. <article-title>Adaptive neural coding: from biological to behavioral decision-making</article-title>. <source>Curr Opin Behav Sci</source>. <year>2015</year>; <volume>5</volume>: <fpage>91</fpage>–<lpage>99</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cobeha.2015.08.008" xlink:type="simple">10.1016/j.cobeha.2015.08.008</ext-link></comment> <object-id pub-id-type="pmid">26722666</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rangel</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Clithero</surname> <given-names>JA</given-names></name>. <article-title>Value normalization in decision making: theory and evidence</article-title>. <source>Curr Opin Neurobiol</source>. <year>2012</year>; <volume>22</volume>: <fpage>970</fpage>–<lpage>981</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2012.07.011" xlink:type="simple">10.1016/j.conb.2012.07.011</ext-link></comment> <object-id pub-id-type="pmid">22939568</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Summerfield</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Tsetsos</surname> <given-names>K</given-names></name>. <article-title>Building bridges between perceptual and economic decision-making: neural and computational mechanisms</article-title>. <source>Front Neurosci</source>. <year>2012</year>; <volume>6</volume>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Summerfield</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Tsetsos</surname> <given-names>K</given-names></name>. <article-title>Do humans make good decisions?</article-title>. <source>Trends Cogn Sci</source>,. <year>2015</year> <volume>19</volume>: <fpage>27</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2014.11.005" xlink:type="simple">10.1016/j.tics.2014.11.005</ext-link></comment> <object-id pub-id-type="pmid">25488076</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cheadle</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wyart</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Tsetsos</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Myers</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>De Gardelle</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Castañón</surname> <given-names>SH</given-names></name>, <name name-style="western"><surname>Summerfield</surname> <given-names>C</given-names></name>. <article-title>Adaptive gain control during human perceptual choice</article-title>. <source>Neuron</source>. <year>2014</year>; <volume>81</volume>: <fpage>1429</fpage>–<lpage>1441</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2014.01.020" xlink:type="simple">10.1016/j.neuron.2014.01.020</ext-link></comment> <object-id pub-id-type="pmid">24656259</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hennequin</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Aitchison</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Fast Sampling-Based Inference in Balanced Neuronal Networks</article-title>. <source>Adv Neural Inf Process Syst</source>. <year>2014</year>; <fpage>2240</fpage>–<lpage>2248</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>The Bayesian brain: the role of uncertainty in neural coding and computation</article-title>. <source>Trends Neurosci</source>. <year>2004</year>; <volume>27</volume>: <fpage>712</fpage>–<lpage>719</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2004.10.007" xlink:type="simple">10.1016/j.tins.2004.10.007</ext-link></comment> <object-id pub-id-type="pmid">15541511</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Howes</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Warren</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Farmer</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>El-Deredy</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Lewis</surname> <given-names>RL</given-names></name>. <article-title>Why contextual preference reversals maximize expected value</article-title>. <source>Psychol Rev</source>. <year>2016</year>; <volume>123</volume>: <fpage>368</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0039996" xlink:type="simple">10.1037/a0039996</ext-link></comment> <object-id pub-id-type="pmid">27337391</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>. <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source>. <year>1997</year>; <volume>275</volume>: <fpage>1593</fpage>–<lpage>1599</lpage>. <object-id pub-id-type="pmid">9054347</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref074"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Acuña</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Schrater</surname> <given-names>P</given-names></name>. <article-title>Structure Learning in Human Sequential Decision-Making</article-title>. <source>PLOS Comput Biol</source>. <year>2010</year>; <volume>6</volume>, <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1001003" xlink:type="simple">10.1371/journal.pcbi.1001003</ext-link></comment> <object-id pub-id-type="pmid">21151963</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref075"><label>75</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Behrens</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Walton</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MF</given-names></name>. <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source>. <year>2007</year>; <volume>10</volume>: <fpage>1214</fpage>–<lpage>1221</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1954" xlink:type="simple">10.1038/nn1954</ext-link></comment> <object-id pub-id-type="pmid">17676057</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref076"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Collins</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>. <article-title>Cognitive control over learning: creating, clustering, and generalizing task-set structure</article-title>. <source>Psychol Revi</source>. <year>2013</year>; <volume>120</volume>: <fpage>190</fpage>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref077"><label>77</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Courville</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Touretzky</surname> <given-names>DS</given-names></name>. <article-title>Bayesian theories of conditioning in a changing world</article-title>. <source>Trends Cogn Sci</source>. <year>2006</year>; <volume>10</volume>: <fpage>294</fpage>–<lpage>300</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2006.05.004" xlink:type="simple">10.1016/j.tics.2006.05.004</ext-link></comment> <object-id pub-id-type="pmid">16793323</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref078"><label>78</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>FitzGerald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Model averaging, optimal inference, and habit formation</article-title>. <source>Front Hum Neurosci</source>. <year>2014</year>; <volume>8</volume>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref079"><label>79</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gershman</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>. <article-title>Learning latent structure: carving nature at its joints</article-title>. <source>Curr Opin Neurobiol</source>. <year>2010</year>; <volume>20</volume>: <fpage>251</fpage>–<lpage>256</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2010.02.008" xlink:type="simple">10.1016/j.conb.2010.02.008</ext-link></comment> <object-id pub-id-type="pmid">20227271</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref080"><label>80</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>. <article-title>A Bayesian foundation for individual learning under uncertainty</article-title>. <source>Front Hum Neurosci</source>; <year>2011</year>; <volume>5</volume>: <fpage>39</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2011.00039" xlink:type="simple">10.3389/fnhum.2011.00039</ext-link></comment> <object-id pub-id-type="pmid">21629826</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref081"><label>81</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Parducci</surname> <given-names>A</given-names></name>. <article-title>Category judgment: a range-frequency model</article-title>. <source>Psychol Rev</source>. <year>1965</year>; <volume>72</volume>: <fpage>407</fpage>. <object-id pub-id-type="pmid">5852241</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref082"><label>82</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Parducci</surname> <given-names>A</given-names></name>. <source>Happiness, pleasure, and judgment: The contextual theory and its applications</source>. <year>1995</year>; <publisher-name>Lawrence Erlbaum Associates, Inc</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1005769.ref083"><label>83</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maltby</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wood</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Vlaev</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>GD</given-names></name>. <article-title>Contextual effects on the perceived health benefits of exercise: The exercise rank hypothesis</article-title>. <source>J Sport Exerc Psychol</source>. <year>2012</year>; <volume>34</volume>: <fpage>828</fpage>–<lpage>841</lpage>. <object-id pub-id-type="pmid">23204361</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref084"><label>84</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Watkinson</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wood</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Lloyd</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>GD</given-names></name>. <article-title>Pain ratings reflect cognitive context: A range frequency model of pain perception</article-title>. <source>Pain</source>. <year>2013</year>; <volume>154</volume>: <fpage>743</fpage>–<lpage>749</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.pain.2013.01.016" xlink:type="simple">10.1016/j.pain.2013.01.016</ext-link></comment> <object-id pub-id-type="pmid">23498366</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref085"><label>85</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Trueblood</surname> <given-names>JS</given-names></name>. <article-title>Multialternative context effects obtained using an inference task</article-title>. <source>Psychon Bull Rev</source>. <year>2012</year>; <volume>19</volume>: <fpage>962</fpage>–<lpage>968</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13423-012-0288-9" xlink:type="simple">10.3758/s13423-012-0288-9</ext-link></comment> <object-id pub-id-type="pmid">22736437</object-id></mixed-citation></ref>
<ref id="pcbi.1005769.ref086"><label>86</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Trueblood</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Heathcote</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Busemeyer</surname> <given-names>JR</given-names></name>. <article-title>Not just for consumers context effects are fundamental to decision making</article-title>. <source>Psychol Sci</source>. <year>2013</year>; <volume>24</volume>: <fpage>901</fpage>–<lpage>908</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797612464241" xlink:type="simple">10.1177/0956797612464241</ext-link></comment> <object-id pub-id-type="pmid">23610134</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.2005339</article-id>
<article-id pub-id-type="publisher-id">pbio.2005339</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Eukaryota</subject><subj-group><subject>Animals</subject><subj-group><subject>Vertebrates</subject><subj-group><subject>Amniotes</subject><subj-group><subject>Mammals</subject><subj-group><subject>Primates</subject><subj-group><subject>Monkeys</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Amygdala</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Amygdala</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Behavior</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Foraging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Zoology</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Foraging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Behavior</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>Amygdala activity for the modulation of goal-directed behavior in emotional contexts</article-title>
<alt-title alt-title-type="running-head">Amygdala for goal-directed behavior in emotional environments</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8543-5289</contrib-id>
<name name-style="western">
<surname>Maeda</surname>
<given-names>Kazutaka</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Kunimatsu</surname>
<given-names>Jun</given-names>
</name>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Hikosaka</surname>
<given-names>Okihide</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Funding Acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project Administration</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Laboratory of Sensorimotor Research, National Eye Institute, National Institutes of Health, Bethesda, Maryland, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Rushworth</surname>
<given-names>Matthew</given-names>
</name>
<role>Academic Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Oxford, United Kingdom of Great Britain and Northern Ireland</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">kaz.maeda.86@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>5</day>
<month>6</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="collection">
<month>6</month>
<year>2018</year>
</pub-date>
<volume>16</volume>
<issue>6</issue>
<elocation-id>e2005339</elocation-id>
<history>
<date date-type="received">
<day>10</day>
<month>1</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>2</day>
<month>5</month>
<year>2018</year>
</date>
</history>
<permissions>
<license xlink:href="https://creativecommons.org/publicdomain/zero/1.0/" xlink:type="simple">
<license-p>This is an open access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/" xlink:type="simple">Creative Commons CC0</ext-link> public domain dedication.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.2005339"/>
<abstract>
<p>Choosing valuable objects and rewarding actions is critical for survival. While such choices must be made in a way that suits the animal’s circumstances, the neural mechanisms underlying such context-appropriate behavior are unclear. To address this question, we devised a context-dependent reward-seeking task for macaque monkeys. Each trial started with the appearance of one of many visual scenes containing two or more objects, and the monkey had to choose the good object by saccade to get a reward. These scenes were categorized into two dimensions of emotional context: dangerous versus safe and rich versus poor. We found that many amygdala neurons were more strongly activated by dangerous scenes, by rich scenes, or by both. Furthermore, saccades to target objects occurred more quickly in dangerous than in safe scenes and were also quicker in rich than in poor scenes. Thus, amygdala neuronal activity and saccadic reaction times were negatively correlated in each monkey. These results suggest that amygdala neurons facilitate targeting saccades predictably based on aspects of emotional context, as is necessary for goal-directed and social behavior.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>The amygdala is known to control passive fear responses (e.g., freezing), but it is unclear if it also contributes to active behaviors. To reach certain goals, we (humans and animals) often need to go through fearful environments. We hypothesized that the amygdala contributes to such an active behavior and devised a new foraging task for macaque monkeys in which various emotional contexts changed across many environments. This “exciting” task provoked extremely fast learning and high-capacity memory of objects and environments, and thereby caused extremely fast goal-directed behaviors. We found that the goal-directed behavior was affected by the emotional context in two dimensions (dangerous–safe and rich–poor) separately from the object values. Then, many neurons in the amygdala responded to the environments before any object appeared and did so selectively, depending on the emotional context of the environment. The neuronal activity was tightly correlated with the reaction time of goal-directed behavior across the contexts: faster behavior in dangerous or rich context. These results suggest that the amygdala facilitates goal-directed behavior by focusing on emotional contexts. Such a function is also important for emotional–social behavior and its disorder, including averted eye gaze in autism.</p>
</abstract>
<funding-group>
<funding-statement>Intramural Research Program at the National Institutes of Health, National Eye Institute <ext-link ext-link-type="uri" xlink:href="https://projectreporter.nih.gov/project_info_description.cfm?aid=9555680&amp;icde=37797872" xlink:type="simple">https://projectreporter.nih.gov/project_info_description.cfm?aid=9555680&amp;icde=37797872</ext-link> (grant number EY000415-15). Received by OH. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="9"/>
<table-count count="0"/>
<page-count count="29"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The neurophysiological and behavior data are available from the Open Science Framework (“Amygdala activity for the modulation of goal-directed behavior in emotional contexts” <ext-link ext-link-type="uri" xlink:href="https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09" xlink:type="simple">https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09</ext-link>).</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Goal-directed behavior is strongly influenced by the predicted outcome of choices on the basis of repeated experience with multiple objects and actions [<xref ref-type="bibr" rid="pbio.2005339.ref001">1</xref>]. However, the outcome of choices often changes, depending on the context [<xref ref-type="bibr" rid="pbio.2005339.ref002">2</xref>]. Thus, neurons contributing to goal-directed behavior should integrate information about both behavioral targets and context, which actually involve various brain areas [<xref ref-type="bibr" rid="pbio.2005339.ref003">3</xref>–<xref ref-type="bibr" rid="pbio.2005339.ref005">5</xref>]. It is thus difficult to understand the mechanism of context specificity: how is context information created, and how is it integrated with target information?</p>
<p>To address these questions, we used visual scenes as contexts, which often serve as “environment contexts” in real life [<xref ref-type="bibr" rid="pbio.2005339.ref002">2</xref>]. For a visual scene to establish context, the subject needs to learn the predictable events, for instance, that a robber may appear [<xref ref-type="bibr" rid="pbio.2005339.ref006">6</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref007">7</xref>]. It is known that various scenes are discriminated in particular areas in the visual cortices based on their visual features [<xref ref-type="bibr" rid="pbio.2005339.ref008">8</xref>], but scene context (e.g., dangerous, safe, rich, poor) may be detected in different brain areas where the visual features are associated with the predictable events. One procedure to examine this mechanism is to make multiple scenes that represent a particular context, which would suggest that a context is created regardless of sensory features.</p>
<p>Importantly, goal-directed behavior must start sometime after the subject enters into a particular environment. Thus, the context information can be available earlier than target information, which may allow separate processing mechanisms. To utilize this temporal feature, it would be better if the environment appeared suddenly and unpredictably, which should be followed by, not preceded by, the activation of the context mechanism.</p>
<p>To this end, we created a new foraging task using visual scenes derived from satellite imagery as environments, each of which was presented in a large portion of the subject’s (macaque monkey) visual field. Within each scene, smaller fractal objects appeared, which the subject either reacted to or ignored. Initially, all the visual scenes and objects were novel, but after repeated experiences they started representing several groups of scenes and targets. In one block of the experiment, many scenes were presented randomly so that the context mechanism had to be activated differently each time after the scene appeared.</p>
<p>As the first step in studying the mechanisms of context, we recorded neuronal activity in the amygdala of monkeys performing the foraging task. The amygdala is highly sensitive to emotional stimuli or contexts [<xref ref-type="bibr" rid="pbio.2005339.ref003">3</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref009">9</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref010">10</xref>]. This has been shown clearly by experiments using passive procedures (e.g., Pavlovian conditioning tasks), especially with fearful objects acting as conditioned stimuli [<xref ref-type="bibr" rid="pbio.2005339.ref011">11</xref>]. On the other hand, recent studies showed that the amygdala also contributes to goal-directed behavior [<xref ref-type="bibr" rid="pbio.2005339.ref012">12</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref013">13</xref>]. These studies together raise a hypothesis that the amygdala promotes goal-directed behavior in emotional or dangerous contexts, which is critical in real life. Our study supports this hypothesis, as shown below.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<p>How the monkey performed the foraging task is shown in <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1</xref>. Initially, the screen in front of the monkey was dark. Next, a large visual scene chosen from satellite imagery appeared suddenly, which acted as an environment. Each scene contained at least two fractal images (“good” and “bad” objects), which appeared one at a time and were randomized both in sequence and position (<xref ref-type="fig" rid="pbio.2005339.g001">Fig 1A</xref>). In this example trial, the bad object appeared twice, but the monkey avoided it by saccading to it and then quickly looking away (gaze duration &lt;400 ms). Then, the good object appeared, and the monkey chose it by saccading and holding fixation (FX) (gaze duration &gt;400 ms) and obtained a reward. The scene disappeared after the monkey chose either the good object (with reward) or the bad object (with no reward), thus ending the trial. Similar example trials are shown in <xref ref-type="supplementary-material" rid="pbio.2005339.s009">S1 Movie</xref>.</p>
<fig id="pbio.2005339.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2005339.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Foraging task in environmental contexts.</title>
<p>(<bold>A</bold>) Example trial from monkey PA with a safe environment (#121 in Fig 1C). Top: sequence of events starting with blank screen during the ITI. Bottom: eye position (magenta: horizontal; green: vertical) and spike activity of one amygdala neuron (spike timing, blue). In this trial, the bad object appeared twice, followed by the good object (top). The monkey made saccades from the fixation point to both objects but quickly returned to the center for the bad object and kept fixating the good object to get a reward. The neuron was nearly silent (only two spikes). (<bold>B</bold>) Trial from monkey PA with a dangerous environment (#172 in Fig 1C). After the bad object, the robber object appeared and remained until the good object appeared, to which the monkey made a saccade quickly enough to trigger reward delivery. On other trials when the saccade was delayed, the robber object jumped to the good object and no reward was available. See <xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1 Fig</xref> and <xref ref-type="sec" rid="sec009">Materials and methods</xref> for detailed procedures. See also <xref ref-type="supplementary-material" rid="pbio.2005339.s009">S1</xref> and <xref ref-type="supplementary-material" rid="pbio.2005339.s010">S2</xref> Movies. The same neuron continued to be active until the reward delivery (unlike in the safe environment in A). Performing these trials correctly required the monkey to retrieve the memories of the objects contained in the scene. We refer to each scene as an “environment.” (<bold>C</bold>) Multiple sets of example scenes (<italic>n</italic> = 56) and objects (<italic>n</italic> = 140) for monkey PA. Each scene contained one good object (associated with a big or small reward) and one bad object (associated with no reward). Some scenes contained a third object that acted as a robber object (D/R) or a distractor object (some in S/R and S/P). The robber object tried to attack the good object and forestall the reward (as in <xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1 Fig</xref>). The distractor remained while another object (good or bad) appeared, but never attacked the other object. Each good object was consistently associated with either a big or a small reward. We thus classified these scenes into three groups. D/R: dangerous (with robber) and rich (big reward). S/R: safe (no robber) and rich (big reward). S/P: safe (no robber) and poor (small reward). The trial continued with objects appearing in random sequence and position until the monkey ended the trial by holding fixation on either the good object (followed by reward) or the bad object (followed by no reward). The scene remained until the end of the trial. These example scene images were derived from OpenAerialMap (<ext-link ext-link-type="uri" xlink:href="https://openaerialmap.org/" xlink:type="simple">https://openaerialmap.org</ext-link>). D/R, dangerous and rich; ITI, intertrial interval; S/P, safe and poor; S/R, safe and rich.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.g001" xlink:type="simple"/>
</fig>
<p>In another trial (<xref ref-type="fig" rid="pbio.2005339.g001">Fig 1B</xref>), a different scene with different objects appeared. This scene contained a third type of object in addition to good and bad objects, which we call the “robber object.” In this example, the bad object appeared first, which the monkey avoided. Then, the robber appeared and waited for the good object. When the good object appeared, both the monkey and the robber tried to get it first. In this case, the monkey won the competition and got a reward. Had the monkey’s saccade been slower, the robber would have jumped to the good object and stolen the reward (<xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1 Fig</xref>). Similar procedures have been used for rodents [<xref ref-type="bibr" rid="pbio.2005339.ref014">14</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref015">15</xref>]. These two scenes can be classified as a “safe” scene (i.e., no robber will come; <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1A</xref>) and a “dangerous” scene (i.e., robber may come; <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1B</xref>), respectively. Similar example trials are shown in <xref ref-type="supplementary-material" rid="pbio.2005339.s010">S2 Movie</xref>.</p>
<p>Spike activity of one amygdala neuron was recorded during these trials. It was nearly silent (i.e., only fired two spikes) during the safe scene (<xref ref-type="fig" rid="pbio.2005339.g001">Fig 1A</xref>, bottom) but started firing immediately after the dangerous scene appeared (<xref ref-type="fig" rid="pbio.2005339.g001">Fig 1B</xref>, bottom). This result raised the possibility that amygdala neurons process scenes selectively.</p>
<p>However, the difference in neuronal activity or behavior could be due to different visual features of the scenes (as described in the Introduction). To address this issue, we created many scenes (together with objects) for each class of environmental context. <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref> shows the example scenes used for monkey PA. We classified the scenes into three groups: (1) D/R: dangerous (robber+) and rich (large reward), (2) S/R: safe (robber−) and rich (large reward), and (3) S/P: safe (robber−) and poor (small reward). We did not use the other possible environment, D/P (dangerous and poor) because we found that this combination led the monkeys to quit the task. Based on the three groups, we investigated two dimensions of emotional context, the dangerous–safe dimension (D/R versus S/R) and the rich–poor dimension (S/R versus S/P). These task dimensions roughly correspond to a common way to conceptualizing emotional dimensions, namely valence and arousal [<xref ref-type="bibr" rid="pbio.2005339.ref016">16</xref>]. In some of the safe scenes, another type of “distractor object” could appear, which, like the robber, lingered on the screen but never attacked the reward. Task details for trials with distractor and robber objects are shown in <xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1 Fig</xref>.</p>
<p>All three monkeys learned the many combinations of scenes and objects quickly and accurately. <xref ref-type="supplementary-material" rid="pbio.2005339.s002">S2A Fig</xref> shows the change in the correct choice rate (i.e., choosing good objects) when monkey PI learned four new scenes and eight new objects simultaneously. By the end of the first day of learning (13 trials for each scene, 52 total), the correct choice rate approached 100%. After 2–3-d learning sessions, his performance became almost perfect for all the four scenes. Quick learning similarly occurred for the other scenes that monkey PI experienced (<italic>n</italic> = 56), and likewise with monkeys PA and SO (<xref ref-type="supplementary-material" rid="pbio.2005339.s002">S2B Fig</xref>). Average SacRT was initially about 150 ms and quickly decreased to about 100 ms, after the monkey started experiencing the foraging task (<xref ref-type="supplementary-material" rid="pbio.2005339.s002">S2C Fig</xref>). The monkeys’ performance for well-practiced environments remained high after initial learning and during neuronal recording.</p>
<p>However, it was still unclear whether the environment context affected behavior. To address this question, we compared SacRT to good/bad objects between different contexts. <xref ref-type="fig" rid="pbio.2005339.g002">Fig 2A</xref> shows an example comparison between a safe (S/R) scene (top) and a dangerous (D/R) scene (bottom). We assessed SacRT data in multiple scenes for each context (<xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref> for monkey PA). We found that SacRT was changed by the environmental contexts (<xref ref-type="fig" rid="pbio.2005339.g002">Fig 2B</xref>): shorter with dangerous scenes (black) than safe scenes (two-sample <italic>t</italic> test: <italic>P</italic> &lt; 0.001, <italic>t</italic> = −11.086, df = 14,000), even though the reward amount was the same (i.e., big). Notably, the whole distribution of SacRTs (including &lt;100 ms) was shifted between these contexts in monkey PA (<xref ref-type="fig" rid="pbio.2005339.g002">Fig 2B</xref>). In each context (e.g., dangerous), SacRT was also influenced by the object (<xref ref-type="fig" rid="pbio.2005339.g002">Fig 2C</xref>): shorter for good objects than bad objects (two-sample <italic>t</italic> test: <italic>P</italic> &lt; 0.001, <italic>t</italic> = −10.385, df = 4,161), but only during the late period (roughly &gt;100 ms). These data suggest that the two factors (scene and object) influenced SacRT and did so with different time courses. It is then likely that there are separate neural mechanisms for the context discrimination and for the object discrimination.</p>
<fig id="pbio.2005339.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2005339.g002</object-id>
<label>Fig 2</label>
<caption>
<title>SacRTs in safe and dangerous contexts.</title>
<p>(<bold>A</bold>) Safe scene (top, #121 in <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref>) and dangerous scene (bottom, #172 in <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref>), which appeared occasionally and randomly among many others (<xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref>). The first object can be a good or bad object, or a robber object (in the dangerous scene). (<bold>B</bold>) Distribution of the SacRT in monkey PA to the first object (good or bad) in the dangerous (D/R) scenes (black) and the safe (S/R) scenes (red). The data are based on all scenes in each group (<italic>n</italic> = 24 for D/R, <italic>n</italic> = 20 for S/R, <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref>). SacRT distribution is shown using reciprobit plot, in which a straight line indicates a normal (Gaussian) distribution of the speed of the saccade preparation process [<xref ref-type="bibr" rid="pbio.2005339.ref016">16</xref>]. (<bold>C</bold>) SacRT distribution in the dangerous scenes, shown separately for good objects and bad objects. Example scene images were derived from OpenAerialMap (<ext-link ext-link-type="uri" xlink:href="https://openaerialmap.org/" xlink:type="simple">https://openaerialmap.org</ext-link>). D/R, dangerous and rich; S/R, safe and rich; SacRT, saccade reaction time.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.g002" xlink:type="simple"/>
</fig>
<p>The SacRT difference between the context and object effects was present in the all monkeys (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3</xref>). In order to examine these two factors cleanly, we measured SacRT for the first saccade in a trial (see <xref ref-type="fig" rid="pbio.2005339.g002">Fig 2A</xref>). Second and subsequent saccades can be influenced by other factors, such as the positions or values of the preceding objects and the presence or absence of the robber/distractor objects. The environmental context affected SacRT across the entire distribution of latencies (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3A</xref>), unlike the object value (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3B</xref>). In monkey PA (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3A</xref>, left), SacRT was shorter with D/R than S/R scenes (two-way ANOVA with scenes and objects, F[2, 18693] = 5.966, <italic>P</italic> = 0.003, post hoc: Tukey–Kramer, <italic>P</italic> &lt; 0.001), indicating that the dangerous–safe dimension had a significant effect on SacRT. In monkey PI (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3A</xref>, center), SacRT was shorter with S/R than S/P scenes (F[2, 12428] = 21.892, <italic>P</italic> &lt; 0.001, post hoc: <italic>P</italic> &lt; 0.001), indicating that the rich–poor dimension had a significant effect on SacRT. In monkey SO (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3A</xref>, right), SacRT was different in two dimensions of context: (1) dangerous–safe dimension: shorter with D/R than S/R scenes (F[2, 27266] = 37.405, <italic>P</italic> &lt; 0.001; post hoc: <italic>P</italic> &lt; 0.001), and (2) rich–poor dimension: shorter with S/R than S/P scenes (post hoc: <italic>P</italic> &lt; 0.001). These data suggest that SacRT was affected by the context, but somewhat differently in the three subjects. Interestingly, the context effect was observed in saccades to both good and bad objects, even though the monkey left the bad object quickly after making a saccade to it (to avoid no reward). These data again suggest that the context mechanism starts working early after a scene appears, regardless of the upcoming object.</p>
<fig id="pbio.2005339.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2005339.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Distribution of SacRTs in different contexts and for different targets.</title>
<p>(<bold>A</bold>) Distributions of the SacRT for three groups of scenes are superimposed: D/R, S/R, and S/P (see <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref>). They are shown separately for the good and bad objects. Data are shown for monkeys PA (left), PI (center), and SO (right) after learning (&gt;350, &gt;200, and &gt;200 trials for each environment, respectively). (<bold>B</bold>) The same SacRT data are shown separately for the three groups of scenes (D/R, S/R, S/P), but data for good (G) and bad (B) objects are superimposed. The numbers of saccades examined are shown in each graph. The effects of scenes (A) and objects (B) on SacRT were independent and orthogonal in all subjects (two-way ANOVA, monkey PA [scene, F(2,18693) = 68.004, <italic>P</italic> &lt; 0.001; object, F(1,18693) = 381.645, <italic>P</italic> &lt; 0.001; scene*object, F(2,18693) = 5.966, <italic>P</italic> = 0.003], monkey PI [scene, F(2,12428) = 18.313, <italic>P</italic> &lt; 0.001; object, F(1,12428) = 1,216.167, <italic>P</italic> &lt; 0.001; scene*object, F(2,12428) = 21.892, <italic>P</italic> &lt; 0.001], monkey SO [scene, F(2,27266) = 84.198, <italic>P</italic> &lt; 0.001; object, F(1,27266) = 584.585, <italic>P</italic> &lt; 0.001; scene*object, F(2, 27266) = 37.405, <italic>P</italic> &lt; 0.001]). Data used to generate these plots can be found at <ext-link ext-link-type="uri" xlink:href="https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09" xlink:type="simple">https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09</ext-link>. B, bad; D/R, dangerous and rich; G, good; S/P, safe and poor; S/R, safe and rich; SacRT, saccade reaction time.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.g003" xlink:type="simple"/>
</fig>
<p>SacRT was also influenced by the object (i.e., shorter for good than bad objects) (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3B</xref>) regardless of the scene, but only for the right tail of the distribution (roughly &gt;100 ms). These data suggest two separate neural mechanisms for the scene and object effects. First, the object-processing neurons cannot identify the object’s value immediately after the object appears, until about 100 ms [<xref ref-type="bibr" rid="pbio.2005339.ref017">17</xref>]. Second, the scene-processing neurons affect the saccade preparatory process before the object appears, because the scene is already present. That the reciprobit plots showed nearly parallel distributions across environment contexts (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3A</xref>) suggests that the speed (rather than threshold) of saccade preparation is changed by the contexts [<xref ref-type="bibr" rid="pbio.2005339.ref018">18</xref>], namely faster saccades when the scene was dangerous or rich.</p>
<p>These behavioral data suggest that in our foraging task, context-processing neurons should change their activity after the scene appears. Indeed, we found many such neurons in the amygdala. <xref ref-type="fig" rid="pbio.2005339.g004">Fig 4</xref> shows the responses of one example neuron in monkey PA to the appearance of many scenes, which were classified in three groups (<xref ref-type="fig" rid="pbio.2005339.g004">Fig 4D</xref>). This neuron is the same as shown in <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1</xref>. It started firing in response to D/R scenes but was almost silent when the scene was S/R or S/P. These data suggest that the neuron was sensitive to one dimension of context: dangerous–safe dimension (D/R versus S/R in free-viewing [FV] period, one-way ANOVA, F[2, 29] = 17.932, <italic>P</italic> &lt; 0.001, post hoc: Tukey–Kramer, <italic>P</italic> &lt; 0.001; D/R versus S/R in FX period, one-way ANOVA, F[2, 29] = 18.628, <italic>P</italic> &lt; 0.001, post hoc: Tukey–Kramer, <italic>P</italic> &lt; 0.001) (<xref ref-type="fig" rid="pbio.2005339.g004">Fig 4C</xref>, dangerous versus safe). It was not significantly sensitive to the other dimension: rich–poor dimension (S/R versus S/P in FV period, post hoc: Tukey–Kramer, <italic>P</italic> = 0.935; S/R versus S/P in FX period, post hoc: Tukey–Kramer, <italic>P</italic> = 0.983) (<xref ref-type="fig" rid="pbio.2005339.g004">Fig 4C</xref>, rich versus poor). The dangerous–safe difference started quickly, 157 ms after the scene onset (<xref ref-type="fig" rid="pbio.2005339.g004">Fig 4B</xref>, black triangle). These results suggest that the neuron processed the environmental context in the dangerous–safe dimension.</p>
<fig id="pbio.2005339.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2005339.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Responses of one example neuron in the amygdala to scene environments.</title>
<p>Neuron (#73) in monkey PA that was selectively active in the dangerous context (partially shown in <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1</xref>). (<bold>A–B</bold>) The neuron’s activities in the three groups of scenes: dangerous (D/R), rich (S/R), poor (S/P). They are shown separately as spike rasters (<bold>A</bold>) and are superimposed as SDF. (<bold>B</bold>). For SDF, each spike was replaced by a Gaussian curve (σ = 10 ms) in this and the following figures. Triangle indicates the onset of the scene response (white) and the onset of the context-dependent differentiation (black). (<bold>C</bold>) Time course of the neuron’s activity bias in two dimensions of context: (1) dangerous–safe (D versus S): difference in activity between D/R and S/R, (2) rich–poor (R versus P): difference in activity between S/R and S/P. In each dimension, the difference of activity (ΔFR score) was calculated in a sliding 300-ms window (10 ms steps) if it was statistically significant (tested by one-way ANOVA and Tukey–Kramer post hoc test); otherwise the score was put as 0. Then, the scores were divided by the maximum of the difference during free-viewing and fixation periods. ΔFR &gt; 0: D &gt; S (top) and R &gt; P (bottom). (<bold>D</bold>) The neuron’s response (z-score) to individual scenes in the three groups examined (see <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref>). In this and the following figures, the neuronal data are focused on the activity before the first object appeared (see <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1A and 1B</xref>). This period was divided into the two parts: free-viewing period (from scene onset to fixation start) (left) and fixation period (from fixation start to object onset) (right). Data used to generate these plots can be found at <ext-link ext-link-type="uri" xlink:href="https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09" xlink:type="simple">https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09</ext-link>. D/R, dangerous and rich; FR, firing rate; S/P, safe and poor; S/R, safe and rich; SDF, spike density function.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.g004" xlink:type="simple"/>
</fig>
<p>Alternatively, the difference in the neuronal activity might be caused by the different visual features between the environments. This is one reason we used many visual scenes to represent the same context (<xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref>). In fact, the neuron’s activity was stronger in the D/R context than the S/R or S/P context regardless of the scene-based differences (assessed in FV periods, one-way ANOVA, F[2, 29] = 17.932, <italic>P</italic> &lt; 0.001; in FX period, one-way ANOVA, F[2, 29] = 18.628, <italic>P</italic> &lt; 0.001) (<xref ref-type="fig" rid="pbio.2005339.g004">Fig 4D</xref>). Notably, the neuron’s activity was variable across scenes within the same context, which is evident in D/R context (<xref ref-type="fig" rid="pbio.2005339.g004">Fig 4D</xref>). Its significance will be examined later (<xref ref-type="supplementary-material" rid="pbio.2005339.s005">S5 Fig</xref>).</p>
<p>This neuron was recorded in monkey PA, whose SacRT was shorter in the dangerous than in the safe context (Figs <xref ref-type="fig" rid="pbio.2005339.g002">2</xref> and <xref ref-type="fig" rid="pbio.2005339.g003">3A</xref>, left). According to the reciprobit plot [<xref ref-type="bibr" rid="pbio.2005339.ref018">18</xref>], this was caused by the difference in speed of the saccade preparation process. To achieve such a speed increase, the saccade generator (e.g., superior colliculus [SC]) should receive modulatory inputs before the preparation process starts. The neuron in <xref ref-type="fig" rid="pbio.2005339.g004">Fig 4</xref> may thus contribute to the faster saccades in the dangerous context. Its activity actually further increased toward the end of the FX period (<xref ref-type="fig" rid="pbio.2005339.g004">Fig 4B</xref>), after which an object appeared and a saccade occurred.</p>
<p><xref ref-type="supplementary-material" rid="pbio.2005339.s003">S3 Fig</xref> shows the activity of two amygdala neurons in the other monkeys. The first neuron (<xref ref-type="supplementary-material" rid="pbio.2005339.s003">S3A Fig</xref>) was very active spontaneously. It was first inhibited by virtually all scenes (latency: 94 ms). Its activity then became differential (latency: 416 ms), higher with the rich than the poor scenes (S/R versus S/P in FV period, one-way ANOVA, F[2, 29] = 7.003, <italic>P</italic> = 0.003, post hoc: Tukey–Kramer, <italic>P</italic> = 0.015; S/R versus S/P in FX period, one-way ANOVA, F[2, 29] = 8.994, <italic>P</italic> = 0.001, post hoc: Tukey–Kramer, <italic>P</italic> = 0.001), but not different between the dangerous and safe scenes (D/R versus S/R in FV period, <italic>P</italic> = 0.783; D/R versus S/R in FX period, <italic>P</italic> = 0.747). This neuron was recorded in monkey PI, whose SacRT was shorter with the rich than the poor scenes (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3A</xref>, center). The neuron may thus contribute to the faster saccades in the rich context.</p>
<p>The second neuron (<xref ref-type="supplementary-material" rid="pbio.2005339.s003">S3B Fig</xref>) was first activated by virtually all scenes (latency: 76 ms). Its differential activity evolved later (latency: 201 ms for S/P and 1,662 ms for D/R in comparison with S/R) in two dimensions, namely (1) dangerous–safe dimension (D/R versus S/R in FV period, one-way ANOVA, F[2, 29] = 4.407, <italic>P</italic> = 0.021, post hoc: Tukey–Kramer, <italic>P</italic> = 0.993; D/R versus S/R in FX period, one-way ANOVA, F[2, 29] = 17.229, <italic>P</italic> &lt; 0.001, post hoc: Tukey–Kramer, <italic>P</italic> = 0.008) and (2) rich–poor dimension (S/R versus S/P in FV period, post hoc: Tukey–Kramer, <italic>P</italic> = 0.030; S/R versus S/P in FX period, post hoc: Tukey–Kramer, <italic>P</italic> = 0.018). This neuron was recorded in monkey SO, whose SacRT was different in the same two dimensions: (1) D/R &lt; S/R and (2) S/R &lt; S/P. The neuron may thus contribute to the faster saccades in the dangerous and rich contexts.</p>
<p>The combined activity of amygdala neurons in monkeys PA, PI, and SO is shown in <xref ref-type="fig" rid="pbio.2005339.g005">Fig 5</xref>. After the scene appeared, a majority of the neurons increased their activity (excited type, <xref ref-type="fig" rid="pbio.2005339.g005">Fig 5B</xref> top), while some neurons eventually decreased their activity (inhibited type, <xref ref-type="fig" rid="pbio.2005339.g005">Fig 5B</xref> bottom) (<xref ref-type="fig" rid="pbio.2005339.g005">Fig 5A</xref>). Many of them were activated (or inhibited) immediately after the scene appeared (<xref ref-type="supplementary-material" rid="pbio.2005339.s004">S4 Fig</xref>). Their activity then diverged depending on the context: dangerous–safe dimension (D versus S) and/or rich–poor dimension (R versus P). This occurred more clearly among excited-type neurons (<xref ref-type="fig" rid="pbio.2005339.g005">Fig 5B</xref>, top). The context effect sometimes changed between the early FV period and the late FX period. During the FV period, the neuronal activity tended to be higher in the rich (red) than poor (blue) context, which was statistically significant in all three monkeys (one-way ANOVA and Tukey–Kramer post hoc test; PA: F[2, 53] = 4.984, <italic>P</italic> = 0.01, post hoc, <italic>P</italic> = 0.019; PI: F[2, 53] = 6.937, <italic>P</italic> = 0.002, post hoc, <italic>P</italic> = 0.002; SO: F[2, 29] = 103.568, <italic>P</italic> &lt; 0.001, post hoc, <italic>P</italic> &lt; 0.001). The significant sensitivity to the dangerous–safe dimension (i.e., black versus red) emerged later in the FX period in two monkeys, PA (F[2, 53] = 25.924, <italic>P</italic> &lt; 0.001, post hoc, <italic>P</italic> &lt; 0.001) and SO (F[2, 29] = 51.747, <italic>P</italic> &lt; 0.001, post hoc, <italic>P</italic> &lt; 0.001). Inhibited-type neurons (<xref ref-type="fig" rid="pbio.2005339.g005">Fig 5B</xref>, bottom) overall were clearly inhibited only during the late period (FX). Their inhibitory responses were not clearly related to the context-dependent modulation of SacRT (PA in FV: F[2, 53] = 6.569, <italic>P</italic> = 0.003 [D versus S: <italic>P</italic> = 0.017; R versus P: <italic>P</italic> = 0.753]; PA in FX: F[2, 53] = 0.868, <italic>P</italic> = 0.426 [D versus S: <italic>P</italic> = 0.449; R versus P: <italic>P</italic> = 0.995]; PI in FV: F[2, 53] = 4.846, <italic>P</italic> = 0.012 [D versus S: <italic>P</italic> = 0.014; R versus P: <italic>P</italic> = 0.933]; PI in FX: F[2, 53] = 2.239, <italic>P</italic> = 0.117 [D versus S: <italic>P</italic> = 0.167; R versus P: <italic>P</italic> = 0.994]; SO in FV: F[2, 29] = 2.916, <italic>P</italic> = 0.070 [D versus S: <italic>P</italic> = 0.558; R versus P: <italic>P</italic> = 0.056]; SO in FX: F[2, 29] = 5.427, <italic>P</italic> = 0.010 [D versus S: <italic>P</italic> = 0.008; R versus P: <italic>P</italic> = 0.143]), unlike excited type neurons.</p>
<fig id="pbio.2005339.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2005339.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Responses of amygdala neurons in three monkeys to scene environments.</title>
<p>(<bold>A</bold>) The numbers of neurons (excited type, inhibited type, others) in monkeys PA, PI, and SO. (<bold>B</bold>) Average activities in the three groups of environments: dangerous (D/R), rich (S/R), and poor (S/P). They are shown separately for the excited-type neurons (top) and the inhibited-type neurons (bottom) for each monkey. The averaging was based on the normalized z-scores of individual neurons (see <xref ref-type="sec" rid="sec009">Materials and methods</xref>). Shaded gray area indicates the free-viewing (left) and fixation (right) periods. (<bold>B</bold>, bottom) Time course of the activity biases of individual neurons in two dimensions of environmental context: dangerous–safe dimension (D versus S) and rich–poor dimension (R versus P) (same format as <xref ref-type="fig" rid="pbio.2005339.g004">Fig 4C</xref>). Individual neuron data are sorted by their mean ΔFR scores in the fixation period, high to low scores. In each dimension, the averaged ΔFR scores are shown by a cyan line with black dots. Data used to generate these plots can be found at <ext-link ext-link-type="uri" xlink:href="https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09" xlink:type="simple">https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09</ext-link>. D/R, dangerous and rich; FR, firing rate; S/P, safe and poor; S/R, safe and rich.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.g005" xlink:type="simple"/>
</fig>
<p>These data raise the possibility that amygdala neurons, as a population, affect saccadic eye movements based on the rich–poor and dangerous–safe dimensions of context. To further address this question, we compared the neuronal activity during the FX period and SacRT (<xref ref-type="fig" rid="pbio.2005339.g006">Fig 6A and 6B</xref>), because the FX period is immediately before the saccade (<xref ref-type="fig" rid="pbio.2005339.g002">Fig 2A</xref>). The effect of the rich–poor context was evaluated by the difference between the poor (S/P) scenes (blue) and the rich (S/R) scenes (red). In monkeys PI and SO, neuronal activity was higher, while SacRT was shorter with the rich than poor scenes (one-way ANOVA and Tukey–Kramer post hoc test; activity in PI: <italic>P</italic> = 0.006; activity in SO: <italic>P</italic> &lt; 0.001; SacRT in PI: <italic>P</italic> &lt; 0.001; SacRT in SO: <italic>P</italic> &lt; 0.001, <xref ref-type="supplementary-material" rid="pbio.2005339.s011">S1 Table</xref>).</p>
<fig id="pbio.2005339.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2005339.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Amygdala neuronal activity and SacRT modulated by two dimensions of scene context.</title>
<p>(<bold>A–B</bold>) Neuronal activity during the fixation period (<bold>A</bold>) and SacRT (<bold>B</bold>) in three monkeys (PA, PI, SO), shown separately for three groups of scenes: S/P, D/R, and S/R. The data (ordinate) are plotted against the predicted reward value (abscissa), which was defined as: reward amount × success rate (see <xref ref-type="sec" rid="sec009">Materials and methods</xref>). Neuronal activity was based on the normalized z-scores; SE is shown by a vertical bar. Asterisk (*) indicates statistically significant contrasts at <italic>P</italic> &lt; 0.05 (scene context: one-way ANOVA, post hoc: Tukey–Kramer [see <xref ref-type="supplementary-material" rid="pbio.2005339.s011">S1 Table</xref>]; predicted versus actual in D/R: one-sample <italic>t</italic> test). (<bold>C</bold>) Relation between the neuronal activity (abscissa) and SacRT (ordinate) for individual scenes. Statistics (Pearson’s correlation) are shown in each graph. The color of each data point indicates the scene context, as used in A and B. Data are based on excited-type neurons (<xref ref-type="fig" rid="pbio.2005339.g005">Fig 5</xref>). Data used to generate these plots can be found at <ext-link ext-link-type="uri" xlink:href="https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09" xlink:type="simple">https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09</ext-link>. D/R, dangerous and rich; S/P, safe and poor; S/R, safe and rich; SacRT, saccade reaction time.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.g006" xlink:type="simple"/>
</fig>
<p>Additionally, the dangerous (D/R) scenes (black) affected the neuronal activity and SacRT. In monkeys PA and SO, neuronal activity with the dangerous (D/R) scenes was higher than the safe scenes, either rich (S/R) or poor (S/P) scenes (activity in PA: <italic>P</italic> &lt; 0.001; activity in SO: <italic>P</italic> &lt; 0.001), while SacRT was shorter than the safe scenes (SacRT in PA: <italic>P</italic> &lt; 0.001; SacRT in SO: <italic>P</italic> &lt; 0.001).</p>
<p>In <xref ref-type="fig" rid="pbio.2005339.g006">Fig 6A and 6B</xref>, the neuronal activity and SacRT are plotted against the predicted reward value. Although the reward volume per delivery event was the same between the dangerous and rich scenes (<xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1A Fig</xref>), the predicted reward value was smaller with the dangerous scenes because the reward was sometimes removed by the robber object (<xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1C Fig</xref>). Then, the effect of dangerous context (yellow circle) can be estimated by comparing the safe context with the same predicted reward value (pink circle). According to this analysis, even in monkey PI, the neuronal activity tended to be higher (one-sample <italic>t</italic> test, PA: <italic>P</italic> &lt; 0.001, <italic>t</italic> = 9.628; PI: <italic>P</italic> = 0.22, <italic>t</italic> = 1.261; SO: <italic>P</italic> &lt; 0.001, <italic>t</italic> = 6.518) and SacRT shorter (one-sample <italic>t</italic> test, PA: <italic>P</italic> &lt; 0.001, <italic>t</italic> = −31.155; PI: <italic>P</italic> &lt; 0.001, <italic>t</italic> = −6.863; SO: <italic>P</italic> &lt; 0.001, <italic>t</italic> = −18.492) with dangerous than with safe scenes.</p>
<p>These data together suggest that the two dimensions of emotional context (i.e., rich–poor, dangerous–safe) worked independently to affect the neuronal activity and SacRT, and they did so somewhat differently across subjects. Importantly, both the rich and dangerous scenes increased the neuronal activity and decreased SacRT. In fact, there was a significant negative correlation between the neuronal activity and SacRT among all three groups of scenes (poor, rich, dangerous) in all the monkeys (<xref ref-type="fig" rid="pbio.2005339.g006">Fig 6C</xref>). These data suggest that both rich and dangerous scenes activated amygdala neurons, which in turn led to the facilitation of saccades. Because the context starts working early after a scene appears (but before an object appears), saccades to both good and bad objects were facilitated (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3</xref>).</p>
<p>Even though many of these amygdala neurons showed context-dependent activity, their activity was often variable or selective across scenes within the same context (<xref ref-type="fig" rid="pbio.2005339.g004">Fig 4</xref>). Notably, such variability was different across neurons that are sensitive to the same context in the same monkey (<xref ref-type="supplementary-material" rid="pbio.2005339.s005">S5A Fig</xref>). Presumably, based on the variable variability, amygdala neurons as a population were less variably active in different scenes that belonged to a particular context (<xref ref-type="supplementary-material" rid="pbio.2005339.s005">S5B Fig</xref>). Overall, the scene selectivity tended to be lower in the population activity than in individual neuronal activity, especially before the first saccade (FX period) (<xref ref-type="supplementary-material" rid="pbio.2005339.s005">S5C Fig</xref>) (one-sample <italic>t</italic> test; PA[D/R]: <italic>P</italic> &lt; 0.001, <italic>t</italic> = 5.435; PA[S/R]: <italic>P</italic> = 0.104, <italic>t</italic> = –1.653; PA[S/P]: <italic>P</italic> = 0.986, <italic>t</italic> = –0.017; PI[D/R]: <italic>P</italic> = 0.068, <italic>t</italic> = 1.868; PI[S/R]: <italic>P</italic> = 0.012, <italic>t</italic> = 2.606; PO[S/P]: <italic>P</italic> = 0.023, <italic>t</italic> = –2.345; SO[D/R]: <italic>P</italic> = 0.042, <italic>t</italic> = 2.084; SO[S/R]: <italic>P</italic> &lt; 0.001, <italic>t</italic> = 4.750; SO[S/P]: <italic>P</italic> &lt; 0.001, <italic>t</italic> = 7.091).</p>
<p>Notably, any context is based on the behavioral outcome associated with each environment. What happens if the outcome is changed? To address this question, we let the subjects experience some of the well-learned scenes, but with a different outcome (i.e., no object, no robber) in a nonforaging task and examined some danger-sensitive neurons (<xref ref-type="supplementary-material" rid="pbio.2005339.s006">S6A Fig</xref>). Although the nonforaging task was presented separately from the foraging task, these neurons were still activated by the dangerous scenes immediately after their appearance in the nonforaging task (<xref ref-type="supplementary-material" rid="pbio.2005339.s006">S6C</xref>, <xref ref-type="supplementary-material" rid="pbio.2005339.s006">S6E</xref> and <xref ref-type="supplementary-material" rid="pbio.2005339.s006">S6G Fig</xref>). Moreover, they expressed scene selectivity that was similar to the selectivity in the foraging task. These results suggest that amygdala neurons can be activated automatically when the subject encounters emotional environments that are no longer associated with emotional events. Their activity decreased quickly, however, suggesting that these automatic responses were suppressed by subsequent events in the trial.</p>
<p>Our data so far have shown that the effects of the environment context were somewhat different across subjects. Does this mean that they have different sensitivities to emotion? To address this question, we compared pupil size and heart rate across the three groups of scenes (<xref ref-type="fig" rid="pbio.2005339.g007">Fig 7</xref>). The pupil size was affected by both dimensions of context (<xref ref-type="fig" rid="pbio.2005339.g007">Fig 7A</xref>): larger with the rich than the poor scenes and also larger with the dangerous than the safe scenes. This result was seen in all subjects, suggesting that all of the monkeys were sensitive to both richness and danger. The heart rate (<xref ref-type="fig" rid="pbio.2005339.g007">Fig 7B</xref>) was higher with the rich than the poor scenes in monkeys PI and SO (but not PA) and with the dangerous than safe scenes in monkey PA and SO (but not PI). This result followed the same pattern seen with amygdala neuronal activity and SacRT (<xref ref-type="fig" rid="pbio.2005339.g006">Fig 6</xref>) and raises the possibility that both heart rate and saccades are modulated by amygdala neurons, based on the environment context.</p>
<fig id="pbio.2005339.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2005339.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Pupil size and heart rate modulated by two dimensions of environmental context.</title>
<p>Pupil size (<bold>A</bold>) and heart rate (<bold>B</bold>) during the fixation period in all three monkeys, shown separately for three groups of environments: S/P, D/R, and S/R. The physiological measures (ordinate) are plotted against the predicted reward value (abscissa), defined as reward volume × success rate (see <xref ref-type="supplementary-material" rid="pbio.2005339.s002">S2D Fig</xref>). Same format as <xref ref-type="fig" rid="pbio.2005339.g006">Fig 6A and 6B</xref>. Asterisk (*) indicates statistically significant contrasts at <italic>P</italic> &lt; 0.05 (environment context: one-way ANOVA, post hoc: Tukey–Kramer [see <xref ref-type="supplementary-material" rid="pbio.2005339.s012">S2 Table</xref>]; predicted versus actual in D/R: one-sample <italic>t</italic> test, pupil size [PA]: <italic>P</italic> &lt; 0.001, <italic>t</italic> = 14.962, pupil size [PI]: <italic>P</italic> &lt; 0.001, <italic>t</italic> = 10.639, pupil size [SO]: <italic>P</italic> &lt; 0.001, <italic>t</italic> = 39.775; heart rate [PA]: <italic>P</italic> = 0.001, <italic>t</italic> = 2.571; heart rate [PI]: <italic>P</italic> = 0.986, <italic>t</italic> = 0.017; heart rate [SO]: <italic>P</italic> = 0.018, <italic>t</italic> = 2.377). Data used to generate these plots can be found at <ext-link ext-link-type="uri" xlink:href="https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09" xlink:type="simple">https://osf.io/2yq8p/?view_only=97c4b290514348bb91cdbb9ec1c85e09</ext-link>. D/R, dangerous and rich; n.s., not significant; S/P, safe and poor; S/R, safe and rich.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.g007" xlink:type="simple"/>
</fig>
<p>The mere presence of dangerous scenes affected SacRT to the first object as well as amygdala neuronal activity preceding the saccade in monkeys PA and SO (<xref ref-type="fig" rid="pbio.2005339.g006">Fig 6</xref>). However, the appearance of an actual robber was a more threatening event. We refer to the presence or absence of a robber object as “object context.” Additionally, some trials with safe scenes contained a distractor object that stayed on the screen but never robbed a good object (<xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1 Fig</xref>). We defined “object context” as the presence or absence of robber or distractor objects. We then examined the effect of object context over and above effects of danger and richness considered thus far (<xref ref-type="supplementary-material" rid="pbio.2005339.s007">S7 Fig</xref>). The data suggest that amygdala neurons could facilitate saccades based on the object context, in addition to the scene context. This is explained in detail in the legend of <xref ref-type="supplementary-material" rid="pbio.2005339.s007">S7 Fig</xref>.</p>
<p>Finally, we estimated the locations of these neurons by the 3D coordinates of the recording sites that were aligned on magnetic resonance (MR) images (<xref ref-type="fig" rid="pbio.2005339.g008">Fig 8</xref>). Neurons responding to the visual environments (scenes) were located in various areas in the amygdala, presumably including the central (CE), lateral (L), and basolateral (BL) nuclei (<xref ref-type="fig" rid="pbio.2005339.g008">Fig 8B</xref>). Neurons that were sensitive to the dangerous–safe dimension of context (D &gt; S; S &gt; D) were located mainly in CE and sparsely in BL and L (<xref ref-type="fig" rid="pbio.2005339.g008">Fig 8C</xref>). Neurons that were sensitive to the rich–poor dimension of context (R &gt; P; P &gt; R) seem localized in CE (<xref ref-type="fig" rid="pbio.2005339.g008">Fig 8D</xref>). Compared with neurons in BL and L, neurons in CE had more variable features, including the background firing rate (<xref ref-type="supplementary-material" rid="pbio.2005339.s008">S8C and S8D Fig</xref>) and scene selectivity (<xref ref-type="supplementary-material" rid="pbio.2005339.s008">S8E and S8F Fig</xref>).</p>
<fig id="pbio.2005339.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2005339.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Estimated positions of recorded neurons.</title>
<p>Recording sites are shown in five coronal MR images spanning 0–4 mm posterior to the AC. <bold>(A)</bold> Amygdala and surrounding brain areas. <bold>(B–D)</bold> The neurons’ positions are shown, based on different features. <bold>(B)</bold> Neurons excited and inhibited by visual scenes during the fixation period, and neurons showing no response to the scenes (Visual −). <bold>(C)</bold> Excited-type neurons showing significantly different activity between dangerous (D) and safe (S) contexts (D &gt; S; S &gt; D), and others (D = S). <bold>(D)</bold> Excited-type neurons showing significantly different activity between rich (R) and poor (P) contexts (R &gt; P; P &gt; R), and others (R = P). AC, anterior commissure; BL, basolateral complex of the amygdala; CE, central nucleus of the amygdala; D, dangerous; HP, hippocampus; L, lateral nucleus of the amygdala; LV, lateral ventricle; MR, magnetic resonance; OC, optic chiasm; OT, optic tract; P, poor; PU, putamen; R, rich; S, safe.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.g008" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec003" sec-type="conclusions">
<title>Discussion</title>
<sec id="sec004">
<title>Amygdala neuronal activity correlated with context-based saccades</title>
<p>Goal-directed behavior is affected by various contexts [<xref ref-type="bibr" rid="pbio.2005339.ref007">7</xref>]. Furthermore, neurons in various brain areas [<xref ref-type="bibr" rid="pbio.2005339.ref004">4</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref019">19</xref>–<xref ref-type="bibr" rid="pbio.2005339.ref023">23</xref>], including the amygdala [<xref ref-type="bibr" rid="pbio.2005339.ref003">3</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref024">24</xref>], are sensitive to both target and context information, suggesting that these regions contribute to context-dependent decision-making. However, it was still unclear from previous studies which brain areas process individual contexts, largely because targets and contexts were presented simultaneously. To dissociate these effects, we presented the scene context before the target objects appeared.</p>
<p>This design allowed us to find that many amygdala neurons became active during the appearance of scenes but before objects appeared (Figs <xref ref-type="fig" rid="pbio.2005339.g004">4</xref> and <xref ref-type="fig" rid="pbio.2005339.g005">5</xref>). Moreover, the population activity of amygdala neurons was negatively correlated with SacRT in all three monkeys (<xref ref-type="fig" rid="pbio.2005339.g006">Fig 6C</xref>), suggesting that these neurons facilitate the initiation of saccades. Because the neuronal activity changed before the appearance of an object, it could modulate the whole distribution of SacRTs. This fact could account for the speeding of saccades of all latencies in dangerous or rich contexts (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3A</xref>). This parallel shift of the whole SacRT distribution by environment context stands in contrast to the effect of object value on saccades in that good objects cannot attract faster saccades at the shortest latencies (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3B</xref>).</p>
<p>We used two dimensions of context (i.e., rich–poor and dangerous–safe) by categorizing many visual scenes. First, in contrast to poor scenes, rich scenes increased amygdala neuronal activity and decreased SacRT in two monkeys (PI and SO) (<xref ref-type="fig" rid="pbio.2005339.g006">Fig 6A and 6B</xref>). This finding is relevant to studies showing that amygdala neurons encode internally generated reward goals [<xref ref-type="bibr" rid="pbio.2005339.ref012">12</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref025">25</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref026">26</xref>]. Second, the dangerous–safe dimension of context was examined by dangerous scenes where the good object can be removed by a third (“robber”) object (<xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1B Fig</xref>). These dangerous scenes (compared with safe scenes) increased amygdala neuronal activity and decreased SacRT in two monkeys (PA and SO) (<xref ref-type="fig" rid="pbio.2005339.g006">Fig 6A and 6B</xref>). Importantly, both dimensions of context (rich–poor and dangerous–safe) affected amygdala neuronal activity and SacRT in opposite directions (i.e., increases versus decreases). This suggests that amygdala neurons facilitate saccades based on these two dimensions of environmental context.</p>
<p>Our results are consistent with previous studies showing that the amygdala is involved in gaze orientation and attention [<xref ref-type="bibr" rid="pbio.2005339.ref027">27</xref>–<xref ref-type="bibr" rid="pbio.2005339.ref031">31</xref>], including a study suggesting that the amygdala enhances attention to visual stimuli associated with rewarding or aversive experiences [<xref ref-type="bibr" rid="pbio.2005339.ref032">32</xref>].</p>
</sec>
<sec id="sec005">
<title>Effects of multiple contexts</title>
<p>These results raise a question: are the two context-based mechanisms operated by the same or by different groups of amygdala neurons? If the same, the two dimensions of context (rich–poor and dangerous–safe) would have similar neuronal–behavioral effects and would do so in all subjects, which was not the case in our study. Thus, two different groups of amygdala neurons may encode the two dimensions of context selectively. The across-subject difference (e.g., monkey PI versus PA) may reflect the biased activation of the amygdala neurons: more activation of the rich–poor neurons in monkey PI and of the dangerous–safe neurons in monkey PA. This speculative mechanism might be related to emotional dimensions [<xref ref-type="bibr" rid="pbio.2005339.ref033">33</xref>].</p>
<p>Why, then, did different contexts affect the three monkeys somewhat differently? For example, judging by neuronal responses and saccade metrics, monkey PI seemed insensitive to dangerous scenes (<xref ref-type="fig" rid="pbio.2005339.g006">Fig 6A and 6B</xref>). However, pupil size was affected by the three groups of scenes (poor, rich, dangerous) similarly in all three monkeys (<xref ref-type="fig" rid="pbio.2005339.g007">Fig 7A</xref>), suggesting that they shared the same types of emotion or arousal [<xref ref-type="bibr" rid="pbio.2005339.ref034">34</xref>–<xref ref-type="bibr" rid="pbio.2005339.ref036">36</xref>]. These data suggest that a change in the emotional state started affecting the amygdala-saccade mechanism in different time courses across subjects: before the robber object appeared in monkeys PA and SO (<xref ref-type="fig" rid="pbio.2005339.g006">Fig 6A and 6B</xref>) and after the robber object appeared in monkey PI (<xref ref-type="supplementary-material" rid="pbio.2005339.s007">S7B Fig</xref>). In contrast with pupil size effects, heart rate effects matched the pattern of changes seen in the amygdala recordings and saccade metrics (Figs <xref ref-type="fig" rid="pbio.2005339.g007">7B</xref>, <xref ref-type="fig" rid="pbio.2005339.g006">6A and 6B</xref>).</p>
<p>We also found that both amygdala neuronal activity and SacRT were affected by the presence of nonthreatening distractor objects that never robbed the reward (<xref ref-type="supplementary-material" rid="pbio.2005339.s007">S7 Fig</xref>). Because the success rate (i.e., probability of rewarded trials) was not significantly different between the distractor present or absent trials, the change in SacRT is unlikely to be caused by the dangerous context. Instead, it may be related to a higher demand of attention when two objects are present simultaneously [<xref ref-type="bibr" rid="pbio.2005339.ref037">37</xref>].</p>
</sec>
<sec id="sec006">
<title>Neural circuit model for target choice modulated by emotional contexts</title>
<p>Based on these results, we propose a scheme for the context-target interaction (<xref ref-type="fig" rid="pbio.2005339.g009">Fig 9</xref>). During the foraging task used in this study, a particular circuit originating from the tail of the caudate nucleus (CDt) is likely to control the targeting of saccades. Its final output station is the caudal-dorsal-lateral part of the substantia nigra pars reticulata (cdlSNr), where neurons discriminate between good and bad objects about 100 ms after object appearance in the contralateral-peripheral position and send the information to the SC [<xref ref-type="bibr" rid="pbio.2005339.ref038">38</xref>]. Therefore, the CDt-cdlSNr-SC circuit may cause the object-based change in SacRT in our foraging task (<xref ref-type="fig" rid="pbio.2005339.g003">Fig 3B</xref>). Importantly, this mechanism works regardless of the context.</p>
<fig id="pbio.2005339.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2005339.g009</object-id>
<label>Fig 9</label>
<caption>
<title>How emotional–environmental contexts affect saccadic eye movement—hypothetical neural circuits.</title>
<p>cdlSNr, caudal-dorsal-lateral part of the substantia nigra pars reticulata; cdlSNc, caudal-dorsal-lateral part of the substantia nigra pars compacta; CDt, caudate nucleus; cvGPe, caudal-ventral part of the globus pallidus externus; SC, superior colliculus.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.g009" xlink:type="simple"/>
</fig>
<p>This basal ganglia circuit may be modified by the inputs from the amygdala [<xref ref-type="bibr" rid="pbio.2005339.ref039">39</xref>–<xref ref-type="bibr" rid="pbio.2005339.ref043">43</xref>], which convey multiple dimensions of context information. The caudal-ventral part of the striatum (including CDt) receives inputs from the basal nucleus of the amygdala (BA) [<xref ref-type="bibr" rid="pbio.2005339.ref039">39</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref043">43</xref>], which in turn can facilitate corticostriatal synaptic plasticity [<xref ref-type="bibr" rid="pbio.2005339.ref044">44</xref>]. In addition, the substantia nigra pars compacta (SNc) and pars reticulata (SNr, including cdlSNr) receives inputs from the CE [<xref ref-type="bibr" rid="pbio.2005339.ref040">40</xref>–<xref ref-type="bibr" rid="pbio.2005339.ref042">42</xref>]. Notably, most neurons sensitive to the scene-based context were located in or close to CE (<xref ref-type="fig" rid="pbio.2005339.g008">Fig 8</xref>) [<xref ref-type="bibr" rid="pbio.2005339.ref045">45</xref>]. In this sense, the CE–SN connection [<xref ref-type="bibr" rid="pbio.2005339.ref046">46</xref>] might play a major role.</p>
<p>In our foraging task the performance of the monkeys was extraordinary in several aspects, specifically fast learning, high-capacity memory, and fast saccadic reactions. The SacRTs were largely in the range of express saccades [<xref ref-type="bibr" rid="pbio.2005339.ref047">47</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref048">48</xref>], which are controlled directly by SC [<xref ref-type="bibr" rid="pbio.2005339.ref049">49</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref050">50</xref>]. This SC mechanism may be promoted by amygdala neurons that were sensitive to the emotional contexts (i.e., dangerous, safe, rich, poor). Such emotional signals may be used for defensive behavior through the SNr–SC circuit [<xref ref-type="bibr" rid="pbio.2005339.ref051">51</xref>], consistent with our scheme (<xref ref-type="fig" rid="pbio.2005339.g009">Fig 9</xref>). This mechanism might work commonly in real-world contexts [<xref ref-type="bibr" rid="pbio.2005339.ref052">52</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref053">53</xref>].</p>
</sec>
<sec id="sec007">
<title>Categorization of scenes into contexts</title>
<p>How, then, does the amygdala obtain information? The subjects experienced many scene images, each of which acted as an environment that contained two or three objects. We therefore speculate that the amygdala receives environmental information from scene-sensitive neurons (<xref ref-type="fig" rid="pbio.2005339.g009">Fig 9</xref>). Indeed, the parahippocampal area contains scene-sensitive neurons [<xref ref-type="bibr" rid="pbio.2005339.ref008">8</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref054">54</xref>] and also projects to the amygdala [<xref ref-type="bibr" rid="pbio.2005339.ref055">55</xref>]. Notably, some amygdala neurons responded to the scenes variably, even among scenes that belonged to the same context (<xref ref-type="supplementary-material" rid="pbio.2005339.s005">S5 Fig</xref>). These findings suggest that each amygdala neuron intrinsically receives inputs from a variable assortment of scene-sensitive neurons. As a result, some of the amygdala neurons would have limited information about the contexts. As a population, however, because the within-context variability is lower, the across-context differences are signaled clearly (<xref ref-type="supplementary-material" rid="pbio.2005339.s005">S5 Fig</xref>). An equivalent process of categorization is present in the CDt-cdlSNr-SC circuit, through which target context could be established [<xref ref-type="bibr" rid="pbio.2005339.ref056">56</xref>].</p>
<p>However, the scenes themselves may have no information about context. Context is created by learning—that is, by experiencing various events repeatedly in each scene, such as the occurrence of robbers or big rewards [<xref ref-type="bibr" rid="pbio.2005339.ref003">3</xref>, <xref ref-type="bibr" rid="pbio.2005339.ref007">7</xref>]. Because the contexts in our foraging task were emotional (i.e., dangerous, safe, rich, poor) [<xref ref-type="bibr" rid="pbio.2005339.ref016">16</xref>], the information of each scene must be modified by a separate source of information related to the emotional events (<xref ref-type="fig" rid="pbio.2005339.g009">Fig 9</xref>). This may be controlled by various inputs from emotion-sensitive brain areas [<xref ref-type="bibr" rid="pbio.2005339.ref057">57</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref058">58</xref>] and neuromodulatory neurons, including dopamine, norepinephrine, serotonin, oxytocin, and acetylcholine [<xref ref-type="bibr" rid="pbio.2005339.ref030">30</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref059">59</xref>]. Thus, the cortico-amygdala connection may be modulated by the emotional inputs, for example, another person's direct gaze [<xref ref-type="bibr" rid="pbio.2005339.ref060">60</xref>].</p>
</sec>
<sec id="sec008">
<title>Social–emotional roles of saccade</title>
<p>If the amygdala mechanism (<xref ref-type="fig" rid="pbio.2005339.g009">Fig 9</xref>) is disrupted, the automatic saccades to target objects would be suppressed in some contexts. This actually occurs in human subjects with amygdala lesions [<xref ref-type="bibr" rid="pbio.2005339.ref061">61</xref>]. When facing other humans, they rarely look at their eyes, unlike control subjects. This appears to be dependent on social context (in which fearful emotions might be evoked), because such saccade suppression can be eliminated when only a small region of the face is made visible [<xref ref-type="bibr" rid="pbio.2005339.ref062">62</xref>]. Similar changes in social–emotional saccades occur in human subjects with amygdala dysfunctions (e.g., autism) [<xref ref-type="bibr" rid="pbio.2005339.ref063">63</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref064">64</xref>]. These results suggest that the amygdala mechanism on saccade attention is important personally and socially.</p>
<p>We have suggested that the amygdala modulates goal-directed behavior based on emotional contexts. However, different kinds of context are likely controlled by different brain areas [<xref ref-type="bibr" rid="pbio.2005339.ref065">65</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref066">66</xref>]. For example, something unexpected often suppresses ongoing behavior, which may be controlled by dorsomedial cortical areas [<xref ref-type="bibr" rid="pbio.2005339.ref067">67</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref068">68</xref>]. Overall, many brain areas may modulate behavior based on specific or integrated contexts [<xref ref-type="bibr" rid="pbio.2005339.ref069">69</xref>,<xref ref-type="bibr" rid="pbio.2005339.ref070">70</xref>].</p>
</sec>
</sec>
<sec id="sec009" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec010">
<title>Ethics statement</title>
<p>All animal care and experimental procedures were approved by the National Eye Institute Animal Care and Use Committee (proposal number: NEI-622) and complied with the Public Health Service Policy on the humane care and use of laboratory animals. Anesthesia was induced with ketamine and diazepam, after which animals were intubated and then maintained with isoflurane. Animals had respiratory, blood pressure, and electrocardiogram monitors and were placed on a heating pad throughout the period of anesthesia.</p>
</sec>
<sec id="sec011">
<title>General procedures</title>
<p>Three adult male monkeys (rhesus macaque), PA (9.0 kg, 9 y old), PI (13.0 kg, 7 y old), and SO (9.0 kg, 6 y old), were used for behavioral testing and neuronal recording.</p>
<p>We implanted a plastic head holder and a plastic recording chamber to the skull under general anesthesia and sterile surgical conditions. One search coil was surgically implanted under the conjunctiva of an eye in each monkey to record eye movements. After the monkeys fully recovered from surgery, we started training them on the foraging task.</p>
</sec>
<sec id="sec012">
<title>Foraging task</title>
<p>Behavioral tasks were controlled by a custom neural-recording and behavior-controlling system (Blip; available at <ext-link ext-link-type="uri" xlink:href="http://www.robilis.com/blip/" xlink:type="simple">http://www.robilis.com/blip/</ext-link>). The monkeys sat in a primate chair facing a fronto-parallel screen in a sound-attenuated and electrically shielded room. Visual stimuli were rear-projected on the screen by a digital light processing projector (PJD8353s, ViewSonic). Eye position was sampled at 1 kHz using the scleral search coil (monkey PA) or a video-based eye tracker (EyeLink 1000 Plus, SR Research; monkeys PI and SO).</p>
<p>We devised a foraging task in which the monkeys viewed many scenes presented in randomized order across different trials (<xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref>). Each scene contained at least two objects with different features (<xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1 Fig</xref>). Objects #1 and #2 were responsive to the subject’s choice (i.e., sustained gaze). Saccades to object #1 gave the subject a reward (called “good” object), whereas saccades to object #2 gave no reward (called “bad” object). Thus, the subject’s goal was to make saccades to object #1 but not object #2. Such objects were present in all scenes, although they were visually different. Some scenes also contained the third object (object #3, “robber” or “distractor”). Based on the effects of these objects, the scenes were classified into several groups, as described below.</p>
<p>We will first describe the physical features of the scene and object (<xref ref-type="fig" rid="pbio.2005339.g001">Fig 1</xref>). The scene was a large visual image (circular, radius: 25 deg) that was projected onto a screen in front of the subject (distance: 45 cm). The scenes were grayscale images derived from Google Earth imagery (<ext-link ext-link-type="uri" xlink:href="https://www.google.com/earth/" xlink:type="simple">https://www.google.com/earth/</ext-link>). Example scene images in Figs <xref ref-type="fig" rid="pbio.2005339.g001">1</xref>, <xref ref-type="fig" rid="pbio.2005339.g002">2A</xref>, <xref ref-type="supplementary-material" rid="pbio.2005339.s010">S2A Fig</xref>, <xref ref-type="supplementary-material" rid="pbio.2005339.s009">S1</xref> and <xref ref-type="supplementary-material" rid="pbio.2005339.s010">S2 Movies</xref> were derived from OpenAerialMap (<ext-link ext-link-type="uri" xlink:href="https://openaerialmap.org/" xlink:type="simple">https://openaerialmap.org</ext-link>). The objects were computer-generated fractals with multiple colors (radius about 5 deg). They were small enough to be presented at different positions in the scene (<xref ref-type="fig" rid="pbio.2005339.g001">Fig 1</xref>). Because it was unlikely that the subject had seen any of the objects or scenes before the experiment, we could control the levels of both object–reward association learning and scene–context association learning. Furthermore, we could generate an infinite number of novel objects and novel scene images. These features allowed us to repeat these association learnings with fresh visual stimuli.</p>
<p>To examine the behavioral and neuronal encoding of scenes (environments), both the learning (of the meanings of objects and scenes) and testing (of the monkey’s behavior and of the activity of the amygdala neurons) were done in the same task procedure (Figs <xref ref-type="fig" rid="pbio.2005339.g001">1</xref> and <xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1</xref>). After the ITI (4–8 s), a scene appeared suddenly and the subject was allowed to view the scene freely for 1,080 ms (FV period). Then, a fixation point (FP) appeared at the center. If the subject held its gaze on the FP for 780 ms (FX period), an object appeared at the same time as the FP disappeared. The object appearance was random and unpredictable in two ways: (1) sequence: two or three objects contained in the scene appeared randomly in sequence and (2) position: the objects appeared randomly at one of eight positions (eccentricity: 15 deg; angle: in steps of 45 deg from straight up).</p>
<p>A response to object #1 (good) or #2 (bad) occurred if the subject made saccade to it within 1,000 ms and kept fixating on it (&gt;400 ms). This action was followed by a reward with the good object and no reward with the bad object, either of which ended the trial. Depending on the scene, the size of reward was either big (0.3 mL) or small (0.1 mL). To gain a reward the subject needed to refrain from responding to the bad object so as to wait for the good object. There were two ways to perform “no action”: (1) no saccade to the bad object or (2) saccade to the bad object followed quickly (within 400 ms) by a second saccade away from the bad object. Both subjects performed the latter no-action behaviors more commonly. After the no-action, the FP reappeared and the object presentation cycle was repeated, with the possibility that the good object might appear (<xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1 Fig</xref>).</p>
<p>Some scenes were designated as “dangerous” contexts and could feature the appearance of a third type of object (called the “robber” object). After appearing, it remained in place (irrespective of the subject’s eye movements) until either the good or the bad object appeared. If the bad object appeared, the robber object did nothing and the subject simply needed to make no action before FP reappeared. If the good object appeared, the robber was programmed to jump across the screen and interrupt the object with timing designed to race against the monkey’s saccade to the good target. On trials for which the robber’s jump preceded the monkey’s response, the robber “stole” the reward that would otherwise follow a correct saccade to the good object. Stolen trials occurred if the subject’s saccade was delayed (reaction time: &gt;90–120 ms for monkey PA, &gt;100–180 ms for monkey PI, &gt; 95–125 ms for monkey SO; the threshold was random across trials between these numbers). Otherwise, the subject obtained the reward (<xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1 Fig</xref>). If the subject failed (i.e., the robber beat the saccade), the same trial was repeated in the same sequence until a successful trial (i.e., the saccade beat the robber), but these repeated trials were not included in behavioral and neuronal analysis. To encourage the subject, the criterion reaction time was incremented by 10 ms after each failure. There was another effect of the robber object in some scenes (#170–173, #190–193, #240–243, 280–283, shown in <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref>): on trials in which the subject failed (robber wins), an air puff was delivered to the subject’s face. A third object also appeared in some scenes that were designated as “safe” scenes. This object #3 was called the “distractor” object and, like the robber, lingered on the screen but never attacked the good object (<xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1 Fig</xref>).</p>
<p>Monkeys PA and PI both learned 56 scenes and 140 objects, and monkey SO learned 32 scenes and 68 objects. In each experimental session, many of the scenes (i.e., 32 scenes for each subject) were presented randomly.</p>
<p>These combinations of scenes and objects together constituted two dimensions of context.</p>
<list list-type="simple">
<list-item><p>(1) Dangerous (D) versus safe (S):</p>
<list list-type="simple">
<list-item><p>Dangerous: the robber object is present and might appear but does not do so on every trial.</p></list-item>
<list-item><p>Safe: the robber object is absent.</p></list-item>
</list></list-item>
<list-item><p>(2) Rich (R) versus poor (P):</p>
<list list-type="simple">
<list-item><p>Rich: the good object is associated with a big reward (0.3 mL).</p></list-item>
<list-item><p>Poor: the good object is associated with a small reward (0.1 mL).</p></list-item>
</list>
<p>By combining the context dimensions in a 2 × 2 matrix, we created environments matching three of the possible combinations (<xref ref-type="fig" rid="pbio.2005339.g001">Fig 1C</xref>):</p>
<list list-type="simple">
<list-item><p>(1) dangerous and rich (D/R)</p></list-item>
<list-item><p>(2) safe and rich (S/R)</p></list-item>
<list-item><p>(3) safe and poor (S/P)</p></list-item>
</list>
<p>For practical purposes, the fourth (D/P) combination was not used. Pairwise contrasts in behavioral or neuronal activity between groups indicated a context effect, as follows:</p>
<list list-type="simple">
<list-item><p>(1) D/R versus S/R: dangerous–safe context.</p></list-item>
<list-item><p>(2) S/R versus S/P: rich–poor context.</p></list-item>
</list></list-item>
</list>
</sec>
<sec id="sec013">
<title>Nonforaging task</title>
<p>Some neurons were tested in this task to investigate whether recorded neurons could discriminate the contexts or environments absent the usual the outcomes (<xref ref-type="supplementary-material" rid="pbio.2005339.s006">S6A Fig</xref>). At the beginning of the trial, the monkeys had to keep fixating on FP until FP disappeared (700–1,200 ms). Then, a scene image was presented for 2,000 ms at the center of the screen and the subject was allowed to view the scene freely. After that, the scene image disappeared and the FP appeared at a random peripheral position (10 degrees from center). If the monkey continued fixating on the FP until it disappeared (700–1,200 ms), a reward was delivered.</p>
</sec>
<sec id="sec014">
<title>Electrophysiology</title>
<p>Based on a stereotaxic atlas (Saleem and Logothetis, 2007), we implanted a rectangular chamber targeting the amygdala. The chamber was tilted laterally by 20 degrees for monkeys PA and PI and tilted anteriorly by 15 degrees for monkey SO. MR images (4.7 T, Bruker) were then obtained along the direction of the recording chamber, which was visualized with gadolinium that filled grid holes and the space outside the grid and inside the chamber. Single-unit recording was performed using glass-coated electrodes (Alpha-Omega). The electrode was inserted into the brain through a stainless steel guide tube and advanced by an oil-driven micromanipulator (MO-97A, Narishige). The recording sites were determined by using a grid system that allowed recordings at 1-mm intervals in x- and y-directions, orthogonal to the guide tube. The input from the electrode was amplified with a band-pass filter (0.2–10 kHz; BAK). Neuronal spikes were isolated online using custom software implementing a voltage and time window discriminator (Blip). To find visually responsive amygdala neurons, we let the monkey continue to perform the foraging task and checked responses to scene images and object images. We examined any neuron systematically if it responded to at least one scene image (<italic>n</italic> = 54 in monkey PA, <italic>n</italic> = 50 in monkey PI, and <italic>n</italic> = 54 in monkey SO; see <xref ref-type="supplementary-material" rid="pbio.2005339.s008">S8B Fig</xref>) using the foraging task.</p>
</sec>
<sec id="sec015">
<title>Quantification and statistical analysis</title>
<sec id="sec016">
<title>Behavior analysis</title>
<p>In order to study the pure effect of the environment (scene) on the targeting behavior, we analyzed the reaction time of the first saccade to an object (either good or bad object) in each trial. Up to this point, everything was the same across trials, except for the scene (see <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1A and 1B</xref>). For the object context, we analyzed the second or later saccades, both before and after distractor/robber was presented.</p>
<p>To evaluate the effects of the scene–context and object–reward association learning, we measured two parameters: (1) the probability of choosing good objects (<xref ref-type="supplementary-material" rid="pbio.2005339.s002">S2B Fig</xref>) and (2) the SacRT (<xref ref-type="supplementary-material" rid="pbio.2005339.s002">S2C Fig</xref>). The choice probability was calculated as follows: “Choice probability = N<sub>good</sub> / (N<sub>good</sub> + N<sub>bad</sub>),” where N<sub>good</sub> and N<sub>bad</sub> are the number of trials of choosing the good object and the bad object, respectively. SacRT was measured as the time between the offset of the FP (simultaneous with the onset of the object) and the onset of the saccade to the fractal object. Saccades were detected when the peak velocity of the polar component exceeded 300 degrees/s. Saccade onset time was defined as the time point preceding the detected saccade at which the velocity exceeded 30 degrees/s.</p>
<p>As described in Figs <xref ref-type="fig" rid="pbio.2005339.g002">2</xref>, <xref ref-type="fig" rid="pbio.2005339.g003">3</xref>, and <xref ref-type="fig" rid="pbio.2005339.g006">6</xref>, SacRT was measured only for the saccade to the first object (either good or bad object) in each trial. SacRT for trials in which the robber or distractor objects appeared was analyzed in <xref ref-type="supplementary-material" rid="pbio.2005339.s007">S7A Fig</xref>. Repeat trials showing the same scene after errors, failure trials, or saccades to wrong directions were excluded from analysis. To compare the SacRTs in different contexts (<xref ref-type="fig" rid="pbio.2005339.g006">Fig 6</xref>), the mean SacRTs in these contexts were calculated and compared with one-way ANOVAs (three groups [D/R, S/R, S/P], post hoc: Tukey–Kramer).</p>
<p>To compare SacRT between different contexts and objects, the cumulative distributions of SacRTs were plotted on a probit scale with a reciprocal time axis (reciprobit plot, Figs <xref ref-type="fig" rid="pbio.2005339.g002">2</xref> and <xref ref-type="fig" rid="pbio.2005339.g003">3</xref>) [<xref ref-type="bibr" rid="pbio.2005339.ref018">18</xref>]. In this procedure a cumulative Gaussian distribution was transformed to a straight line as reciprobit plot. Variation in the mean rate of the distribution leads to horizontal, self-parallel translation of the reciprobit plot [<xref ref-type="bibr" rid="pbio.2005339.ref018">18</xref>]. Altering the variance of a distribution rotates the plot around its median.</p>
<p>Additionally, we examined pupil size and heart rate in the foraging task. Pupillary changes were recorded by using video-based eye tracker (EyeLink 1000 Plus, SR Research). Heart rates were measured by using a pulse sensor (World Famous Electronics llc) at the ear. Outliers related to eyelid closure or loss of the eye-tracking signals were detected and removed. Mean pupil diameter in each trial was calculated during 500 ms before target onset, when gaze was fixed (FX period). Heart rate was calculated from recent interpulse interval before target onset in the FX period. These values were converted to z-scores across trials.</p>
</sec>
<sec id="sec017">
<title>Neuronal activity analysis</title>
<p>A main purpose of this study was to examine the pure effect of the environment (scene) on neuronal activity. For this purpose, we focused on the neuronal activity in the early stage of each trial (i.e., after the scene appeared and before the first object appeared) (see <xref ref-type="fig" rid="pbio.2005339.g002">Fig 2A</xref>). Immediately after this epoch, the first saccade to the object occurred, which we analyzed specifically (see above, Behavior analysis). This early stage contained two periods: FV period (scene onset to FX start timing, around 1,100 ms) and FX period (FX start to object onset timing, around 800 ms). We analyzed neuronal data for these periods separately as well as in combination.</p>
<p>First, we classified neurons into either excited type or inhibited type (<xref ref-type="fig" rid="pbio.2005339.g005">Fig 5</xref>). This was determined by the difference in the firing rate between FX period and baseline period (500–0 ms before scene presentation) in one of the environment groups (D/R, S/R, or S/P) that affected the neuron most strongly. If the firing rates were significantly larger or smaller than the baseline firing rates (<italic>P</italic> &lt; 0.05, Wilcoxon rank-sum test), the neuron was defined as either excited or inhibited type, respectively. The excited-type neurons were used to calculate population neuronal activities for environment contexts.</p>
<p>We measured the latency of the neuronal response to the scene in general (<xref ref-type="supplementary-material" rid="pbio.2005339.s004">S4 Fig</xref>). It was calculated for the excited-type neurons. At each time point after scene onset, the averaged discharge rate was calculated during the 35-ms period before that time point (period A) and during the preceding 200-ms period (i.e., the 235–35 ms period before the time point) (period B). Then, the average discharge rate during period A was compared with that during period B (student <italic>t</italic> test). If the averaged discharge rate was significantly different between period A and period B (<italic>P</italic> &lt; 0.05), that time point was regarded as a time of significant difference. This procedure was repeated by shifting the time point in 1-ms steps after scene onset. If, over 30 consecutive 1-ms steps, the first and at least 26 subsequent showed significant differences, that first time point was defined as the latency of responses. If the latency was not detected until object onset, period B was fixed during the 200-ms period before the scene onset.</p>
<p>We then examined whether the neurons discriminated between contexts in the two dimensions (dangerous versus safe, rich versus poor) and measured the latency of the discrimination (<xref ref-type="supplementary-material" rid="pbio.2005339.s004">S4 Fig</xref>). First, we measured the discrimination latency for neurons during the combined test window (FV–FX period). At each time point after the latency of the scene response, the neurons’ averaged discharge rate was calculated during 30 ms before the time point in each context. If, over 30 consecutive 1-ms steps, the first and at least 26 subsequent showed significant differences, that first time point was defined as the onset of discrimination signaling. Then, we measured the magnitude of the neuron’s response in each context by counting the numbers of spikes within each of the two test windows (FV and FX periods) in individual trials. The neuronal discrimination score was calculated as ΔFR based on differences of response magnitudes of the amygdala neurons between two groups of environments (D/R versus S/R, S/R versus S/P; see <xref ref-type="fig" rid="pbio.2005339.g004">Fig 4</xref>), each of which contrasts a particular context dimension (dangerous–safe, rich–poor). The statistical significance of neuronal discrimination was tested using one-way ANOVA and Tukey–Kramer post hoc test in each of the two test windows (FV and FX periods) (Figs <xref ref-type="fig" rid="pbio.2005339.g004">4</xref> and <xref ref-type="supplementary-material" rid="pbio.2005339.s003">S3</xref>). To estimate the selectivity of neuronal responses to scenes in each context, the selectivity index (SI) was calculated based on the mean FR in each scene.</p>
<p>SI = 1 − (FRall / FRm × NS),</p>
<list list-type="simple">
<list-item><p>FRall: the total of FR in all scenes in the context,</p></list-item>
<list-item><p>FRm: the largest FR among tested scenes,</p></list-item>
<list-item><p>NS: number of tested scenes.</p></list-item>
</list>
<p>We compared the responses of amygdala neurons to different contexts as well as individual scenes (Figs <xref ref-type="fig" rid="pbio.2005339.g006">6</xref> and <xref ref-type="supplementary-material" rid="pbio.2005339.s005">S5</xref>). For each neuron, we calculated the mean firing rate to each scene in each neuron, which was converted to normalized z-scores: (FR<sub>i</sub> − FR<sub>b</sub>) / SD, (FR<sub>i</sub>: mean firing rate during the test window, FR<sub>b</sub>: baseline firing rate, SD: standard deviation of mean firing rates for all scenes). We then averaged z-scores of all scene-responsive neurons for each context of scenes (e.g., <xref ref-type="fig" rid="pbio.2005339.g006">Fig 6A</xref>) and for each scene (e.g., <xref ref-type="supplementary-material" rid="pbio.2005339.s006">S6 Fig</xref>). To examine the significance of context discrimination we used one-way ANOVA (three groups [D/R, S/R, S/P], post hoc: Tukey–Kramer).</p>
<p>The dangerous–safe dimension of context was estimated basically by the comparison between the two groups of scenes (D/R versus S/R) because the predicted reward amount was the same (big). However, the average reward amount was smaller in D/R than S/R because the reward was sometimes removed by the robber object. Therefore, we also used another method based on the predicted reward values for neuronal activity (<xref ref-type="fig" rid="pbio.2005339.g006">Fig 6</xref>). The actual neuronal activity in D/R was compared with the predicted neuronal activity (PN) based on the predicted reward value in D/R.</p>
<p>PN = FRp + (FRr − FRp) × (PVd − PVp) / (PVr − PVp),</p>
<list list-type="simple">
<list-item><p>FRr/FRp: neuronal activity (mean firing rate) in S/R or S/P,</p></list-item>
<list-item><p>PVd/PVr/PVp: predicted reward value in D/R, S/R, or S/P.</p></list-item>
</list>
<p>The predicted reward value was calculated by a following equation: PV = R × S × 10 (R: reward amount when the monkey chose the good object [0.3 mL in rich and 0.1 mL in poor environments], S: rate of successful [rewarded] trials).</p>
<p>The same method was used for pupil size and heart rate (<xref ref-type="fig" rid="pbio.2005339.g007">Fig 7</xref>).</p>
<p>The effect of object context on neuronal activity was evaluated based on the effects of the robber and distractor objects (<xref ref-type="supplementary-material" rid="pbio.2005339.s007">S7 Fig</xref>). We compared the neuronal activity in the FX period between the two object contexts: robber/distractor (−) (before the robber/distractor object appeared) and robber/distractor (+) (after the robber/distractor object appeared). We analyzed neuronal and SacRT data in these object contexts separately as well as in combination.</p>
</sec>
</sec>
</sec>
<sec id="sec018">
<title>Supporting information</title>
<supplementary-material id="pbio.2005339.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>(Related to <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1</xref>). Foraging task procedure.</title>
<p>(<bold>A</bold>) The sequence of events on trials with additional (robber or distractor) object. An environment (scene) appears first, which contains two or three objects with meanings shown in (<bold>B</bold>). After gaze fixation at the center, one of the objects appears at a random position. A saccade to the good object followed by sustained gaze terminates the trial with delivery of reward. The amount of reward is either big or small depending on the scene, creating the rich versus poor dimension of context. Saccades to the bad object followed by sustained fixation terminate the trial with no reward. The subject thus learns to avoid the bad object by either withholding a saccade or leaving the bad object quickly, after which the fixation point reappears. Another object, either robber or distractor, remains for a while, irrespective of the animal’s behavior. The distractor simply remains on the screen, whereas the robber jumps to the good object (if present) and precludes reward delivery if it beats the monkey’s saccade (<bold>C</bold>, see <xref ref-type="supplementary-material" rid="pbio.2005339.s010">S2 Movie</xref>). The presence or absence of the robber determines the dangerous versus safe dimension of context. Both dimensions of context were examined by varying the dimension of interest, while the orthogonal dimension was constant. See <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1</xref> and <xref ref-type="sec" rid="sec009">Materials and methods</xref>.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2005339.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Fast learning of environmental contexts and object values.</title>
<p>(<bold>A</bold>) Learning across 4-d sessions in monkey PI during the foraging task (4 scenes with 8 objects). Before this experiment the subject had learned the task rule completely, but all scenes and objects were completely new on Day 1. Each session consisted of 52 trials (13 trials for each scene). In the early stage of learning on Day 1, the subject’s choice was sometimes wrong (i.e., bad object) or invalid (i.e., fixation break) but became nearly perfect toward the end of the session. The speed of learning is shown as the change in the correct response rate. The good performance was well retained across days. These example scene images were derived from OpenAerialMap (<ext-link ext-link-type="uri" xlink:href="https://openaerialmap.org/" xlink:type="simple">https://openaerialmap.org</ext-link>). (<bold>B–D</bold>) Learning in three monkeys (PA, PI, SO). (<bold>B</bold>) Time course of object choice learning for many scenes (56 scenes for monkey PA and PI, 32 scenes for monkey SO). (<bold>C</bold>) Change in saccade reaction time to the good object across learning. For each subject, data are shown separately for three scene types: D/R, S/R, and S/P. Trial number was measured for individual scenes, not the subject’s task career. (<bold>D</bold>) Performance after learning (&gt;200 trials for each scene) in the three groups of scenes. “Failure” indicates the D/R context trials in which the robber beat the monkey’s saccade. Dangerous trials featured the appearance of the robber; those that did are indicated in light gray. D/R, dangerous and rich; S/P, safe and poor; S/R, safe and rich.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2005339.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>(Related to <xref ref-type="fig" rid="pbio.2005339.g004">Fig 4</xref>).</title>
<p>(<bold>A</bold>) Neuron in monkey PI (#234) that was selectively active in the rich context during the fixation period (S/R &gt; S/P). (<bold>B</bold>) Neuron in monkey SO (#339) that was active in both the dangerous and rich contexts during the fixation period (D/R &gt; S/R and S/R &gt; S/P). The same format as in <xref ref-type="fig" rid="pbio.2005339.g004">Fig 4</xref>. S/P, safe and poor; S/R, safe and rich.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2005339.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s004" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Neuronal response latency and differentiation time.</title>
<p>Latencies of neuronal responses to visual scenes. (<bold>A</bold>) General latency: time when the neuronal activity (PA, <italic>n</italic> = 33; PI, <italic>n</italic> = 32; SO, <italic>n</italic> = 39) changed significantly after the onset of any of the tested scenes. (<bold>B–C</bold>) Context-discrimination latency: time when the neuronal activity changed significantly between dangerous and safe scenes (<bold>B</bold>, PA, <italic>n</italic> = 27; PI, <italic>n</italic> = 20; SO, <italic>n</italic> = 18) and between rich and poor scenes (<bold>C</bold>, PA, <italic>n</italic> = 25; PI, <italic>n</italic> = 23; SO, <italic>n</italic> = 27). Data are based on excited-type neurons (see <xref ref-type="supplementary-material" rid="pbio.2005339.s004">S4 Fig</xref>) in monkey PA, PI, SO, and all.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2005339.s005" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s005" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>(Related to <xref ref-type="fig" rid="pbio.2005339.g004">Fig 4D</xref>). Scene selectivity of individual and population neuronal activity.</title>
<p>(<bold>A</bold>) Scene selectivity of two example neurons in monkey PA. Left: the neuron’s activities in the three groups of scenes: D/R, S/R, S/P. Right: the neuron’s responses to individual scenes in the dangerous (D/R) context (in the fixation period). Same format as in <xref ref-type="fig" rid="pbio.2005339.g004">Fig 4B and 4D</xref>. Shaded gray area indicates the tested scenes for each neuron. Scene selectivity (SI): 0.473 (#73), 0.775 (#83). (<bold>B</bold>) Scene selectivity of the population neuronal activity (excited-type neurons, <italic>n</italic> = 33) in D/R context in monkey PA (SI: 0.234). Same format as in (A). (<bold>C</bold>) SIs in individual neuronal activity (small dots) and the population neuronal activity (gray squares) in three contexts in each monkey (PA, PI, SO). Mean SI: 0.386 (PA[D/R]), 0.404 (PA[S/R]), 0.345 (PA[S/P]), 0.299 (PI[D/R]), 0.298 (PI[S/R]), 0.264 (PI[S/P]), 0.245 (SO[D/R]), 0.305 (SO[S/R]), 0.311 (SO[S/P]). Population SI: 0.234 (PA[D/R]), 0.444 (PA[S/R]), 0.346 (PA[S/P]), 0.261 (PI[D/R]), 0.248 (PI[S/R]), 0.308 (PI[S/P]), 0.203 (SO[D/R]), 0.180 (SO[S/R]), 0.145 (SO[S/P]). On the right, the probabilistic distribution of SIs is shown by kernel density estimation (width = 0.03) for each context and in each monkey. D/R, dangerous and rich; S/P, safe and poor; S/R, safe and rich; SI, selectivity index.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2005339.s006" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s006" xlink:type="simple">
<label>S6 Fig</label>
<caption>
<title>Effect of environment outcome change on amygdala neuronal activity.</title>
<p>(<bold>A</bold>) Nonforaging task. Reward was delivered if the subject kept gaze on the fixation point that moved from the center to a random peripheral position. Before the position change, a well-learned scene was presented for 2,000 ms, during which free viewing was allowed. Across trials, different scenes appeared randomly, but no object (good, bad, robber, distractor) appeared inside the scene. (<bold>B–G</bold>) Activity of three neurons in monkey PA during the foraging task (<bold>B, D, F</bold>) and nonforaging task (<bold>C, E, G</bold>). These tasks were presented as separate blocks of trials. Their responses to individual scenes are also shown. The FV and FX period in the foraging task was combined. FV, free-viewing; FX, fixation.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2005339.s007" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s007" xlink:type="simple">
<label>S7 Fig</label>
<caption>
<title>Effects of dangerous or distracting objects on amygdala neuronal activity and SacRT.</title>
<p><bold>(A)</bold> Distributions of the SacRT to good objects in three monkeys (PA, PI, SO) in three groups of scenes: S/P, D/R, S/R. In each panel, data from two groups of object context are superimposed: Robber(+) and Robber(−) in D/R, and Distractor(+) and Distractor(−) in S/R and S/P. SacRT distribution is shown using reciprobit plot. (<bold>B</bold>) Relation between the neuronal activity (abscissa) and SacRT (ordinate) in two dimensions of context: environment contexts (D/R, S/R, S/P) and object context (Robber/Distractor[+], Robber/Distractor[−]). The object contexts shown here correspond to data shown in (A). (<bold>C</bold>) Relation between the neuronal activity (abscissa) and SacRT (ordinate) for individual scenes. Some scenes provide two data points: Robber/Distractor(+) and Robber/Distractor(−). Findings are presented in further detail below. In the dangerous scene (D/R), SacRT was shorter when a robber object was present (Robber+) than when absent (Robber−) (<bold>B</bold>). The distribution of SacRT became curved, indicating that the saccade preparation process became non-Gaussian by including extremely short SacRTs (<bold>A</bold>, D/R). Notably, these effects occurred in the all monkeys. Taken together with data shown in <bold>B</bold>, these results show that all monkeys were sensitive to danger, in both scene and object (i.e., robber present or absent) contexts. Monkey PI was primarily sensitive to the object context (faster when a robber object was present), in tandem with amygdala neurons tending to be more active on Robber(+) trials than on Robber(−) (<bold>B</bold>), although the statistical significance was shown only in monkey SO. Results of two-way ANOVA tests with environments and object+/− with Tukey–Kramer post hoc tests were as follows. Monkey PA: F[2, 1882] = 0.025, <italic>P</italic> = 0.975, post hoc, <italic>P</italic> = 0.811. Monkey PI: F[2, 1773] = 1.149, <italic>P</italic> = 0.317, post hoc, <italic>P</italic> = 0.882. Monkey SO: F[2, 1958] = 0.425, <italic>P</italic> = 0.654, post hoc, <italic>P</italic> = 0.0422. In the safe scenes (S/R, S/P), SacRT was shorter when a distractor object was present than when absent in monkeys PA and SO (<bold>B</bold>). Because the success rate (i.e., probability of rewarded trials) was not significantly different between the distractor present and distracter absent trials (PA[S/R]: chi-squared = 0.286, <italic>P</italic> = 0.593; PA[S/P]: chi-squared = 0.225, <italic>P</italic> = 0.636; PI[S/R]: chi-squared = 0.205, <italic>P</italic> = 0.651; PI[S/P]: chi-squared = 0.020, <italic>P</italic> = 0.887; SO[S/R] chi-squared = 3.274, <italic>P</italic> = 0.070; SO[S/P]: chi-squared = 2.954, <italic>P</italic> = 0.086), the change in SacRT is unlikely to be caused by the dangerous context. Instead, it may be related to a higher demand of attention when two objects are present simultaneously [<xref ref-type="bibr" rid="pbio.2005339.ref019">19</xref>]. Amygdala neurons tended to be more active when a distractor object was present (Distractor+) than when absent (Distractor−) in monkeys PA and SO (<bold>B</bold>), although this trend did not reach statistical significance (two-way ANOVA with environments and object+/−, post hoc: Tukey–Kramer; PA[S/R]: <italic>P</italic> = 0.965; PA[S/P]: <italic>P</italic> = 0.890; PI[S/R]: <italic>P</italic> = 0.930; PI[S/P]: <italic>P</italic> = 0.998; SO[S/R]: <italic>P</italic> = 0.483; SO[S/P]: <italic>P</italic> = 0.716). The integration of neuron-behavior data in the object context (i.e., presence and absence) (<bold>C</bold>) shows that the activity of amygdala neurons was significantly correlated with SacRT in monkeys PA and SO (PA: <italic>r</italic> = −0.288, <italic>P</italic> = 0.005; PI: <italic>r</italic> = 0.022, <italic>P</italic> = 0.833; SO: <italic>r</italic> = −0.660, <italic>P</italic> &lt; 0.001). These data suggest that amygdala neurons could facilitate saccades based on the object context, in addition to the scene context. D/R, dangerous and rich; S/P, safe and poor; S/R, safe and rich; SacRT, saccade reaction time.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2005339.s008" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s008" xlink:type="simple">
<label>S8 Fig</label>
<caption>
<title>(Related to <xref ref-type="fig" rid="pbio.2005339.g008">Fig 8</xref>). Recording sites.</title>
<p>(<bold>A</bold>) Amygdala and surrounding brain areas. Same format as in <xref ref-type="fig" rid="pbio.2005339.g008">Fig 8A</xref>. A horizontal black line indicates the dorsoventral border of neurons based on their background firing rate (data shown in D). (<bold>B</bold>) Neurons with visual responses (Visual +) and with no visual responses (Visual −), shown separately for three monkeys. (<bold>C</bold>) Visual scene-sensitive neurons (excited type) are classified based on their background FRs. (<bold>D)</bold> Background FRs of individual neurons (abscissa) plotted against their recorded depths from the AC (ordinate). The horizontal line (i.e., 8 mm below AC) indicates the dorsoventral border, by which the variance of Background FR was maximally higher in the dorsal area than the ventral area. This was determined by the lowest <italic>P</italic> value (two-sample F-test) while moving the border line (0.2 mm step) (as shown in colored bars on the right) (F[108, 48] = 3.363, <italic>P</italic> &lt; 0.001, dorsal [355.856], ventral [105.812]). Note that the border line roughly corresponds to the border between CE and BL/L. (<bold>E-F</bold>) SIs of individual neurons (abscissa) plotted against their recorded depths (ordinate) during the free-viewing period (<bold>E</bold>) and the fixation period (<bold>F</bold>). With the border based on Background FR (D), the variance of SIs was significantly higher in the dorsal area than the ventral areas (SI in free-viewing: F[324,146] = 1.958, <italic>P</italic> &lt; 0.001, dorsal [0.030], ventral [0.015]; SI in fixation: F[326,146] = 1.476, <italic>P</italic> = 0.008, dorsal [0.033], ventral [0.023]). AC, anterior commissure; BL/L, basolateral complex and lateral nucleus of the amygdala; CE, central nucleus of the amygdala; FR, firing rate; SI, Selectivity index.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2005339.s009" mimetype="video/quicktime" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s009" xlink:type="simple">
<label>S1 Movie</label>
<caption>
<title>(Related to <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1</xref> and <xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1 Fig</xref>). Monkey’s gaze positions during performance of the foraging task (safe and rich context). Yellow dots show monkey’s gaze positions. </title>
<p>The example scene image was derived from OpenAerialMap (<ext-link ext-link-type="uri" xlink:href="https://openaerialmap.org/" xlink:type="simple">https://openaerialmap.org</ext-link>).</p>
<p>(MOV)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2005339.s010" mimetype="video/quicktime" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s010" xlink:type="simple">
<label>S2 Movie</label>
<caption>
<title>(Related to <xref ref-type="fig" rid="pbio.2005339.g001">Fig 1</xref> and <xref ref-type="supplementary-material" rid="pbio.2005339.s001">S1 Fig</xref>). Monkey’s gaze positions during performance of the foraging task (dangerous and rich context). Same format as <xref ref-type="supplementary-material" rid="pbio.2005339.s009">S1 Movie</xref>.</title>
<p>The example scene image was derived from OpenAerialMap (<ext-link ext-link-type="uri" xlink:href="https://openaerialmap.org/" xlink:type="simple">https://openaerialmap.org</ext-link>).</p>
<p>(MOV)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2005339.s011" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s011" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>(Related to <xref ref-type="fig" rid="pbio.2005339.g006">Fig 6</xref>). Statistical values for the neuronal activity and SacRT.</title>
<p>SacRT, saccade reaction time.</p>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2005339.s012" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pbio.2005339.s012" xlink:type="simple">
<label>S2 Table</label>
<caption>
<title>(Related to <xref ref-type="fig" rid="pbio.2005339.g007">Fig 7</xref>). Statistical values for the pupil size and HR.</title>
<p>HR, heart rate.</p>
<p>(XLSX)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank D. McMahon for manuscript-writing assistance; A. Gopal for data analysis assistance; and M.K. Smith, D. Parker, V.L. McLean, I. Bunea, G. Tansey, D. Yu, A.M. Nichols, T.W. Ruffner, J.W. McClurkin, and A.V. Hays for technical assistance.</p>
</ack>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>BA</term>
<def><p>basal nucleus of the amygdala</p></def>
</def-item>
<def-item><term>BL</term>
<def><p>basolateral complex of the amygdala</p></def>
</def-item>
<def-item><term>BL/L</term>
<def><p>basolateral complex and lateral nucleus of the amygdala</p></def>
</def-item>
<def-item><term>cdlSNc</term>
<def><p>caudal-dorsal-lateral part of the substantia nigra pars compacta</p></def>
</def-item>
<def-item><term>cdlSNr</term>
<def><p>caudal-dorsal-lateral part of the substantia nigra pars reticulata</p></def>
</def-item>
<def-item><term>CDt</term>
<def><p>tail of the caudate nucleus</p></def>
</def-item>
<def-item><term>CE</term>
<def><p>central nucleus of the amygdala</p></def>
</def-item>
<def-item><term>cvGPe</term>
<def><p>caudal- ventral part of the globus pallidus externus</p></def>
</def-item>
<def-item><term>D/P</term>
<def><p>dangerous and poor</p></def>
</def-item>
<def-item><term>D/R</term>
<def><p>dangerous and rich</p></def>
</def-item>
<def-item><term>FP</term>
<def><p>fixation point</p></def>
</def-item>
<def-item><term>FV</term>
<def><p>free-viewing</p></def>
</def-item>
<def-item><term>FX</term>
<def><p>fixation</p></def>
</def-item>
<def-item><term>L</term>
<def><p>lateral nucleus of the amygdala</p></def>
</def-item>
<def-item><term>LV</term>
<def><p>lateral ventricle</p></def>
</def-item>
<def-item><term>MR</term>
<def><p>magnetic resonance</p></def>
</def-item>
<def-item><term>PN</term>
<def><p>predicted neuronal activity</p></def>
</def-item>
<def-item><term>S/P</term>
<def><p>safe and poor</p></def>
</def-item>
<def-item><term>S/R</term>
<def><p>safe and rich</p></def>
</def-item>
<def-item><term>SacRT</term>
<def><p>saccade reaction time</p></def>
</def-item>
<def-item><term>SC</term>
<def><p>superior colliculus</p></def>
</def-item>
<def-item><term>SI</term>
<def><p>selectivity index</p></def>
</def-item>
<def-item><term>SN</term>
<def><p>substantia nigra</p></def>
</def-item>
<def-item><term>SNc</term>
<def><p>substantia nigra pars compacta</p></def>
</def-item>
<def-item><term>SNr</term>
<def><p>substantia nigra pars reticulata</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.2005339.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>. <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source>. <year>1997</year>;<volume>275</volume>:<fpage>1593</fpage>–<lpage>9</lpage>. <object-id pub-id-type="pmid">9054347</object-id></mixed-citation></ref>
<ref id="pbio.2005339.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doya</surname> <given-names>K</given-names></name>. <article-title>Modulators of decision making</article-title>. <source>Nature neuroscience</source>. <year>2008</year>;<volume>11</volume>(<issue>4</issue>):<fpage>410</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn2077" xlink:type="simple">10.1038/nn2077</ext-link></comment> <object-id pub-id-type="pmid">18368048</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saez</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rigotti</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ostojic</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Fusi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Salzman</surname> <given-names>CD</given-names></name>. <article-title>Abstract Context Representations in Primate Amygdala and Prefrontal Cortex</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>87</volume>(<issue>4</issue>):<fpage>869</fpage>–<lpage>81</lpage>. Epub 2015/08/21. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.07.024" xlink:type="simple">10.1016/j.neuron.2015.07.024</ext-link></comment> <object-id pub-id-type="pmid">26291167</object-id>; PubMed Central PMCID: PMC4574873.</mixed-citation></ref>
<ref id="pbio.2005339.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nakahara</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Itoh</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Kawagoe</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Takikawa</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hikosaka</surname> <given-names>O</given-names></name>. <article-title>Dopamine neurons can represent context-dependent prediction error</article-title>. <source>Neuron</source>. <year>2004</year>;<volume>41</volume>(<issue>2</issue>):<fpage>269</fpage>–<lpage>80</lpage>. <object-id pub-id-type="pmid">14741107</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mante</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Sussillo</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Shenoy</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>. <article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title>. <source>Nature</source>. <year>2013</year>;<volume>503</volume>(<issue>7474</issue>):<fpage>78</fpage>–<lpage>84</lpage>. Epub 2013/11/10. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature12742" xlink:type="simple">10.1038/nature12742</ext-link></comment> <object-id pub-id-type="pmid">24201281</object-id>; PubMed Central PMCID: PMC4121670.</mixed-citation></ref>
<ref id="pbio.2005339.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chun</surname> <given-names>MM</given-names></name>. <article-title>Contextual cueing of visual attention</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2000</year>;<volume>4</volume>:<fpage>170</fpage>–<lpage>8</lpage>. <object-id pub-id-type="pmid">10782102</object-id></mixed-citation></ref>
<ref id="pbio.2005339.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maren</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Phan</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Liberzon</surname> <given-names>I</given-names></name>. <article-title>The contextual brain: implications for fear conditioning, extinction and psychopathology</article-title>. <source>Nat Rev Neurosci</source>. <year>2013</year>;<volume>14</volume>(<issue>6</issue>):<fpage>417</fpage>–<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn3492" xlink:type="simple">10.1038/nrn3492</ext-link></comment> <object-id pub-id-type="pmid">23635870</object-id>; PubMed Central PMCID: PMCPMC5072129.</mixed-citation></ref>
<ref id="pbio.2005339.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nasr</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Devaney</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Yue</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Rajimehr</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name>, <etal>et al</etal>. <article-title>Scene-selective cortical regions in human and nonhuman primates</article-title>. <source>J Neurosci</source>. <year>2011</year>;<volume>31</volume>(<issue>39</issue>):<fpage>13771</fpage>–<lpage>85</lpage>. Epub 2011/10/01. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2792-11.2011" xlink:type="simple">10.1523/JNEUROSCI.2792-11.2011</ext-link></comment> <object-id pub-id-type="pmid">21957240</object-id>; PubMed Central PMCID: PMC3489186.</mixed-citation></ref>
<ref id="pbio.2005339.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Phelps</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>LeDoux</surname> <given-names>JE</given-names></name>. <article-title>Contributions of the amygdala to emotion processing: from animal models to human behavior</article-title>. <source>Neuron</source>. <year>2005</year>;<volume>48</volume>(<issue>2</issue>):<fpage>175</fpage>–<lpage>87</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2005.09.025" xlink:type="simple">10.1016/j.neuron.2005.09.025</ext-link></comment> <object-id pub-id-type="pmid">16242399</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leathers</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Olson</surname> <given-names>CR</given-names></name>. <article-title>In monkeys making value-based decisions, amygdala neurons are sensitive to cue value as distinct from cue salience</article-title>. <source>J Neurophysiol</source>. <year>2017</year>;<volume>117</volume>(<issue>4</issue>):<fpage>1499</fpage>–<lpage>511</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00564.2016" xlink:type="simple">10.1152/jn.00564.2016</ext-link></comment> <object-id pub-id-type="pmid">28077664</object-id>; PubMed Central PMCID: PMCPMC5376613.</mixed-citation></ref>
<ref id="pbio.2005339.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maren</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Quirk</surname> <given-names>GJ</given-names></name>. <article-title>Neuronal signalling of fear memory</article-title>. <source>Nat Rev Neurosci</source>. <year>2004</year>;<volume>5</volume>(<issue>11</issue>):<fpage>844</fpage>–<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn1535" xlink:type="simple">10.1038/nrn1535</ext-link></comment> <object-id pub-id-type="pmid">15496862</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hernadi</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Grabenhorst</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Planning activity for internally generated reward goals in monkey amygdala neurons</article-title>. <source>Nature neuroscience</source>. <year>2015</year>;<volume>18</volume>(<issue>3</issue>):<fpage>461</fpage>–<lpage>9</lpage>. Epub 2015/01/27. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3925" xlink:type="simple">10.1038/nn.3925</ext-link></comment> <object-id pub-id-type="pmid">25622146</object-id>; PubMed Central PMCID: PMC4340753.</mixed-citation></ref>
<ref id="pbio.2005339.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peck</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Lau</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Salzman</surname> <given-names>CD</given-names></name>. <article-title>The primate amygdala combines information about space and value</article-title>. <source>Nature neuroscience</source>. <year>2013</year>;<volume>16</volume>(<issue>3</issue>):<fpage>340</fpage>–<lpage>8</lpage>. Epub 2013/02/05. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3328" xlink:type="simple">10.1038/nn.3328</ext-link></comment> <object-id pub-id-type="pmid">23377126</object-id>; PubMed Central PMCID: PMC3596258.</mixed-citation></ref>
<ref id="pbio.2005339.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Choi</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>JJ</given-names></name>. <article-title>Amygdala regulates risk of predation in rats foraging in a dynamic fear environment</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2010</year>;<volume>107</volume>(<issue>50</issue>):<fpage>21773</fpage>–<lpage>7</lpage>. Epub 2010/12/01. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1010079108" xlink:type="simple">10.1073/pnas.1010079108</ext-link></comment> <object-id pub-id-type="pmid">21115817</object-id>; PubMed Central PMCID: PMC3003044.</mixed-citation></ref>
<ref id="pbio.2005339.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Amir</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Headley</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Herzallah</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Pare</surname> <given-names>D</given-names></name>. <article-title>Amygdala Signaling during Foraging in a Hazardous Environment</article-title>. <source>J Neurosci</source>. <year>2015</year>;<volume>35</volume>(<issue>38</issue>):<fpage>12994</fpage>–<lpage>3005</lpage>. Epub 2015/09/25. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0407-15.2015" xlink:type="simple">10.1523/JNEUROSCI.0407-15.2015</ext-link></comment> <object-id pub-id-type="pmid">26400931</object-id>; PubMed Central PMCID: PMC4579372.</mixed-citation></ref>
<ref id="pbio.2005339.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Feldman</surname> <given-names>LA</given-names></name>. <article-title>Valence Focus and Arousal Focus: Individual Differences in the Structure of Affective Experience</article-title>. <source>J Person Soc Psychol</source>. <year>1995</year>;<volume>69</volume>(<issue>1</issue>):<fpage>153</fpage>–<lpage>66</lpage>.</mixed-citation></ref>
<ref id="pbio.2005339.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hikosaka</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>HF</given-names></name>, <name name-style="western"><surname>Yasuda</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Yamamoto</surname> <given-names>S</given-names></name>. <article-title>Basal Ganglia circuits for reward value-guided behavior</article-title>. <source>Annu Rev Neurosci</source>. <year>2014</year>;<volume>37</volume>:<fpage>289</fpage>–<lpage>306</lpage>. Epub 2014/07/18. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-neuro-071013-013924" xlink:type="simple">10.1146/annurev-neuro-071013-013924</ext-link></comment> <object-id pub-id-type="pmid">25032497</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Noorani</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Carpenter</surname> <given-names>RH</given-names></name>. <article-title>The LATER model of reaction time and decision</article-title>. <source>Neurosci Biobehav Rev</source>. <year>2016</year>;<volume>64</volume>:<fpage>229</fpage>–<lpage>51</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neubiorev.2016.02.018" xlink:type="simple">10.1016/j.neubiorev.2016.02.018</ext-link></comment> <object-id pub-id-type="pmid">26915927</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zipser</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Lamme</surname> <given-names>VAF</given-names></name>, <name name-style="western"><surname>Schiller</surname> <given-names>PH</given-names></name>. <article-title>Contextual modulation in primary visual cortex</article-title>. <source>J Neurosci</source>. <year>1996</year>;<volume>16</volume>:<fpage>7376</fpage>–<lpage>89</lpage>. <object-id pub-id-type="pmid">8929444</object-id></mixed-citation></ref>
<ref id="pbio.2005339.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Watanabe</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hikosaka</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Sakagami</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Shirakawa</surname> <given-names>S</given-names></name>. <article-title>Coding and monitoring of motivational context in the primate prefrontal cortex</article-title>. <source>J Neurosci</source>. <year>2002</year>;<volume>22</volume>(<issue>6</issue>):<fpage>2391</fpage>–<lpage>400</lpage>. <object-id pub-id-type="pmid">11896178</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Anderson</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Sheinberg</surname> <given-names>DL</given-names></name>. <article-title>Effects of temporal context and temporal expectancy on neural activity in inferior temporal cortex</article-title>. <source>Neuropsychologia</source>. <year>2008</year>;<volume>46</volume>(<issue>4</issue>):<fpage>947</fpage>–<lpage>57</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuropsychologia.2007.11.025" xlink:type="simple">10.1016/j.neuropsychologia.2007.11.025</ext-link></comment> <object-id pub-id-type="pmid">18206961</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mizumori</surname> <given-names>SJY</given-names></name>, <name name-style="western"><surname>Baker</surname> <given-names>PM</given-names></name>. <article-title>The Lateral Habenula and Adaptive Behaviors</article-title>. <source>Trends Neurosci</source>. <year>2017</year>;<volume>40</volume>(<issue>8</issue>):<fpage>481</fpage>–<lpage>93</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2017.06.001" xlink:type="simple">10.1016/j.tins.2017.06.001</ext-link></comment> <object-id pub-id-type="pmid">28688871</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Self</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Peters</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Possel</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Reithler</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Goebel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ris</surname> <given-names>P</given-names></name>, <etal>et al</etal>. <article-title>The Effects of Context and Attention on Spiking Activity in Human Early Visual Cortex</article-title>. <source>PLoS Biol</source>. <year>2016</year>;<volume>14</volume>(<issue>3</issue>):<fpage>e1002420</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1002420" xlink:type="simple">10.1371/journal.pbio.1002420</ext-link></comment> <object-id pub-id-type="pmid">27015604</object-id>; PubMed Central PMCID: PMCPMC4807817.</mixed-citation></ref>
<ref id="pbio.2005339.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hobin</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Goosens</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Maren</surname> <given-names>S</given-names></name>. <article-title>Context-dependent neuronal activity in the lateral amygdala represents fear memories after extinction</article-title>. <source>J Neurosci</source>. <year>2003</year>;<volume>23</volume>(<issue>23</issue>):<fpage>8410</fpage>–<lpage>6</lpage>. <object-id pub-id-type="pmid">12968003</object-id>; PubMed Central PMCID: PMCPMC2291151.</mixed-citation></ref>
<ref id="pbio.2005339.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grabenhorst</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Hernadi</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Prediction of economic choice by primate amygdala neurons</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2012</year>;<volume>109</volume>(<issue>46</issue>):<fpage>18950</fpage>–<lpage>5</lpage>. Epub 2012/11/01. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1212706109" xlink:type="simple">10.1073/pnas.1212706109</ext-link></comment> <object-id pub-id-type="pmid">23112182</object-id>; PubMed Central PMCID: PMC3503170.</mixed-citation></ref>
<ref id="pbio.2005339.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grabenhorst</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Hernadi</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Primate amygdala neurons evaluate the progress of self-defined economic choice sequences</article-title>. <source>Elife</source>. <year>2016</year>;<volume>5</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.18731" xlink:type="simple">10.7554/eLife.18731</ext-link></comment> <object-id pub-id-type="pmid">27731795</object-id>; PubMed Central PMCID: PMCPMC5061547.</mixed-citation></ref>
<ref id="pbio.2005339.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vuilleumier</surname> <given-names>P</given-names></name>. <article-title>How brains beware: neural mechanisms of emotional attention</article-title>. <source>Trends in cognitive sciences</source>. <year>2005</year>;<volume>9</volume>(<issue>12</issue>):<fpage>585</fpage>–<lpage>94</lpage>. Epub 2005/11/18. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2005.10.011" xlink:type="simple">10.1016/j.tics.2005.10.011</ext-link></comment> <object-id pub-id-type="pmid">16289871</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mosher</surname> <given-names>CP</given-names></name>, <name name-style="western"><surname>Zimmerman</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Gothard</surname> <given-names>KM</given-names></name>. <article-title>Neurons in the monkey amygdala detect eye contact during naturalistic social interactions</article-title>. <source>Curr Biol</source>. <year>2014</year>;<volume>24</volume>(<issue>20</issue>):<fpage>2459</fpage>–<lpage>64</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2014.08.063" xlink:type="simple">10.1016/j.cub.2014.08.063</ext-link></comment> <object-id pub-id-type="pmid">25283782</object-id>; PubMed Central PMCID: PMCPMC4253056.</mixed-citation></ref>
<ref id="pbio.2005339.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dal Monte</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Costa</surname> <given-names>VD</given-names></name>, <name name-style="western"><surname>Noble</surname> <given-names>PL</given-names></name>, <name name-style="western"><surname>Murray</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Averbeck</surname> <given-names>BB</given-names></name>. <article-title>Amygdala lesions in rhesus macaques decrease attention to threat</article-title>. <source>Nat Commun</source>. <year>2015</year>;<volume>6</volume>:<fpage>10161</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ncomms10161" xlink:type="simple">10.1038/ncomms10161</ext-link></comment> <object-id pub-id-type="pmid">26658670</object-id>; PubMed Central PMCID: PMCPMC4682115.</mixed-citation></ref>
<ref id="pbio.2005339.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McGaugh</surname> <given-names>JL</given-names></name>. <article-title>Memory—a century of consolidation</article-title>. <source>Science</source>. <year>2000</year>;<volume>287</volume>(<issue>5451</issue>):<fpage>248</fpage>–<lpage>51</lpage>. Epub 2000/01/15. <object-id pub-id-type="pmid">10634773</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Richter-Levin</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Akirav</surname> <given-names>I</given-names></name>. <article-title>Emotional tagging of memory formation—in the search for neural mechanisms</article-title>. <source>Brain Res Brain Res Rev</source>. <year>2003</year>;<volume>43</volume>(<issue>3</issue>):<fpage>247</fpage>–<lpage>56</lpage>. <object-id pub-id-type="pmid">14629927</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peck</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Salzman</surname> <given-names>CD</given-names></name>. <article-title>Amygdala neural activity reflects spatial attention towards stimuli promising reward or threatening punishment</article-title>. <source>Elife</source>. <year>2014</year>;<volume>3</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.04478" xlink:type="simple">10.7554/eLife.04478</ext-link></comment> <object-id pub-id-type="pmid">25358090</object-id>; PubMed Central PMCID: PMCPMC4238057.</mixed-citation></ref>
<ref id="pbio.2005339.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ohl</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Toschi</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Wigger</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Henniger</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Landgraf</surname> <given-names>R</given-names></name>. <article-title>Dimensions of emotionality in a rat model of innate anxiety</article-title>. <source>Behav Neurosci</source>. <year>2001</year>;<volume>115</volume>(<issue>2</issue>):<fpage>429</fpage>–<lpage>36</lpage>. <object-id pub-id-type="pmid">11345967</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hess</surname> <given-names>EH</given-names></name>, <name name-style="western"><surname>Polt</surname> <given-names>JM</given-names></name>. <article-title>Pupil size as related to interest value of visual stimuli</article-title>. <source>Science</source>. <year>1960</year>;<volume>132</volume>(<issue>3423</issue>):<fpage>349</fpage>–<lpage>50</lpage>. <object-id pub-id-type="pmid">14401489</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nassar</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Rumsey</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Parikh</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Heasly</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>. <article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title>. <source>Nature neuroscience</source>. <year>2012</year>;<volume>15</volume>(<issue>7</issue>):<fpage>1040</fpage>–<lpage>6</lpage>. Epub 2012/06/05. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3130" xlink:type="simple">10.1038/nn.3130</ext-link></comment> <object-id pub-id-type="pmid">22660479</object-id>; PubMed Central PMCID: PMC3386464.</mixed-citation></ref>
<ref id="pbio.2005339.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ebitz</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Pearson</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Platt</surname> <given-names>ML</given-names></name>. <article-title>Pupil size and social vigilance in rhesus macaques</article-title>. <source>Front Neurosci</source>. <year>2014</year>;<volume>8</volume>:<fpage>100</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnins.2014.00100" xlink:type="simple">10.3389/fnins.2014.00100</ext-link></comment> <object-id pub-id-type="pmid">24834026</object-id>; PubMed Central PMCID: PMCPMC4018547.</mixed-citation></ref>
<ref id="pbio.2005339.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Desimone</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Duncan</surname> <given-names>J</given-names></name>. <article-title>Neural mechanisms of selective visual attention</article-title>. <source>Annu Rev Neurosci</source>. <year>1995</year>;<volume>18</volume>:<fpage>193</fpage>–<lpage>222</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.ne.18.030195.001205" xlink:type="simple">10.1146/annurev.ne.18.030195.001205</ext-link></comment> <object-id pub-id-type="pmid">7605061</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yasuda</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Yamamoto</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Hikosaka</surname> <given-names>O</given-names></name>. <article-title>Robust representation of stable object values in the oculomotor Basal Ganglia</article-title>. <source>J Neurosci</source>. <year>2012</year>;<volume>32</volume>(<issue>47</issue>):<fpage>16917</fpage>–<lpage>32</lpage>. Epub 2012/11/24. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3438-12.2012" xlink:type="simple">10.1523/JNEUROSCI.3438-12.2012</ext-link></comment> <object-id pub-id-type="pmid">23175843</object-id>; PubMed Central PMCID: PMC3537824.</mixed-citation></ref>
<ref id="pbio.2005339.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Russchen</surname> <given-names>FT</given-names></name>, <name name-style="western"><surname>Bakst</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Amaral</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Price</surname> <given-names>JL</given-names></name>. <article-title>The amygdalostriatal projections in the monkey. An anterograde tracing study</article-title>. <source>Brain research</source>. <year>1985</year>;<volume>329</volume>(<issue>1–2</issue>):<fpage>241</fpage>–<lpage>57</lpage>. <object-id pub-id-type="pmid">3978445</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shinonaga</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Takada</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mizuno</surname> <given-names>N</given-names></name>. <article-title>Direct projections from the central amygdaloid nucleus to the globus pallidus and substantia nigra in the cat</article-title>. <source>Neuroscience</source>. <year>1992</year>;<volume>51</volume>(<issue>3</issue>):<fpage>691</fpage>–<lpage>703</lpage>. Epub 1992/12/01. <object-id pub-id-type="pmid">1283209</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vankova</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Arluison</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Leviel</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Tramu</surname> <given-names>G</given-names></name>. <article-title>Afferent connections of the rat substantia nigra pars lateralis with special reference to peptide-containing neurons of the amygdalo-nigral pathway</article-title>. <source>J Chem Neuroanat</source>. <year>1992</year>;<volume>5</volume>(<issue>1</issue>):<fpage>39</fpage>–<lpage>50</lpage>. Epub 1992/01/01. <object-id pub-id-type="pmid">1376607</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fudge</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Haber</surname> <given-names>SN</given-names></name>. <article-title>The central nucleus of the amygdala projection to dopamine subpopulations in primates</article-title>. <source>Neuroscience</source>. <year>2000</year>;<volume>97</volume>:<fpage>479</fpage>–<lpage>94</lpage>. <object-id pub-id-type="pmid">10828531</object-id></mixed-citation></ref>
<ref id="pbio.2005339.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fudge</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Breitbart</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>McClain</surname> <given-names>C</given-names></name>. <article-title>Amygdaloid inputs define a caudal component of the ventral striatum in primates</article-title>. <source>The Journal of comparative neurology</source>. <year>2004</year>;<volume>476</volume>(<issue>4</issue>):<fpage>330</fpage>–<lpage>47</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/cne.20228" xlink:type="simple">10.1002/cne.20228</ext-link></comment> <object-id pub-id-type="pmid">15282709</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Popescu</surname> <given-names>AT</given-names></name>, <name name-style="western"><surname>Saghyan</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Pare</surname> <given-names>D</given-names></name>. <article-title>NMDA-dependent facilitation of corticostriatal plasticity by the amygdala</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2007</year>;<volume>104</volume>(<issue>1</issue>):<fpage>341</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0609831104" xlink:type="simple">10.1073/pnas.0609831104</ext-link></comment> <object-id pub-id-type="pmid">17182737</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gamer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Zurowski</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Buchel</surname> <given-names>C</given-names></name>. <article-title>Different amygdala subregions mediate valence-related and attentional effects of oxytocin in humans</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2010</year>;<volume>107</volume>(<issue>20</issue>):<fpage>9400</fpage>–<lpage>5</lpage>. Epub 2010/04/28. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1000985107" xlink:type="simple">10.1073/pnas.1000985107</ext-link></comment> <object-id pub-id-type="pmid">20421469</object-id>; PubMed Central PMCID: PMC2889107.</mixed-citation></ref>
<ref id="pbio.2005339.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holland</surname> <given-names>PC</given-names></name>, <name name-style="western"><surname>Gallagher</surname> <given-names>M</given-names></name>. <article-title>Amygdala circuitry in attentional and representational processes</article-title>. <source>Trends in cognitive sciences</source>. <year>1999</year>;<volume>3</volume>(<issue>2</issue>):<fpage>65</fpage>–<lpage>73</lpage>. Epub 1999/05/11. <object-id pub-id-type="pmid">10234229</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fischer</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Ramsperger</surname> <given-names>E</given-names></name>. <article-title>Human express saccades: extremely short reaction times of goal directed eye movements</article-title>. <source>Exp Brain Res</source>. <year>1984</year>;<volume>57</volume>(<issue>1</issue>):<fpage>191</fpage>–<lpage>5</lpage>. Epub 1984/01/01. <object-id pub-id-type="pmid">6519226</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Munoz</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Wurtz</surname> <given-names>RH</given-names></name>. <article-title>Role of the rostral superior colliculus in active visual fixation and execution of express saccades</article-title>. <source>J Neurophysiol</source>. <year>1992</year>;<volume>67</volume>(<issue>4</issue>):<fpage>1000</fpage>–<lpage>2</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1992.67.4.1000" xlink:type="simple">10.1152/jn.1992.67.4.1000</ext-link></comment> <object-id pub-id-type="pmid">1588382</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schiller</surname> <given-names>PH</given-names></name>, <name name-style="western"><surname>Sandell</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JHR</given-names></name>. <article-title>The effect of frontal eye field and superior colliculus lesions on saccadic latencies in the rhesus monkey</article-title>. <source>Journal of Neurophysiology</source>. <year>1987</year>;<volume>57</volume>:<fpage>1033</fpage>–<lpage>49</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1987.57.4.1033" xlink:type="simple">10.1152/jn.1987.57.4.1033</ext-link></comment> <object-id pub-id-type="pmid">3585453</object-id></mixed-citation></ref>
<ref id="pbio.2005339.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Edelman</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Keller</surname> <given-names>EL</given-names></name>. <article-title>Activity of visuomotor burst neurons in the superior colliculus accompanying express saccades</article-title>. <source>Journal of Neurophysiology</source>. <year>1996</year>;<volume>76</volume>:<fpage>908</fpage>–<lpage>26</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1996.76.2.908" xlink:type="simple">10.1152/jn.1996.76.2.908</ext-link></comment> <object-id pub-id-type="pmid">8871208</object-id></mixed-citation></ref>
<ref id="pbio.2005339.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Almada</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Coimbra</surname> <given-names>NC</given-names></name>. <article-title>Recruitment of striatonigral disinhibitory and nigrotectal inhibitory GABAergic pathways during the organization of defensive behavior by mice in a dangerous environment with the venomous snake Bothrops alternatus (Reptilia, Viperidae).</article-title> <source>Synapse</source>. <year>2015</year>;<volume>69</volume>(<issue>6</issue>):<fpage>299</fpage>–<lpage>313</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/syn.21814" xlink:type="simple">10.1002/syn.21814</ext-link></comment> <object-id pub-id-type="pmid">25727065</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sommer</surname> <given-names>MA</given-names></name>. <article-title>Express saccades elicited during visual scan in the monkey</article-title>. <source>Vision Res</source>. <year>1994</year>;<volume>34</volume>(<issue>15</issue>):<fpage>2023</fpage>–<lpage>38</lpage>. Epub 1994/08/01. <object-id pub-id-type="pmid">7941401</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>White</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Stritzke</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gegenfurtner</surname> <given-names>KR</given-names></name>. <article-title>Saccadic facilitation in natural backgrounds</article-title>. <source>Curr Biol</source>. <year>2008</year>;<volume>18</volume>(<issue>2</issue>):<fpage>124</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2007.12.027" xlink:type="simple">10.1016/j.cub.2007.12.027</ext-link></comment> <object-id pub-id-type="pmid">18191567</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kornblith</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Cheng</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Ohayon</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tsao</surname> <given-names>DY</given-names></name>. <article-title>A network for scene processing in the macaque temporal lobe</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>79</volume>(<issue>4</issue>):<fpage>766</fpage>–<lpage>81</lpage>. Epub 2013/07/31. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.06.015" xlink:type="simple">10.1016/j.neuron.2013.06.015</ext-link></comment> <object-id pub-id-type="pmid">23891401</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stefanacci</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Amaral</surname> <given-names>DG</given-names></name>. <article-title>Topographic organization of cortical inputs to the lateral nucleus of the macaque monkey amygdala: a retrograde tracing study</article-title>. <source>The Journal of comparative neurology</source>. <year>2000</year>;<volume>421</volume>(<issue>1</issue>):<fpage>52</fpage>–<lpage>79</lpage>. Epub 2000/05/17. <object-id pub-id-type="pmid">10813772</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yamamoto</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>HF</given-names></name>, <name name-style="western"><surname>Hikosaka</surname> <given-names>O</given-names></name>. <article-title>Reward value-contingent changes of visual responses in the primate caudate tail associated with a visuomotor skill</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>(<issue>27</issue>):<fpage>11227</fpage>–<lpage>38</lpage>. Epub 2013/07/05. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0318-13.2013" xlink:type="simple">10.1523/JNEUROSCI.0318-13.2013</ext-link></comment> <object-id pub-id-type="pmid">23825426</object-id>; PubMed Central PMCID: PMC3718386.</mixed-citation></ref>
<ref id="pbio.2005339.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ghashghaei</surname> <given-names>HT</given-names></name>, <name name-style="western"><surname>Barbas</surname> <given-names>H</given-names></name>. <article-title>Pathways for emotion: interactions of prefrontal and anterior temporal pathways in the amygdala of the rhesus monkey</article-title>. <source>Neuroscience</source>. <year>2002</year>;<volume>115</volume>(<issue>4</issue>):<fpage>1261</fpage>–<lpage>79</lpage>. <object-id pub-id-type="pmid">12453496</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Morrison</surname> <given-names>SE</given-names></name>, <name name-style="western"><surname>Salzman</surname> <given-names>CD</given-names></name>. <article-title>The convergence of information about rewarding and aversive stimuli in single neurons</article-title>. <source>J Neurosci</source>. <year>2009</year>;<volume>29</volume>(<issue>37</issue>):<fpage>11471</fpage>–<lpage>83</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1815-09.2009" xlink:type="simple">10.1523/JNEUROSCI.1815-09.2009</ext-link></comment> <object-id pub-id-type="pmid">19759296</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>LeDoux</surname> <given-names>J</given-names></name>. <article-title>The amygdala</article-title>. <source>Curr Biol</source>. <year>2007</year>;<volume>17</volume>(<issue>20</issue>):<fpage>R868</fpage>–<lpage>74</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2007.08.005" xlink:type="simple">10.1016/j.cub.2007.08.005</ext-link></comment> <object-id pub-id-type="pmid">17956742</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>George</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Driver</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Seen gaze-direction modulates fusiform activity and its coupling with other brain areas during face processing</article-title>. <source>Neuroimage</source>. <year>2001</year>;<volume>13</volume>(<issue>6</issue> Pt 1):<fpage>1102</fpage>–<lpage>12</lpage>. Epub 2001/05/16. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/nimg.2001.0769" xlink:type="simple">10.1006/nimg.2001.0769</ext-link></comment> <object-id pub-id-type="pmid">11352615</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adolphs</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Gosselin</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Buchanan</surname> <given-names>TW</given-names></name>, <name name-style="western"><surname>Tranel</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Schyns</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Damasio</surname> <given-names>AR</given-names></name>. <article-title>A mechanism for impaired fear recognition after amygdala damage</article-title>. <source>Nature</source>. <year>2005</year>;<volume>433</volume>(<issue>7021</issue>):<fpage>68</fpage>–<lpage>72</lpage>. Epub 2005/01/07. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature03086" xlink:type="simple">10.1038/nature03086</ext-link></comment> <object-id pub-id-type="pmid">15635411</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kennedy</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Adolphs</surname> <given-names>R</given-names></name>. <article-title>Impaired fixation to eyes following amygdala damage arises from abnormal bottom-up attention</article-title>. <source>Neuropsychologia</source>. <year>2010</year>;<volume>48</volume>(<issue>12</issue>):<fpage>3392</fpage>–<lpage>8</lpage>. Epub 2010/07/06. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuropsychologia.2010.06.025" xlink:type="simple">10.1016/j.neuropsychologia.2010.06.025</ext-link></comment> <object-id pub-id-type="pmid">20600184</object-id>; PubMed Central PMCID: PMC2949539.</mixed-citation></ref>
<ref id="pbio.2005339.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dalton</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Nacewicz</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Johnstone</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Schaefer</surname> <given-names>HS</given-names></name>, <name name-style="western"><surname>Gernsbacher</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Goldsmith</surname> <given-names>HH</given-names></name>, <etal>et al</etal>. <article-title>Gaze fixation and the neural circuitry of face processing in autism</article-title>. <source>Nature neuroscience</source>. <year>2005</year>;<volume>8</volume>(<issue>4</issue>):<fpage>519</fpage>–<lpage>26</lpage>. Epub 2005/03/08. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1421" xlink:type="simple">10.1038/nn1421</ext-link></comment> <object-id pub-id-type="pmid">15750588</object-id>; PubMed Central PMCID: PMC4337787.</mixed-citation></ref>
<ref id="pbio.2005339.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baron-Cohen</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ring</surname> <given-names>HA</given-names></name>, <name name-style="western"><surname>Bullmore</surname> <given-names>ET</given-names></name>, <name name-style="western"><surname>Wheelwright</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ashwin</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Williams</surname> <given-names>SC</given-names></name>. <article-title>The amygdala theory of autism</article-title>. <source>Neurosci Biobehav Rev</source>. <year>2000</year>;<volume>24</volume>(<issue>3</issue>):<fpage>355</fpage>–<lpage>64</lpage>. <object-id pub-id-type="pmid">10781695</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Apicella</surname> <given-names>P</given-names></name>. <article-title>Leading tonically active neurons of the striatum from reward detection to context recognition</article-title>. <source>Trends in neurosciences</source>. <year>2007</year>;<volume>30</volume>(<issue>6</issue>):<fpage>299</fpage>–<lpage>306</lpage>. Epub 2007/04/11. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2007.03.011" xlink:type="simple">10.1016/j.tins.2007.03.011</ext-link></comment> <object-id pub-id-type="pmid">17420057</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Miall</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Kawato</surname> <given-names>M</given-names></name>. <article-title>Internal models in the cerebellum</article-title>. <source>Trends Cogn Sci</source>. <year>1998</year>;<volume>2</volume>(<issue>9</issue>):<fpage>338</fpage>–<lpage>47</lpage>. Epub 1998/09/01. <object-id pub-id-type="pmid">21227230</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stuphorn</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Schall</surname> <given-names>JD</given-names></name>. <article-title>Executive control of countermanding saccades by the supplementary eye field</article-title>. <source>Nature neuroscience</source>. <year>2006</year>;<volume>9</volume>(<issue>7</issue>):<fpage>925</fpage>–<lpage>31</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1714" xlink:type="simple">10.1038/nn1714</ext-link></comment> <object-id pub-id-type="pmid">16732274</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Isoda</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hikosaka</surname> <given-names>O</given-names></name>. <article-title>Switching from automatic to controlled action by monkey medial frontal cortex</article-title>. <source>Nature neuroscience</source>. <year>2007</year>;<volume>10</volume>(<issue>2</issue>):<fpage>240</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1830" xlink:type="simple">10.1038/nn1830</ext-link></comment> <object-id pub-id-type="pmid">17237780</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krakauer</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Mazzoni</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Ghazizadeh</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ravindran</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Shadmehr</surname> <given-names>R</given-names></name>. <article-title>Generalization of motor learning depends on the history of prior action</article-title>. <source>PLoS Biol</source>. <year>2006</year>;<volume>4</volume>(<issue>10</issue>):<fpage>e316</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.0040316" xlink:type="simple">10.1371/journal.pbio.0040316</ext-link></comment> <object-id pub-id-type="pmid">16968135</object-id>.</mixed-citation></ref>
<ref id="pbio.2005339.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pearson</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Heilbronner</surname> <given-names>SR</given-names></name>, <name name-style="western"><surname>Barack</surname> <given-names>DL</given-names></name>, <name name-style="western"><surname>Hayden</surname> <given-names>BY</given-names></name>, <name name-style="western"><surname>Platt</surname> <given-names>ML</given-names></name>. <article-title>Posterior cingulate cortex: adapting behavior to a changing world</article-title>. <source>Trends Cogn Sci</source>. <year>2011</year>;<volume>15</volume>(<issue>4</issue>):<fpage>143</fpage>–<lpage>51</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2011.02.002" xlink:type="simple">10.1016/j.tics.2011.02.002</ext-link></comment> <object-id pub-id-type="pmid">21420893</object-id>; PubMed Central PMCID: PMCPMC3070780.</mixed-citation></ref>
</ref-list>
</back>
</article>
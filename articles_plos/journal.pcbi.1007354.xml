<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-19-00033</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1007354</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Molecular biology</subject><subj-group><subject>Interaction networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical mechanics</subject><subj-group><subject>Acceleration</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Animal studies</subject><subj-group><subject>Experimental organism systems</subject><subj-group><subject>Model organisms</subject><subj-group><subject>Zebrafish</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Model organisms</subject><subj-group><subject>Zebrafish</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Animal studies</subject><subj-group><subject>Experimental organism systems</subject><subj-group><subject>Animal models</subject><subj-group><subject>Zebrafish</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Eukaryota</subject><subj-group><subject>Animals</subject><subj-group><subject>Vertebrates</subject><subj-group><subject>Fish</subject><subj-group><subject>Osteichthyes</subject><subj-group><subject>Zebrafish</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical mechanics</subject><subj-group><subject>Motion</subject><subj-group><subject>Velocity</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Network analysis</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Collective human behavior</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Collective human behavior</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Collective animal behavior</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Collective animal behavior</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Zoology</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Collective animal behavior</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Deep attention networks reveal the rules of collective motion in zebrafish</article-title>
<alt-title alt-title-type="running-head">Deep attention networks reveal the rules of collective motion in zebrafish</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8124-2359</contrib-id>
<name name-style="western">
<surname>Heras</surname> <given-names>Francisco J. H.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4353-7997</contrib-id>
<name name-style="western">
<surname>Romero-Ferrero</surname> <given-names>Francisco</given-names></name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7333-2477</contrib-id>
<name name-style="western">
<surname>Hinz</surname> <given-names>Robert C.</given-names></name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5359-3426</contrib-id>
<name name-style="western">
<surname>de Polavieja</surname> <given-names>Gonzalo G.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<addr-line>Champalimaud Research, Champalimaud Centre for the Unknown, Lisbon, Portugal</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Battaglia</surname> <given-names>Francesco P.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Radboud Universiteit Nijmegen, NETHERLANDS</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">francisco.heras@neuro.fchampalimaud.org</email> (FJHH); <email xlink:type="simple">gonzalo.polavieja@neuro.fchampalimaud.org</email> (GGP)</corresp>
</author-notes>
<pub-date pub-type="collection">
<month>9</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="epub">
<day>13</day>
<month>9</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>9</issue>
<elocation-id>e1007354</elocation-id>
<history>
<date date-type="received">
<day>11</day>
<month>1</month>
<year>2019</year>
</date>
<date date-type="accepted">
<day>21</day>
<month>8</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Heras et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1007354"/>
<abstract>
<p>A variety of simple models has been proposed to understand the collective motion of animals. These models can be insightful but may lack important elements necessary to predict the motion of each individual in the collective. Adding more detail increases predictability but can make models too complex to be insightful. Here we report that deep attention networks can obtain a model of collective behavior that is simultaneously predictive and insightful thanks to an organization in modules. When using simulated trajectories, the model recovers the ground-truth interaction rule used to generate them, as well as the number of interacting neighbours. For experimental trajectories of large groups of 60-100 zebrafish, <italic>Danio rerio</italic>, the model obtains that interactions between pairs can approximately be described as repulsive, attractive or as alignment, but only when moving slowly. At high velocities, interactions correspond only to alignment or alignment mixed with repulsion at close distances. The model also shows that each zebrafish decides where to move by aggregating information from the group as a weighted average over neighbours. Weights are higher for neighbours that are close, in a collision path or moving faster in frontal and lateral locations. The network also extracts that the number of interacting individuals is dynamical and typically in the range 8–22, with 1–10 more important ones. Our results suggest that each animal decides by dynamically selecting information from the collective.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Simple models have traditionally been very successful, because they usually provide more insight than complicated models. This is particularly true in physics, where simple models can often give highly precise quantitative predictions. However, biology is fundamentally complex and thus it is difficult to find simple models that give precise predictions. To create models that are both precise and insightful, we propose to harness the power of deep neural networks but to confine them into modules with a low number of inputs and outputs. We trained one such model to predict the future turning side of a fish in a collective. By plotting the different modules we obtain insight about how fish interact and how they aggregate information from different neighbours. This aggregation is dynamical and shows that fish can interact with approximately 20 neighbours but can also focus on fewer neighbours, down to 1-2, when some move at higher speed in front or to the sides, are very close or are in a collision path.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>Fundação para a Ciência e a Tecnologia (PT)</institution>
</funding-source>
<award-id>PTDC/NEU-SCC/0948/2014</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8124-2359</contrib-id>
<name name-style="western">
<surname>Heras</surname> <given-names>Francisco J. H.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>Fundação para a Ciência e a Tecnologia (PT)</institution>
</funding-source>
<award-id>PTDC/NEU-SCC/0948/2014</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5359-3426</contrib-id>
<name name-style="western">
<surname>de Polavieja</surname> <given-names>Gonzalo G.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution>Cogento</institution>
</funding-source>
<award-id>LISBOA-01-0145-FEDER-022170,</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5359-3426</contrib-id>
<name name-style="western">
<surname>de Polavieja</surname> <given-names>Gonzalo G.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>PHY-1748958</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5359-3426</contrib-id>
<name name-style="western">
<surname>de Polavieja</surname> <given-names>Gonzalo G.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award005">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>R25GM067110</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5359-3426</contrib-id>
<name name-style="western">
<surname>de Polavieja</surname> <given-names>Gonzalo G.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award006">
<funding-source>
<institution>Gordon and Betty Moore Foundation (US)</institution>
</funding-source>
<award-id>2919.01.</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5359-3426</contrib-id>
<name name-style="western">
<surname>de Polavieja</surname> <given-names>Gonzalo G.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award007">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001871</institution-id>
<institution>Fundação para a Ciência e a Tecnologia</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4353-7997</contrib-id>
<name name-style="western">
<surname>Romero-Ferrero</surname> <given-names>Francisco</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by Fundação para a Ciência e a Tecnologia (<ext-link ext-link-type="uri" xlink:href="http://www.fct.pt" xlink:type="simple">www.fct.pt</ext-link>) PTDC/NEU-SCC/0948/2014 (to GGdP and contract to FJHH), Congento (congento.org) LISBOA-01-0145-FEDER-022170, NVIDIA (nvidia.com) (FJHH, GGdP), Champalimaud Foundation (fchampalimaud.org) (GGdP) and GGdP work at Kavli Institute for Theoretical Physics Santa Barbara (<ext-link ext-link-type="uri" xlink:href="https://www.kitp.ucsb.edu" xlink:type="simple">https://www.kitp.ucsb.edu</ext-link>) by National Science Foundation (nsf.gov) Grant No. PHY-1748958, National Institutes of Health (nih.gov) Grant No. R25GM067110, and the Gordon and Betty Moore Foundation (<ext-link ext-link-type="uri" xlink:href="http://www.moore.org" xlink:type="simple">www.moore.org</ext-link>) Grant No. 2919.01. F. R-F. acknowledges a Fundação para a Ciência e a Tecnologia (<ext-link ext-link-type="uri" xlink:href="http://www.fct.pt" xlink:type="simple">www.fct.pt</ext-link>) PhD fellowship (PD/BD/105946/2014). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="0"/>
<page-count count="23"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-09-25</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The data can be found at <ext-link ext-link-type="uri" xlink:href="https://idtracker.ai" xlink:type="simple">https://idtracker.ai</ext-link>. Code used in this study is free and open-source and may be used to study interactions in any animal species or other agents (<ext-link ext-link-type="uri" xlink:href="https://gitlab.com/polavieja_lab/fishandra" xlink:type="simple">https://gitlab.com/polavieja_lab/fishandra</ext-link>).</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>There is a wide range of models of collective behavior. A useful way to understand the relative merits of these models is to classify them by their accuracy and their complexity (e.g. [<xref ref-type="bibr" rid="pcbi.1007354.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref002">2</xref>]). Some of the classical models of collective behavior, like interaction models [<xref ref-type="bibr" rid="pcbi.1007354.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1007354.ref007">7</xref>], many-eyes or weighted averages [<xref ref-type="bibr" rid="pcbi.1007354.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1007354.ref011">11</xref>], Condorcet [<xref ref-type="bibr" rid="pcbi.1007354.ref012">12</xref>] or others [<xref ref-type="bibr" rid="pcbi.1007354.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1007354.ref017">17</xref>] are of very low complexity. Low complexity can be formally characterised [<xref ref-type="bibr" rid="pcbi.1007354.ref018">18</xref>], but in practical terms we can define it as the number of parameters in the model. If a model has a low parameter-complexity, we can write down the mathematical description and study it in detail, leading to an intuitive grasp of the problem and therefore a better design of new experiments. In general, however, this simplicity likely misses important biological components. For this reason, these low-parameter-complexity models are not typically tested in their detailed quantitative predictions, using simpler global parameters instead (but see [<xref ref-type="bibr" rid="pcbi.1007354.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref020">20</xref>]).</p>
<p>New techniques allow to individually track each animal in large collectives with high precision [<xref ref-type="bibr" rid="pcbi.1007354.ref021">21</xref>], and can provide enough data to build accurate models of collective behaviour. However, it is difficult to increase accuracy without increasing complexity. For example, we can use the trajectories to train a very precise model based on deep neural networks, because they contain thousands or millions of parameters that can be adjusted to approximate any possible function [<xref ref-type="bibr" rid="pcbi.1007354.ref022">22</xref>]. Unfortunately, this parameter-complexity typically makes deep neural networks black boxes difficult to analyse. However, a function that is parameter-rich but has few inputs and outputs (i.e. low variable-complexity) can in principle be understood through graphical plotting. Here we propose to use deep attention networks [<xref ref-type="bibr" rid="pcbi.1007354.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1007354.ref025">25</xref>], because they express the social interaction as a combination of two deep-network modules of few inputs and outputs each, and thus they allow to simultaneously achieve insight and predictive accuracy.</p>
<p>We can illustrate the reduction of variables in a modular model by comparing it against an equivalent non-modular model. Without a modular approach, a case with, say, 25 neighbours, and with each animal being sensitive to the 2D position, speed and orientation of each, would need to be modelled using 25 × 6 = 150 variables for each individual. Studying a problem in 150 dimensions is impractical as insight is very difficult to extract. However, deep attention networks are organized in modules, and for some problems each module might depend only on a small number of variables, of the order of 4–6 in our problem. This reduction from 150 variables to modules of 4–6 variables allows for insight into the rules by analysis of these modules, while still achieving high prediction accuracy.</p>
<p>In addition to requiring high prediction accuracy and insight into the underlying interaction rule, we also require that the network model recovers the interaction rule and number of interacting neighbours in ground-truth data generated by agents following some mathematical rules. We found deep attention networks to be well suited for this recovery, as tested for a variety of interaction rules and different number of interacting neighbours.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Predicting the future using a deep interaction network</title>
<p>We recorded videos of groups of 60, 80 or 100 juvenile zebrafish, <italic>Danio rerio</italic>, (<xref ref-type="fig" rid="pcbi.1007354.g001">Fig 1A</xref> for a detail; [<xref ref-type="bibr" rid="pcbi.1007354.ref021">21</xref>] for setup). We tracked videos using our system idtracker.ai, obtaining high-quality position, velocity and acceleration values (see <xref ref-type="sec" rid="sec010">Methods and materials</xref>). See also <xref ref-type="supplementary-material" rid="pcbi.1007354.s001">S1</xref>, <xref ref-type="supplementary-material" rid="pcbi.1007354.s002">S2</xref> and <xref ref-type="supplementary-material" rid="pcbi.1007354.s003">S3</xref> Figs for statistics analysis of the trajectories obtained for videos of 100, 80 and 60 individuals, respectively, including distance to center of arena, local polarization, interindividual distance and probability of finding another animal around a focal one.</p>
<fig id="pcbi.1007354.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007354.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Deep-learning a model of collective behaviour.</title>
<p>(<bold>A</bold>) Variables used to predict future turns. Asocial variables, those only involving the focal, in red. Social variables, those involving both the focal and a neighbour, in blue. (<bold>B</bold>) Pair-interaction subnetwork, receiving asocial variables <italic>α</italic> and social variables <italic>σ</italic><sub><italic>i</italic></sub> from a single neighbour <italic>i</italic>, and outputting a vector of 128 components. All pair-interaction networks share the same weights. (<bold>C</bold>) Interaction network, showing how the outputs of the pair-interaction subnetworks, one for each neighbour, are summed and then fed to an interaction subnetwork. The output, <italic>z</italic> is the logit of the focal fish turning right after 1 s. (<bold>D</bold>) Pair-interaction subnetwork of the attention network. (<bold>E</bold>) Aggregation subnetwork of the attention network. Same structure as D, but the input is a restricted symmetric subset of the variables and the output is passed through an exponential function to make it positive. (<bold>F</bold>) Attention network, showing how the inputs of the pair-interaction and aggregation subnetworks are integrated to produce a single logit <italic>z</italic> for the focal fish turning right after 1 s.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.g001" xlink:type="simple"/>
</fig>
<p>We used the trajectories to obtain data-driven models of fish interactions. First, we required our models to be predictive of the future of a focal fish in test data (video sequences not used to train the model). The requirement of biological insight, which we discuss in the next section, was only added later. The reason for this strategy is that we first need to find out how much we can predict from video and models designed to be insightful need to make assumptions that may reduce the ability to predict.</p>
<p>We used a deep interaction network, inspired by their success in interacting systems in Physics [<xref ref-type="bibr" rid="pcbi.1007354.ref026">26</xref>]. Our deep interaction network is divided in two parts: (i) <italic>n</italic> pair-interaction subnetworks, each describing the interaction of a focal fish with one of its <italic>n</italic> closest neighbors (<xref ref-type="fig" rid="pcbi.1007354.g001">Fig 1B</xref>), and (ii) an aggregation or weighting subnetwork, aggregating the <italic>n</italic> outputs of the pair-interaction subnetworks (<xref ref-type="fig" rid="pcbi.1007354.g001">Fig 1C</xref>, subnetwork to the right).</p>
<p>The inputs to the network are quantities expressed in a coordinate system centered at the focal fish and with the <italic>y</italic>-axis in the direction of the velocity of the focal (<xref ref-type="fig" rid="pcbi.1007354.g001">Fig 1A</xref>, red). The pair-interaction subnetwork has as inputs the asocial information of the focal, <italic>α</italic> (<xref ref-type="fig" rid="pcbi.1007354.g001">Fig 1B</xref>, red), and the social information of one neighbour <italic>i</italic>, <italic>σ</italic><sub><italic>i</italic></sub> (<xref ref-type="fig" rid="pcbi.1007354.g001">Fig 1B</xref>, blue). The asocial information of the focal is its speed, <italic>v</italic>, tangential acceleration, <italic>a</italic><sub>∥</sub>, and normal acceleration, <italic>a</italic><sub>⊥</sub>. We found that <italic>a</italic><sub>∥</sub> had little impact on accuracy (<xref ref-type="supplementary-material" rid="pcbi.1007354.s022">S1 Table</xref>), so we did not consider it in further computations. The social information is the neighbour position with respect to the focal, <italic>x</italic><sub><italic>i</italic></sub> and <italic>y</italic><sub><italic>i</italic></sub>, its velocity, <italic>v</italic><sub><italic>i</italic>,<italic>x</italic></sub> and <italic>v</italic><sub><italic>i</italic>,<italic>y</italic></sub>, and acceleration, <italic>a</italic><sub><italic>i</italic>,<italic>x</italic></sub> and <italic>a</italic><sub><italic>i</italic>,<italic>y</italic></sub>. Neighbour accelerations had little impact on accuracy (<xref ref-type="supplementary-material" rid="pcbi.1007354.s022">S1 Table</xref>) and were not used in further computations.</p>
<p>Accuracy of prediction of the turning side of the focal fish after 1 second evaluated on held-out test data improves with the number of neighbours, but with diminishing returns (<xref ref-type="supplementary-material" rid="pcbi.1007354.s004">S4 Fig</xref>); we chose <italic>n</italic> = 25 neighbors. In the main text we provide analysis of groups of 100 animals and prediction at 1 s in the future for illustration purposes. Our models predict well a range of futures (<xref ref-type="supplementary-material" rid="pcbi.1007354.s005">S5 Fig</xref>). Results on how fish interact were found to be similar in computations using 250 ms, 500 ms and 1.5 s in the future (<xref ref-type="supplementary-material" rid="pcbi.1007354.s006">S6</xref>, <xref ref-type="supplementary-material" rid="pcbi.1007354.s007">S7</xref> and <xref ref-type="supplementary-material" rid="pcbi.1007354.s008">S8</xref> Figs) and for groups of 60 or 80 zebrafish (<xref ref-type="supplementary-material" rid="pcbi.1007354.s009">S9</xref> and <xref ref-type="supplementary-material" rid="pcbi.1007354.s010">S10</xref> Figs).</p>
<p>Accuracy of prediction of the turning side after 1 s is higher for large turning angles than for turning angles close to 0 or 180 degrees (<xref ref-type="supplementary-material" rid="pcbi.1007354.s011">S11 Fig</xref>). For turning angles of 20–160°, the interaction network predicted the correct side with an accuracy of 85.6%; up to 86.8% for 30–100°. In contrast, a model using only focal variables failed to obtain a high accuracy and reached only 60%. Interaction networks with different architectures performed slightly worse (<xref ref-type="supplementary-material" rid="pcbi.1007354.s023">S2 Table</xref>), while fully-connected networks performed consistently worse (<xref ref-type="supplementary-material" rid="pcbi.1007354.s024">S3 Table</xref>).</p>
<p>The high accuracy of the interaction network shows that the 6 × 25 = 150 dimensions capture an important part of the collective dynamics. The instances not predicted may originate from a variety of effects, including higher-order correlations, individuality and non-markovian effects, i.e. history-dependency, be it at short scales or at long scales (internal states or unaccounted behavioural variables, like posture or eye movements). For instance, adding a history of previous locations of focal and neighbour fish improved accuracy (<xref ref-type="supplementary-material" rid="pcbi.1007354.s012">S12 Fig</xref>).</p>
</sec>
<sec id="sec004">
<title>Deep attention networks obtain a predictive and analyzable model</title>
<p>The deep interaction model of the previous section is too high-dimensional to provide useful insight into animal interactions. The pair interaction subnetwork, for example, takes the values of 6 variables as inputs and outputs 128 values (<xref ref-type="fig" rid="pcbi.1007354.g001">Fig 1B</xref>). The aggregation subnetwork first sums up the 25 128-dimensional vectors to give a single vector of 128 components, and then processes it to output a single number, <italic>z</italic> (<xref ref-type="fig" rid="pcbi.1007354.g001">Fig 1C</xref>).</p>
<p>To gain insight on the nature of fish interactions, we will add hypotheses into the structure of the solution. Specifically, like others before us (e.g. [<xref ref-type="bibr" rid="pcbi.1007354.ref027">27</xref>–<xref ref-type="bibr" rid="pcbi.1007354.ref029">29</xref>]), we will assume that animal interactions take place in animal pairs and that each animal integrates with weights these pair interactions,
<disp-formula id="pcbi.1007354.e001"><alternatives><graphic id="pcbi.1007354.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:munderover> <mml:mo>Π</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mfrac><mml:mrow><mml:mi>W</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:msub> <mml:mi>W</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where Π is the pair-wise interaction function and <italic>W</italic> is the weighting function.</p>
<p>A possible approach would be to assume simple functional forms for these functions and estimate the parameters from error minimization (like e.g. [<xref ref-type="bibr" rid="pcbi.1007354.ref030">30</xref>]). Here we explore the alternative of using deep neural networks, powerful function approximators [<xref ref-type="bibr" rid="pcbi.1007354.ref022">22</xref>], to be shaped into the needed functions by minimizing the prediction error. To this end, we will use two network modules, one capturing the interaction between pairs of fish (<xref ref-type="fig" rid="pcbi.1007354.g001">Fig 1D</xref>), and a second one capturing the aggregation of pair-interactions (<xref ref-type="fig" rid="pcbi.1007354.g001">Fig 1E</xref>). Using these two modules, we can express the probability that the focal turns to the right after 1 s, <italic>p</italic>, as <italic>p</italic> = 1/1 + exp(−<italic>z</italic>), where <italic>z</italic> is the logit that the network outputs (<xref ref-type="fig" rid="pcbi.1007354.g001">Fig 1F</xref>),
<disp-formula id="pcbi.1007354.e002"><alternatives><graphic id="pcbi.1007354.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>z</mml:mi> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:munderover> <mml:mo>Π</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mfrac><mml:mrow><mml:mi>W</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi>α</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="normal">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="normal">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:msub> <mml:mi>W</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>α</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="normal">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="normal">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
The pair-interaction subnetwork, Π(<italic>α</italic>, <italic>σ</italic><sub><italic>i</italic></sub>), describes the interaction of the focal and one neighbour <italic>i</italic>. The aggregation subnetwork <italic>W</italic> gives different weights to the different neighbors <italic>i</italic> in the aggregation depending on the kinematic parameters of focal <italic>α</italic><sup>(w)</sup> and neighbor relative to focal <inline-formula id="pcbi.1007354.e003"><alternatives><graphic id="pcbi.1007354.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="normal">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. The subscript indicates that these variables are, in general, different to the ones in the pair-interaction subnetwork. We found that focal speed, neighbor location and neighbour speed as inputs to the aggregation subnetwork can make an accurate model (<xref ref-type="supplementary-material" rid="pcbi.1007354.s025">S4 Table</xref>), which we will use in main text. An alternative model with the same number of variables considers the neighbour velocity (not simply neighbour speed) but does not need the focal speed (<xref ref-type="supplementary-material" rid="pcbi.1007354.s025">S4 Table</xref>). For this second model, consider results in <xref ref-type="supplementary-material" rid="pcbi.1007354.s019">S19 Fig</xref>.</p>
<p>Since we want the pair-interaction subnetwork, Π, and the aggregation subnetwork, <italic>W</italic>, to represent the logit of turning after 1 s given a neighbor and a weight representing the importance of that neighbor, respectively, they must differ on several accounts. (i) Π can have any real output, while <italic>W</italic> must be always positive. (ii) Π must be antisymmetric with respect to reflection on the y-axis, while <italic>W</italic> must be symmetric. This is because we assume (like e.g. [<xref ref-type="bibr" rid="pcbi.1007354.ref030">30</xref>]) that a neighbour to the right makes the focal go to the right as much as an identical neighbour to the left of the focal makes the focal move to the left. For the aggregation weight <italic>W</italic>, however, we assume that the importance of the two cases is the same. (iii) The aggregation weights must sum 1. These three conditions are required and we enforced them by: (i) using an exponential as final activation function of <italic>W</italic>, (ii) antisymmetrizing Π and using symmetric input in <italic>W</italic>, and (iii) normalising the outputs of <italic>W</italic> by the sum across all neighbours prior to the integration with the outputs of Π.</p>
<p>The network structure given by equation <xref ref-type="disp-formula" rid="pcbi.1007354.e002">Eq (2)</xref> has been called deep attention network [<xref ref-type="bibr" rid="pcbi.1007354.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref024">24</xref>]. We trained the deep attention network with our trajectories, achieving 85.1-85.3% accuracy for turns between 20° and 160° and around 86.6% for 30-100°. This is slightly less accurate than the interaction network, but the much lower dimensionality of the two subnetworks allows for a detailed analysis. An attention network trained using shuffled neighbour trajectories only reached an accuracy of 70.3% (large turns, 20°–160°), suggesting that the model trained on normal (unshuffled) data is mainly capturing real interactions and relatively few spurious correlations.</p>
</sec>
<sec id="sec005">
<title>The structure of interaction of a pair of animals in a collective</title>
<p>The pair-interaction subnetwork Π is a six-dimensional function. We plotted its output, the logit of the focal fish turning to the right after 1 s, <italic>z</italic>, as a function of two variables: the angle, <italic>θ</italic><sub><italic>i</italic></sub>, and the speed of the neighbour, <italic>v</italic><sub><italic>i</italic></sub> (<xref ref-type="fig" rid="pcbi.1007354.g002">Fig 2</xref>). We fixed the other four variables: focal at median speed of 3.04 BL/s, focal normal acceleration at <italic>a</italic><sub>⊥</sub> = 0, and neighbour position at <italic>x</italic><sub><italic>i</italic></sub> = 7 BL and <italic>y</italic><sub><italic>i</italic></sub> = 1 BL. At a neighbour speed above the median (<xref ref-type="fig" rid="pcbi.1007354.g002">Fig 2A</xref>, left; median speed indicated with a horizontal line at 3.04 BL/s), the focal animal is sensitive to the neighbour orientation, with a high probability of turning right (left) after 1 s when the neighbour is moving away from (towards) the focal, resulting in an alignment of the focal to the neighbour. When the neighbour speed is below the median, however, the focal is attracted towards it regardless of the neighbour orientation.</p>
<fig id="pcbi.1007354.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007354.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Properties of interaction between a pair of fish in the collective.</title>
<p>(<bold>A</bold>) Logit <italic>z</italic> resulting from the pair-interaction subnetwork of the attention network, plotted as a function of the orientation of the neighbour respect to the focal, <italic>θ</italic><sub><italic>i</italic></sub>, and speed of the neighbour, <italic>v</italic><sub><italic>i</italic></sub>, for neighbour located at (<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>) = (7, 1) BL (body lengths, left) and (<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>) = (3, 1) BL (right). Focal speed is fixed at median speed of 3.04 BL/s and focal acceleration at <italic>a</italic><sub>⊥</sub> = 0 BL/s<sup>2</sup>. Red colour is evidence that the focal fish will turn right in 1s, while blue is evidence that the focal fish will turn left. Horizontal dashed line highlights the median speed of 3.04 BL/s. (<bold>B</bold>) Same as (A) but for 64 different neighbour positions (<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>), with <italic>x</italic><sub><italic>i</italic></sub> and <italic>y</italic><sub><italic>i</italic></sub> taking values in (−7, −5, −3, −1, 1, 3, 5, 7) BL.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.g002" xlink:type="simple"/>
</fig>
<p>As a contrasting example, consider when the neighbour is closer and slightly in front, at <italic>x</italic><sub><italic>i</italic></sub> = 3 BL and <italic>y</italic><sub><italic>i</italic></sub> = 1 BL (<xref ref-type="fig" rid="pcbi.1007354.g002">Fig 2A</xref>, right). In this case, the focal gets repelled by the neighbour when the neighbor speed is below 3 BL/s.</p>
<p>These two examples illustrate how alignment, attraction and repulsion depend not only on the neighbour location but also on its speed (<xref ref-type="fig" rid="pcbi.1007354.g002">Fig 2B</xref>, similar to <xref ref-type="fig" rid="pcbi.1007354.g002">Fig 2A</xref> but for a 8x8 matrix of subplots, each for a different neighbour position), and on the speed (<xref ref-type="supplementary-material" rid="pcbi.1007354.s013">S13</xref>, <xref ref-type="supplementary-material" rid="pcbi.1007354.s014">S14</xref>, <xref ref-type="supplementary-material" rid="pcbi.1007354.s015">S15</xref> and <xref ref-type="supplementary-material" rid="pcbi.1007354.s016">S16</xref> Figs) and acceleration of the focal (<xref ref-type="supplementary-material" rid="pcbi.1007354.s017">S17 Fig</xref>).</p>
<p>From this six-dimensional function we can define alignment regions as those where the logit changes sign with neighbour orientation, that is, when focal will turn right (left) if neighbour orients to the right (left) (<xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3</xref>, gray regions). The alignment score (<xref ref-type="disp-formula" rid="pcbi.1007354.e018">Eq (12)</xref>) measures how sensitive the logit is to neighbour orientation (<xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A</xref>, gray region; focal speed fixed at median value of 3.04 BL/s and neighbour speed indicated on top of each subplot). The alignment region increases in size and in score with increasing neighbour speed. At high neighbour velocities, strong alignment areas are 2-5 BL behind the focal and 3-5 BL at the sides (<xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A</xref>, right, darker gray regions). In a region 5-7 BL behind the focal there is a weak orientation effect but reversed in sign, with focal turning right (left) when neighbour orients to the left (right), (<xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A</xref>, pink). This anti-alignment region extends when increasing focal speed, while keeping neighbour speed fixed at the median value of 3.04 BL/s (<xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3B</xref>, pink).</p>
<fig id="pcbi.1007354.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007354.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Alignment, attraction and repulsion areas depend on kinematic parameters of focal and neighbour.</title>
<p>(<bold>A, B</bold>). Alignment (gray), attraction (orange), repulsion (purple) and anti-alignment (pink) areas. Alignment score (gray) measures how much the logit changes when changing the neighbour orientation angle, and it is computed only in the orientation areas (see <xref ref-type="sec" rid="sec010">Methods and materials</xref>). Attraction (orange) and repulsion scores (purple) are the logit averaged across relative orientation angles (positive or negative, respectively), plotted outside orientation areas. (<bold>A</bold>) Scores given at four different values of the neighbour speed (1, 2, 4 and 8 BL/s) while fixing focal speed at the median 3.04 BL/s. Focal normal acceleration fixed at <italic>a</italic><sub>⊥</sub> = 0. (<bold>B</bold>) Same as (<bold>A</bold>) but now fixing neighbour speed and varying focal speed. (<bold>C, D</bold>) Attraction and repulsion scores as in (<bold>A,B</bold>) but now plotted for all regions regardless of whether there is alignment effect or not.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.g003" xlink:type="simple"/>
</fig>
<p>We define attraction (resp. repulsion) regions as those where the logit does not change sign when changing the neighbour angle. Instead, the focal is attracted towards (resp. repelled away from) the neighbour’s location independently of its orientation. The attraction-repulsion score (<xref ref-type="disp-formula" rid="pcbi.1007354.e017">Eq (11)</xref>) measures how positive (attraction) or negative (repulsion) is the logit of turning towards the neighbour (<xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A</xref>). Attraction regions shrink with increasing neighbour speed. They are mainly located to the side at 6-8 BL, extending to the back. Repulsion takes place only when the neighbour speed is below the median speed and neighbours are close to the focal (<xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A and 3B</xref>, purple).</p>
<p>However, classifying interactions into only 4 classes is oversimplistic, and a more complete account is captured by the six dimensional pair-interaction function in <xref ref-type="fig" rid="pcbi.1007354.g002">Fig 2</xref>. For example, when the neighbour is at (<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>) = (3, 1) BL and at high speed there is alignment but with a much higher probability of turning left at angles below <italic>π</italic>/2 than turning right at angles above <italic>π</italic>/2. This asymmetry in angles makes the sensitivity to orientation to the neighbour a mix of alignment and repulsion. We can see the full extent of relative attraction and repulsion areas by plotting the attraction-repulsion score for all points in space regardless of whether they correspond to an alignment effect or not (<xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3C</xref> for different neighbour speeds and <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3D</xref> for different focal speeds). There is an approximately 5 BL diameter region of relative repulsion around the focal. Regions with a mix of alignment and repulsion (or attraction) are those of alignment in <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A and 3B</xref> that overlap with regions of relative repulsion (attraction) in <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3C and 3D</xref>.</p>
<p>We also tested which interactions we would obtain when using shuffled trajectories. We could not find clear repulsion, orientation and attraction areas (<xref ref-type="supplementary-material" rid="pcbi.1007354.s018">S18 Fig</xref>), and the outputs are closer to zero. The only exception is the anti-alignment area appearing 5-7 BL behind the focal fish, (<xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A and 3B</xref>; <xref ref-type="supplementary-material" rid="pcbi.1007354.s018">S18 Fig</xref>, pink), consistent with the idea that the anti-alignment areas have an origin in spurious correlation from wall interactions rather than a causal rule of collective motion. This area of anti-alignment corresponds to the complex patterns observed at 5-7 BL behind the focal fish in <xref ref-type="fig" rid="pcbi.1007354.g002">Fig 2B</xref>.</p>
</sec>
<sec id="sec006">
<title>Recovering interactions in ground-truth data</title>
<p>To validate our ability to reconstruct rules of collective behaviour, we applied our method to simulated trajectories. We generated artificial trajectories of several interacting agents following a variation of well studied behavioural rules [<xref ref-type="bibr" rid="pcbi.1007354.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref031">31</xref>]. The behavioural rule divides the surroundings of the fish in three areas (<xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4A</xref>, left). If there are neighbours in the innermost area, the fish will turn away from them regardless of the other neighbours. Otherwise, the fish will align with respect to fish in the middle area and turn towards fish in the outermost area (see <xref ref-type="sec" rid="sec010">Methods and materials</xref> for details).</p>
<fig id="pcbi.1007354.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007354.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Ground-truth validation using simulated trajectories with known interaction rules.</title>
<p>(<bold>A</bold>) Interaction models used to generate data. Fish turn away from neighbours that are in the repulsion area. If there are no neighbours in the repulsion area, fish align with neighbours in the alignment area and are attracted to neighbours in the attraction area. The shape, size and relative location of the areas is varied in different simulations, shown here in different columns. (<bold>B</bold>) Pair interaction scores (above) and aggregation weights (below) obtained when training using simulated trajectories generated by the interaction rules in A. (<bold>C</bold>) Average total number of interacting neighbours, <italic>N</italic><sub>total</sub>, (blue) as estimated from the deep attention network. Each dot corresponds to a different video with different maximum number of interacting individuals of 3, 7, 11, 15, 19 and 23. Exact correspondence with ground truth number of interacting neighbours as black line. Right: histogram (upper) and example time series (lower) for the estimated number of interacting neighbours, <italic>N</italic><sub>total</sub>, (blue) and the groundtruth (black). Histogram and time series calculated for trajectories where a maximum of 15 individuals interact.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.g004" xlink:type="simple"/>
</fig>
<p>Our method successfully recovers the three areas, both correctly labelling them with our definitions of repulsion, orientation and attraction, and matching their spatial extent (<xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4B</xref>, 1st column). We further tested whether we could recover different interaction rules (<xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4A</xref>). We recovered the rule when changing the value of radius of repulsion (<xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4B</xref>, 2nd column), when the orientation area is displaced to the front of the focal (3rd column), when making the orientation area elliptical (4th column) or when adding a blind angle (5th column).</p>
</sec>
<sec id="sec007">
<title>The aggregation module</title>
<p>The aggregation subnetwork <italic>W</italic> in <xref ref-type="disp-formula" rid="pcbi.1007354.e002">Eq (2)</xref> outputs the (positive) weight of each neighbor in the aggregation. We found it to depend mainly on 4 variables <xref ref-type="supplementary-material" rid="pcbi.1007354.s025">S4 Table</xref> <disp-formula id="pcbi.1007354.e004"><alternatives><graphic id="pcbi.1007354.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>W</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>W</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>v</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
with <italic>v</italic> the focal speed, <italic>v</italic><sub><italic>i</italic></sub> the neighbor speed and <italic>x</italic><sub><italic>i</italic></sub> and <italic>y</italic><sub><italic>i</italic></sub> the relative position of neighbour <italic>i</italic>.</p>
<p>In each subplot of <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref> we give <italic>W</italic> for different neighbour positions, keeping neighbour and focal speed constant. Generally, <italic>W</italic> is higher for neighbours that are closer to the focal, and lower for neighbours behind the focal. In contrast, when shuffled trajectories are used during training, the resulting aggregation module shows no clear structure, except for a weak front-back gradient (<xref ref-type="supplementary-material" rid="pcbi.1007354.s018">S18 Fig</xref>).</p>
<fig id="pcbi.1007354.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007354.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Weighting function: How a fish aggregates information from neighbours.</title>
<p>Logarithm of the aggregation weight, log(<italic>W</italic>), as a function of neighbour position, <italic>x</italic><sub><italic>i</italic></sub> and <italic>y</italic><sub><italic>i</italic></sub>. Top row: focal speed fixed at 3.04 BL/s and each subplot corresponding to different neighbour speeds marked on top of each. Bottom row: same as top row but for fixed neighbour speed at 3.04 BL/s and different focal speeds.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.g005" xlink:type="simple"/>
</fig>
<p>In the upper row of <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref> all subplots have the same focal speed at the median speed of 3.04 BL/s, and each indicates the neighbour speed on top, with values <italic>v</italic><sub><italic>i</italic></sub> = 1, 2, 4 and 8 BL/s. We see how <italic>W</italic> increases with neighbour speed for most neighbour positions, implying that faster neighbours carry more weight in the aggregation. This is more pronounced when the neighbour is close by and to the side.</p>
<p>In the lower row of <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref> all subplots have the same neighbour speed at the median speed of 3.04 BL/s, and each indicates the focal speed on top, with values <italic>v</italic><sub><italic>i</italic></sub> = 1, 2, 4 and 8 BL/s. We see how the mass of <italic>W</italic> increasingly shifts towards the front the faster the focal fish moves. Adding other variables to the attention marginally improves accuracy <xref ref-type="supplementary-material" rid="pcbi.1007354.s025">S4 Table</xref>, and still further insight is gained. If the neighbour orientation angle is added as input, higher values of the weight <italic>W</italic> are obtained in positions leading to an immediate collision (<xref ref-type="supplementary-material" rid="pcbi.1007354.s019">S19 Fig</xref>).</p>
<p>The final impact of each neighbour on the probability of the focal turning right can be seen from <xref ref-type="disp-formula" rid="pcbi.1007354.e002">Eq (2)</xref> to be given by a normalized weight, that is, the weight given by <italic>W</italic> relative to the sum of the weights of all individuals,
<disp-formula id="pcbi.1007354.e005"><alternatives><graphic id="pcbi.1007354.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>ω</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>W</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mi>W</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula></p>
<p>For example, if all 25 neighbours are assigned the same weight by <italic>W</italic>, after normalization all animals weight 1/25 = 0.04, no matter how large or small the value of <italic>W</italic> is. If one of the neighbours has a higher (lower) value of <italic>W</italic>, the importance of the other neighbours decreases (increases).</p>
<p>In the network trained using simulated data, the areas corresponding to repulsion are labelled as having an attention several times higher (<xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4B</xref>). This is exactly as it should be, because the collective rules we used to generate the simulated data dictate that the presence of neighbours in the repulsion area causes the focal fish to ignore all neighbours in the orientation and attraction areas.</p>
</sec>
<sec id="sec008">
<title>Estimating the number of interacting neighbours</title>
<p>Using the aggregation weights, we tested whether it is possible to estimate the number of interacting neighbours. We generated ground-truth trajectories with different numbers of interacting neighbours. Specifically, we generated simulated trajectories with different topological ranges, that is, with different maximum number of interacting neighbours (3, 7, 11, 15, 19 and 23). For this simulated data, the more accurate network was the one that used the topological index of each neighbour in addition to the dynamical variables selected above (80.6% vs 81.6%, all angles), and we thus used it for the following analysis.</p>
<p>Previous work (e.g. [<xref ref-type="bibr" rid="pcbi.1007354.ref032">32</xref>]) detect social interaction by looking for correlations between trajectories, analysing time delays to determine the direction of the influence. In our case, it is natural to use the aggregation weights as a proxy of the strength of the influence of each neighbour, and based on them we designed functions to quantify the number of the most influential. More specifically, we used the inverse of the typical weight <italic>N</italic><sub>total</sub> = 1/<italic>ω</italic><sub>t</sub> = exp(− ∑<sub><italic>i</italic></sub> <italic>ω</italic><sub><italic>i</italic></sub> log(<italic>ω</italic><sub><italic>i</italic></sub>)) ([<xref ref-type="bibr" rid="pcbi.1007354.ref033">33</xref>], section 4.4). Using this expression, we recovered the average ground-truth values for all the cases in which we used simulated trajectories (<xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4C</xref>, left).</p>
<p>The recovery of the number of interacting neighbours can be seen in more detail using statistics instead of simply the average number of neighbours. We show for illustration this statistics for simulations with a maximum number of neighbours of 15 (<xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4C</xref>). Note that the ground truth has a peak at 1 neighbour, corresponding to a neighbour in the repulsion region, when the simulated agent ignores other neighbours outside the repulsion area (<xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4C</xref>, right, black). The peak at a 15 neighbours in the ground truth corresponds to the number of neighbours within the interacting areas, with a maximum of 15 (<xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4C</xref>, right, black). The statistics of interacting neighbours estimated by the network model has a good correspondence with the ground truth (<xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4C</xref>, right, blue). Consistent with the statistics, the network also correctly estimates the time variation of the number of interacting neighbours, as illustrated in the example of <xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4C</xref>, bottom.</p>
<p>We performed a similar analysis in the fish experimental data. To illustrate the effect of aggregation in the data, we give the normalized weights <italic>ω</italic><sub><italic>i</italic></sub> in <xref ref-type="disp-formula" rid="pcbi.1007354.e005">Eq (4)</xref> for each neighbour in three illustrative frames (<xref ref-type="fig" rid="pcbi.1007354.g006">Fig 6A</xref>; animals with higher normalized weights in darker green). We observe cases in which a large number of neighbours has an important impact (<xref ref-type="fig" rid="pcbi.1007354.g006">Fig 6A</xref>, upper right), others with fewer (<xref ref-type="fig" rid="pcbi.1007354.g006">Fig 6A</xref>, upper middle) or even with a single neighbour that overweights the others by far (<xref ref-type="fig" rid="pcbi.1007354.g006">Fig 6A</xref>, upper left).</p>
<fig id="pcbi.1007354.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007354.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Relevant neighbours in the aggregation.</title>
<p><bold>A</bold> (Upper panel) Three example frames with each neighbour coloured with its normalized weight in the aggregation. Focal animal is indicated in gray color, with a horizontal line proportional to the normal acceleration to either left or right and a small dot in its frontal positions indicating the focal position 1 second into the future. In both focal and neighbours, a line along the major axis indicates the fish velocity. (Lower panel) Distribution of the total number of interacting neighbours <italic>N</italic><sub>total</sub> (blue), and of the important neighbours, <italic>N</italic><sub>important</sub> (red). <bold>B</bold> Left: Time variation of the number of total interacting neighbours, <italic>N</italic><sub>total</sub>, and the number of important neighbours, <italic>N</italic><sub>important</sub> for a illustrative focal fish and short period of time. Right: Power spectra of the two measures of the estimated number of neighbours.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.g006" xlink:type="simple"/>
</fig>
<p>To quantify this smaller set of important neighbours, we computed the number of neighbours with weight smaller than the typical weight, <italic>N</italic><sub>important</sub>. For the videos with 100 individuals, the resulting distribution of estimated total number of interacting neighbours <italic>N</italic><sub>total</sub> has a mean of 16.6, and the distribution of number of important neighbours <italic>N</italic><sub>important</sub> has a mean of 4.8, (<xref ref-type="fig" rid="pcbi.1007354.g006">Fig 6A</xref>, red).</p>
<p>The number of interacting and important neighbours changes dynamically. To gain some intuition on the dynamics of the number of total and important interacting neighbours, consider how these values change in time in an illustrative section of video for a focal individual (<xref ref-type="fig" rid="pcbi.1007354.g006">Fig 6B</xref>, left). It can be seen that both measures of interacting and important neighbours are roughly proportional and that they can change in a fast sub-second scale. We analyzed the time scales by computing the power spectrum of both measures (<xref ref-type="fig" rid="pcbi.1007354.g006">Fig 6B</xref>, right). The power spectra monotonically decrease with frequency, implying that most of the variation occurs at low frequencies, albeit without a concrete value for the time-scale (<xref ref-type="fig" rid="pcbi.1007354.g006">Fig 6B</xref>, right).</p>
</sec>
</sec>
<sec id="sec009" sec-type="conclusions">
<title>Discussion</title>
<p>We developed a model of collective motion that (i) accurately predicts future behaviour (like e.g. [<xref ref-type="bibr" rid="pcbi.1007354.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref034">34</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref035">35</xref>]) (ii) is insightful, (iii) works for data not used to obtain the model, a standard requirement in machine learning, and (iv) it recovers the interaction rule and number of neighbours in groundtruth data.</p>
<p>We divided the interaction rule into two functions, a pair-wise interaction function and a second function giving the weight of each neighbour in the aggregation. Instead of fitting a simple functional expression (e.g. [<xref ref-type="bibr" rid="pcbi.1007354.ref030">30</xref>]) or a shallow network [<xref ref-type="bibr" rid="pcbi.1007354.ref036">36</xref>], we used a deep neural network, specifically a deep attention network. After training, we found that we could extract attraction, repulsion and alignment as approximate notions [<xref ref-type="bibr" rid="pcbi.1007354.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref031">31</xref>] from the trained pairwise interaction. Usually, these interaction classes are defined only in terms of relative position of neighbour. However, we found them to exist in a 6-dimensional space. This translates into these classes also depending on speeds of focal and neighbour, focal acceleration and relative orientation between the two fish. This implies that experiments testing for the relevance of one variable, say speed, may give contradictory results depending on the analysis strategy. Our results imply that analysis needs to take into account that the interactions take place in a space with more dimensions. Also note that the three classes are not cleanly separated as alignment regions are mixed with attraction or repulsion, as found in [<xref ref-type="bibr" rid="pcbi.1007354.ref030">30</xref>].</p>
<p>To calculate the weight in the aggregation we also chose a neural network instead of a simple rule. The neural network architecture we chose has enough flexibility to approximate many previously proposed weighting rules. This includes the angle subtended by the neighbour fish [<xref ref-type="bibr" rid="pcbi.1007354.ref029">29</xref>], the inverse of the distance to the neighbour [<xref ref-type="bibr" rid="pcbi.1007354.ref028">28</xref>], and a decreasing function of the topological rank [<xref ref-type="bibr" rid="pcbi.1007354.ref027">27</xref>]. Other previously proposed rules are binary weights based on thresholds of simulated visual motion cues [<xref ref-type="bibr" rid="pcbi.1007354.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref038">38</xref>], first Voronoi neighbourhood [<xref ref-type="bibr" rid="pcbi.1007354.ref007">7</xref>] and topological ranges [<xref ref-type="bibr" rid="pcbi.1007354.ref039">39</xref>]. A simple aggregation rule would be to average the outputs of the pairwise-interaction network. Compatible with previous studies (e.g. [<xref ref-type="bibr" rid="pcbi.1007354.ref040">40</xref>]), we found that this simple rule gives a lower accuracy (<xref ref-type="supplementary-material" rid="pcbi.1007354.s025">S4 Table</xref>).</p>
<p>Providing it is large enough to be flexible and small enough not to seriously suffer from overfitting, the exact architecture of the two neural subnetworks does not have a strong effect in the obtained maps (<xref ref-type="supplementary-material" rid="pcbi.1007354.s020">S20</xref> and <xref ref-type="supplementary-material" rid="pcbi.1007354.s021">S21</xref> Figs).</p>
<p>An aggregation rule obtained by weighting using functions of dynamical variables can explain data that seem to be generated by a fixed number of neighbours in the interaction, as shown by using a simpler alternative [<xref ref-type="bibr" rid="pcbi.1007354.ref028">28</xref>]. Our aggregation may be seen as allowing a smooth transition from average type models [<xref ref-type="bibr" rid="pcbi.1007354.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1007354.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref041">41</xref>] and models in which one or very few animals influence the rest as in the many-eyes model for predator detection [<xref ref-type="bibr" rid="pcbi.1007354.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1007354.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref042">42</xref>] and others [<xref ref-type="bibr" rid="pcbi.1007354.ref017">17</xref>]. Note that this ability to shift from many to few can allow a collective to match the changing knowledge distribution in the group [<xref ref-type="bibr" rid="pcbi.1007354.ref043">43</xref>]. We believe our methodology could open the door to the experimental study of the properties of this matching.</p>
<p>In addition to the attention network, we developed a more precise deep interaction network that taught us which are the relevant variables to consider and gave us a reference accuracy. The interaction network is a smooth interpolation of the raw data, and it may also be used to complement data analysis studies of experimental data. This is particularly true in high-dimensional systems, where data-analysis runs into many practical difficulties. Having an interpolating function that can be queried simplifies the exploration of the space of inputs. Important input variables can be identified, and their effects readily tested for a few different combinations of the other variables. Intuitions obtained from exploring the interpolating function can then be used to produce a model or to guide data analysis. The deep interaction network can also be used for problems requiring prediction of the future location of an animal, for example the optogenetic brain stimulation [<xref ref-type="bibr" rid="pcbi.1007354.ref044">44</xref>] or microscopic imaging [<xref ref-type="bibr" rid="pcbi.1007354.ref045">45</xref>] of free-swimming animals.</p>
<p>The variables selected as input to the models can be enriched at the cost of increasing the model dimensionality. For example, one can add more information about behavioral history, possible internal variables (parametrized, for example, by time of day or more direct internal measurements), explicit dynamics and posture [<xref ref-type="bibr" rid="pcbi.1007354.ref046">46</xref>–<xref ref-type="bibr" rid="pcbi.1007354.ref049">49</xref>]. For instance, a longer history of previous locations allows the attention network to increase its predicting accuracy, albeit with diminishing returns (<xref ref-type="supplementary-material" rid="pcbi.1007354.s012">S12 Fig</xref>). Also, the existence of higher-order interactions not captured by the deep attention network is evidenced by its lower accuracy compared to the interaction network, (<xref ref-type="supplementary-material" rid="pcbi.1007354.s026">S5 Table</xref>).</p>
<p>Our results illustrate how modular deep networks enable flexible data-driven modelling without losing insight. Each module is flexible, with tens of thousands of parameters, but implements a function with low dimensionality in the number of inputs and outputs. Combinations of modules [<xref ref-type="bibr" rid="pcbi.1007354.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1007354.ref051">51</xref>], two in the attention network we used, can achieve higher compositional complexity that adds flexibility without losing insight.</p>
</sec>
<sec id="sec010" sec-type="materials|methods">
<title>Methods and materials</title>
<sec id="sec011">
<title>Data and code availability</title>
<p>60- and 100-fish as well as the new 80-fish videos can be found at <ext-link ext-link-type="uri" xlink:href="https://idtracker.ai" xlink:type="simple">https://idtracker.ai</ext-link>. Code used in this study is free and open-source and may be used to study interactions in any animal species or other agents (<ext-link ext-link-type="uri" xlink:href="https://gitlab.com/polavieja_lab/fishandra" xlink:type="simple">https://gitlab.com/polavieja_lab/fishandra</ext-link>).</p>
</sec>
<sec id="sec012">
<title>Ethics statement</title>
<p>We performed the experiments following the approved animal research protocol entitled ‘Decision-making in animal groups: a multidisciplinary approach to understand how social information is processed’ (CF internal reference 2015/007, DGAV reference 0421/000/0002016). The animal research protocol was approved by the Animal Welfare Body of the Champalimaud Foundation (ORBEA FC) and the Portuguese competent authority for animal welfare issues, Direcao Geral de Alimentao e Veterinaria (DGAV).</p>
</sec>
<sec id="sec013">
<title>Animal rearing and handling</title>
<p>Zebrafish, <italic>D. rerio</italic>, of the wild-type TU strain were raised by the Champalimaud Foundation Fish Platform, according to methods in [<xref ref-type="bibr" rid="pcbi.1007354.ref052">52</xref>]. Handling procedures were as in [<xref ref-type="bibr" rid="pcbi.1007354.ref021">21</xref>]. We used juveniles of 31-33 days post fertilization (a body length of 16 mm, subtending ∼ 80 px in the videos).</p>
</sec>
<sec id="sec014">
<title>Videos and tracking</title>
<p>We used 6 10-minute videos of 60 and 100 freely swimming juvenile zebrafish from [<xref ref-type="bibr" rid="pcbi.1007354.ref021">21</xref>], and 3 new 10-minute videos of 80 juveniles. The camera had a frame rate of 32 fps and 20 Mpx of definition. We obtained all the fish trajectories using <italic>idtracker.ai</italic> with an accuracy of 99.95 (mean) ±0.01% (std) [<xref ref-type="bibr" rid="pcbi.1007354.ref021">21</xref>].</p>
</sec>
<sec id="sec015">
<title>Preprocessing</title>
<p>We interpolated linearly the very small holes in the tracked trajectories (0.027% for 100-fish videos). We normalized trajectories, by translation (center of arena to (0,0)) and scaling (radius of the arena to 1). To reduce noise while preventing contamination by any future information, we smoothed the trajectories using a 5-frame half-Gaussian kernel with <italic>σ</italic> = 1 frame. We obtained velocity and acceleration by finite differences, using only current and past frames. To avoid direct border effects, we removed datapoints where the focal fish is further away from the center than 80% of the radius. Each video was divided in three parts, to obtain the training, validation and test datasets (97%/2%/1%). Sometimes we use one such division, and often we use three with validation and test covering different parts of the video.</p>
<p>In each video frame, for each individual, we found the <italic>n</italic> nearest neighbours (<inline-formula id="pcbi.1007354.e006"><alternatives><graphic id="pcbi.1007354.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mi mathvariant="script">I</mml:mi></mml:math></alternatives></inline-formula>). We then obtained (i) velocity and acceleration of the focal fish, (ii) relative position, absolute velocity and absolute acceleration of the closest <italic>n</italic> neighbours, (iii) whether the focal fish has turned right or left after <italic>N</italic><sub><italic>f</italic></sub> frames in the future.</p>
<p>Shuffled trajectories were obtained by shifting in time the trajectories of each individual, before finding the <italic>n</italic> closest neighbours. Each individual was shifted by a different multiple of the number of frames in the video divided by the number of individuals. In 10-minute videos of 100 individuals this strategy guarantees a minimum shift of 6 s and an average shift of 150 s. Properties of the focal fish (speed, acceleration) are not affected by this shuffling.</p>
</sec>
<sec id="sec016">
<title>Deep networks</title>
<p>We implemented the Deep Networks using Keras [<xref ref-type="bibr" rid="pcbi.1007354.ref053">53</xref>] through its Python API and with TensorFlow backend [<xref ref-type="bibr" rid="pcbi.1007354.ref054">54</xref>]. We solved the following classification task: Given dynamical properties of a focal fish and its <italic>n</italic> closest neighbours, does the focal fish turn right or left after 1s? Asocial information is the set of speed and normal and tangential acceleration of the focal,
<disp-formula id="pcbi.1007354.e007"><alternatives><graphic id="pcbi.1007354.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e007" xlink:type="simple"/><mml:math display="block" id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>α</mml:mi> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mi>v</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mo>⊥</mml:mo></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mo>‖</mml:mo></mml:msub> <mml:mo>…</mml:mo> <mml:mo>}</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
Social information from a neighbour <italic>i</italic> is its location, velocity and acceleration
<disp-formula id="pcbi.1007354.e008"><alternatives><graphic id="pcbi.1007354.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e008" xlink:type="simple"/><mml:math display="block" id="M8"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mrow><mml:mi mathvariant="normal">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mrow><mml:mi mathvariant="normal">y</mml:mi> <mml:mo>,</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
whose coordinates we calculate in an instantaneous frame of reference that is not moving, which is centered in the focal fish and whose y-axis is co-lineal with the focal fish velocity. Note that <italic>v</italic><sub><italic>i</italic></sub> is the absolute speed, while (<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>) is the relative position of the neighbour, rotated to the frame of reference. In each network, we first obtain the logits <italic>z</italic>, and then the probabilities by using a logistic function <italic>p</italic> = 1/(1 + <italic>e</italic><sup>−<italic>z</italic></sup>).</p>
<sec id="sec017">
<title>Interaction network</title>
<p>In the interaction network [<xref ref-type="bibr" rid="pcbi.1007354.ref026">26</xref>], given asocial (<italic>α</italic>) and social (<inline-formula id="pcbi.1007354.e009"><alternatives><graphic id="pcbi.1007354.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>i</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">I</mml:mi> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>) information, the logit of turning right is calculated as
<disp-formula id="pcbi.1007354.e010"><alternatives><graphic id="pcbi.1007354.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e010" xlink:type="simple"/><mml:math display="block" id="M10"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>z</mml:mi> <mml:mo>=</mml:mo> <mml:mi>I</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>Γ</mml:mo> <mml:mo>(</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">I</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mo>Π</mml:mo> <mml:mi mathvariant="normal">I</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
The function Π<sub>I</sub> is the pair-interaction subnetwork. We modelled it using a fully-connected network with 3 hidden layers of 128 neurons each, plus a readout layer of 128 neurons. There are rectified linear unit (ReLU, [<xref ref-type="bibr" rid="pcbi.1007354.ref055">55</xref>]) nonlinearities after each hidden layer (but not after the readout). The outputs of Π<sub>I</sub> for different neighbours are summed together and transformed by a second function, Γ. We modelled Γ as a fully-connected layer with one hidden layer of 128 neurons, plus a one-neuron readout layer. There are ReLU nonlinearities preceding the whole network and after each hidden layer (but not after the one-neuron readout layer).</p>
<p>To effectively multiply available data by <italic>n</italic>, we considered all neighbours to be equal. Equivalently, there is symmetry with respect to exchange of neighbour labels. We did not observe any turning side preference. Therefore, to effectively multiply available data by 2, we forced the network to be antisymmetrical with respect to a reflection along the body axis by antisymmetrization of <italic>I</italic>,
<disp-formula id="pcbi.1007354.e011"><alternatives><graphic id="pcbi.1007354.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e011" xlink:type="simple"/><mml:math display="block" id="M11"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>z</mml:mi> <mml:mo>=</mml:mo> <mml:mi>I</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi>I</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>α</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
where the star superscript represents a reflection along the longitudinal axis of the body, calculated by switching the sign of all <italic>x</italic> components.</p>
</sec>
<sec id="sec018">
<title>Attention network</title>
<p>
<xref ref-type="disp-formula" rid="pcbi.1007354.e002">Eq (2)</xref> can be rewritten using a notation that compares directly with <xref ref-type="disp-formula" rid="pcbi.1007354.e010">Eq (7)</xref> as
<disp-formula id="pcbi.1007354.e012"><alternatives><graphic id="pcbi.1007354.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>z</mml:mi> <mml:mo>=</mml:mo> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">I</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mo>Π</mml:mo> <mml:mi mathvariant="normal">A</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mfrac><mml:mrow><mml:mi>W</mml:mi> <mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:msub> <mml:mi>W</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>α</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
The function Π<sub>A</sub> captures the effect of pairwise interactions. It has the same structure as Π<sub>I</sub> except that its readout layer has only one neuron, and that we anti-symmetrise it. <italic>W</italic> is an attention layer, weighting the logits of the different neighbours. <italic>W</italic> has the same structure as Π<sub>A</sub>, except that it accepts as input a y-axis-reflection-invariant subset of the asocial and social variables, and that there is an exponential function after the single-neuron readout signal.</p>
</sec>
<sec id="sec019">
<title>Loss</title>
<p>Following standard procedures in binary classification, when training the network to estimate the probability <italic>p</italic><sub><italic>i</italic></sub> of turning right, we minimised the cross-entropy loss, [<xref ref-type="bibr" rid="pcbi.1007354.ref055">55</xref>]
<disp-formula id="pcbi.1007354.e013"><alternatives><graphic id="pcbi.1007354.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e013" xlink:type="simple"/><mml:math display="block" id="M13"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="script">L</mml:mi> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>N</mml:mi> <mml:mi>b</mml:mi></mml:msub></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mi>b</mml:mi></mml:msub></mml:munderover> <mml:mo form="prefix">log</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>p</mml:mi> <mml:mi>i</mml:mi> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
summed along <italic>N</italic><sub><italic>b</italic></sub> data points in the minibatch and where <inline-formula id="pcbi.1007354.e014"><alternatives><graphic id="pcbi.1007354.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:msubsup><mml:mi>p</mml:mi> <mml:mi>i</mml:mi> <mml:mo>*</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> is the probability given by the network to the actual turn. When the network predicts a right turn with probability <italic>p</italic><sub><italic>i</italic></sub>, <inline-formula id="pcbi.1007354.e015"><alternatives><graphic id="pcbi.1007354.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi> <mml:mi>i</mml:mi> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> if the actual turn was to the right, and <inline-formula id="pcbi.1007354.e016"><alternatives><graphic id="pcbi.1007354.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi> <mml:mi>i</mml:mi> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> if the actual turn was to the left. We minimise loss using Adam [<xref ref-type="bibr" rid="pcbi.1007354.ref055">55</xref>]. We stopped training if validation loss did not reach a new minimum for 10 epochs and did increase 25% from the current minimum, or after 100 training epochs. In the attention network, we annealed learning rate from 10<sup>−4</sup> to 10<sup>−5</sup>, using a batch size of 500. In the interaction network, we annealed learning rate from 5 × 10<sup>−5</sup> to 10<sup>−5</sup> and trained with a batch size of 200. Dropout [<xref ref-type="bibr" rid="pcbi.1007354.ref055">55</xref>] did not improve accuracy.</p>
</sec>
</sec>
<sec id="sec020">
<title>Attraction-repulsion and alignment scores</title>
<p>Attraction-repulsion score is obtained as
<disp-formula id="pcbi.1007354.e017"><alternatives><graphic id="pcbi.1007354.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e017" xlink:type="simple"/><mml:math display="block" id="M17"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>sign</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mrow><mml:msub><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>∈</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>-</mml:mo> <mml:mi>π</mml:mi> <mml:mo>,</mml:mo> <mml:mi>π</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
where 〈〉<sub><italic>θ</italic><sub><italic>i</italic></sub>∈[−<italic>π</italic>,<italic>π</italic>)</sub> indicates average over all possible relative orientation angles of the neighbour. There is attraction (repulsion) when the score is positive (negative). Alignment score is obtained as
<disp-formula id="pcbi.1007354.e018"><alternatives><graphic id="pcbi.1007354.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007354.e018" xlink:type="simple"/><mml:math display="block" id="M18"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mtext>max</mml:mtext> <mml:mrow><mml:msub><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>∈</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>-</mml:mo> <mml:mi>π</mml:mi> <mml:mo>,</mml:mo> <mml:mi>π</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder> <mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mtext>sign</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo> <mml:mrow><mml:msub><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>∈</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>-</mml:mo> <mml:mi>π</mml:mi> <mml:mo>,</mml:mo> <mml:mi>π</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder> <mml:mrow><mml:mo>{</mml:mo> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mtext>sign</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
If the logit <italic>z</italic><sub><italic>i</italic></sub> changes sign when changing the relative orientation of the neighbour <italic>θ</italic><sub><italic>i</italic></sub> we consider that point in parameter space to be in an orientation area. Otherwise, it is in an attraction or repulsion area, depending on the sign of the attraction-repulsion score.</p>
</sec>
<sec id="sec021">
<title>Simulated trajectories</title>
<p>At time step increment of 1/32 s, animals have a probability 2/3 of not changing its velocity. With probability 1/3, the animal changes the direction of its velocity (not its module: speed is constant) following rules explained in [<xref ref-type="bibr" rid="pcbi.1007354.ref004">4</xref>]. In some simulations we consider a blind angle behind the fish, and the shape, size and relative position of the different areas are changed (as explained in text and <xref ref-type="fig" rid="pcbi.1007354.g004">Fig 4</xref>). The other parameters of the model (as defined in Table 1 in [<xref ref-type="bibr" rid="pcbi.1007354.ref004">4</xref>]) and the values we chose are: number of individuals (50), turning rate (0.2 rad), speed (3 BL/s) and error (0.2 rad). All simulated agents are confined inside a circular arena of radius 25 BL, and when touching the arena border they reverse the component of the velocity perpendicular to the border. Training with simulated trajectories was performed to predict turning side after 125 ms.</p>
</sec>
</sec>
<sec id="sec022">
<title>Supporting information</title>
<supplementary-material id="pcbi.1007354.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Summary of the collective behaviour statistics for 3 videos of 10 minutes of 100 juvenile zebrafish.</title>
<p><bold>A</bold> Probability density function (pdf) of the distance to the center of the arena. The black vertical line marks the point 0.8 radius from the center; data to its right is neither used to train nor to evaluate the model to avoid direct border effects. <bold>B</bold> Polarisation, calculated locally in each frame for each focal fish and a different number of its closest neighbours, both for original and shuffled trajectories. <bold>C</bold> pdf of interindividual distances, in each frame for each fish to each of its closest neighbours. <bold>D</bold> Difference between the pdfs of relative locations of the 25 nearest neighbours in original and shuffled trajectories.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Summary of the collective behaviour statistics for 3 videos of 10 minutes of 80 juvenile zebrafish.</title>
<p>As in <xref ref-type="supplementary-material" rid="pcbi.1007354.s001">S1 Fig</xref>.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Summary of the collective behaviour statistics for 3 videos of 10 minutes of 60 juvenile zebrafish.</title>
<p>As in <xref ref-type="supplementary-material" rid="pcbi.1007354.s001">S1 Fig</xref>.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s004" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Accuracy of prediction of the turning side of the focal fish after 1 second evaluated on a held-out test data of large turns (20°-160°) as a function of number of closest neighbours.</title>
<p>One run for each network/condition. Both the interaction network (blue) and the attention network (orange) improve in accuracy with the number of neighbours, and then plateau after approx. 20 neighbours.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s005" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Accuracy of prediction of the turning side of the focal fish evaluated on held-out test data of large turns (20°-160°) for different times to prediction.</title>
<p>Mean of three runs, taking the test set at different positions of the video. The prediction from an aggregation model with 25 neighbours (blue) and from a model that is blind to any social information (black). Accuracy for immediate futures (less than 100 ms) is high for both models, because of correlations in the acceleration. Then it decreases for both models, but accuracy with 25 neighbours has a broad maximum when predicting futures between 1 and 10 s, and then slowly drops when predicting more distant futures.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s006" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s006" xlink:type="simple">
<label>S6 Fig</label>
<caption>
<title>Pair interaction and aggregation in 250 ms predictions.</title>
<p><bold>A</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A</xref>. <bold>B</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3B</xref> <bold>C</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref>. Note how high-attention areas are closer to the focal fish. <bold>D</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref>.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s007" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s007" xlink:type="simple">
<label>S7 Fig</label>
<caption>
<title>Pair interaction and aggregation in 500 ms predictions.</title>
<p><bold>A</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A</xref>. <bold>B</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3B</xref> <bold>C</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref>. <bold>D</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref>.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s008" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s008" xlink:type="simple">
<label>S8 Fig</label>
<caption>
<title>Pair interaction and aggregation in 1500 ms predictions.</title>
<p><bold>A</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A</xref>. <bold>B</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3B</xref> <bold>C</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref>. Note how high-attention areas are closer to the front. <bold>D</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref>.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s009" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s009" xlink:type="simple">
<label>S9 Fig</label>
<caption>
<title>Pair interaction and aggregation, obtained from 60-fish videos.</title>
<p><bold>A</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A</xref>. The most conspicuous difference with <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A</xref> is the weakening of anti-alignment <bold>B</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3B</xref> <bold>C</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref>. <bold>D</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref>. Note the comparatively weak attention at the back of the focal.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s010" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s010" xlink:type="simple">
<label>S10 Fig</label>
<caption>
<title>Pair interaction and aggregation, obtained from 80-fish videos.</title>
<p><bold>A</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A</xref>. The most conspicuous difference with <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3A</xref> is the weakening of anti-alignment <bold>B</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g003">Fig 3B</xref> <bold>C</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref>. <bold>D</bold> Same as <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref>.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s011" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s011" xlink:type="simple">
<label>S11 Fig</label>
<caption>
<title>Accuracy of prediction of the turning side of the focal fish after 1 second evaluated on held-out test data, as a function of turning angle.</title>
<p>Data from one single run. When using only focal variables (blue) remains low at all turning angles. Both networks integrating information from 25 neighbours, interaction (orange) and attention (green) perform better at turning angles between 40 and 100.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s012" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s012" xlink:type="simple">
<label>S12 Fig</label>
<caption>
<title>Accuracy of prediction of the turning side of the focal fish evaluated on held-out test data of large turns (20°-160°) when the interaction subnetwork of the aggregation network uses history of previous positions of focal and neighbour fish.</title>
<p>Mean of three runs, taking the test set at different positions in the video. Prediction accuracies increase when information from more frames in the past is available to the network.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s013" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s013" xlink:type="simple">
<label>S13 Fig</label>
<caption>
<title>Properties of interaction between a pair of fish in the collective when the focal fish is moving at low speed (1 BL/s).</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s014" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s014" xlink:type="simple">
<label>S14 Fig</label>
<caption>
<title>Properties of interaction between a pair of fish in the collective when the focal fish is moving at low speed (2 BL/s).</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s015" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s015" xlink:type="simple">
<label>S15 Fig</label>
<caption>
<title>Properties of interaction between a pair of fish in the collective when the focal fish is moving at low speed (4 BL/s).</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s016" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s016" xlink:type="simple">
<label>S16 Fig</label>
<caption>
<title>Properties of interaction between a pair of fish in the collective when the focal fish is moving at low speed (8 BL/s).</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s017" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s017" xlink:type="simple">
<label>S17 Fig</label>
<caption>
<title>Properties of interaction between a pair of fish in the collective when the focal fish is in the midst of a right turn.</title>
<p>Focal normal acceleration fixed to <italic>a</italic><sub>⊥</sub> = 100 BL/s<sup>2</sup>.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s018" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s018" xlink:type="simple">
<label>S18 Fig</label>
<caption>
<title>Aggregation, attraction-repulsion, and pair interaction maps for groups of 60, 80 and 100 zebrafish.</title>
<p>We show results for the network trained with the original data and the data shuffled according to Methods and Materials. Focal and neighbour speeds fixed to the median.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s019" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s019" xlink:type="simple">
<label>S19 Fig</label>
<caption>
<title>Aggregation with information about relative orientation.</title>
<p>Same as <xref ref-type="fig" rid="pcbi.1007354.g005">Fig 5</xref>, but when the aggregation subnetwork is trained with the relative orientation of the neighbour, in addition to the variables used in the main text. <bold>A</bold> The neighbour is parallel (at 0 degrees) to the focal. <bold>B</bold> The neighbour is at 45 degrees (towards the right) with the focal, <bold>C</bold> the neighbour is perpendicular (90 degrees) and pointing to the right of the focal. <bold>D</bold> The neighbour is antiparallel (180 degrees) to the focal.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s020" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s020" xlink:type="simple">
<label>S20 Fig</label>
<caption>
<title>Aggregation, attraction-repulsion, and pair interaction maps for different architectures of the attention network.</title>
<p>We show results for different number of layers in both, the pair-wise interaction subnetwork, and the aggregation subnetwork. Focal and neighbour speeds fixed to the median.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s021" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s021" xlink:type="simple">
<label>S21 Fig</label>
<caption>
<title>Aggregation, attraction-repulsion, and pair interaction maps for different architectures of the attention network.</title>
<p>We show results for different number of neurons in the layers of both, the pair-wise interaction subnetwork, and the aggregation subnetwork. Focal and neighbour speeds fixed to the median.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s022" mimetype="image/png" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s022" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Validation loss and test accuracy of prediction of the turning side of the focal fish after 1 second, changing input variables.</title>
<p>25 neighbours, interaction network, mean of three runs. In all cases, in addition to the variables mentioned in the table, we provide the relative position of the neighbour (<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>). Elsewhere in this article, we use <italic>v</italic>, <italic>a</italic><sub>⊥</sub>, <italic>v</italic><sub><italic>i</italic></sub>, <italic>θ</italic><sub><italic>i</italic></sub> and (<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>), the simplest among the sets of variables with high accuracy. Average of three runs with different train-validation-test splits.</p>
<p>(PNG)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s023" mimetype="image/png" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s023" xlink:type="simple">
<label>S2 Table</label>
<caption>
<title>Different architectures of interaction networks (number neurons of per layer × number of hidden layers).</title>
<p>Best (i.e. lowest validation loss) of at least three runs with different batch sizes, with a constant train-validation-test split.</p>
<p>(PNG)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s024" mimetype="image/png" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s024" xlink:type="simple">
<label>S3 Table</label>
<caption>
<title>Different architectures of fully connected networks (number of neurons per layer × number of hidden layers).</title>
<p>Best of at least three runs with different batch sizes with a constant train-validation-test split.</p>
<p>(PNG)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s025" mimetype="image/png" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s025" xlink:type="simple">
<label>S4 Table</label>
<caption>
<title>Validation loss and test accuracy of prediction of the turning side of the focal fish after 1 second, changing variables in the aggregation subnetwork.</title>
<p>25 neighbours, attention network, mean of three runs. Elsewhere in this article, we use <italic>v</italic>, <italic>v</italic><sub><italic>i</italic></sub> and (<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>), the simplest to plot among the two sets of four variables with lower validation loss.</p>
<p>(PNG)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007354.s026" mimetype="image/png" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007354.s026" xlink:type="simple">
<label>S5 Table</label>
<caption>
<title>Accuracy of the prediction of large turns for videos of different number of animals.</title>
<p>Accuracy of the prediction for all turns and for large turns (20°-160°) for videos of different number of animals. 25 neighbours, average of three runs.</p>
<p>(PNG)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Kristin Branson, Jimmy Liao, Richard Mann, the Collective Behavior Lab at Champalimaud and Ana Catarina Certal for animal care.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1007354.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schmidt</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lipson</surname> <given-names>H</given-names></name>. <article-title>Distilling free-form natural laws from experimental data</article-title>. <source>science</source>. <year>2009</year>;<volume>324</volume>(<issue>5923</issue>):<fpage>81</fpage>–<lpage>85</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1165893" xlink:type="simple">10.1126/science.1165893</ext-link></comment> <object-id pub-id-type="pmid">19342586</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Daniels</surname> <given-names>BC</given-names></name>, <name name-style="western"><surname>Nemenman</surname> <given-names>I</given-names></name>. <article-title>Automated adaptive inference of phenomenological dynamical models</article-title>. <source>Nature communications</source>. <year>2015</year>;<volume>6</volume>:<fpage>8133</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ncomms9133" xlink:type="simple">10.1038/ncomms9133</ext-link></comment> <object-id pub-id-type="pmid">26293508</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Vicsek</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Czirók</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ben-Jacob</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Shochet</surname> <given-names>O</given-names></name>. <article-title>Novel type of phase transition in a system of self-driven particles</article-title>. <source>Physical review letters</source>. <year>1995</year>;<volume>75</volume>(<issue>6</issue>):<fpage>1226</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevLett.75.1226" xlink:type="simple">10.1103/PhysRevLett.75.1226</ext-link></comment> <object-id pub-id-type="pmid">10060237</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Couzin</surname> <given-names>ID</given-names></name>, <name name-style="western"><surname>Krause</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>James</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ruxton</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Franks</surname> <given-names>NR</given-names></name>. <article-title>Collective memory and spatial sorting in animal groups</article-title>. <source>Journal of theoretical biology</source>. <year>2002</year>;<volume>218</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/jtbi.2002.3065" xlink:type="simple">10.1006/jtbi.2002.3065</ext-link></comment> <object-id pub-id-type="pmid">12297066</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Couzin</surname> <given-names>ID</given-names></name>, <name name-style="western"><surname>Krause</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Franks</surname> <given-names>NR</given-names></name>, <name name-style="western"><surname>Levin</surname> <given-names>SA</given-names></name>. <article-title>Effective leadership and decision-making in animal groups on the move</article-title>. <source>Nature</source>. <year>2005</year>;<volume>433</volume>(<issue>7025</issue>):<fpage>513</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature03236" xlink:type="simple">10.1038/nature03236</ext-link></comment> <object-id pub-id-type="pmid">15690039</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chaté</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Ginelli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Grégoire</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Peruani</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Raynaud</surname> <given-names>F</given-names></name>. <article-title>Modeling collective motion: variations on the Vicsek model</article-title>. <source>The European Physical Journal B</source>. <year>2008</year>;<volume>64</volume>(<issue>3-4</issue>):<fpage>451</fpage>–<lpage>456</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1140/epjb/e2008-00275-9" xlink:type="simple">10.1140/epjb/e2008-00275-9</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gautrais</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ginelli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Fournier</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Blanco</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Soria</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Chaté</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Deciphering interactions in moving animal groups</article-title>. <source>Plos computational biology</source>. <year>2012</year>;<volume>8</volume>(<issue>9</issue>):<fpage>e1002678</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002678" xlink:type="simple">10.1371/journal.pcbi.1002678</ext-link></comment> <object-id pub-id-type="pmid">23028277</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lima</surname> <given-names>SL</given-names></name>. <article-title>Back to the basics of anti-predatory vigilance: the group-size effect</article-title>. <source>Animal Behaviour</source>. <year>1995</year>;<volume>49</volume>(<issue>1</issue>):<fpage>11</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0003-3472(95)80149-9" xlink:type="simple">10.1016/0003-3472(95)80149-9</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roberts</surname> <given-names>G</given-names></name>. <article-title>Why individual vigilance declines as group size increases</article-title>. <source>Animal Behaviour</source>. <year>1996</year>;<volume>51</volume>(<issue>5</issue>):<fpage>1077</fpage>–<lpage>1086</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/anbe.1996.0109" xlink:type="simple">10.1006/anbe.1996.0109</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Conradt</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Roper</surname> <given-names>TJ</given-names></name>. <article-title>Group decision-making in animals</article-title>. <source>Nature</source>. <year>2003</year>;<volume>421</volume>(<issue>6919</issue>):<fpage>155</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature01294" xlink:type="simple">10.1038/nature01294</ext-link></comment> <object-id pub-id-type="pmid">12520299</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Marshall</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Radford</surname> <given-names>AN</given-names></name>. <article-title>Individual confidence-weighting and group decision-making</article-title>. <source>Trends in ecology &amp; evolution</source>. <year>2017</year>;<volume>32</volume>(<issue>9</issue>):<fpage>636</fpage>–<lpage>645</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tree.2017.06.004" xlink:type="simple">10.1016/j.tree.2017.06.004</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref012">
<label>12</label>
<mixed-citation publication-type="other" xlink:type="simple">De Condorcet N. Essai sur l’application de l’analyse à la probabilité des décisions rendues à la pluralité des voix. L’imprimerie royale; 1785.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ward</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Sumpter</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Couzin</surname> <given-names>ID</given-names></name>, <name name-style="western"><surname>Hart</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Krause</surname> <given-names>J</given-names></name>. <article-title>Quorum decision-making facilitates information transfer in fish shoals</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2008</year>;<volume>105</volume>(<issue>19</issue>):<fpage>6948</fpage>–<lpage>6953</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0710344105" xlink:type="simple">10.1073/pnas.0710344105</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sumpter</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Krause</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>James</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Couzin</surname> <given-names>ID</given-names></name>, <name name-style="western"><surname>Ward</surname> <given-names>AJ</given-names></name>. <article-title>Consensus decision making by fish</article-title>. <source>Current Biology</source>. <year>2008</year>;<volume>18</volume>(<issue>22</issue>):<fpage>1773</fpage>–<lpage>1777</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2008.09.064" xlink:type="simple">10.1016/j.cub.2008.09.064</ext-link></comment> <object-id pub-id-type="pmid">19013067</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pérez-Escudero</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>de Polavieja</surname> <given-names>GG</given-names></name>. <article-title>Collective animal behavior from Bayesian estimation and probability matching</article-title>. <source>PLoS computational biology</source>. <year>2011</year>;<volume>7</volume>(<issue>11</issue>):<fpage>e1002282</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002282" xlink:type="simple">10.1371/journal.pcbi.1002282</ext-link></comment> <object-id pub-id-type="pmid">22125487</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Arganda</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Pérez-Escudero</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>de Polavieja</surname> <given-names>GG</given-names></name>. <article-title>A common rule for decision making in animal collectives across species</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2012</year>;<volume>109</volume>(<issue>50</issue>):<fpage>20508</fpage>–<lpage>13</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1210664109" xlink:type="simple">10.1073/pnas.1210664109</ext-link></comment> <object-id pub-id-type="pmid">23197836</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hinz</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>de Polavieja</surname> <given-names>GG</given-names></name>. <article-title>Ontogeny of collective behavior reveals a simple attraction rule</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2017</year>;<volume>114</volume>(<issue>9</issue>):<fpage>2295</fpage>–<lpage>2300</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1616926114" xlink:type="simple">10.1073/pnas.1616926114</ext-link></comment> <object-id pub-id-type="pmid">28193864</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref018">
<label>18</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Grünwald</surname> <given-names>PD</given-names></name>. <source>The minimum description length principle</source>. <publisher-name>MIT press</publisher-name>; <year>2007</year>.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Strandburg-Peshkin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Twomey</surname> <given-names>CR</given-names></name>, <name name-style="western"><surname>Bode</surname> <given-names>NWF</given-names></name>, <name name-style="western"><surname>Kao</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Katz</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Ioannou</surname> <given-names>CC</given-names></name>, <etal>et al</etal>. <article-title>Visual sensory networks and effective information transfer in animal groups</article-title>. <source>Current Biology</source>. <year>2013</year>;<volume>23</volume>(<issue>17</issue>):<fpage>R709</fpage>–<lpage>R711</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2013.07.059" xlink:type="simple">10.1016/j.cub.2013.07.059</ext-link></comment> <object-id pub-id-type="pmid">24028946</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Harpaz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Tkačik</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Schneidman</surname> <given-names>E</given-names></name>. <article-title>Discrete modes of social information processing predict individual behavior of fish in a group</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2017</year>;<volume>114</volume>(<issue>38</issue>):<fpage>10149</fpage>–<lpage>10154</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1703817114" xlink:type="simple">10.1073/pnas.1703817114</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Romero-Ferrero</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Bergomi</surname> <given-names>MG</given-names></name>, <name name-style="western"><surname>Hinz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Heras</surname> <given-names>FJH</given-names></name>, <name name-style="western"><surname>de Polavieja</surname> <given-names>GG</given-names></name>. <article-title>idtracker.ai: Tracking all individuals in large collectives of unmarked animals</article-title>. <source>Nature Methods</source>. <year>2019</year>; <volume>16</volume>:<fpage>179</fpage>–<lpage>182</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref022">
<label>22</label>
<mixed-citation publication-type="other" xlink:type="simple">Raghu M, Poole B, Kleinberg J, Ganguli S, Sohl-Dickstein J. On the expressive power of deep neural networks. arXiv preprint arXiv:160605336. 2016.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref023">
<label>23</label>
<mixed-citation publication-type="other" xlink:type="simple">Bahdanau D, Cho K, Bengio Y. Neural Machine Translation by Jointly Learning to Align and Translate. arXiv preprint. 2014;abs/1409.0473.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref024">
<label>24</label>
<mixed-citation publication-type="other" xlink:type="simple">Xu K, Ba J, Kiros R, Cho K, Courville AC, Salakhutdinov R, et al. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. arXiv preprint. 2015;abs/1502.03044.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref025">
<label>25</label>
<mixed-citation publication-type="other" xlink:type="simple">Hoshen Y. Vain: Attentional multi-agent predictive modeling. In: Advances in Neural Information Processing Systems; 2017. p. 2701–2711.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref026">
<label>26</label>
<mixed-citation publication-type="other" xlink:type="simple">Battaglia PW, Pascanu R, Lai M, Rezende DJ, Kavukcuoglu K. Interaction Networks for Learning about Objects, Relations and Physics. arXiv preprint. 2016;abs/1612.00222.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Huth</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Wissel</surname> <given-names>C</given-names></name>. <article-title>The simulation of the movement of fish schools</article-title>. <source>Journal of theoretical biology</source>. <year>1992</year>;<volume>156</volume>(<issue>3</issue>):<fpage>365</fpage>–<lpage>385</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0022-5193(05)80681-2" xlink:type="simple">10.1016/S0022-5193(05)80681-2</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bode</surname> <given-names>NW</given-names></name>, <name name-style="western"><surname>Franks</surname> <given-names>DW</given-names></name>, <name name-style="western"><surname>Wood</surname> <given-names>AJ</given-names></name>. <article-title>Limited interactions in flocks: relating model simulations to empirical data</article-title>. <source>Journal of The Royal Society Interface</source>. <year>2010</year>;<volume>8</volume>(<issue>55</issue>):<fpage>301</fpage>–<lpage>304</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rsif.2010.0397" xlink:type="simple">10.1098/rsif.2010.0397</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Collignon</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Séguret</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Halloy</surname> <given-names>J</given-names></name>. <article-title>A stochastic vision-based model inspired by zebrafish collective behaviour in heterogeneous environments</article-title>. <source>Royal Society open science</source>. <year>2016</year>;<volume>3</volume>(<issue>1</issue>):<fpage>150473</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rsos.150473" xlink:type="simple">10.1098/rsos.150473</ext-link></comment> <object-id pub-id-type="pmid">26909173</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Calovi</surname> <given-names>DS</given-names></name>, <name name-style="western"><surname>Litchinko</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Lecheval</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Lopez</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Escudero</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Chaté</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Disentangling and modeling interactions in fish with burst-and-coast swimming reveal distinct alignment and attraction behaviors</article-title>. <source>PLoS computational biology</source>. <year>2018</year>;<volume>14</volume>(<issue>1</issue>):<fpage>e1005933</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005933" xlink:type="simple">10.1371/journal.pcbi.1005933</ext-link></comment> <object-id pub-id-type="pmid">29324853</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Aoki</surname></name>. <article-title>A simulation study on the schooling mechanism in fish</article-title>. <source>Bull Japan Soc Sci Fisheries</source>. <year>1982</year>;<volume>48</volume>(<issue>8</issue>):<fpage>1081</fpage>–<lpage>1088</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2331/suisan.48.1081" xlink:type="simple">10.2331/suisan.48.1081</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jiang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Giuggioli</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Perna</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Escobedo</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Lecheval</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Sire</surname> <given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Identifying influential neighbors in animal flocking</article-title>. <source>PLoS Computational Biology</source>. <year>2017</year>;<volume>13</volume>(<issue>11</issue>):<fpage>e1005822</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005822" xlink:type="simple">10.1371/journal.pcbi.1005822</ext-link></comment> <object-id pub-id-type="pmid">29161269</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref033">
<label>33</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>MacKay</surname> <given-names>DJ</given-names></name>. <source>Information theory, inference and learning algorithms</source>. <publisher-name>Cambridge university press</publisher-name>; <year>2003</year>.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref034">
<label>34</label>
<mixed-citation publication-type="other" xlink:type="simple">Eyjolfsdottir E, Branson K, Yue Y, Perona P. Learning recurrent representations for hierarchical behavior modeling. arXiv preprint arXiv:161100094. 2016.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref035">
<label>35</label>
<mixed-citation publication-type="other" xlink:type="simple">Bartoli F, Lisanti G, Ballan L, Del Bimbo A. Context-aware trajectory prediction. arXiv preprint arXiv:170502503. 2017.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Herbert-Read</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Perna</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Mann</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Schaerf</surname> <given-names>TM</given-names></name>, <name name-style="western"><surname>Sumpter</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Ward</surname> <given-names>AJ</given-names></name>. <article-title>Inferring the rules of interaction of shoaling fish</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2011</year>;<volume>108</volume>(<issue>46</issue>):<fpage>18726</fpage>–<lpage>18731</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1109355108" xlink:type="simple">10.1073/pnas.1109355108</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lemasson</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Goodwin</surname> <given-names>R</given-names></name>. <article-title>Collective motion in animal groups from a neurobiological perspective: the adaptive benefits of dynamic sensory loads and selective attention</article-title>. <source>Journal of theoretical biology</source>. <year>2009</year>;<volume>261</volume>(<issue>4</issue>):<fpage>501</fpage>–<lpage>510</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jtbi.2009.08.013" xlink:type="simple">10.1016/j.jtbi.2009.08.013</ext-link></comment> <object-id pub-id-type="pmid">19699212</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lemasson</surname> <given-names>BH</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Goodwin</surname> <given-names>RA</given-names></name>. <article-title>Motion-guided attention promotes adaptive communications during social navigation</article-title>. <source>Proceedings of the Royal Society B: Biological Sciences</source>. <year>2013</year>;<volume>280</volume>(<issue>1754</issue>):<fpage>20122003</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rspb.2012.2003" xlink:type="simple">10.1098/rspb.2012.2003</ext-link></comment> <object-id pub-id-type="pmid">23325772</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ballerini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Cabibbo</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Candelier</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Cavagna</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Cisbani</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Giardina</surname> <given-names>I</given-names></name>, <etal>et al</etal>. <article-title>Interaction ruling animal collective behavior depends on topological rather than metric distance: Evidence from a field study</article-title>. <source>Proceedings of the national academy of sciences</source>. <year>2008</year>;<volume>105</volume>(<issue>4</issue>):<fpage>1232</fpage>–<lpage>1237</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0711437105" xlink:type="simple">10.1073/pnas.0711437105</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Katz</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Tunstrom</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Ioannou</surname> <given-names>CC</given-names></name>, <name name-style="western"><surname>Huepe</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Couzin</surname> <given-names>ID</given-names></name>. <article-title>Inferring the structure and dynamics of interactions in schooling fish</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2011</year>;<volume>108</volume>(<issue>46</issue>):<fpage>18720</fpage>–<lpage>18725</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1107583108" xlink:type="simple">10.1073/pnas.1107583108</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Vicsek</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Zafeiris</surname> <given-names>A</given-names></name>. <article-title>Collective motion</article-title>. <source>Physics Reports</source>. <year>2012</year>;<volume>517</volume>(<issue>3-4</issue>):<fpage>71</fpage>–<lpage>140</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.physrep.2012.03.004" xlink:type="simple">10.1016/j.physrep.2012.03.004</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kao</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Torney</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Hartnett</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Couzin</surname> <given-names>ID</given-names></name>. <article-title>Collective learning and optimal consensus decisions in social animal groups</article-title>. <source>PLoS computational biology</source>. <year>2014</year>;<volume>10</volume>(<issue>8</issue>):<fpage>e1003762</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003762" xlink:type="simple">10.1371/journal.pcbi.1003762</ext-link></comment> <object-id pub-id-type="pmid">25101642</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Laan</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Madirolas</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>de Polavieja</surname> <given-names>GG</given-names></name>. <article-title>Rescuing Collective Wisdom when the Average Group Opinion Is Wrong</article-title>. <source>Frontiers in Robotics and AI</source>. <year>2017</year>;<volume>4</volume>:<fpage>56</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/frobt.2017.00056" xlink:type="simple">10.3389/frobt.2017.00056</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zhu</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Narita</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Bundschuh</surname> <given-names>ST</given-names></name>, <name name-style="western"><surname>Fajardo</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Zhang Schärer</surname> <given-names>YP</given-names></name>, <name name-style="western"><surname>Chattopadhyaya</surname> <given-names>B</given-names></name>, <etal>et al</etal>. <article-title>Optogenetic dissection of neuronal circuits in zebrafish using viral gene transfer and the Tet system</article-title>. <source>Frontiers in neural circuits</source>. <year>2009</year>;<volume>3</volume>:<fpage>21</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/neuro.04.021.2009" xlink:type="simple">10.3389/neuro.04.021.2009</ext-link></comment> <object-id pub-id-type="pmid">20126518</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kim</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Marques</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Grama</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hildebrand</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Gu</surname> <given-names>W</given-names></name>, <etal>et al</etal>. <article-title>Pan-neuronal calcium imaging with cellular resolution in freely swimming zebrafish</article-title>. <source>Nature methods</source>. <year>2017</year>;<volume>14</volume>(<issue>11</issue>):<fpage>1107</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nmeth.4429" xlink:type="simple">10.1038/nmeth.4429</ext-link></comment> <object-id pub-id-type="pmid">28892088</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref046">
<label>46</label>
<mixed-citation publication-type="other" xlink:type="simple">Nakajima M, Uchida S, Mori A, Kurazume R, Taniguchi Ri, Hasegawa T, et al. Motion prediction based on eigen-gestures. In: Proc. of the 1st First Korea-Japan Joint Workshop on Pattern Recognition; 2006.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref047">
<label>47</label>
<mixed-citation publication-type="other" xlink:type="simple">Ciocarlie MT, Goldfeder C, Allen PK. Dimensionality reduction for hand-independent dexterous robotic grasping. In: IROS. vol. 7; 2007. p. 3270–3275.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stephens</surname> <given-names>GJ</given-names></name>, <name name-style="western"><surname>Johnson-Kerner</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Ryu</surname> <given-names>WS</given-names></name>. <article-title>Dimensionality and dynamics in the behavior of C. elegans</article-title>. <source>PLoS computational biology</source>. <year>2008</year>;<volume>4</volume>(<issue>4</issue>):<fpage>e1000028</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1000028" xlink:type="simple">10.1371/journal.pcbi.1000028</ext-link></comment> <object-id pub-id-type="pmid">18389066</object-id></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Berman</surname> <given-names>GJ</given-names></name>, <name name-style="western"><surname>Choi</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Shaevitz</surname> <given-names>JW</given-names></name>. <article-title>Mapping the stereotyped behaviour of freely moving fruit flies</article-title>. <source>Journal of The Royal Society Interface</source>. <year>2014</year>;<volume>11</volume>(<issue>99</issue>):<fpage>20140672</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rsif.2014.0672" xlink:type="simple">10.1098/rsif.2014.0672</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref050">
<label>50</label>
<mixed-citation publication-type="other" xlink:type="simple">Grosse R, Salakhutdinov RR, Freeman WT, Tenenbaum JB. Exploiting compositionality to explore a large space of model structures. arXiv preprint arXiv:12104856. 2012.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref051">
<label>51</label>
<mixed-citation publication-type="other" xlink:type="simple">Reed S, de Freitas N. Neural Programmer-Interpreters. In: International Conference on Learning Representations (ICLR); 2016. Available from: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/pdf/1511.06279v3" xlink:type="simple">http://arxiv.org/pdf/1511.06279v3</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Martins</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Monteiro</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Vito</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Weintraub</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Almeida</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Certal</surname> <given-names>AC</given-names></name>. <article-title>Toward an integrated zebrafish health management program supporting cancer and neuroscience research</article-title>. <source>Zebrafish</source>. <year>2016</year>;<volume>13</volume>(<issue>S1</issue>):<fpage>S</fpage>–<lpage>47</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1089/zeb.2015.1198" xlink:type="simple">10.1089/zeb.2015.1198</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1007354.ref053">
<label>53</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Chollet</surname> <given-names>F</given-names></name>. <source>Deep learning with python</source>. <publisher-name>Manning Publications Co</publisher-name>.; <year>2017</year>.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref054">
<label>54</label>
<mixed-citation publication-type="other" xlink:type="simple">Abadi M, Barham P, Chen J, Chen Z, Davis A, Dean J, et al. Tensorflow: a system for large-scale machine learning. In: OSDI. vol. 16; 2016. p. 265–283.</mixed-citation>
</ref>
<ref id="pcbi.1007354.ref055">
<label>55</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Goodfellow</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Courville</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>. <source>Deep learning</source>. <publisher-name>MIT press Cambridge</publisher-name>; <year>2016</year>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
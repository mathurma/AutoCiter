<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id><journal-title-group>
<journal-title>PLoS Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-13-03340</article-id>
<article-id pub-id-type="doi">10.1371/journal.pbio.1001677</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Editorial</subject></subj-group></article-categories>
<title-group>
<article-title>Expert Failure: Re-evaluating Research Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Eisen</surname><given-names>Jonathan A.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>MacCallum</surname><given-names>Catriona J.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Neylon</surname><given-names>Cameron</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>University of California Davis, Davis, California, United States of America</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Public Library of Science, Cambridge, United Kingdom</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">cmaccallum@plos.org</email></corresp>
<fn fn-type="conflict"><p>Jonathan Eisen is chair of the <italic>PLOS Biology</italic> Advisory Board. Catriona MacCallum and Cameron Neylon are employees of PLOS whose salary is supported by PLOS income derived from the publication of open-access papers.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>10</month><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>8</day><month>10</month><year>2013</year></pub-date>
<volume>11</volume>
<issue>10</issue>
<elocation-id>e1001677</elocation-id><permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Eisen et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article id="RA1" related-article-type="companion" ext-link-type="uri" vol="" page="e1001675" xlink:type="simple" xlink:href="info:doi/10.1371/journal.pbio.1001675"> <article-title>The Assessment of Science: The Relative Merits of Post-publication Review, the Impact Factor, and the Number of Citations.</article-title></related-article>
<abstract abstract-type="toc"><sec>
<title/>
<p>It is unlikely that there is any single objective measure of merit, so research assessment therefore requires new multivariate metrics that reflect the context of research, regardless of discipline.</p>
</sec></abstract>
<counts><page-count count="3"/></counts></article-meta>
</front>
<body><sec id="s1">
<title/>
<p>Funding organisations, scientists, and the general public need robust and reliable ways to evaluate the output of scientific research. In this issue of <italic>PLOS Biology</italic>, Adam Eyre-Walker and Nina Stoletzki analyse the subjective assessment and citations of more than 6,000 published papers <xref ref-type="bibr" rid="pbio.1001677-EyreWalker1">[1]</xref>. They show that expert assessors are biased by the impact factor (IF) of the journal in which the paper has been published and cannot consistently and independently judge the “merit” of a paper or predict its future impact, as measured by citations. They also show that citations themselves are not a reliable way to assess merit as they are inherently highly stochastic. In a final twist, the authors argue that the IF is probably the least-bad metric amongst the small set that they analyse, concluding that it is the best surrogate of the merit of individual papers currently available.</p>
<p>Although we disagree with some of Eyre-Walker and Stoletzki's interpretations, their study is important for two reasons: it is not only among the first to provide a quantitative assessment of the reliability of evaluating research (see also, e.g., <xref ref-type="bibr" rid="pbio.1001677-Allen1">[2]</xref>) but it also raises fundamental questions about how we currently evaluate science and how we should do so in the future.</p>
<p>Their analysis (see <xref ref-type="sec" rid="pbio-1001677-box001">Box 1</xref> for a summary) elegantly demonstrates that current research assessment practice is neither consistent nor reliable; it is both highly variable and definitely not independent of the journal. The subjective assessment of research by experts has always been considered a gold standard—an approach championed by researchers and funders alike <xref ref-type="bibr" rid="pbio.1001677-Hochberg1">[3]</xref>–<xref ref-type="bibr" rid="pbio.1001677-US1">[5]</xref>, despite its problems <xref ref-type="bibr" rid="pbio.1001677-Smith1">[6]</xref>. Yet a key conclusion of the study is that the scores of two assessors of the same paper are only very weakly correlated (<xref ref-type="sec" rid="pbio-1001677-box001">Box 1</xref>). As Eyre-Walker and Stoletzki rightly conclude, their analysis now raises serious questions about this process and, for example, the ∼£60 million investment by the UK Government into the UK Research Assessment Exercise (estimated for 2008), where the work of scientists and universities are largely judged by a panel of experts and funding allocated accordingly. Although we agree with this core conclusion and applaud the paper, we take issue with their assumption of “merit” and their subsequent argument that the IF (or any other journal metric) is the best surrogate we currently have.</p>
<boxed-text id="pbio-1001677-box001" position="float"><sec id="s1a1">
<title>Box 1. The Error of Our Ways</title>
<p>The analysis that Eyre-Walker and Stoletzki provides is clever and you should read it in full. The data on subjective assessment come from the Faculty1000 database <xref ref-type="bibr" rid="pbio.1001677-Faculty1">[26]</xref>, where published papers are rated by researchers, and from the scoring of previously published articles by a Wellcome Trust grant panel (the data are available in Dryad <xref ref-type="bibr" rid="pbio.1001677-Dryad1">[11]</xref>). All the papers assessed were published in a single year (2005) and citation counts to the papers were collated from Google Scholar <xref ref-type="bibr" rid="pbio.1001677-Google1">[27]</xref> in 2011. The five-year IFs from 2010 were used as they were over a similar timescale.</p>
<p>They reached their conclusions by partitioning the variation in the assessment scores and the number of citations that can be attributed either to “merit” or to “error” (i.e. the other possible factors that contribute to the variability). They also neatly sidestep defining merit independently, leaving it as whatever it is that makes someone score a paper highly.</p>
<p>It is already known that researchers and others rate papers more highly if they are from journals with higher IFs <xref ref-type="bibr" rid="pbio.1001677-Allen1">[2]</xref>, but Eyre-Walker and Stoletzki carefully demonstrate the extent of this and control for the inflationary effect to reveal the crux of their study—that there is a woefully small correlation (<italic>r</italic>&lt;0.2) between the different scores made by two assessors of the same paper (<italic>N</italic>&gt;1,000). Moreover, in relation to “impact,” assessment scores explain even less of the variation in citations between papers (<italic>r</italic>≤0.15). As one of the reviewers of the article, Carl Bergstrom, stated:</p>
<disp-quote>
<p>“What it shows is not that evaluators fail to predict some objective measure of merit—it isn't clear, after all, what that objective measure of merit might even be. What this paper shows is that whatever merit might be, scientists can't be doing a good job of evaluating it when they rank the importance or quality of papers. From the (lack of) correlation among assessor scores, most of the variation in ranking has to be due to ‘error’ rather than actual quality differences.”</p>
</disp-quote>
<p>But the problems are potentially more insidious than this. Citations are also inflated by the IF (though there is much more variation in citations within than between journals; see <xref ref-type="bibr" rid="pbio.1001677-EyreWalker1">[1]</xref> for their Figure 5). Once controlled for, however, the variation in citation counts <italic>per se</italic> that can't be explained by “merit” turns out to be even larger than the unexplained variance in the subjective scoring of scientists. The authors conclude that papers are therefore accumulating citations essentially by chance, a factor that helps to account for the low correlation between assessor score and citations. This also implies that we don't yet understand why some papers accumulate more citations than others, or what citation counts are telling us about individual articles in general.</p>
<p>Eyre-Walker and Stoletzki's conclusion that the IF is the best metric of the set they analyse is based purely on the fact that it is likely to have less bias or error associated with it than either subjective assessment by experts after publication or subsequent citations to individual papers. Their rationale is that IFs reflect a process whereby several individuals are involved in a decision to publish (i.e. reviewers), and simply averaging over a larger number of assessors means you end up with a stronger “signal” of merit. They also argue that because such assessment happens <italic>before</italic> publication, it is not influenced by the journal's IF. Even so, they accept that IFs will still be extremely error prone. If three reviewers contribute equally to a decision, and you assume that their ability to assess papers is no worse than those evaluating papers after publication, the variation between assessors is still much larger than any component of merit that might ultimately be manifested in the IF. This is not surprising, at least to editors, who continually have to juggle judgments based on disparate reviews.</p>
</sec></boxed-text>
<p>First, and most importantly, their analysis relies on a clever setup that purposely avoids defining what merit is (<xref ref-type="sec" rid="pbio-1001677-box001">Box 1</xref>). The lack of correlation between assessors is then interpreted as meaning that this hypothetical quantity is not being reliably measured. However, an alternative interpretation is that assessors are reliable at assessment, but are assessing <italic>different things</italic>. The lack of correlation, therefore, is a signal that “merit” is not a single measurable quantity. This is consistent with the finding that citation data are highly stochastic: the factors leading individuals to cite a paper (which the authors discuss) will also vary. Citations and subjective assessments of merit will therefore inevitably be the result of multivariate factors each with an associated variance that may act in different and nonlinear combinations—no wonder it looks like chance.</p>
<p>Second, the authors assume that the IF will be the best surrogate of merit because reviewers of papers <italic>before</italic> publication are less influenced by the journal (<xref ref-type="sec" rid="pbio-1001677-box001">Box 1</xref>). They appreciate the many problems associated with the IF (e.g. <xref ref-type="bibr" rid="pbio.1001677-The1">[7]</xref>–<xref ref-type="bibr" rid="pbio.1001677-Rossner2">[9]</xref>) and stress that it is not in any way a quantitative measure of merit. They acknowledge, for example, that an article in a journal with an IF of 30 is not 6 times better than one in an IF of 5. Yet they remain convinced that prepublication assessment of merit is the most appropriate means of assessment and that journal-level metrics, like the IF, provide the best surrogate. Because of the known biases with the IF, they suggest an alternative journal-level metric in the discussion, where journals are ranked by experts in different fields and ranks used as measure of an individual paper's merit.</p>
<p>This to us appears to contradict the central findings of the paper. It is not clear why experts should be more reliable at rating journals than rating articles. We would argue that prepublication reviewers are still influenced by the journal they are making the assessment for (e.g. potentially assessing different aspects of the work for “better” journals). Further, if our alternative interpretation of the findings is accepted, then any <italic>binary</italic> assessment (accept or reject) can only ever be a very weak indicator of the multivariate nature of a given paper's merit. Finally, as Bjoern Brembs and colleagues have argued in a recent review, given that the variance in article quality within any given journal is generally larger than any signal a quantitative journal quality measure can provide, any journal-based ranking (not just the IF) is potentially detrimental to science <xref ref-type="bibr" rid="pbio.1001677-Brembs1">[10]</xref>.</p>
<p>Indeed, any single metric that is highly variable is going to pose a problem for research assessment if we don't understand what is driving that variation. This is compounded when assessments are based on subjective opinion or other very biased measures, such as the IF. There is a sane solution, however, and that is to have a system of assessment that doesn't rely on one measure but uses a suite of metrics at the level of the article. In such a system it will also be important to enable research into new metrics of assessment. Crucial to this is the availability of data about research assessment itself. Although the Wellcome Trust and F1000 data used in this study are freely available (via Dryad <xref ref-type="bibr" rid="pbio.1001677-Dryad1">[11]</xref>), the data upon which the RAE is based in the UK (to be known as the Research Excellence Framework, REF, in the next 2014 round) are not even collated, let alone available for others to analyse (assessors are asked to destroy their own raw assessment data). Eyre-Walker and Stoletzki recommend that all submissions to the UK REF be independently assessed by two assessors and then analysed. Likewise, similar data from grant panels or tenure decisions, wherever they are based, should be archived and made available for others to mine (while ensuring appropriate levels of confidentiality about individuals).</p>
<p>It is only with the development of rich multidimensional assessment tools that we will be able to recognise and value the different contributions made by individuals, regardless of their discipline. We have sequenced the human genome, cloned sheep, sent rovers to Mars, and identified the Higgs boson (at least tentatively); it is surely not beyond our reach to make assessment useful, to recognise that different factors are important to different people and depend on research context.</p>
<p>What can realistically be done to achieve this? It doesn't need to be left to governments and funding agencies. PLOS has been at the forefront of developing new Article-Level Metrics <xref ref-type="bibr" rid="pbio.1001677-Allen2">[12]</xref>–<xref ref-type="bibr" rid="pbio.1001677-Lin1">[14]</xref>, and we encourage you to take a look at these measures not just on PLOS articles but on other publishers' sites where they are also being developed (e.g. <italic>Frontiers</italic> and <italic>Nature</italic>). Eyre-Walker and Stoletzki's study looks at only three metrics – postpublication subjective assessment, citations, and the IF. As one reviewer noted, they do not consider other article-level metrics, such as the number of views, researcher bookmarking, social media discussions, mentions in the popular press, or the actual outcomes of the work (e.g. for practice and policy). Start using these where you can (e.g. using ImpactStory <xref ref-type="bibr" rid="pbio.1001677-ImpactStory1">[15]</xref>,<xref ref-type="bibr" rid="pbio.1001677-Kwok1">[16]</xref>) and even evaluate the metrics themselves (all PLOS metric data can be downloaded).</p>
<p>You can also sign the San Francisco Declaration on Research Assessment (DORA <xref ref-type="bibr" rid="pbio.1001677-San1">[17]</xref>), which calls on funders, institutions, publishers, and researchers to stop using journal-based metrics, such as the IF, as the criteria to reach hiring, tenure, and promotion decisions, but rather to consider a broad range of impact measures that focus on the scientific content of the individual paper. You will be in good company—there were 83 original signatory organisations, including publishers (e.g. PLOS), societies such as AAAS (who publish <italic>Science</italic>), and funders such as the Wellcome Trust.</p>
<p>Initiatives like DORA, papers like Eyre-Walker and Stoletzki's, and the emerging field of “altmetrics” <xref ref-type="bibr" rid="pbio.1001677-Altmetric1">[18]</xref>–<xref ref-type="bibr" rid="pbio.1001677-Priem1">[25]</xref> will eventually shift the culture and identify multivariate metrics that are more appropriate to 21<sup>st</sup> Century science. Do what you can today; help disrupt and redesign the scientific norms around how we assess, search, and filter science.</p>
</sec></body>
<back><ref-list>
<title>References</title>
<ref id="pbio.1001677-EyreWalker1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eyre-Walker</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Stoletzki</surname><given-names>N</given-names></name> (<year>2013</year>) <article-title>The Assessment of Science: The Relative Merits of Post-publication Review, the Impact Factor, and the Number of Citations</article-title>. <source>PLOS Biol</source> <volume>11</volume> (<issue>10</issue>) <fpage>e1001675</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1001675" xlink:type="simple">10.1371/journal.pbio.1001675</ext-link></comment></mixed-citation>
</ref>
<ref id="pbio.1001677-Allen1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Allen</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Dolby</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Lynn</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Walport</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Looking for Landmarks: The Role of Expert Review and Bibliometric Analysis in Evaluating Scientific Publication Outputs</article-title>. <source>PLoS ONE</source> <volume>4</volume>: <fpage>e5910</fpage> Available: <ext-link ext-link-type="uri" xlink:href="http://dx.plos.org/10.1371/journal.pone.0005910" xlink:type="simple">http://dx.plos.org/10.1371/journal.pone.0005910</ext-link>. Accessed 26 December 2011.</mixed-citation>
</ref>
<ref id="pbio.1001677-Hochberg1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hochberg</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Good Science Depends on Good Peer-Review</article-title>. <source>Perspectives in Publishing (Blog)</source> Available: <ext-link ext-link-type="uri" xlink:href="https://sites.google.com/site/perspectivesinpublishing/our-mission" xlink:type="simple">https://sites.google.com/site/perspectivesinpublishing/our-mission</ext-link>. Accessed 22 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Corbyn1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Corbyn</surname><given-names>Z</given-names></name> (<year>18 June 2009</year>) <article-title>Hefce backs off citations in favour of peer review in REF</article-title>. <source>The Times Higher Education</source> Available: <ext-link ext-link-type="uri" xlink:href="http://www.timeshighereducation.co.uk/news/hefce-backs-off-citations-in-favour-of-peer-review-in-ref/407041.article" xlink:type="simple">http://www.timeshighereducation.co.uk/news/hefce-backs-off-citations-in-favour-of-peer-review-in-ref/407041.article</ext-link>. Accessed 22 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-US1"><label>5</label>
<mixed-citation publication-type="other" xlink:type="simple">US National Institutes of Health (page last updated on August 15, 2013) Peer Review Process. Available: <ext-link ext-link-type="uri" xlink:href="http://grants.nih.gov/grants/peer_review_process.htm" xlink:type="simple">http://grants.nih.gov/grants/peer_review_process.htm</ext-link>. Accessed 22 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Smith1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname><given-names>R</given-names></name> (<year>2006</year>) <article-title>Peer review: a flawed process at the heart of science and journals</article-title>. <source>J R Soc Med</source> <volume>99</volume>: <fpage>178</fpage>–<lpage>182</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://jrs.sagepub.com/content/99/4/178.full" xlink:type="simple">http://jrs.sagepub.com/content/99/4/178.full</ext-link>. Accessed 6 July 2009.</mixed-citation>
</ref>
<ref id="pbio.1001677-The1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><collab xlink:type="simple">The <italic>PLOS Medicine</italic> Editors</collab> (<year>2006</year>) <article-title>The Impact Factor Game</article-title>. <source>PLoS Med</source> <volume>3</volume>: <fpage>e291</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pmed.0030291" xlink:type="simple">10.1371/journal.pmed.0030291</ext-link>. Accessed 26 June 2013</comment></mixed-citation>
</ref>
<ref id="pbio.1001677-Rossner1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rossner</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Epps</surname><given-names>HV</given-names></name>, <name name-style="western"><surname>Hill</surname><given-names>E</given-names></name> (<year>2007</year>) <article-title>Show me the data</article-title>. <source>J Cell Biol</source> <volume>179</volume>: <fpage>1091</fpage>–<lpage>1092</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://jcb.rupress.org/content/179/6/1091" xlink:type="simple">http://jcb.rupress.org/content/179/6/1091</ext-link>. Accessed 8 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Rossner2"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rossner</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Van Epps</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Hill</surname><given-names>E</given-names></name> (<year>2008</year>) <article-title>Irreproducible Results—A Response to Thomson Scientific</article-title>. <source>J Gen Physiol</source> <volume>131</volume>: <fpage>183</fpage>–<lpage>184</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://jcb.rupress.org/content/179/6/1091" xlink:type="simple">http://jcb.rupress.org/content/179/6/1091</ext-link>. Accessed 8 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Brembs1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brembs</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Button</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Munafò</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Deep impact: unintended consequences of journal rank</article-title>. <source>Front Hum Neurosci</source> <volume>7</volume>: <fpage>291</fpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.frontiersin.org/Human_Neuroscience/10.3389/fnhum.2013.00291/full" xlink:type="simple">http://www.frontiersin.org/Human_Neuroscience/10.3389/fnhum.2013.00291/full</ext-link>. Accessed 26 June 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Dryad1"><label>11</label>
<mixed-citation publication-type="other" xlink:type="simple">Dryad (n.d.) Digital Data Repository. Available: <ext-link ext-link-type="uri" xlink:href="http://datadryad.org/" xlink:type="simple">http://datadryad.org/</ext-link>. Accessed 8 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Allen2"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Allen</surname><given-names>L</given-names></name> (<year>2013</year>) <article-title>Providing context to Article-Level Metrics</article-title>. <source>PLOS Blog</source> Available: <ext-link ext-link-type="uri" xlink:href="http://blogs.plos.org/plos/2013/05/providing-context-to-article-level-metrics/" xlink:type="simple">http://blogs.plos.org/plos/2013/05/providing-context-to-article-level-metrics/</ext-link>. Accessed 8 May 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Neylon1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Neylon</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>Article-Level Metrics and the Evolution of Scientific Impact</article-title>. <source>PLoS Biol</source> <volume>7</volume>: <fpage>e1000242</fpage> Available: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1000242" xlink:type="simple">http://dx.doi.org/10.1371/journal.pbio.1000242</ext-link>. Accessed 19 November 2011.</mixed-citation>
</ref>
<ref id="pbio.1001677-Lin1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lin</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Fenner</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Altmetrics in Evolution: Defining and Redefining the Ontology of Article-Level Metrics</article-title>. <source>Information Standards Quarterly</source> <volume>25</volume>: <fpage>20</fpage>–<lpage>26</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.niso.org/publications/isq/2013/v25no2/lin/" xlink:type="simple">http://www.niso.org/publications/isq/2013/v25no2/lin/</ext-link>. Accessed 15 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-ImpactStory1"><label>15</label>
<mixed-citation publication-type="other" xlink:type="simple">ImpactStory (n.d.) Share the full story of your research impact. Available: <ext-link ext-link-type="uri" xlink:href="http://impactstory.org/" xlink:type="simple">http://impactstory.org/</ext-link>. Accessed 23 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Kwok1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kwok</surname><given-names>R</given-names></name> (<year>2013</year>) <article-title>Research impact: Altmetrics make their mark</article-title>. <source>Nature</source> <volume>500</volume>: <fpage>491</fpage>–<lpage>493</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/naturejobs/science/articles/10.1038/nj7463-491a" xlink:type="simple">http://www.nature.com/naturejobs/science/articles/10.1038/nj7463-491a</ext-link>. Accessed 22 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-San1"><label>17</label>
<mixed-citation publication-type="other" xlink:type="simple">San Francisco Declaration on Research Assessment (DORA) (n.d.). Available: <ext-link ext-link-type="uri" xlink:href="http://am.ascb.org/dora/" xlink:type="simple">http://am.ascb.org/dora/</ext-link>. Accessed 26 June 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Altmetric1"><label>18</label>
<mixed-citation publication-type="other" xlink:type="simple">Altmetric (n.d.) Company website. Available: <ext-link ext-link-type="uri" xlink:href="http://www.altmetric.com/" xlink:type="simple">http://www.altmetric.com/</ext-link>. Accessed 26 June 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Galligan1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Galligan</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Dyas-Correia</surname><given-names>S</given-names></name> (<year>2013</year>) <article-title>Altmetrics: Rethinking the Way We Measure</article-title>. <source>Ser Rev</source> <volume>39</volume>: <fpage>56</fpage>–<lpage>61</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://linkinghub.elsevier.com/retrieve/pii/S009879131300004X" xlink:type="simple">http://linkinghub.elsevier.com/retrieve/pii/S009879131300004X</ext-link>. Accessed 15 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Piwowar1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Piwowar</surname><given-names>H</given-names></name> (<year>2013</year>) <article-title>Altmetrics: Value all research products</article-title>. <source>Nature</source> <volume>493</volume>: <fpage>159</fpage>–<lpage>159</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/nature/journal/v493/n7431/full/493159a.html?WT.ec_id=NATURE-20130110" xlink:type="simple">http://www.nature.com/nature/journal/v493/n7431/full/493159a.html?WT.ec_id=NATURE-20130110</ext-link>. Accessed 10 January 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Thelwall1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thelwall</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Haustein</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Larivière</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Sugimoto</surname><given-names>CR</given-names></name> (<year>2013</year>) <article-title>Do Altmetrics Work? Twitter and Ten Other Social Web Services</article-title>. <source>PLoS ONE</source> <volume>8</volume>: <fpage>e64841</fpage> Available: <ext-link ext-link-type="uri" xlink:href="http://dx.plos.org/10.1371/journal.pone.0064841" xlink:type="simple">http://dx.plos.org/10.1371/journal.pone.0064841</ext-link>. Accessed 15 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Taylor1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Taylor</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Exploring the Boundaries: How Altmetrics Can Expand Our Vision of Scholarly Communication and Social Impact</article-title>. <source>Information Standards Quarterly</source> <volume>25</volume>: <fpage>27</fpage>–<lpage>32</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.niso.org/publications/isq/2013/v25no2/taylor/" xlink:type="simple">http://www.niso.org/publications/isq/2013/v25no2/taylor/</ext-link>. Accessed 15 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Roemer1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Roemer</surname><given-names>RC</given-names></name>, <name name-style="western"><surname>Borchardt</surname><given-names>R</given-names></name> (<year>2013</year>) <article-title>Institutional Altmetrics and Academic Libraries</article-title>. <source>Information Standards Quarterly</source> <volume>25</volume>: <fpage>14</fpage>–<lpage>19</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.niso.org/publications/isq/2013/v25no2/roemer/" xlink:type="simple">http://www.niso.org/publications/isq/2013/v25no2/roemer/</ext-link>. Accessed 15 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Konkiel1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Konkiel</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Scherer</surname><given-names>D</given-names></name> (<year>2013</year>) <article-title>New opportunities for repositories in the age of altmetrics</article-title>. <source>Bull Am Soc Inf Sci Technol</source> <volume>39</volume>: <fpage>22</fpage>–<lpage>26</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://doi.wiley.com/10.1002/bult.2013.1720390408" xlink:type="simple">http://doi.wiley.com/10.1002/bult.2013.1720390408</ext-link>. Accessed 15 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Priem1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Priem</surname><given-names>J</given-names></name> (<year>2013</year>) <article-title>Scholarship: Beyond the paper</article-title>. <source>Nature</source> <volume>495</volume>: <fpage>437</fpage>–<lpage>440</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/nature/journal/v495/n7442/full/495437a.html" xlink:type="simple">http://www.nature.com/nature/journal/v495/n7442/full/495437a.html</ext-link>. Accessed 21 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Faculty1"><label>26</label>
<mixed-citation publication-type="other" xlink:type="simple">Faculty of 1000 (n.d) F1000Prime. Available: <ext-link ext-link-type="uri" xlink:href="http://f1000.com/prime" xlink:type="simple">http://f1000.com/prime</ext-link>. Accessed 8 August 2013.</mixed-citation>
</ref>
<ref id="pbio.1001677-Google1"><label>27</label>
<mixed-citation publication-type="other" xlink:type="simple">Google Scholar (n.d.). Available: <ext-link ext-link-type="uri" xlink:href="http://scholar.google.com" xlink:type="simple">http://scholar.google.com</ext-link>. Accessed 9 August 2013.</mixed-citation>
</ref>
</ref-list></back>
</article>
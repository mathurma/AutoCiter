<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006563</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-00486</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject><subj-group><subject>Memory recall</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject><subj-group><subject>Memory recall</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Working memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Working memory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject><subj-group><subject>Working memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject><subj-group><subject>Working memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject><subj-group><subject>Eye movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Database and informatics methods</subject><subj-group><subject>Information retrieval</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject><subj-group><subject>Research validity</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Independent working memory resources for egocentric and allocentric spatial information</article-title>
<alt-title alt-title-type="running-head">Independent working memory resources for egocentric and allocentric spatial information</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0725-9448</contrib-id>
<name name-style="western">
<surname>Aagten-Murphy</surname>
<given-names>David</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4684-4893</contrib-id>
<name name-style="western">
<surname>Bays</surname>
<given-names>Paul M.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Department of Psychology, University of Cambridge, Cambridge, United Kingdom</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Boorman</surname>
<given-names>Erie</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>UC Davis, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">david.aagtenmurphy@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>21</day>
<month>2</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<month>2</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>2</issue>
<elocation-id>e1006563</elocation-id>
<history>
<date date-type="received">
<day>26</day>
<month>3</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>15</day>
<month>10</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Aagten-Murphy, Bays</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006563"/>
<abstract>
<p>Visuospatial working memory enables us to maintain access to visual information for processing even when a stimulus is no longer present, due to occlusion, our own movements, or transience of the stimulus. Here we show that, when localizing remembered stimuli, the precision of spatial recall does not rely solely on memory for individual stimuli, but additionally depends on the relative distances between stimuli and visual landmarks in the surroundings. Across three separate experiments, we consistently observed a spatially selective improvement in the precision of recall for items located near a persistent landmark. While the results did not require that the landmark be visible throughout the memory delay period, it was essential that it was visible both during encoding and response. We present a simple model that can accurately capture human performance by considering relative (allocentric) spatial information as an independent localization estimate which degrades with distance and is optimally integrated with egocentric spatial information. Critically, allocentric information was encoded without cost to egocentric estimation, demonstrating independent storage of the two sources of information. Finally, when egocentric and allocentric estimates were put in conflict, the model successfully predicted the resulting localization errors. We suggest that the relative distance between stimuli represents an additional, independent spatial cue for memory recall. This cue information is likely to be critical for spatial localization in natural settings which contain an abundance of visual landmarks.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Human capacity to maintain spatial information over brief interruptions is strongly limited. However, while studies of visual working memory typically examine recall in sparse displays, consisting only of the stimuli to remember, natural scenes are commonly filled with other objects that—although not required to be remembered—may nevertheless influence subsequent localization. We demonstrate that memory for spatial location depends on independent stores for egocentric (relative to the observer) and allocentric (relative to other stimuli) information about object position. Both types of spatial representation become increasingly imprecise as the number of objects in memory increases. However, even when visual landmarks are present—and allocentric information encoded—there is no change in egocentric precision. This suggests that the encoding of additional allocentric spatial information does not compete for working memory resources with egocentric spatial information. Additionally, the fidelity of allocentric position information diminished rapidly with distance, resulting in a spatially specific advantage for recall of objects in the vicinity of stable landmarks. The effect of a landmark on recall matches that of an ideal observer who optimally combines egocentric and allocentric cues. This work provides a new experimental and theoretical framework for the investigation of spatial memory mechanisms.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4684-4893</contrib-id>
<name name-style="western">
<surname>Bays</surname>
<given-names>Paul M.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This research was supported by the Wellcome Trust (grant number 106926 to PMB). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="4"/>
<table-count count="0"/>
<page-count count="20"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-03-05</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All data has been made available on the Open Science Framework at <ext-link ext-link-type="uri" xlink:href="https://osf.io/gzkcm/" xlink:type="simple">https://osf.io/gzkcm/</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Imagine trying to locate your friends while watching a crowded street parade. If you catch only a glimpse of them in the crowd before they are obscured by others, remembering how far they were from a nearby building (a stable landmark in the external world) may provide a useful cue to help you localize them later. Indeed, this relative (or allocentric) information may prove more valuable than memory of their location within your visual field (egocentric information). However, the nature of storage of allocentric information, and its interaction with other forms of visual memory, have not been clearly established.</p>
<p>Interruptions in sensory input represent a frequent challenge to the visual system, whether due to our own actions, such as an eye-movement or blink, or changes in the external world, such as object occlusions or the disappearance of a transient stimulus. Visuospatial working memory (VSWM) helps bridge these discontinuities, by allowing us to retain sensory information about visual objects even when they are no longer visible. However, the capacity of VSWM to store information is limited. Even when explicitly instructed to remember specific stimuli—in anticipation of an interruption—individuals make substantial errors in both their ability to detect the occurrence of a change [<xref ref-type="bibr" rid="pcbi.1006563.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref003">3</xref>] and to reproduce remembered features [<xref ref-type="bibr" rid="pcbi.1006563.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref005">5</xref>]. Error increases monotonically as the number of items increases, and this holds true for recall of object locations as well as features [<xref ref-type="bibr" rid="pcbi.1006563.ref006">6</xref>]. This is consistent with models in which objects compete for allocation of a limited representational resource [<xref ref-type="bibr" rid="pcbi.1006563.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref009">9</xref>].</p>
<p>Representations of visual information in early visual cortex are inherently egocentric, emerging directly from the projection of the external world onto the retina. Consequently, the spatial information associated with visual processing is at least initially gaze-centered, encoding locations relative to the observer, and decreasing in resolution as the distance from the fovea increases [<xref ref-type="bibr" rid="pcbi.1006563.ref010">10</xref>]. This retinotopic spatial encoding appears to be preserved throughout much of the brain, particularly in dorsal brain regions that support the execution of actions towards remembered locations [<xref ref-type="bibr" rid="pcbi.1006563.ref011">11</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref012">12</xref>] (but see [<xref ref-type="bibr" rid="pcbi.1006563.ref013">13</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref014">14</xref>] with respect to ventral areas). Indeed, it is actively debated whether spatial information is ever encoded in non-retinotopic reference frames [<xref ref-type="bibr" rid="pcbi.1006563.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref018">18</xref>]. The point of contention is whether separable representations of stimuli are encoded—within distinct neural populations and potentially within different neural pathways—or if the apparent use of other representations merely reflects timely manipulations of egocentric information [<xref ref-type="bibr" rid="pcbi.1006563.ref016">16</xref>]. Important evidence has come from studies of motor action, which have shown that movement errors are reduced in the presence of visual landmarks, and suggested motor programming reflects the combination of egocentric (retinotopically encoded relative to current gaze) and allocentric (relative to external landmarks) spatial cues [<xref ref-type="bibr" rid="pcbi.1006563.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref021">21</xref>].</p>
<p>In this paper we investigate how egocentric and allocentric VSWM representations interact. Specifically, in view of the limited capacity of VSWM, we examine the impact of encoding additional allocentric spatial information in the form of distance from a visual landmark. We show that the behavioral data is consistent with an optimal integration of an egocentric signal, independent of the landmark, with an allocentric signal that degrades with distance from the landmark. We further show that allocentric information does not compete with egocentric information for storage, indicating that the two sources of information rely on independent memory resources.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>A stable landmark enhances spatial working memory precision</title>
<p>In Experiment 1 we investigated the influence of a visual landmark on spatial working memory for different numbers of remembered objects (set size: 1, 2 or 4). Participants used a computer mouse to report the remembered location of one item from a memory array, identified by color (<xref ref-type="fig" rid="pcbi.1006563.g001">Fig 1A</xref>). Examining spatial recall precision in the absence (LM-ABSENT) and presence (LM-PRESENT) of a stable visual landmark, we observed a substantial reduction in the variability of memory reproduction for stimuli located near the landmark, at all set sizes (<xref ref-type="fig" rid="pcbi.1006563.g001">Fig 1B–1D</xref>). These changes occurred in the absence of systematic shifts in bias (<xref ref-type="supplementary-material" rid="pcbi.1006563.s005">S3 Fig</xref>) and indicate that the presence of the landmark gave participants access to additional information to facilitate recall.</p>
<fig id="pcbi.1006563.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006563.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Experiment one.</title>
<p><bold>(A)</bold> LM-PRESENT design. Participants memorized the locations of colored disks in the presence of a landmark (a larger dark gray disk; note object sizes are exaggerated for visibility). <bold>(B-D)</bold> Data points indicate mean variability in location recall for set sizes 1, 2 and 4 respectively, with predictions of the optimal integration model overlaid (colored lines). Note the model captures both the reduction in variability near the landmark, and the plateau in variability at far landmark-target separations. LM-PRESENT data is shown in red, LM-ABSENT in blue. Errorbars and patches indicate 95% CI. Gray dots indicate size of the landmark on the x-axis scale. <bold>(E-H)</bold> Box plots depicting parameter estimates for the best-fitting model (notch represents 95% confidence interval on the median). Note the decrease in egocentric precision (E), decrease in allocentric precision (F) and increase in lapse rate (H) associated with increasing set size, while the best-fitting model exhibited no changes in the allocentric scale (rate of decay with distance), which is therefore estimated by a single parameter (G).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006563.g001" xlink:type="simple"/>
</fig>
<p>We implemented a simple cue-combination model to investigate whether this spatially selective improvement in precision could be captured by optimal integration of independent <italic>egocentric</italic> and <italic>allocentric</italic> spatial encodings (<xref ref-type="fig" rid="pcbi.1006563.g002">Fig 2</xref>; see <xref ref-type="sec" rid="sec008">Methods</xref>). In the model, the precision of the allocentric signal diminishes with distance to the landmark from a peak A<sub><italic>max</italic></sub> at rate A<sub><italic>scale</italic></sub>, while precision of the egocentric signal is independent of distance. The model also includes a lapse rate to capture random responding and “swap” errors [<xref ref-type="bibr" rid="pcbi.1006563.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref009">9</xref>]. The fit of the optimal integration model is shown as solid lines in <xref ref-type="fig" rid="pcbi.1006563.g001">Fig 1B–1D</xref>. This model provided a substantially better fit to data than a reduced model with allocentric encoding omitted (ΔAICc = 662).</p>
<fig id="pcbi.1006563.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006563.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Ideal observer model.</title>
<p><bold>(A)</bold> The visual working memory decoding model, in which egocentric and allocentric estimates are integrated depending on their respective reliabilities. While precision of the egocentric component is set by <italic>P</italic><sub><italic>ego</italic></sub>, the allocentric precision is determined by two parameters: the peak precision obtained when landmark and target are aligned (<italic>A</italic><sub><italic>max</italic></sub>), and a scale parameter describing how quickly allocentric precision declines with increasing landmark-target distance (<italic>A</italic><sub><italic>scale</italic></sub>). The model further incorporates a fixed probability of lapsing (<italic>p(lapse);</italic> responding at random relative to the target), giving four free parameters in total. <bold>(B)</bold> Precision of egocentric (blue) and allocentric (green) estimates shown as a function of distance from the landmark. While egocentric precision is constant, the precision of allocentric information decreases exponentially as the distance increases. The precision of the integrated estimate (red) is equal to the sum of precisions of the individual components.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006563.g002" xlink:type="simple"/>
</fig>
<p>Consistent with previous studies [<xref ref-type="bibr" rid="pcbi.1006563.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref005">5</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref022">22</xref>], the precision of the egocentric signal declined with increasing set size (<xref ref-type="fig" rid="pcbi.1006563.g001">Fig 1E</xref>; comparison to model with fixed precision: ΔAICc = 234; linear regression slope = –18.4 ± 2.7 (M ± SE), t(11) = 6.89, p &lt; 0.001). Similarly, model comparison indicated a decrease in peak precision of the allocentric signal with set size (<xref ref-type="fig" rid="pcbi.1006563.g001">Fig 1F</xref>; ΔAICc = 45.94; linear regression slope = -461 ± 78; t(11) = 5.88; p &lt; 0.001). There were no changes across set size in the rate with which precision of the allocentric signal scaled with distance (<xref ref-type="fig" rid="pcbi.1006563.g001">Fig 1G</xref>; ΔAICc = 18.45). The lapse rate increased with set size but accounted for only a very small fraction of trials (<xref ref-type="fig" rid="pcbi.1006563.g001">Fig 1H</xref>; ΔAICc = 139; slope = 0.014 ± 0.003; t(11) = 4.48; p &lt; 0.001).</p>
</sec>
<sec id="sec004">
<title>Independence of egocentric and allocentric stores</title>
<p>The presence of a visual landmark substantially improved the localization of memory stimuli in the landmark’s vicinity, implying that participants remembered the allocentric distance between the landmark and each memory stimulus, in addition to the egocentric location of each stimulus. In previous studies, increasing the amount of information stored in working memory has consistently been shown to decrease the precision of recall, consistent with distribution of a limited memory resource between items to be remembered [<xref ref-type="bibr" rid="pcbi.1006563.ref007">7</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref009">9</xref>]. If egocentric and allocentric encodings of location similarly share memory resources, the additional inclusion of relative information should convey a cost in the form of decreased precision of egocentric information. However, we found no evidence for such a cost, as can be seen qualitatively in <xref ref-type="fig" rid="pcbi.1006563.g001">Fig 1A–1C</xref> by comparing LM-PRESENT performance at 180° separation to LM-ABSENT performance. Were there a cost in the fidelity of egocentric information associated with encoding allocentric information, then localization of targets far from the landmark (where allocentric information should make a negligible contribution to response precision) would be noticeably more variable than in the absence of a landmark. A model in which egocentric precision decreased in the presence of a landmark (see <xref ref-type="sec" rid="sec008">Methods</xref>) provided a substantially worse description of the data (ΔAICc = 53.65), confirming that memory resources for egocentric and allocentric information are independent. The distribution of individual parameter values obtained for the rejected model (in this and subsequent experiments) was also inconsistent with a cost to egocentric precision (see <xref ref-type="supplementary-material" rid="pcbi.1006563.s004">S2 Text and S2 Fig</xref>).</p>
</sec>
<sec id="sec005">
<title>Landmark persistence</title>
<p>A plausible alternative account of the landmark effect is that the presence of the salient landmark in the initial array biased encoding towards memoranda in its vicinity. In Experiment 2 we tested a condition (LM-ENCODE) in which the landmark was visible only during the presentation of the memory array (set size 4). This condition was interleaved with other conditions such that participants did not know during encoding whether the landmark would disappear. We observed no landmark-related improvement of precision in this condition (<xref ref-type="fig" rid="pcbi.1006563.g003">Fig 3A</xref>) and a reduced model with no allocentric signal provided a better fit to data than the optimal integration model (ΔAICc = 16.56). This confirms that the landmark benefit is a result of the use of allocentric spatial information and not due to encoding bias. If items presented in the vicinity of a landmark were preferentially encoded, or encoded with enhanced precision, we would have seen a benefit for those items even when the landmark was absent during the response phase.</p>
<fig id="pcbi.1006563.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006563.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Experiment two.</title>
<p><bold>(A-C)</bold> Mean variability in memory recall across participants for LM-ENCODE (A), LM-GAP (B) and LM-PRESENT (C) conditions (with LM-ABSENT shown on the right in blue). There is a substantial reduction in variability in the vicinity of the landmark irrespective of whether the landmark was persistently (LM-PRESENT) or intermittently shown (LM-GAP), but no apparent influence of the visual landmark when it was only visible during encoding (LM-ENCODE). Predictions of the best-fitting model are overlaid.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006563.g003" xlink:type="simple"/>
</fig>
<p>Does the use of the landmark depend on its continuous presence during the memory delay? We tested a condition (LM-GAP) in which the landmark disappeared at the offset of the sample array and only reappeared at the time of the probe. We found a robust landmark effect in this condition (ΔAICc = 135 compared to reduced model; <xref ref-type="fig" rid="pcbi.1006563.g003">Fig 3B</xref>). Comparing the LM-GAP condition to one in which the landmark was continuously present (LM-PRESENT, as in Exp 1) revealed no difference in peak precision of the allocentric signal (ΔAICc = 9.34 favoring a model with shared <italic>A</italic><sub><italic>max</italic></sub> parameter between conditions) but some evidence for a difference in the rate of change of precision with distance (ΔAICc = 13.19 favoring a model in which <italic>A</italic><sub><italic>scale</italic></sub> differed between conditions; median <italic>A</italic><sub><italic>scale</italic></sub> 20.9% lower in LM-GAP condition). Exp 2 also replicated the finding from Exp 1 that the presence of a landmark incurred no cost to the precision of egocentric memory (model with cost performed worse, ΔAICc = 23.31; parameter estimates for Exp 2 are shown in <xref ref-type="supplementary-material" rid="pcbi.1006563.s006">S4 Fig</xref>).</p>
<p>A final possibility is that the benefits observed in the LM-GAP and LM-PRESENT conditions arose from enhanced retrieval of items whose previous locations were close to the landmark’s location at the time of the probe, perhaps due to internal attention being drawn to that location in memory. We therefore carried out an additional control experiment (see <xref ref-type="supplementary-material" rid="pcbi.1006563.s001">S1 Text</xref> and <xref ref-type="supplementary-material" rid="pcbi.1006563.s003">S1 Fig</xref>) which included an LM-RETRIEVE condition, in which the landmark was visible only at the time of response, and not during the presentation of the memory stimuli. In this condition, allocentric information about the items’ locations relative to the landmark could not be encoded from the memory array, but any effect of the landmark on internal attention at the time of retrieval should still be present. We found no evidence for a landmark-related improvement of precision in this condition, and a reduced model with no allocentric signal for the LM-RETRIEVE condition provided a better fit to data than the optimal integration model (ΔAICc = 39.86).</p>
<p>Considering in combination the results of LM-ENCODE (no benefit if the landmark is present only during encoding), LM-RETRIEVE (no benefit if the landmark is present only during retrieval) and LM-GAP (clear benefit if the landmark is present during both encoding and retrieval), our results strongly indicate that landmark-related benefits are due to encoding and subsequent retrieval of allocentric (relative position) information present in the memory array.</p>
</sec>
<sec id="sec006">
<title>Cue conflict</title>
<p>To provide a strong test of the optimal integration model, in Experiment 3 we implemented a variant of the LM-GAP condition in which the landmark reappeared at a location displaced through a small distance (6° on the circle) from its original position (LM-SHIFT; <xref ref-type="fig" rid="pcbi.1006563.g004">Fig 4A</xref>). According to the model, this manipulation should introduce a conflict between egocentric and allocentric spatial information, with the allocentric estimate shifting with the visual landmark. As a result, we predicted that participants would show systematic biases in their localization responses in the direction of the shift, with the strength of the bias determined by the relative reliability of each cue.</p>
<fig id="pcbi.1006563.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006563.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Experiment three.</title>
<p><bold>(A)</bold> Example LM-SHIFT trial. When the landmark returned, it was shifted by either 6° clockwise or counter-clockwise (exaggerated above for clarity; light gray disk illustrates previous landmark location and was not visible in the experiment). If participants used the post-shift location to anchor their allocentric estimates, we would expect their responses to be biased in the direction of the displacement, with the magnitude related to the reliability of the allocentric cue. <bold>(B)</bold> The response bias measured in the direction of the shift (magnitude 6° indicated by gray line), as a function of distance from the landmark. The data reveals a consistent bias in the direction of the displacement, which may be either towards or away from the visible landmark location. Bias magnitude depended on distance from the landmark with a peak of ~80% of the shift. <bold>(C)</bold> Spatially specific decreases in response variability near the landmark in LM-SHIFT. Note that for clarity the bias was subtracted prior to calculation of the median absolute deviation. The model predictions (overlaid) simultaneously capture landmark effects on both bias (B) and variability (C), without any additional free parameters.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006563.g004" xlink:type="simple"/>
</fig>
<p>We found a clear landmark effect in the LM-SHIFT condition (ΔAICc = 179 compared to reduced model), and the recalled locations of items presented close to the landmark were strongly shifted in the direction of landmark displacement (<xref ref-type="fig" rid="pcbi.1006563.g004">Fig 4B</xref>). The optimal integration model accurately predicted changes in both bias and variability with landmark distance (<xref ref-type="fig" rid="pcbi.1006563.g004">Fig 4B&amp;4C</xref>). The additional fitting of bias required no extra parameters, relying on the same reliability estimates used to calculate variability. Parameter estimates for Exp 3 are shown in <xref ref-type="supplementary-material" rid="pcbi.1006563.s007">S5 Fig</xref>.</p>
<p>Examining the effect of shifting the landmark on precision of the allocentric signal (by contrasting LM-GAP and LM-SHIFT conditions), revealed a reduction in both the peak precision of allocentric information (ΔAICc = 19.03 favoring a model in which <italic>A</italic><sub><italic>max</italic></sub> differed between conditions; median <italic>A</italic><sub><italic>max</italic></sub> 74.0% lower in LM-SHIFT condition) and the rate at which it decayed with distance (ΔAICc = 21.6 favoring a model in which <italic>A</italic><sub><italic>scale</italic></sub> differed between conditions; median <italic>A</italic><sub><italic>scale</italic></sub> 35.1% lower in LM-SHIFT condition).</p>
<p>Finally, as in previous experiments, we examined whether there was evidence for a precision cost on egocentric encoding. We found a ΔAICc of 28.11 favoring the model without cost, further confirming that allocentric and egocentric information are independently stored.</p>
</sec>
</sec>
<sec id="sec007" sec-type="conclusions">
<title>Discussion</title>
<p>Natural scenes rarely contain only a single item, and are instead frequently populated by multiple stable objects, any of which could act as a visual landmark for locations we need to remember. However, how the brain stores and uses this information is only partially understood. Here, using simple experimental displays, we have demonstrated a spatially specific enhancement of localization precision in the vicinity of a landmark, consistent with observers using not only memory of the egocentric spatial locations of stimuli, but also memory of their locations relative to other objects in the environment (allocentric information). We further investigated the consequences of encoding this additional information into VSWM, in light of established limitations on working memory resources [<xref ref-type="bibr" rid="pcbi.1006563.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref007">7</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref009">9</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref022">22</xref>].</p>
<p>It is now well established that increasing the number of items to be remembered increases variability in recall of their features and locations [<xref ref-type="bibr" rid="pcbi.1006563.ref004">4</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref006">6</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref022">22</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref023">23</xref>]. If egocentric and allocentric information compete for access to the same limited memory resource, then the introduction of a landmark (with the consequent encoding of additional allocentric information) should reduce egocentric memory fidelity. While we observed a spatially specific increase in recall precision for items near the landmark, memory items located far from the landmark were recalled just as precisely as when the landmark was absent. Thus, our results demonstrate that the presence of the landmark had no influence on the fidelity of egocentric memory representation. Instead, the presence of a landmark appeared to grant access to an additional allocentric source of spatial information. To confirm this finding, we incorporated a cost parameter into a cue-combination model, which allowed the reliability of egocentric information to be degraded in the presence of a landmark. In three separate experiments, we consistently found a model with no cost provided the best description of the data, a result further supported by a meta-analysis of cost estimates pooled across experiments (<xref ref-type="supplementary-material" rid="pcbi.1006563.s002">S2 Text</xref> and <xref ref-type="supplementary-material" rid="pcbi.1006563.s004">S2 Fig</xref>). Thus, rather than directly competing, our results suggest that egocentric and allocentric locations are encoded independently and draw upon separate memory resources.</p>
<p>We also examined competition <italic>within</italic> each representation as the number of items encoded increased. For egocentric spatial information, this competition led to a gradual decrease in the reliability of spatial estimates (<italic>P</italic><sub><italic>ego</italic></sub>) as set size increased, consistent with previous results [<xref ref-type="bibr" rid="pcbi.1006563.ref006">6</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref007">7</xref>]. Similarly, we found that increasing set size led to a decrease in the maximum reliability of allocentric spatial information (<italic>A</italic><sub><italic>max</italic></sub>), indicating that the recollection of multiple relative locations also reflects a distribution of limited memory resources. In contrast, set size had no influence on the rate at which allocentric precision diminished with distance (<italic>A</italic><sub><italic>scale</italic></sub>). So, while the number of items in memory determined the overall reliability of allocentric information, the relationship between landmark distance and reliability appears to be fixed.</p>
<p>We observed a substantial, spatially specific improvement in recall precision even when the landmark was hidden during the memory delay (LM-GAP). While this manipulation did not change the maximum precision of allocentric information (<italic>A</italic><sub><italic>max</italic></sub>), there was a decrease in the spatial scale over which the precision enhancement was observed (<italic>A</italic><sub><italic>scale</italic></sub>). The interruption in landmark persistence may have reduced the perceived stability of the visual landmark, introducing uncertainty as to whether the returning landmark had reappeared at the same location or if it should be considered the same object [<xref ref-type="bibr" rid="pcbi.1006563.ref024">24</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref027">27</xref>]. This is consistent with a study of reach programming in which landmark locations were jittered [<xref ref-type="bibr" rid="pcbi.1006563.ref019">19</xref>], which demonstrated that participants are sensitive to perceived landmark stability and adjust reliance on allocentric information as a result.</p>
<p>Importantly, when the landmark was only present during encoding (LM-ENCODE)—and not during recall—there was no advantage in localization compared to conditions without a landmark (LM-ABSENT). This means the landmark benefit cannot be explained simply by enhanced encoding of items in its vicinity, as this would predict improved localization irrespective of the landmark’s presence at recall. Furthermore, because the interleaved LM-GAP and LM-ENCODE conditions were indistinguishable until the time of recall, we can be certain that the same amount of allocentric information was encoded in both conditions. Therefore, the absence of a benefit in LM-ENCODE must arise from an inability to use this information. A landmark only appears to improve localization performance when at the time of testing the recalled allocentric distance can be anchored to the visible location of the landmark itself.</p>
<p>We also saw no benefit when the landmark was present only at the time of retrieval (LM-RETRIEVE), a condition in which allocentric information relating memory items to the landmark could not have been stored. This also demonstrates that the landmark benefit is not due to an enhancement of retrieval for items whose location in memory falls close to the probe, as such an enhancement would be observed regardless of whether the landmark was visible during encoding.</p>
<p>The lack of difference in recall precision between LM-ENCODE and LM-ABSENT conditions enables two additional observations to be made. First, participants apparently did not encode the egocentric location of the visual landmark itself, as its presence had no influence on precision (i.e. there was no set-size effect diminishing precision in the LM-ENCODE condition). This is consistent with both the task instructions and our conclusion that, to be useful for localization, the landmark had to be present at test. Second, given that we know allocentric information was encoded (but not used) in the LM-ENCODE condition, any competition between allocentric and egocentric information would be readily apparent as a decrease in precision compared to LM-ABSENT. The absence of such a difference is itself strong additional evidence for the independence of egocentric and allocentric spatial representations.</p>
<p>Across a variety of different conditions, an optimal integration model accurately described how allocentric and egocentric information were combined to generate estimates of location. Based on exponential decay of allocentric precision with distance from the landmark, this model captured not only how recall variability changed as a function of distance, but also the distance-dependent recall biases that emerged when egocentric and allocentric cues were put in conflict (Exp 3). Specifically, when we covertly changed the location at which the landmark reappeared (LM-SHIFT), we observed systematic shifts in recall position based on the distance of the recalled item from the landmark, with memoranda near to the landmark biased substantially in the direction of the displacement. Critically, these biases were consistent with a displacement in localization (i.e. relying more strongly on the allocentric information), not with an attractive bias to the landmark’s location. This result adds considerable support for our model, demonstrating that the integration of egocentric and allocentric information was close to optimal, and reinforces the conclusion that allocentric and egocentric estimates are encoded separately and as such associated with independent noise. Such integration models have proved invaluable in the study of multisensory integration (e.g. [<xref ref-type="bibr" rid="pcbi.1006563.ref028">28</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref029">29</xref>]), and several studies have used similar methods to describe the integration of allocentric and egocentric information in reaching and eye-movements to a single target [<xref ref-type="bibr" rid="pcbi.1006563.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref021">21</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref030">30</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref031">31</xref>]. However, to our knowledge, no previous study has quantitatively examined the consequences of encoding both egocentric and allocentric information on memory fidelity, determined how the precision of allocentric spatial information varies with set size, nor quantified the relationship between distance and the reliability of allocentric information.</p>
<p>The results of the LM-SHIFT condition also provide evidence against any alternative account of our findings based on local changes in the encoding or retrieval of items in the vicinity of the landmark. The observed biases in recall could not be the result of a difference in how items near to the landmark were encoded, because the biases were specifically in the direction of the landmark displacement, which was entirely unpredictable at the time of encoding. Equally, the biases could not be a consequence of proximity of items in memory to the location of the landmark at the time of retrieval, because this location was also randomized with respect to displacement direction. In contrast, biases in the direction of displacement are fully compatible with an account in which observers remember the relative deviation of items from the landmark, and a model in which this allocentric memory provides an additional, independent source of information for item localization provided an excellent quantitative account of both the biases and the enhancements in precision associated with proximity to the landmark (<xref ref-type="fig" rid="pcbi.1006563.g004">Fig 4B&amp;4C</xref>).</p>
<p>Other than the systematic localization shift in the conflict condition (LM-SHIFT)—which was well characterized by our optimal integration model—we observed no consistent biases in localization due to the presence of the landmark in any of our tasks. However, several previous papers have reported biases, both attractive and repulsive, linked to visual landmarks, as well as fixation and attended, non-fixated locations [<xref ref-type="bibr" rid="pcbi.1006563.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref041">41</xref>]. For example, in a task in which participants were required to make a pointing movement to the location of a single flashed target in the presence of a continuous visual landmark, Diedrichsen and colleagues [<xref ref-type="bibr" rid="pcbi.1006563.ref032">32</xref>] found that movement endpoints were both repulsed from the location of the landmark and less variable in its vicinity. However, in a similar condition to our LM-ENCODE, in which the landmark was only present during the encoding stage, they observed the presence of the same systematic biases without the improvement in precision. This suggests that the systematic biases they observed are independent of the spatially-specific improvements in precision that occur for items near a landmark. The absence of consistent landmark-related biases in the present experiments may be a consequence of preventing eye movements, ensuring both landmarks and stimuli were equally eccentric, and confining responses to the stimulus circle, all of which would tend to minimize the impact of attentional spatial distortions. Some dynamical models of working memory predict attraction or repulsion between items in memory depending on their separation [<xref ref-type="bibr" rid="pcbi.1006563.ref042">42</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref044">44</xref>], but we would not expect the same principles to apply to the landmark, which as discussed above does not appear to itself be stored in memory.</p>
<p>Our experimental manipulations compared recall in the presence and absence of a landmark object. This allowed us to quantify the performance changes resulting from adding a new source of allocentric information to the scene, irrespective of whether allocentric information was also encoded in the LM-ABSENT condition. One possibility is that participants encoded item locations relative to other elements that remained visible throughout the trial, i.e. the screen edges or the fixation spot. Although we elected not to obscure these elements (removing the fixation spot would have made it impractical to control eye movements), we think a contribution of this relative information to our egocentric estimate is unlikely. In our task, the reliability of allocentric information diminished rapidly with distance from the landmark: indeed, the localization of memoranda more than 4.7° of visual angle (46° on the circle) from the landmark received negligible benefit from allocentric information (&lt; 5% change in precision from no-landmark performance). This renders the distance from the memoranda to the screen edges (min 6.5°) or the fixation dot (6°) too far to exert any meaningful influence on localization. Previous studies have attempted to estimate a distance threshold beyond which allocentric information no longer has a significant influence, based on qualitative comparisons of conditions with different spatial separations [<xref ref-type="bibr" rid="pcbi.1006563.ref030">30</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref045">45</xref>]. Our approach enabled us to identify and quantify a continuous change in the reliability of relative cues that occurs as the distance from the landmark increases.</p>
<p>The format in which allocentric information is extracted from the array and stored in memory cannot be unambiguously determined from our experiments. The simplest account of our results would posit an internal representation of the vector connecting each memory item with the landmark. However, it is possible that other static elements in the participant’s surroundings, or overarching geometric principles such as the fact all stimuli were displayed in the vertical plane of the monitor (defining an observer-independent coordinate frame), influence the representation format also. These issues have been explored primarily in the context of navigation and large-scale spatial cognition [<xref ref-type="bibr" rid="pcbi.1006563.ref046">46</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref049">49</xref>]. The present design could in future be extended to examine corresponding principles in VSWM, for example by presenting two or more landmarks in a single memory array.</p>
<p>Competition in encoding information within a feature dimension has been linked to the normalization of neural population activity [<xref ref-type="bibr" rid="pcbi.1006563.ref050">50</xref>], and this model has been successful in accounting for set size effects [<xref ref-type="bibr" rid="pcbi.1006563.ref051">51</xref>]. While this neural account of resource limitations has been extended to incorporate multiple feature dimensions, including spatial location [<xref ref-type="bibr" rid="pcbi.1006563.ref052">52</xref>], no attempt has been made to distinguish between different spatial reference frames. This work has, however, both confirmed and provided new evidence for a privileged role of spatial information in binding object features [<xref ref-type="bibr" rid="pcbi.1006563.ref053">53</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref054">54</xref>]. Evidence for a specific contribution of allocentric information to object binding has been revealed in change detection tasks in which individual item locations (egocentric) or global spatial layout (allocentric) are separately manipulated. Here, even when explicitly informed that location information was irrelevant, performance was compromised by individual changes in spatial position unless allocentric information remained veridical [<xref ref-type="bibr" rid="pcbi.1006563.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref055">55</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref058">58</xref>].</p>
<p>While our observation of set size effects on the precision of allocentric information suggests a commonality in neural representation with other feature dimensions, relative location information may be unique in that it spans objects rather than being associated with a single object. For this reason it is unclear how object file [<xref ref-type="bibr" rid="pcbi.1006563.ref053">53</xref>] or slot-based models of VSWM [<xref ref-type="bibr" rid="pcbi.1006563.ref002">2</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref009">9</xref>] would be able to incorporate such spatial information. Our model does not attempt to capture transformations between egocentric and allocentric reference frames (e.g. [<xref ref-type="bibr" rid="pcbi.1006563.ref059">59</xref>]) and this will be an important direction for future investigation, particularly with respect to the effects of self-motion.</p>
<p>Classically, the division between egocentric and allocentric information has been associated with the neuropsychological distinction between the dorsal and ventral visual processing streams [<xref ref-type="bibr" rid="pcbi.1006563.ref060">60</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref061">61</xref>]. While spatial information is encoded in egocentric coordinates throughout the dorsal pathway, the ventral projections into the inferior temporal cortex represent progressively more complex information about object properties, encoded by neurons with decreasing sensitivity to spatial location [<xref ref-type="bibr" rid="pcbi.1006563.ref061">61</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref064">64</xref>] and little retinotopic organization [<xref ref-type="bibr" rid="pcbi.1006563.ref013">13</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref014">14</xref>]. Contemporary research suggests that, rather than being lost, spatial information along the ventral path is instead increasingly represented in terms of the relations within and between objects in the environment [<xref ref-type="bibr" rid="pcbi.1006563.ref065">65</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref067">67</xref>]. Indeed, neuroimaging studies looking for correlates of allocentric coding have frequently identified higher areas in the ventral stream [<xref ref-type="bibr" rid="pcbi.1006563.ref068">68</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref073">73</xref>] as components of a broader distributed network contributing to allocentric representation [<xref ref-type="bibr" rid="pcbi.1006563.ref065">65</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref071">71</xref>]. Hippocampal structures are also implicated in relative spatial encoding, most clearly in relation to navigation, but with growing evidence for a role in coding visual space [<xref ref-type="bibr" rid="pcbi.1006563.ref059">59</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref071">71</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref074">74</xref>–<xref ref-type="bibr" rid="pcbi.1006563.ref078">78</xref>].</p>
<p>Despite these recent findings, the neural coding of allocentric space remains far more poorly understood than egocentric space. We believe the present work provides a computational and experimental framework within which future studies can explore the neural bases of these spatial memory mechanisms.</p>
</sec>
<sec id="sec008" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec009">
<title>Participants</title>
<p>39 participants took part in the study in total. All participants gave informed consent, in accordance with the Declaration of Helsinki. The study was approved by the Cambridge Psychology Research Ethics Committee. All participants had normal or corrected-to-normal color vision. Each experiment recruited new participants, ensuring all were naïve to the aims of the experiment. Three subjects failed to understand the task and were excluded from analysis (one in Exp 2; two in Exp 3). This left 12 participants in Experiment 1 (age range: 18–28; mean: 24±3; 4 male, 8 female), 12 in Experiment 2 (age range: 20–34; mean: 26±4; 5 male, 7 female), and 12 in Experiment 3 (age range: 19–30; mean: 25±4; 1 male, 11 female). Sample sizes were preselected based on pilot experiments and reports of previous studies examining spatial recall [<xref ref-type="bibr" rid="pcbi.1006563.ref006">6</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref052">52</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref079">79</xref>]. Recruiting new participants for each experiment had the advantage of providing multiple internal replications of our key results.</p>
</sec>
<sec id="sec010" sec-type="materials|methods">
<title>Experimental design</title>
<sec id="sec011">
<title>Experiment 1</title>
<p>In the first experiment we examined whether the absence (LM-ABSENT) or presence (LM-PRESENT) of a visual landmark influenced spatial working memory performance. Participants began each trial by fixating a central dot for 500 ms. A sample array of 1, 2 or 4 colored disks (diameter 1° of visual angle, on an invisible circle with a radius of 6°) was then presented for 1000 ms (<xref ref-type="fig" rid="pcbi.1006563.g001">Fig 1</xref>). The colors of the memory items were chosen from a set of four (color [L, a, b]; yellow [50, 20, 80], pink [50, 80, 20], purple [50, 20, –40], green [50, –40, 20]), selected to have maximally distinctive hues in CIELAB colorspace. The sample array was followed by a 1000 ms blank delay period, after which the fixation dot changed to the color of one of the items in the sample array (the <italic>target</italic>). Participants used a computer mouse to indicate the remembered location of the target. First, a mouse cursor appeared at the location of the fixation dot. Once participants moved the mouse cursor &gt;2° from fixation, a response disk (white) appeared on the invisible circle and participants used the mouse to move this disk to the target location. They made their response by clicking on the disk.</p>
<p>LM-ABSENT and LM-PRESENT conditions were identical, apart from a dark gray ([10, 0, 0]) landmark disk (1.5° diameter) that appeared on the invisible circle 500 ms before the sample array in the LM-PRESENT condition and persisted until after participants made their response. Participants were informed that on some trials the gray disk would be present, but that they would only be asked to recall the location of the colored disks and they could think of the gray disk as a background object. The spatial location of the landmark was selected randomly on the circle, while the location of the target stimulus on each trial was randomly assigned such that across each experimental block an equal number of targets occurred at 12 angular bins around the circle relative to the landmark. This was to ensure that all distances from the landmark were approximately equally sampled within each block. Locations of the remaining memory items were randomly assigned, with the constraint that items were separated by at least 15° on the circle (to prevent overlap). There was no such constraint on the landmark, enabling memory items to occasionally overlap it. However, as the landmark was both larger and situated “behind” the memory items, in these cases both landmark and memory items remained visible.</p>
<p>Participants were instructed to maintain fixation at the center of the screen and gaze position was monitored online at 1000 Hz using an infrared eye tracker (Eyelink 1000, SR Research). Trials with eye-movements prior to the response cue were aborted, and a new trial initiated. Both conditions, and all three set sizes, were interleaved. To facilitate later analysis there were six times as many trials in LM-PRESENT (216 per set size) as LM-ABSENT (36 per set size). Participants completed 6 blocks of 126 trials, for a total of 756 trials, taking approximately 1.5 hours.</p>
</sec>
<sec id="sec012">
<title>Experiment 2</title>
<p>The second experiment proceeded identically to Experiment 1, with a few notable exceptions. Only the largest set size was tested (4 items) and, in addition to LM-ABSENT and LM-PRESENT, two new conditions were included. The LM-GAP condition was identical to LM-PRESENT except that the landmark was removed at the start of the memory delay, returning at the same time as the response cue. In the LM-ENCODE condition the landmark was removed at the start of the memory delay and did not reappear. Because all four conditions were interleaved, participants did not know during the presentation of the sample array whether the landmark would be present during the delay or response. Participants completed a total of 216 trials in each of the LM-PRESENT, LM-GAP, and LM-ENCODE conditions, and 72 trials in LM-ABSENT. Trials were divided into 6 blocks of 120 trials, for a total of 720 trials, taking approximately 1.5 hours.</p>
</sec>
<sec id="sec013">
<title>Experiment 3</title>
<p>The third experiment was identical to Experiment 2 with a few exceptions. The LM-ENCODE condition was removed and replaced with a new condition, LM-SHIFT, which was identical to LM-GAP except that the landmark reappeared in a new position, displaced 6° on the circle randomly clockwise or counter-clockwise from its original location. There were a total of 216 trials in the LM-PRESENT, LM-GAP and LM-SHIFT conditions and 36 trials in LM-ABSENT. Participants completed 6 blocks of 114 trials, for a total of 684 trials, taking approximately 1.5 hours.</p>
</sec>
</sec>
<sec id="sec014">
<title>Analysis</title>
<p>We calculated the median angular deviation (a measure of response bias) and the median absolute angular deviation (a measure of response variability) between the response and the target for each condition and, in conditions with a landmark, for different landmark-target distances. For display purposes, we summarized data into 24 partially overlapping bins, separated by 15° and encompassing data from ±15°.</p>
<sec id="sec015">
<title>Ideal observer model</title>
<p>We modeled localization responses as arising from an optimal integration of two independent estimates of target location: an <italic>egocentric</italic> estimate <inline-formula id="pcbi.1006563.e001"><alternatives><graphic id="pcbi.1006563.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> that is normally distributed with mean <italic>μ</italic><sub><italic>ego</italic></sub> and precision (inverse variance) <italic>P</italic><sub><italic>ego</italic></sub>, and an <italic>allocentric</italic> estimate <inline-formula id="pcbi.1006563.e002"><alternatives><graphic id="pcbi.1006563.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> that is normally distributed with mean <italic>μ</italic><sub><italic>allo</italic></sub> and precision <italic>P</italic><sub><italic>allo</italic></sub>.</p>
<p>The precision of the egocentric estimate, <italic>P</italic><sub><italic>ego</italic></sub>, does not depend on the landmark location and is a free parameter of the model. The precision of the allocentric estimate declines exponentially with distance <italic>d</italic> between the landmark and the stimulus,
<disp-formula id="pcbi.1006563.e003">
<alternatives>
<graphic id="pcbi.1006563.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.12em"/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>A</italic><sub><italic>max</italic></sub> and <italic>A</italic><sub><italic>scale</italic></sub> are free parameters capturing the peak precision and the rate at which precision declines with distance, respectively. For landmark-absent conditions we set <italic>P</italic><sub><italic>allo</italic></sub> to zero.</p>
<p>The mean of the egocentric estimate of location, <italic>μ</italic><sub><italic>ego</italic></sub>, is in all cases equal to the true location of the stimulus, <italic>x</italic>. This is also true for the mean of the allocentric estimate, except in Exp 3 where the landmark is shifted through a displacement <italic>s</italic> during the delay; in this case the allocentric estimate follows the shifted landmark, i.e. <italic>μ</italic><sub><italic>allo</italic></sub> = <italic>x</italic> + <italic>s</italic>.</p>
<p>A maximum likelihood estimate (<inline-formula id="pcbi.1006563.e004"><alternatives><graphic id="pcbi.1006563.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>) is obtained by weighting each of the individual estimates by their precision [<xref ref-type="bibr" rid="pcbi.1006563.ref028">28</xref>,<xref ref-type="bibr" rid="pcbi.1006563.ref080">80</xref>]. As a result, <inline-formula id="pcbi.1006563.e005"><alternatives><graphic id="pcbi.1006563.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is normally distributed with mean,
<disp-formula id="pcbi.1006563.e006">
<alternatives>
<graphic id="pcbi.1006563.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
and precision,
<disp-formula id="pcbi.1006563.e007">
<alternatives>
<graphic id="pcbi.1006563.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
<p>In generating a response, we allow for a certain proportion of <italic>lapse</italic> trials in which the response is randomly (uniformly) distributed relative to the target location. So, the response distribution is given by,
<disp-formula id="pcbi.1006563.e008">
<alternatives>
<graphic id="pcbi.1006563.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where <italic>p</italic>(<italic>lapse</italic>) is a free parameter and <italic>ϕ</italic>(<italic>x</italic>;<italic>μ</italic>,<italic>P</italic>) is the von Mises distribution function evaluated at <italic>x</italic> with mean <italic>μ</italic> and precision <italic>P</italic> (we use a von Mises, or circular normal, function because the response space is circular, to ensure the response distribution integrates to one; however, in practice, values of <italic>P</italic><sub><italic>MLE</italic></sub> that fit the data were always sufficiently high that the von Mises was indistinguishable from a Gaussian with the same mean and precision).</p>
<p>The model was fit to each participant’s data using maximum likelihood obtained by a nonlinear optimization algorithm (<italic>fmincon</italic> in MATLAB). We placed bounds on the free parameters as follows: <italic>P</italic><sub><italic>ego</italic></sub>, [0, ∞]; <italic>A</italic><sub><italic>max</italic></sub>, [0, ∞]; <italic>A</italic><sub><italic>scale</italic></sub>, [0, 500]; <italic>p</italic>(<italic>lapse</italic>), [0, 1]. Tests for effects of experimental condition on model parameters were carried out by comparing models in which the relevant parameter was shared between conditions versus models with independent parameter values for each condition.</p>
<p>Monte-Carlo simulation was used to generate predictions of median absolute angular deviation and median angular deviation to facilitate comparison with behavioral data.</p>
</sec>
<sec id="sec016">
<title>Model with cost</title>
<p>To ascertain whether encoding allocentric information decreased precision of egocentric memory, we also examined an extended model with an additional cost parameter (<italic>C</italic>). Here we replaced <italic>P</italic><sub><italic>ego</italic></sub> with two parameters corresponding to egocentric precision in the presence (<inline-formula id="pcbi.1006563.e009"><alternatives><graphic id="pcbi.1006563.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) or absence (<inline-formula id="pcbi.1006563.e010"><alternatives><graphic id="pcbi.1006563.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>O</mml:mi><mml:mo>−</mml:mo><mml:mi>L</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) of a landmark, related by
<disp-formula id="pcbi.1006563.e011">
<alternatives>
<graphic id="pcbi.1006563.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>O</mml:mi><mml:mo>−</mml:mo><mml:mi>L</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where <italic>C</italic> is bounded in the range [0, 1]. The inclusion of this cost parameter enabled egocentric precision to be reduced when the landmark was present. This model had five free parameters: <inline-formula id="pcbi.1006563.e012"><alternatives><graphic id="pcbi.1006563.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006563.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>O</mml:mi><mml:mo>−</mml:mo><mml:mi>L</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, <italic>A</italic><sub><italic>max</italic></sub>, <italic>A</italic><sub><italic>scale</italic></sub>, <italic>p</italic>(<italic>lapse</italic>), <italic>C</italic>. To test for a cost of landmark encoding we compared this model to the unextended model described above. We used the Akaike Information Criterion with correction for finite sample sizes (AICc) for model comparison. This criterion typically incorporates a smaller penalty for additional parameters than the Bayesian Information Criterion (BIC). Using AICc meant that the addition of a cost parameter was relatively unlikely to be rejected, making it a conservative test of the hypothesis that the landmark conferred no cost.</p>
</sec>
</sec>
</sec>
<sec id="sec017">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006563.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006563.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Testing for an effect of landmark presence at retrieval.</title>
<p>Experiment 2 revealed that the presence of a landmark during encoding alone (LM-ENCODE) was not sufficient to induce a landmark effect. This indicates that the benefit of the landmark is not due to items near the landmark capturing attention and being preferentially encoded (leading to greater precision). We are grateful to an anonymous reviewer for suggesting an additional control experiment, in which the landmark is present only at retrieval (LM-RETRIEVE). This experiment tested whether the presence of the landmark at the time of recall conveys a benefit to items whose locations in memory are in its vicinity, for example by directing internal attention to the location in memory corresponding to the landmark.</p>
<p>Twelve new participants (age range: 20–30; mean: 24±4; 3 male, 9 female) took part in Experiment 2B (with 2 additional subjects excluded for not understanding the task), which comprised three interleaved conditions: LM-ABSENT and LM-PRESENT, which were identical to the corresponding conditions in Exp 2, and the new LM-RETRIEVE condition (<xref ref-type="supplementary-material" rid="pcbi.1006563.s003">S1A Fig</xref>). In this condition the landmark appeared at a random position on the circle at the same time as the probe color (matching the timing of the landmark’s re-appearance in the LM-GAP condition of Exp 2). Participants completed a total of 210 trials in each of the LM-PRESENT and LM-RETRIEVE conditions, and 105 trials in LM-ABSENT. Trials were divided into 5 blocks of 105 trials, for a total of 525 trials, taking approximately 1 hour.</p>
<p>In the LM-RETRIEVE condition we found no evidence for a spatially-specific improvement in the precision of recall for items in the vicinity of the landmark (<xref ref-type="supplementary-material" rid="pcbi.1006563.s003">S1B Fig</xref>). A reduced model in which there was no allocentric signal in this condition provided a better fit to data than the full optimal integration model (ΔAICc = 39.86). This contrasted with the LM-PRESENT condition where, as for the other experiments in this study, excluding the allocentric component made the model worse (ΔAICc = 68.74). These results demonstrate that the presence of a landmark solely during retrieval was insufficient to generate the improvements observed in LM-PRESENT (or LM-GAP, Exp 2) conditions.</p>
<p>As in the other experiments in this study we found no evidence for a cost to precision of egocentric encoding due to the presence of the landmark (model with cost on LM-PRESENT performed worse, ΔAICc = 24.1). We additionally tested whether the appearance of the landmark in the LM-RETRIEVE condition reduced egocentric precision, perhaps by acting as an attentional distractor. We found weak evidence against this (model with cost on LM-RETRIEVE performed worse, ΔAICc = 2.65).</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006563.s002" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006563.s002" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Investigating the cost parameter across experiments.</title>
<p>For each of the three experiments reported in the paper, and the supplementary experiment 2B, model comparison supported models in which the precision of egocentric information was unaffected by the presence or absence of a landmark in preference to models in which the presence of the landmark conveyed a cost to egocentric precision. To further validate this result and assess how any potential cost varied between participants, we pooled the cost parameters obtained from models incorporating a cost of landmark presence fit to data from Experiments 2, 2B and 3. Importantly, in the main analysis the cost parameter was constrained to always be positive, in order that the model comparison provided a one-tailed test at the group level of the hypothesis that the presence of the landmark made egocentric precision worse. Here we allowed cost to take on negative values also, so as to fairly assess how the estimates varied between participants. The resulting distribution of cost parameter values is shown in <xref ref-type="supplementary-material" rid="pcbi.1006563.s004">S2A Fig</xref>. We found that when cost was incorporated as a free parameter in the model, it took up a relatively broad range of values, both positive and negative, across participants, with an average that was negative but close to zero (mean ± SEM: –0.070 ± 0.030; median: –0.063%). This is consistent with the findings of formal model comparison which indicated no evidence at the group level for a (positive) cost of landmark presence, implying that allocentric estimates of location do not compete with egocentric estimates for representation in memory. To further evaluate these data, we considered what cost we would expect if the converse were true, i.e. were egocentric and allocentric representations to compete for the same working memory resources. We reasoned that in this case the addition of a landmark would double the number of competing location representations, because the egocentric representation of each memory stimulus would be supplemented by an allocentric representation encoding its location relative to the landmark. The proportionate decrease in egocentric precision (the cost) should therefore be comparable to that observed when the number of memory items is doubled, which would also be expected to double the number of representations in memory. An estimate of this effect is available from Exp 1, calculated as the ratio of <italic>P</italic><sub><italic>ego</italic></sub> estimates obtained at set size 2 and set size 1, or alternatively at set size 4 and set size 2. This method produced predicted costs of 0.24 ± 0.04 and 0.20 ± 0.04, respectively (<xref ref-type="supplementary-material" rid="pcbi.1006563.s004">S2B Fig</xref>). The large majority of participants (97% versus 2:1 estimate; 92% versus 4:2 estimate) had estimated cost parameters below these predictions, further strengthening the evidence for independence of allocentric and egocentric working memory stores. (Note that data from Exp 1 was excluded from the pooling of cost estimates specifically to avoid circularity in this comparison).</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006563.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006563.s003" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Experiment 2B.</title>
<p><bold>(A)</bold> The paradigm for experiment 2B, including the new LM-RETRIEVE condition to investigate whether landmarks present only during response convey any benefit to recall <bold>(B-C)</bold> Mean variability in memory recall across participants for LM-RETRIEVE (B) and LM-PRESENT (C) conditions (with LM-ABSENT shown on the right in blue). There was no apparent influence of the visual landmark when it was only visible during response (LM-RETRIEVE). Predictions of the best-fitting model are overlaid.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006563.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006563.s004" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Meta-analysis of cost parameter estimates.</title>
<p>(A) Histogram of estimates of cost (proportionate decrease in <italic>P</italic><sub><italic>ego</italic></sub>) due to presence of the landmark in Experiments 2, 2B and 3 (based on LM-PRESENT and LM-ABSENT conditions; all set size 4). <bold>(B)</bold> The mean cost (red) across participants is compared to the proportionate change in <italic>P</italic><sub><italic>ego</italic></sub> associated with doubling the number of memory items (Exp 1). Under the hypothesis of shared resources, these estimates should be equal. Instead, the mean cost of adding a landmark is small in magnitude compared to increasing set size, and in the opposite direction (i.e. a minor benefit of the landmark).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006563.s005" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006563.s005" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Experiment one.</title>
<p><bold>(A-C)</bold> Average bias (+ve, CW) in location recall for set sizes 1, 2 and 4 respectively, with the best fitting model overlaid. There were no consistent biases related to distance from the landmark.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006563.s006" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006563.s006" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Experiment two.</title>
<p>Parameter estimates for the best-fitting model. Parameters for egocentric precision (A) and lapse rate (D) were common to all three conditions, while the best fitting model for LM-Encode had no allocentric components. While there was no difference in the maximum allocentric precision between LM-GAP and LM-PRESENT (B), there was a small difference in the allocentric scale (C).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006563.s007" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006563.s007" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Experiment three.</title>
<p>Parameter estimates for the best-fitting model. Parameters for egocentric precision (A) and lapse rate (D) were common to all three conditions. While parameters for maximum allocentric precision were shared between LM-GAP and LM-PRESENT, the maximum allocentric precision in the LM-SHIFT condition was decreased (B). The three conditions were best fit with differing allocentric scale parameters (C).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1006563.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jiang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Olson</surname> <given-names>IR</given-names></name>, <name name-style="western"><surname>Chun</surname> <given-names>MM</given-names></name>. <article-title>Organization of visual short-term memory</article-title>. <source>J Exp Psychol Learn Mem Cogn</source>. <year>2000</year>;<volume>26</volume>: <fpage>683</fpage>–<lpage>702</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037//0278-7393.26.3.683" xlink:type="simple">10.1037//0278-7393.26.3.683</ext-link></comment> <object-id pub-id-type="pmid">10855426</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Luck</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Vogel</surname> <given-names>EK</given-names></name>. <article-title>The capacity of visual working memory for features and conjunctions</article-title>. <source>Nature</source>. <year>1997</year>;<volume>390</volume>: <fpage>279</fpage>–<lpage>281</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/36846" xlink:type="simple">10.1038/36846</ext-link></comment> <object-id pub-id-type="pmid">9384378</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pashler</surname> <given-names>H.</given-names></name> <article-title>Familiarity and visual change detection</article-title>. <source>Percept Psychophys</source>. <year>1988</year>;<volume>44</volume>: <fpage>369</fpage>–<lpage>378</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03210419" xlink:type="simple">10.3758/BF03210419</ext-link></comment> <object-id pub-id-type="pmid">3226885</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Catalao</surname> <given-names>RFG</given-names></name>, <name name-style="western"><surname>Husain</surname> <given-names>M</given-names></name>. <article-title>The precision of visual working memory is set by allocation of a shared resource</article-title>. <source>J Vis</source>. <year>2009</year>;<volume>9</volume>: <fpage>7.1</fpage>–<lpage>711</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/9.10.7" xlink:type="simple">10.1167/9.10.7</ext-link></comment> <object-id pub-id-type="pmid">19810788</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilken</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>A detection theory account of change detection</article-title>. <source>J Vis</source>. <year>2004</year>;<volume>4</volume>: <fpage>1120</fpage>–<lpage>1135</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/4.12.11" xlink:type="simple">10.1167/4.12.11</ext-link></comment> <object-id pub-id-type="pmid">15669916</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schneegans</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>. <article-title>No fixed item limit in visuospatial working memory</article-title>. <source>Cortex</source>. <year>2016</year>;<volume>83</volume>: <fpage>181</fpage>–<lpage>193</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cortex.2016.07.021" xlink:type="simple">10.1016/j.cortex.2016.07.021</ext-link></comment> <object-id pub-id-type="pmid">27565636</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Husain</surname> <given-names>M</given-names></name>. <article-title>Dynamic Shifts of Limited Working Memory Resources in Human Vision</article-title>. <source>Science</source>. <year>2008</year>;<volume>321</volume>: <fpage>851</fpage>–<lpage>854</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1158023" xlink:type="simple">10.1126/science.1158023</ext-link></comment> <object-id pub-id-type="pmid">18687968</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Shin</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Chou</surname> <given-names>W-C</given-names></name>, <name name-style="western"><surname>George</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Variability in encoding precision accounts for visual short-term memory limitations</article-title>. <source>Proc Natl Acad Sci</source>. <year>2012</year>;<volume>109</volume>: <fpage>8780</fpage>–<lpage>8785</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1117465109" xlink:type="simple">10.1073/pnas.1117465109</ext-link></comment> <object-id pub-id-type="pmid">22582168</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Luck</surname> <given-names>SJ</given-names></name>. <article-title>Discrete fixed-resolution representations in visual working memory</article-title>. <source>Nature</source>. <year>2008</year>;<volume>453</volume>: <fpage>233</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature06860" xlink:type="simple">10.1038/nature06860</ext-link></comment> <object-id pub-id-type="pmid">18385672</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cowey</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rolls</surname> <given-names>ET</given-names></name>. <article-title>Human cortical magnification factor and its relation to visual acuity</article-title>. <source>Exp Brain Res</source>. <year>1974</year>;<volume>21</volume>: <fpage>447</fpage>–<lpage>454</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00237163" xlink:type="simple">10.1007/BF00237163</ext-link></comment> <object-id pub-id-type="pmid">4442497</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Andersen</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Buneo</surname> <given-names>CA</given-names></name>. <article-title>Intentional Maps in Posterior Parietal Cortex</article-title>. <source>Annu Rev Neurosci</source>. <year>2002</year>;<volume>25</volume>: <fpage>189</fpage>–<lpage>220</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.neuro.25.112701.142922" xlink:type="simple">10.1146/annurev.neuro.25.112701.142922</ext-link></comment> <object-id pub-id-type="pmid">12052908</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Colby</surname> <given-names>CL</given-names></name>, <name name-style="western"><surname>Goldberg</surname> <given-names>ME</given-names></name>. <article-title>Space and attention in parietal cortex</article-title>. <source>Annu Rev Neurosci</source>. <year>1999</year>;<volume>22</volume>: <fpage>319</fpage>–<lpage>349</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.neuro.22.1.319" xlink:type="simple">10.1146/annurev.neuro.22.1.319</ext-link></comment> <object-id pub-id-type="pmid">10202542</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gross</surname> <given-names>CG</given-names></name>, <name name-style="western"><surname>Rocha-Miranda</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Bender</surname> <given-names>DB</given-names></name>. <article-title>Visual properties of neurons in inferotemporal cortex of the Macaque</article-title>. <source>J Neurophysiol</source>. <year>1972</year>;<volume>35</volume>: <fpage>96</fpage>–<lpage>111</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1972.35.1.96" xlink:type="simple">10.1152/jn.1972.35.1.96</ext-link></comment> <object-id pub-id-type="pmid">4621506</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kobatake</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>K</given-names></name>. <article-title>Neuronal selectivities to complex object features in the ventral visual pathway of the macaque cerebral cortex</article-title>. <source>J Neurophysiol</source>. <year>1994</year>;<volume>71</volume>: <fpage>856</fpage>–<lpage>867</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1994.71.3.856" xlink:type="simple">10.1152/jn.1994.71.3.856</ext-link></comment> <object-id pub-id-type="pmid">8201425</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burgess</surname> <given-names>N.</given-names></name> <article-title>Spatial memory: how egocentric and allocentric combine</article-title>. <source>Trends Cogn Sci</source>. <year>2006</year>;<volume>10</volume>: <fpage>551</fpage>–<lpage>557</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2006.10.005" xlink:type="simple">10.1016/j.tics.2006.10.005</ext-link></comment> <object-id pub-id-type="pmid">17071127</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Filimon</surname> <given-names>F.</given-names></name> <article-title>Are All Spatial Reference Frames Egocentric? Reinterpreting Evidence for Allocentric, Object-Centered, or World-Centered Reference Frames</article-title>. <source>Front Hum Neurosci</source>. <year>2015</year>;<volume>9</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2015.00648" xlink:type="simple">10.3389/fnhum.2015.00648</ext-link></comment> <object-id pub-id-type="pmid">26696861</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref017"><label>17</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Klatzky</surname> <given-names>RL</given-names></name>. <chapter-title>Allocentric and Egocentric Spatial Representations: Definitions, Distinctions, and Interconnections</chapter-title>. <source>Spatial Cognition</source>. <publisher-name>Springer</publisher-name>, <publisher-loc>Berlin, Heidelberg</publisher-loc>; <year>1998</year>. pp. <fpage>1</fpage>–<lpage>17</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/3-540-69342-4_1" xlink:type="simple">10.1007/3-540-69342-4_1</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006563.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>RF</given-names></name>, <name name-style="western"><surname>Spelke</surname> <given-names>ES</given-names></name>. <article-title>Human spatial representation: insights from animals</article-title>. <source>Trends Cogn Sci</source>. <year>2002</year>;<volume>6</volume>: <fpage>376</fpage>–<lpage>382</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S1364-6613(02)01961-7" xlink:type="simple">10.1016/S1364-6613(02)01961-7</ext-link></comment> <object-id pub-id-type="pmid">12200179</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Byrne</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Crawford</surname> <given-names>JD</given-names></name>. <article-title>Cue Reliability and a Landmark Stability Heuristic Determine Relative Weighting Between Egocentric and Allocentric Visual Information in Memory-Guided Reach</article-title>. <source>J Neurophysiol</source>. <year>2010</year>;<volume>103</volume>: <fpage>3054</fpage>–<lpage>3069</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.01008.2009" xlink:type="simple">10.1152/jn.01008.2009</ext-link></comment> <object-id pub-id-type="pmid">20457858</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fiehler</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Wolf</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Klinghammer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Blohm</surname> <given-names>G</given-names></name>. <article-title>Integration of egocentric and allocentric information during memory-guided reaching to images of a natural environment.</article-title> <source>Front Hum Neurosci</source>. <year>2014</year>;<volume>8</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2014.00636" xlink:type="simple">10.3389/fnhum.2014.00636</ext-link></comment> <object-id pub-id-type="pmid">25202252</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schütz</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Henriques</surname> <given-names>DYP</given-names></name>, <name name-style="western"><surname>Fiehler</surname> <given-names>K</given-names></name>. <article-title>Gaze-centered spatial updating in delayed reaching even in the presence of landmarks</article-title>. <source>Vision Res</source>. <year>2013</year>;<volume>87</volume>: <fpage>46</fpage>–<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2013.06.001" xlink:type="simple">10.1016/j.visres.2013.06.001</ext-link></comment> <object-id pub-id-type="pmid">23770521</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Husain</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>. <article-title>Changing concepts of working memory</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>: <fpage>347</fpage>–<lpage>356</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3655" xlink:type="simple">10.1038/nn.3655</ext-link></comment> <object-id pub-id-type="pmid">24569831</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palmer</surname> <given-names>J.</given-names></name> <article-title>Attentional limits on the perception and memory of visual information</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>1990</year>;<volume>16</volume>: <fpage>332</fpage>. <object-id pub-id-type="pmid">2142203</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atsma</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Maij</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Koppen</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Irwin</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Medendorp</surname> <given-names>WP</given-names></name>. <article-title>Causal Inference for Spatial Constancy across Saccades</article-title>. <source>PLOS Comput Biol</source>. <year>2016</year>;<volume>12</volume>: <fpage>e1004766</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004766" xlink:type="simple">10.1371/journal.pcbi.1004766</ext-link></comment> <object-id pub-id-type="pmid">26967730</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Deubel</surname> <given-names>H.</given-names></name> <article-title>Localization of targets across saccades: Role of landmark objects</article-title>. <source>Vis Cogn</source>. <year>2004</year>;<volume>11</volume>: <fpage>173</fpage>–<lpage>202</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/13506280344000284" xlink:type="simple">10.1080/13506280344000284</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006563.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Deubel</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Bridgeman</surname> <given-names>B</given-names></name>. <article-title>Landmarks facilitate visual space constancy across saccades and during fixation</article-title>. <source>Vision Res</source>. <year>2010</year>;<volume>50</volume>: <fpage>249</fpage>–<lpage>259</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2009.09.020" xlink:type="simple">10.1016/j.visres.2009.09.020</ext-link></comment> <object-id pub-id-type="pmid">19833147</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Poth</surname> <given-names>CH</given-names></name>, <name name-style="western"><surname>Herwig</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schneider</surname> <given-names>WX</given-names></name>. <article-title>Breaking Object Correspondence Across Saccadic Eye Movements Deteriorates Object Recognition</article-title>. <source>Front Syst Neurosci</source>. <year>2015</year>;<volume>9</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnsys.2015.00176" xlink:type="simple">10.3389/fnsys.2015.00176</ext-link></comment> <object-id pub-id-type="pmid">26732235</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>. <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title>. <source>Nature</source>. <year>2002</year>;<volume>415</volume>: <fpage>429</fpage>–<lpage>433</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/415429a" xlink:type="simple">10.1038/415429a</ext-link></comment> <object-id pub-id-type="pmid">11807554</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Bülthoff</surname> <given-names>HH</given-names></name>. <article-title>Merging the senses into a robust percept</article-title>. <source>Trends Cogn Sci</source>. <year>2004</year>;<volume>8</volume>: <fpage>162</fpage>–<lpage>169</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2004.02.002" xlink:type="simple">10.1016/j.tics.2004.02.002</ext-link></comment> <object-id pub-id-type="pmid">15050512</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Camors</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Jouffrais</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Cottereau</surname> <given-names>BR</given-names></name>, <name name-style="western"><surname>Durand</surname> <given-names>JB</given-names></name>. <article-title>Allocentric coding: Spatial range and combination rules</article-title>. <source>Vision Res</source>. <year>2015</year>;<volume>109</volume>: <fpage>87</fpage>–<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2015.02.018" xlink:type="simple">10.1016/j.visres.2015.02.018</ext-link></comment> <object-id pub-id-type="pmid">25749676</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sajad</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Marino</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Yan</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Sun</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Effect of allocentric landmarks on primate gaze behavior in a cue conflict task</article-title>. <source>J Vis</source>. <year>2017</year>;<volume>17</volume>: <fpage>20</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/17.5.20" xlink:type="simple">10.1167/17.5.20</ext-link></comment> <object-id pub-id-type="pmid">28558393</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Diedrichsen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Werner</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Trommershäuser</surname> <given-names>J</given-names></name>. <article-title>Immediate spatial distortions of pointing movements induced by visual landmarks</article-title>. <source>Percept Psychophys</source>. <year>2004</year>;<volume>66</volume>: <fpage>89</fpage>–<lpage>103</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03194864" xlink:type="simple">10.3758/BF03194864</ext-link></comment> <object-id pub-id-type="pmid">15095943</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schmidt</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Werner</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Diedrichsen</surname> <given-names>J</given-names></name>. <article-title>Spatial distortions induced by multiple visual landmarks: How local distortions combine to produce complex distortion patterns</article-title>. <source>Atten Percept Psychophys</source>. <year>2003</year>;<volume>65</volume>: <fpage>861</fpage>–<lpage>873</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006563.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Werner</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Diedrichsen</surname> <given-names>J</given-names></name>. <article-title>The time course of spatial memory distortions</article-title>. <source>Mem Cognit</source>. <year>2002</year>;<volume>30</volume>: <fpage>718</fpage>–<lpage>730</lpage>. <object-id pub-id-type="pmid">12219889</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schmidt</surname> <given-names>T.</given-names></name> <article-title>Spatial Distortions in Visual Short-term Memory: Interplay of Intrinsic and Extrinsic Reference Systems</article-title>. <source>Spat Cogn Comput</source>. <year>2004</year>;<volume>4</volume>: <fpage>313</fpage>–<lpage>336</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1207/s15427633scc0404_2" xlink:type="simple">10.1207/s15427633scc0404_2</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006563.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hubbard</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Ruppel</surname> <given-names>SE</given-names></name>. <article-title>Spatial memory averaging, the landmark attraction effect, and representational gravity</article-title>. <source>Psychol Res</source>. <year>2000</year>;<volume>64</volume>: <fpage>41</fpage>–<lpage>55</lpage>. <object-id pub-id-type="pmid">11109866</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sheth</surname> <given-names>BR</given-names></name>, <name name-style="western"><surname>Shimojo</surname> <given-names>S</given-names></name>. <article-title>Compression of space in visual memory</article-title>. <source>Vision Res</source>. <year>2001</year>;<volume>41</volume>: <fpage>329</fpage>–<lpage>341</lpage>. <object-id pub-id-type="pmid">11164448</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sheth</surname> <given-names>BR</given-names></name>, <name name-style="western"><surname>Shimojo</surname> <given-names>S</given-names></name>. <article-title>Extrinsic Cues Suppress the Encoding of Intrinsic Cues</article-title>. <source>J Cogn Neurosci</source>. <year>2004</year>;<volume>16</volume>: <fpage>339</fpage>–<lpage>350</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089892904322984616" xlink:type="simple">10.1162/089892904322984616</ext-link></comment> <object-id pub-id-type="pmid">15068602</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ono</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Watanabe</surname> <given-names>K</given-names></name>. <article-title>Attention can retrospectively distort visual space</article-title>. <source>Psychol Sci</source>. <year>2011</year>;<volume>22</volume>: <fpage>472</fpage>–<lpage>477</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797611403319" xlink:type="simple">10.1177/0956797611403319</ext-link></comment> <object-id pub-id-type="pmid">21441225</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kerzel</surname> <given-names>D.</given-names></name> <article-title>Memory for the position of stationary objects: disentangling foveal bias and memory averaging</article-title>. <source>Vision Res</source>. <year>2002</year>;<volume>42</volume>: <fpage>159</fpage>–<lpage>167</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0042-6989(01)00274-7" xlink:type="simple">10.1016/S0042-6989(01)00274-7</ext-link></comment> <object-id pub-id-type="pmid">11809470</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Suzuki</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Cavanagh</surname> <given-names>P</given-names></name>. <article-title>Focused attention distorts visual space: an attentional repulsion effect</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>1997</year>;<volume>23</volume>: <fpage>443</fpage>–<lpage>463</lpage>. <object-id pub-id-type="pmid">9104004</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wei</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>X-J</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>D-H</given-names></name>. <article-title>From Distributed Resources to Limited Slots in Multiple-Item Working Memory: A Spiking Network Model with Normalization</article-title>. <source>J Neurosci</source>. <year>2012</year>;<volume>32</volume>: <fpage>11228</fpage>–<lpage>11240</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0735-12.2012" xlink:type="simple">10.1523/JNEUROSCI.0735-12.2012</ext-link></comment> <object-id pub-id-type="pmid">22895707</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Almeida</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Barbosa</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Compte</surname> <given-names>A</given-names></name>. <article-title>Neural circuit basis of visuo-spatial working memory precision: a computational and behavioral study</article-title>. <source>J Neurophysiol</source>. <year>2015</year>;<volume>114</volume>: <fpage>1806</fpage>–<lpage>1818</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00362.2015" xlink:type="simple">10.1152/jn.00362.2015</ext-link></comment> <object-id pub-id-type="pmid">26180122</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Starc</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Murray</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Santamauro</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Savic</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Diehl</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Cho</surname> <given-names>YT</given-names></name>, <etal>et al</etal>. <article-title>Schizophrenia is associated with a pattern of spatial working memory deficits consistent with cortical disinhibition</article-title>. <source>Schizophr Res</source>. <year>2017</year>;<volume>181</volume>: <fpage>107</fpage>–<lpage>116</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.schres.2016.10.011" xlink:type="simple">10.1016/j.schres.2016.10.011</ext-link></comment> <object-id pub-id-type="pmid">27745755</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krigolson</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Heath</surname> <given-names>M</given-names></name>. <article-title>Background visual cues and memory-guided reaching</article-title>. <source>Hum Mov Sci</source>. <year>2004</year>;<volume>23</volume>: <fpage>861</fpage>–<lpage>877</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.humov.2004.10.011" xlink:type="simple">10.1016/j.humov.2004.10.011</ext-link></comment> <object-id pub-id-type="pmid">15664677</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burgess</surname> <given-names>N.</given-names></name> <article-title>Spatial cognition and the brain</article-title>. <source>Ann N Y Acad Sci</source>. <year>2008</year>;<volume>1124</volume>: <fpage>77</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1196/annals.1440.002" xlink:type="simple">10.1196/annals.1440.002</ext-link></comment> <object-id pub-id-type="pmid">18400925</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ekstrom</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Isham</surname> <given-names>EA</given-names></name>. <article-title>Human spatial navigation: Representations across dimensions and scales</article-title>. <source>Curr Opin Behav Sci</source>. <year>2017</year>;<volume>17</volume>: <fpage>84</fpage>–<lpage>89</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cobeha.2017.06.005" xlink:type="simple">10.1016/j.cobeha.2017.06.005</ext-link></comment> <object-id pub-id-type="pmid">29130062</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hartley</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Lever</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Burgess</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>O’Keefe</surname> <given-names>J</given-names></name>. <article-title>Space in the brain: how the hippocampal formation supports spatial cognition</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source>. <year>2014</year>;<volume>369</volume>: <fpage>20120510</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rstb.2012.0510" xlink:type="simple">10.1098/rstb.2012.0510</ext-link></comment> <object-id pub-id-type="pmid">24366125</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McNamara</surname> <given-names>TP</given-names></name>, <name name-style="western"><surname>Rump</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Werner</surname> <given-names>S</given-names></name>. <article-title>Egocentric and geocentric frames of reference in memory of large-scale space.</article-title> <source>Psychon Bull Rev</source>. <year>2003</year>;<volume>10</volume>: <fpage>589</fpage>–<lpage>595</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03196519" xlink:type="simple">10.3758/BF03196519</ext-link></comment> <object-id pub-id-type="pmid">14620351</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>. <article-title>Normalization as a canonical neural computation</article-title>. <source>Nat Rev Neurosci</source>. <year>2011</year>;<volume>13</volume>: <fpage>51</fpage>–<lpage>62</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn3136" xlink:type="simple">10.1038/nrn3136</ext-link></comment> <object-id pub-id-type="pmid">22108672</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>. <article-title>Noise in Neural Populations Accounts for Errors in Working Memory</article-title>. <source>J Neurosci</source>. <year>2014</year>;<volume>34</volume>: <fpage>3632</fpage>–<lpage>3645</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3204-13.2014" xlink:type="simple">10.1523/JNEUROSCI.3204-13.2014</ext-link></comment> <object-id pub-id-type="pmid">24599462</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schneegans</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>. <article-title>Neural Architecture for Feature Binding in Visual Working Memory</article-title>. <source>J Neurosci</source>. <year>2017</year>;<volume>37</volume>: <fpage>3913</fpage>–<lpage>3925</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3493-16.2017" xlink:type="simple">10.1523/JNEUROSCI.3493-16.2017</ext-link></comment> <object-id pub-id-type="pmid">28270569</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kahneman</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Treisman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Gibbs</surname> <given-names>BJ</given-names></name>. <article-title>The reviewing of object files: object-specific integration of information</article-title>. <source>Cognit Psychol</source>. <year>1992</year>;<volume>24</volume>: <fpage>175</fpage>–<lpage>219</lpage>. <object-id pub-id-type="pmid">1582172</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Treisman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>W</given-names></name>. <article-title>Location and binding in visual working memory</article-title>. <source>Mem Cognit</source>. <year>2006</year>;<volume>34</volume>: <fpage>1704</fpage>–<lpage>1719</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03195932" xlink:type="simple">10.3758/BF03195932</ext-link></comment> <object-id pub-id-type="pmid">17489296</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boduroglu</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Shah</surname> <given-names>P</given-names></name>. <article-title>Effects of spatial configurations on visual change detection: An account of bias changes</article-title>. <source>Mem Cognit</source>. <year>2009</year>;<volume>37</volume>: <fpage>1120</fpage>–<lpage>1131</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/MC.37.8.1120" xlink:type="simple">10.3758/MC.37.8.1120</ext-link></comment> <object-id pub-id-type="pmid">19933456</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hollingworth</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rasmussen</surname> <given-names>IP</given-names></name>. <article-title>Binding objects to locations: the relationship between object files and visual working memory</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>2010</year>;<volume>36</volume>: <fpage>543</fpage>–<lpage>564</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0017836" xlink:type="simple">10.1037/a0017836</ext-link></comment> <object-id pub-id-type="pmid">20515188</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zimmer</surname> <given-names>HD</given-names></name>. <article-title>Spatial information with pictures and words in visual short-term memory</article-title>. <source>Psychol Res</source>. <year>1998</year>;<volume>61</volume>: <fpage>277</fpage>–<lpage>284</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s004260050032" xlink:type="simple">10.1007/s004260050032</ext-link></comment> <object-id pub-id-type="pmid">9870295</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zimmer</surname> <given-names>HD</given-names></name>, <name name-style="western"><surname>Lehnert</surname> <given-names>G</given-names></name>. <article-title>The spatial mismatch effect is based on global configuration and not on perceptual records within the visual cache</article-title>. <source>Psychol Res</source>. <year>2006</year>;<volume>70</volume>: <fpage>1</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00426-004-0186-5" xlink:type="simple">10.1007/s00426-004-0186-5</ext-link></comment> <object-id pub-id-type="pmid">15503130</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Byrne</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Becker</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Burgess</surname> <given-names>N</given-names></name>. <article-title>Remembering the past and imagining the future: a neural model of spatial memory and imagery</article-title>. <source>Psychol Rev</source>. <year>2007</year>;<volume>114</volume>: <fpage>340</fpage>–<lpage>375</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.114.2.340" xlink:type="simple">10.1037/0033-295X.114.2.340</ext-link></comment> <object-id pub-id-type="pmid">17500630</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goodale</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Milner</surname> <given-names>AD</given-names></name>. <article-title>Separate visual pathways for perception and action</article-title>. <source>Trends Neurosci</source>. <year>1992</year>;<volume>15</volume>: <fpage>20</fpage>–<lpage>25</lpage>. <object-id pub-id-type="pmid">1374953</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schenk</surname> <given-names>T.</given-names></name> <article-title>An allocentric rather than perceptual deficit in patient D.F</article-title>. <source>Nat Neurosci</source>. <year>2006</year>;<volume>9</volume>: <fpage>1369</fpage>–<lpage>1370</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1784" xlink:type="simple">10.1038/nn1784</ext-link></comment> <object-id pub-id-type="pmid">17028584</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carey</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Dijkerman</surname> <given-names>HC</given-names></name>, <name name-style="western"><surname>Murphy</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Goodale</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Milner</surname> <given-names>AD</given-names></name>. <article-title>Pointing to places and spaces in a patient with visual form agnosia</article-title>. <source>Neuropsychologia</source>. <year>2006</year>;<volume>44</volume>: <fpage>1584</fpage>–<lpage>1594</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuropsychologia.2006.01.024" xlink:type="simple">10.1016/j.neuropsychologia.2006.01.024</ext-link></comment> <object-id pub-id-type="pmid">16527317</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Merigan</surname> <given-names>WH</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JH</given-names></name>. <article-title>How parallel are the primate visual pathways?</article-title> <source>Annu Rev Neurosci</source>. <year>1993</year>;<volume>16</volume>: <fpage>369</fpage>–<lpage>402</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.ne.16.030193.002101" xlink:type="simple">10.1146/annurev.ne.16.030193.002101</ext-link></comment> <object-id pub-id-type="pmid">8460898</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Milner</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Goodale</surname> <given-names>MA</given-names></name>. <article-title>Two visual systems re-viewed</article-title>. <source>Neuropsychologia</source>. <year>2008</year>;<volume>46</volume>: <fpage>774</fpage>–<lpage>785</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuropsychologia.2007.10.005" xlink:type="simple">10.1016/j.neuropsychologia.2007.10.005</ext-link></comment> <object-id pub-id-type="pmid">18037456</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Connor</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Knierim</surname> <given-names>JJ</given-names></name>. <article-title>Integration of objects and space in perception and memory</article-title>. <source>Nat Neurosci</source>. <year>2017</year>;<volume>20</volume>: <fpage>1493</fpage>–<lpage>1503</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4657" xlink:type="simple">10.1038/nn.4657</ext-link></comment> <object-id pub-id-type="pmid">29073645</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Freud</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Plaut</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Behrmann</surname> <given-names>M</given-names></name>. <article-title>‘What’ Is Happening in the Dorsal Visual Pathway</article-title>. <source>Trends Cogn Sci</source>. <year>2016</year>;<volume>20</volume>: <fpage>773</fpage>–<lpage>784</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2016.08.003" xlink:type="simple">10.1016/j.tics.2016.08.003</ext-link></comment> <object-id pub-id-type="pmid">27615805</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schenk</surname> <given-names>T.</given-names></name> <article-title>Visuomotor robustness is based on integration not segregation</article-title>. <source>Vision Res</source>. <year>2010</year>;<volume>50</volume>: <fpage>2627</fpage>–<lpage>2632</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2010.08.013" xlink:type="simple">10.1016/j.visres.2010.08.013</ext-link></comment> <object-id pub-id-type="pmid">20723556</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Crawford</surname> <given-names>JD</given-names></name>. <article-title>Cortical Activation during Landmark-Centered vs. Gaze-Centered Memory of Saccade Targets in the Human: An FMRI Study</article-title>. <source>Front Syst Neurosci</source>. <year>2017</year>;<volume>11</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnsys.2017.00044" xlink:type="simple">10.3389/fnsys.2017.00044</ext-link></comment> <object-id pub-id-type="pmid">28690501</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Monaco</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Byrne</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Yan</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Henriques</surname> <given-names>DYP</given-names></name>, <name name-style="western"><surname>Crawford</surname> <given-names>JD</given-names></name>. <article-title>Allocentric versus Egocentric Representation of Remembered Reach Targets in Human Cortex</article-title>. <source>J Neurosci</source>. <year>2014</year>;<volume>34</volume>: <fpage>12515</fpage>–<lpage>12526</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1445-14.2014" xlink:type="simple">10.1523/JNEUROSCI.1445-14.2014</ext-link></comment> <object-id pub-id-type="pmid">25209289</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Committeri</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Galati</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Paradis</surname> <given-names>A-L</given-names></name>, <name name-style="western"><surname>Pizzamiglio</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Berthoz</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>LeBihan</surname> <given-names>D</given-names></name>. <article-title>Reference frames for spatial cognition: different brain areas are involved in viewer-, object-, and landmark-centered judgments about object location</article-title>. <source>J Cogn Neurosci</source>. <year>2004</year>;<volume>16</volume>: <fpage>1517</fpage>–<lpage>1535</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/0898929042568550" xlink:type="simple">10.1162/0898929042568550</ext-link></comment> <object-id pub-id-type="pmid">15601516</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ekstrom</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Arnold</surname> <given-names>AEGF</given-names></name>, <name name-style="western"><surname>Iaria</surname> <given-names>G</given-names></name>. <article-title>A critical review of the allocentric spatial representation and its neural underpinnings: toward a network-based perspective</article-title>. <source>Front Hum Neurosci</source>. <year>2014</year>;<volume>8</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2014.00803" xlink:type="simple">10.3389/fnhum.2014.00803</ext-link></comment> <object-id pub-id-type="pmid">25346679</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Neggers</surname> <given-names>SFW</given-names></name>, <name name-style="western"><surname>Van der Lubbe</surname> <given-names>RHJ</given-names></name>, <name name-style="western"><surname>Ramsey</surname> <given-names>NF</given-names></name>, <name name-style="western"><surname>Postma</surname> <given-names>A</given-names></name>. <article-title>Interactions between ego- and allocentric neuronal representations of space</article-title>. <source>NeuroImage</source>. <year>2006</year>;<volume>31</volume>: <fpage>320</fpage>–<lpage>331</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2005.12.028" xlink:type="simple">10.1016/j.neuroimage.2005.12.028</ext-link></comment> <object-id pub-id-type="pmid">16473025</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thaler</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Goodale</surname> <given-names>MA</given-names></name>. <article-title>The Role of Online Visual Feedback for the Control of Target-Directed and Allocentric Hand Movements</article-title>. <source>J Neurophysiol</source>. <year>2011</year>;<volume>105</volume>: <fpage>846</fpage>–<lpage>859</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00743.2010" xlink:type="simple">10.1152/jn.00743.2010</ext-link></comment> <object-id pub-id-type="pmid">21160005</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref074"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ekstrom</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Huffman</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Starrett</surname> <given-names>M</given-names></name>. <article-title>Interacting networks of brain regions underlie human spatial navigation: a review and novel synthesis of the literature</article-title>. <source>J Neurophysiol</source>. <year>2017</year>;<volume>118</volume>: <fpage>3328</fpage>–<lpage>3344</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00531.2017" xlink:type="simple">10.1152/jn.00531.2017</ext-link></comment> <object-id pub-id-type="pmid">28931613</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref075"><label>75</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holdstock</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Mayes</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Cezayirli</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Isaac</surname> <given-names>CL</given-names></name>, <name name-style="western"><surname>Aggleton</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Roberts</surname> <given-names>N</given-names></name>. <article-title>A comparison of egocentric and allocentric spatial memory in a patient with selective hippocampal damage</article-title>. <source>Neuropsychologia</source>. <year>2000</year>;<volume>38</volume>: <fpage>410</fpage>–<lpage>425</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0028-3932(99)00099-8" xlink:type="simple">10.1016/S0028-3932(99)00099-8</ext-link></comment> <object-id pub-id-type="pmid">10683392</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref076"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Julian</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Keinath</surname> <given-names>AT</given-names></name>, <name name-style="western"><surname>Frazzetta</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Epstein</surname> <given-names>RA</given-names></name>. <article-title>Human entorhinal cortex represents visual space using a boundary-anchored grid</article-title>. <source>Nat Neurosci</source>. <year>2018</year>; <fpage>1</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41593-017-0049-1" xlink:type="simple">10.1038/s41593-017-0049-1</ext-link></comment> <object-id pub-id-type="pmid">29311745</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref077"><label>77</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kravitz</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Saleem</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Baker</surname> <given-names>CI</given-names></name>, <name name-style="western"><surname>Mishkin</surname> <given-names>M</given-names></name>. <article-title>A new neural framework for visuospatial processing</article-title>. <source>Nat Rev Neurosci</source>. <year>2011</year>;<volume>12</volume>: <fpage>217</fpage>–<lpage>230</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn3008" xlink:type="simple">10.1038/nrn3008</ext-link></comment> <object-id pub-id-type="pmid">21415848</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref078"><label>78</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nau</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schröder</surname> <given-names>TN</given-names></name>, <name name-style="western"><surname>Bellmund</surname> <given-names>JLS</given-names></name>, <name name-style="western"><surname>Doeller</surname> <given-names>CF</given-names></name>. <article-title>Hexadirectional coding of visual space in human entorhinal cortex</article-title>. <source>Nat Neurosci</source>. <year>2018</year>; <fpage>1</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41593-017-0050-8" xlink:type="simple">10.1038/s41593-017-0050-8</ext-link></comment> <object-id pub-id-type="pmid">29311746</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref079"><label>79</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rajsic</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>DE</given-names></name>. <article-title>Asymmetrical access to color and location in visual working memory</article-title>. <source>Atten Percept Psychophys</source>. <year>2014</year>;<volume>76</volume>: <fpage>1902</fpage>–<lpage>1913</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13414-014-0723-2" xlink:type="simple">10.3758/s13414-014-0723-2</ext-link></comment> <object-id pub-id-type="pmid">25190322</object-id></mixed-citation></ref>
<ref id="pcbi.1006563.ref080"><label>80</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Ghahramani</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>. <chapter-title>Computational models of sensorimotor integration</chapter-title>. In: <name name-style="western"><surname>Morasso</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Sanguineti</surname> <given-names>V</given-names></name>, editors. <source>Advances in Psychology</source>. <publisher-name>North-Holland</publisher-name>; <year>1997</year>. pp. <fpage>117</fpage>–<lpage>147</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0166-4115(97)80006-4" xlink:type="simple">10.1016/S0166-4115(97)80006-4</ext-link></comment></mixed-citation></ref>
</ref-list>
</back>
</article>
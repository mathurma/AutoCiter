<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">plos</journal-id>
      <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
      <journal-id journal-id-type="pmc">ploscomp</journal-id>
      <journal-title-group>
        <journal-title>PLoS Computational Biology</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1553-734X</issn>
      <issn pub-type="epub">1553-7358</issn>
      <publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">PCOMPBIOL-D-12-00846</article-id>
      <article-id pub-id-type="doi">10.1371/journal.pcbi.1002889</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Computational biology</subject>
            <subj-group>
              <subject>Computational neuroscience</subject>
              <subj-group>
                <subject>Sensory systems</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computational Biology</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Temporal Adaptation Enhances Efficient Contrast Gain Control on Natural Images</article-title>
        <alt-title alt-title-type="running-head">Contrast Gain Control on Natural Images</alt-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Sinz</surname>
            <given-names>Fabian</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Bethge</surname>
            <given-names>Matthias</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <label>1</label>
        <addr-line>Department for Neuroethology, University Tübingen, Tübingen, Germany</addr-line>
      </aff>
      <aff id="aff2">
        <label>2</label>
        <addr-line>Werner Reichardt Centre for Integrative Neuroscience, University of Tübingen, Tübingen, Germany</addr-line>
      </aff>
      <aff id="aff3">
        <label>3</label>
        <addr-line>Bernstein Center for Computational Neuroscience, Tübingen, Germany</addr-line>
      </aff>
      <contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Maloney</surname>
            <given-names>Laurence T.</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group>
      <aff id="edit1">
        <addr-line>New York University, United States of America</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">fabian.sinz@bethgelab.org</email></corresp>
        <fn fn-type="conflict">
          <p>The authors have declared that no competing interests exist.</p>
        </fn>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: FS MB. Performed the experiments: FS. Analyzed the data: FS. Contributed reagents/materials/analysis tools: FS MB. Wrote the paper: FS MB.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="collection">
        <month>1</month>
        <year>2013</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>31</day>
        <month>1</month>
        <year>2013</year>
      </pub-date>
      <volume>9</volume>
      <issue>1</issue>
      <elocation-id>e1002889</elocation-id>
      <history>
        <date date-type="received">
          <day>23</day>
          <month>5</month>
          <year>2012</year>
        </date>
        <date date-type="accepted">
          <day>4</day>
          <month>12</month>
          <year>2012</year>
        </date>
      </history>
      <permissions>
        <copyright-year>2013</copyright-year>
        <copyright-holder>Sinz, Bethge</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>Divisive normalization in primary visual cortex has been linked to adaptation to natural image statistics in accordance to Barlow's redundancy reduction hypothesis. Using recent advances in natural image modeling, we show that the previously studied static model of divisive normalization is rather inefficient in reducing local contrast correlations, but that a simple temporal contrast adaptation mechanism of the half-saturation constant can substantially increase its efficiency. Our findings reveal the experimentally observed temporal dynamics of divisive normalization to be critical for redundancy reduction.</p>
      </abstract>
      <abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>The redundancy reduction hypothesis postulates that neural representations adapt to sensory input statistics such that their responses become as statistically independent as possible. Based on this hypothesis, many properties of early visual neurons—like orientation selectivity or divisive normalization—have been linked to natural image statistics. Divisive normalization, in particular, models a widely observed neural response property: The divisive inhibition of a single neuron by a pool of others. This mechanism has been shown to reduce the redundancy among neural responses to typical contrast dependencies in natural images. Here, we show that the standard model of divisive normalization achieves substantially less redundancy reduction than a theoretically optimal mechanism called <italic>radial factorization</italic>. On the other hand, we find that radial factorization is inconsistent with existing neurophysiological observations. As a solution we suggest a new physiologically plausible modification of the standard model which accounts for the dynamics of the visual input by adapting to local contrasts during fixations. In this way the dynamic version of the standard model achieves almost optimal redundancy reduction performance. Our results imply that the dynamics of natural viewing conditions are critical for testing the role of divisive normalization for redundancy reduction.</p>
      </abstract>
      <funding-group>
        <funding-statement>This study was financially supported by the German Ministry of Education, Science, Research and Technology through the Bernstein award (BMBF; FKZ: 01GQ0601). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
      </funding-group>
      <counts>
        <page-count count="13"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>It is a long-standing hypothesis that the computational goal of the early visual processing stages is to reduce redundancies which are abundantly present in natural sensory signals <xref ref-type="bibr" rid="pcbi.1002889-Barlow1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Simoncelli1">[2]</xref>. Redundancy reduction is a general information theoretic principle that plays an important role for many possible goals of sensory systems like maximizing the amount of information between stimulus and neural response <xref ref-type="bibr" rid="pcbi.1002889-Bell1">[3]</xref>, obtaining a probabilistic model of sensory signals <xref ref-type="bibr" rid="pcbi.1002889-Barlow2">[4]</xref>, or learning a representation of hidden causes <xref ref-type="bibr" rid="pcbi.1002889-Bell1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Lewicki1">[5]</xref>. For a population of neurons, redundancy reduction predicts that neuronal responses should be made as statistically independent from each other as possible <xref ref-type="bibr" rid="pcbi.1002889-Simoncelli1">[2]</xref>.</p>
      <p>Many prominent neural response properties such as receptive field structure or contrast gain control have been linked to redundancy reduction on natural images <xref ref-type="bibr" rid="pcbi.1002889-Simoncelli1">[2]</xref>. While an appropriate structure of linear receptive fields can always remove all redundancies caused by second order correlations, they have only little effect on the reduction of higher order statistical dependencies <xref ref-type="bibr" rid="pcbi.1002889-Bethge1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Eichhorn1">[7]</xref>. However, one of the most prominent contrast gain control mechanisms—divisive normalization—has been demonstrated to reduce higher order correlations on natural images and sound <xref ref-type="bibr" rid="pcbi.1002889-Heeger1">[8]</xref>–<xref ref-type="bibr" rid="pcbi.1002889-Carandini1">[10]</xref>. Its central mechanism is a divisive rescaling of a single neuron's activity by that of a pool of other neurons <xref ref-type="bibr" rid="pcbi.1002889-Heeger1">[8, see also Figure 1a]</xref>.</p>
      <p>Recently, <italic>radial factorization</italic> and <italic>radial Gaussianization</italic> have been derived independently by <xref ref-type="bibr" rid="pcbi.1002889-Sinz1">[11]</xref> and <xref ref-type="bibr" rid="pcbi.1002889-Lyu1">[12]</xref>, respectively, based on Barlow's redundancy reduction principle <xref ref-type="bibr" rid="pcbi.1002889-Barlow1">[1]</xref>. Both mechanisms share with divisive normalization the two main functional components, linear filtering and rescaling and have been shown to be the unique and optimal redundancy reduction mechanism for this class of transformations under certain symmetry assumptions for the data. Radial factorization is optimal for a more general symmetry class than radial Gaussianization <xref ref-type="bibr" rid="pcbi.1002889-Sinz1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Sinz2">[13]</xref> and contains radial Gaussianization as a special case. As a consequence, radial factorization can achieve slightly better redundancy reduction for natural images than radial Gaussianization but the advantage is very small.</p>
      <p>Here, we compare the redundancy reduction performance of divisive normalization to that of radial factorization in order to see to what extent divisive normalization can serve the goal of redundancy reduction. Our comparison shows that a non-adapting <italic>static</italic> divisive normalization is not powerful enough to capture the contrast dependencies of natural images. Furthermore, we show that (i) the shape of contrast response curves predicted by radial factorization is not consistent with that found in physiological recordings, and (ii) that for a <italic>static</italic> divisive normalization mechanism this inconsistency is a necessary consequence of strong redundancy reduction. Finally, we demonstrate that a <italic>dynamic</italic> adaptation of the half-saturation constant in divisive normalization may provide a physiologically plausible mechanism that can achieve close to optimal performance. Our proposed adaptation mechanism works via horizontal shifts of the contrast response curve along the log-contrast axis. Such shifts have been observed in experiments in response to a change of the ambient contrast level <xref ref-type="bibr" rid="pcbi.1002889-Bonds1">[14]</xref>.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Measures, Models, Mechanisms</title>
        <p>We now briefly introduce divisive normalization, radial factorization, and the information theoretic measure of redundancy used in this study.</p>
        <sec id="s2a1">
          <title>Redundancy reduction and multi-information</title>
          <p>We consider a population of sensory neurons that transforms natural image patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e001" xlink:type="simple"/></inline-formula> into a set of neural activities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e002" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e003" xlink:type="simple"/></inline-formula>. We always use <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e004" xlink:type="simple"/></inline-formula> to denote responses to linear filters, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e005" xlink:type="simple"/></inline-formula> for the output of divisive normalization or radial factorization. The goal of redundancy reduction is to remove statistical dependencies between the single coefficients of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e006" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e007" xlink:type="simple"/></inline-formula>.</p>
          <p>Redundancy is quantified by the information theoretic measure called <italic>multi-information</italic><disp-formula id="pcbi.1002889.e008"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e008" xlink:type="simple"/><label>(1)</label></disp-formula>which measures how much the representation differs from having independent components. More precisely, the multi-information is the Kullback-Leibler divergence between the joint distribution and the product of its marginals or, equivalently, the difference between the sum of the marginal entropies and the joint entropy. In case of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e009" xlink:type="simple"/></inline-formula> this equals the better known mutual information. If the different entries of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e010" xlink:type="simple"/></inline-formula> are independent, then its joint distribution equals the product of the single marginals or–-equivalently–-the joint entropy equals the sum of the marginal entropies. Thus, the multi-information is zero if and only if the different dimensions of the random vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e011" xlink:type="simple"/></inline-formula> are independent, and positive otherwise. In summary, the multi-information measures all kinds of statistical dependencies among the single coefficients of a random vector. In the <xref ref-type="sec" rid="s4">Methods</xref> Section, we describe how we estimate the multi-information for the various signals considered here.</p>
        </sec>
        <sec id="s2a2">
          <title>Divisive normalization</title>
          <p>From all existing divisive normalization models considered previously in the literature, ours is most closely related to the one used by Schwartz and Simoncelli <xref ref-type="bibr" rid="pcbi.1002889-Schwartz1">[9]</xref>. It consists of two main components: a linear filtering step and a rescaling step based on the Euclidean norm of the filter responses<disp-formula id="pcbi.1002889.e012"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e012" xlink:type="simple"/><label>(2)</label></disp-formula>While the linear filters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e013" xlink:type="simple"/></inline-formula> capture the receptive field properties, the rescaling step captures the nonlinear interactions between the single neurons. Most divisive normalization models use filters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e014" xlink:type="simple"/></inline-formula> that resemble the receptive fields of complex cells <xref ref-type="bibr" rid="pcbi.1002889-Schwartz1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Hyvrinen1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Hyvrinen2">[16]</xref>. Therefore, we use filters obtained from training an <italic>Independent Subspace Analysis (ISA)</italic> on a large collection of randomly sampled image patches <xref ref-type="bibr" rid="pcbi.1002889-Hyvrinen1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Hyvrinen2">[16, see also Methods]</xref>. ISA can be seen as a redundancy reduction transform whose outputs are computed by the complex cell energy model <xref ref-type="bibr" rid="pcbi.1002889-Pollen1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Adelson1">[18]</xref>. For this study, the algorithm has the advantage that it not only yields complex cell-like filter shapes, but also ensures that single filter responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e015" xlink:type="simple"/></inline-formula> are decorrelated and already optimized for statistical independence. This ensures that the redundancies removed by divisive normalization and radial factorization are the ones that cannot be removed by the choice of linear filters <xref ref-type="bibr" rid="pcbi.1002889-Eichhorn1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Sinz3">[19]</xref>.</p>
          <p>Several divisive normalization models exist in the literature. They differ, for instance, by whether a unit <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e016" xlink:type="simple"/></inline-formula> is contained in its own normalization pool, or in the exact form of the rescaling function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e017" xlink:type="simple"/></inline-formula> also known as <italic>Naka-Rushton function</italic>. From the viewpoint of redundancy reduction, the former distinction between models is irrelevant because the influence of a single unit on its normalization pool can always be removed by the elementwise invertible transformation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e018" xlink:type="simple"/></inline-formula> which does not change the redundancies between the responses <xref ref-type="bibr" rid="pcbi.1002889-Lyu2">[20]</xref> (the multi-information is invariant with respect to elementwise invertible transformations). Sometimes, a more general form of the Naka-Rushton function is found in the literature which uses different types of exponents<disp-formula id="pcbi.1002889.e019"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e019" xlink:type="simple"/><label>(3)</label></disp-formula>The divisive normalization model considered in this study (<xref ref-type="disp-formula" rid="pcbi.1002889.e012">equation (2)</xref>) differs from this more general version by the type of the norm used for rescaling the single responses: Where <xref ref-type="disp-formula" rid="pcbi.1002889.e019">equation (3)</xref> uses the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e020" xlink:type="simple"/></inline-formula>-norm <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e021" xlink:type="simple"/></inline-formula> we use the Euclidean norm. Because radial factorization is defined for the more general <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e022" xlink:type="simple"/></inline-formula>-norm (see <xref ref-type="sec" rid="s4">Methods</xref>), all analyses in this paper could be carried out for this more general transform. However, we instead chose to use the Euclidean norm for simplicity and to make our model more comparable to the ones most commonly used in redundancy reduction studies of divisive normalization <xref ref-type="bibr" rid="pcbi.1002889-Schwartz1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Lyu2">[20]</xref>–<xref ref-type="bibr" rid="pcbi.1002889-Wainwright2">[22]</xref>.</p>
          <p>Also note that the Naka-Rushton function is often defined as the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e023" xlink:type="simple"/></inline-formula>th power of <xref ref-type="disp-formula" rid="pcbi.1002889.e019">equation (3)</xref>. However, the form of <xref ref-type="disp-formula" rid="pcbi.1002889.e019">equation (3)</xref> is more common in redundancy reduction studies in order to maintain the sign of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e024" xlink:type="simple"/></inline-formula>. We mention the consequences of this choice in the discussion.</p>
        </sec>
        <sec id="s2a3">
          <title>Radial factorization</title>
          <p>Radial factorization is an optimal radial rescaling for redundancy reduction. We will now briefly introduce radial factorization starting from divisive normalization. For more mathematical details see the <xref ref-type="sec" rid="s4">Methods</xref> Section.</p>
          <p>On a population level, the rescaling step of divisive normalization is a nonlinear mapping that changes the Euclidean radius of the filter response population. This can be seen by decomposing divisive normalization into two multiplicative terms<disp-formula id="pcbi.1002889.e025"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e025" xlink:type="simple"/><label>(4)</label></disp-formula>The second term normalizes the response vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e026" xlink:type="simple"/></inline-formula> to length one while the Naka-Rushton function in the first term determines the new radius. Since the rescaling <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e027" xlink:type="simple"/></inline-formula> depends only on the norm, the new radius does not depend on any specific direction of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e028" xlink:type="simple"/></inline-formula>.</p>
          <p>The redundancy between the coefficients of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e029" xlink:type="simple"/></inline-formula> is determined by three factors: The statistics of natural image patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e030" xlink:type="simple"/></inline-formula> which—together with the choice of filters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e031" xlink:type="simple"/></inline-formula>—determine the statistics of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e032" xlink:type="simple"/></inline-formula>, and the radial transformation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e033" xlink:type="simple"/></inline-formula>. If we allow the radial transformation to be a general invertible transform <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e034" xlink:type="simple"/></inline-formula> on the Euclidean norm, we can now ask how the different model components can be chosen in order to minimize the redundancy in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e035" xlink:type="simple"/></inline-formula>.</p>
          <p>A substantial part of the redundancies in natural images are second order correlations, which can be removed by linear filters during <italic>whitening</italic> <xref ref-type="bibr" rid="pcbi.1002889-Bethge1">[6]</xref>. Whitening does not completely determine the filters since the data can always be rotated afterwards and still stay decorrelated. Higher order decorrelation algorithms like <italic>independent component analysis</italic> use this rotational degree of freedom to decrease higher order dependencies in the filter responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e036" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002889-Bell1">[3]</xref>. However, there is no set of filters that could remove all statistical dependencies from natural images <xref ref-type="bibr" rid="pcbi.1002889-Bethge1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Eichhorn1">[7]</xref>, because whitened natural images exhibit an approximately spherical but non-Gaussian joint distribution <xref ref-type="bibr" rid="pcbi.1002889-Eichhorn1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Wainwright1">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Field1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Ruderman1">[24]</xref>. Since spherical symmetry is invariant under rotation and because the only spherically symmetric factorial distribution is the Gaussian distribution <xref ref-type="bibr" rid="pcbi.1002889-Sinz2">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Kac1">[25]</xref>, the marginals cannot be independent.</p>
          <p>Hence, the remaining dependencies must be removed by nonlinear mechanisms like an appropriate radial transformation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e037" xlink:type="simple"/></inline-formula>. Fortunately, the joint spherically symmetric distribution of the filter responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e038" xlink:type="simple"/></inline-formula> already dictates a unique and optimal way to choose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e039" xlink:type="simple"/></inline-formula>: Since a rescaling with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e040" xlink:type="simple"/></inline-formula> will necessarily result in a spherically symmetric distribution again, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e041" xlink:type="simple"/></inline-formula> must be chosen such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e042" xlink:type="simple"/></inline-formula> is jointly Gaussian distributed. Therefore, we need to choose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e043" xlink:type="simple"/></inline-formula> such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e044" xlink:type="simple"/></inline-formula> follows the radial distribution of a Gaussian or, in other words, a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e045" xlink:type="simple"/></inline-formula>-distribution. This is a central point for our study: For a spherically symmetric distribution the univariate distribution on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e046" xlink:type="simple"/></inline-formula> determines higher order dependencies in the multi-variate joint distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e047" xlink:type="simple"/></inline-formula>. This means that if we restrict ourselves to radial transformations, it is sufficient to look at radial distributions only. The fact that the Gaussian is the only spherically symmetric factorial distribution implies that the coefficients in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e048" xlink:type="simple"/></inline-formula> can only be statistically independent if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e049" xlink:type="simple"/></inline-formula> follows radial <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e050" xlink:type="simple"/></inline-formula>-distribution. <italic>Radial factorization</italic> finds a transformation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e051" xlink:type="simple"/></inline-formula> which achieves exactly that by using histogram equalization on the distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e052" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002889-Sinz1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Lyu1">[12, see also Methods]</xref>. All these considerations also hold for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e053" xlink:type="simple"/></inline-formula>-spherically symmetric distributions <xref ref-type="bibr" rid="pcbi.1002889-Sinz1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Sinz2">[13]</xref>.</p>
          <p>Note that this does not imply that the neural responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e054" xlink:type="simple"/></inline-formula> must follow a Gaussian distribution if they are to be independent because the distribution of the single responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e055" xlink:type="simple"/></inline-formula> can always be altered by applying an elementwise invertible transformation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e056" xlink:type="simple"/></inline-formula> without changing the redundancy. The above considerations only mean that given the two main model components of divisive normalization (and the assumption of spherical symmetry), the best we can do is to choose the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e057" xlink:type="simple"/></inline-formula> to be whitening filters and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e058" xlink:type="simple"/></inline-formula> according to radial factorization.</p>
        </sec>
        <sec id="s2a4">
          <title>Radial factorization and divisive normalization are not equivalent</title>
          <p>The goal of this study is to compare the redundancy reduction achieved by divisive normalization and radial factorization. Apart from all similarities between the two models, there is a profound mathematical difference showing that the two mechanisms are not equivalent (as noted by <xref ref-type="bibr" rid="pcbi.1002889-Lyu1">[12]</xref>).</p>
          <p>Both mechanisms have the form<disp-formula id="pcbi.1002889.e059"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e059" xlink:type="simple"/></disp-formula>However, the radial rescalings of radial factorization and that of divisive normalization, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e060" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e061" xlink:type="simple"/></inline-formula>, have a different range. Since the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e062" xlink:type="simple"/></inline-formula>-distribution is non-zero on all of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e063" xlink:type="simple"/></inline-formula> the range of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e064" xlink:type="simple"/></inline-formula> must be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e065" xlink:type="simple"/></inline-formula> as well. However, in case of divisive normalization, the Naka-Rushton function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e066" xlink:type="simple"/></inline-formula> saturates at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e067" xlink:type="simple"/></inline-formula>. This means that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e068" xlink:type="simple"/></inline-formula> can never transform a radial distribution into a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e069" xlink:type="simple"/></inline-formula>-distribution since values beyond <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e070" xlink:type="simple"/></inline-formula> cannot be reached.</p>
          <p>While this implies that the two mechanisms are mathematically not equivalent, it could still be that they perform similarly on data if the probability mass of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e071" xlink:type="simple"/></inline-formula>-distribution in the range beyond <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e072" xlink:type="simple"/></inline-formula> is small. Therefore, we choose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e073" xlink:type="simple"/></inline-formula> to be the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e074" xlink:type="simple"/></inline-formula> quantile of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e075" xlink:type="simple"/></inline-formula>-distribution in all our experiments (see <xref ref-type="sec" rid="s4">Methods</xref>).</p>
        </sec>
        <sec id="s2a5">
          <title>Comparison of the redundancy reduction performance</title>
          <p>We compared the amount of redundancy removed by divisive normalization and radial factorization by measuring the multi-information in the plain filter responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e076" xlink:type="simple"/></inline-formula> and the normalized responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e077" xlink:type="simple"/></inline-formula> for a large collection of natural image patches (<xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1b</xref>). In both cases the parameters of the radial transformation were chosen to yield the best possible redundancy reduction performance (see <xref ref-type="sec" rid="s4">Methods</xref>). While both divisive normalization and radial factorization remove variance correlations (<xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1a</xref>), the residual amount of dependencies for divisive normalization is still approximately <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e078" xlink:type="simple"/></inline-formula> of the total redundancies removed by radial factorization (<xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1a–b</xref>). This demonstrates that divisive normalization is not optimally tailored to the statistics of natural images.</p>
          <fig id="pcbi-1002889-g001" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002889.g001</object-id>
            <label>Figure 1</label>
            <caption>
              <title>Redundancy reduction and radial distributions for different normalization models.</title>
              <p><bold>A</bold>: Divisive normalization model used in this study: Natural image patches are linearly filtered. These responses are nonlinearly transformed by divisive normalization or radial factorization (see text). After linear filtering the width of the conditional distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e079" xlink:type="simple"/></inline-formula> of two filter responses depends on the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e080" xlink:type="simple"/></inline-formula> (conditional log-histograms as contour plots). This demonstrates the presence of variance correlations. These dependencies are decreased by divisive normalization and radial factorization. <bold>B</bold>: Redundancy measured by multi-information after divisive normalization, extended divisive normalization, and radial factorization: divisive normalization leaves a substantial amount of residual redundancy (error bars show standard deviation over different datasets). <bold>C</bold>: Distributions on the norm of the filter responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e081" xlink:type="simple"/></inline-formula> for which divisive normalization (red) and extended divisive normalization (blue) are the optimal redundancy reducing mechanisms. The radial transformation of radial factorization and its corresponding distribution (mixture of five <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e082" xlink:type="simple"/></inline-formula>-distributions) is shown in black. While radial factorization (inset, black curve) and extended divisive normalization (inset, blue curve) achieve good redundancy reduction, they lead to physiologically implausibly shaped contrast response curves which are mainly determined by their respective radial transformations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e083" xlink:type="simple"/></inline-formula> shown in the inset. The radial transformation of divisive normalization is shown for comparison (inset, red curve).</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002889.g001" position="float" xlink:type="simple"/>
          </fig>
          <p>To understand this in more detail, we derived the distribution that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e084" xlink:type="simple"/></inline-formula> should have if divisive normalization were the optimal redundancy reducing mechanism and compared it to the empirical radial distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e085" xlink:type="simple"/></inline-formula> represented by a large collection of uniformly sampled patches from natural images. This optimal distribution for divisive normalization can be derived by transforming a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e086" xlink:type="simple"/></inline-formula>-distributed random variable with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e087" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">Methods</xref>). Since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e088" xlink:type="simple"/></inline-formula> has limited range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e089" xlink:type="simple"/></inline-formula> we actually have to use a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e090" xlink:type="simple"/></inline-formula>-distribution which is truncated at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e091" xlink:type="simple"/></inline-formula>. The parametric form of the resulting distribution is given in the <xref ref-type="sec" rid="s4">Methods</xref> Section. We refer to is as <italic>Naka-Rushton distribution</italic> in the following. The parameters of the Naka-Ruston distribution are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e092" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e093" xlink:type="simple"/></inline-formula>. Since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e094" xlink:type="simple"/></inline-formula> is already determined by fixing the range of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e095" xlink:type="simple"/></inline-formula> to the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e096" xlink:type="simple"/></inline-formula> quantile of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e097" xlink:type="simple"/></inline-formula>-distribution, the remaining free parameter is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e098" xlink:type="simple"/></inline-formula>. In the Naka-Rushton function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e099" xlink:type="simple"/></inline-formula> this parameter is called half-saturation constant and controls the horizontal position of the contrast response curve in model neurons.</p>
          <p>We fitted <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e100" xlink:type="simple"/></inline-formula> via maximum likelihood (see <xref ref-type="sec" rid="s4">Methods</xref>) and found that even for the best fitting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e101" xlink:type="simple"/></inline-formula> there is a pronounced mismatch between the Naka-Rushton distribution and the empirical distribution given by the histogram (<xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1c</xref>). This explains the insufficient redundancy reduction because the Naka-Rushton distribution expects most of the responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e102" xlink:type="simple"/></inline-formula> to fall into a much narrower range than responses to natural images do in reality. The Naka-Rushton function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e103" xlink:type="simple"/></inline-formula> would map the red radial density in <xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1c</xref> perfectly into a truncated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e104" xlink:type="simple"/></inline-formula>-distribution. However, it maps a profound part of the true radial distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e105" xlink:type="simple"/></inline-formula> (gray histogram) close to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e106" xlink:type="simple"/></inline-formula>, since this part is located to the right of the mode of the Naka-Rushton distribution where it expects almost no probability mass. Additionally, the Naka-Rushton distribution exhibits a small gap of almost zero probability around zero. This gap, however, also contains a portion of empirical distribution. This part gets mapped close to zero. To understand why this leaves significant redundancies, imagine the most extreme case in which all the probability mass of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e107" xlink:type="simple"/></inline-formula> would either be mapped onto <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e108" xlink:type="simple"/></inline-formula> or on onto <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e109" xlink:type="simple"/></inline-formula>. The corresponding distribution on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e110" xlink:type="simple"/></inline-formula> would consist of a point mass at zero and a spherical shell at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e111" xlink:type="simple"/></inline-formula>. Such a distribution would clearly exhibit strong dependencies.</p>
        </sec>
        <sec id="s2a6">
          <title>Augmenting divisive normalization by more parameters</title>
          <p>It is clear that the suboptimal redundancy reduction performance of divisive normalization is due to its restricted parametric form. Therefore, we explored two options how to increase its degrees of freedom and thereby its redundancy reduction performance: the first option endows static divisive normalization with additional parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e112" xlink:type="simple"/></inline-formula>, the second option allows for a dynamic temporal adaptation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e113" xlink:type="simple"/></inline-formula>.</p>
          <p>The simplest way to increase the degrees of freedom in divisive normalization is to introduce two additional parameters in the Naka-Rushton function<disp-formula id="pcbi.1002889.e114"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e114" xlink:type="simple"/></disp-formula>These parameters allow for more flexibility in the scale and shape of the corresponding Naka-Rushton distribution. We label all models that use this parametrization as <italic>extended</italic> in the following. Note that the extended Naka-Rushton function only saturates for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e115" xlink:type="simple"/></inline-formula>. This means that it could in principle transform <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e116" xlink:type="simple"/></inline-formula> into <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e117" xlink:type="simple"/></inline-formula> such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e118" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e119" xlink:type="simple"/></inline-formula>-distributed. For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e120" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e121" xlink:type="simple"/></inline-formula>, the original Naka-Rushton function is recovered. As before, we derived the corresponding extended Naka-Rushton distribution by transforming a (truncated) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e122" xlink:type="simple"/></inline-formula>-distributed random variable with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e123" xlink:type="simple"/></inline-formula>. We fitted the resulting distribution to a large collection of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e124" xlink:type="simple"/></inline-formula>, used the maximum likelihood parameters for extended divisive normalization, and measured the redundancy via multi-information in the resulting normalized responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e125" xlink:type="simple"/></inline-formula>.</p>
          <p>We found that an extended divisive normalization transform achieves substantially more redundancy reduction and that the extended Naka-Rushton distribution on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e126" xlink:type="simple"/></inline-formula> fits the image data significantly better (<xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1b–c</xref>). However, we also find that the best extended Naka-Rushton function for redundancy reduction would yield biologically implausible contrast response curves which capture the firing rate of a neuron upon stimulation with gratings of different contrast at the neuron's preferred spatial frequency and orientation.</p>
          <p>In the divisive normalization and the radial factorization model, the shape of the contrast response curve is determined by the shape of the radial rescaling function (<xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1c</xref>, inset) <xref ref-type="bibr" rid="pcbi.1002889-Heeger1">[8]</xref>. In contrast to the normal Naka-Rushton function (<xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1c</xref>, inset, red curve), the extended version (<xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1c</xref>, inset, blue curve) exhibits a physiologically unreasonable shape: it starts at a non-zero value, increases without saturation, and does not resemble any sigmoidal shape at all. The non-zero level for low contrasts is a direct consequence of the optimization for redundancy reduction: redundancy reduction implies that the target radial distribution is a (truncated) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e127" xlink:type="simple"/></inline-formula>-distribution which has only very little probability mass close to zero. Therefore, the radial rescaling function must map the substantial portion of low contrast values in the empirical distribution upwards in order to match the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e128" xlink:type="simple"/></inline-formula>-distribution. This results in the immediate non-zero onset. This is a pronounced mismatch to the typical contrast response curves measured in cortical neurons (see <xref ref-type="fig" rid="pcbi-1002889-g002">Figure 2</xref> in <xref ref-type="bibr" rid="pcbi.1002889-Bonds1">[14]</xref>). In fact, the addition of more parameters merely leads to a contrast response curve which is more similar to radial factorization (<xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1</xref>, inset, black) which does not have a plausible shape, too. Therefore, we dismiss the option of adding more parameters to the Naka-Rushton function and turn to the option in which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e129" xlink:type="simple"/></inline-formula> is allowed to dynamically adapt to the ambient contrast level.</p>
          <fig id="pcbi-1002889-g002" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002889.g002</object-id>
            <label>Figure 2</label>
            <caption>
              <title>Simulated eye movements and adapted contrast distributions.</title>
              <p><bold>A</bold>: Simulated eye movements on a image from the van Hateren database <xref ref-type="bibr" rid="pcbi.1002889-VanHateren1">[31]</xref>. Local microsaccades are simulated with Brownian motion with a standard deviation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e130" xlink:type="simple"/></inline-formula>px. In this example, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e131" xlink:type="simple"/></inline-formula> patches are extracted around the fixation location and whitened. <bold>B</bold>: Values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e132" xlink:type="simple"/></inline-formula> for the extracted patches plotted along the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e133" xlink:type="simple"/></inline-formula>-axis. Vertical offset was manually introduced for visibility. Colors match the ones in <bold>A</bold>. The different curves are the maximum likelihood Naka-Rushton distributions estimated from the data points of the same color.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002889.g002" position="float" xlink:type="simple"/>
          </fig>
        </sec>
        <sec id="s2a7">
          <title>Dynamic divisive normalization</title>
          <p>Previous studies found that single neurons adapt to the ambient contrast level via horizontal shifts of their contrast response curve along the log-contrast axis <xref ref-type="bibr" rid="pcbi.1002889-Heeger1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Bonds1">[14]</xref>. In the divisive normalization model, this shift is realized by changes in the half-saturation constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e134" xlink:type="simple"/></inline-formula>. This means, however, that there is not a single static divisive normalization mechanism, but a whole continuum whose elements differ by the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e135" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002889-g002">Figure 2</xref>). This is equivalent to a continuum of Naka-Rushton distributions which can be adapted to the ambient contrast level by changing the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e136" xlink:type="simple"/></inline-formula>. Since this kind of adaptation increases the degrees of freedom, it could also lead to a better redundancy reduction performance.</p>
          <p>In order to investigate adaptation to the local contrast in a meaningful way, we used a simple model of saccades and micro-saccades on natural images to sample fixation locations and their corresponding filter responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e137" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">Methods</xref>). Previous studies on redundancy reduction with divisive normalization <xref ref-type="bibr" rid="pcbi.1002889-Schwartz1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Sinz1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Lyu1">[12]</xref> ignored both the structure imposed by fixations between saccades in natural viewing conditions, and the adaptation of neural contrast response curves to the ambient contrast level via the adaptation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e138" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002889-Bonds1">[14]</xref>. <xref ref-type="fig" rid="pcbi-1002889-g002">Figure 2</xref> shows an example of simulated eye movements on a natural image from the van Hateren database. For each sample location, we computed the corresponding values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e139" xlink:type="simple"/></inline-formula> and fitted a Naka-Rushton distribution to it. The right hand side show the resulting Naka-Rushton distributions. One can see that the mode of the distribution shifts with the location of the data, which itself depends on the ambient contrast of the fixation location.</p>
          <p>A dynamically adapting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e140" xlink:type="simple"/></inline-formula> predicts that the distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e141" xlink:type="simple"/></inline-formula> across time should be well fit by a mixture of Naka-Rushton distributions. Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e142" xlink:type="simple"/></inline-formula> (we use <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e143" xlink:type="simple"/></inline-formula> to emphasize that the radial distribution is a univariate density and not a multivariate density on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e144" xlink:type="simple"/></inline-formula>), then averaged over all time points <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e145" xlink:type="simple"/></inline-formula>, the distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e146" xlink:type="simple"/></inline-formula> is given by<disp-formula id="pcbi.1002889.e147"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e147" xlink:type="simple"/><label>(5)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e148" xlink:type="simple"/></inline-formula> denotes a single Naka-Rushton distribution at a specific point in time.</p>
          <p>We fitted such a mixture distribution to samples <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e149" xlink:type="simple"/></inline-formula> from simulated eye movements (see <xref ref-type="sec" rid="s4">Methods</xref>). <xref ref-type="fig" rid="pcbi-1002889-g003">Figure 3a</xref> shows that the mixture of Naka-Rushton distributions fits the empirical data very well, thus confirming the possibility that a dynamic divisive normalization mechanism may be used to achieve optimal redundancy reduction.</p>
          <fig id="pcbi-1002889-g003" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002889.g003</object-id>
            <label>Figure 3</label>
            <caption>
              <title>Radial distribution and redundancy reduction achieved by the dynamically adapting model.</title>
              <p><bold>A</bold>: Histogram of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e150" xlink:type="simple"/></inline-formula> for natural image patches sampled with simulated eye movements: The distribution predicted by the dynamically adapting model closely matches the empirical distribution. <bold>B</bold>: Same as in <xref ref-type="fig" rid="pcbi-1002889-g001">Fig. 1B</xref> but for simulated eye movement data. The dynamically adapting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e151" xlink:type="simple"/></inline-formula> achieves an almost optimal redundancy reduction performance. <bold>C</bold>: Each colored line shows the distribution of a random variable from 3A transformed with a Naka-Rushton function. Different colors correspond to different values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e152" xlink:type="simple"/></inline-formula>. The dashed curve corresponds to a truncated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e153" xlink:type="simple"/></inline-formula>-distribution. A mixture of the colored distributions cannot resemble the truncated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e154" xlink:type="simple"/></inline-formula>-distribution since there will either be peaks on the left or the right of the dashed distribution that cannot be canceled by other mixture components.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002889.g003" position="float" xlink:type="simple"/>
          </fig>
          <p>The next step is to find an explicit dynamic adaptation mechanism that can achieve optimal redundancy reduction. To this end, we sought for a way to adapt <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e155" xlink:type="simple"/></inline-formula> such that the redundancies between the output responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e156" xlink:type="simple"/></inline-formula> were small. Our temporally adapting mechanism chooses the current <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e157" xlink:type="simple"/></inline-formula> based on the recent stimulation history by using correlations between the contrast values at consecutive time steps. We estimated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e158" xlink:type="simple"/></inline-formula> for the present set of filter responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e159" xlink:type="simple"/></inline-formula> from the immediately preceding responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e160" xlink:type="simple"/></inline-formula> by sampling <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e161" xlink:type="simple"/></inline-formula> from a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e162" xlink:type="simple"/></inline-formula>-distribution whose parameters were determined by the mean and the variance of the posterior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e163" xlink:type="simple"/></inline-formula> which was derived from the mixture distribution above (see <xref ref-type="sec" rid="s4">Methods</xref>). We found that this temporal adaptation mechanism significantly decreased the amount of residual redundancies to about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e164" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002889-g003">Figure 3B</xref>). Note that the proposed mechanism is a simple heuristic that does not commit to a particular biophysical implementation of the adaptation, but it demonstrates that there is at least one mechanism that can perform well under realistic conditions a neural system would face.</p>
          <p>Looking at the joint dynamics of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e165" xlink:type="simple"/></inline-formula> and its <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e166" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002889-g004">Figure 4</xref>) we find them to be strongly and positively correlated. Therefore, a higher value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e167" xlink:type="simple"/></inline-formula> is accompanied by a higher value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e168" xlink:type="simple"/></inline-formula>. This is analogous to the adaptation of neural contrast response curves observed in vivo where a higher contrast (higher <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e169" xlink:type="simple"/></inline-formula>) shifts the contrast response curve to the right (higher <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e170" xlink:type="simple"/></inline-formula>), and vice versa <xref ref-type="bibr" rid="pcbi.1002889-Bonds1">[14]</xref>.</p>
          <fig id="pcbi-1002889-g004" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002889.g004</object-id>
            <label>Figure 4</label>
            <caption>
              <title>Dynamics of the adaptive <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e171" xlink:type="simple"/></inline-formula>.</title>
              <p>The scatter plot shows the values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e172" xlink:type="simple"/></inline-formula> plotted against the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e173" xlink:type="simple"/></inline-formula> used to transform <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e174" xlink:type="simple"/></inline-formula> in the dynamic divisive normalization model. The two values are clearly correlated. This indicates that the shift of the contrast response curve, which is controlled by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e175" xlink:type="simple"/></inline-formula>, tracks the ambient contrast level, which is proportional to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e176" xlink:type="simple"/></inline-formula>. Single elements in the plot are colored according to the quantile the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e177" xlink:type="simple"/></inline-formula> falls in. When the ambient contrast level changes abruptly (e.g. when a saccade is made), this value is large. If the ambient contrast level is relatively stable (e.g. during fixation), this value is small. In those situations (blue dots), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e178" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e179" xlink:type="simple"/></inline-formula> exhibit the strongest proportionality.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002889.g004" position="float" xlink:type="simple"/>
          </fig>
          <p>In order to demonstrate that improved redundancy reduction is a true adaptation mechanism which relies on correlations between temporally subsequent sample, we need to preclude the possibility that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e180" xlink:type="simple"/></inline-formula> can be sampled independently (i.e. context independent). For strong redundancy reduction, the normalized responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e181" xlink:type="simple"/></inline-formula> should follow a (possibly truncated) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e182" xlink:type="simple"/></inline-formula>-distribution (see <xref ref-type="sec" rid="s4">Methods</xref>). The history-independent choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e183" xlink:type="simple"/></inline-formula> predicts that this truncated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e184" xlink:type="simple"/></inline-formula>-distribution should be expressible as a mixture of distributions that result from transforming random variables, that follow a mixture of Naka-Rushton distributions from <xref ref-type="fig" rid="pcbi-1002889-g003">Figure 3C</xref>, with Naka-Rushton functions for different values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e185" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">Methods</xref> for the derivation). We transformed the input distribution with Naka-Rushton functions that differed in the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e186" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002889-g003">Figure 3C</xref>, colored lines). Different colors in <xref ref-type="fig" rid="pcbi-1002889-g003">Figure 3C</xref> refer to different values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e187" xlink:type="simple"/></inline-formula>. If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e188" xlink:type="simple"/></inline-formula> was history-independent, a positively weighted average of the colored distributions should be able to yield a truncated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e189" xlink:type="simple"/></inline-formula>-distribution (<xref ref-type="fig" rid="pcbi-1002889-g003">Figure 3C</xref>, dashed line). It is obvious that this is not possible. Every component will either add a tail to the left of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e190" xlink:type="simple"/></inline-formula>-distribution or a peak to the right of it. Since distributions can only be added with non-negative weight in a mixture, there is no way that one distribution can make up for a tail or peak introduced by another. Therefore, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e191" xlink:type="simple"/></inline-formula> cannot be chosen independently of the preceding stimulation, but critically relies on exploiting the temporal correlation structure in the input.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>In this study we have demonstrated that a <italic>static</italic> divisive normalization mechanism is not powerful enough to capture the contrast dependencies of natural images leading to a suboptimal redundancy reduction performance. Static divisive normalization could only exhibit close to optimal performance if the contrast distribution of the input data would be similar to a Naka-Rushton distribution that we derived in this paper. For the best fitting Naka-Rushton distribution, however, the interval containing most of the probability mass is too narrow and too close to zero compared to the contrast distribution empirically found for natural image patches. A divisive normalization mechanism that uses the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e192" xlink:type="simple"/></inline-formula>-norm as in <xref ref-type="disp-formula" rid="pcbi.1002889.e019">equation (3)</xref> instead of the Euclidean norm would suffer from the same problem because the Naka-Rushton distribution for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e193" xlink:type="simple"/></inline-formula>-norms other than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e194" xlink:type="simple"/></inline-formula> would have similar properties. However, the good performance of extended divisive normalization demonstrates that it is not necessary to model the contrast distribution perfectly everywhere but that it would be sufficient to match the range where most natural contrasts appear (<xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1C</xref>).</p>
      <p>Not every mapping on natural contrasts that achieves strong redundancy reduction is also physiologically plausible: We showed that the extended static mechanism yields physiologically implausible contrast response curves. Extending the static mechanism of divisive normalization for better redundancy reduction simply makes it more similar to the optimal mechanism and, therefore, yields implausible tuning curves as well. We thus suggested to consider temporal properties of divisive normalization and devised a model that can resolve this conflict by temporally adapting the half-saturation constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e195" xlink:type="simple"/></inline-formula> using temporal correlations between consecutive data points caused by fixations.</p>
      <p>Another point concerning physiological plausibility is the relationship between divisive normalization models used to explain neurophysiological observations, and those used in redundancy reduction studies like ours. One very common neurophysiological model was introduced by Heeger <xref ref-type="bibr" rid="pcbi.1002889-Heeger1">[8]</xref> which uses half-squared instead of linear single responses:<disp-formula id="pcbi.1002889.e196"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e196" xlink:type="simple"/><label>(6)</label></disp-formula>In order to represent each possible image patch this model would need two neurons per filter: one for the positive part and one for the negative part <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e197" xlink:type="simple"/></inline-formula>. Of course, these two units would be strongly anti-correlated since only one can be nonzero at a given point in time. Therefore, taking a redundancy reduction view requires considering the positive and the negative part. For this reason it is reasonable to use <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e198" xlink:type="simple"/></inline-formula> as the most basic unit and define the normalization as in <xref ref-type="disp-formula" rid="pcbi.1002889.e012">equation (2)</xref>. Since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e199" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e200" xlink:type="simple"/></inline-formula> are just two different representations of the same information, the multi-information between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e201" xlink:type="simple"/></inline-formula> is the same as the multi-information between different tuples <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e202" xlink:type="simple"/></inline-formula>. Apart from this change of viewpoint, the two models are equivalent, because the normalized half-squared response of <xref ref-type="disp-formula" rid="pcbi.1002889.e196">equation (6)</xref> can be obtained by half-squaring the normalized response of <xref ref-type="disp-formula" rid="pcbi.1002889.e012">equation (2)</xref>. Therefore, a model equivalent to the one in <xref ref-type="disp-formula" rid="pcbi.1002889.e196">equation (6)</xref> can be obtained by using the model of <xref ref-type="disp-formula" rid="pcbi.1002889.e012">equation (2)</xref> and representing its responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e203" xlink:type="simple"/></inline-formula> by twice as many half-squared coefficients afterwards.</p>
      <p>Previous work on the role of contrast gain control for efficient coding has either focused on the temporal domain <xref ref-type="bibr" rid="pcbi.1002889-Brenner1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Wark1">[27]</xref>, or on its role in the spatial domain as a redundancy reduction mechanism for contrast correlations in natural images <xref ref-type="bibr" rid="pcbi.1002889-Schwartz1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Sinz1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Lyu1">[12]</xref>. Our results emphasize the importance of combining both approaches by showing that the temporal properties of the contrast gain control mechanism can have a critical effect on the redundancies that originate from the spatial contrast correlations in natural images. Our analysis does not commit to a certain physiological implementation or biophysical constraints, but it demonstrates that the statistics of natural images require more degrees of freedom for redundancy reduction in a population response than a classical static divisive normalization model can offer. Our heuristic mechanism demonstrates that strong redundancy reduction is possible with an adaptation mechanism that faces realistic conditions, i.e. has only access to stimuli encountered in the past.</p>
      <p>As we showed above, biologically plausible shapes of the contrast response curve and strong redundancy reduction cannot be easily brought together in a single model. Our dynamical model offers a possible solution to this problem. To what extent this model reflects the physiological reality, however, still needs to be tested experimentally.</p>
      <p>The first aspect to test is whether the adaptation of the half-saturation constant reflects the temporal structure imprinted by saccades and fixations as predicted by our study. Previous work has measured adaptation timescales for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e204" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002889-Bonds1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Hu1">[28]</xref>. However, these measurements are carried out in anesthetized animals and cannot account for eye movements. Since our adaptation mechanism mainly uses the fact that contrasts at a particular fixation location are very similar it predicts that that adaptive changes of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e205" xlink:type="simple"/></inline-formula> should be seen from one fixation location to another when measured under natural viewing conditions.</p>
      <p>The mechanism we proposed is only one possible candidate for a <italic>dynamic</italic> contrast gain control mechanism that can achieve strong redundancy reduction. We conclude the paper with defining a measure that can be used to distinguish contrast gain control mechanisms that are likely to achieve strong redundancy reduction from those that do not. As discussed above, a necessary condition for strong redundancy reduction is that the the location and the width of the distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e206" xlink:type="simple"/></inline-formula> implied by a model must match the distribution of unnormalized responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e207" xlink:type="simple"/></inline-formula> determined by the statistics of natural images. In order to measure the location and the width of the distributions in a way that does not depend on a particular scaling of the data, we plotted the median against the width of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e208" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e209" xlink:type="simple"/></inline-formula>–percentile interval (<xref ref-type="fig" rid="pcbi-1002889-g005">Figure 5</xref>). For the empirical distributions generated by the statistics of the image data we always found a ratio greater than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e210" xlink:type="simple"/></inline-formula>. We also included a dataset from real human eye movements by Kienzle et al. to ensure the generality of this finding <xref ref-type="bibr" rid="pcbi.1002889-Kienzle1">[29]</xref> as real fixations could introduce a change in the statistics due to the fact that real observers tend to look at image regions with higher contrasts <xref ref-type="bibr" rid="pcbi.1002889-Reinagel1">[30]</xref>. All models that yield strong redundancy reduction also exhibit a ratio greater than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e211" xlink:type="simple"/></inline-formula>. Thus, the ratio of the median to the width of the contrast distribution is a simple signature that can be used to check whether an adaptation mechanism is potentially powerful enough for near-optimal redundancy reduction.</p>
      <fig id="pcbi-1002889-g005" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002889.g005</object-id>
        <label>Figure 5</label>
        <caption>
          <title>Median vs. width of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e212" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e213" xlink:type="simple"/></inline-formula> percentile interval of the models shown in <xref ref-type="fig" rid="pcbi-1002889-g003">Figure 3b</xref>.</title>
          <p>The red line corresponds to a static <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e214" xlink:type="simple"/></inline-formula> for different values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e215" xlink:type="simple"/></inline-formula>, the blue triangles correspond to the temporally adapting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e216" xlink:type="simple"/></inline-formula>, the orange markers correspond to uniformly sampled (diamond) and fixational image patches with Brownian motion micro-saccades (circle) from Kienzle et al. <xref ref-type="bibr" rid="pcbi.1002889-Kienzle1">[29]</xref>, the gray markers to simulated eye movement datasets from van Hateren image data <xref ref-type="bibr" rid="pcbi.1002889-VanHateren1">[31]</xref>, and the black marker to the optimal extended divisive normalization model. All transforms that yield a strong redundancy reduction have models that exhibit a ratio greater than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e217" xlink:type="simple"/></inline-formula> (dashed lines).</p>
        </caption>
        <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002889.g005" position="float" xlink:type="simple"/>
      </fig>
    </sec>
    <sec id="s4" sec-type="methods">
      <title>Methods</title>
      <p>The code and the data are available online under <ext-link ext-link-type="uri" xlink:href="http://www.bethgelab.org/code/sinz2012" xlink:type="simple">http://www.bethgelab.org/code/sinz2012</ext-link>.</p>
      <sec id="s4a">
        <title>Data</title>
        <sec id="s4a1">
          <title>van Hateren data</title>
          <p>For the static experiments, we used randomly sampled <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e218" xlink:type="simple"/></inline-formula> patches from the van Hateren database <xref ref-type="bibr" rid="pcbi.1002889-VanHateren1">[31]</xref>. For all experiments we used the logarithm of the raw light intensities. We sampled <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e219" xlink:type="simple"/></inline-formula> pairs of training and test sets of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e220" xlink:type="simple"/></inline-formula> patches which we centered on the pixel mean.</p>
          <p>For the simulated eye movements, we also used <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e221" xlink:type="simple"/></inline-formula> pairs of training and test sets. For the sampling procedure, we repeated the following steps until <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e222" xlink:type="simple"/></inline-formula> samples were drawn: We first drew an image randomly from the van Hateren database. For each image, we simulated ten saccades to random locations in that image. For each saccade location which was uniformly drawn over the entire image, we determined the number <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e223" xlink:type="simple"/></inline-formula> of patches to be sampled from around that location by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e224" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e225" xlink:type="simple"/></inline-formula> was the assumed sampling frequency and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e226" xlink:type="simple"/></inline-formula> was a sample from an exponential distribution with average fixation time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e227" xlink:type="simple"/></inline-formula> (i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e228" xlink:type="simple"/></inline-formula>). The actual locations of the patches were determined by Brownian motion starting at the saccade location and then propagating with a diffusion constant of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e229" xlink:type="simple"/></inline-formula>. This means that each patch location was drawn relative to the previous one based on an isotropic Gaussian centered at the current location with a standard deviation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e230" xlink:type="simple"/></inline-formula>.</p>
        </sec>
        <sec id="s4a2">
          <title>Kienzle data</title>
          <p>The van Hateren database is a standard dataset for static natural image statistics. To make sure that our results also hold for real fixations, we sampled data from the images used by Kienzle et al. <xref ref-type="bibr" rid="pcbi.1002889-Kienzle1">[29]</xref>. We computed the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e231" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e232" xlink:type="simple"/></inline-formula> percentiles, as well as the width of the interval between them, for both datasets for <xref ref-type="fig" rid="pcbi-1002889-g005">Figure 5</xref>.</p>
          <p>We constructed two datasets: One where the patches were uniformly drawn from the images, and one where we again used Brownian motion with a similar standard deviation around human fixation spots to simulate human fixational data. We applied the same preprocessing as for the van Hateren data: centering and whitening.</p>
        </sec>
      </sec>
      <sec id="s4b">
        <title>Models</title>
        <p>Both the divisive normalization model and the optimal radial factorization consist of two steps: a linear filtering step and a radial rescaling step (<xref ref-type="table" rid="pcbi-1002889-t001">Table 1</xref>). In the following, we describe the different steps in more detail.</p>
        <table-wrap id="pcbi-1002889-t001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002889.t001</object-id>
          <label>Table 1</label>
          <caption>
            <title>Model components of the divisive normalization and radial factorization model: Natural image patches are filtered by a set of linear oriented band-pass filters.</title>
          </caption>
          <alternatives>
            <graphic id="pcbi-1002889-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002889.t001" xlink:type="simple"/>
            <table>
              <colgroup span="1">
                <col align="left" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1">divisive normalization model</td>
                  <td align="left" rowspan="1" colspan="1">radial factorization</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" rowspan="1" colspan="1">filtering</td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e233" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e234" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">normalization</td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e235" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e236" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1">(static case <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e237" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e238" xlink:type="simple"/></inline-formula>)</td>
                  <td align="left" rowspan="1" colspan="1"/>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="nt101">
              <label/>
              <p>The filter responses are normalized and their norm is rescaled in the normalization step.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <sec id="s4b1">
          <title>Filters</title>
          <p>The receptive fields of our model neurons, i.e. the linear filters of our models, are given by the rows of a matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e239" xlink:type="simple"/></inline-formula>. In summary, the filters are obtained by (i) projecting the data onto the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e240" xlink:type="simple"/></inline-formula> dimensional subspace that is insensitive to the DC component in the image patches, (ii) performing dimensionality reduction and whitening using principal component analysis, and (iii) training an independent subspace analysis algorithm (ISA) to obtain <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e241" xlink:type="simple"/></inline-formula>:</p>
          <list list-type="roman-lower">
            <list-item>
              <p>The projection of the data onto the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e242" xlink:type="simple"/></inline-formula> dimensional subspace that is insensitive to the DC component is achieved via the matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e243" xlink:type="simple"/></inline-formula>. This matrix is a fixed matrix for which the coefficients in each row sum to zero and all rows are mutually orthogonal. The matrix we used has been obtained via a QR-decomposition as described in the <xref ref-type="sec" rid="s4">Methods</xref> Section of <xref ref-type="bibr" rid="pcbi.1002889-Eichhorn1">[7]</xref>.</p>
            </list-item>
            <list-item>
              <p>The dimensionality reduction and whitening is achieved by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e244" xlink:type="simple"/></inline-formula>. The matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e245" xlink:type="simple"/></inline-formula> contains the principal components of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e246" xlink:type="simple"/></inline-formula> such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e247" xlink:type="simple"/></inline-formula>. As it is common practice, we kept only the first <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e248" xlink:type="simple"/></inline-formula> principal components to avoid “noisy” high frequency filters. However, our analysis would also be valid and lead to the same conclusions if we kept the full set of filters.</p>
            </list-item>
            <list-item>
              <p>The last matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e249" xlink:type="simple"/></inline-formula> is constrained to be an orthogonal matrix because the covariance of whitened data remains white under orthogonal transformations. This additional degree of freedom is used by Independent Subspace Analysis (see below) to optimize the filter shapes for redundancy reduction beyond removing second-order correlations. While the matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e250" xlink:type="simple"/></inline-formula> has a large effect on the particular filter shapes, the same results would have been obtained with any type of whitening filter, i.e. for any orthogonal matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e251" xlink:type="simple"/></inline-formula>, because they only differ by an orthogonal rotation. Since we use the Euclidean norm in the divisive normalization model, the rotation would not change the norm of the filter responses and therefore all radial distributions would be the same. The only aspect in our analysis for which the filter choice would make a (small) difference is the multi-information of the raw filter responses. When using ICA filter, the multi-information could be a bit lower. However, since even for rather drastic changes of filter shapes (within the class of whitening filters) there is only a small effect on redundancy reduction <xref ref-type="bibr" rid="pcbi.1002889-Bethge1">[6]</xref>, the particular choice of filter shapes does not affect any of our conclusions. The same is true for any choice of parametric filters as long as the covariance matrix of the filter responses is proportional to the identity matrix. Since the second-order correlations provide the dominant contribution to the multi-information any substantial deviation from the class of whitening filters is likely to yield suboptimal results.</p>
            </list-item>
          </list>
          <p>The independent subspace analysis (with two-dimensional subspaces) used to obtain the matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e252" xlink:type="simple"/></inline-formula> is based on the model by Hyvärinen <xref ref-type="bibr" rid="pcbi.1002889-Hyvrinen2">[16]</xref>:<disp-formula id="pcbi.1002889.e253"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e253" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e254" xlink:type="simple"/></inline-formula> denotes the list of free parameters for each <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e255" xlink:type="simple"/></inline-formula>. More specifically, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e256" xlink:type="simple"/></inline-formula> consists of the value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e257" xlink:type="simple"/></inline-formula> for the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e258" xlink:type="simple"/></inline-formula>-norm and the parameters of the radial distribution for each of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e259" xlink:type="simple"/></inline-formula>-spherically symmetric distributions. Each single <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e260" xlink:type="simple"/></inline-formula> was chosen to be a two-dimensional <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e261" xlink:type="simple"/></inline-formula>-spherically symmetric distribution <xref ref-type="bibr" rid="pcbi.1002889-Gupta1">[32]</xref><disp-formula id="pcbi.1002889.e262"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e262" xlink:type="simple"/></disp-formula><disp-formula id="pcbi.1002889.e263"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e263" xlink:type="simple"/></disp-formula>with a radial <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e264" xlink:type="simple"/></inline-formula>-distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e265" xlink:type="simple"/></inline-formula> with shape <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e266" xlink:type="simple"/></inline-formula> and scale <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e267" xlink:type="simple"/></inline-formula>. Therefore, the parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e268" xlink:type="simple"/></inline-formula> were given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e269" xlink:type="simple"/></inline-formula>. In the denominator, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e270" xlink:type="simple"/></inline-formula> denotes the surface area of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e271" xlink:type="simple"/></inline-formula>-norm unit sphere in two dimensions <xref ref-type="bibr" rid="pcbi.1002889-Gupta1">[32]</xref>. During training, we first fixed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e272" xlink:type="simple"/></inline-formula>; after initial convergence, we retrained the model with free <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e273" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e274" xlink:type="simple"/></inline-formula>.</p>
          <p>The likelihood of the data under <xref ref-type="disp-formula" rid="pcbi.1002889.e253">equation (7)</xref> was optimized by alternating between optimizing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e275" xlink:type="simple"/></inline-formula> for fixed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e276" xlink:type="simple"/></inline-formula>, and optimizing the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e277" xlink:type="simple"/></inline-formula> for fixed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e278" xlink:type="simple"/></inline-formula>. The gradient ascent on the log-likelihood of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e279" xlink:type="simple"/></inline-formula> over the orthogonal group used the backprojection method by Manton <xref ref-type="bibr" rid="pcbi.1002889-Sinz3">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Manton1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Sinz4">[34]</xref>. Optimizing over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e280" xlink:type="simple"/></inline-formula> yields filter pairs that resemble quadrature pairs like in the energy model of complex cells <xref ref-type="bibr" rid="pcbi.1002889-Pollen1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Adelson1">[18]</xref>.</p>
        </sec>
      </sec>
      <sec id="s4c">
        <title>Radial rescaling</title>
        <sec id="s4c1">
          <title>Optimal contrast gain control: radial factorization</title>
          <p>In the following we describe the general mechanism of radial factorization. The spherical symmetric case mostly used in this study is obtained by setting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e281" xlink:type="simple"/></inline-formula>.</p>
          <p>Radial factorization is the optimal redundancy reduction mechanism for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e282" xlink:type="simple"/></inline-formula>-spherically symmetric distributed data <xref ref-type="bibr" rid="pcbi.1002889-Sinz1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Gupta1">[32]</xref>. Samples from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e283" xlink:type="simple"/></inline-formula>-spherically symmetric distributions with identical <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e284" xlink:type="simple"/></inline-formula>-norm <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e285" xlink:type="simple"/></inline-formula> are uniformly distributed on the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e286" xlink:type="simple"/></inline-formula>-sphere with that radius. A radial distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e287" xlink:type="simple"/></inline-formula> determines how likely it is that a data point is drawn from an <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e288" xlink:type="simple"/></inline-formula>-sphere with that specific radius. Since the distribution on the sphere is uniform for any <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e289" xlink:type="simple"/></inline-formula>-spherically symmetric distribution, the radial distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e290" xlink:type="simple"/></inline-formula> determines the specific type of distribution. For example, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e291" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e292" xlink:type="simple"/></inline-formula> yields an isotropic Gaussian since the Gaussian distribution is spherically symmetric (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e293" xlink:type="simple"/></inline-formula>) and has a radial <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e294" xlink:type="simple"/></inline-formula>-distribution (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e295" xlink:type="simple"/></inline-formula>). One can show that, for a fixed value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e296" xlink:type="simple"/></inline-formula>, there is only one type of radial distribution such that the joint distribution is factorial <xref ref-type="bibr" rid="pcbi.1002889-Sinz2">[13]</xref>. For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e297" xlink:type="simple"/></inline-formula> this radial distribution is the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e298" xlink:type="simple"/></inline-formula>-distribution corresponding to a joint Gaussian distribution. For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e299" xlink:type="simple"/></inline-formula>, the radial distribution is a generalization of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e300" xlink:type="simple"/></inline-formula>-distribution and the joint distribution is the so called <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e301" xlink:type="simple"/></inline-formula>-generalized Normal <xref ref-type="bibr" rid="pcbi.1002889-Goodman1">[35]</xref>.</p>
          <p>Radial factorization is a mapping on the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e302" xlink:type="simple"/></inline-formula>-norm <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e303" xlink:type="simple"/></inline-formula> of the data points that transforms a given source <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e304" xlink:type="simple"/></inline-formula>-spherically symmetric distribution into a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e305" xlink:type="simple"/></inline-formula>-generalized Normal. To this end, it first models the distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e306" xlink:type="simple"/></inline-formula> with a flexible distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e307" xlink:type="simple"/></inline-formula> and then nonlinearly rescales <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e308" xlink:type="simple"/></inline-formula> such that the radial distribution becomes a generalized <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e309" xlink:type="simple"/></inline-formula>-distribution. This is achieved via histogram equalization <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e310" xlink:type="simple"/></inline-formula> where the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e311" xlink:type="simple"/></inline-formula> denote the respective cumulative distribution functions. On the level of joint responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e312" xlink:type="simple"/></inline-formula>, radial factorization first normalizes the radius to one and then rescales the data point with the new radius:<disp-formula id="pcbi.1002889.e313"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e313" xlink:type="simple"/></disp-formula>In our case <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e314" xlink:type="simple"/></inline-formula> was chosen to be a mixture of five <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e315" xlink:type="simple"/></inline-formula>-distributions.</p>
          <p>When determining the optimal redundancy reduction performance on the population response, we set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e316" xlink:type="simple"/></inline-formula> in order to use the same norm as the divisive normalization model. Only when estimating the redundancy of the linear filter responses, we use <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e317" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002889-Sinz1">[11]</xref>.</p>
          <p>Note that the divisive normalization model and the radial factorization model used in this study are invariant with respect to the choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e318" xlink:type="simple"/></inline-formula> since the Euclidean norm (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e319" xlink:type="simple"/></inline-formula>) is invariant under orthogonal transforms. However, the choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e320" xlink:type="simple"/></inline-formula> would affect the redundancies in the plain filter responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e321" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1002889-g001">Figure 1B</xref>. But even if we had chosen a different <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e322" xlink:type="simple"/></inline-formula>, i.e. another set of whitening filters, the redundancy between the coefficients of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e323" xlink:type="simple"/></inline-formula> would not vary much as previous studies have demonstrated <xref ref-type="bibr" rid="pcbi.1002889-Bethge1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1002889-Eichhorn1">[7]</xref>.</p>
        </sec>
        <sec id="s4c2">
          <title>Divisive normalization model and Naka-Rushton distribution</title>
          <p>We use the following divisive normalization transform<disp-formula id="pcbi.1002889.e324"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e324" xlink:type="simple"/></disp-formula>which is the common model for neural contrast gain control <xref ref-type="bibr" rid="pcbi.1002889-Heeger1">[8]</xref> and redundancy reduction <xref ref-type="bibr" rid="pcbi.1002889-Schwartz1">[9]</xref>.</p>
          <p>Divisive normalization acts on the Euclidean norm of the filter responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e325" xlink:type="simple"/></inline-formula>. Therefore, divisive normalization can only achieve independence if it outputs a Gaussian random variable. While in radial factorization the target and source distribution were fixed, and the goal was to find a mapping that transforms one into the other, we now fix the mapping to divisive normalization, the target distribution on the normalized response <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e326" xlink:type="simple"/></inline-formula> to be Gaussian (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e327" xlink:type="simple"/></inline-formula> to be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e328" xlink:type="simple"/></inline-formula>-distributed) and search for the corresponding source distribution that would lead to a factorial representation when divisive normalization is applied. Since divisive normalization saturates at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e329" xlink:type="simple"/></inline-formula>, we will actually have to use a truncated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e330" xlink:type="simple"/></inline-formula>-distribution on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e331" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e332" xlink:type="simple"/></inline-formula> becomes the truncation threshold. Note that radial truncation actually introduces some dependencies, but we keep them small by choosing the truncation threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e333" xlink:type="simple"/></inline-formula> to be the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e334" xlink:type="simple"/></inline-formula> percentile of the radial <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e335" xlink:type="simple"/></inline-formula>-distribution which is approximately <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e336" xlink:type="simple"/></inline-formula>. The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e337" xlink:type="simple"/></inline-formula> was chosen to keep the target distribution close to a factorial Gaussian. However, it could still be that another cut-off (value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e338" xlink:type="simple"/></inline-formula>) leads to a better redundancy reduction even though the target distribution is less factorial for lower values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e339" xlink:type="simple"/></inline-formula> (quantiles lower than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e340" xlink:type="simple"/></inline-formula>). We made sure that this is not the case by choosing different values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e341" xlink:type="simple"/></inline-formula>, computing the best <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e342" xlink:type="simple"/></inline-formula> via a maximum likelihood fit of a Naka-Rushton distribution (see below), and estimating the multi-information in the transformed outputs. We found that the choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e343" xlink:type="simple"/></inline-formula> has virtually no effect on the residual multi-infomation (it varies by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e344" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e345" xlink:type="simple"/></inline-formula> and takes its optimum within this interval). Therefore, we kept the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e346" xlink:type="simple"/></inline-formula> choice as it is most similar to the target distribution of radial factorization.</p>
          <p>Note also that choosing a Gaussian target distribution does not contradict the finding that cortical firing rates are found to be exponentially distributed <xref ref-type="bibr" rid="pcbi.1002889-Baddeley1">[36]</xref> since each single response <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e347" xlink:type="simple"/></inline-formula> can always be transformed again to be exponentially distributed without changing the redundancy of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e348" xlink:type="simple"/></inline-formula>.</p>
          <p>The distribution on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e349" xlink:type="simple"/></inline-formula> such that<disp-formula id="pcbi.1002889.e350"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e350" xlink:type="simple"/></disp-formula>is truncated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e351" xlink:type="simple"/></inline-formula>-distributed can be derived by a simple change of variables. In the resulting distribution<disp-formula id="pcbi.1002889.e352"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e352" xlink:type="simple"/></disp-formula>the truncation threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e353" xlink:type="simple"/></inline-formula>, the half-saturation constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e354" xlink:type="simple"/></inline-formula>, and the scale of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e355" xlink:type="simple"/></inline-formula>-distribution become parameters of the model. The parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e356" xlink:type="simple"/></inline-formula> of the Naka-Rushton distribution controls the variance of the corresponding Gaussian and was always chosen such that the Gaussian was white with variance one. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e357" xlink:type="simple"/></inline-formula> was determined by the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e358" xlink:type="simple"/></inline-formula>-percentile. The only remaining free parameter of the Naka-Rushton distribution is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e359" xlink:type="simple"/></inline-formula> which simultaneously affects both shape and scale. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e360" xlink:type="simple"/></inline-formula> is the regularized-incomplete-gamma function which accounts for the truncation at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e361" xlink:type="simple"/></inline-formula>. We call the distribution <italic>Naka-Rushton distribution</italic> and denote it with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e362" xlink:type="simple"/></inline-formula>.</p>
          <p>To derive the distribution on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e363" xlink:type="simple"/></inline-formula> for which the extended divisive normalization transformation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e364" xlink:type="simple"/></inline-formula> yields a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e365" xlink:type="simple"/></inline-formula>-distribution, the steps are exactly the same as for the plain divisive normalization transform above. This yields<disp-formula id="pcbi.1002889.e366"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e366" xlink:type="simple"/></disp-formula>for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e367" xlink:type="simple"/></inline-formula>. The parameters of the distribution are now <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e368" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e369" xlink:type="simple"/></inline-formula>.</p>
          <p>The parameters for all divisive normalization transforms were estimated via maximum likelihood of the Naka-Rushton distribution on the Euclidean norms <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e370" xlink:type="simple"/></inline-formula> of the filter responses to natural image patches. As before, we did not optimize for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e371" xlink:type="simple"/></inline-formula> in the extended Naka-Rushton distribution but fixed it such that the corresponding Gaussian was white.</p>
        </sec>
        <sec id="s4c3">
          <title>Dynamically adapting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e372" xlink:type="simple"/></inline-formula></title>
          <p>For the model with dynamically adapting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e373" xlink:type="simple"/></inline-formula>, we first model the Euclidean norms <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e374" xlink:type="simple"/></inline-formula> of the filter responses to the patches from the simulated eye movement data with a mixture of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e375" xlink:type="simple"/></inline-formula> Naka-Rushton distributions<disp-formula id="pcbi.1002889.e376"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e376" xlink:type="simple"/></disp-formula>using EM <xref ref-type="bibr" rid="pcbi.1002889-Dempster1">[37]</xref>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e377" xlink:type="simple"/></inline-formula> denotes the probability that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e378" xlink:type="simple"/></inline-formula>. The values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e379" xlink:type="simple"/></inline-formula> where chosen in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e380" xlink:type="simple"/></inline-formula> equidistant steps from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e381" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e382" xlink:type="simple"/></inline-formula>.</p>
          <p>How much redundancy reduction can be achieved with a dynamically adapting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e383" xlink:type="simple"/></inline-formula>, depends on the dynamics according to which it is selected based on the recent history. While there might be many strategies, we chose a parsimonious one based on the mean and the standard deviation of the posterior over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e384" xlink:type="simple"/></inline-formula>. Our heuristic consists of two steps: First the mean and the standard deviation of the posterior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e385" xlink:type="simple"/></inline-formula> derived from the mixture distribution is approximated with piecewise linear functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e386" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e387" xlink:type="simple"/></inline-formula>, then we sample <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e388" xlink:type="simple"/></inline-formula> used to transform <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e389" xlink:type="simple"/></inline-formula> from a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e390" xlink:type="simple"/></inline-formula>-distribution with mean and standard deviation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e391" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e392" xlink:type="simple"/></inline-formula>. This strategy emphasizes that the first two moments of the posterior are the important features for obtaining a good <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e393" xlink:type="simple"/></inline-formula>.</p>
          <p>In more detail, we evaluated the posterior<disp-formula id="pcbi.1002889.e394"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e394" xlink:type="simple"/></disp-formula>of the mixture distribution at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e395" xlink:type="simple"/></inline-formula> equidistant locations between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e396" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e397" xlink:type="simple"/></inline-formula>, computed the posterior mean and standard deviation at those locations, rescaled the standard deviation by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e398" xlink:type="simple"/></inline-formula>, and fitted the piecewise linear functions on the intervals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e399" xlink:type="simple"/></inline-formula> to each set of values. In the first interval, the linear function was constraint to start at zero. From these two functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e400" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e401" xlink:type="simple"/></inline-formula>, we computed two functions for the scale <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e402" xlink:type="simple"/></inline-formula> and the shape <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e403" xlink:type="simple"/></inline-formula> of a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e404" xlink:type="simple"/></inline-formula>-distribution<disp-formula id="pcbi.1002889.e405"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e405" xlink:type="simple"/></disp-formula>via moment matching. We obtained the value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e406" xlink:type="simple"/></inline-formula> for transforming a value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e407" xlink:type="simple"/></inline-formula> with a Naka-Rushton function by sampling <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e408" xlink:type="simple"/></inline-formula> from a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e409" xlink:type="simple"/></inline-formula>-distribution with shape and scale determined by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e410" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e411" xlink:type="simple"/></inline-formula>.</p>
        </sec>
        <sec id="s4c4">
          <title>Computation of percentiles for <xref ref-type="fig" rid="pcbi-1002889-g005">Figure 5</xref></title>
          <p>For the dynamically adapting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e412" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1002889-g005">Figure 5</xref>, we sampled from<disp-formula id="pcbi.1002889.e413"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e413" xlink:type="simple"/></disp-formula>and computed the percentiles based on the sampled dataset. For the sampling procedure, we drew <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e414" xlink:type="simple"/></inline-formula> from the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e415" xlink:type="simple"/></inline-formula>-distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e416" xlink:type="simple"/></inline-formula> with shape and scale computed from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e417" xlink:type="simple"/></inline-formula> and then sampled <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e418" xlink:type="simple"/></inline-formula> from the Naka-Rushton distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e419" xlink:type="simple"/></inline-formula> with that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e420" xlink:type="simple"/></inline-formula>. We repeated that for all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e421" xlink:type="simple"/></inline-formula> from a test set of simulated eye movement radii. This procedure was carried out for all pairs of training and test sets, and the distributions fitted to them.</p>
          <p>For the static case, we sampled data from single Naka-Rushton distributions for different values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e422" xlink:type="simple"/></inline-formula> and computed the percentiles from the samples.</p>
        </sec>
        <sec id="s4c5">
          <title>History-independent choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e423" xlink:type="simple"/></inline-formula></title>
          <p>In the following, let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e424" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e425" xlink:type="simple"/></inline-formula> be the unnormalized and normalized responses at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e426" xlink:type="simple"/></inline-formula>, respectively, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e427" xlink:type="simple"/></inline-formula> be the recent history of responses. The underlying generative structure of the model for temporally correlated data is the following: given a fixed history <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e428" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e429" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e430" xlink:type="simple"/></inline-formula> are sampled from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e431" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e432" xlink:type="simple"/></inline-formula>. Then, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e433" xlink:type="simple"/></inline-formula> is generated from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e434" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e435" xlink:type="simple"/></inline-formula> through divisive normalization.</p>
          <p>For strong redundancy reduction, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e436" xlink:type="simple"/></inline-formula> should follow a truncated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e437" xlink:type="simple"/></inline-formula>-distribution, which means that for given history <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e438" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e439" xlink:type="simple"/></inline-formula>, the unnormalized response energy <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e440" xlink:type="simple"/></inline-formula> must have a Naka-Rushton distribution<disp-formula id="pcbi.1002889.e441"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e441" xlink:type="simple"/></disp-formula>because normalizing this response via <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e442" xlink:type="simple"/></inline-formula> yields a truncated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e443" xlink:type="simple"/></inline-formula>-distribution. Averaged over all histories <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e444" xlink:type="simple"/></inline-formula> and half-saturation constants <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e445" xlink:type="simple"/></inline-formula> the distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e446" xlink:type="simple"/></inline-formula> is a mixture of Naka-Rushton distributions<disp-formula id="pcbi.1002889.e447"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e447" xlink:type="simple"/><label>(8)</label></disp-formula>If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e448" xlink:type="simple"/></inline-formula> depends deterministically on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e449" xlink:type="simple"/></inline-formula> we obtain <xref ref-type="disp-formula" rid="pcbi.1002889.e147">equation (5)</xref>.</p>
          <p>If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e450" xlink:type="simple"/></inline-formula> could be chosen independently of the preceding history the distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e451" xlink:type="simple"/></inline-formula> would be given by<disp-formula id="pcbi.1002889.e452"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e452" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e453" xlink:type="simple"/></inline-formula> is the marginal distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e454" xlink:type="simple"/></inline-formula> transformed with divisive normalization and a specific value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e455" xlink:type="simple"/></inline-formula>. Since redundancy reduction requires <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e456" xlink:type="simple"/></inline-formula> to be truncated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e457" xlink:type="simple"/></inline-formula>-distributed, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e458" xlink:type="simple"/></inline-formula> can be chosen independently only if the truncated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e459" xlink:type="simple"/></inline-formula>-distribution can be modelled as mixture of the different <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e460" xlink:type="simple"/></inline-formula>. Since we assume stationarity, we can drop the index <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e461" xlink:type="simple"/></inline-formula> in the equation.</p>
        </sec>
      </sec>
      <sec id="s4d">
        <title>Multi-information estimation</title>
        <p>We use the <italic>multi-information</italic> to quantify the statistical dependencies between the filter responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e462" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002889-Perez1">[38]</xref>. The multi-information is the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e463" xlink:type="simple"/></inline-formula>-dimensional generalization of the <italic>mutual-information</italic>. It is defined as the Kullback-Leibler divergence between the joint distribution and the product of its marginals or, equivalently, the difference between the sum of the marginal entropies and the joint entropy<disp-formula id="pcbi.1002889.e464"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e464" xlink:type="simple"/><label>(9)</label></disp-formula>The multi-information is zero if and only if the different dimensions of the random vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e465" xlink:type="simple"/></inline-formula> are independent. Since the joint entropy <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e466" xlink:type="simple"/></inline-formula> is hard to estimate we employ a semi-parametric estimate of the multi-information that is conservative in the sense that it is downward biased.</p>
        <p>For the marginal entropies <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e467" xlink:type="simple"/></inline-formula>, we use a jackknifed estimator for the discrete entropy on the binned values <xref ref-type="bibr" rid="pcbi.1002889-Paninski1">[39]</xref>. We chose the bin size with the heuristic proposed by Scott <xref ref-type="bibr" rid="pcbi.1002889-Scott1">[40]</xref>. We obtain an estimate for the differential entropy by correcting with the logarithm of the bin width (see e.g. <xref ref-type="bibr" rid="pcbi.1002889-Eichhorn1">[7]</xref>).</p>
        <p>In order to estimate the joint entropy, we use the average log-loss to get an upper bound<disp-formula id="pcbi.1002889.e468"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e468" xlink:type="simple"/></disp-formula>Since the average log-loss overestimates the true entropy, replacing the joint entropy by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e469" xlink:type="simple"/></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1002889.e008">equation (1)</xref> underestimates the multi-information. Therefore, we sometimes get estimates smaller than zero. Since the multi-information is always positive, we set the value to zero in that case. For computing errorbars on the multi-information estimations, we use the negative values but a mean zero in such cases, which effectively increases the standard deviation of the error.</p>
        <p>Since we want commit ourselves as little as possible to a particular model, we estimate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e470" xlink:type="simple"/></inline-formula> by making the assumption that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e471" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e472" xlink:type="simple"/></inline-formula>-spherically symmetric distributed but estimating everything else with non-parametric estimators. If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e473" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e474" xlink:type="simple"/></inline-formula>-spherically symmetric distributed, the radial component is independent from the directional component <xref ref-type="bibr" rid="pcbi.1002889-Gupta1">[32]</xref> and we can write<disp-formula id="pcbi.1002889.e475"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e475" xlink:type="simple"/><label>(10)</label></disp-formula>The entropy <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e476" xlink:type="simple"/></inline-formula> of the radial component is again estimated via a histogram estimator. The term <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e477" xlink:type="simple"/></inline-formula> is approximated by the empirical mean.</p>
        <p>Putting all the equations together yields our estimator for the multi-information under the assumption of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e478" xlink:type="simple"/></inline-formula>-spherically symmetric distributed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e479" xlink:type="simple"/></inline-formula><disp-formula id="pcbi.1002889.e480"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e480" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e481" xlink:type="simple"/></inline-formula> are the univariate entropies estimated via binning.</p>
        <p>Since the optimal value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e482" xlink:type="simple"/></inline-formula> for filter responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e483" xlink:type="simple"/></inline-formula> to natural image patches is approximately <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e484" xlink:type="simple"/></inline-formula> we use that value to estimate the multi-information of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e485" xlink:type="simple"/></inline-formula>.</p>
        <p>When estimating the multi-information of the responses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e486" xlink:type="simple"/></inline-formula> of either divisive normalization or radial factorization, we use the fact that<disp-formula id="pcbi.1002889.e487"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e487" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e488" xlink:type="simple"/></inline-formula> is the Jacobian of the normalization transformation. The mean is estimated by averaging over data points. The determinants of radial factorization, divisive normalization, and extended divisive normalization are given by<disp-formula id="pcbi.1002889.e489"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e489" xlink:type="simple"/></disp-formula><disp-formula id="pcbi.1002889.e490"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e490" xlink:type="simple"/></disp-formula><disp-formula id="pcbi.1002889.e491"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e491" xlink:type="simple"/></disp-formula>All multi-information values were computed on test data.</p>
        <p>For the dynamically adapting model, the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e492" xlink:type="simple"/></inline-formula> for each data point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e493" xlink:type="simple"/></inline-formula> is sampled from a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e494" xlink:type="simple"/></inline-formula>-distribution whose parameters are determined from the previous value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e495" xlink:type="simple"/></inline-formula> and the posterior over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e496" xlink:type="simple"/></inline-formula> obtained from the mixture of Naka-Rushton distributions. Since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e497" xlink:type="simple"/></inline-formula> changes from step to step it becomes part of the representation and should be included when computing the multi-information (i.e. the redundancy) between the outputs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e498" xlink:type="simple"/></inline-formula>. Therefore, the redundancy for the dynamically adapting model is measured by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e499" xlink:type="simple"/></inline-formula>. For its computation, we use that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e500" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e501" xlink:type="simple"/></inline-formula> is the mutual information between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e502" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e503" xlink:type="simple"/></inline-formula>. In the following, we write <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e504" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e505" xlink:type="simple"/></inline-formula>. Under the assumption that both <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e506" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e507" xlink:type="simple"/></inline-formula> are spherically symmetric distributed, we can decompose respective random variables into the uniform (on the sphere) and the radial part: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e508" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e509" xlink:type="simple"/></inline-formula>. This yields<disp-formula id="pcbi.1002889.e510"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002889.e510" xlink:type="simple"/></disp-formula>which means that we can restrict ourselves to the mutual information between the two univariate signals <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e511" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e512" xlink:type="simple"/></inline-formula>, which we estimate from a two-dimensional histogram with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002889.e513" xlink:type="simple"/></inline-formula> bins.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank P. Berens, L. Busse, S. Katzner and L. Theis for fruitful discussions and comments on the manuscript.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002889-Barlow1">
        <label>1</label>
        <mixed-citation publication-type="other" xlink:type="simple">Barlow HB (1961) Possible Principles Underlying the Transformations of Sensory Messages. In: Rosenblith WA, editor. Sensory Communication. Cambridge, MA: MIT Press. pp. 217–234.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Simoncelli1">
        <label>2</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>, <name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name> (<year>2003</year>) <article-title>Natural Image Statistics and Neural Representation</article-title>. <source>Annual Review of Neuroscience</source> <volume>24</volume>: <fpage>1193</fpage>–<lpage>1216</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Bell1">
        <label>3</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>1997</year>) <article-title>The “independent components” of natural scenes are edge filters</article-title>. <source>Vision Research</source> <volume>37</volume>: <fpage>3327</fpage>–<lpage>3338</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Barlow2">
        <label>4</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barlow</surname><given-names>HB</given-names></name> (<year>1989</year>) <article-title>Unsupervised Learning</article-title>. <source>Neural Computation</source> <volume>1</volume>: <fpage>295</fpage>–<lpage>311</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Lewicki1">
        <label>5</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name>, <name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name> (<year>1999</year>) <article-title>Probabilistic framework for the adaptation and comparison of image codes</article-title>. <source>Journal of the Optical Society of America A</source> <volume>16</volume>: <fpage>1587</fpage>–<lpage>1601</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Bethge1">
        <label>6</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Factorial coding of natural images: how effective are linear models in removing higher-order dependencies?</article-title> <source>Journal of the Optical Society of America A</source> <volume>23</volume>: <fpage>1253</fpage>–<lpage>1268</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Eichhorn1">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eichhorn</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sinz</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Natural Image Coding in V1: How Much Use Is Orientation Selectivity?</article-title> <source>PLoS Comput Biol</source> <volume>5</volume>: <fpage>e1000336</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Heeger1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name> (<year>1992</year>) <article-title>Normalization of cell responses in cat striate cortex</article-title>. <source>Vis Neurosci</source> <volume>9</volume>: <fpage>181</fpage>–<lpage>197</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Schwartz1">
        <label>9</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2001</year>) <article-title>Natural signal statistics and sensory gain control</article-title>. <source>Nat Neurosci</source> <volume>4</volume>: <fpage>819</fpage>–<lpage>825</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Carandini1">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name> (<year>2011</year>) <article-title>Normalization as a canonical neural computation</article-title>. <source>Nature reviews Neuroscience</source> <volume>13</volume>: <fpage>51</fpage>–<lpage>62</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Sinz1">
        <label>11</label>
        <mixed-citation publication-type="other" xlink:type="simple">Sinz F, Bethge M (2009) The Conjoint Effect of Divisive Normalization and Orientation Selectivity on Redundancy Reduction. In: Koller D, Schuurmans D, Bengio Y, Bottou L, editors. Advances in neural information processing systems 21: 22nd Annual Conference on Neural Information Processing Systems 2008. Red Hook, NY, USA: Curran Associates. pp. 1521–1528.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Lyu1">
        <label>12</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lyu</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2009</year>) <article-title>Nonlinear extraction of independent components of natural images using radial gaussianization</article-title>. <source>Neural Computation</source> <volume>21</volume>: <fpage>1485</fpage>–<lpage>1519</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Sinz2">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sinz</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Gerwinn</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Characterization of the p-generalized normal distribution</article-title>. <source>Journal of Multivariate Analysis</source> <volume>100</volume>: <fpage>817</fpage>–<lpage>820</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Bonds1">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bonds</surname><given-names>AB</given-names></name> (<year>1991</year>) <article-title>Temporal dynamics of contrast gain in single cells of the cat striate cortex</article-title>. <source>Vis Neurosci</source> <volume>6</volume>: <fpage>239</fpage>–<lpage>255</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Hyvrinen1">
        <label>15</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hoyer</surname><given-names>P</given-names></name> (<year>2000</year>) <article-title>Emergence of Phase- and Shift-Invariant Features by Decomposition of Natural Images into Independent Feature Subspaces</article-title>. <source>Neural Computation</source> <volume>12</volume>: <fpage>1705</fpage>–<lpage>1720</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Hyvrinen2">
        <label>16</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Koester</surname><given-names>U</given-names></name> (<year>2007</year>) <article-title>Complex cell pooling and the statistics of natural images</article-title>. <source>Network: Computation in Neural Systems</source> <volume>18</volume>: <fpage>81</fpage>–<lpage>100</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Pollen1">
        <label>17</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pollen</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Ronner</surname><given-names>S</given-names></name> (<year>1981</year>) <article-title>Phase relationships between adjacent simple cells in the visual cortex</article-title>. <source>Science</source> <volume>212</volume>: <fpage>1409</fpage>–<lpage>1411</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Adelson1">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adelson</surname><given-names>EH</given-names></name>, <name name-style="western"><surname>Bergen</surname><given-names>JR</given-names></name> (<year>1985</year>) <article-title>Spatiotemporal energy models for the perception of motion</article-title>. <source>Journal of the Optical Society of America A</source> <volume>2</volume>: <fpage>284</fpage>–<lpage>299</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Sinz3">
        <label>19</label>
        <mixed-citation publication-type="other" xlink:type="simple">Sinz F, Simoncelli EP, Bethge M (2009) Hierarchical Modeling of Local Image Features through Lp-Nested Symmetric Distributions. In: Bengio Y, Schuurmans D, Lafferty J, Williams C, Culotta A, editors. Advances in Neural Information Processing Systems 22: 23rd Annual Conference on Neural Information Processing Systems 2009. Red Hook, NY, USA: Curran Associates. pp. 1696–1704.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Lyu2">
        <label>20</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lyu</surname><given-names>S</given-names></name> (<year>2011</year>) <article-title>Dependency Reduction with Divisive Normalization: Justification and Effectiveness</article-title>. <source>Neural Computation</source> <volume>23</volume>: <fpage>2942</fpage>–<lpage>2973</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Wainwright1">
        <label>21</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wainwright</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2000</year>) <article-title>Scale mixtures of Gaussians and the statistics of natural images</article-title>. <source>Neural Information Processing Systems</source> <volume>12</volume>: <fpage>855</fpage>–<lpage>861</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Wainwright2">
        <label>22</label>
        <mixed-citation publication-type="other" xlink:type="simple">Wainwright MJ, Schwartz O, Simoncelli EP (2002) Natural image statistics and divisive normalization: modeling nonlinearities and adaptation in cortical neurons. In: Statistical theories of the brain. MIT Press. pp. 203–222.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Field1">
        <label>23</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>1987</year>) <article-title>Relations between the statistics of natural images and the response properties of cortical cells</article-title>. <source>Journal of the Optical Society of America A</source> <volume>4</volume>: <fpage>2379</fpage>–<lpage>2394</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Ruderman1">
        <label>24</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ruderman</surname><given-names>DL</given-names></name>, <name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name> (<year>1994</year>) <article-title>Statistics of natural images: Scaling in the woods</article-title>. <source>Physical Review Letters</source> <volume>73</volume>: <fpage>814</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Kac1">
        <label>25</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kac</surname><given-names>M</given-names></name> (<year>1939</year>) <article-title>On a Characterization of the Normal Distribution</article-title>. <source>American Journal of Mathematics</source> <volume>61</volume>: <fpage>726</fpage>–<lpage>728</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Brenner1">
        <label>26</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brenner</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name>, <name name-style="western"><surname>De Ruyter Van Steveninck</surname><given-names>R</given-names></name> (<year>2000</year>) <article-title>Adaptive rescaling maximizes information transmission</article-title>. <source>Neuron</source> <volume>26</volume>: <fpage>695</fpage>–<lpage>702</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Wark1">
        <label>27</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wark</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Lundstrom</surname><given-names>BN</given-names></name>, <name name-style="western"><surname>Fairhall</surname><given-names>A</given-names></name> (<year>2007</year>) <article-title>Sensory adaptation</article-title>. <source>Current Opinion in Neurobiology</source> <volume>17</volume>: <fpage>423</fpage>–<lpage>429</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Hu1">
        <label>28</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hu</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name> (<year>2011</year>) <article-title>Rapid Dynamics of Contrast Responses in the Cat Primary Visual Cortex</article-title>. <source>PLoS ONE</source> <volume>6</volume>: <fpage>e25410</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Kienzle1">
        <label>29</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kienzle</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Franz</surname><given-names>MO</given-names></name>, <name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Wichmann</surname><given-names>FA</given-names></name> (<year>2009</year>) <article-title>Center-surround patterns emerge as optimal predictors for human saccade targets</article-title>. <source>Journal of Vision</source> <volume>9</volume>: <fpage>7.1</fpage>–<lpage>15</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Reinagel1">
        <label>30</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reinagel</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Zador</surname><given-names>AM</given-names></name> (<year>1999</year>) <article-title>Natural scene statistics at the centre of gaze</article-title>. <source>Network</source> <volume>10</volume>: <fpage>341</fpage>–<lpage>350</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-VanHateren1">
        <label>31</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Hateren</surname><given-names>JH</given-names></name>, <name name-style="western"><surname>Van Der Schaaf</surname><given-names>A</given-names></name> (<year>1998</year>) <article-title>Independent component filters of natural images compared with simple cells in primary visual cortex</article-title>. <source>Proceedings of the Royal Society B Biological Sciences</source> <volume>265</volume>: <fpage>359</fpage>–<lpage>366</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Gupta1">
        <label>32</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gupta</surname><given-names>AK</given-names></name>, <name name-style="western"><surname>Song</surname><given-names>D</given-names></name> (<year>1997</year>) <article-title>Lp-norm spherical distribution</article-title>. <source>Journal of Statistical Planning and Inference</source> <volume>60</volume>: <fpage>241</fpage>–<lpage>260</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Manton1">
        <label>33</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Manton</surname><given-names>JH</given-names></name> (<year>2002</year>) <article-title>Optimization algorithms exploiting unitary constraints</article-title>. <source>Signal Processing, IEEE Transactions on</source> <volume>50</volume>: <fpage>635</fpage>–<lpage>650</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Sinz4">
        <label>34</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sinz</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>Lp -Nested Symmetric Distributions</article-title>. <source>Journal of Machine Learning Research</source> <volume>11</volume>: <fpage>3409</fpage>–<lpage>3451</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Goodman1">
        <label>35</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goodman</surname><given-names>IR</given-names></name>, <name name-style="western"><surname>Kotz</surname><given-names>S</given-names></name> (<year>1973</year>) <article-title>Multivariate theta]-generalized normal distributions</article-title>. <source>Journal of Multivariate Analysis</source> <volume>3</volume>: <fpage>204</fpage>–<lpage>219</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Baddeley1">
        <label>36</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baddeley</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name>, <name name-style="western"><surname>Booth</surname><given-names>MC</given-names></name>, <name name-style="western"><surname>Sengpiel</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Freeman</surname><given-names>T</given-names></name>, <etal>et al</etal>. (<year>1997</year>) <article-title>Responses of neurons in primary and inferior temporal visual cortices to natural scenes</article-title>. <source>Proceedings of the Royal Society B Biological Sciences</source> <volume>264</volume>: <fpage>1775</fpage>–<lpage>1783</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Dempster1">
        <label>37</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dempster</surname><given-names>AP</given-names></name>, <name name-style="western"><surname>Laird</surname><given-names>NM</given-names></name>, <name name-style="western"><surname>Rubin</surname><given-names>DB</given-names></name> (<year>1977</year>) <article-title>Maximum likelihood from incomplete data via the EM algorithm</article-title>. <source>Journal of the Royal Statistical Society Series B Methodological</source> <volume>39</volume>: <fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Perez1">
        <label>38</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perez</surname><given-names>A</given-names></name> (<year>1977</year>) <article-title>ε-admissible simplification of the dependence structure of a set of random variables</article-title>. <source>Kybernetika</source> <volume>13</volume>: <fpage>439</fpage>–<lpage>444</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Paninski1">
        <label>39</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Paninski</surname><given-names>L</given-names></name> (<year>2003</year>) <article-title>Estimation of Entropy and Mutual Information</article-title>. <source>Neural Computation</source> <volume>15</volume>: <fpage>1191</fpage>–<lpage>1253</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002889-Scott1">
        <label>40</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Scott</surname><given-names>DW</given-names></name> (<year>1979</year>) <article-title>On optimal and data-based histograms</article-title>. <source>Biometrika</source> <volume>66</volume>: <fpage>605</fpage>–<lpage>610</lpage>.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
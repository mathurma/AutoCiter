<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006973</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-01499</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Reaction time</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Reaction time</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Economics</subject><subj-group><subject>Experimental economics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Metacognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Approximation methods</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Contextual influence on confidence judgments in human reinforcement learning</article-title>
<alt-title alt-title-type="running-head">Contextual influence on confidence judgments in learning</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2071-4890</contrib-id>
<name name-style="western">
<surname>Lebreton</surname>
<given-names>Maël</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Bacily</surname>
<given-names>Karin</given-names>
</name>
<role content-type="http://credit.casrai.org/">Investigation</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Palminteri</surname>
<given-names>Stefano</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
<xref ref-type="aff" rid="aff006"><sup>6</sup></xref>
<xref ref-type="aff" rid="aff007"><sup>7</sup></xref>
<xref ref-type="fn" rid="econtrib001"><sup>‡</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6493-8792</contrib-id>
<name name-style="western">
<surname>Engelmann</surname>
<given-names>Jan B.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff008"><sup>8</sup></xref>
<xref ref-type="fn" rid="econtrib001"><sup>‡</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>CREED, Amsterdam School of Economics (ASE), Universiteit van Amsterdam, Amsterdam, the Netherlands</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Amsterdam Brain and Cognition (ABC), Universiteit van Amsterdam, Amsterdam, the Netherlands</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Neurology and Imaging of Cognition (LabNIC), Department of Basic Neurosciences, University of Geneva, Geneva, Switzerland</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Swiss Center for Affective Science (CISA), University of Geneva, Geneva, Switzerland</addr-line></aff>
<aff id="aff005"><label>5</label> <addr-line>Human Reinforcement Learning team, Université de Recherche Paris Sciences et Lettres, Paris, France</addr-line></aff>
<aff id="aff006"><label>6</label> <addr-line>Département d’Études Cognitives, École Normale Supérieure, Paris, France</addr-line></aff>
<aff id="aff007"><label>7</label> <addr-line>Laboratoire de Neurosciences Cognitives et Computationnelles, Institut National de la Santé et de la Recherche Médicale, Paris, France</addr-line></aff>
<aff id="aff008"><label>8</label> <addr-line>The Tinbergen Institute, Amsterdam, the Netherlands</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Latham</surname>
<given-names>Peter E.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>UCL, UNITED KINGDOM</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="other" id="econtrib001">
<p>‡ These authors are both co last authors on this work.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">mael.lebreton@unige.ch</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>8</day>
<month>4</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<month>4</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>4</issue>
<elocation-id>e1006973</elocation-id>
<history>
<date date-type="received">
<day>29</day>
<month>8</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>22</day>
<month>3</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Lebreton et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006973"/>
<abstract>
<p>The ability to correctly estimate the probability of one’s choices being correct is fundamental to optimally re-evaluate previous choices or to arbitrate between different decision strategies. Experimental evidence nonetheless suggests that this metacognitive process—confidence judgment- is susceptible to numerous biases. Here, we investigate the effect of outcome valence (gains or losses) on confidence while participants learned stimulus-outcome associations by trial-and-error. In two experiments, participants were more confident in their choices when learning to seek gains compared to avoiding losses, despite equal difficulty and performance between those two contexts. Computational modelling revealed that this bias is driven by the context-value, a dynamically updated estimate of the average expected-value of choice options, necessary to explain equal performance in the gain and loss domain. The biasing effect of context-value on confidence, revealed here for the first time in a reinforcement-learning context, is therefore domain-general, with likely important functional consequences. We show that one such consequence emerges in volatile environments, where the (in)flexibility of individuals’ learning strategies differs when outcomes are framed as gains or losses. Despite apparent similar behavior- profound asymmetries might therefore exist between learning to avoid losses and learning to seek gains.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>In order to arbitrate between different decision strategies, as well as to inform future choices, a decision maker needs to estimate the probability of her choices being correct as precisely as possible. Surprisingly, this metacognitive operation, known as confidence judgment, has not been systematically investigated in the context of simple instrumental-learning tasks. Here, we assessed how confident individuals are in their choices when learning stimulus-outcome associations by trial-and-errors to maximize gains or to minimize losses. In two experiments, we show that individuals are more confident in their choices when learning to seek gains compared to avoiding losses, despite equal difficulty and performance between those two contexts. To simultaneously account for this pattern of choices and confidence judgments, we propose that individuals learn context-values, which approximate the average expected-value of choice options. We finally show that, in volatile environments, the biasing effect of context-value on confidence induces difference in learning flexibility when outcomes are framed as gains or losses.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100003246</institution-id>
<institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution>
</institution-wrap>
</funding-source>
<award-id>451-15-015</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2071-4890</contrib-id>
<name name-style="western">
<surname>Lebreton</surname>
<given-names>Maël</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung (CH)</institution>
</funding-source>
<award-id>PZ00P3_174127</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2071-4890</contrib-id>
<name name-style="western">
<surname>Lebreton</surname>
<given-names>Maël</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by startup funds from the Amsterdam School of Economics, awarded to JBE. JBE and ML gratefully acknowledge support from Amsterdam Brain and Cognition (ABC). ML is supported by an NWO Veni Fellowship (Grant 451-15-015), a Swiss National Fund Ambizione grant (PZ00P3_174127) and the Fondation Bettencourt Schueller. SP is supported by an ATIP-Avenir grant (R16069JS), the Programme Emergence(s) de la Ville de Paris, the Fondation Fyssen and Fondation Schlumberger pour l’Education et la Recherche. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="5"/>
<page-count count="27"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-04-18</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All codes and data needed to evaluate or reproduce the figures and analysis described in the paper are available online at <ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.6084/m9.figshare.7851767" xlink:type="simple">https://dx.doi.org/10.6084/m9.figshare.7851767</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Simple reinforcement learning algorithms efficiently learn by trial-and-error to implement decision policies that maximize the occurrence of rewards and minimize the occurrence of punishments [<xref ref-type="bibr" rid="pcbi.1006973.ref001">1</xref>]. Such basic algorithms have been extensively used in experimental psychology, neuroscience and economics, and seem to parsimoniously account for a large amount of experimental data at the behavioral [<xref ref-type="bibr" rid="pcbi.1006973.ref002">2</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref003">3</xref>] and neuronal levels [<xref ref-type="bibr" rid="pcbi.1006973.ref004">4</xref>–<xref ref-type="bibr" rid="pcbi.1006973.ref006">6</xref>], as well as for learning abnormalities due to specific pharmacological manipulations [<xref ref-type="bibr" rid="pcbi.1006973.ref007">7</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref008">8</xref>] and neuro-psychiatric disorders [<xref ref-type="bibr" rid="pcbi.1006973.ref009">9</xref>]. Yet, ecological environments are inherently ever-changing, volatile and complex, such that organisms need to be able to flexibly adjust their learning strategies or to dynamically select among different learning strategies. These more sophisticated behaviors can be implemented by reinforcement-learning algorithms which compute different measures of environmental uncertainty [<xref ref-type="bibr" rid="pcbi.1006973.ref010">10</xref>–<xref ref-type="bibr" rid="pcbi.1006973.ref012">12</xref>] or strategy reliability [<xref ref-type="bibr" rid="pcbi.1006973.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1006973.ref015">15</xref>].</p>
<p>To date, surprisingly little research has investigated if and how individuals engaged in learning by trial-and-error can actually compute such reliability estimates or related proxy variables. One way to experimentally assess such reliability estimates is via eliciting confidence judgments. Confidence is defined as a decision-maker’s estimation of her probability of being correct [<xref ref-type="bibr" rid="pcbi.1006973.ref016">16</xref>–<xref ref-type="bibr" rid="pcbi.1006973.ref018">18</xref>]. It results from a meta-cognitive operation [<xref ref-type="bibr" rid="pcbi.1006973.ref019">19</xref>], which according to recent studies could be performed automatically even when confidence judgments are not explicitly required [<xref ref-type="bibr" rid="pcbi.1006973.ref020">20</xref>]. In the context of predictive-inference tasks, individuals’ subjective confidence judgments have been shown to track the likelihood of decisions being correct in changing environments with remarkable accuracy [<xref ref-type="bibr" rid="pcbi.1006973.ref021">21</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref022">22</xref>]. Confidence could therefore be employed as a meta-cognitive variable that enables dynamic comparisons of different learning strategies and ultimately, decisions about whether to adjust learning strategies. Despite the recent surge of neural, computational and behavioral models of confidence estimation in decision-making and prediction tasks [<xref ref-type="bibr" rid="pcbi.1006973.ref017">17</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref023">23</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref024">24</xref>], how decision-makers estimate their confidence in their choices in reinforcement-learning contexts remains poorly investigated.</p>
<p>Crucially, although confidence judgments have been reported to accurately track decision-makers probability of being correct [<xref ref-type="bibr" rid="pcbi.1006973.ref018">18</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref022">22</xref>], they are also known to be subject to various biases. Notably, it appears that individuals are generally overconfident regarding their own performance [<xref ref-type="bibr" rid="pcbi.1006973.ref025">25</xref>], and that confidence judgments are modulated by numerous psychological factors including desirability biases [<xref ref-type="bibr" rid="pcbi.1006973.ref026">26</xref>], arousal [<xref ref-type="bibr" rid="pcbi.1006973.ref027">27</xref>], mood [<xref ref-type="bibr" rid="pcbi.1006973.ref028">28</xref>], and emotions [<xref ref-type="bibr" rid="pcbi.1006973.ref029">29</xref>] such as anxiety [<xref ref-type="bibr" rid="pcbi.1006973.ref030">30</xref>]. A recent study also revealed that monetary stakes can bias individuals’ confidence in their choice: irrespective of the choice correctness, the prospects of gains and losses bias confidence judgments upwards and downwards, respectively [<xref ref-type="bibr" rid="pcbi.1006973.ref031">31</xref>]. Given the potential importance of confidence in mediating learning strategies in changing environments, investigating confidence judgments and their biases in reinforcement-learning appears crucial.</p>
<p>Here, we simultaneously investigated the learning behavior and confidence estimations of individuals engaged in a reinforcement-learning task where the valence of the decision outcomes was systematically manipulated (gains versus losses) [<xref ref-type="bibr" rid="pcbi.1006973.ref008">8</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>]. In this task, young adults have repeatedly been shown to perform equally well in gain-seeking and loss-avoidance learning contexts [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref033">33</xref>]. Yet, in line with the confidence bias induced by monetary stakes [<xref ref-type="bibr" rid="pcbi.1006973.ref031">31</xref>], we hypothesized that individuals would exhibit lower confidence in their choices while learning to avoid losses compared to seeking gains, despite similar performance and objectively equal difficulty between these two learning contexts. In addition, we anticipated that this bias would be generated by the learned <italic>context-value</italic>: this latent variable computed in some reinforcement-learning models–see e.g. [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref034">34</xref>]—approximates the overall expected value from available cues on a trial-by-trial basis, hence it could mimic the effects of the monetary stakes observed in [<xref ref-type="bibr" rid="pcbi.1006973.ref031">31</xref>]. Finally, conditional on those first hypotheses being confirmed, we hypothesized that the valence-induced confidence bias would modulate performance in volatile environments such as reversal tasks.</p>
<p>Our results, which confirm these hypotheses, first illustrate the generalizability of the confidence bias induced by the framing of incentives and outcomes as gains or losses. They also suggest that tracking confidence judgments in reinforcement-learning tasks can provide valuable insight into learning processes. Finally, they reveal that–despite apparent similar behavior- profound asymmetries might exist between learning to avoid losses and learning to seek gains [<xref ref-type="bibr" rid="pcbi.1006973.ref035">35</xref>], with likely important functional consequences.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Experiment 1</title>
<p>We invited 18 participants to partake in our first experiment, and asked them to perform a probabilistic instrumental-learning task adapted from a previous study [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref033">33</xref>]. Participants repeatedly faced pairs of abstract symbols probabilistically associated with monetary outcomes. Symbol pairs were fixed, and associated with two levels of two outcome features, namely valence and information, in a 2×2 factorial design. Therefore, pairs of symbols could be associated with either gains or losses, and with partial or complete feedback (<bold>Methods</bold> and <bold><xref ref-type="fig" rid="pcbi.1006973.g001">Fig 1A and 1B</xref></bold>). Participants could maximize their payoffs by learning to choose the most advantageous symbol of each pair, i.e., the highest expected gain or the lowest expected loss. At each trial, after their choice but before receiving feedback, participants were also asked to report their confidence in their choice on a Likert scale from 0 to 10. Replicating previous findings [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref033">33</xref>], we found that participants correctly learned by trial-and-error to choose the best outcomes, (average correct choice rate 76.50 ± 2.38, t-test vs chance t<sub>17</sub> = 11.16; P = 3.04×10<sup>−9</sup>), and that learning performance was marginally affected by the information factor, but unaffected by the outcome valence (ANOVA; main effect of information F<sub>1,17</sub> = 4.28; P = 0.05; main effect of valence F<sub>1,17</sub> = 1.04; P = 0.32; interaction F<sub>1,17</sub> = 1.06; P = 0.32; <bold><xref ref-type="fig" rid="pcbi.1006973.g001">Fig 1C</xref></bold>). In other words, participants learned equally well to seek gains and to avoid losses. However, and in line with our hypothesis, the confidence ratings showed a very dissimilar pattern, as they were strongly influenced by the valence of outcomes (ANOVA; main effect of information F<sub>1,17</sub> = 2.00; P = 0.17; main effect of valence F<sub>1,17</sub> = 33.11; P = 2,33×10<sup>−11</sup>; interaction F<sub>1,17</sub> = 7.58; P = 0.01; <bold><xref ref-type="fig" rid="pcbi.1006973.g001">Fig 1D</xref></bold>). Similar to the valence bias reported in perceptual decision-making tasks [<xref ref-type="bibr" rid="pcbi.1006973.ref031">31</xref>], these effects were driven by the fact that participants were more confident in the gain than in the loss condition when receiving partial feedback (6.86 ± 0.28 vs 4.66 ± 0.39; t-test t<sub>17</sub> = 7.20; P = 1.50×10<sup>−6</sup>), and that this difference was still very significant although smaller in the complete feedback condition (6.58 ± 0.35 vs 5.24 ± 0.37; t-test t<sub>17</sub> = 3.52; P = 2.65×10<sup>−3</sup>).</p>
<fig id="pcbi.1006973.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.g001</object-id>
<label>Fig 1</label>
<caption>
<title/>
<p><bold>Experiment 1 Task Schematic, Learning and Confidence Results (A) Behavioral task.</bold> Successive screens displayed in one trial are shown from left to right with durations in ms. After a fixation cross, participants viewed a couple of abstract symbols displayed on both sides of a computer screen and had to choose between them. They were thereafter asked to report their confidence in their choice on a numerical scale (graded from 0 to 10). Finally, the outcome associated with the chosen symbol was revealed. (B) <bold>Task design and contingencies.</bold> (C) <bold>Performance.</bold> Trial by trial percentage of correct responses in the partial (left) and the complete (middle) information conditions. Filled colored areas represent mean ± sem; Right: Individual averaged performances in the different conditions. Connected dots represent individual data points in the within-subject design. The error bar displayed on the side of the scatter plots indicate the sample mean ± sem. (D) <bold>Confidence.</bold> Trial by trial confidence ratings in the partial (left) and the complete (middle) information conditions. Filled colored areas represent mean ± sem; Right: Individual averaged performances in the different conditions. Connected dots represent individual data points in the within-subject design. The error bar displayed on the side of the scatter plots indicate the sample mean ± sem.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.g001" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec004">
<title>Experiment 2</title>
<p>While the results of the first experiment are strongly suggestive of an effect of outcome valence on confidence in reinforcement learning, they cannot <italic>formally</italic> characterize a bias, as the notion of cognitive bias depends on the optimal reward-maximizing strategy [<xref ref-type="bibr" rid="pcbi.1006973.ref036">36</xref>]. In other terms: does this bias persist in situations where a truthful and accurate confidence report is associated with payoff maximization? We addressed this limitation of experiment 1 by directly incentivizing reports of confidence accuracy in our follow-up experiment. In this new experiment, confidence was formally defined as an estimation of the probability of being correct, and participants could maximize their chance to gain an additional monetary bonus (3×5 euros) by reporting their confidence as accurately and truthfully as possible on a rating scale ranging from 50% to 100% (<bold><xref ref-type="fig" rid="pcbi.1006973.g002">Fig 2A</xref></bold>). Specifically, confidence judgments were incentivized with a Matching Probability (MP) mechanism, a well-validated method from behavioral economics adapted from the Becker-DeGroot-Marschak auction [<xref ref-type="bibr" rid="pcbi.1006973.ref037">37</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref038">38</xref>]. Briefly, the MP mechanism considers participants’ confidence reports as bets on the correctness of their answers, and implements comparisons between these bets and random lotteries (<bold><xref ref-type="fig" rid="pcbi.1006973.g003">Fig 3A</xref></bold>). Under utility maximization assumptions, this guarantees that participants maximize their earnings by reporting their most precise and truthful confidence estimation [<xref ref-type="bibr" rid="pcbi.1006973.ref039">39</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref040">40</xref>]. This mechanism and the dominant strategy were explained to the 18 new participants before the experiment (<bold>Methods</bold>). In addition, because the neutral and non-informative outcome was more frequently experienced in the punishment partial than in the reward partial context in experiment 1, we replaced the neutral 0€ with a 10c gain or loss (see <bold><xref ref-type="sec" rid="sec008">Methods</xref></bold> and <bold><xref ref-type="fig" rid="pcbi.1006973.g002">Fig 2B</xref></bold>).</p>
<fig id="pcbi.1006973.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.g002</object-id>
<label>Fig 2</label>
<caption>
<title/>
<p><bold>Experiment 2 Task Schematic, Learning and Confidence Results (A) Behavioral task.</bold> Successive screens displayed in one trial are shown from left to right with durations in ms. After a fixation cross, participants viewed a couple of abstract symbols displayed on both sides of a computer screen, and had to choose between them. They were thereafter asked to report their confidence in their choice on a numerical scale (graded from 50 to 100%). Finally, the outcome associated with the chosen symbol was revealed. (B) <bold>Task design and contingencies.</bold> (C) <bold>Performance.</bold> Trial by trial percentage of correct responses in the partial (left) and the complete (middle) information conditions. Filled colored areas represent mean ± sem; Right: Individual averaged performances in the different conditions. Connected dots represent individual data points in the within-subject design. The error bar displayed on the side of the scatter plots indicate the sample mean ± sem. (D) <bold>Confidence.</bold> Trial by trial confidence ratings in the partial (left) and the complete (middle) information conditions. Filled colored areas represent mean ± sem; Right: Individual averaged performances in the different conditions. Connected dots represent individual data points in the within-subject design. The error bar displayed on the side of the scatter plots indicate the sample mean ± sem.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.g002" xlink:type="simple"/>
</fig>
<fig id="pcbi.1006973.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.g003</object-id>
<label>Fig 3</label>
<caption>
<title/>
<p><bold>Incentive mechanism and overconfidence (A) Incentive mechanism.</bold> In Experiment 2, for the payout-relevant trials a lottery L is randomly drawn in the 50–100% interval and compared to the confidence rating C. If L &gt; C, the lottery is implemented. A wheel of fortune, with a L% chance of losing is displayed, and played out. Then, feedback informed participants whether the lottery resulted in a win or a loss. If C &gt; L, a clock is displayed together with the message “Please wait”, followed by feedback which depended on the correctness of the initial choice. With this mechanism, participant can maximize their earning by reporting their confidence accurately and truthfully. (B) <bold>Overconfidence</bold>. Individual averaged calibration, as a function of Experiment 2 experimental conditions (with a similar color code as in <bold>Figs <xref ref-type="fig" rid="pcbi.1006973.g001">1</xref> and <xref ref-type="fig" rid="pcbi.1006973.g002">2</xref></bold>). Connected dots represent individual data points in the within-subject design. The error bar displayed on the side of the scatter plots indicate the sample mean ± sem.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.g003" xlink:type="simple"/>
</fig>
<p>Replicating the results from the first experiment, we found that learning performance was affected by the information factor, but unaffected by the outcome valence (ANOVA; main effect of information F<sub>1,17</sub> = 18.64; P = 4.67×10<sup>−4</sup>; main effect of valence F<sub>1,17</sub> = 1.33×10<sup>−3</sup>; P = 0.97; interaction F<sub>1,17</sub> = 0.77; P = 0.39; <bold><xref ref-type="fig" rid="pcbi.1006973.g002">Fig 2C</xref></bold>). Yet, the confidence ratings were again strongly influenced by the valence of outcomes (ANOVA; main effect of information F<sub>1,17</sub> = 4.92; P = 0.04; main effect of valence F<sub>1,17</sub> = 15.43; P = 1.08×10<sup>−3</sup>; interaction F<sub>1,17</sub> = 4.25; P = 0.05; <bold><xref ref-type="fig" rid="pcbi.1006973.g002">Fig 2D</xref></bold>). Similar to Experiment 1, these effects were driven by the fact that participants were more confident in the gain than in the loss conditions (85.25 ± 1.23 vs 76.96 ± 2.38 (in %); t-test t<sub>17</sub> = 3.93; P = 1.08×10<sup>−3</sup>).</p>
<p>Importantly, the changes in the experimental design also allowed us to estimate the bias in confidence judgments (sometimes called calibration, or “overconfidence”), by contrasting individuals’ average reported confidence (i.e. estimated probability of being correct) with their actual average probability of being correct. A positive bias therefore indicates that participants are overconfident reporting a higher probability of being correct than their objective average performance. Conversely, a negative bias indicates reporting a lower probability of being correct than the true average (“underconfidence”). These analyses revealed that participants are, in general marginally overconfident (4.07 ± 2.37 (%); t-test vs 0: t<sub>17</sub> = 1.72; P = 0.10). This overconfidence, which was maximal in the gain-partial information condition (14.00 ± 3.86 (%)), was nonetheless mitigated by complete information (gain-complete: 2.53 ± 2.77 (%); t-test vs gain-partial: t<sub>17</sub> = 2.72; P = 0.01) and losses (loss-partial: 1.56 ± 3.35 (%); t-test vs gain-partial: t<sub>17</sub> = 2.76; P = 0.01). These effects of outcome valence and counterfactual feedback information on overconfidence appeared to be simply additive (ANOVA; main effect of information F<sub>1,17</sub> = 8.40; P = 0.01; main effect of valence F<sub>1,17</sub> = 7.03; P = 0.02; interaction F<sub>1,17</sub> = 2.05; P = 0.17; <bold><xref ref-type="fig" rid="pcbi.1006973.g003">Fig 3B</xref></bold>).</p>
</sec>
<sec id="sec005">
<title>Context-dependent learning</title>
<p>While the results from our two first experiments provide convincing support for our hypotheses at the aggregate level (i.e. averaged choice rate and confidence ratings), we aimed at providing a finer description of the dynamical processes at stake, and therefore turned to computational modelling. Standard reinforcement-learning algorithms [<xref ref-type="bibr" rid="pcbi.1006973.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref003">3</xref>] typically give a satisfactory account of learning dynamics in stable contingency tasks as ours, but recent studies [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1006973.ref034">34</xref>] have demonstrated that human learning is highly context (or reference)-dependent. The specific context-dependent reinforcement-learning algorithm proposed to account for learning and post-learning choices in the present task explicitly computes a context-value, which approximates the average expected value from a specific context [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>]. We therefore hypothesized that this latent variable would capture the effects of monetary stakes observed in our previous study [<xref ref-type="bibr" rid="pcbi.1006973.ref031">31</xref>] and bias confidence. While this hypothesis about confidence will be explicitly tested in the in the next section, we first aim to demonstrate in the present section that context-dependent learning is necessary to explain choices.</p>
<p>Context dependency, by allowing neutral or moderately negative outcomes to be reframed as relative gains, provides an effective and parsimonious solution to the punishment-avoidance paradox. Briefly, this paradox stems from the notion that once a punishment is successfully avoided, the instrumental response is no longer reinforced. Reward learning (in which the extrinsic reinforcements are frequent, because they are sought) should therefore, theoretically, be more efficient than punishment learning (in which the extrinsic reinforcements are infrequent, because they are avoided). Yet, human subjects have repeatedly been shown to learn equally well in both domains, which paradoxically contradicts this prediction [<xref ref-type="bibr" rid="pcbi.1006973.ref041">41</xref>]. Reframing successful punishment-avoidance as a relative gain in context-dependent learning models solves this punishment-avoidance paradox.</p>
<p>Typically, implementing context dependency during learning generates “irrational” preferences in a transfer task performed after learning: participants express higher preference for mildly unfavorable items to objectively better items, because the former were initially paired with unfavorable items and hence acquired a higher “relative” subjective value [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1006973.ref034">34</xref>]. As in these previous studies, the participants from our two experiments also performed the transfer task after the learning task (see <bold><xref ref-type="sec" rid="sec008">Methods</xref></bold>). The typical behavioral signature of context-dependent learning is a preference reversal in the complete information contexts, where symbols associated with small losses (L<sub>25</sub>) are preferred to symbols associated with small gains (G<sub>25</sub>), despite having objectively lower expected value [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1006973.ref034">34</xref>]. This pattern was present in both of our experiments (% choices; experiment 1: L<sub>25</sub>: 59.52 ± 4.88, G<sub>25</sub>: 38.89 ± 5.04; t-test t<sub>17</sub> = 2.46; P = 0.02; experiment 2: L<sub>25</sub>: 67.26 ± 5.35, G<sub>25</sub>: 28.37 ± 4.46; t-test t<sub>17</sub> = 5.27; P = 6.24×10<sup>−5</sup>, see <bold><xref ref-type="fig" rid="pcbi.1006973.g004">Fig 4A and 4B</xref></bold>, middle panels).</p>
<fig id="pcbi.1006973.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Modelling results: Fits.</title>
<p>Behavioral results and model fits in Experiments 1(<bold>A</bold>) and 2 (<bold>B</bold>). Top: Learning performance (i.e. percent correct). Middle: Choice rate in the transfer test. Symbols are ranked by expected value (L<sub>75</sub>: symbol associated with 75% probability of losing 1€; L<sub>25</sub>: symbol associated with 25% probability of losing 1€; G<sub>25</sub>: symbol associated with 25% probability of winning 1€; G<sub>75</sub>: symbol associated with 75% probability of winning 1€;) Bottom: Confidence ratings. In all panels, colored dots and error bars represent the actual data (mean ± sem), and filled areas represent the model fits (mean ± sem). Model fits were obtained with the RELATIVE reinforcement-learning model for the learning performance (top) and the choice rate in the transfer test (middle), and with the FULL glme for the confidence ratings (bottom). Dark grey diamonds in the Preference panels (middle) indicate the fit from the ABSOLUTE model.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.g004" xlink:type="simple"/>
</fig>
<p>To confirm these observations, we adopted a model-fitting and model-comparison approach, where a standard learning model (ABSOLUTE) was compared to a context-dependent learning model (RELATIVE) in its ability to account for the participants’ choices (<bold>Methods</bold>). Replicating previous findings [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref033">33</xref>], the context-dependent model provided the best and most parsimonious account of the data collected in our 2 experiments (<bold><xref ref-type="table" rid="pcbi.1006973.t001">Table 1</xref></bold>), and a satisfactory account of choice patterns in both the learning (average likelihood per trial in experiment 1: 0.72 ± 0.03; in experiment 2: 0.72 ± 0.02; see <bold><xref ref-type="fig" rid="pcbi.1006973.g004">Fig 4A and 4B</xref></bold>, top panels) and transfer tasks (average likelihood per trial; experiment 1: 0.71 ± 0.02; experiment 1: 0.70 ± 0.02; see <bold><xref ref-type="fig" rid="pcbi.1006973.g004">Fig 4A and 4B</xref></bold>, middle panels). Please also note that the model estimated free-parameters (<bold><xref ref-type="table" rid="pcbi.1006973.t002">Table 2</xref></bold>) are very similar to what was reported in the previous studies [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref033">33</xref>].</p>
<table-wrap id="pcbi.1006973.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.t001</object-id>
<label>Table 1</label> <caption><title>Reinforcement-learning.</title> <p><bold>Model comparison.</bold> AIC, Akaike Information Criterion (computed with nLL<sub>max</sub>); BIC, Bayesian Information Criterion (computed with nLL<sub>max</sub>); DF, degrees of freedom; nLL<sub>max</sub>, negative log likelihood; nLPP<sub>max</sub>, negative log of posterior probability; EF, expected frequency of the model given the data; XP, exceedance probability (computed using the Laplace approximation of the model evidence ME). The table summarizes for each model its fitting performances.</p></caption>
<alternatives>
<graphic id="pcbi.1006973.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<tbody>
<tr>
<td align="center" rowspan="3"><bold>Exp. 1</bold></td>
<td align="center"><bold>Model</bold></td>
<td align="center"><bold>DF</bold></td>
<td align="center"><bold>-2*nLL</bold><sub><bold>max</bold></sub></td>
<td align="center"><bold>2*AIC</bold></td>
<td align="center"><bold>BIC</bold></td>
<td align="center"><bold>-2*nLPP</bold><sub><bold>max</bold></sub></td>
<td align="center"><bold>EF</bold></td>
<td align="center"><bold>XP</bold></td>
</tr>
<tr>
<td align="center">ABSOLUTE</td>
<td align="center">3</td>
<td align="center">385±20</td>
<td align="center">392±20</td>
<td align="center">404±20</td>
<td align="center">391±20</td>
<td align="center">0.28</td>
<td align="center">0.02</td>
</tr>
<tr>
<td align="center">RELATIVE</td>
<td align="center">4</td>
<td align="center">345±24</td>
<td align="center">353±24</td>
<td align="center">369±24</td>
<td align="center">354±24</td>
<td align="center">0.72</td>
<td align="center">0.98</td>
</tr>
<tr>
<td align="center" rowspan="3"><bold>Exp. 2</bold></td>
<td align="center"><bold>Model</bold></td>
<td align="center"><bold>DF</bold></td>
<td align="center"><bold>-2*nLL</bold><sub><bold>max</bold></sub></td>
<td align="center"><bold>2*AIC</bold></td>
<td align="center"><bold>BIC</bold></td>
<td align="center"><bold>-2*nLPP</bold><sub><bold>max</bold></sub></td>
<td align="center"><bold>EF</bold></td>
<td align="center"><bold>XP</bold></td>
</tr>
<tr>
<td align="center">ABSOLUTE</td>
<td align="center">3</td>
<td align="center">411±15</td>
<td align="center">417±15</td>
<td align="center">429±15</td>
<td align="center">416±15</td>
<td align="center">0.05</td>
<td align="center">0.0</td>
</tr>
<tr>
<td align="center">RELATIVE</td>
<td align="center">4</td>
<td align="center">355±16</td>
<td align="center">363±16</td>
<td align="center">379±16</td>
<td align="center">362±16</td>
<td align="center">0.95</td>
<td align="center">1.0</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="pcbi.1006973.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.t002</object-id>
<label>Table 2</label> <caption><title>Reinforcement-learning.</title> <p><bold>Free parameters.</bold> ABSOLUTE, absolute value learning model; RELATIVE, relative value learning model (best-fitting model); LL optimization, parameters obtained when minimizing the negative log likelihood; LPP optimization, parameters obtained when minimizing the negative log of the posterior probability. The table summarizes for each model the likelihood maximizing (best) parameters averaged across subjects. Data are expressed as mean±s.e.m. The values retrieved from the LPP optimization procedure are those used to generate the variable used in the confidence glme models.</p></caption>
<alternatives>
<graphic id="pcbi.1006973.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<tbody>
<tr>
<td align="center" colspan="2"/>
<td align="center" colspan="2"><bold>LL Optimization</bold></td>
<td align="center" colspan="2"><bold>LPP Optimization</bold></td>
</tr>
<tr>
<td align="center" rowspan="5"><bold>Exp. 1</bold></td>
<td align="center"><bold>Free Parameter</bold></td>
<td align="center">ABSOLUTE</td>
<td align="center">RELATIVE</td>
<td align="center">ABSOLUTE</td>
<td align="center">RELATIVE</td>
</tr>
<tr>
<td align="center">Inverse temperature (<italic>β</italic>)</td>
<td align="center">6.29±0.63</td>
<td align="center">54.04±38.8</td>
<td align="center">6.07±0.61</td>
<td align="center">12.65±1.47</td>
</tr>
<tr>
<td align="center">Factual learning rate (<italic>α</italic><sub><italic>c</italic></sub>)</td>
<td align="center">0.37±0.05</td>
<td align="center">0.23±0.04</td>
<td align="center">0.36±0.04</td>
<td align="center">0.24±0.04</td>
</tr>
<tr>
<td align="center">Counterfactual learning rate (<italic>α</italic><sub><italic>u</italic></sub>)</td>
<td align="center">0.13±0.03</td>
<td align="center">0.07±0.02</td>
<td align="center">0.15±0.03</td>
<td align="center">0.09±0.02</td>
</tr>
<tr>
<td align="center">Context learning rate (<italic>α</italic><sub><italic>V</italic></sub>)</td>
<td align="center">-</td>
<td align="center">0.46±0.10</td>
<td align="center">-</td>
<td align="center">0.46±0.10</td>
</tr>
<tr>
<td align="center" colspan="2"/>
<td align="center" colspan="2"><bold>LL Optimization</bold></td>
<td align="center" colspan="2"><bold>LPP Optimization</bold></td>
</tr>
<tr>
<td align="center" rowspan="5"><bold>Exp. 2</bold></td>
<td align="center"><bold>Free Parameter</bold></td>
<td align="center">ABSOLUTE</td>
<td align="center">RELATIVE</td>
<td align="center">ABSOLUTE</td>
<td align="center">RELATIVE</td>
</tr>
<tr>
<td align="center">Inverse temperature (<italic>β</italic>)</td>
<td align="center">102.00±99.49</td>
<td align="center">83.05±73.15</td>
<td align="center">2.65±0.29</td>
<td align="center">6.86±0.81</td>
</tr>
<tr>
<td align="center">Factual learning rate (<italic>α</italic><sub><italic>c</italic></sub>)</td>
<td align="center">0.49±0.07</td>
<td align="center">0.26±0.04</td>
<td align="center">0.49±0.07</td>
<td align="center">0.24±0.04</td>
</tr>
<tr>
<td align="center">Counterfactual learning rate (<italic>α</italic><sub><italic>u</italic></sub>)</td>
<td align="center">0.24±0.08</td>
<td align="center">0.12±0.04</td>
<td align="center">0.24±0.08</td>
<td align="center">0.13±0.03</td>
</tr>
<tr>
<td align="center">Context learning rate (<italic>α</italic><sub><italic>V</italic></sub>)</td>
<td align="center">-</td>
<td align="center">0.41±0.09</td>
<td align="center">-</td>
<td align="center">0.40±0.09</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec006">
<title>A descriptive model of confidence formation</title>
<p>We next used latent variables from this computational model, along with other variables known to inform confidence judgments, to inform a descriptive model of confidence formation. We propose confidence to be under the influence of three main variables, entered as explanatory variables in linear mixed-effect regressions (FULL model–see <bold><xref ref-type="sec" rid="sec008">Methods</xref>. Confidence Model</bold>). The first explanatory variable is choice difficulty, a feature captured in value-based choices by the absolute difference between the expected value of the two choice options [<xref ref-type="bibr" rid="pcbi.1006973.ref042">42</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref043">43</xref>], and indexed by the absolute difference between the option Q-values calculated by the RELATIVE model. The second explanatory variable is the confidence expressed at the preceding trial. Confidence judgments indeed exhibit a strong auto-correlation, even when they relate to decisions made in different tasks [<xref ref-type="bibr" rid="pcbi.1006973.ref044">44</xref>]. Note that in our task, where the stimuli are presented in an interleaved design, this last term captures the features of confidence which are transversal to different contexts such as aspecific drifts due to attention fluctuation and/or fatigue. The third and final explanatory variable is V(s), the approximation of the average expected-value of a pair of stimuli (i.e., the context value from the RELATIVE model) [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>]. The context value, initialized at zero, gradually becomes positive in the reward-seeking conditions and negative in the punishment-avoidance conditions. This variable is central to our hypothesis that the decision frame (gain vs. loss) influences individuals’ estimated confidence about being correct [<xref ref-type="bibr" rid="pcbi.1006973.ref031">31</xref>]. Crucially, in the FULL model, all included explanatory variables were significant predictors of confidence ratings in both experiments (see <bold><xref ref-type="table" rid="pcbi.1006973.t003">Table 3</xref></bold>). As a quality check, we also verified that the confidence ratings estimated under the FULL model satisfactorily capture the evolution of observed confidence ratings across the course of our experiments (<bold><xref ref-type="fig" rid="pcbi.1006973.g004">Fig 4A and 4B</xref></bold>, bottom panels).</p>
<table-wrap id="pcbi.1006973.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.t003</object-id>
<label>Table 3</label> <caption><title>Modelling confidence ratings.</title> <p>Estimated fixed-effect coefficients from generalized linear mixed-effect models.</p></caption>
<alternatives>
<graphic id="pcbi.1006973.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.t003" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<tbody>
<tr>
<td align="center" colspan="2"/>
<td align="center" colspan="3"><bold>GLME</bold></td>
</tr>
<tr>
<td align="center" rowspan="5"><bold>Experiment 1</bold></td>
<td align="center"><bold>Fixed-Effect</bold></td>
<td align="center"><bold>REDUCED 1</bold></td>
<td align="center"><bold>REDUCED 2</bold></td>
<td align="center"><bold>FULL</bold></td>
</tr>
<tr>
<td align="center">Intercept (<italic>β</italic><sub>0</sub>)</td>
<td align="center">0.52±0.04<break/>t<sub>5079</sub> = 14.46; P = 1.90×10<sup>−46</sup></td>
<td align="center">0.72±0.02<break/>t<sub>5124</sub> = 39.00; P = 1.61×10<sup>−291</sup></td>
<td align="center">0.53±0.04<break/>t<sub>5078</sub> = 14.55; P = 4.92×10<sup>−47</sup></td>
</tr>
<tr>
<td align="center">Choice difficulty (<italic>β</italic><sub>Δ<italic>Q</italic></sub>)</td>
<td align="center">0.33±0.06<break/>t<sub>5079</sub> = 5.77; P = 8.43×10<sup>−9</sup></td>
<td align="center">0.47±0.07<break/>t<sub>5124</sub> = 6.51; P = 8.18×10<sup>−11</sup>-</td>
<td align="center">0.30±0.05<break/>t<sub>5078</sub> = 5.96; P = 2.73×10<sup>−9</sup></td>
</tr>
<tr>
<td align="center">Preceding confidence (<italic>β</italic><sub><italic>c</italic>1</sub>)</td>
<td align="center">0.28±0.04<break/>t<sub>5079</sub> = 7.60; P = 3.62×10<sup>−14</sup></td>
<td align="center">-</td>
<td align="center">0.28±0.03<break/>t<sub>5078</sub> = 7.39; P = 1.67×10<sup>−13</sup></td>
</tr>
<tr>
<td align="center">Context value (<italic>β</italic><sub><italic>V</italic></sub>)</td>
<td align="center">-</td>
<td align="center">0.45±0.14<break/>t<sub>5124</sub> = 3.16; P = 1.58×10<sup>−3</sup></td>
<td align="center">0.47±0.14<break/>t<sub>5078</sub> = 3.21; P = 1.35×10<sup>−3</sup></td>
</tr>
<tr>
<td align="center" colspan="2"/>
<td align="center" colspan="3"><bold>GLME</bold></td>
</tr>
<tr>
<td align="center" rowspan="5"><bold>Experiment 2</bold></td>
<td align="center"><bold>Fixed-Effect</bold></td>
<td align="center"><bold>REDUCED 1</bold></td>
<td align="center"><bold>REDUCED 2</bold></td>
<td align="center"><bold>FULL</bold></td>
</tr>
<tr>
<td align="center">Intercept (<italic>β</italic><sub>0</sub>)</td>
<td align="center">0.53±0.03<break/>t<sub>5145</sub> = 17.57; P = 3.77×10<sup>−67</sup></td>
<td align="center">0.75±0.02<break/>t<sub>5145</sub> = 44.91; P = 0</td>
<td align="center">0.53±0.03<break/>t<sub>5144</sub> = 17.12; P = 5.94×10<sup>−64</sup></td>
</tr>
<tr>
<td align="center">Choice difficulty (<italic>β</italic><sub>Δ<italic>Q</italic></sub>)</td>
<td align="center">0.18±0.02<break/>t<sub>5145</sub> = 6.33; P = 2.63×10<sup>−10</sup></td>
<td align="center">0.25±0.04<break/>t<sub>5145</sub> = 6.51; P = 8.26×10<sup>−11</sup></td>
<td align="center">0.17±0.03<break/>t<sub>5144</sub> = 5.90; P = 3.85×10<sup>−9</sup></td>
</tr>
<tr>
<td align="center">Preceding confidence (<italic>β</italic><sub><italic>c</italic>1</sub>)</td>
<td align="center">0.29±0.04<break/>t<sub>5145</sub> = 7.01; P = 2.75×10<sup>−12</sup></td>
<td align="center">-</td>
<td align="center">0.30±0.04<break/>t<sub>5144</sub> = 7.48; P = 8.54×10<sup>−14</sup></td>
</tr>
<tr>
<td align="center">Context value (<italic>β</italic><sub><italic>V</italic></sub>)</td>
<td align="center">-</td>
<td align="center">0.17±0.7<break/>t<sub>5145</sub> = 2.52; P = 1.18×10<sup>−2</sup></td>
<td align="center">0.16±0.06<break/>t<sub>5144</sub> = 2.51; P = 1.19×10<sup>−2</sup></td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001"><p>Note that the number of degrees-of-freedom differs between REDUCED GLME 1 and 2 in Experiment 1, because some participants failed to answer within the allocated time, causing missed observations. This has a lower impact on the number of usable observations in the REDUCED GLME 2 because this model does not make use of “preceding confidence” (which are missing observations–in addition to the missed trials- in the REDUCED GLME 2 and FULL FLME).</p></fn>
</table-wrap-foot>
</table-wrap>
<p>On the contrary, when attempting to predict the trial-by-trial correct answers (i.e. performance) rather than confidence judgments with the same explanatory variables, the choice difficulty and the confidence expressed at the preceding trial were significant predictors in the two experiments, while the context value was not (<bold><xref ref-type="table" rid="pcbi.1006973.t004">Table 4</xref></bold>). This again captures the idea that context value might bias confidence judgments above and beyond the variation in performance. Finally, because decision reaction times are known to be (negatively) correlated with subsequent confidence judgments—the more confident individuals are in their choices, the faster their decisions [<xref ref-type="bibr" rid="pcbi.1006973.ref020">20</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref042">42</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref045">45</xref>]-, we anticipated and verified that the same explanatory variables which are significant predictors of confidence also predict reaction times (although with opposite signs–see <bold><xref ref-type="table" rid="pcbi.1006973.t004">Table 4</xref></bold>).</p>
<table-wrap id="pcbi.1006973.t004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.t004</object-id>
<label>Table 4</label> <caption><title>Modelling performance and reaction times.</title> <p>Estimated fixed-effect coefficients from generalized linear mixed-effect models (performance: logistic regression; reaction times: linear regression).</p></caption>
<alternatives>
<graphic id="pcbi.1006973.t004g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.t004" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<tbody>
<tr>
<td align="center" colspan="2"/>
<td align="center" colspan="2"><bold>GLME</bold></td>
</tr>
<tr>
<td align="center" rowspan="5"><bold>Experiment 1</bold></td>
<td align="center"><bold>Fixed-Effect</bold></td>
<td align="center"><bold>PERFORMANCE</bold></td>
<td align="center"><bold>RT</bold></td>
</tr>
<tr>
<td align="center">Intercept (<italic>β</italic><sub>0</sub>)</td>
<td align="center">-0.84±0.20<break/>t<sub>5078</sub> = -4.15; P = 3.40×10<sup>−5</sup></td>
<td align="center">1.90±0.09<break/>t<sub>5078</sub> = 20.12; P = 1.12×10<sup>−86</sup></td>
</tr>
<tr>
<td align="center">Choice difficulty (<italic>β</italic><sub>Δ<italic>Q</italic></sub>)</td>
<td align="center">9.90±1.67<break/>t<sub>5078</sub> = 5.92; P = 3.32×10<sup>−9</sup></td>
<td align="center">-0.65±0.20<break/>t<sub>5078</sub> = -3.15; P = 1.63×10<sup>−3</sup></td>
</tr>
<tr>
<td align="center">Preceding confidence (<italic>β</italic><sub><italic>c</italic>1</sub>)</td>
<td align="center">1.28±0.36<break/>t<sub>5078</sub> = 3.60; P = 3.19×10<sup>−4</sup></td>
<td align="center">-0.24±0.14<break/>t<sub>5078</sub> = -1.78; P = 0.08</td>
</tr>
<tr>
<td align="center">Context value (<italic>β</italic><sub><italic>V</italic></sub>)</td>
<td align="center">1.19±0.54<break/>t<sub>5078</sub> = 2.19; P = 0.03</td>
<td align="center">-0.37±0.11<break/>t<sub>5078</sub> = -3.48; P = 5.04×10<sup>−4</sup></td>
</tr>
<tr>
<td align="center" colspan="2"/>
<td align="center" colspan="2"><bold>GLME</bold></td>
</tr>
<tr>
<td align="center" rowspan="5"><bold>Experiment 2</bold></td>
<td align="center"><bold>Fixed-Effect</bold></td>
<td align="center"><bold>PERFORMANCE</bold></td>
<td align="center"><bold>RT</bold></td>
</tr>
<tr>
<td align="center">Intercept (<italic>β</italic><sub>0</sub>)</td>
<td align="center">-0.71±0.22<break/>t<sub>5144</sub> = -3.20; P = 1.37×10<sup>−3</sup></td>
<td align="center">1.68±0.09<break/>t<sub>5144</sub> = 17.93; P = 9.09×10<sup>−70</sup></td>
</tr>
<tr>
<td align="center">Choice difficulty (<italic>β</italic><sub>Δ<italic>Q</italic></sub>)</td>
<td align="center">5.29±0.76<break/>t<sub>5144</sub> = 6.94; P = 4.49×10<sup>−12</sup></td>
<td align="center">-0.41±0.09<break/>t<sub>5144</sub> = -4.50; P = 6.81×10<sup>−6</sup></td>
</tr>
<tr>
<td align="center">Preceding confidence (<italic>β</italic><sub><italic>c</italic>1</sub>)</td>
<td align="center">1.21±0.33<break/>t<sub>5144</sub> = 3.66; P = 2.57×10<sup>−4</sup></td>
<td align="center">-0.54±0.10<break/>t<sub>5144</sub> = -5.31; P = 1.08×10<sup>−7</sup></td>
</tr>
<tr>
<td align="center">Context value (<italic>β</italic><sub><italic>V</italic></sub>)</td>
<td align="center">0.30±0.28<break/>t<sub>5144</sub> = 1.05; P = 0.29</td>
<td align="center">-0.17±0.05<break/>t<sub>5144</sub> = -3.68; P = 2.35×10<sup>−4</sup></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<sec id="sec007">
<title>Context values explain the confidence bias</title>
<p>In this last section, we aimed at demonstrating that the context values are necessary and sufficient to explain the difference in confidence observed between the reward seeking and the loss avoidance conditions. We therefore built a REDUCED model 1, which was similar to the FULL model, but lacked the context value (see <bold><xref ref-type="table" rid="pcbi.1006973.t003">Table 3</xref></bold>). First, because the REDUCED model 1 is nested in the FULL model, a likelihood ratio test statistically assesses the probability of observing the estimated fitting difference under the null hypothesis that the FULL model is not better than the REDUCED model 1. In both experiments, this null hypothesis was rejected (both P&lt;0.001), indicating that the FULL model provides a better explanation of the observed data. Hence confidence is critically modulated by the context value.</p>
<p>Then, to demonstrate that the biasing effect of outcome valence on confidence is operated through the context value, we show that the REDUCED model 1 (see <bold><xref ref-type="sec" rid="sec008">Methods</xref></bold> for a detailed model description), which only lacks the context value as an explanatory variable, cannot reproduce the critical pattern of valence-induced confidence biases observed in our data, while the FULL model can (<bold><xref ref-type="fig" rid="pcbi.1006973.g005">Fig 5</xref></bold>) [<xref ref-type="bibr" rid="pcbi.1006973.ref046">46</xref>].</p>
<fig id="pcbi.1006973.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Modelling results: Lesioning approach.</title>
<p>Three nested models are compared in their ability to reproduce the pattern of interest observed in averaged confidence ratings, in experiment 1 (<bold>A</bold>) and experiment 2 (<bold>B</bold>). In the FULL model, confidence is modelled as a function of three factors: the absolute difference between options values, the confidence observed in the previous trial, and the context value. In the REDUCED model 1, confidence is modelled as a function of only two factors: the absolute difference between options values and the confidence observed in the previous trial. Hence, the REDUCED model 1 omits the context-value as a predictor of confidence. In the REDUCED model 2, confidence is modelled as a function of only two factors: the absolute difference between options values and the context-value. Hence, the REDUCED model 2 omits the confidence observed in the previous trial as a predictor of confidence. Left: pattern of confidence ratings observed in the behavioral data. Middle-left: pattern of confidence ratings estimated from the FULL model. Middle-right: pattern of confidence ratings estimated from the REDUCED model 1. Right: pattern of confidence ratings estimated from the REDUCED model 2. In red are reported statistics from a repeated-measure ANOVA where the alternative model fails to reproduce important statistical properties of confidence observed in the data. Connected dots represent individual data points in the within-subject design. The error bar displayed on the side of the scatter plots indicate the sample mean ± sem.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.g005" xlink:type="simple"/>
</fig>
<p>We performed similar analyses with a REDUCED model 2 (see <bold><xref ref-type="sec" rid="sec008">Methods</xref></bold> for a detailed model description), which only lacked the dependence on preceding confidence ratings. While this model could reproduce the valence-induced bias in confidence (<bold><xref ref-type="fig" rid="pcbi.1006973.g005">Fig 5</xref></bold>), likelihood ratio tests again rejected the hypothesis that the FULL model is not better than the REDUCED model 2 in both experiments (both P&lt;0.001). Overall, those analyses demonstrate that both context-value and preceding confidence are necessary variables to explain confidence, context value being the crucial factor necessary to explain the valence-induced bias.</p>
<p>Overall, these results provide additional evidence for the importance of context value as an important latent variable in learning, not only explaining irrational choices in transfer tests, but also confidence biases observed during learning (<bold><xref ref-type="fig" rid="pcbi.1006973.g006">Fig 6</xref></bold>).</p>
<fig id="pcbi.1006973.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Summary of the modelling results.</title>
<p>The schematic illustrates the computational architecture that best accounts for the choice and confidence data. In each context (or state) ‘s’, the agent tracks option values (Q(s,:)), which are used to decide amongst alternative courses of action, together with the value of the context (V(s)), which quantify the average expected value of the decision context. In all contexts, the agent receives an outcome associated with the chosen option (R<sub>c</sub>), which is used to update the chosen option value (Q(s,c)) via a prediction error (δ<sub>c</sub>) weighted by a learning rate (α<sub>c</sub>). In the complete feedback condition, the agent also receives information about the outcome of the unselected option (R<sub>u</sub>), which is used to update the unselected option value (Q(s,u)) via a prediction error (δ<sub>u</sub>) weighted by a learning rate (α<sub>u</sub>). The available feedback information (R<sub>c</sub> and R<sub>u</sub>, in the complete feedback contexts and Q(s,u) in the partial feedback contexts) is also used to update the value of the context (V(s)), via a prediction error (δ<sub>V</sub>) weighted by a specific learning rate (α<sub>V</sub>). Option and context values jointly contribute to the generation of confidence judgments.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.g006" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec008">
<title>Assessing the specific role of context values in biasing confidence</title>
<p>So far, our investigations show that including context values (V(s)) as a predictor of confidence is necessary and sufficient to reproduce the bias in confidence induced by the decision frame (gain vs. loss). However, it remains unclear how specific and robust the contribution of context-values in generating this bias is, notably when other valence-sensitive model-free and model-based variable are accounted for. To address this question, we run two additional linear models: one including the sum of the two q-values (∑Q), which also tracks aspects of the valence of the context; the second including RTs, which were also predicted by both ΔQ and V(s) (see previous paragraph). In both experiments and for both linear models, the residual effect of V(s) on trial-by-trial confidence judgments remained positive and (marginally) significant (see <bold><xref ref-type="table" rid="pcbi.1006973.t005">Table 5</xref></bold>), thus indicating a specific role of our model-driven estimate of V(s) above and beyond other related variables.</p>
<table-wrap id="pcbi.1006973.t005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.t005</object-id>
<label>Table 5</label> <caption><title>Assessing the specific role of context values on confidence.</title> <p>Estimated fixed-effect coefficients from generalized linear mixed-effect models.</p></caption>
<alternatives>
<graphic id="pcbi.1006973.t005g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.t005" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<tbody>
<tr>
<td align="center" colspan="2"/>
<td align="center" colspan="2"><bold>GLME</bold></td>
</tr>
<tr>
<td align="center" rowspan="6"><bold>GLME 1</bold></td>
<td align="center"><bold>Fixed-Effect</bold></td>
<td align="center"><bold>Experiment 1</bold></td>
<td align="center"><bold>Experiment 2</bold></td>
</tr>
<tr>
<td align="center">Intercept (<italic>β</italic><sub>0</sub>)</td>
<td align="center">0.58±0.05<break/>t<sub>5077</sub> = 18.06; P = 1.01×10<sup>−70</sup></td>
<td align="center">0.68±0.03<break/>t<sub>5143</sub> = 21.74; P = 2.48×10<sup>−100</sup></td>
</tr>
<tr>
<td align="center">Choice difficulty (<italic>β</italic><sub>Δ<italic>Q</italic></sub>)</td>
<td align="center">0.27±0.05<break/>t<sub>5077</sub> = 5.55; P = 2.97×10<sup>−8</sup></td>
<td align="center">0.13±0.03<break/>t<sub>5143</sub> = 4.97; P = 6.76×10<sup>−7</sup></td>
</tr>
<tr>
<td align="center">Preceding confidence (<italic>β</italic><sub><italic>c</italic>1</sub>)</td>
<td align="center">0.26±0.03<break/>t<sub>5077</sub> = 7.56; P = 4.79×10<sup>−14</sup></td>
<td align="center">0.24±0.04<break/>t<sub>5143</sub> = 6.93; P = 4.69×10<sup>−12</sup></td>
</tr>
<tr>
<td align="center">Context value (<italic>β</italic><sub><italic>V</italic></sub>)</td>
<td align="center">0.43±0.14<break/>t<sub>5077</sub> = 3.14; P = 1.68×10<sup>−3</sup></td>
<td align="center">0.15±0.06<break/>t<sub>5143</sub> = 2.36; P = 1.81×10<sup>−2</sup></td>
</tr>
<tr>
<td align="center">Reaction times (<italic>β</italic><sub><italic>RT</italic></sub>)</td>
<td align="center">-0.03±0.01<break/>t<sub>5077</sub> = -2.53; P = 1.15×10<sup>−2</sup></td>
<td align="center">-0.09±0.01<break/>t<sub>5143</sub> = -9.95; P = 4.04×10<sup>−24</sup></td>
</tr>
<tr>
<td align="center" colspan="2"/>
<td align="center" colspan="2"><bold>GLME</bold></td>
</tr>
<tr>
<td align="center" rowspan="6"><bold>GLME 2</bold></td>
<td align="center"><bold>Fixed-Effect</bold></td>
<td align="center"><bold>Experiment 1</bold></td>
<td align="center"><bold>Experiment 2</bold></td>
</tr>
<tr>
<td align="center">Intercept (<italic>β</italic><sub>0</sub>)</td>
<td align="center">0.53±0.04<break/>t<sub>5077</sub> = 14.99; P = 9.36×10<sup>−50</sup></td>
<td align="center">0.53±0.03<break/>t<sub>5143</sub> = 16.83; P = 6.45×10<sup>−62</sup></td>
</tr>
<tr>
<td align="center">Choice difficulty (<italic>β</italic><sub>Δ<italic>Q</italic></sub>)</td>
<td align="center">0.24±0.05<break/>t<sub>5077</sub> = 4.59; P = 4.53×10<sup>−6</sup></td>
<td align="center">0.14±0.03<break/>t<sub>5143</sub> = 4.79; P = 1.75×10<sup>−6</sup></td>
</tr>
<tr>
<td align="center">Preceding confidence (<italic>β</italic><sub><italic>c</italic>1</sub>)</td>
<td align="center">0.28±0.04<break/>t<sub>5077</sub> = 7.50; P = 7.30×10<sup>−14</sup></td>
<td align="center">0.30±0.04<break/>t<sub>5143</sub> = 7.70; P = 1.60×10<sup>−14</sup></td>
</tr>
<tr>
<td align="center">Context value (<italic>β</italic><sub><italic>V</italic></sub>)</td>
<td align="center">0.10±0.05<break/>t<sub>5077</sub> = 1.94; P = 5.22×10<sup>−2</sup></td>
<td align="center">0.06±0.02<break/>t<sub>5143</sub> = 3.96; P = 7.50×10<sup>−5</sup></td>
</tr>
<tr>
<td align="center">q-values sum (<italic>β</italic><sub>∑Q</sub>)</td>
<td align="center">0.22±0.09<break/>t<sub>5077</sub> = 2.43; P = 1.52×10<sup>−2</sup></td>
<td align="center">0.06±0.02<break/>t<sub>5143</sub> = 2.65; P = 7.98×10<sup>−3</sup></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec009">
<title>Assessing the consequences of the valence-induced confidence bias</title>
<p>We finally investigated potential consequences of the valence-induced confidence bias. We reasoned that, in volatile environments, confidence could be the meta-cognitive variable underlying decisions about whether to adjust learning strategies. In this case, individuals should exhibit lower performance in loss than gain contexts when contingencies are stable and better performance when contingencies change. The reason is that, because confidence is lower in loss contexts, they should sub-optimally explore alternative strategies when contingencies are stable but should display greater ease to change/adjust their learning strategies when contingencies change. To test this hypothesis, we invited 48 participants to partake in a reversal-learning task, where the probabilistic outcomes associated with half of the pairs saw their contingencies reversing halfway through the task (see <bold><xref ref-type="sec" rid="sec008">Methods</xref></bold>). Importantly, participants were explicitly told that the environment was unstable, so that strategies might need to be adjusted. Similar to experiments 1 and 2, outcomes could be either gains or losses depending on the pairs, and participants had to indicate how confident they felt about their choices (<bold><xref ref-type="fig" rid="pcbi.1006973.g007">Fig 7A</xref></bold>).</p>
<fig id="pcbi.1006973.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006973.g007</object-id>
<label>Fig 7</label>
<caption>
<title/>
<p><bold>Experiment 3 task schematic, reversal learning and confidence results. (A) Task design and contingencies.</bold> (B) <bold>Performance.</bold> Trial by trial percentage of correct responses in the partial (left) and the complete (middle-left) information conditions. Filled colored areas represent mean ± sem; Middle-right and right: Individual averaged performances in the different conditions, before (middle-right) and after (right) the reversal. The orange shaded area highlights the post-reversal behavior. Connected dots represent individual data points in the within-subject design. The error bar displayed on the side of the scatter plots indicate the sample mean ± sem. (C) <bold>Confidence.</bold> Trial by trial confidence ratings in the partial (left) and the complete (middle-left) information conditions. Filled colored areas represent mean ± sem; Middle-right and right: Individual averaged performances in the different conditions, before (middle-right) and after (right) the reversal. The orange shaded area highlights the post-reversal behavior. Connected dots represent individual data points in the within-subject design. The error bar displayed on the side of the scatter plots indicate the sample mean ± sem. G<sub>Sta</sub>: Gain Stable; L<sub>Sta</sub>: Loss Stable; G<sub>Rev</sub>: gain reversal; L<sub>Rev</sub>: Loss Reversal.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006973.g007" xlink:type="simple"/>
</fig>
<p>In the first half of the task (i.e. before the occurrence of any reversal), replicating our previous findings, we found that while learning performance was unaffected by the outcome valence (ANOVA; main effect of reversal F<sub>1,47</sub> = 0.64; P = 0.42; main effect of valence F<sub>1,47</sub> = 2.46; P = 0.12; interaction F<sub>1,47</sub> = 2.38; P = 0.13; <bold><xref ref-type="fig" rid="pcbi.1006973.g007">Fig 7B</xref></bold>), confidence ratings were (ANOVA; main effect of reversal F<sub>1,47</sub> = 0.66; P = 0.42; main effect of valence F<sub>1,47</sub> = 39.13; P = 1.10×10<sup>−7</sup>; interaction F<sub>1,47</sub> = 0.42; P = 0.52; <bold><xref ref-type="fig" rid="pcbi.1006973.g007">Fig 7C</xref></bold>). Yet and most importantly, in the second half of the task (i.e. after reversals happened in Reversal contexts), we observed an interaction between the Valence and Reversal factors on performance (ANOVA; main effect of reversal F<sub>1,47</sub> = 88.67; P = 2.15×10<sup>−12</sup> main effect of valence F<sub>1,47</sub> = 0.26; P = 0.62; interaction F<sub>1,47</sub> = 6.69; P = 0.01; <bold><xref ref-type="fig" rid="pcbi.1006973.g007">Fig 7A</xref></bold>). Post-hoc tests confirmed that participants performed relatively better in the gain than in the loss conditions if no reversal occurred (gain vs loss: t-test t<sub>47</sub> = 2.34; P = 0.02), and showed a non-significant tendency to perform better in the loss than in the gain contexts if a reversal happened (gain vs loss: t-test t<sub>47</sub> = -1.17; P = 0.25). Overall, these results indicate that the performance benefits for the gain frame in the stable context are eliminated in the reversal context, which seems to confirm our hypothesis that a valence-induced bias in confidence bears functional consequences.</p>
</sec>
</sec>
</sec>
<sec id="sec010" sec-type="conclusions">
<title>Discussion</title>
<p>In this paper we investigated the effect of context-value on confidence during reinforcement-learning, by combining well-validated tasks: a probabilistic instrumental task with monetary gains and losses as outcomes [<xref ref-type="bibr" rid="pcbi.1006973.ref008">8</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref035">35</xref>], and two variants of a confidence elicitation task [<xref ref-type="bibr" rid="pcbi.1006973.ref040">40</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref047">47</xref>]: a free elicitation of confidence (experiment 1), and an incentivized elicitation of confidence called matching probability (experiment 2). Behavioral results from two experiments consistently show a clear dissociation of the effect of decision frame on learning performance and confidence judgments: while the valence of decision outcomes (gains vs. losses) had no effect on the learning performance, it significantly impacted subjects’ confidence in the very same choices. Specifically, learning to avoid losses generated lower confidence reports than learning to seek gains regardless of the confidence elicitation methods employed. These results extend prior findings [<xref ref-type="bibr" rid="pcbi.1006973.ref031">31</xref>], by demonstrating a biasing effect of incentive valence in a reinforcement learning context. They are also consistent with other decision-making studies reporting that positive psychological factors and states, such as joy or desirability, bias confidence upwards, while negative ones, such as worry, bias confidence downwards [<xref ref-type="bibr" rid="pcbi.1006973.ref026">26</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref028">28</xref>–<xref ref-type="bibr" rid="pcbi.1006973.ref030">30</xref>].</p>
<p>Based on the current design and results, we can rule out two potential explanation for the presence of this confidence bias. First, we used both a free confidence elicitation method (experiment 1) and an incentivized method (experiment 2) and clearly replicate our results across these two methods. This indicates that the confidence bias cannot be attributed to the confidence elicitation mechanism. This is also supported by the fact that the confidence bias is observed despite the incentives in the primary task (gain and loss) being orthogonalized from the ones used to elicit confidence judgments (always framed as a gain). Second, an interesting feature of the present experiments is that monetary outcomes are displayed after–rather than before- confidence judgments. At the time of decision and confidence judgments, the value of decision-contexts is implicitly inferred by participants and not explicitly displayed on the screen. Combined with the fact that loss and gain conditions were interleaved and that previous studies indicate that in a similar paradigm subjects remain largely unaware of the contextual manipulations [<xref ref-type="bibr" rid="pcbi.1006973.ref048">48</xref>], this suggests that the biasing effect of monetary outcomes demonstrated in previous reports [<xref ref-type="bibr" rid="pcbi.1006973.ref031">31</xref>] is not due to a simple framing effect, created by the display of monetary gains or losses prior to confidence judgments.</p>
<p>Contrary to our previous study [<xref ref-type="bibr" rid="pcbi.1006973.ref031">31</xref>], the current reinforcement-learning design provides little control on the effect of the experimental manipulations on choice reaction times. Our results show that, like confidence, reaction times are also biased by the context value. Given that some studies have suggested that reaction times could inform confidence judgments [<xref ref-type="bibr" rid="pcbi.1006973.ref045">45</xref>]–although this has recently been challenged [<xref ref-type="bibr" rid="pcbi.1006973.ref049">49</xref>]-, the observed confidence bias could be a by-product of a reaction-time bias. However, both our control analysis (<bold><xref ref-type="table" rid="pcbi.1006973.t005">Table 5</xref></bold>) and our previous study [<xref ref-type="bibr" rid="pcbi.1006973.ref031">31</xref>] seem to rule out this interpretation and point toward an authentic confidence bias that is at least partially independent of reaction times.</p>
<p>We offer two interpretations for the observed effects of gains versus losses on confidence. In the first interpretation, we propose that loss prospects simply bias confidence downward. In the second interpretation, we propose that loss prospects improve confidence calibration over gain prospects, thereby correcting overconfidence. Following the first interpretation, the apparent improvement in confidence calibration observed in our study does not correspond to a confidence judgment improvement <italic>per se</italic>, but is a mere consequence of participants being overconfident in this task. Accordingly, in a hypothetical task where participants would be underconfident in the gain domain, while the loss prospects would aggravate this underconfidence under the first interpretation, they would improve confidence calibration (hence correct this underconfidence) under the second interpretation. Future research is needed to distinguish between the two potential mechanisms.</p>
<p>Regardless of the interpretation of the reported effects, we showed that confidence can be modelled as a simple linear and additive combination of three variables: previous confidence rating, choice difficulty and the context value inferred from the context-dependent reinforcement learning model. The critical contribution of the present study is the demonstration that confidence judgments are affected by the value of the decision-context, also referred to as context value. The context value is a subjective estimate of the average expected-value of a pair of stimuli: in our experimental paradigm, the context value is therefore neutral (equal to 0) at the beginning of learning, and gradually becomes positive in the reward-seeking conditions and negative in the punishment-avoidance conditions [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>]. The fact that the context-value significantly contributes to confidence judgments therefore complements our model-free results showing that outcome valence impacts confidence, while embedding it in the learning dynamics. The fact that the context value is a significant predictor of confidence judgments also suggests that context-dependency in reinforcement learning is not only critical to account for choice patterns but also to account for additional behavioral manifestations, such as confidence judgments and reaction times. This result therefore provides additional support for the idea that context values are explicitly represented during learning [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>]. Crucially, context-dependency has been shown to display locally adaptive (i.e. successful punishment-avoidance in the learning test) and globally maladaptive (i.e. irrational preferences in the transfer test) effects [<xref ref-type="bibr" rid="pcbi.1006973.ref048">48</xref>]. Whether the context-dependence of confidence judgments is adaptive or maladaptive remains to be elucidated and will require teasing apart the different interpretation of this effect discussed above.</p>
<p>Our findings are also consistent with a growing literature showing that in value-based decision-making, choice-difficulty, as proxyed by the absolute difference in expected subjective value between the available [<xref ref-type="bibr" rid="pcbi.1006973.ref050">50</xref>–<xref ref-type="bibr" rid="pcbi.1006973.ref052">52</xref>] is a significant predictor of confidence judgments [<xref ref-type="bibr" rid="pcbi.1006973.ref042">42</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref043">43</xref>]. Finally, the notion that confidence judgments expressed in preceding trials could inform confidence expressed in subsequent trails is relatively recent, but has received both theoretical and experimental support [<xref ref-type="bibr" rid="pcbi.1006973.ref044">44</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref053">53</xref>] and intuitively echoes findings of serial dependence in perceptual decisions [<xref ref-type="bibr" rid="pcbi.1006973.ref054">54</xref>]. In interleaved experimental designs like ours, successive trials pertain to different learning contexts. Therefore, the significant serial dependence of confidence judgments revealed by our analyses captures a temporal stability of confidence, which is context-independent. This result is highly consistent with the findings reported in Rahnev and colleagues (2015), which show that serial dependence in confidence can even be observed between different tasks.</p>
<p>In the present report, the modelling approach is strongly informed and constrained by our previous studies [<xref ref-type="bibr" rid="pcbi.1006973.ref031">31</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>]. In this sense, the proposed models are solely meant to provide a parsimonious, descriptive account of the confidence bias observed in the reinforcement-learning task. We acknowledge that other models and model families could provide a better, mechanistic and/or principled account of both learning performance and confidence judgments [<xref ref-type="bibr" rid="pcbi.1006973.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref023">23</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref055">55</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref056">56</xref>].</p>
<p>Overall, our results outline the importance of investigating confidence biases in reinforcement-learning. As outlined in the introduction, most sophisticated RL algorithms assume representation of uncertainty and/or strategy reliability estimates, which allow them to flexibly adjust learning strategies or to dynamically select among different learning strategies. Yet, despite their fundamental importance in learning, these uncertainty estimates have, so far, mostly emerged as latent variables, computed from individuals’ choices under strong computational assumptions [<xref ref-type="bibr" rid="pcbi.1006973.ref013">13</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref014">14</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref057">57</xref>–<xref ref-type="bibr" rid="pcbi.1006973.ref061">61</xref>]. In the present paper we propose that confidence judgments could be a useful experimental proxy for such estimates in RL. Confidence judgments indeed possess important properties, which suggest that they might be an important variable mitigating learning and decision-making strategies. First, confidence judgments accurately track the probability of being correct in stochastic environments, integrating expected and unexpected uncertainty in a close-to-optimal fashion [<xref ref-type="bibr" rid="pcbi.1006973.ref021">21</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref022">22</xref>]. Second, subjective confidence in one’s choices impacts subsequent decision processes [<xref ref-type="bibr" rid="pcbi.1006973.ref062">62</xref>] and information seeking strategies [<xref ref-type="bibr" rid="pcbi.1006973.ref063">63</xref>]. Finally, confidence acts as a common currency and therefore can be used to trade-off between different strategies [<xref ref-type="bibr" rid="pcbi.1006973.ref064">64</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref065">65</xref>].</p>
<p>With this in mind, biases of confidence could have critical consequences on reinforcement learning and reveal important features about the flexibility of learning and decision-making processes in different contexts. Along those lines, our last experiment provides suggestive evidence that, in volatile environments, the valence-induced confidence bias induces differences in learning-flexibility between reward-seeking and loss-avoidance contexts. The fact that such behavioral manifestations were absent in previous experiments—where participants were explicitly told that symbol-outcome association probabilities were stable—suggests that confidence is linked to a higher level of strategic exploration, contingent on the representation of task and environment structure. See also [<xref ref-type="bibr" rid="pcbi.1006973.ref021">21</xref>] for a similar claim in a sequence learning task.</p>
<p>Considering evolutionary perspectives, future research should investigate whether lower confidence in the loss domain–as demonstrated in the present report—could play an adaptive function, e.g. by allowing rapid behavioral adjustments under threat.</p>
</sec>
<sec id="sec011" sec-type="materials|methods">
<title>Material and methods</title>
<sec id="sec012">
<title>Ethics statement</title>
<p>All studies were approved by the local Ethics Committee of the Center for Research in Experimental Economics and political Decision-making (CREED), at the University of Amsterdam. All subjects gave informed consent prior to partaking in the study.</p>
</sec>
<sec id="sec013">
<title>Subjects</title>
<p>The subjects were recruited from the laboratory's participant database (<ext-link ext-link-type="uri" xlink:href="http://www.creedexperiment.nl/" xlink:type="simple">www.creedexperiment.nl</ext-link>). A total of 84 subjects took part in this study: 18 took part in experiment 1 (8/10 M/F, age = 24.6±8.5), 18 in experiment 2 (8/10 MF, age = 24.6±4.3), and 48 in experiment 3 (26/22 M/F, age = 22.8±4). They were compensated with a combination of a base amount (5€), and additional gains and/or losses depending on their performance during the learning task: experiment 1 had an exchange rate of 1 (in-game euros = payout); experiments 2 and 3 had an exchange rate of 0.3 (in game euros = 0.3 payout euros). In addition, in experiments 2 and 3, three trials (one per session) were randomly selected for a potential 5 euros bonus each, attributed based on the confidence incentivization scheme (see below).</p>
</sec>
<sec id="sec014">
<title>Power analysis and sample size determination</title>
<p>Power analysis were performed with GPower.3.1.9.2 [<xref ref-type="bibr" rid="pcbi.1006973.ref066">66</xref>]. The sample size for Experiments 1 and 2 was determined prior to the start of the experiments based on the effects of incentives on confidence judgments in Lebreton et al. (2018). Cohen’s d was estimated from a GLM d = .941 t<sub>23</sub> = 4.61, P = 1.23e-4). For a similar within-subject design, a sample of N = 17 subjects was required to reach a power of 95% with a two-tailed one-sample t-test.</p>
</sec>
<sec id="sec015">
<title>Learning tasks</title>
<sec id="sec016">
<title>Learning tasks–general features</title>
<p>All tasks were implemented using MatlabR2015a (MathWorks) and the COGENT toolbox (<ext-link ext-link-type="uri" xlink:href="http://www.vislab.ucl.ac.uk/cogent.php" xlink:type="simple">http://www.vislab.ucl.ac.uk/cogent.php</ext-link>). In all experiments, the main learning task was adapted from a probabilistic instrumental learning task used in a previous study [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>]. Invited participants were first provided with written instructions, which were reformulated orally if necessary. They were explained that the aim of the task was to maximize their payoff and that gain seeking and loss avoidance were equally important. In each of the three learning sessions, participants repeatedly faced four pairs of cues—taken from Agathodaimon alphabet, corresponding to four conditions of a 2×2 factorial design. In all tasks, one of the factors was the Valence of the outcome, with two pairs corresponding to reward conditions, and two to loss conditions (the stimuli visuals were randomized across subjects). The second factor differed between Experiment 1–2 and Experiment 3, and is therefore detailed in the following sections.</p>
</sec>
<sec id="sec017">
<title>Learning task conditions—Experiments 1 and 2</title>
<p>In experiments 1 and 2, the four cue pairs were presented 24 times in a pseudo-randomized and unpredictable manner to the subject (intermixed design). Within each pair the cues were associated with two possible outcomes defined by the valence factor (1€/0€ for the Gain and -1€/0€ for the Loss conditions in Exp. 1; 1€/0.1€ for the gain and -1€/-0.1€ for the loss conditions in Exp. 2) with reciprocal (but independent and fixed) probabilities (75%/25% and 25%/75%). The second factor was the Information given about the outcome: in Partial information trials, only the outcome linked to the chosen cue was revealed, while in Complete information trials, the outcome linked to both the chosen and unchosen cue were revealed.</p>
<p>Replacing the neutral outcome (0 euro) with a 10c gain or loss in Experiment 2 was meant to neutralize an experimental asymmetry between the gain and loss conditions, present in Experiment 1, which could have contributed to the valence impact on confidence in the partial information condition: when learning to avoid losses, subjects increasingly selected the symbol associated with a neutral outcome (0 euro), hence were provided more often with this ambiguous feedback. It is worth noting that this asymmetry was almost absent in the complete feedback case where the context value can be inferred in both gains and losses thanks to the counterfactual feedback (e.g. a forgone loss), and nonetheless showed lower reported confidence. Besides, despite this theoretical asymmetry in the partial condition, there was no detectable difference in performance between gain and loss performance in the partial information condition in the Experiment 1. Yet, replacing the ambiguous neutral option with small monetary gains and losses in experiment 2 completely corrected the imbalance between the partial information gain and loss conditions.</p>
<p>Participants were explicitly informed that there were fixed “good” and “bad” options within each pair, hence that the contingencies were stable.</p>
</sec>
<sec id="sec018">
<title>Learning task conditions–experiment 3 (reversal)</title>
<p>In experiment 3, the four cue pairs were presented 30 times in a pseudo-randomized and unpredictable manner to the subject (intermixed design). Within each pair, the cues were associated with two possible outcomes defined by the Valence factor (1€/0.1€ for the Gain and -1€/-0.1€ for the Loss conditions) with reciprocal (but independent) probabilities (80%/20% and 80%/20%). The second factor was the presence or absence of a Reversal: in Reversal conditions, the probabilistic contingencies within a pair reversed halfway through the task (from the 16<sup>th</sup> occurrence of the pair). Then, the initial “good” cue of a pair became the “bad” cue, and vice-versa. Instead, in Stable conditions, there was no such reversal, and the probabilistic contingencies remained stable throughout the task.</p>
<p>Note that participants were explicitly informed that “good” and “bad” options within each pair could change, hence that the contingencies were not always stable.</p>
</sec>
<sec id="sec019">
<title>Learning task trials–all experiments</title>
<p>At each trial, participants first viewed a central fixation cross (500-1500ms). Then, the two cues of a pair were presented on each side of this central cross. Note that the side in which a given cue of a pair was presented (left or right of a central fixation cross) was pseudo-randomized, such as a given cue was presented an equal number of times on the left and the right of the screen. Subjects were required to select between the two cues by pressing the left or right arrow on the computer keyboard, within a 3000ms time window. After the choice window, a red pointer appeared below the selected cue for 500ms. Subsequently, participants were asked to indicate how confident they were in their choice. In Experiment 1, confidence ratings were simply given on a rating scale without any additional incentivization. In Experiments 2–3 confidence ratings were given on a probability rating scale and were incentivized (see below). To perform this rating, subjects could move a cursor–which appeared at a random position- to the left or to the right using the left and right arrows, and validate their final answer with the spacebar. This rating step was self-paced. Finally, an outcome screen displayed the outcome associated with the selected cue, accompanied with the outcome of the unselected cue if the pair was associated with a complete-feedback condition (only in Experiments 1–2).</p>
</sec>
<sec id="sec020">
<title>Experiments 2 and 3—Matching probability and incentivization</title>
<p>In Experiment 2 and 3, participant’s reports of confidence were incentivized via a matching probability procedure that is based on the Becker-DeGroot-Marshak (BDM) auction [<xref ref-type="bibr" rid="pcbi.1006973.ref037">37</xref>] Specifically, participants were asked to report as their confidence judgment their estimated probability (p) of having selected the symbol with the higher average value, (i.e. the symbol offering a 75% chance of gain (G75) in the gain conditions, and the symbol offering a 25% chance of loss (L25) in the loss conditions) on a scale between 50% and 100%. A random mechanism, which draws a number (r) in the interval [0.5 1], is then implemented to select whether the subject will be paid an additional bonus of 5 euros as follows: If p ≥ r, the selection of the correct symbol will lead to a bonus payment; if p &lt; r, a lottery will determine whether an additional bonus is won. This lottery offers a payout of 5 euros with probability r and 0 with probability 1-r. This procedure has been shown to incentivize participants to truthfully report their true confidence regardless of risk preferences [<xref ref-type="bibr" rid="pcbi.1006973.ref047">47</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref067">67</xref>].</p>
<p>Participants were trained on this lottery mechanism and informed that up to 15 euros could be won and added to their final payment via the MP mechanism applied on one randomly chosen trial at the end of each learning session (3×5 euros). Therefore, the MP mechanism screens (<bold><xref ref-type="fig" rid="pcbi.1006973.g003">Fig 3A</xref></bold>) were not displayed during the learning sessions.</p>
</sec>
<sec id="sec021">
<title>Experiments 1–3—Transfer task</title>
<p>In all experiments, the 8 abstract stimuli (2×4 pairs) used in the third (i.e. last) session were re-used in the transfer task. All possible pair-wise combinations of these 8 stimuli (excluding pairs formed by two identical stimuli) were presented 4 times, leading to a total of 112 trials [<xref ref-type="bibr" rid="pcbi.1006973.ref007">7</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref034">34</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref068">68</xref>]. For each newly formed pair, participants had to indicate the option which they believed had the highest value, by selecting either the left or right option via button press in a manner equivalent to the learning task. Although this task was not incentivized, which was clearly explained to participants, they were nonetheless encouraged to respond as if money was at stake. In order to prevent explicit memorizing strategies, participants were not informed that they would have performed this task until the end of the third (last) session of the learning test.</p>
</sec>
</sec>
<sec id="sec022">
<title>Model-free statistics</title>
<p>All model-free statistical analyses were performed using Matlab R2015a. All reported p-values correspond to two-sided tests. T-tests refer to a one sample t-test when comparing experimental data to a reference value (e.g. chance: 0.5), and paired t-tests when comparing experimental data from different conditions. ANOVA are repeated measure ANOVAs.</p>
</sec>
<sec id="sec023">
<title>Computational modelling—Experiments 1 and 2</title>
<sec id="sec024">
<title>Reinforcement-learning model</title>
<p>The approach for the reinforcement-learning modelling is identical to the one followed in Palminteri and colleagues (2015). Briefly, we adapted two models inspired from classical reinforcement learning algorithms [<xref ref-type="bibr" rid="pcbi.1006973.ref001">1</xref>]: the ABSOLUTE and the RELATIVE model. In the ABSOLUTE model, the values of available options are learned in a context-independent fashion. In the RELATIVE models, however, the values of available options are learned in a context-independent fashion.</p>
<p>In the ABSOLUTE model, at each trial t, the chosen (c) option value of the current context s is updated with the Rescorla-Wagner rule [<xref ref-type="bibr" rid="pcbi.1006973.ref003">3</xref>]:
<disp-formula id="pcbi.1006973.e001">
<alternatives>
<graphic id="pcbi.1006973.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1006973.e002">
<alternatives>
<graphic id="pcbi.1006973.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Where <italic>α</italic><sub><italic>c</italic></sub> is the learning rate for the chosen (c) option and <italic>α</italic><sub><italic>u</italic></sub> t0he learning rate for the unchosen (u) option, i.e. the counterfactual learning rate. <italic>δ</italic><sub><italic>c</italic></sub> and <italic>δ</italic><sub><italic>u</italic></sub> are prediction error terms calculated as follows:
<disp-formula id="pcbi.1006973.e003">
<alternatives>
<graphic id="pcbi.1006973.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1006973.e004">
<alternatives>
<graphic id="pcbi.1006973.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
<p><italic>δ</italic><sub><italic>c</italic></sub> is updated in both partial and complete feedback contexts and <italic>δ</italic><sub><italic>u</italic></sub> is updated in the complete feedback context only.</p>
<p>In the RELATIVE model, a choice context value (<italic>V</italic>(<italic>s</italic>)) is also learned and used as the reference point to which an outcome should be compared before updating option values.</p>
<p>Context value is also learned via a delta rule:
<disp-formula id="pcbi.1006973.e005">
<alternatives>
<graphic id="pcbi.1006973.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Where <italic>α</italic><sub><italic>V</italic></sub> is the context value learning rate and <italic>δ</italic><sub><italic>V</italic></sub> is a prediction error-term calculated as follows: if a counterfactual outcome <italic>R</italic><sub><italic>U</italic>,<italic>t</italic></sub> is provided
<disp-formula id="pcbi.1006973.e006">
<alternatives>
<graphic id="pcbi.1006973.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
<p>If a counterfactual outcome <italic>R</italic><sub><italic>U</italic>,<italic>t</italic></sub> is not, provided, its value is replaced by its expected value <italic>Q</italic><sub><italic>t</italic></sub>(<italic>s</italic>,<italic>u</italic>), hence
<disp-formula id="pcbi.1006973.e007">
<alternatives>
<graphic id="pcbi.1006973.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
<p>The learned context values are then used to center the prediction-errors, as follow:
<disp-formula id="pcbi.1006973.e008">
<alternatives>
<graphic id="pcbi.1006973.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1006973.e009">
<alternatives>
<graphic id="pcbi.1006973.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
<p>In both models, the choice rule was implemented as a softmax function:</p>
<p><italic>P</italic><sub><italic>t</italic></sub>(<italic>s</italic>,<italic>a</italic>) = (1+exp(<italic>β</italic>(<italic>Q</italic><sub><italic>t</italic></sub>(<italic>s</italic>,<italic>b</italic>)−<italic>Q</italic><sub><italic>t</italic></sub>(<italic>s</italic>,<italic>a</italic>))))<sup>−1</sup>, where <italic>β</italic> is the inverse temperature parameter.</p>
</sec>
<sec id="sec025">
<title>Model fitting</title>
<p>Model parameters <italic>θ</italic><sub><italic>M</italic></sub> were estimated by finding the values which minimized the negative log likelihood of the observed choice <italic>D</italic> given the considered model <italic>M</italic> and parameter values (−log(<italic>P</italic>(<italic>D</italic>|<italic>M</italic>,<italic>θ</italic><sub><italic>M</italic></sub>))) and (in a separate optimization procedure) the negative log of posterior probability over the free parameters (−log(<italic>P</italic>(<italic>θ</italic><sub><italic>M</italic></sub>|<italic>D</italic>,<italic>M</italic>))).</p>
<p>The negative logarithm of the posterior probability was computed as
<disp-formula id="pcbi.1006973.e010">
<alternatives>
<graphic id="pcbi.1006973.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>∝</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo>(</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where, <italic>P</italic>(<italic>D</italic>|<italic>M</italic>,<italic>θ</italic><sub><italic>M</italic></sub>) is the likelihood of the data (i.e. the observed choice) given the considered model M and parameter values <italic>θ</italic><sub><italic>M</italic></sub>, and <italic>P</italic>(<italic>θ</italic><sub><italic>M</italic></sub>|<italic>M</italic>) is the prior probability of the parameters.</p>
<p>Following [<xref ref-type="bibr" rid="pcbi.1006973.ref032">32</xref>], the prior probability distributions <italic>P</italic>(<italic>θ</italic><sub><italic>M</italic></sub>|<italic>M</italic>) assumed learning rates beta distributed (betapdf(parameter,1.1,1.1)) and softmax temperature gamma-distributed (gampdf(parameter,1.2,5)).</p>
<p>Note that the observed choices include both choices expressed during the learning test and choices observed during the transfer test, which were modelled using the option’s Q-values estimated at the end of learning. The parameter search was implemented using Matlab’s <italic>fmincon</italic> function, initialized at multiple starting points of the parameter space [<xref ref-type="bibr" rid="pcbi.1006973.ref069">69</xref>].</p>
<p>Negative log-likelihoods corresponding to the best fitting parameters (nLL<sub>max</sub>) were used to compute the Akaike’s information criterion (AIC) and the Bayesian information criterion (BIC). Similarly negative log of posterior probabilities corresponding to the best fitting parameters (nLPP<sub>max</sub>) were used to compute the Laplace approximation to the model evidence (ME) [<xref ref-type="bibr" rid="pcbi.1006973.ref069">69</xref>].</p>
</sec>
<sec id="sec026">
<title>Model comparison</title>
<p>We computed at the individual level (random effects) the Akaike’s information criterion (AIC),
<disp-formula id="pcbi.1006973.e011">
<alternatives>
<graphic id="pcbi.1006973.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:mi>A</mml:mi><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>d</mml:mi><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi><mml:mi>L</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
the Bayesian information criterion (BIC),
<disp-formula id="pcbi.1006973.e012">
<alternatives>
<graphic id="pcbi.1006973.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e012" xlink:type="simple"/>
<mml:math display="block" id="M12">
<mml:mi>B</mml:mi><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mspace width="0.25em"/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>×</mml:mo><mml:mi>d</mml:mi><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi><mml:mi>L</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub>
</mml:math>
</alternatives>
</disp-formula>
and the Laplace approximation to the model evidence (ME);
<disp-formula id="pcbi.1006973.e013">
<alternatives>
<graphic id="pcbi.1006973.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:mi>M</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi><mml:mi>L</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo>|</mml:mo><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mo>|</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Where df is the number of model parameters, and |<italic>H</italic>| is the determinant of the Hessian.</p>
<p>Individual model comparison criteria (AIC, BIC, ME) were fed to the mbb-vb-toolbox (<ext-link ext-link-type="uri" xlink:href="https://code.google.com/p/mbb-vb-toolbox/" xlink:type="simple">https://code.google.com/p/mbb-vb-toolbox/</ext-link>) [<xref ref-type="bibr" rid="pcbi.1006973.ref070">70</xref>]. This procedure estimates the expected frequencies of the model (denoted EF) and the exceedance probability (denoted XP) for each model within a set of models, given the data gathered from all subjects. Expected frequency quantifies the posterior probability, i.e., the probability that the model generated the data for any randomly selected subject. Note that the three different criteria (AIC, BIC, ME) led to the same model comparison results.</p>
</sec>
<sec id="sec027">
<title>Confidence model</title>
<p>To model confidence ratings, we used the parameter and latent variables estimated from the best fitting Model (i.e. the RELATIVE model) under the LPP maximization procedure. Note that for Experiment 1, confidence ratings were linearly transformed from 1:10 to 50:100%.</p>
<p>Following the approach taken with the RL models, we designed two models of confidence: the FULL and the REDUCED confidence models.</p>
<p>In the FULL confidence model, confidence ratings at each trial <italic>t</italic> (<italic>c</italic><sub><italic>t</italic></sub>) were modelled as a linear combination of the choice difficulty–proxied by the absolute difference between the two options expected value (<italic>dQ</italic><sub><italic>t</italic></sub>), the learned context value (<italic>V</italic><sub><italic>t</italic></sub>), and the confidence expressed at the preceding trial (<italic>c</italic><sub><italic>t</italic>−1</sub>).
<disp-formula id="pcbi.1006973.e014">
<alternatives>
<graphic id="pcbi.1006973.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e014" xlink:type="simple"/>
<mml:math display="block" id="M14">
<mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where
<disp-formula id="pcbi.1006973.e015">
<alternatives>
<graphic id="pcbi.1006973.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e015" xlink:type="simple"/>
<mml:math display="block" id="M15">
<mml:msub><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
and <italic>β</italic><sub>0</sub>, <italic>β</italic><sub><italic>dQ</italic></sub>, <italic>β</italic><sub><italic>V</italic></sub> and <italic>β</italic><sub><italic>c</italic>1</sub> represents the linear coefficients of regression to be estimated.</p>
<p>In the REDUCED confidence model 1, we omitted the learned context value (<italic>V</italic><sub><italic>t</italic></sub>), leading to
<disp-formula id="pcbi.1006973.e016">
<alternatives>
<graphic id="pcbi.1006973.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e016" xlink:type="simple"/>
<mml:math display="block" id="M16">
<mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
<p>In the REDUCED confidence model 2, we omitted the confidence expressed at the preceding trial (<italic>c</italic><sub><italic>t</italic>−1</sub>), leading to
<disp-formula id="pcbi.1006973.e017">
<alternatives>
<graphic id="pcbi.1006973.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006973.e017" xlink:type="simple"/>
<mml:math display="block" id="M17">
<mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Those models were implemented as generalized linear mixed-effect (glme) models, including subject level random effects (intercepts and slopes for all predictor variables). The models were estimated using Matlab’s <italic>fitglme</italic> function, which maximize the maximum likelihood of observed data under the model, using the Laplace approximation.</p>
<p>Modelled confidence ratings (i.e. confidence model fits) were estimated using Matlab’s <italic>predict</italic> function.</p>
<p>Because the REDUCED models are nested in the FULL model, a likelihood ratio test can be performed to assess whether the FULL model gives a better account of the data, while being penalized for its additional degrees-of-freedom (i.e. higher complexity). This test was performed using Matlab’s <italic>compare</italic> function.</p>
<p>To assess the specificity of V(s) we run two additional glmes including ∑<italic>Q</italic><sub><italic>t</italic></sub> = <italic>Q</italic><sub><italic>t</italic></sub>(<italic>s</italic>,<italic>b</italic>) + <italic>Q</italic><sub><italic>t</italic></sub>(<italic>s</italic>,<italic>a</italic>) and the reaction time, respectively as model-based and model-free variables affected by the valence factor. We tested whether in these glmes V(s) still predicted confidence rating despite sharing common variance with these variables.</p>
<p>Note that confidence is often explicitly modelled as the probability of being correct [<xref ref-type="bibr" rid="pcbi.1006973.ref017">17</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref018">18</xref>,<xref ref-type="bibr" rid="pcbi.1006973.ref023">23</xref>]. In our dataset, replacing Δ<italic>Q</italic><sub><italic>t</italic></sub> with the probability of choosing the correct option (<italic>P</italic><sub><italic>t</italic></sub>(<italic>s</italic>,<italic>correct</italic>)) in the FULL confidence model gave very similar results on all accounts. Bayesian model comparisons indicate that these two models (i.e. including Δ<italic>Q</italic><sub><italic>t</italic></sub> or <italic>P</italic><sub><italic>t</italic></sub>(<italic>s</italic>,<italic>correct</italic>) as independent variables) are not fully discriminable, but that the FULL model using Δ<italic>Q</italic><sub><italic>t</italic></sub> appears to give a slightly better fit of confidence ratings (exceedance probability in favor of GLM1, experiment 1: 77.95%; experiment 2: 69.79%).</p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<p>We thank Caspar Lusink for his help with data collection in experiment 3.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006973.ref001"><label>1</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>. <source>Reinforcement learning: An introduction</source>. <publisher-name>MIT press Cambridge</publisher-name>; <year>1998</year>.</mixed-citation></ref>
<ref id="pcbi.1006973.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Erev</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Roth</surname> <given-names>AE</given-names></name>. <article-title>Predicting How People Play Games: Reinforcement Learning in Experimental Games with Unique, Mixed Strategy Equilibria</article-title>. <source>Am Econ Rev</source>. <year>1998</year>;<volume>88</volume>: <fpage>848</fpage>–<lpage>881</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2307/117009" xlink:type="simple">10.2307/117009</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006973.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rescorla</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>AR</given-names></name>. <article-title>A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</article-title>. <source>Class Cond II Curr Res Theory</source>. <year>1972</year>;<volume>2</volume>: <fpage>64</fpage>–<lpage>99</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006973.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Cortical substrates for exploratory decisions in humans</article-title>. <source>Nature</source>. <year>2006</year>;<volume>441</volume>: <fpage>876</fpage>–<lpage>879</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature04766" xlink:type="simple">10.1038/nature04766</ext-link></comment> <object-id pub-id-type="pmid">16778890</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O’Doherty</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Deichmann</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Dissociable Roles of Ventral and Dorsal Striatum in Instrumental Conditioning</article-title>. <source>Science</source>. <year>2004</year>;<volume>304</volume>: <fpage>452</fpage>–<lpage>454</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1094285" xlink:type="simple">10.1126/science.1094285</ext-link></comment> <object-id pub-id-type="pmid">15087550</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>. <article-title>A Neural Substrate of Prediction and Reward</article-title>. <source>Science</source>. <year>1997</year>;<volume>275</volume>: <fpage>1593</fpage>–<lpage>1599</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.275.5306.1593" xlink:type="simple">10.1126/science.275.5306.1593</ext-link></comment> <object-id pub-id-type="pmid">9054347</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Seeberger</surname> <given-names>LC</given-names></name>, <name name-style="western"><surname>O’Reilly</surname> <given-names>RC</given-names></name>. <article-title>By Carrot or by Stick: Cognitive Reinforcement Learning in Parkinsonism</article-title>. <source>Science</source>. <year>2004</year>;<volume>306</volume>: <fpage>1940</fpage>–<lpage>1943</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1102941" xlink:type="simple">10.1126/science.1102941</ext-link></comment> <object-id pub-id-type="pmid">15528409</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Flandin</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Frith</surname> <given-names>CD</given-names></name>. <article-title>Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans</article-title>. <source>Nature</source>. <year>2006</year>;<volume>442</volume>: <fpage>1042</fpage>–<lpage>1045</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature05051" xlink:type="simple">10.1038/nature05051</ext-link></comment> <object-id pub-id-type="pmid">16929307</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Justo</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Jauffret</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Pavlicek</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dauta</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Delmaire</surname> <given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Critical Roles for Anterior Insula and Dorsal Striatum in Punishment-Based Avoidance Learning</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>76</volume>: <fpage>998</fpage>–<lpage>1009</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2012.10.017" xlink:type="simple">10.1016/j.neuron.2012.10.017</ext-link></comment> <object-id pub-id-type="pmid">23217747</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Courville</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Touretzky</surname> <given-names>DS</given-names></name>. <article-title>Bayesian theories of conditioning in a changing world</article-title>. <source>Trends Cogn Sci</source>. <year>2006</year>;<volume>10</volume>: <fpage>294</fpage>–<lpage>300</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2006.05.004" xlink:type="simple">10.1016/j.tics.2006.05.004</ext-link></comment> <object-id pub-id-type="pmid">16793323</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>. <article-title>A bayesian foundation for individual learning under uncertainty</article-title>. <source>Front Hum Neurosci</source>. <year>2011</year>;<volume>5</volume>: <fpage>39</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2011.00039" xlink:type="simple">10.3389/fnhum.2011.00039</ext-link></comment> <object-id pub-id-type="pmid">21629826</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yu</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Uncertainty, Neuromodulation, and Attention</article-title>. <source>Neuron</source>. <year>2005</year>;<volume>46</volume>: <fpage>681</fpage>–<lpage>692</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2005.04.026" xlink:type="simple">10.1016/j.neuron.2005.04.026</ext-link></comment> <object-id pub-id-type="pmid">15944135</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Collins</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Koechlin</surname> <given-names>E</given-names></name>. <article-title>Reasoning, Learning, and Creativity: Frontal Lobe Function and Human Decision-Making</article-title>. <source>PLOS Biol</source>. <year>2012</year>;<volume>10</volume>: <fpage>e1001293</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1001293" xlink:type="simple">10.1371/journal.pbio.1001293</ext-link></comment> <object-id pub-id-type="pmid">22479152</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nat Neurosci</source>. <year>2005</year>;<volume>8</volume>: <fpage>1704</fpage>–<lpage>1711</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1560" xlink:type="simple">10.1038/nn1560</ext-link></comment> <object-id pub-id-type="pmid">16286932</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doya</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Samejima</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Katagiri</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kawato</surname> <given-names>M</given-names></name>. <article-title>Multiple Model-Based Reinforcement Learning</article-title>. <source>Neural Comput</source>. <year>2002</year>;<volume>14</volume>: <fpage>1347</fpage>–<lpage>1369</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089976602753712972" xlink:type="simple">10.1162/089976602753712972</ext-link></comment> <object-id pub-id-type="pmid">12020450</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adams</surname> <given-names>JK</given-names></name>. <article-title>A Confidence Scale Defined in Terms of Expected Percentages</article-title>. <source>Am J Psychol</source>. <year>1957</year>;<volume>70</volume>: <fpage>432</fpage>–<lpage>436</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2307/1419580" xlink:type="simple">10.2307/1419580</ext-link></comment> <object-id pub-id-type="pmid">13458516</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Drugowitsch</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kepecs</surname> <given-names>A</given-names></name>. <article-title>Confidence and certainty: distinct probabilistic quantities for different goals</article-title>. <source>Nat Neurosci</source>. <year>2016</year>;<volume>19</volume>: <fpage>366</fpage>–<lpage>374</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4240" xlink:type="simple">10.1038/nn.4240</ext-link></comment> <object-id pub-id-type="pmid">26906503</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sanders</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Hangya</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Kepecs</surname> <given-names>A</given-names></name>. <article-title>Signatures of a Statistical Computation in the Human Sense of Confidence</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>90</volume>: <fpage>499</fpage>–<lpage>506</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2016.03.025" xlink:type="simple">10.1016/j.neuron.2016.03.025</ext-link></comment> <object-id pub-id-type="pmid">27151640</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fleming</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>The neural basis of metacognitive ability</article-title>. <source>Phil Trans R Soc B</source>. <year>2012</year>;<volume>367</volume>: <fpage>1338</fpage>–<lpage>1349</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rstb.2011.0417" xlink:type="simple">10.1098/rstb.2011.0417</ext-link></comment> <object-id pub-id-type="pmid">22492751</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lebreton</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Abitbol</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>. <article-title>Automatic integration of confidence in the brain valuation signal</article-title>. <source>Nat Neurosci</source>. <year>2015</year>;<volume>18</volume>: <fpage>1159</fpage>–<lpage>1167</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4064" xlink:type="simple">10.1038/nn.4064</ext-link></comment> <object-id pub-id-type="pmid">26192748</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heilbron</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Meyniel</surname> <given-names>F</given-names></name>. <article-title>Subjective confidence reveals the hierarchical nature of learning under uncertainty</article-title>. <source>bioRxiv</source>. <year>2018</year>; <volume>256016</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/256016" xlink:type="simple">10.1101/256016</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006973.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meyniel</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Schlunegger</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name>. <article-title>The Sense of Confidence during Probabilistic Learning: A Normative Account</article-title>. <source>PLOS Comput Biol</source>. <year>2015</year>;<volume>11</volume>: <fpage>e1004305</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004305" xlink:type="simple">10.1371/journal.pcbi.1004305</ext-link></comment> <object-id pub-id-type="pmid">26076466</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fleming</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>Self-evaluation of decision-making: A general Bayesian framework for metacognitive computation</article-title>. <source>Psychol Rev</source>. <year>2017</year>;<volume>124</volume>: <fpage>91</fpage>–<lpage>114</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/rev0000045" xlink:type="simple">10.1037/rev0000045</ext-link></comment> <object-id pub-id-type="pmid">28004960</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meyniel</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Sigman</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mainen</surname> <given-names>ZF</given-names></name>. <article-title>Confidence as Bayesian Probability: From Neural Origins to Behavior</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>88</volume>: <fpage>78</fpage>–<lpage>92</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.09.039" xlink:type="simple">10.1016/j.neuron.2015.09.039</ext-link></comment> <object-id pub-id-type="pmid">26447574</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref025"><label>25</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Lichtenstein</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Fischhoff</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Phillips</surname> <given-names>LD</given-names></name>. <chapter-title>Calibration of probabilities: the state of the art to 1980</chapter-title>. In: <name name-style="western"><surname>Kahneman</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Slovic</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Tversky</surname> <given-names>A</given-names></name>, editors. <source>Judgment Under Uncertainty: Heuristics and Biases</source>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>1982</year>. pp. <fpage>306</fpage>–<lpage>334</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://www.cambridge.org/emea/" xlink:type="simple">http://www.cambridge.org/emea/</ext-link></mixed-citation></ref>
<ref id="pcbi.1006973.ref026"><label>26</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Giardini</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Coricelli</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Joffily</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sirigu</surname> <given-names>A</given-names></name>. <source>Overconfidence in Predictions as an Effect of Desirability Bias. Advances in Decision Making Under Risk and Uncertainty</source>. <publisher-name>Springer</publisher-name>, <publisher-loc>Berlin, Heidelberg</publisher-loc>; <year>2008</year>. pp. <fpage>163</fpage>–<lpage>180</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-3-540-68437-4" xlink:type="simple">10.1007/978-3-540-68437-4</ext-link></comment>_11</mixed-citation></ref>
<ref id="pcbi.1006973.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Allen</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Schwarzkopf</surname> <given-names>DS</given-names></name>, <name name-style="western"><surname>Fardo</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Winston</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Hauser</surname> <given-names>TU</given-names></name>, <etal>et al</etal>. <article-title>Unexpected arousal modulates the influence of sensory noise on confidence</article-title>. <source>eLife</source>. <year>2016</year>;<volume>5</volume>: <fpage>e18103</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.18103" xlink:type="simple">10.7554/eLife.18103</ext-link></comment> <object-id pub-id-type="pmid">27776633</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koellinger</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Treffers</surname> <given-names>T</given-names></name>. <article-title>Joy Leads to Overconfidence, and a Simple Countermeasure</article-title>. <source>PLOS ONE</source>. <year>2015</year>;<volume>10</volume>: <fpage>e0143263</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0143263" xlink:type="simple">10.1371/journal.pone.0143263</ext-link></comment> <object-id pub-id-type="pmid">26678704</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jönsson</surname> <given-names>FU</given-names></name>, <name name-style="western"><surname>Olsson</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Olsson</surname> <given-names>MJ</given-names></name>. <article-title>Odor Emotionality Affects the Confidence in Odor Naming</article-title>. <source>Chem Senses</source>. <year>2005</year>;<volume>30</volume>: <fpage>29</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/chemse/bjh254" xlink:type="simple">10.1093/chemse/bjh254</ext-link></comment> <object-id pub-id-type="pmid">15647462</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Massoni</surname> <given-names>S.</given-names></name> <article-title>Emotion as a boost to metacognition: How worry enhances the quality of confidence</article-title>. <source>Conscious Cogn</source>. <year>2014</year>;<volume>29</volume>: <fpage>189</fpage>–<lpage>198</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.concog.2014.08.006" xlink:type="simple">10.1016/j.concog.2014.08.006</ext-link></comment> <object-id pub-id-type="pmid">25286128</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lebreton</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Langdon</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Slieker</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Nooitgedacht</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Goudriaan</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Denys</surname> <given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Two sides of the same coin: Monetary incentives concurrently improve and bias confidence judgments</article-title>. <source>Sci Adv</source>. <year>2018</year>;<volume>4</volume>: <fpage>eaaq0668</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/sciadv.aaq0668" xlink:type="simple">10.1126/sciadv.aaq0668</ext-link></comment> <object-id pub-id-type="pmid">29854944</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Khamassi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Joffily</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Coricelli</surname> <given-names>G</given-names></name>. <article-title>Contextual modulation of value signals in reward and punishment learning</article-title>. <source>Nat Commun</source>. <year>2015</year>;<volume>6</volume>. Available: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/ncomms/2015/150825/ncomms9096/full/ncomms9096.html?WT.ec_id=NCOMMS-20150826&amp;spMailingID=49403992&amp;spUserID=ODkwMTM2NjQyNgS2&amp;spJobID=743954799&amp;spReportId=NzQzOTU0Nzk5S0" xlink:type="simple">http://www.nature.com/ncomms/2015/150825/ncomms9096/full/ncomms9096.html?WT.ec_id=NCOMMS-20150826&amp;spMailingID=49403992&amp;spUserID=ODkwMTM2NjQyNgS2&amp;spJobID=743954799&amp;spReportId=NzQzOTU0Nzk5S0</ext-link></mixed-citation></ref>
<ref id="pcbi.1006973.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kilford</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Coricelli</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Blakemore S-</surname> <given-names>J</given-names></name>. <article-title>The Computational Development of Reinforcement Learning during Adolescence</article-title>. <source>PLOS Comput Biol</source>. <year>2016</year>;<volume>12</volume>: <fpage>e1004953</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004953" xlink:type="simple">10.1371/journal.pcbi.1004953</ext-link></comment> <object-id pub-id-type="pmid">27322574</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klein</surname> <given-names>TA</given-names></name>, <name name-style="western"><surname>Ullsperger</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Jocham</surname> <given-names>G</given-names></name>. <article-title>Learning relative values in the striatum induces violations of normative decision making</article-title>. <source>Nat Commun</source>. <year>2017</year>;<volume>8</volume>: <fpage>16033</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ncomms16033" xlink:type="simple">10.1038/ncomms16033</ext-link></comment> <object-id pub-id-type="pmid">28631734</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref035"><label>35</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>. <source>Opponent Brain Systems for Reward and Punishment Learning: Causal Evidence From Drug and Lesion Studies in Humans. Decision Neuroscience</source>. <publisher-loc>San Diego</publisher-loc>: <publisher-name>Academic Press</publisher-name>; <year>2017</year>. pp. <fpage>291</fpage>–<lpage>303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/B978-0-12-805308-9.00023–3" xlink:type="simple">10.1016/B978-0-12-805308-9.00023–3</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006973.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marshall</surname> <given-names>JAR</given-names></name>, <name name-style="western"><surname>Trimmer</surname> <given-names>PC</given-names></name>, <name name-style="western"><surname>Houston</surname> <given-names>AI</given-names></name>, <name name-style="western"><surname>McNamara</surname> <given-names>JM</given-names></name>. <article-title>On evolutionary explanations of cognitive biases</article-title>. <source>Trends Ecol Evol</source>. <year>2013</year>;<volume>28</volume>: <fpage>469</fpage>–<lpage>473</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tree.2013.05.013" xlink:type="simple">10.1016/j.tree.2013.05.013</ext-link></comment> <object-id pub-id-type="pmid">23790393</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Becker</surname> <given-names>GM</given-names></name>, <name name-style="western"><surname>DeGroot</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Marschak</surname> <given-names>J</given-names></name>. <article-title>Measuring Utility by a Single-Response Sequential Method</article-title>. <source>Behav Sci</source>. <year>1964</year>;<volume>9</volume>: <fpage>226</fpage>–<lpage>232</lpage>. <object-id pub-id-type="pmid">5888778</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ducharme</surname> <given-names>WM</given-names></name>, <name name-style="western"><surname>Donnell</surname> <given-names>ML</given-names></name>. <article-title>Intrasubject comparison of four response modes for “subjective probability” assessment</article-title>. <source>Organ Behav Hum Perform</source>. <year>1973</year>;<volume>10</volume>: <fpage>108</fpage>–<lpage>117</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0030-5073(73)90007-X" xlink:type="simple">10.1016/0030-5073(73)90007-X</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006973.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schotter</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Trevino</surname> <given-names>I</given-names></name>. <article-title>Belief Elicitation in the Laboratory</article-title>. <source>Annu Rev Econ</source>. <year>2014</year>;<volume>6</volume>: <fpage>103</fpage>–<lpage>128</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-economics-080213-040927" xlink:type="simple">10.1146/annurev-economics-080213-040927</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006973.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schlag</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Tremewan</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Weele</surname> <given-names>JJ van der</given-names></name>. <article-title>A penny for your thoughts: a survey of methods for eliciting beliefs</article-title>. <source>Exp Econ</source>. <year>2015</year>;<volume>18</volume>: <fpage>457</fpage>–<lpage>490</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10683-014-9416-x" xlink:type="simple">10.1007/s10683-014-9416-x</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006973.ref041"><label>41</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Mowrer</surname> <given-names>OH</given-names></name>. <source>Learning theory and behavior</source>. <publisher-loc>Hoboken, NJ, US</publisher-loc>: <publisher-name>John Wiley &amp; Sons Inc</publisher-name>; <year>1960</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/10802-000" xlink:type="simple">10.1037/10802-000</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006973.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Martino</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Fleming</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Garrett</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Confidence in value-based choice</article-title>. <source>Nat Neurosci</source>. <year>2013</year>;<volume>16</volume>: <fpage>105</fpage>–<lpage>110</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3279" xlink:type="simple">10.1038/nn.3279</ext-link></comment> <object-id pub-id-type="pmid">23222911</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Folke</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Jacobsen</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fleming</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Martino</surname> <given-names>BD</given-names></name>. <article-title>Explicit representation of confidence informs future value-based decisions</article-title>. <source>Nat Hum Behav</source>. <year>2016</year>;<volume>1</volume>: <fpage>0002</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41562-016-0002" xlink:type="simple">10.1038/s41562-016-0002</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006973.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rahnev</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Koizumi</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>McCurdy</surname> <given-names>LY</given-names></name>, <name name-style="western"><surname>D’Esposito</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lau</surname> <given-names>H</given-names></name>. <article-title>Confidence Leak in Perceptual Decision Making</article-title>. <source>Psychol Sci</source>. <year>2015</year>;<volume>26</volume>: <fpage>1664</fpage>–<lpage>1680</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797615595037" xlink:type="simple">10.1177/0956797615595037</ext-link></comment> <object-id pub-id-type="pmid">26408037</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Corthell</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>. <article-title>Choice Certainty Is Informed by Both Evidence and Decision Time</article-title>. <source>Neuron</source>. <year>2014</year>;<volume>84</volume>: <fpage>1329</fpage>–<lpage>1342</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2014.12.015" xlink:type="simple">10.1016/j.neuron.2014.12.015</ext-link></comment> <object-id pub-id-type="pmid">25521381</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wyart</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Koechlin</surname> <given-names>E</given-names></name>. <article-title>The Importance of Falsification in Computational Cognitive Modeling</article-title>. <source>Trends Cogn Sci</source>. <year>2017</year>;<volume>21</volume>: <fpage>425</fpage>–<lpage>433</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2017.03.011" xlink:type="simple">10.1016/j.tics.2017.03.011</ext-link></comment> <object-id pub-id-type="pmid">28476348</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hollard</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Massoni</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Vergnaud</surname> <given-names>J-C</given-names></name>. <article-title>In search of good probability assessors: an experimental comparison of elicitation rules for confidence judgments</article-title>. <source>Theory Decis</source>. <year>2015</year>;<volume>80</volume>: <fpage>363</fpage>–<lpage>387</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s11238-015-9509-9" xlink:type="simple">10.1007/s11238-015-9509-9</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006973.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bavard</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lebreton</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Khamassi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Coricelli</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>. <article-title>Reference-point centering and range-adaptation enhance human reinforcement learning at the cost of irrational preferences</article-title>. <source>Nat Commun</source>. <year>2018</year>;<volume>9</volume>: <fpage>4503</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41467-018-06781-2" xlink:type="simple">10.1038/s41467-018-06781-2</ext-link></comment> <object-id pub-id-type="pmid">30374019</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dotan</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Meyniel</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name>. <article-title>On-line confidence monitoring during decision making</article-title>. <source>Cognition</source>. <year>2018</year>;<volume>171</volume>: <fpage>112</fpage>–<lpage>121</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cognition.2017.11.001" xlink:type="simple">10.1016/j.cognition.2017.11.001</ext-link></comment> <object-id pub-id-type="pmid">29128659</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lebreton</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Jorge</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Michel</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Thirion</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>. <article-title>An Automatic Valuation System in the Human Brain: Evidence from Functional Neuroimaging</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>64</volume>: <fpage>431</fpage>–<lpage>439</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2009.09.040" xlink:type="simple">10.1016/j.neuron.2009.09.040</ext-link></comment> <object-id pub-id-type="pmid">19914190</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Milosavljevic</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Malmaud</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Huth</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Rangel</surname> <given-names>A</given-names></name>. <article-title>The Drift Diffusion Model can account for the accuracy and reaction time of value-based choices under high and low time pressure</article-title>. <source>Judgm Decis Mak</source>. <year>2010</year>;<volume>5</volume>: <fpage>437</fpage>–<lpage>449</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006973.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shenhav</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Straccia</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Botvinick</surname> <given-names>MM</given-names></name>. <article-title>Anterior cingulate engagement in a foraging context reflects choice difficulty, not foraging value</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>: <fpage>1249</fpage>–<lpage>1254</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3771" xlink:type="simple">10.1038/nn.3771</ext-link></comment> <object-id pub-id-type="pmid">25064851</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Navajas</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bahrami</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>. <article-title>Post-decisional accounts of biases in confidence</article-title>. <source>Curr Opin Behav Sci</source>. <year>2016</year>;<volume>11</volume>: <fpage>55</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cobeha.2016.05.005" xlink:type="simple">10.1016/j.cobeha.2016.05.005</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006973.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fischer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Whitney</surname> <given-names>D</given-names></name>. <article-title>Serial dependence in visual perception</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>: <fpage>738</fpage>–<lpage>743</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3689" xlink:type="simple">10.1038/nn.3689</ext-link></comment> <object-id pub-id-type="pmid">24686785</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adler</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Comparing Bayesian and non-Bayesian accounts of human confidence reports</article-title>. <source>PLOS Comput Biol</source>. <year>2018</year>;<volume>14</volume>: <fpage>e1006572</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1006572" xlink:type="simple">10.1371/journal.pcbi.1006572</ext-link></comment> <object-id pub-id-type="pmid">30422974</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref056"><label>56</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <chapter-title>Chapter 16—Advanced Reinforcement Learning</chapter-title>. In: <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>, <name name-style="western"><surname>Fehr</surname> <given-names>E</given-names></name>, editors. <source>Neuroeconomics (Second Edition)</source>. <publisher-loc>San Diego</publisher-loc>: <publisher-name>Academic Press</publisher-name>; <year>2014</year>. pp. <fpage>299</fpage>–<lpage>320</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/B978-0-12-416008-8.00016–4" xlink:type="simple">10.1016/B978-0-12-416008-8.00016–4</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006973.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Behrens</surname> <given-names>TEJ</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Walton</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MFS</given-names></name>. <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source>. <year>2007</year>;<volume>10</volume>: <fpage>1214</fpage>–<lpage>1221</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1954" xlink:type="simple">10.1038/nn1954</ext-link></comment> <object-id pub-id-type="pmid">17676057</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Donoso</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Collins</surname> <given-names>AGE</given-names></name>, <name name-style="western"><surname>Koechlin</surname> <given-names>E</given-names></name>. <article-title>Foundations of human reasoning in the prefrontal cortex</article-title>. <source>Science</source>. <year>2014</year>;<volume>344</volume>: <fpage>1481</fpage>–<lpage>1486</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1252254" xlink:type="simple">10.1126/science.1252254</ext-link></comment> <object-id pub-id-type="pmid">24876345</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Iglesias</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Brodersen</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Kasper</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Piccirelli</surname> <given-names>M</given-names></name>, den Ouden HEM, <etal>et al</etal>. <article-title>Hierarchical Prediction Errors in Midbrain and Basal Forebrain during Sensory Learning</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>80</volume>: <fpage>519</fpage>–<lpage>530</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.09.009" xlink:type="simple">10.1016/j.neuron.2013.09.009</ext-link></comment> <object-id pub-id-type="pmid">24139048</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>Shimojo</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>. <article-title>Neural Computations Underlying Arbitration between Model-Based and Model-free Learning</article-title>. <source>Neuron</source>. <year>2014</year>;<volume>81</volume>: <fpage>687</fpage>–<lpage>699</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.11.028" xlink:type="simple">10.1016/j.neuron.2013.11.028</ext-link></comment> <object-id pub-id-type="pmid">24507199</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vinckier</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Gaillard</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rigoux</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Salvador</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Fornito</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Confidence and psychosis: a neuro-computational account of contingency learning disruption by NMDA blockade</article-title>. <source>Mol Psychiatry</source>. <year>2016</year>;<volume>21</volume>: <fpage>946</fpage>–<lpage>955</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/mp.2015.73" xlink:type="simple">10.1038/mp.2015.73</ext-link></comment> <object-id pub-id-type="pmid">26055423</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Braun</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Urai</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Donner</surname> <given-names>TH</given-names></name>. <article-title>Adaptive History Biases Result from Confidence-weighted Accumulation of Past Choices</article-title>. <source>J Neurosci</source>. <year>2018</year>; <fpage>2189</fpage>–<lpage>17</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2189-17.2017" xlink:type="simple">10.1523/JNEUROSCI.2189-17.2017</ext-link></comment> <object-id pub-id-type="pmid">29371318</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Desender</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Boldt</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Yeung</surname> <given-names>N</given-names></name>. <article-title>Subjective Confidence Predicts Information Seeking in Decision Making</article-title>. <source>Psychol Sci</source>. <year>2018</year>; 0956797617744771. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797617744771" xlink:type="simple">10.1177/0956797617744771</ext-link></comment> <object-id pub-id-type="pmid">29608411</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>de Gardelle</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Mamassian</surname> <given-names>P</given-names></name>. <article-title>Does Confidence Use a Common Currency Across Two Visual Tasks?</article-title> <source>Psychol Sci</source>. <year>2014</year>;<volume>25</volume>: <fpage>1286</fpage>–<lpage>1288</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797614528956" xlink:type="simple">10.1177/0956797614528956</ext-link></comment> <object-id pub-id-type="pmid">24699845</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>de Gardelle</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Corre</surname> <given-names>FL</given-names></name>, <name name-style="western"><surname>Mamassian</surname> <given-names>P</given-names></name>. <article-title>Confidence as a Common Currency between Vision and Audition</article-title>. <source>PLOS ONE</source>. <year>2016</year>;<volume>11</volume>: <fpage>e0147901</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0147901" xlink:type="simple">10.1371/journal.pone.0147901</ext-link></comment> <object-id pub-id-type="pmid">26808061</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Faul</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Erdfelder</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Lang A-</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Buchner</surname> <given-names>A</given-names></name>. <article-title>G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences</article-title>. <source>Behav Res Methods</source>. <year>2007</year>;<volume>39</volume>: <fpage>175</fpage>–<lpage>191</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03193146" xlink:type="simple">10.3758/BF03193146</ext-link></comment> <object-id pub-id-type="pmid">17695343</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Karni</surname> <given-names>E.</given-names></name> <article-title>A mechanism for eliciting probabilities</article-title>. <source>Econometrica</source>. <year>2009</year>;<volume>77</volume>: <fpage>603</fpage>–<lpage>606</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006973.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wimmer</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Shohamy</surname> <given-names>D</given-names></name>. <article-title>Preference by Association: How Memory Mechanisms in the Hippocampus Bias Decisions</article-title>. <source>Science</source>. <year>2012</year>;<volume>338</volume>: <fpage>270</fpage>–<lpage>273</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1223252" xlink:type="simple">10.1126/science.1223252</ext-link></comment> <object-id pub-id-type="pmid">23066083</object-id></mixed-citation></ref>
<ref id="pcbi.1006973.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>Trial-by-trial data analysis using computational models</article-title>. <source>Decis Mak Affect Learn Atten Perform XXIII</source>. <year>2011</year>;<volume>23</volume>: <fpage>3</fpage>–<lpage>38</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006973.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Adam</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Rigoux</surname> <given-names>L</given-names></name>. <article-title>VBA: a probabilistic treatment of nonlinear models for neurobiological and behavioural data</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>: <fpage>e1003441</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003441" xlink:type="simple">10.1371/journal.pcbi.1003441</ext-link></comment> <object-id pub-id-type="pmid">24465198</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
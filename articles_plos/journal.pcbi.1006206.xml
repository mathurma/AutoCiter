<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-00194</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006206</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Algebra</subject><subj-group><subject>Linear algebra</subject><subj-group><subject>Eigenvalues</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Markov processes</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Markov processes</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Proteins</subject><subj-group><subject>Transmembrane receptors</subject><subj-group><subject>Acetylcholine receptors</subject><subj-group><subject>Nicotinic acetylcholine receptors</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Signal transduction</subject><subj-group><subject>Transmembrane receptors</subject><subj-group><subject>Acetylcholine receptors</subject><subj-group><subject>Nicotinic acetylcholine receptors</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Biophysics</subject><subj-group><subject>Ion channels</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Biophysics</subject><subj-group><subject>Ion channels</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Ion channels</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Ion channels</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Ion channels</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Ion channels</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Ion channels</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Proteins</subject><subj-group><subject>Ion channels</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Algebra</subject><subj-group><subject>Linear algebra</subject><subj-group><subject>Eigenvectors</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Approximation methods</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Random variables</subject><subj-group><subject>Covariance</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Stochastic shielding and edge importance for Markov chains with timescale separation</article-title>
<alt-title alt-title-type="running-head">Stochastic shielding and edge importance</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1943-6221</contrib-id>
<name name-style="western">
<surname>Schmidt</surname> <given-names>Deena R.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Galán</surname> <given-names>Roberto F.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7533-6770</contrib-id>
<name name-style="western">
<surname>Thomas</surname> <given-names>Peter J.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Department of Mathematics and Statistics, University of Nevada, Reno, Reno, Nevada, United States of America</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio, United States of America</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Department of Mathematics, Applied Mathematics and Statistics, Case Western Reserve University, Cleveland, Ohio, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Gillespie</surname> <given-names>Dirk</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Rush University Medical Center, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">drschmidt@unr.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>6</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="epub">
<day>18</day>
<month>6</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>6</issue>
<elocation-id>e1006206</elocation-id>
<history>
<date date-type="received">
<day>3</day>
<month>2</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>15</day>
<month>5</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Schmidt et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006206"/>
<abstract>
<p>Nerve cells produce electrical impulses (“spikes”) through the coordinated opening and closing of ion channels. Markov processes with voltage-dependent transition rates capture the stochasticity of spike generation at the cost of complex, time-consuming simulations. Schmandt and Galán introduced a novel method, based on the stochastic shielding approximation, as a fast, accurate method for generating approximate sample paths with excellent first and second moment agreement to exact stochastic simulations. We previously analyzed the mathematical basis for the method’s remarkable accuracy, and showed that for models with a Gaussian noise approximation, the stationary variance of the occupancy at each vertex in the ion channel state graph could be written as a sum of distinct contributions from each edge in the graph. We extend this analysis to arbitrary discrete population models with first-order kinetics. The resulting decomposition allows us to rank the “importance” of each edge’s contribution to the variance of the current under stationary conditions. In most cases, transitions between open (conducting) and closed (non-conducting) states make the greatest contributions to the variance, but there are exceptions. In a 5-state model of the nicotinic acetylcholine receptor, at low agonist concentration, a pair of “hidden” transitions (between two closed states) makes a greater contribution to the variance than any of the open-closed transitions. We exhaustively investigate this “edge importance reversal” phenomenon in simplified 3-state models, and obtain an exact formula for the contribution of each edge to the variance of the open state. Two conditions contribute to reversals: the opening rate should be faster than all other rates in the system, and the closed state leading to the opening rate should be sparsely occupied. When edge importance reversal occurs, current fluctuations are dominated by a slow noise component arising from the hidden transitions.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Discrete state, continuous time Markov processes occur throughout cell biology, neuroscience, and ecology, representing the random dynamics of processes transitioning among multiple locations or states. Complexity reduction for such models aims to capture the essential dynamics and stochastic properties <italic>via</italic> a simpler representation, with minimal loss of accuracy. Classical approaches, such as aggregation of nodes and elimination of fast variables, lead to reduced models that are no longer Markovian. <italic>Stochastic shielding</italic> provides an alternative approach by simplifying the description of the noise driving the process, while preserving the Markov property, by removing from the model those fluctuations that are not directly observable. We previously applied the stochastic shielding approximation to several Markov processes arising in neuroscience and processes on random graphs. Here we explore the range of validity of stochastic shielding for processes with nonuniform stationary probabilities and multiple timescales, including ion channels with “bursty” dynamics. We show that stochastic shielding is robust to the introduction of timescale separation, for a class of simple networks, but it can break down for more complex systems with three distinct timescales. We also show that our related <italic>edge importance measure</italic> remains valid for arbitrary networks regardless of multiple timescales.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>DMS-1413770</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7533-6770</contrib-id>
<name name-style="western">
<surname>Thomas</surname> <given-names>Peter J.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>DEB-1654989</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7533-6770</contrib-id>
<name name-style="western">
<surname>Thomas</surname> <given-names>Peter J.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100006792</institution-id>
<institution>Hartwell Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>Biomedical Researcher Award</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Galán</surname> <given-names>Roberto F.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100011347</institution-id>
<institution>University of Nevada, Reno</institution>
</institution-wrap>
</funding-source>
<award-id>Start-up funds</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1943-6221</contrib-id>
<name name-style="western">
<surname>Schmidt</surname> <given-names>Deena R.</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This project has been supported by start-up funds of the University of Nevada, Reno (DRS), a Biomedical Researcher Award of The Hartwell Foundation (RFG), and National Science Foundation grants DMS-1413770 and DEB-1654989 (PJT). This research has been supported in part by the Mathematical Biosciences Institute and the National Science Foundation under grant DMS 1440386. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="10"/>
<table-count count="3"/>
<page-count count="35"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-06-28</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Variability in dynamical biological systems is ubiquitous. Discrete state, continuous time Markov process models are used throughout cell biology, neuroscience, and ecology to represent the random dynamics of processes transitioning among multiple locations or states [<xref ref-type="bibr" rid="pcbi.1006206.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1006206.ref003">3</xref>]. Examples include transitions between states defined by degree of phosphorylation and subcellular compartment location in a signaling network [<xref ref-type="bibr" rid="pcbi.1006206.ref004">4</xref>], transitions among several conducting and non-conducting states in populations of ion channels [<xref ref-type="bibr" rid="pcbi.1006206.ref005">5</xref>], random genetic drift across a fitness landscape [<xref ref-type="bibr" rid="pcbi.1006206.ref006">6</xref>], random dispersal of mobile populations [<xref ref-type="bibr" rid="pcbi.1006206.ref007">7</xref>], and many other processes [<xref ref-type="bibr" rid="pcbi.1006206.ref008">8</xref>]. Often fluctuations arise at the molecular level, whether from discrete population effects, thermal (Brownian) effects, or deterministic high dimensional nonlinear dynamics (chaos) at microscopic scales.</p>
<p>In general, nonlinear stochastic systems cannot be solved mathematically in closed form. Even if we limit ourselves to Markov processes, <italic>i.e.</italic> models for which the probability distribution of future states is independent of the past history, given the current state (meaning that the current state is as complete a description of the process as possible, and no additional “hidden” variables exist), the effects of noise on biological dynamics must usually be studied via computer simulation. However, exhaustively simulating all noise sources within a given molecular level Markov process is often computationally prohibitive. Hence there is a need for complexity reduction methods.</p>
<p>In this paper we investigate a complexity reduction method for discrete state, continuous time Markov process models known as <italic>stochastic shielding</italic> which we summarize in the next paragraph [<xref ref-type="bibr" rid="pcbi.1006206.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006206.ref010">10</xref>]. Complexity reduction for such models aims to capture the essential dynamics and stochastic properties of a system via a simpler representation, with minimal loss of accuracy. There is substantial literature on the approximation of complex random walk models with simpler models by mapping states of the full model to the nodes of a smaller set of states [<xref ref-type="bibr" rid="pcbi.1006206.ref011">11</xref>–<xref ref-type="bibr" rid="pcbi.1006206.ref023">23</xref>]. This includes coarse-graining of complex networks [<xref ref-type="bibr" rid="pcbi.1006206.ref011">11</xref>–<xref ref-type="bibr" rid="pcbi.1006206.ref013">13</xref>], elimination of fast variables <italic>via</italic> quasi-steady state approximation [<xref ref-type="bibr" rid="pcbi.1006206.ref024">24</xref>], marginalization of a partially observed Markov process through the solution of a filtering problem [<xref ref-type="bibr" rid="pcbi.1006206.ref025">25</xref>], the <italic>k</italic>-core decomposition (first proposed in [<xref ref-type="bibr" rid="pcbi.1006206.ref014">14</xref>] and shown to be effective for visualization in [<xref ref-type="bibr" rid="pcbi.1006206.ref015">15</xref>]), and various clustering algorithms that have been developed recently [<xref ref-type="bibr" rid="pcbi.1006206.ref016">16</xref>–<xref ref-type="bibr" rid="pcbi.1006206.ref020">20</xref>] (reviewed by [<xref ref-type="bibr" rid="pcbi.1006206.ref021">21</xref>]). Aggregation of tightly interconnected nodes and adiabatic elimination of fast variables lead to reduced models that are no longer Markovian [<xref ref-type="bibr" rid="pcbi.1006206.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1006206.ref022">22</xref>]. As another approach, one may eliminate rarely visited nodes, again leading to a reduction in the number of states [<xref ref-type="bibr" rid="pcbi.1006206.ref023">23</xref>]. <italic>Stochastic shielding</italic> provides an alternative approach by simplifying the description of the noise driving the process, while preserving the Markov property, by removing from the model those fluctuations that are not directly observable [<xref ref-type="bibr" rid="pcbi.1006206.ref009">9</xref>]. As illustrated in <xref ref-type="fig" rid="pcbi.1006206.g001">Fig 1</xref>, rather than reduce the number of nodes in the graph, the stochastic shielding approximation reduces the number of independent noise sources used to drive the stochastic process on the graph, while preserving the dynamical behavior of a particular projection of the random process.</p>
<fig id="pcbi.1006206.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Schematic illustration of the stochastic shielding approximation, for a graph representing 24 transitions (directed edges) interconnecting eight states (vertices).</title>
<p>One of the states (black disk) is distinguishable from the rest (white disks). For example, the black disk could represent a conducting ion channel state, while the white disks could represent non-conducting states. <bold>Left:</bold> Numerical simulation of the full process is computationally expensive: each blue trace superimposed on an edge represents independently generated stochastic forcing, but not all edges make significant contributions to fluctuations in the state of interest. <bold>Right:</bold> Rather than simulate the full process, the stochastic shielding approximation reduces the number of independent noise sources (blue edges) used to drive the stochastic process on the graph, while preserving the dynamical behavior of a particular projection of the random process.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.g001" xlink:type="simple"/>
</fig>
<p>As discussed in more detail in Methods §Summary of Stochastic Shielding in the Langevin Case, in the Langevin approximation for a time homogeneous first-order transition network, the population fraction occupying states 1, …, <italic>n</italic> is a vector <inline-formula id="pcbi.1006206.e001"><alternatives><graphic id="pcbi.1006206.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∈</mml:mo> <mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> satisfying
<disp-formula id="pcbi.1006206.e002"><alternatives><graphic id="pcbi.1006206.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:mi mathvariant="bold">X</mml:mi></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mi>L</mml:mi> <mml:mi mathvariant="bold">X</mml:mi> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">E</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>B</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>L</italic>, the graph Laplacian, captures the mean flux along each directed edge <inline-formula id="pcbi.1006206.e003"><alternatives><graphic id="pcbi.1006206.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">E</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> (edge set). The matrix <italic>B</italic><sub><italic>k</italic></sub> gives the effects of fluctuations <italic>ξ</italic><sub><italic>k</italic></sub> around the mean flux along the <italic>k</italic><sup>th</sup> edge. The noise terms, <italic>ξ</italic><sub><italic>k</italic></sub>, are independent, white and Gaussian, one for each directed edge. Given an observable of interest, represented by a vector <inline-formula id="pcbi.1006206.e004"><alternatives><graphic id="pcbi.1006206.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:mi mathvariant="bold">M</mml:mi> <mml:mo>∈</mml:mo> <mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, the stochastic shielding approximation consists in finding a partition of the edge set into edges of <italic>primary</italic> importance (<inline-formula id="pcbi.1006206.e005"><alternatives><graphic id="pcbi.1006206.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:math></alternatives></inline-formula>) and <italic>secondary</italic> importance (<inline-formula id="pcbi.1006206.e006"><alternatives><graphic id="pcbi.1006206.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:math></alternatives></inline-formula>) that gives an approximate process <inline-formula id="pcbi.1006206.e007"><alternatives><graphic id="pcbi.1006206.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∈</mml:mo> <mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> satisfying
<disp-formula id="pcbi.1006206.e008"><alternatives><graphic id="pcbi.1006206.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e008" xlink:type="simple"/><mml:math display="block" id="M8"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:mi mathvariant="bold">Y</mml:mi></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mi>L</mml:mi> <mml:mi mathvariant="bold">Y</mml:mi> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:munder> <mml:msub><mml:mi>B</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mspace width="1.em"/><mml:mi mathvariant="bold">Y</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
by neglecting the noise forcing along the edges of secondary importance. Such an approximation typically creates a (small) pathwise discrepency relative to <bold>X</bold> that can be quantified by our <italic>edge importance measure</italic>, also defined in <xref ref-type="sec" rid="sec016">Methods</xref> and discussed in more detail below [<xref ref-type="bibr" rid="pcbi.1006206.ref010">10</xref>].</p>
<p>The stochastic shielding approximation exploits filtering properties intrinsic to any network. Given an observable defined on the network (for example the indicator function for a subset of states representing nodes of interest), the fluctuations in population flux along some edges will have a greater impact on fluctuations in the observable, while other edges’ fluctuations will have a lesser impact. Hence the network “shields” the observable from some fluctuations, which may therefore be ignored with little loss of accuracy. To put it another way, the effects of a fluctuation in the movements of populations far removed from a location of interest do not directly affect the fluctuations in the population of interest; their effect reaches the observed nodes only via the indirect effect of influencing the population immediately surrounding the node or nodes of interest. One may view the source of fluctuations (relative to the average flux along a given edge) as independent noise forcing associated with each edge in the graph [<xref ref-type="bibr" rid="pcbi.1006206.ref010">10</xref>]. Edges that connect nodes that are indistinguishable, with respect to the measurement vector <bold>M</bold>, are themselves not directly observable. The fluctuations in rates of transition along these hidden edges are “averaged over” and their effect on the observed value (<bold>M</bold><sup>⊺</sup> <bold>X</bold>(<italic>t</italic>)) is reduced.</p>
<p>This filtering effect leads to the possibility of a novel approximation scheme. Rather than approximating a random process on a graph by aggregating together subsets of nodes, we may replace the fluxes along a subset of edges with the mean flux along the respective edge. If a graph has <italic>K</italic> directed edges, there are 2<sup><italic>K</italic></sup> − 1 such “approximations”, as the independent noise along each edge can be either included or excluded from the approximation. Including all noise terms gives the original model, whereas excluding all noise terms gives a model with no fluctuations.</p>
<p>Which of these 2<sup><italic>K</italic></sup> − 1 different approximations is the “best approximation”? The stochastic shielding <italic>method</italic> provides the following rule: suppress the noise along those edges connecting indistinguishable nodes. We extended this method by introducing an <italic>edge importance measure</italic> that quantifies the effect of suppressing noise along each edge separately. For a linearized Langevin equation (multidimensional Ornstein-Uhlenbeck (OU) process) approximating the full population process, we showed that when the process satisfies detailed balance, the variance of the observable states can be decomposed into a sum of fluctuations attributable to each pair of directed edges in the graph. Thus, the edge importance measure allows one to rank the edges such that the most important edge contributes the most to the stationary variance of the observable states.</p>
<p>We previously applied the stochastic shielding method to Markov processes arising in neuroscience (Hodgkin and Huxley’s sodium and potassium ion channel models) and processes on Erdos-Renyi random graphs [<xref ref-type="bibr" rid="pcbi.1006206.ref010">10</xref>]. However, these processes do not include significant timescale separation. In the present paper we study processes with nonuniform stationary probabilities and multiple timescales, including ion channel models with “bursty” dynamics.</p>
<p>Separation of timescales is an important property of many neural systems [<xref ref-type="bibr" rid="pcbi.1006206.ref026">26</xref>]. For instance, many ion channels exhibit bouts of repeated channel opening and closing, interspersed by long periods of channel closure—often referred to as bursty conductances. The nicotinic acetylcholine receptor (nAChR) is a well studied ligand-gated ion channel that can exhibit bursty behavior [<xref ref-type="bibr" rid="pcbi.1006206.ref027">27</xref>–<xref ref-type="bibr" rid="pcbi.1006206.ref029">29</xref>]. Acetylcholine (ACh) is a neurotransmitter that plays a key role in motor function <italic>via</italic> this ion channel, and the opening of the nAChR channel pore requires the binding of ACh. For low acetylcholine concentration ([ACh]), the nAChR is a classic example of a bursty ion channel.</p>
<p>In the next section, we explore the robustness of the stochastic shielding phenomenon and the accuracy of the approximation under conditions of timescale separation and sparsity in the stationary distribution, by way of the edge importance measure described in [<xref ref-type="bibr" rid="pcbi.1006206.ref010">10</xref>]. We show that typical edge importance hierarchy is robust to the introduction of timescale separation for a class of simple networks, but that it can break down for more complex systems with three or more distinct timescales, such as the nAChR described above. Nevertheless we also establish that the edge importance measure remains a valid tool for analysis for arbitrary networks regardless of multiple timescales.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Overview</title>
<p>The shielding phenomenon leads the fluctuations associated with directly observable transitions to dominate the variance of the observable states in many networks, but this rule does not hold universally. The edge importance measure (see <xref ref-type="disp-formula" rid="pcbi.1006206.e087">Eq 42</xref> in <xref ref-type="sec" rid="sec016">Methods</xref>) provides an exact means to evaluate the applicability of stochastic shielding to any model (Markovian, with first-order transitions) by quantifying the effect of suppressing noise along each edge separately. This measure considers the pathwise mean square error between two trajectories: the full stochastic process with all fluctuations included, and an approximate process with a subset of fluctuations excluded. We use this measure to rank the edges in order of importance with respect to the stationary variance of the observable states. Moreover, we show that the stationary variance decomposes into a sum of contributions from each edge. This decomposition is unique and follows from a straightforward calculation that we describe and prove in Theorem 1 in the last subsection of Results. We apply the stochastic shielding method and compute the edge importance measure for the acetylcholine receptor model introduced above and for a set of simple networks (3-state chains) with timescale separation.</p>
</sec>
<sec id="sec004">
<title>Biological example of a bursty process: Nicotinic acetylcholine receptor</title>
<p>The nicotinic acetylcholine receptor is a ligand-gated ion channel and the opening of the channel pore requires the binding of acetylcholine. For low acetylcholine concentration, the nAChR is a classic example of a bursty ion channel. This channel has been described many times in the literature, and we will follow the formulation from Colquhoun and Hawkes [<xref ref-type="bibr" rid="pcbi.1006206.ref030">30</xref>]. Following Figure 4.1 in their paper, the channel has five states with ten possible transitions between states. The states form a graph with vertices <inline-formula id="pcbi.1006206.e009"><alternatives><graphic id="pcbi.1006206.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:mi>i</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">V</mml:mi> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo> <mml:mn>3</mml:mn> <mml:mo>,</mml:mo> <mml:mn>4</mml:mn> <mml:mo>,</mml:mo> <mml:mn>5</mml:mn> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and edges <inline-formula id="pcbi.1006206.e010"><alternatives><graphic id="pcbi.1006206.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">E</mml:mi> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mo>⋯</mml:mo> <mml:mo>,</mml:mo> <mml:mn>10</mml:mn> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> (see Tables <xref ref-type="table" rid="pcbi.1006206.t001">1</xref> and <xref ref-type="table" rid="pcbi.1006206.t002">2</xref>). <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2A</xref> shows the transition state diagram. The channel can be bound to zero, one, or two ACh molecules. When singly or doubly bound the channel may be open or closed, whereas the unbound state is always closed. <xref ref-type="table" rid="pcbi.1006206.t001">Table 1</xref> gives the definition of the states and labels each state as open (observable) or closed (unobservable). State 5 (<italic>T</italic>) is the unbound state (closed), state 4 (<italic>AT</italic>) is singly bound (with 1 molecule of ACh) and closed, state 3 (<italic>A</italic><sub>2</sub><italic>T</italic>) is doubly bound and closed, state 2 (<italic>A</italic><sub>2</sub><italic>R</italic>) is doubly bound and open, and state 1 (<italic>AR</italic>) is singly bound and open. The measurement vector <bold>M</bold> specifies which states are open and which are closed by labeling each state with a 1 or 0, respectively. In this case, <bold>M</bold> is given by
<disp-formula id="pcbi.1006206.e011"><alternatives><graphic id="pcbi.1006206.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e011" xlink:type="simple"/><mml:math display="block" id="M11"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>M</mml:mi></mml:mstyle> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula>
meaning that states 1 and 2 are open/conducting states and states 3, 4, and 5 are closed/non-conducting states. <xref ref-type="table" rid="pcbi.1006206.t002">Table 2</xref> gives the definition of the edges and the transition rates. Note that the ten transitions are numbered starting with the pair of transitions connecting states 1 (<italic>AR</italic>) and 2 (<italic>A</italic><sub>2</sub><italic>R</italic>) and moving clockwise back to state 1; these are reactions 1-8. The last pair of transitions (9 and 10) connect states 4 (<italic>AT</italic>) and 5 (<italic>T</italic>). We will write the <italic>per capita</italic> transition rate for the <italic>k</italic><sup>th</sup> reaction, with source node <italic>i</italic> and destination node <italic>j</italic>, either with a single index denoting the reaction (<italic>α</italic><sub><italic>k</italic></sub>) or with a double index denoting the source followed by the destination (<italic>α</italic><sub><italic>ij</italic></sub>). Thus, <italic>α</italic><sub>1</sub> and <italic>α</italic><sub>21</sub> are synonymous.</p>
<fig id="pcbi.1006206.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.g002</object-id>
<label>Fig 2</label>
<caption>
<title/>
<p><bold>(A)</bold> Colquhoun &amp; Hawkes’ five-state model for the nicotinic acetylcholine (ACh) receptor [<xref ref-type="bibr" rid="pcbi.1006206.ref030">30</xref>]. White disks: closed (non-conducting) states (<italic>M</italic><sub><italic>j</italic></sub> = 0). Gray disks: open (conducting) states (<italic>M</italic><sub><italic>j</italic></sub> = 1). Nodes 1-5 (large black numbers) are defined in <xref ref-type="table" rid="pcbi.1006206.t001">Table 1</xref>. Transitions 1-10 (small blue numbers) are defined in <xref ref-type="table" rid="pcbi.1006206.t002">Table 2</xref>. The opening of the channel requires the binding of acetylcholine. Transitions 2, 6, and 10 are driven by ACh concentration. Transitions 3, 4, 7, 8 are directly observable through a conductance change. <bold>(B)</bold> Timescale separation (ratio of non-zero eigenvalues of the graph Laplacian) as a function of ACh concentration. <bold>(C)</bold> Edge importance <italic>R</italic><sub><italic>k</italic></sub> for <italic>k</italic> ∈ {1, …, 10} for each edge in the graph as a function of [ACh], see <xref ref-type="disp-formula" rid="pcbi.1006206.e087">Eq 42</xref>. <bold>(D)</bold> Sample trace of the model exhibiting burstiness of the channel for low agonist concentration, here [ACh] = 0.5<italic>μ</italic>M. <bold>(E)</bold> Zoomed in version of the burst in (D) labeled by the red arrow.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.g002" xlink:type="simple"/>
</fig>
<table-wrap id="pcbi.1006206.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.t001</object-id>
<label>Table 1</label>
<caption>
<title>Colquhoun &amp; Hawkes’ five-state model for the nicotinic acetylcholine receptor [<xref ref-type="bibr" rid="pcbi.1006206.ref030">30</xref>], <italic>cf</italic>. <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2A</xref>.</title>
<p>Definition of the states and the measurement vector <italic>M</italic> (normalized conductance). <italic>M</italic><sub><italic>i</italic></sub> = 1 means that state <italic>i</italic> is open (conducting/observable) and <italic>M</italic><sub><italic>i</italic></sub> = 0 means that state <italic>i</italic> is closed (non-conducting/non-observable).</p>
</caption>
<alternatives>
<graphic id="pcbi.1006206.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">
<inline-formula id="pcbi.1006206.e012">
<alternatives>
<graphic id="pcbi.1006206.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e012" xlink:type="simple"/>
<mml:math display="inline" id="M12">
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi mathvariant="script">V</mml:mi>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</th>
<th align="left">State</th>
<th align="center"><italic>M</italic><sub><italic>i</italic></sub></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1</td>
<td align="left"><italic>AR</italic> (singly bound and open)</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">2</td>
<td align="left"><italic>A</italic><sub>2</sub><italic>R</italic> (doubly bound and open)</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">3</td>
<td align="left"><italic>A</italic><sub>2</sub><italic>T</italic> (doubly bound and closed)</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">4</td>
<td align="left"><italic>AT</italic> (singly bound and closed)</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">5</td>
<td align="left"><italic>T</italic> (unbound and closed)</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="pcbi.1006206.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.t002</object-id>
<label>Table 2</label>
<caption>
<title>Colquhoun &amp; Hawkes’ five-state model for the nicotinic acetylcholine receptor [<xref ref-type="bibr" rid="pcbi.1006206.ref030">30</xref>], <italic>cf</italic>. <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2A</xref>.</title>
<p>Definition of the edges and the transition rates <italic>α</italic><sub><italic>ij</italic></sub>. The acetylcholine concentration is <italic>c</italic> ≥ 0. <bold>Bold font</bold> denotes edges with [ACh]-dependent transition rates.</p>
</caption>
<alternatives>
<graphic id="pcbi.1006206.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.t002" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">
<inline-formula id="pcbi.1006206.e013">
<alternatives>
<graphic id="pcbi.1006206.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e013" xlink:type="simple"/>
<mml:math display="inline" id="M13">
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi mathvariant="script">E</mml:mi>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</th>
<th align="left">Transition</th>
<th align="center"><italic>i</italic>(<italic>k</italic>) → <italic>j</italic>(<italic>k</italic>)</th>
<th align="left"><italic>α</italic><sub><italic>ij</italic></sub></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1</td>
<td align="left"><italic>A</italic><sub>2</sub> <italic>R</italic> → <italic>AR</italic> (release)</td>
<td align="center">2 → 1</td>
<td align="left">
<inline-formula id="pcbi.1006206.e014">
<alternatives>
<graphic id="pcbi.1006206.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e014" xlink:type="simple"/>
<mml:math display="inline" id="M14">
<mml:mrow>
<mml:msub>
<mml:mi>α</mml:mi>
<mml:mn>21</mml:mn>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>2</mml:mn>
<mml:msubsup>
<mml:mi>k</mml:mi>
<mml:mrow>
<mml:mo>-</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mo>*</mml:mo>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mover accent="true">
<mml:mn>6</mml:mn>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mo>×</mml:mo>
<mml:msup>
<mml:mn>10</mml:mn>
<mml:mrow>
<mml:mo>-</mml:mo>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="center"><bold>2</bold></td>
<td align="left"><bold>AR → A</bold><sub><bold>2</bold></sub><bold>R(binding)</bold></td>
<td align="center"><bold>1 → 2</bold></td>
<td align="left">
<inline-formula id="pcbi.1006206.e015">
<alternatives>
<graphic id="pcbi.1006206.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e015" xlink:type="simple"/>
<mml:math display="inline" id="M15">
<mml:mrow>
<mml:msub>
<mml:mi>α</mml:mi>
<mml:mn mathvariant="bold">12</mml:mn>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="bold">k</mml:mi>
<mml:mrow>
<mml:mo>+</mml:mo>
<mml:mn mathvariant="bold">2</mml:mn>
</mml:mrow>
<mml:mo>*</mml:mo>
</mml:msubsup>
<mml:mi mathvariant="bold">c</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn mathvariant="bold">5</mml:mn>
<mml:mo>×</mml:mo>
<mml:msup>
<mml:mn mathvariant="bold">10</mml:mn>
<mml:mrow>
<mml:mo>-</mml:mo>
<mml:mn mathvariant="bold">1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi mathvariant="bold">c</mml:mi>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="center">3</td>
<td align="left"><italic>A</italic><sub>2</sub><italic>T</italic> → <italic>A</italic><sub>2</sub><italic>R</italic> (opening)</td>
<td align="center">3 → 2</td>
<td align="left"><italic>α</italic><sub>32</sub> = <italic>b</italic><sub>2</sub> = 15</td>
</tr>
<tr>
<td align="center">4</td>
<td align="left"><italic>A</italic><sub>2</sub><italic>R</italic> → <italic>A</italic><sub>2</sub><italic>T</italic> (closing)</td>
<td align="center">2 → 3</td>
<td align="left"><italic>α</italic><sub>23</sub> = <italic>a</italic><sub>2</sub> = 0.5</td>
</tr>
<tr>
<td align="center">5</td>
<td align="left"><italic>A</italic><sub>2</sub><italic>T</italic> → <italic>AT</italic> (release)</td>
<td align="center">3 → 4</td>
<td align="left"><italic>α</italic><sub>34</sub> = 2<italic>k</italic><sub>−2</sub> = 4</td>
</tr>
<tr>
<td align="center"><bold>6</bold></td>
<td align="left"><bold>AT → A</bold><sub><bold>2</bold></sub><bold>T(binding)</bold></td>
<td align="center"><bold>4 → 3</bold></td>
<td align="left"><bold>α</bold><sub><bold>43</bold></sub> <bold>= k</bold><sub><bold>+2</bold></sub> <bold>c = 5 × 10</bold><sup><bold>−1</bold></sup> <bold>c</bold></td>
</tr>
<tr>
<td align="center">7</td>
<td align="left"><italic>AT</italic> → <italic>AR</italic> (opening)</td>
<td align="center">4 → 1</td>
<td align="left"><italic>α</italic><sub>41</sub> = <italic>b</italic><sub>1</sub> = 1.5 × 10<sup>−2</sup></td>
</tr>
<tr>
<td align="center">8</td>
<td align="left"><italic>AR</italic> → <italic>AT</italic> (closing)</td>
<td align="center">1 → 4</td>
<td align="left"><italic>α</italic><sub>14</sub> = <italic>a</italic><sub>1</sub> = 3</td>
</tr>
<tr>
<td align="center">9</td>
<td align="left"><italic>AT</italic> → <italic>T</italic> (release)</td>
<td align="center">4 → 5</td>
<td align="left"><italic>α</italic><sub>45</sub> = <italic>k</italic><sub>−1</sub> = 2</td>
</tr>
<tr>
<td align="center"><bold>10</bold></td>
<td align="left"><bold>T → AT(binding)</bold></td>
<td align="center"><bold>5 → 4</bold></td>
<td align="left"><bold>α</bold><sub><bold>54</bold></sub> <bold>= 2k</bold><sub><bold>+1</bold></sub> <bold>c</bold> <bold>= 10</bold><sup><bold>−1</bold></sup> <bold>c</bold></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Burstiness is defined by the observation of isolated single channels opening and closing in bouts [<xref ref-type="bibr" rid="pcbi.1006206.ref029">29</xref>–<xref ref-type="bibr" rid="pcbi.1006206.ref031">31</xref>]. <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2D</xref> shows a sample trace of our model simulation exhibiting burstiness of the channel for low agonist concentration ([ACh] = 0.5<italic>μ</italic> Mol). (For details on the model simulation, see Numerical Methods, in <xref ref-type="sec" rid="sec016">Methods</xref>.) <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2E</xref> zooms in on the burst in panel D labeled by the red arrow. The distribution of closed intervals shows a mixture of slow and fast timescales, requiring combinations of two or more exponentials with widely separated time constants. These time constants are related to the eigenvalues of the graph Laplacians (see <xref ref-type="disp-formula" rid="pcbi.1006206.e018">Eq 4</xref>, and see <xref ref-type="sec" rid="sec016">Methods</xref> for details). The ratio of eigenvalues will be used as a measure of timescale separation. <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2B</xref> shows the presence of timescale separation at low [ACh] concentrations by plotting the ratios of the eigenvalues {λ<sub>2</sub>/λ<sub><italic>j</italic></sub>}<sub><italic>j</italic> = 3,4,5</sub>. Significant timescale separation occurs when λ<sub>2</sub>/λ<sub><italic>j</italic></sub> &lt;&lt; 1, or in words, when the two eigenvalues differ by at least one order of magnitude. The graph Laplacian has leading eigenvalue λ<sub>1</sub> = 0. For the acetylcholine receptor, and for the systems we study here, the remaining eigenvalues are real and negative, and are ordered so that <inline-formula id="pcbi.1006206.e016"><alternatives><graphic id="pcbi.1006206.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mrow><mml:mn>0</mml:mn> <mml:mo>&gt;</mml:mo> <mml:msub><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:msub> <mml:mo>≥</mml:mo> <mml:msub><mml:mo>λ</mml:mo> <mml:mn>3</mml:mn></mml:msub> <mml:mo>≥</mml:mo> <mml:mo>…</mml:mo> <mml:mo>≥</mml:mo> <mml:msub><mml:mo>λ</mml:mo> <mml:mrow><mml:mo>|</mml:mo> <mml:mi mathvariant="script">V</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1006206.e017"><alternatives><graphic id="pcbi.1006206.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:mo>|</mml:mo> <mml:mi mathvariant="script">V</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the number of states.</p>
<p>We apply the stochastic shielding method to the nAChR model and show that it works well for high acetylcholine concentration, but not in the bursty regime characterized by low ACh concentration. In fact, we see a reversal of edge importance at low agonist levels (see <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2C</xref> and discussion below). In light of the network filtering effect underlying stochastic shielding, we might naïvely expect that the edges connecting states 2 and 3, and states 1 and 4, should contribute the most to the stationary variance of the observable states (1 and 2), but this is not the case. There is even a regime where the observable edge pair (edges 3 and 4) is only the third most important edge, as defined by our edge importance measure.</p>
<p>Computing the edge importance measure (<xref ref-type="disp-formula" rid="pcbi.1006206.e087">Eq 42</xref> in <xref ref-type="sec" rid="sec016">Methods</xref>), the fraction of the stationary variance contributed by edge <italic>k</italic>, requires the graph Laplacian <italic>L</italic> (and its corresponding eigenvalues and eigenvectors), the noise coefficient matrix <italic>B</italic> (defined below), the stationary mean flux <italic>J</italic><sub><italic>k</italic></sub>, and the measurement vector <bold>M</bold>. The graph Laplacian <italic>L</italic> as a function of ACh concentration <italic>c</italic> is
<disp-formula id="pcbi.1006206.e018"><alternatives><graphic id="pcbi.1006206.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e018" xlink:type="simple"/><mml:math display="block" id="M18"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>k</mml:mi> <mml:mrow><mml:mo>+</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mi>c</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mn>2</mml:mn> <mml:msubsup><mml:mi>k</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:msub><mml:mi>b</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>k</mml:mi> <mml:mrow><mml:mo>+</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mi>c</mml:mi></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:mn>2</mml:mn> <mml:msubsup><mml:mi>k</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:msub><mml:mi>b</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:mn>2</mml:mn> <mml:msub><mml:mi>k</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:msub><mml:mi>k</mml:mi> <mml:mrow><mml:mo>+</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msub> <mml:mi>c</mml:mi></mml:mrow></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mn>2</mml:mn> <mml:msub><mml:mi>k</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>k</mml:mi> <mml:mrow><mml:mo>+</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msub> <mml:mi>c</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>k</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mn>2</mml:mn> <mml:msub><mml:mi>k</mml:mi> <mml:mrow><mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mi>c</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:msub><mml:mi>k</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:msub><mml:mi>k</mml:mi> <mml:mrow><mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mi>c</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
and matrix <italic>B</italic> is
<disp-formula id="pcbi.1006206.e019"><alternatives><graphic id="pcbi.1006206.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e019" xlink:type="simple"/><mml:math display="block" id="M19"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>B</mml:mi> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:msqrt> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>ζ</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:msqrt> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>ζ</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mo>…</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>10</mml:mn></mml:msub></mml:msqrt> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>ζ</mml:mi> <mml:mn>10</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
where <italic>J</italic><sub><italic>k</italic></sub> = <italic>N</italic><sub>tot</sub> <italic>α</italic><sub><italic>ij</italic></sub> <italic>π</italic><sub><italic>i</italic>(<italic>k</italic>)</sub> is the stationary flux across edge <italic>k</italic> for a total population of <italic>N</italic><sub>tot</sub> ion channels, <italic>α</italic><sub><italic>ij</italic></sub> is the appropriate transition rate of reaction <italic>k</italic> (<xref ref-type="table" rid="pcbi.1006206.t002">Table 2</xref>) and <italic>ζ</italic><sub><italic>k</italic></sub> is the stoichoimetry vector for reaction <italic>k</italic>. The <italic>k</italic><sup><italic>th</italic></sup> stoichoimetry vector describes how an individual moves from node <italic>i</italic> to node <italic>j</italic> in reaction <italic>k</italic>. For instance, the first two stoichoimetry vectors are
<disp-formula id="pcbi.1006206.e020"><alternatives><graphic id="pcbi.1006206.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e020" xlink:type="simple"/><mml:math display="block" id="M20"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>ζ</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(6)</label></disp-formula>
<disp-formula id="pcbi.1006206.e021"><alternatives><graphic id="pcbi.1006206.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e021" xlink:type="simple"/><mml:math display="block" id="M21"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>ζ</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mtd> <mml:mtd/> <mml:mn>1</mml:mn> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow> <mml:mo>,</mml:mo></mml:math></alternatives> <label>(7)</label></disp-formula>
which correspond to transition 1 (an individual moves from state 2 to state 1) and transition 2 (an individual moves from state 1 to state 2), respectively, in <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2A</xref>. Note that <italic>ζ</italic><sub>1</sub> = −<italic>ζ</italic><sub>2</sub>, and this relationship holds for each edge pair in the ACh transition graph.</p>
<p>The matrix <italic>B</italic> depends on the equilibrium population distribution <inline-formula id="pcbi.1006206.e022"><alternatives><graphic id="pcbi.1006206.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>5</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. Since <inline-formula id="pcbi.1006206.e023"><alternatives><graphic id="pcbi.1006206.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is the leading eigenvector of the graph Laplacian <italic>L</italic>, the equilibrium fraction <italic>π</italic><sub><italic>i</italic></sub> of the population in state <italic>i</italic> will change as a function of <italic>c</italic> (ACh concentration). Lastly, recall that the measurement vector <bold>M</bold> = (1 1 0 0 0)<sup>⊺</sup> as described in <xref ref-type="table" rid="pcbi.1006206.t001">Table 1</xref>.</p>
<p><xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2C</xref> plots the relative edge importance <italic>R</italic><sub><italic>k</italic></sub> (fraction of the stationary variance contributed by edge <italic>k</italic>) for each edge <italic>k</italic> ∈ {1, …, 10} as a function of acetylcholine concentration over the range [ACh] ∈ [10<sup>−1</sup>, 10<sup>2</sup>] <italic>μ</italic>Mol. At high concentrations, the most important edges are those connecting the doubly bound closed state to the doubly bound open state (edges 3 and 4), that is, the edges along which transitions are directly observable. This situation is consistent with results for Hodgkin-Huxley ion channels and generic Erdos-Renyi random graphs with randomly assigned binary measurement vector [<xref ref-type="bibr" rid="pcbi.1006206.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006206.ref010">10</xref>]. In contrast, the most important edges at low concentrations are those connecting the singly bound state to the doubly bound closed state (edges 5 and 6 in <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2A</xref>). Although transitions along this edge are <italic>not</italic> directly observable, they make a greater contribution to the stationary variance of the open state than the opening/closing transitions.</p>
<p>Moreover, we find that edges 5 and 6 have the highest relative importance for low and intermediate concentrations, followed by edges 3,4 and 9,10. Just below a concentration of 10 <italic>μ</italic>Mol, the relative importance switches so that edges 3 and 4 become the most important for higher concentrations (≥ 10 <italic>μ</italic>Mol). To begin to understand why the edge importance ranking changes for low [ACh], we note that the relative importance depends heavily on state occupancy probability.</p>
<p>As has been previously observed, one of the nodes in the 5-state nAChR model has very low occupancy probability across all agonist concentrations [<xref ref-type="bibr" rid="pcbi.1006206.ref032">32</xref>]. In particular, states 2 (<italic>A</italic><sub>2</sub><italic>R</italic>) and 5 (<italic>T</italic>) are the most likely states to be occupied over the range of [ACh] considered. However, state 1 (<italic>AR</italic>, one of the open states) has very low occupancy probability and hence is rarely visited by the process. As a result, the most likely path between the unbound/closed state 5 (<italic>T</italic>) and the doubly bound/open state 2 (<italic>A</italic><sub>2</sub><italic>R</italic>) is 5 → 4 → 3 → 2. This means that transitions 7,8 and 1,2 do not happen very often. The stochastic shielding method predicts that these reactions should be important, but if they rarely happen, they contribute little to the stationary variance. Thus, their relative importance as computed by our edge importance measure is very small. Indeed, for all values of [ACh], the equilibrium occupancy probability of state 1, <italic>π</italic><sub>1</sub> is ≪ 1. The variance of the open states for a population of <italic>N</italic><sub>tot</sub> channels at equilibrium is
<disp-formula id="pcbi.1006206.e024"><alternatives><graphic id="pcbi.1006206.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e024" xlink:type="simple"/><mml:math display="block" id="M24"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi> <mml:mo>[</mml:mo> <mml:mtext>Open</mml:mtext> <mml:mo>]</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mtext>tot</mml:mtext></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:msub><mml:mi>π</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>≈</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mtext>tot</mml:mtext></mml:msub> <mml:msub><mml:mi>π</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>tot</mml:mtext></mml:msub> <mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>O</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>π</mml:mi> <mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mspace width="4.pt"/><mml:mtext>as</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>π</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>→</mml:mo> <mml:msup><mml:mn>0</mml:mn> <mml:mo>+</mml:mo></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Although the goal of the stochastic shielding approximation is not to change the network topology by eliminating nodes as other authors have suggested [<xref ref-type="bibr" rid="pcbi.1006206.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1006206.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1006206.ref033">33</xref>], when edges are “unimportant” it is natural to consider eliminating them. If all the edges to a node are unimportant, eliminating them would eliminate the node, and in this case the change in stationary variance of the open states would be approximately <italic>N</italic><sub>tot</sub><italic>π</italic><sub>1</sub>(1 − <italic>π</italic><sub>1</sub>) − 2<italic>N</italic><sub>tot</sub><italic>π</italic><sub>1</sub><italic>π</italic><sub>2</sub>, if <italic>π</italic><sub>1</sub> is small. (Compare to [<xref ref-type="bibr" rid="pcbi.1006206.ref032">32</xref>], “Scheme 1”.)</p>
<p>The edge importance measure <italic>R</italic><sub><italic>k</italic></sub> (for each edge <italic>k</italic>) provides an intrinsic idea of how many edges could be suppressed in an approximation (whether by suppressing the fluctuations generated by that edge, which is the focus here, or by removing the edge entirely). For the typical operating range of the nAChR, roughly 1-10 <italic>μ</italic>M [ACh], there are three transition pairs with similar edge importance (edge pairs 3,4, 5,6, and 9,10), suggesting that accurate simulations of stochastic effects would require keeping the fluctuations generated by all three of these edge pairs.</p>
<p>The acetylcholine receptor example suggests that the inversion of edge importance is related to timescale separation. In the next subsection, we investigate the edge importance measure in the presence of timescale separation, as well as a combination of sparsely and abundantly populated vertices. We show that edge importance ranking is preserved despite the introduction of arbitrary timescale separation in simple graphs (3-state chains) with <italic>per capita</italic> transition rates at two distinct timescales. As we will see, a system needs at least three distinct timescales in order to see the method break down. Nevertheless, the edge importance measure remains exact, and informative, for arbitrary networks, and can be used to extend the original stochastic shielding method to systems with timescale separation and bursty behavior.</p>
</sec>
<sec id="sec005">
<title>3-state model with timescale separation</title>
<p>Motivated by the example of the acetylcholine receptor, we systematically study the effects of introducing timescale separation into the simplest nontrivial model to which stochastic shielding applies: the 3-state chain with one observable state (or one pair of observable transitions into and out of the observable state). Specifically, we consider a discrete state, continuous time Markov jump process <inline-formula id="pcbi.1006206.e025"><alternatives><graphic id="pcbi.1006206.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mrow><mml:mi mathvariant="bold">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∈</mml:mo> <mml:msup><mml:mi mathvariant="double-struck">N</mml:mi> <mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> with <italic>N</italic><sub>tot</sub> random walkers moving independently on a graph with three nodes. See <xref ref-type="fig" rid="pcbi.1006206.g003">Fig 3</xref> for an illustration of the graph, and see <xref ref-type="sec" rid="sec016">Methods</xref> for general notation and see <xref ref-type="supplementary-material" rid="pcbi.1006206.s001">S1 Supporting Information</xref> for a detailed description of the 3-state model. Here we assume that state 3 (black disk) is the observable state, which yields the following measurement vector: <bold>M</bold> = (0 0 1)<sup>⊺</sup>.</p>
<fig id="pcbi.1006206.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.g003</object-id>
<label>Fig 3</label>
<caption>
<title>An illustration of the general 3-state chain with <italic>per capita</italic> transition rates <italic>α</italic><sub><italic>k</italic></sub> for <italic>k</italic> = 1, 2, 3, 4.</title>
<p>State 3 (black) is the observable state (or open/conducting state) of the system, and all other states are not observable (or closed/non-conducting states). By convention, we identify <italic>α</italic><sub>1</sub> ≡ <italic>α</italic><sub>12</sub>, <italic>α</italic><sub>2</sub> ≡ <italic>α</italic><sub>21</sub>, <italic>α</italic><sub>3</sub> ≡ <italic>α</italic><sub>23</sub>, and <italic>α</italic><sub>4</sub> ≡ <italic>α</italic><sub>32</sub>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.g003" xlink:type="simple"/>
</fig>
<p>If we think of this model as a simplified ion channel with three states, then the observable state is the open or conducting state of the system, and all other states are closed or non-conducting. There are four directed edges in the graph, and edge <italic>k</italic> represents a transition from source node <italic>i</italic>(<italic>k</italic>) to destination node <italic>j</italic>(<italic>k</italic>) which happens at rate <italic>α</italic><sub><italic>k</italic></sub> (or <italic>α</italic><sub><italic>ij</italic></sub>, see <xref ref-type="sec" rid="sec016">Methods</xref> for details on notation). We focus on the observed process <bold>M</bold><sup>⊺</sup><bold>N</bold>(<italic>t</italic>) which describes the evolution of the open state, and approximate processes that suppress noise along a subset of the four edges. In particular, we use the following two approximate processes to illustrate how stochastic shielding “usually” works: (i) suppress noise along edge pair 1,2 (and preserve noise along edge pair 3,4) and (ii) suppress noise along edge pair 3,4 (and preserve noise along edge pair 1,2). In most cases (i) is the best approximation; we investigate here whether or not this heuristic holds universally.</p>
<p>The mechanism of stochastic shielding can be readily understood by considering the power spectrum of the observed process <bold>M</bold><sup>⊺</sup><bold>N</bold>(<italic>t</italic>). The relationship between the power spectrum and the covariance matrix of a stochastic process is well known; the power spectrum is the Fourier transform of its covariance [<xref ref-type="bibr" rid="pcbi.1006206.ref034">34</xref>]. The stationary covariance <italic>C</italic> of a discrete state Markov process (such as <bold>N</bold> described above) is given by Gadgil, <italic>et al.</italic> [<xref ref-type="bibr" rid="pcbi.1006206.ref008">8</xref>], and satisfies the Lyapunov <xref ref-type="disp-formula" rid="pcbi.1006206.e094">Eq 46</xref> (see <xref ref-type="sec" rid="sec016">Methods</xref>).</p>
<p>The stationary variance <italic>R</italic> of the full and approximate observed processes has the following connection to the power spectrum: integrating over the power spectral density (PSD) <italic>S</italic>(<italic>ω</italic>) gives the stationary variance. Moreover, since the stationary variance decomposes into a sum of contributions from each edge in the graph (<italic>R</italic> = ∑<sub><italic>k</italic></sub><italic>R</italic><sub><italic>k</italic></sub> where <italic>R</italic><sub><italic>k</italic></sub> is the edge importance measure of edge <italic>k</italic> given in <xref ref-type="disp-formula" rid="pcbi.1006206.e087">Eq 42</xref>), the power spectrum decomposes as well (<italic>S</italic>(<italic>ω</italic>) = ∑<sub><italic>k</italic></sub> <italic>S</italic><sub><italic>k</italic></sub>(<italic>ω</italic>), see <xref ref-type="disp-formula" rid="pcbi.1006206.e121">Eq 66</xref>). We provide more details on how the power spectrum is obtained in <xref ref-type="sec" rid="sec016">Methods</xref> §Numerical Methods.</p>
<p><xref ref-type="fig" rid="pcbi.1006206.g004">Fig 4B</xref> shows sample trajectories for the full process (denoted by <italic>X</italic>, black trace) and the two approximations (i) and (ii) described above (denoted by <italic>X</italic><sub>3,4</sub> (red trace) and <italic>X</italic><sub>1,2</sub> (blue trace), respectively) in the Gaussian (OUP) version of the model. <xref ref-type="fig" rid="pcbi.1006206.g004">Fig 4A</xref> shows the corresponding power spectral contributions for the three processes: <italic>S</italic>(<italic>ω</italic>) is the total PSD (shown in black), <italic>S</italic><sub>3,4</sub>(<italic>ω</italic>) is the PSD for approximation <italic>X</italic><sub>3,4</sub> (red), and <italic>S</italic><sub>1,2</sub>(<italic>ω</italic>) is the PSD for approximation <italic>X</italic><sub>1,2</sub> (blue). See <xref ref-type="sec" rid="sec016">Methods</xref> §Numerical Methods for details on model simulation and calculation of the power spectra.</p>
<fig id="pcbi.1006206.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Stochastic shielding and the power spectrum when all transition rates equal unity.</title>
<p><bold>Panel A</bold> shows that the majority of the power comes from the observable edges (red dashed line), as expected from the edge importance measure and the stochastic shielding method. Black line is the total power spectral density (<italic>S</italic>) for the observed process <italic>X</italic>, red dashed line is the PSD (<italic>S</italic><sub>3,4</sub>) for the approximate process <italic>X</italic><sub>3,4</sub> with noise from observable edges preserved, blue dashed line is PSD (<italic>S</italic><sub>1,2</sub>) for the approximation <italic>X</italic><sub>1,2</sub> with noise from hidden edges preserved. <bold>Panel B</bold> shows trajectories (Gaussian version of the model) of the full observed process with all noise sources included (black trace), the approximate process with noise preserved on the observable edges (red), and the approximate process with noise preserved on the hidden edges (blue). The red trace closely follows the black trace, whereas the blue trace only tracks mean behavior and misses most fluctuations; <italic>X</italic><sub>3,4</sub> is the best approximation of <italic>X</italic>, in agreement with the stochastic shielding method.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.g004" xlink:type="simple"/>
</fig>
<p>At all frequencies, the power from the observable edge pair 3,4 predominates, as shown by the red dashed line (<italic>S</italic><sub>3,4</sub>(<italic>ω</italic>)) closely following the black line (total PSD). This spectral decomposition agrees with our edge ranking based on edge importance (i.e. edge pair 3,4 contributes the most to the stationary variance), and illustrates why the stochastic shielding method says that the best approximation of the full process is to preserve the noise along edge pair 3,4 and to suppress the noise along edge pair 1,2. <xref ref-type="fig" rid="pcbi.1006206.g004">Fig 4B</xref> illustrates the consequence in the time domain: the red trajectory closely follows the black trajectory, but the blue trajectory only captures a rough approximation of the full process.</p>
<p>However, this situation breaks down and leads to edge importance reversal for certain bursty systems, which we aim to understand in the rest of the paper. In the remainder of this section, we show that edge importance inversion cannot be obtained by taking a 3-state chain and accelerating or decelerating any single edge, pair, or trio of edges with a single parameter (<italic>i.e.</italic> by introducing two distinct timescales). As we shall see, in order to invert the edge importance as we did in the nAChR example for low agonist concentration, we need to introduce a third timescale. This will be addressed in §Generalized 3-State Model with Timescale Separation.</p>
<sec id="sec006">
<title>Two distinct timescales</title>
<p>Starting with two distinct timescales, we systematically survey all 3-state chains with one, two, or three out of four edge transition rates (<italic>α</italic><sub><italic>k</italic></sub>) accelerated or decelerated relative to the remaining edges. The graph Laplacian <italic>L</italic> and matrix <italic>B</italic> for the 3-state model are given by
<disp-formula id="pcbi.1006206.e026"><alternatives><graphic id="pcbi.1006206.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e026" xlink:type="simple"/><mml:math display="block" id="M26"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:msub><mml:mi>α</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:msub><mml:mi>α</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:msub><mml:mi>α</mml:mi> <mml:mn>4</mml:mn></mml:msub></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:msub><mml:mi>α</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mi>B</mml:mi> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:msqrt></mml:mrow></mml:mtd> <mml:mtd><mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:msqrt></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:msqrt></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:msqrt></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:msqrt></mml:mrow></mml:mtd> <mml:mtd><mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>4</mml:mn></mml:msub></mml:msqrt></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:msqrt></mml:mtd> <mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>4</mml:mn></mml:msub></mml:msqrt></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
recalling that the stationary flux along the <italic>k</italic><sup>th</sup> edge is given by <italic>J</italic><sub><italic>k</italic></sub> = <italic>N</italic><sub>tot</sub><italic>α</italic><sub><italic>k</italic></sub><italic>π</italic><sub><italic>i</italic>(<italic>k</italic>)</sub>. The systems we consider satisfy detailed balance, which means that <italic>J</italic><sub>1</sub> ≡ <italic>J</italic><sub>2</sub> and <italic>J</italic><sub>3</sub> ≡ <italic>J</italic><sub>4</sub>. Matrices <italic>L</italic> and <italic>B</italic> will be used to compute the relative edge importance <italic>R</italic><sub><italic>k</italic></sub> for each edge in all cases described below.</p>
<p>We introduce a parameter <italic>α</italic> (ranging from 10<sup>−4</sup> to 10<sup>4</sup>) and consider seven different cases: three cases where two transition rates are set to <italic>α</italic> and the other two rates are 1, and four cases where one rate is set to <italic>α</italic> and the other three rates are 1. See <xref ref-type="table" rid="pcbi.1006206.t003">Table 3</xref> for a detailed description of these cases. In Case 1, transition rates between closed states differ from transition rates between the open and closed states; in Case 2, transition rates into the middle (closed) state differ from transition rates out of the middle state; in Case 3, upward transition rates differ from downward transition rates; in Cases 4-7, one of the four transition rates differs from the other three. We use <xref ref-type="disp-formula" rid="pcbi.1006206.e087">Eq 42</xref> (see <xref ref-type="sec" rid="sec016">Methods</xref>) to compute the relative edge importance <italic>R</italic><sub><italic>k</italic></sub> for each edge <italic>k</italic> as a function of <italic>α</italic>. The relative edge importance is computed with respect to the total variance of the third state.</p>
<table-wrap id="pcbi.1006206.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.t003</object-id>
<label>Table 3</label>
<caption>
<title>Detailed description of each case for the 3-state model.</title>
<p>The first seven cases correspond to the chain that has the third state observable (see <xref ref-type="fig" rid="pcbi.1006206.g003">Fig 3</xref>). The last five cases have the middle state as the observable state. Transition rates <italic>α</italic><sub><italic>k</italic></sub> for <italic>k</italic> = 1, 2, 3, 4 are given by columns 3-6. The final column shows the characterization of each case into one of six different types determined by their edge importance graph as a function of parameter <italic>α</italic> (see right most column in Figs <xref ref-type="fig" rid="pcbi.1006206.g005">5</xref> and <xref ref-type="fig" rid="pcbi.1006206.g006">6</xref>).</p>
</caption>
<alternatives>
<graphic id="pcbi.1006206.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.t003" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Case<break/>(1-12)</th>
<th align="center">Observable<break/>State</th>
<th align="center">Edge<break/>1 → 2</th>
<th align="center">Edge<break/>2 → 1</th>
<th align="center">Edge<break/>2 → 3</th>
<th align="center">Edge<break/>3 → 2</th>
<th align="center">Type<break/>(I-VI)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1</td>
<td align="center">3</td>
<td align="center"><italic>α</italic></td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">I</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">3</td>
<td align="center">1</td>
<td align="center"><italic>α</italic></td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center">II</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center">3</td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center">III</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">3</td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">I</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">3</td>
<td align="center">1</td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">III</td>
</tr>
<tr>
<td align="center">6</td>
<td align="center">3</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center">II</td>
</tr>
<tr>
<td align="center">7</td>
<td align="center">3</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center"><italic>α</italic></td>
<td align="center">I</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center">2</td>
<td align="center"><italic>α</italic></td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">IV</td>
</tr>
<tr>
<td align="center">9</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center"><italic>α</italic></td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center">V</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">2</td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center">VI</td>
</tr>
<tr>
<td align="center">11</td>
<td align="center">2</td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">VI</td>
</tr>
<tr>
<td align="center">12</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center"><italic>α</italic></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">IV</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p><xref ref-type="fig" rid="pcbi.1006206.g005">Fig 5</xref> shows all possible cases of the 3-state chain with state 3 as the open/conducting state and <italic>α</italic> ranging from 10<sup>−4</sup> to 10<sup>4</sup>. The left column gives the 3-state diagram for each case with transition rates <italic>α</italic><sub><italic>k</italic></sub> equal to 1 or <italic>α</italic>, as described in <xref ref-type="table" rid="pcbi.1006206.t003">Table 3</xref>. The middle column shows the “timescale separation” for each case, defined to be the logarithm of the ratio of the two non-zero eigenvalues (λ<sub>2</sub>/λ<sub>3</sub>) versus <italic>α</italic>. As in the nAChR model, significant timescale separation occurs when λ<sub>2</sub>/λ<sub>3</sub> ≪ 1, or when the two eigenvalues differ by at least one order of magnitude. The right column shows the relative edge importance <italic>R</italic><sub><italic>k</italic></sub> versus <italic>α</italic> for each case.</p>
<fig id="pcbi.1006206.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.g005</object-id>
<label>Fig 5</label>
<caption>
<title>All possible cases for the 3-state chain with state 3 conducting.</title>
<p><bold>Left column:</bold> 3-state diagram with accelerated/decelerated edges labeled 1 or <italic>α</italic> where <italic>α</italic> ∈ [10<sup>−4</sup>, 10<sup>4</sup>]. <bold>Middle column:</bold> logarithm of the ratio of the two non-zero eigenvalues (λ<sub>2</sub>/λ<sub>3</sub>) versus <italic>α</italic>. This shows the “timescale separation” (present when λ<sub>2</sub>/λ<sub>3</sub> ≪ 1). <bold>Right column:</bold> relative edge importance <italic>R</italic><sub><italic>k</italic></sub> versus <italic>α</italic>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.g005" xlink:type="simple"/>
</fig>
<p>According to the stochastic shielding method, we expect edge pair 3,4 to have higher relative edge importance than edge pair 1,2. In <xref ref-type="fig" rid="pcbi.1006206.g005">Fig 5</xref>, this is shown by the blue curve (<italic>R</italic><sub>3</sub>, <italic>R</italic><sub>4</sub>) lying above the red curve (<italic>R</italic><sub>1</sub>, <italic>R</italic><sub>2</sub>) in the edge importance graphs in the right column. This holds for all cases except cases 2 and 6 which show a convergence of the two edge importance curves for large values of <italic>α</italic>. In these cases we also find significant timescale separation for large <italic>α</italic>, as shown by widely separated eigenvalues of the graph Laplacian (middle column graphs). For instance, when <italic>α</italic> = 10<sup>4</sup>, Cases 2 and 6 show that λ<sub>2</sub> differs from λ<sub>3</sub> by four orders of magnitude. However, there are several cases for which we find significant timescale separation but do not see a convergence or reversal of edge importance. Therefore, timescale separation is a necessary but not sufficient condition to see a breakdown of the stochastic shielding phenomenon.</p>
<p>Cases 2 and 6 share a feature that distinguish them from the other cases: although the importance of the hidden edges never exceeds that of the observable edges, they become equally important in the limit <italic>α</italic> ≫ 1. In both cases, this “fast” rate applies to the transition from the closed states to the open state (2 → 3). In Case 6, the 2 → 3 transition has the only accelerated rate; in Case 2 the 2 → 1 transition is also accelerated. However, in Case 3, which accelerates both the 2 → 3 and the 1 → 2 transitions, the edge importance does <italic>not</italic> converge. This conundrum will be resolved when we consider the general 3-state model (<italic>cf.</italic> <xref ref-type="disp-formula" rid="pcbi.1006206.e042">Eq 22</xref>).</p>
</sec>
</sec>
<sec id="sec007">
<title>3-state model with middle state conducting</title>
<p>For completeness, we may consider the same 3-state chain as in <xref ref-type="fig" rid="pcbi.1006206.g003">Fig 3</xref>, except that we set the middle state (state 2) to be the open/conducting state instead of state 3. The measurement vector in this case is <bold>M</bold> = (0 1 0)<sup>⊺</sup>. See the left column of <xref ref-type="fig" rid="pcbi.1006206.g006">Fig 6</xref> for an illustration, and note that there are five possible cases to consider. In this version of the 3-state chain, all transitions are observable since each edge connects the conducting state to a closed state, and hence, all edges should be important in terms of stochastic shielding. State 2 no longer acts as a “shield” as it did when state 3 was the conducting state. We expect that the most important edges will either depend on the parameter <italic>α</italic> or all edges will be equally important in terms of the edge importance measure. We repeat the same analysis as in the previous section and the results are shown in <xref ref-type="fig" rid="pcbi.1006206.g006">Fig 6</xref>.</p>
<fig id="pcbi.1006206.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.g006</object-id>
<label>Fig 6</label>
<caption>
<title>All possible cases for the 3-state chain with middle state 2 conducting.</title>
<p>In this case there are no hidden transitions, and hence no stochastic shielding effect. <bold>Left column:</bold> 3-state diagram with accelerated/decelerated edges labeled as 1 or <italic>α</italic> where <italic>α</italic> ∈ [10<sup>−4</sup>, 10<sup>4</sup>]. <bold>Middle column:</bold> logarithm of ratio of the two non-zero eigenvalues (λ<sub>2</sub>/λ<sub>3</sub>) versus <italic>α</italic>. This shows the timescale separation (present when λ<sub>2</sub>/λ<sub>3</sub> ≪ 1). <bold>Right column:</bold> relative edge importance <italic>R</italic><sub><italic>k</italic></sub> versus <italic>α</italic>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.g006" xlink:type="simple"/>
</fig>
<p><xref ref-type="fig" rid="pcbi.1006206.g006">Fig 6</xref> has the same three column format as <xref ref-type="fig" rid="pcbi.1006206.g005">Fig 5</xref>. The left column shows the 3-state diagram with accelerated/decelerated transition rates (1 or <italic>α</italic> as outlined in <xref ref-type="table" rid="pcbi.1006206.t003">Table 3</xref>) where again <italic>α</italic> ∈ [10<sup>−4</sup>,10<sup>4</sup>]. The middle column shows timescale separation as defined by the ratio of the two non-zero eigenvalues (λ<sub>2</sub>/λ<sub>3</sub>) versus <italic>α</italic>. The right column shows the relative edge importance <italic>R</italic><sub><italic>k</italic></sub> versus <italic>α</italic>. In contrast to the previous cases with state 3 conducting, now we see edge importance reversal or convergence in every case. This is what we expect, given that the stochastic shielding method says that all edges are important in this version of the model. However, we find edge importance reversal in Case 10 without corresponding timescale separation since λ<sub>2</sub> and λ<sub>3</sub> differ by less than one order of magnitude in that case.</p>
</sec>
<sec id="sec008">
<title>Generalized 3-state model with timescale separation</title>
<p>We showed above that the presence of two distinct timescales was not sufficient to see an inversion of the edge importance in a 3-state network. However, as we show next, a network exhibiting <italic>three</italic> separate timescales can lead to edge importance reversal. In order to find examples of inversion, we study an ensemble of 3-state chains with observable state 3 (see <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2</xref>) with arbitrary transition rates {<italic>α</italic><sub>12</sub>, <italic>α</italic><sub>21</sub>, <italic>α</italic><sub>23</sub>, <italic>α</italic><sub>32</sub>}. We randomly draw the transition rates <italic>α</italic><sub><italic>ij</italic></sub> independently from a lognormal distribution with a given width <italic>w</italic>, that is, log(<italic>α</italic><sub><italic>ij</italic></sub>) is Gaussian distributed with mean zero and standard deviation <italic>w</italic>. Then we calculate the edge importance for each realization of transition rates for this general 3-state model and look at the instances for which <italic>R</italic><sub>12</sub> = <italic>R</italic><sub>21</sub> &gt; <italic>R</italic><sub>23</sub> = <italic>R</italic><sub>32</sub>. Note that <italic>R</italic><sub><italic>ij</italic></sub> refers to the importance measure for the edges connecting node <italic>i</italic> to node <italic>j</italic>.</p>
<p>For an ensemble of 10<sup>5</sup> samples with <inline-formula id="pcbi.1006206.e027"><alternatives><graphic id="pcbi.1006206.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mrow><mml:mo form="prefix">log</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mn>10</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> (i.e. <inline-formula id="pcbi.1006206.e028"><alternatives><graphic id="pcbi.1006206.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:mi>w</mml:mi> <mml:mo>=</mml:mo> <mml:msqrt><mml:mn>10</mml:mn></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>), we find that inversion of the edge importance occurs approximately 9.8% of the time. This observation raises a number of questions. Which factors contribute to inversion of the usual edge importance relation (<italic>e.g.</italic> timescale separation)? Given an arbitrary set of transition rates, is there a canonical transformation leading to edge importance reversal? Can we obtain an exact expression for the relative contribution of the hidden edges to the stationary variance? The balance of this section addresses these questions.</p>
<p><xref ref-type="fig" rid="pcbi.1006206.g007">Fig 7</xref> illustrates the distribution, for this ensemble, of several factors that might be expected to play a role in inverting edge importance. Each panel plots the relative importance of the hidden edges
<disp-formula id="pcbi.1006206.e029"><alternatives><graphic id="pcbi.1006206.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>η</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>R</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mrow><mml:msub><mml:mi>R</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>R</mml:mi> <mml:mn>23</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula> <italic>versus</italic> factors representing node occupancy, timescale separation, flux distribution, and local timescale difference. Inversion of edge importance occurs when <italic>R</italic><sub>12</sub> &gt; <italic>R</italic><sub>23</sub>, that is, when <italic>η</italic> &gt; 1/2.</p>
<fig id="pcbi.1006206.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Factors contributing to edge importance reversal.</title>
<p>The relative importance due to the hidden edges, <italic>η</italic> = <italic>R</italic><sub>12</sub>/(<italic>R</italic><sub>12</sub> + <italic>R</italic><sub>23</sub>), was calculated for an ensemble of 3-state chains (100,000 samples, see text for details). Relative edge importance is inverted when <italic>η</italic> &gt; 0.5. <bold>Left column</bold> shows <italic>η</italic> plotted versus stationary occupancy probability of node 3 (<italic>π</italic><sub>3</sub>, panel <bold>A</bold>), node 2 (<italic>π</italic><sub>2</sub>, <bold>C</bold>), and the ratio of nodes 2 to 3 (<italic>π</italic><sub>2</sub>/<italic>π</italic><sub>3</sub>, <bold>E</bold>). The corresponding plot for <italic>π</italic><sub>1</sub> appears similar to that for <italic>π</italic><sub>3</sub> (not shown). Edge importance can be inverted for any values of <italic>π</italic><sub>1</sub> and <italic>π</italic><sub>3</sub>, but requires <italic>π</italic><sub>2</sub> ≲ 1/6. <bold>Right column</bold> shows <italic>η</italic> plotted versus timescale separation (<italic>ν</italic> = λ<sub>3</sub>/λ<sub>2</sub>, <bold>B</bold>), relative fraction of flux generated by the hidden edges (Δ<italic>J</italic> = (<italic>J</italic><sub>12</sub> − <italic>J</italic><sub>23</sub>)/(<italic>J</italic><sub>12</sub> + <italic>J</italic><sub>23</sub>), <bold>D</bold>), and ratio of relaxation times for isolated 2-state systems corresponding to the hidden versus observable transitions (<italic>τ</italic><sub>12</sub>/<italic>τ</italic><sub>23</sub>, <bold>F</bold>). Edge importance reversal requires timescale separation (|λ<sub>3</sub>| ≳ 15|λ<sub>2</sub>| or <italic>ν</italic> ≳ 15), larger mean flux along the observable edges than the hidden edges (<italic>J</italic><sub>23</sub> &gt; <italic>J</italic><sub>12</sub>), and faster relaxation along the visible edges than along the hidden edges (<italic>τ</italic><sub>12</sub> &gt; <italic>τ</italic><sub>23</sub>). None of these conditions alone are sufficient. However, panel <bold>G</bold> shows <italic>η</italic> versus the two factors <italic>F</italic><sub>1</sub> and <italic>F</italic><sub>2</sub> in the exact expression for <italic>η</italic>, black ‘+’ line is <italic>F</italic><sub>1</sub> ⋅ <italic>F</italic><sub>2</sub> (see <xref ref-type="disp-formula" rid="pcbi.1006206.e042">Eq 22</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.g007" xlink:type="simple"/>
</fig>
<p><bold>Node Occupancy:</bold> The left column of <xref ref-type="fig" rid="pcbi.1006206.g007">Fig 7</xref> plots <italic>η</italic> versus the stationary occupancy probability of each state: <italic>π</italic><sub>3</sub> for state 3 (panel A), <italic>π</italic><sub>2</sub> for state 2 (panel C), and the ratio <italic>π</italic><sub>2</sub>/<italic>π</italic><sub>3</sub> (panel E). Panel A suggests that edge importance can be inverted for any values of <italic>π</italic><sub>3</sub> (<italic>mutatis mutandis</italic> <italic>π</italic><sub>1</sub>), but panel C suggests that inversion requires <italic>π</italic><sub>2</sub> ≲ 1/6. Moreover, panel E indicates that inversion requires <italic>π</italic><sub>2</sub> &lt; <italic>π</italic><sub>3</sub> (equivalently, <italic>α</italic><sub>23</sub> &gt; <italic>α</italic><sub>32</sub> since <italic>π</italic><sub>2</sub>/<italic>π</italic><sub>3</sub> ≡ <italic>α</italic><sub>32</sub>/<italic>α</italic><sub>23</sub>). Together, these conditions suggest that sparse occupancy of the hidden state directly connected to the observable state (relative to the occupancy of the observable state) contributes to inversion of edge importance. However, this condition alone is not sufficient, as shown by Example A below (see Examples subsection), for which the relative importance due to the hidden edges is <italic>η</italic> = 0.4132 &lt; 0.5.</p>
<p>We can extract several strict inequalities relating <italic>η</italic> to properties of the 3-state process. Maximizing <italic>η</italic> with <italic>π</italic><sub>2</sub> fixed, we find
<disp-formula id="pcbi.1006206.e030"><alternatives><graphic id="pcbi.1006206.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e030" xlink:type="simple"/><mml:math display="block" id="M30"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>η</mml:mi> <mml:mo>≤</mml:mo> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(10)</label></disp-formula>
<xref ref-type="fig" rid="pcbi.1006206.g007">Fig 7C</xref> shows this inequality is tight (dashed red curve superimposed on the dots matches the upper boundary). In panel E, maximizing <italic>η</italic> with <italic>π</italic><sub>2</sub>/<italic>π</italic><sub>3</sub> fixed, we observe that
<disp-formula id="pcbi.1006206.e031"><alternatives><graphic id="pcbi.1006206.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>η</mml:mi> <mml:mo>≤</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>/</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>/</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>π</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mrow><mml:msub><mml:mi>π</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>32</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
(dashed red curve matching boundary), which shows that inversion (<italic>η</italic> &gt; 0.5) is only possible if <italic>π</italic><sub>2</sub> &lt; <italic>π</italic><sub>3</sub>, or equivalently, <italic>α</italic><sub>23</sub> &gt; <italic>α</italic><sub>32</sub>. More extreme edge importance inversion requires a more extreme likelihood difference between the observable state and its neighbor or between the transition rates connecting these states.</p>
<p><bold>Timescale Separation:</bold> We introduce two different notions of timescale separation. First, we define
<disp-formula id="pcbi.1006206.e032"><alternatives><graphic id="pcbi.1006206.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e032" xlink:type="simple"/><mml:math display="block" id="M32"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>ν</mml:mi> <mml:mo>=</mml:mo> <mml:msub><mml:mo>λ</mml:mo> <mml:mn>3</mml:mn></mml:msub> <mml:mo>/</mml:mo> <mml:msub><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
which is the ratio of the two non-zero eigenvalues of the graph Laplacian <italic>L</italic>. This quantity is shown in <xref ref-type="fig" rid="pcbi.1006206.g007">Fig 7B</xref> where <italic>η</italic> is plotted versus <italic>ν</italic>. (Note <italic>ν</italic> is the reciprocal of the ratio used to define timescale separation in the previous 3-state model sections with two distinct timescales and discussed in Figs <xref ref-type="fig" rid="pcbi.1006206.g005">5</xref> and <xref ref-type="fig" rid="pcbi.1006206.g006">6</xref>). Large timescale separation, defined <italic>via</italic> the eigenvalues of the graph Laplacian, occurs when <italic>ν</italic> ≫ 1. Specifically, <xref ref-type="fig" rid="pcbi.1006206.g007">Fig 7B</xref> shows that edge importance reversal requires timescale separation such that |λ<sub>3</sub>| ≳ 15|λ<sub>2</sub>| or (<italic>ν</italic> ≳ 15).</p>
<p>Second, we consider the relaxation time
<disp-formula id="pcbi.1006206.e033"><alternatives><graphic id="pcbi.1006206.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e033" xlink:type="simple"/><mml:math display="block" id="M33"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula>
for an isolated 2-state Markov processes with rates <italic>α</italic><sub><italic>ij</italic></sub>, <italic>α</italic><sub><italic>ji</italic></sub> between the nodes <italic>i</italic>, <italic>j</italic>. The ratio of two such local relaxation times gives an alternative measure of timescale separation within the network. Specifically, consider the two possible 2-state processes in our 3-state model (nodes 1-2 and nodes 2-3). In the first system (between nodes 1 and 2), the eigenvalues of the graph Laplacian are 0 and <italic>α</italic><sub>12</sub> + <italic>α</italic><sub>21</sub> = 1/<italic>τ</italic><sub>12</sub>. Likewise, looking at states 2 and 3 as a 2-state Markov process yields eigenvalues 0 and <italic>α</italic><sub>23</sub> + <italic>α</italic><sub>32</sub> = 1/<italic>τ</italic><sub>23</sub>. <xref ref-type="fig" rid="pcbi.1006206.g007">Fig 7F</xref> shows the dependence of <italic>η</italic> on the ratio of the non-zero eigenvalues for these two 2-state systems. Empirically, we see that
<disp-formula id="pcbi.1006206.e034"><alternatives><graphic id="pcbi.1006206.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e034" xlink:type="simple"/><mml:math display="block" id="M34"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>η</mml:mi> <mml:mo>≤</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>23</mml:mn></mml:msub></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mo>/</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>23</mml:mn></mml:msub></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>τ</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mn>23</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula>
(dashed red curve in <xref ref-type="fig" rid="pcbi.1006206.g007">Fig 7F</xref> where <italic>η</italic> is plotted versus <italic>τ</italic><sub>12</sub>/<italic>τ</italic><sub>23</sub>). That is, inversion of the edge importance (<italic>η</italic> &gt; 0.5) occurs only when equilibration along the hidden edges is slower than along the observable edges (<italic>τ</italic><sub>12</sub> &gt; <italic>τ</italic><sub>23</sub>).</p>
<p><bold>Stationary Flux Distribution:</bold> Recall that the stationary flux along edge <italic>k</italic> is given by <italic>J</italic><sub><italic>k</italic></sub> = <italic>N</italic><sub>tot</sub><italic>α</italic><sub><italic>k</italic></sub><italic>π</italic><sub><italic>i</italic>(<italic>k</italic>)</sub>. We can also represent this term as <italic>J</italic><sub><italic>ij</italic></sub>, the stationary flux from node <italic>i</italic>(<italic>k</italic>) to node <italic>j</italic>(<italic>k</italic>) (see §Notation in <xref ref-type="sec" rid="sec016">Methods</xref>). Here we define
<disp-formula id="pcbi.1006206.e035"><alternatives><graphic id="pcbi.1006206.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e035" xlink:type="simple"/><mml:math display="block" id="M35"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>Δ</mml:mo> <mml:mi>J</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>J</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>J</mml:mi> <mml:mn>23</mml:mn></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mi>J</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>J</mml:mi> <mml:mn>23</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula>
which is the relative fraction of the stationary flux generated by the hidden edges. In <xref ref-type="fig" rid="pcbi.1006206.g007">Fig 7D</xref>, we observe that the upper boundary is given by
<disp-formula id="pcbi.1006206.e036"><alternatives><graphic id="pcbi.1006206.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e036" xlink:type="simple"/><mml:math display="block" id="M36"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>η</mml:mi> <mml:mo>≤</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mo>Δ</mml:mo> <mml:mi>J</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
which says that edge importance reversal (<italic>η</italic> &gt; 0.5) requires larger mean flux along the observable edges than along the hidden edges. In other words, the system needs to satisfy Δ<italic>J</italic> &lt; 0 or <italic>J</italic><sub>12</sub> &lt; <italic>J</italic><sub>23</sub>.</p>
<sec id="sec009">
<title>Conditions for edge importance inversion</title>
<p>The results of our ensemble analysis suggest that in order to invert the edge importance, the following conditions must hold:</p>
<list id="list1" list-type="simple">
<list-item><label>1</label><p>The channel opening rate must be significantly faster than the other transition rates. That is, <italic>α</italic><sub>23</sub> ≫ max{<italic>α</italic><sub>12</sub>, <italic>α</italic><sub>21</sub>, <italic>α</italic><sub>32</sub>}. This condition introduces a “fast” and a “slow” timescale.</p>
</list-item>
<list-item><label>2</label><p>Of the “shielded” transitions, the rate away from the observable state must be significantly faster than the rate towards the observable state. That is, <italic>α</italic><sub>12</sub> ≪ <italic>α</italic><sub>21</sub>. This condition introduces a third “super slow” timescale, and guarantees a low occupancy probability for the middle state.</p></list-item></list>
<p>Further examination of the stationary flux along the edges reveals a third condition that is implied by the the first condition:</p>
<list continued-from="list1" list-type="simple">
<list-item><label>3</label><p>The majority of the stationary flux must be along the visible edges rather than the hidden edges. That is, <italic>J</italic><sub>12</sub> &lt; <italic>J</italic><sub>23</sub>.</p></list-item></list>
<p>To see this, note that (see <xref ref-type="sec" rid="sec016">Methods</xref> for derivation of stationary occupancy probability and flux)
<disp-formula id="pcbi.1006206.e037"><alternatives><graphic id="pcbi.1006206.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e037" xlink:type="simple"/><mml:math display="block" id="M37"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>J</mml:mi> <mml:mn>12</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>π</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>21</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>32</mml:mn></mml:msub></mml:mrow> <mml:mi>Z</mml:mi></mml:mfrac></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula>
<disp-formula id="pcbi.1006206.e038"><alternatives><graphic id="pcbi.1006206.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e038" xlink:type="simple"/><mml:math display="block" id="M38"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>J</mml:mi> <mml:mn>23</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>32</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>32</mml:mn></mml:msub></mml:mrow> <mml:mi>Z</mml:mi></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(18)</label></disp-formula>
where <italic>Z</italic> = <italic>α</italic><sub>12</sub><italic>α</italic><sub>23</sub> + <italic>α</italic><sub>12</sub><italic>α</italic><sub>32</sub> + <italic>α</italic><sub>21</sub><italic>α</italic><sub>32</sub>. Then
<disp-formula id="pcbi.1006206.e039"><alternatives><graphic id="pcbi.1006206.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e039" xlink:type="simple"/><mml:math display="block" id="M39"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>J</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>J</mml:mi> <mml:mn>12</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>32</mml:mn></mml:msub></mml:mrow> <mml:mi>Z</mml:mi></mml:mfrac> <mml:mo>-</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>21</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>32</mml:mn></mml:msub></mml:mrow> <mml:mi>Z</mml:mi></mml:mfrac></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>32</mml:mn></mml:msub></mml:mrow> <mml:mi>Z</mml:mi></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>21</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(19)</label></disp-formula>
<disp-formula id="pcbi.1006206.e040"><alternatives><graphic id="pcbi.1006206.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e040" xlink:type="simple"/><mml:math display="block" id="M40"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>J</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>J</mml:mi> <mml:mn>12</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mn>32</mml:mn></mml:msub></mml:mrow> <mml:mi>Z</mml:mi></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>21</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(20)</label></disp-formula>
<disp-formula id="pcbi.1006206.e041"><alternatives><graphic id="pcbi.1006206.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e041" xlink:type="simple"/><mml:math display="block" id="M41"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>⇒</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>J</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>J</mml:mi> <mml:mn>12</mml:mn></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mi>J</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>J</mml:mi> <mml:mn>12</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>21</mml:mn></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>21</mml:mn></mml:msub></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(21)</label></disp-formula>
Condition 1 guarantees that <italic>α</italic><sub>23</sub> &gt; <italic>α</italic><sub>12</sub>, and hence, <italic>J</italic><sub>23</sub> &gt; <italic>J</italic><sub>12</sub>.</p>
</sec>
<sec id="sec010">
<title>Examples</title>
<p>Our ensemble suggests that both conditions 1 and 2 are necessary to see a reversal of the edge importance. However, the following two examples show that one condition can hold without inverting edge importance.</p>
<list list-type="bullet">
<list-item>
<p>Example A: <italic>α</italic><sub>12</sub> = <italic>α</italic><sub>21</sub> = 1, <italic>α</italic><sub>23</sub> = 10, and <italic>α</italic><sub>32</sub> = 0.1. Condition 1 holds, but not condition 2 since the first two transition rates are equal. Note that <italic>π</italic><sub>2</sub> &lt; <italic>π</italic><sub>3</sub> (specifically, <italic>π</italic><sub>2</sub>/<italic>π</italic><sub>3</sub> = 0.01). The fraction of the stationary variance generated by the hidden edges is <italic>η</italic> = 0.4132 &lt; 0.5 which means that the observable edges have higher edge importance than the hidden edges, in agreement with the stochastic shielding method (i.e. no edge importance reversal).</p>
</list-item>
<list-item>
<p>Example B: <italic>α</italic><sub>12</sub> = 0.1, <italic>α</italic><sub>21</sub> = 1, and <italic>α</italic><sub>23</sub> = <italic>α</italic><sub>32</sub> = 10. Condition 2 holds, but not condition 1 since the last two transition rates are equal. The fraction of edge importance due to the hidden edges is <italic>η</italic> = 0.4308 &lt; 0.5 which, again, means that there is no reversal of edge importance.</p>
</list-item>
</list>
<p>Moreover, it is straightforward to see that the simple inequalities <italic>α</italic><sub>23</sub> &gt; max(<italic>α</italic><sub>12</sub>, <italic>α</italic><sub>21</sub>, <italic>α</italic><sub>32</sub>), and <italic>α</italic><sub>12</sub> &lt; <italic>α</italic><sub>21</sub>, are not sufficient. When <italic>α</italic><sub><italic>ij</italic></sub> ≡ 1 we have <italic>R</italic><sub>12</sub> = 1/8 and <italic>R</italic><sub>23</sub> = 7/8; the edge importance varies continuously with the <italic>α</italic><sub><italic>ij</italic></sub> so there will be some neighborhood of (1, 1, 1, 1) satisfying the simple inequalities for which inversion does not occur. For instance, setting <italic>α</italic><sub>23</sub> = <italic>β</italic>, <italic>α</italic><sub>12</sub> = 1/<italic>β</italic>, and <italic>α</italic><sub>21</sub> = <italic>α</italic><sub>32</sub> = 1, we find the hidden edges contributing the majority of the variance to the observable state 3 when <italic>β</italic> ≳ 3.848, while inversion does not occur for <italic>β</italic> ≲ 3.847, although all values <italic>β</italic> &gt; 1 satisfy the simple inequalities.</p>
</sec>
</sec>
<sec id="sec011">
<title>Exact expression for <italic>η</italic></title>
<p>Reproducing edge importance reversal in 3-state chain models is advantageous because such simple Markov models can be analyzed more completely than models with greater numbers of states [<xref ref-type="bibr" rid="pcbi.1006206.ref023">23</xref>]. Fortunately, explicit expressions may be derived for the eigenvalues and eigenvectors of the 3-state chain model which allows direct calculation of <italic>η</italic>, the fraction of the stationary variance generated by the hidden edges (see <xref ref-type="supplementary-material" rid="pcbi.1006206.s001">S1 Supporting Information</xref> §Explicit calculation of <italic>η</italic> for detailed derivation):
<disp-formula id="pcbi.1006206.e042"><alternatives><graphic id="pcbi.1006206.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e042" xlink:type="simple"/><mml:math display="block" id="M42"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>η</mml:mi> <mml:mo>≡</mml:mo> <mml:mfrac><mml:msub><mml:mi>R</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mrow><mml:msub><mml:mi>R</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>R</mml:mi> <mml:mn>23</mml:mn></mml:msub></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:msub><mml:mi>α</mml:mi> <mml:mn>21</mml:mn></mml:msub> <mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>21</mml:mn></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>21</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>32</mml:mn></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:msub><mml:mi>π</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:msub><mml:mi>π</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mrow><mml:mtext>Tr</mml:mtext> <mml:mo>[</mml:mo> <mml:mo>-</mml:mo> <mml:mi>L</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(22)</label></disp-formula>
where Tr[<italic>L</italic>] ≡ ∑<sub><italic>i</italic></sub> <italic>L</italic><sub><italic>ii</italic></sub> is the trace of <italic>L</italic>.</p>
<p>The fraction in <xref ref-type="disp-formula" rid="pcbi.1006206.e042">Eq 22</xref> is a product of two factors (denoted by <italic>F</italic><sub>1</sub> and <italic>F</italic><sub>2</sub> and shown in <xref ref-type="fig" rid="pcbi.1006206.g007">Fig 7G</xref> for the ensemble). The first factor <italic>F</italic><sub>1</sub> is the ratio of the speed of transition from hidden state 2 to hidden state 1 (<italic>α</italic><sub>21</sub>) to the sum of the transition rates between states 1 and 2. Equivalently, this is the proportion of time spent in hidden state 1 relative to hidden state 2. <italic>F</italic><sub>1</sub> approaches 1 as <italic>α</italic><sub>12</sub> decreases, which only occurs if condition 2 holds (<italic>α</italic><sub>12</sub> ≪ <italic>α</italic><sub>21</sub>). The second factor <italic>F</italic><sub>2</sub> is the ratio of the opening transition rate (<italic>α</italic><sub>23</sub>) to the sum of the four rates. This factor is large if and only if the opening rate is much faster than the other rates, and this is exactly condition 1 (<italic>α</italic><sub>23</sub> ≫ max{<italic>α</italic><sub>12</sub>, <italic>α</italic><sub>21</sub>, <italic>α</italic><sub>32</sub>}). Together these <italic>two</italic> conditions bring about a reversal of edge importance (<italic>η</italic> &gt; 0.5) in this simple scenario.</p>
<p>While the exact formula for the relative edge importance <xref ref-type="disp-formula" rid="pcbi.1006206.e042">(22)</xref> applies only for the 3-state chain model considered here, we anticipate that analogous results may hold for more general Markov processes. We consider this question further in §<xref ref-type="sec" rid="sec015">Discussion</xref>.</p>
<sec id="sec012">
<title>Canonical transformation leading to edge importance reversal</title>
<p>In §Generalized 3-State Model with Timescale Separation, we posed the question: <italic>Given an arbitrary set of transition rates, is there a canonical transformation leading to edge importance reversal?</italic> That is, can we show that inversion holds asymptotically in the following sense: given any <italic>α</italic><sub><italic>ij</italic></sub> &gt; 0, if we accelerate the transition to the open state while simultaneously decelerating the exit from the hidden state, can we guarantee that we will eventually have inversion, and pushing the ratios further, approach 100% inversion? The answer is yes, and the exact expression <xref ref-type="disp-formula" rid="pcbi.1006206.e042">(22)</xref> allows us to show this.</p>
<p>Given an arbitrary initial set of transition rates <inline-formula id="pcbi.1006206.e043"><alternatives><graphic id="pcbi.1006206.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mn>0</mml:mn></mml:msubsup> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <italic>ϵ</italic> &gt; 0, define the following rescaled transition rates
<disp-formula id="pcbi.1006206.e044"><alternatives><graphic id="pcbi.1006206.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e044" xlink:type="simple"/><mml:math display="block" id="M44"><mml:msub><mml:mi>α</mml:mi> <mml:mn>12</mml:mn></mml:msub> <mml:mrow><mml:mo>=</mml:mo> <mml:mi>ϵ</mml:mi> <mml:msubsup><mml:mi>α</mml:mi> <mml:mrow><mml:mn>12</mml:mn></mml:mrow> <mml:mn>0</mml:mn></mml:msubsup> <mml:mspace width="1.em"/><mml:mrow><mml:mo>(</mml:mo> <mml:mtext>decelerate</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>transition</mml:mtext> <mml:mspace width="4.pt"/><mml:mn>1</mml:mn> <mml:mo>→</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(23)</label></disp-formula>
<disp-formula id="pcbi.1006206.e045"><alternatives><graphic id="pcbi.1006206.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e045" xlink:type="simple"/><mml:math display="block" id="M45"><mml:msub><mml:mi>α</mml:mi> <mml:mn>21</mml:mn></mml:msub> <mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mi>α</mml:mi> <mml:mrow><mml:mn>21</mml:mn></mml:mrow> <mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives> <label>(24)</label></disp-formula>
<disp-formula id="pcbi.1006206.e046"><alternatives><graphic id="pcbi.1006206.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e046" xlink:type="simple"/><mml:math display="block" id="M46"><mml:msub><mml:mi>α</mml:mi> <mml:mn>23</mml:mn></mml:msub> <mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>ϵ</mml:mi></mml:mfrac> <mml:msubsup><mml:mi>α</mml:mi> <mml:mrow><mml:mn>23</mml:mn></mml:mrow> <mml:mn>0</mml:mn></mml:msubsup> <mml:mspace width="1.em"/><mml:mrow><mml:mo>(</mml:mo> <mml:mtext>accelerate</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>transition</mml:mtext> <mml:mspace width="4.pt"/><mml:mn>2</mml:mn> <mml:mo>→</mml:mo> <mml:mn>3</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(25)</label></disp-formula>
<disp-formula id="pcbi.1006206.e047"><alternatives><graphic id="pcbi.1006206.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e047" xlink:type="simple"/><mml:math display="block" id="M47"><mml:msub><mml:mi>α</mml:mi> <mml:mn>32</mml:mn></mml:msub> <mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mi>α</mml:mi> <mml:mrow><mml:mn>32</mml:mn></mml:mrow> <mml:mn>0</mml:mn></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(26)</label></disp-formula>
In <xref ref-type="supplementary-material" rid="pcbi.1006206.s001">S1 Supporting Information</xref> §Explicit calculation of <italic>η</italic>, we show that as <italic>ϵ</italic> approaches 0, we eventually reverse the edge importance and then approach <italic>η</italic> = <italic>R</italic><sub>12</sub>/(<italic>R</italic><sub>12</sub> + <italic>R</italic><sub>23</sub>) → 1. At the same time <italic>π</italic><sub>2</sub> → 0, the timescale separation grows, as does the flux imbalance. In other words, an arbitrarily large fraction of the stationary variance in the occupancy of the third state arises from the fluctuations in the transitions between nodes 1 and 2.</p>
<p>In summary, inversion of edge importance requires two conditions: the observable state dominates its immediate neighbor (higher occupancy probability), with which it rapidly comes to equilibrium, and this neighboring state is connected to a third state by a slow hidden transition. This combination results in a low occupancy of the intermediate state, but at the same time a larger stationary flux along the observable edges than along the hidden edges. These two conditions also explain why inversion occurs in roughly 10% of cases in our ensemble. To construct the ensemble we chose the edge weights <italic>α</italic><sub><italic>ij</italic></sub> to be independently and identically distributed (<italic>iid</italic>). Given four <italic>iid</italic> random variables <italic>W</italic>, <italic>X</italic>, <italic>Y</italic> and <italic>Z</italic>, it is an elementary exercise to show that <italic>P</italic>[{<italic>Z</italic> &gt; max(<italic>W</italic>, <italic>X</italic>, <italic>Y</italic>)} ∩ {<italic>W</italic> &lt; <italic>X</italic>}] = 1/8. Identifying <italic>α</italic><sub>12</sub> = <italic>W</italic>, <italic>α</italic><sub>21</sub> = <italic>X</italic>, <italic>α</italic><sub>32</sub> = <italic>Y</italic>, <italic>α</italic><sub>23</sub> = <italic>Z</italic>, and considering that the two conditions above are necessary but not sufficient, we expect the frequency of edge importance inversion to be less than, but not too different from, 12.5%.</p>
<p>Edge importance is a useful measure for evaluating the stochastic shielding effect that remains valid for arbitrary transition rates, despite the introduction of multiple timescales or sparsely occupied states. The stochastic shielding phenomenon occurs for a broad range of possible transition rates, with exceptions characterized by particular inequalities. Introducing a second timescale does not promote reversal of the edge importance, but introducing a second and third timescale to the graph dynamics in a specific way does.</p>
</sec>
</sec>
<sec id="sec013">
<title>Edge importance and power spectra</title>
<p>Additional insight into the error arising from different noise-suppressing approximations can be obtained by examining the power spectral density distributions of the true and approximate processes. Recalling <xref ref-type="fig" rid="pcbi.1006206.g004">Fig 4A</xref> in the case <italic>α</italic><sub><italic>ij</italic></sub> ≡ 1, the power spectra for the full process with all noise sources included (<italic>S</italic>, black curve) and the approximate process with hidden edge flux noise suppressed (<italic>S</italic><sub>3,4</sub>, red curve) are very similar, with an order of magnitude less power arising from the hidden edges at all frequencies. In contrast, <xref ref-type="fig" rid="pcbi.1006206.g008">Fig 8A</xref> shows the power spectra for the 3-timescale model. In particular, it shows that at low frequencies, the power spectrum for the approximate process with visible edge flux noise suppressed (<italic>S</italic><sub>1,2</sub>, blue curve) is very similar to the PSD for the full process, but that the blue and red curves cross at an intermediate frequency (<italic>ω</italic> ≈ 3) so the red curve dominates at high frequencies.</p>
<fig id="pcbi.1006206.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Stochastic shielding and the power spectrum in the 3-state chain for the case where edge importance is reversed (<italic>α</italic> = 10 shown here).</title>
<p><bold>Panel A</bold> shows that the majority of the power comes from the hidden edges (blue) for low frequencies, but the red and blue curves cross at <italic>ω</italic> ≈ 3, so for high frequencies the majority of the power comes from the observable edges (red). This switch in dominant spectral contributions is reflected in the corresponding Gaussian model trajectories shown in <bold>Panel B</bold> with the blue trace closely following the black trace, and the red trace deviating from the black trace. This shows that <italic>X</italic><sub>1,2</sub> best approximates the full process <italic>X</italic> in this case (whereas <italic>X</italic><sub>3,4</sub> is the best approximation in the uniform transition rate case shown in <xref ref-type="fig" rid="pcbi.1006206.g004">Fig 4</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.g008" xlink:type="simple"/>
</fig>
<p>The change in power spectral contributions is also reflected in model simulations (see Numerical Methods for details on simulations). <xref ref-type="fig" rid="pcbi.1006206.g008">Fig 8B</xref> illustrates sample trajectories for the three processes described above: full process <italic>X</italic> (black), approximation <italic>X</italic><sub>3,4</sub> (red), and approximation <italic>X</italic><sub>1,2</sub> (blue) where <italic>α</italic> = 10. Comparing this edge importance reversal case to the base case shown in <xref ref-type="fig" rid="pcbi.1006206.g004">Fig 4B</xref>, we see that the blue trajectory (instead of the red one) closely follows the black trajectory. Hence, <italic>X</italic><sub>1,2</sub> is the better approximation to the full process in this case.</p>
<p>Thus, the edge importance reversal observed under the combined conditions <italic>α</italic><sub>12</sub> ≪ <italic>α</italic><sub>21</sub> and <italic>α</italic><sub>23</sub> ≫ max(<italic>α</italic><sub>12</sub>, <italic>α</italic><sub>21</sub>, <italic>α</italic><sub>32</sub>) may be understood as resulting from enhancement of the noise power contribution from the hidden edges at <italic>low</italic> frequencies, as well as the small amplitude of the full process’ power spectrum at <italic>high</italic> frequencies.</p>
<p>We see a similar mechanism at work in the 5-state acetylcholine receptor model in the low-[ACh] regime (where a hidden edge becomes more important than a visible edge) as opposed to the high-[ACh] regime, in which the usual edge importance ordering is observed. Figs <xref ref-type="fig" rid="pcbi.1006206.g009">9</xref> and <xref ref-type="fig" rid="pcbi.1006206.g010">10</xref> show the power spectrum and Gaussian model trajectories in the high-[ACh] and low-[ACh] regimes, respectively. Here we have similar notation to the 3-state cases: <italic>X</italic> (black) is the full observed process (Gaussian version) with all sources of noise included and <italic>X</italic><sub><italic>i</italic>,<italic>j</italic></sub> is the approximate process that preserves noise on edge pair <italic>i</italic>, <italic>j</italic> but suppresses noise on all other edges. In particular, we focus on the red trace (<italic>X</italic><sub>3,4</sub>, noise preserved on visible edges 3,4) and the blue trace (<italic>X</italic><sub>5,6</sub> noise preserved on hidden edges 5,6).</p>
<fig id="pcbi.1006206.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Stochastic shielding and the power spectrum in the acetylcholine receptor model.</title>
<p>For a high concentration ([ACh] = 100 <italic>μ</italic>M shown here), edge importance is not reversed. <bold>Panel A</bold> shows that the majority of the power comes from the visible edges at all frequencies (<italic>S</italic><sub>3,4</sub>, red trace), in agreement with the usual edge importance ranking. The corresponding Gaussian model trajectories shown in <bold>Panel B</bold> illustrate that <italic>X</italic><sub>3,4</sub> is the best approximation to <italic>X</italic>, whereas the other approximation only captures average behavior.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.g009" xlink:type="simple"/>
</fig>
<fig id="pcbi.1006206.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006206.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Stochastic shielding and the power spectrum in the acetylcholine receptor model.</title>
<p>For a low concentration ([ACh] = 0.5 <italic>μ</italic>M shown here), edge importance is reversed. <bold>Panel A</bold> shows that the majority of the power comes from the hidden edges at low frequencies (<italic>S</italic><sub>5,6</sub>, blue trace) and from the visible edges at high frequencies (<italic>S</italic><sub>3,4</sub>, red trace), just as we saw in the 3-state model under the case of edge importance reversal. The corresponding Gaussian model trajectories shown in <bold>Panel B</bold> illustrate that <italic>X</italic><sub>5,6</sub> (blue) is the best approximation to <italic>X</italic>, although it misses some the fluctuations captured by <italic>X</italic><sub>3,4</sub> (red).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.g010" xlink:type="simple"/>
</fig>
<p>The usual edge ordering via the edge importance measure for high [ACh] ranks edge pair 3,4 the most important, followed by edges 5,6, then 9,10 (the last two edge pairs have relative importance close to 0 and make the two lowest spectral contributions); See <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2</xref>. <xref ref-type="fig" rid="pcbi.1006206.g009">Fig 9A</xref> shows that for [ACh] = 100 <italic>μ</italic>M, most of the power is attributable to the observable edge pair 3,4, and this agrees with the edge importance ranking. Model trajectories in panel B illustrate that <italic>X</italic><sub>3,4</sub> is the best approximation of the full process <italic>X</italic> and that the other approximations at best only capture the mean behavior of the system.</p>
<p>In the low-[ACh] case shown in <xref ref-type="fig" rid="pcbi.1006206.g010">Fig 10</xref> ([ACh] = 0.5 <italic>μ</italic>M), however, we see the crossing of the top blue and red power spectral density curves at an intermediate frequency (<italic>ω</italic> ≈ 2). As in the 3-state case, this indicates a reversal of edge importance whereby now the hidden edge pair 5,6 contributes the most to the stationary variance of the observable process. Again, this change in spectral contributions is reflected in model trajectories shown in panel B. We see that the blue curve <italic>X</italic><sub>5,6</sub> closely follows the full process <italic>X</italic>, and is the best approximation in this case, but the blue curve misses some of the fluctuations captured by the red curve <italic>X</italic><sub>3,4</sub> even though the red curve clearly deviates from the other two processes.</p>
</sec>
<sec id="sec014">
<title>Edge importance and decomposition of the stationary observed variance for a general first-order transition network</title>
<p>Gadgil <italic>et al.</italic> showed rigorously that the time evolution of the second moments of a discrete population evolving as a first-order reaction network system can be represented explicitly in terms of the eigenvalues and eigenvectors of the matrix that governs the evolution of the mean population dynamics [<xref ref-type="bibr" rid="pcbi.1006206.ref008">8</xref>]. We apply their general results to the specific example of a first-order transition network in two ways. First, we use the spectral decomposition of the stationary variance to establish our main stochastic shielding result. Second, their result on time varying systems allows us to obtain the decomposition of the power spectrum in terms of the eigenvalue spectral decomposition, shown in Eqs <xref ref-type="disp-formula" rid="pcbi.1006206.e119">64</xref>–<xref ref-type="disp-formula" rid="pcbi.1006206.e121">66</xref>.</p>
<p>Consider an arbitrary first-order reaction network with graph Laplacian <italic>L</italic> and matrix <italic>B</italic> satisfying Eqs <xref ref-type="disp-formula" rid="pcbi.1006206.e063">32</xref>–<xref ref-type="disp-formula" rid="pcbi.1006206.e069">36</xref> (see <xref ref-type="sec" rid="sec016">Methods</xref>). The fact that the stationary covariance matrix decomposes into a sum of contributions from each edge in the graph follows from a straightforward calculation that we describe in Lemma 1 and Theorem 1. We defer the proof of Lemma 1 to §<xref ref-type="sec" rid="sec016">Methods</xref>, below.</p>
<p><bold>Definition 1</bold> <italic>Let X denote the set of n</italic> × <italic>n real matrices C such that for all j</italic> = 1, …, <italic>n</italic>, <inline-formula id="pcbi.1006206.e048"><alternatives><graphic id="pcbi.1006206.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e048" xlink:type="simple"/><mml:math display="inline" id="M48"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup> <mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. <italic>Let</italic> <italic>Y</italic> = {<italic>C</italic> ∈ <italic>X</italic> | <italic>C</italic><sup>⊺</sup> = <italic>C</italic>}.</p>
<p><bold>Lemma 1</bold> <italic>Let L be an n</italic> × <italic>n real valued matrix with L</italic><sub><italic>ij</italic></sub> ≥ 0 <italic>for i</italic> ≠ <italic>j, and L</italic><sub><italic>ii</italic></sub> = −∑<sub><italic>i</italic>,<italic>i</italic> ≠ <italic>j</italic></sub> <italic>L</italic><sub><italic>ij</italic></sub> (<italic>so that</italic> <inline-formula id="pcbi.1006206.e049"><alternatives><graphic id="pcbi.1006206.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e049" xlink:type="simple"/><mml:math display="inline" id="M49"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup> <mml:msub><mml:mi>L</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>) <italic>for j</italic> = 1, …, <italic>n, and satisfying dim</italic>(<italic>ker</italic>(<italic>L</italic>)) = 1, <italic>and with a null eigenvector Lv</italic> = 0 <italic>satisfying v</italic><sub><italic>i</italic></sub> ≥ 0 <italic>for i</italic> = 1, …, <italic>n. Then for any F</italic> ∈ <italic>Y, the equation</italic> <disp-formula id="pcbi.1006206.e050"><alternatives><graphic id="pcbi.1006206.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e050" xlink:type="simple"/><mml:math display="block" id="M50"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi> <mml:mi>C</mml:mi> <mml:mo>+</mml:mo> <mml:mi>C</mml:mi> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:mi>F</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(27)</label></disp-formula> <italic>has a unique solution C</italic> ∈ <italic>Y</italic>.</p>
<p><bold>Theorem 1</bold> <italic>For an arbitrary first-order reaction network with graph Laplacian L and matrix B satisfying</italic> Eqs <xref ref-type="disp-formula" rid="pcbi.1006206.e063">32</xref>–<xref ref-type="disp-formula" rid="pcbi.1006206.e069">36</xref>, <italic>there is a unique linear decomposition of the stationary covariance matrix C as a sum of contributions from each edge</italic>:
<disp-formula id="pcbi.1006206.e051"><alternatives><graphic id="pcbi.1006206.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e051" xlink:type="simple"/><mml:math display="block" id="M51"><mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mrow><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">E</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>C</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="1.em"/><mml:mi>w</mml:mi> <mml:mi>h</mml:mi> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>e</mml:mi></mml:mrow></mml:math></alternatives> <label>(28)</label></disp-formula>
<disp-formula id="pcbi.1006206.e052"><alternatives><graphic id="pcbi.1006206.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e052" xlink:type="simple"/><mml:math display="block" id="M52"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mstyle displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>B</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:msubsup><mml:mi>B</mml:mi> <mml:mi>k</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives> <label>(29)</label></disp-formula></p>
<p><bold>Proof 1</bold> <italic>Proof of Theorem 1. Consider a first-order reaction network defined by graph Laplacian L and matrix B, satisfying</italic> Eqs <xref ref-type="disp-formula" rid="pcbi.1006206.e063">32</xref>–<xref ref-type="disp-formula" rid="pcbi.1006206.e069">36</xref>. <italic>We want to solve the Lyapunov equation</italic> <disp-formula id="pcbi.1006206.e053"><alternatives><graphic id="pcbi.1006206.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e053" xlink:type="simple"/><mml:math display="block" id="M53"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi> <mml:mi>C</mml:mi> <mml:mo>+</mml:mo> <mml:mi>C</mml:mi> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mi>B</mml:mi> <mml:msup><mml:mi>B</mml:mi> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(30)</label></disp-formula> <italic>for matrix C. Note that L satisfies the conditions in Lemma 1, and BB</italic><sup>⊺</sup> ∈ <italic>Y since BB</italic><sup>⊺</sup> <italic>is an n</italic> × <italic>n real symmetric matrix with columns that sum to zero. Then by Lemma 1</italic>, <xref ref-type="disp-formula" rid="pcbi.1006206.e053">Eq 30</xref> <italic>has a unique solution C</italic> ∈ <italic>Y. By replacing F with BB</italic><sup>⊺</sup> <italic>in the proof of Lemma 1, we see that the unique solution is</italic> <disp-formula id="pcbi.1006206.e054"><alternatives><graphic id="pcbi.1006206.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e054" xlink:type="simple"/><mml:math display="block" id="M54"><mml:mrow><mml:mrow><mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup> <mml:mi>B</mml:mi> <mml:msup><mml:mi>B</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives> <label>(31)</label></disp-formula> <italic>since all eigenvalues of L have negative real part (except for the Perron-Frobenius eigenvalue</italic> λ<sub>1</sub> ≡ 0), <inline-formula id="pcbi.1006206.e055"><alternatives><graphic id="pcbi.1006206.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e055" xlink:type="simple"/><mml:math display="inline" id="M55"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi> <mml:mn>1</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>B</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, <italic>and</italic> <italic>B</italic><sup>⊺</sup><italic>u</italic><sub>1</sub> = 0.</p>
<p><italic>Since BB</italic><sup>⊺</sup> <italic>can be written as a sum of</italic> <inline-formula id="pcbi.1006206.e056">
<alternatives>
<graphic id="pcbi.1006206.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e056" xlink:type="simple"/>
<mml:math display="inline" id="M56">
<mml:mrow>
<mml:msub>
<mml:mi>B</mml:mi>
<mml:mi>k</mml:mi>
</mml:msub>
<mml:msubsup>
<mml:mi>B</mml:mi>
<mml:mi>k</mml:mi>
<mml:mo>⊺</mml:mo>
</mml:msubsup>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>, <italic>we can repeat the calculation above to get</italic> <xref ref-type="disp-formula" rid="pcbi.1006206.e052">Eq 29</xref> <italic>for each k separately. The integral in</italic> <xref ref-type="disp-formula" rid="pcbi.1006206.e052">Eq 29</xref> <italic>holds for all k since the k</italic><sup><italic>th</italic></sup> <italic>stoichiometry vector ζ</italic><sub><italic>k</italic></sub> <italic>appearing in the k</italic><sup><italic>th</italic></sup> <italic>column of B is orthogonal to the steady state eigenvector. Therefore, C decomposes into a sum over the C</italic><sub><italic>k</italic></sub> <italic>terms, and</italic> <xref ref-type="disp-formula" rid="pcbi.1006206.e051">Eq 28</xref> <italic>holds</italic>.</p>
<p>The decomposition in Theorem 1 allows us to rank each edge in the network in terms of its contribution to the stationary variance of any given node, which we call its “importance” relative to that node. In the case of a single open or conducting node, we refer simply to the edge importance. Moreover, the decomposition allows us to quantify the accuracy of the stochastic shielding approximation with respect to the population process projected onto individual nodes. The decomposition given by Theorem 1 is exact regardless of timescale separation or node sparsity.</p>
</sec>
</sec>
<sec id="sec015" sec-type="conclusions">
<title>Discussion</title>
<p>Markov chains provide a general framework for mathematically modeling and simulating stochastic processes in natural and artificial systems. However, Markov chains are computationally expensive as their simulations require random numbers at each time step for every transition (edge). The stochastic shielding approximation relies on the fact that, when hidden states are present, the edges are not equally important, so that random fluctuations in some (typically most) edges can be neglected. Here, we provide a thorough study addressing how to identify the relevant and irrelevant edges when the stochastic fluctuations span slow and fast timescales. Our analysis shows that the stochastic shielding approach not only provides a practical increase in computational efficiency, but also facilitates a systematic understanding of the propagation of fluctuations in a general Markovian network, and hence, is applicable to many areas of mathematical biology and related disciplines.</p>
<p>The stochastic shielding method is being used increasingly to incorporate fast, accurate simulation of stochastic ion channels into larger neuronal network models. A recent paper [<xref ref-type="bibr" rid="pcbi.1006206.ref035">35</xref>] comparing different methods for simulating ion channels, based on diffusion approximations, recommended using the stochastic shielding approximation in conjuction with a direct Langevin approach advanced by Orio and Soudry [<xref ref-type="bibr" rid="pcbi.1006206.ref036">36</xref>]. Two examples in which stochastic shielding makes large-scale simulations tractable include [<xref ref-type="bibr" rid="pcbi.1006206.ref037">37</xref>] and [<xref ref-type="bibr" rid="pcbi.1006206.ref038">38</xref>]. In the first paper, the use of stochastic shielding allowed for a significant reduction in computation time of multiple simulations of a conductance-based model with synaptic and ion channel noise that are necessary to reliably estimate the entropy and information rate of neuronal firing. In the second paper, stochastic shielding is applied to a heterogeneous neural circuit for the first time, allowing the authors to investigate the role of channel noise in the generation of breathing variability in the isolated central pattern generator of respiration. In both cases, these studies would have not been possible in practice without the stochastic shielding approximation.</p>
<p>The analysis conducted here and in [<xref ref-type="bibr" rid="pcbi.1006206.ref010">10</xref>] is restricted to the case of a stationary Markov process, <italic>i.e.</italic> with time-invariant <italic>per capita</italic> transition rates. In many applications, for example under current-clamp (rather than voltage-clamp) in electrophysiology, the transition rates vary over time. In [<xref ref-type="bibr" rid="pcbi.1006206.ref009">9</xref>], which introduced the stochastic shielding method, stochastic shielding was shown to produce accurate approximations through comparison of voltage traces and spike trains generated via both stochastic shielding and full Monte Carlo simulations.</p>
<p>In the present paper, we have shown that in the presence of multiple timescales, for instance as seen in the dynamics of the nicotinic acetylcholine receptor (nAChR) under low agonist concentrations, one or more unobserved edges can become more important than the observable edges, in terms of making a greater contribution to the stationary variance of the occupancy of the open channel state (and hence the variance of the ionic current through the population of channels). In such a case the stochastic shielding phenomenon is still present, but is significantly reduced, to the point that the approximation given by suppressing the noise on the hidden edges does not provide the best approximation. Indeed, as seen in <xref ref-type="fig" rid="pcbi.1006206.g010">Fig 10</xref>, one may conclude that in this situation there is no suitable approximation of the type we consider, since the traces generated by reduced models with noise suppressed either on the observed or unobserved edges do not bear much similarity to the trace generated by the full model (with identical noise forcing where the noise is included). On the one hand, the edge importance measure remains exact under all conditions, as long as the network is irreducible (meaning here that <italic>α</italic><sub>12</sub>, <italic>α</italic><sub>21</sub>, <italic>α</italic><sub>23</sub> and <italic>α</italic><sub>32</sub> are all nonzero). On the other hand, the stationary variance does not capture the full shape of the trajectories. The decomposition of the fluctuations at one node as a sum of contributions from distinct edges extends to the correlation function and the power spectrum and the cross-spectrum, as well as to the variance.</p>
<p>Motivated by the example of the nicotinic acetylcholine receptor, we systematically studied the effects of introducing separation of timescales into the simplest nontrivial model to which stochastic shielding applies: the 3-state chain with one observable state. We found that, in the case of two distinct timescales, accelerating or decelerating a subset of edges relative to a baseline case (<italic>α</italic><sub><italic>ij</italic></sub> = 1 for all adjacent nodes (<italic>i</italic>, <italic>j</italic>)) could in some cases enhance, and in other cases reduce the gap in edge importance between the observed and unobserved edges, but in no case could induce a reversal of the edge importance (as observed in nAChR).</p>
<p>Finally, by sampling an ensemble of different transition rates, we found that inversion of edge importance can be seen in a 3-state chain when the channel opening rate is large (that is, <italic>α</italic><sub>23</sub> ≫ max(<italic>α</italic><sub>12</sub>, <italic>α</italic><sub>21</sub>, <italic>α</italic><sub>32</sub>)), <italic>and also</italic> the rate of return from the first hidden state to the middle hidden state is small (that is, <italic>α</italic><sub>12</sub> ≪ <italic>α</italic><sub>21</sub>). These complementary conditions are captured by the exact expression for the relative edge importance (<xref ref-type="disp-formula" rid="pcbi.1006206.e042">Eq 22</xref>). Together, these conditions lead to sparse occupation of the middle node, introducing a bottleneck, while also introducing timescale separation in such a way that equilibration between the observable node and its immediate neighbor occurs much faster than between the two unobservable nodes.</p>
<p>Although our exact formula applies only to the 3-state chain model from which it was derived, we are optimistic that it may be extended to broader classes of Markov processes. The forms of such extensions are not <italic>a priori</italic> obvious, for several reasons. Consider the case of an ion channel with <italic>n</italic> states of which a single open conducting state (<italic>O</italic><sub><italic>n</italic></sub>) is connected to the closed, non-conducting states (<italic>C</italic><sub>1</sub>, …, <italic>C</italic><sub><italic>n</italic>−1</sub>) through a single bottleneck state (<italic>C</italic><sub><italic>n</italic>−1</sub>); the closed states may interconnect arbitrarily with rates <italic>α</italic><sub><italic>ij</italic></sub>, 1 ≤ <italic>i</italic>, <italic>j</italic> ≤ (<italic>n</italic> − 1). In this case the analog of the first factor in <xref ref-type="disp-formula" rid="pcbi.1006206.e042">Eq 22</xref> would be the conditional occupancy probability of the bottleneck node <italic>C</italic><sub><italic>n</italic>−1</sub>, given the channel is in any of the states <italic>C</italic><sub>1</sub>, …, <italic>C</italic><sub><italic>n</italic>−1</sub>. However, the analog of the second factor, the ratio of the <italic>C</italic><sub><italic>n</italic>−1</sub> → <italic>O</italic><sub><italic>n</italic></sub> transition to some combination of all the rates in the system, is far from clear. For ion channel models with multiple transitions into and out of a single open state (see <xref ref-type="fig" rid="pcbi.1006206.g001">Fig 1</xref>), the parallel to our exact 3-state chain analysis is scarcely obvious, and remains for future investigation.</p>
<p>The stochastic shielding approximation and method provide an approach distinct from aggregation based on community structure [<xref ref-type="bibr" rid="pcbi.1006206.ref020">20</xref>] or similarity of spectral components [<xref ref-type="bibr" rid="pcbi.1006206.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1006206.ref039">39</xref>], and pruning of sparsely populated nodes [<xref ref-type="bibr" rid="pcbi.1006206.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1006206.ref033">33</xref>], although there are some relations between these methods. Both spectral coarse graining [<xref ref-type="bibr" rid="pcbi.1006206.ref013">13</xref>] and our edge importance measure [<xref ref-type="bibr" rid="pcbi.1006206.ref010">10</xref>] rely on spectral decomposition of the graph Laplacian. As Ullah <italic>et al.</italic> point out, finding eigenvalues and eigenvectors of the Laplacian for a large complicated graph can be challenging [<xref ref-type="bibr" rid="pcbi.1006206.ref023">23</xref>]. An advantage of the stochastic shielding method is that it can be applied in the vast majority of cases without calculating the edge importance explicitly. Exceptions can occur when there is significant timescale separation with fast relaxation of the observable node with its immediate neighbors and slow relaxation among unobservable states, with a hidden bottleneck state separating the observable from a well populated pool of unobservable nodes. Except in this particular case, the stochastic shielding method can be applied without necessarily having to calculate the edge importance in detail. The effect of fluctuations in rates along the hidden edges is filtered by the network, and their impact on fluctuations at the observable nodes is diminished.</p>
</sec>
<sec id="sec016" sec-type="materials|methods">
<title>Materials and methods</title>
<p>In this section we fill in the details behind the results. We introduce notation, define the edge importance measure relative to an arbitrary measurement vector, justify our use of the Lyapunov equation, prove Lemma 1, and describe our numerical methods.</p>
<p>In <xref ref-type="supplementary-material" rid="pcbi.1006206.s001">S1 Supporting Information</xref>, we establish the decomposition of the stationary variance. We provide explicit calculations for the 3-state process, and calculate <italic>η</italic>, the fraction of variance of the observable state arising from the hidden edges. We review the connection between the population process and Gaussian approximations thereof, and give a detailed derivation of the Lyapunov equation for the 3-state case.</p>
<sec id="sec017">
<title>Notation</title>
<p>We begin with a directed graph <inline-formula id="pcbi.1006206.e057"><alternatives><graphic id="pcbi.1006206.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e057" xlink:type="simple"/><mml:math display="inline" id="M57"><mml:mrow><mml:mi mathvariant="script">G</mml:mi> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mi mathvariant="script">V</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="script">E</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> with edge weights <italic>α</italic><sub><italic>ij</italic></sub> ≥ 0 representing a population of <italic>N</italic><sub>tot</sub> individuals moving randomly and independently among <italic>n</italic> states (<inline-formula id="pcbi.1006206.e058"><alternatives><graphic id="pcbi.1006206.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e058" xlink:type="simple"/><mml:math display="inline" id="M58"><mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">V</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>) along <italic>m</italic> edges {<italic>i</italic>(<italic>k</italic>)→<italic>j</italic>(<italic>k</italic>)}<sub>1≤<italic>k</italic>≤<italic>m</italic></sub>, with <italic>per capita</italic> transition rates {<italic>α</italic><sub><italic>k</italic></sub>}<sub>1≤<italic>k</italic>≤<italic>m</italic></sub>. We emphasize that edge <italic>k</italic> is the unique directed edge connecting source node <italic>i</italic>(<italic>k</italic>) to destination node <italic>j</italic>(<italic>k</italic>). The <italic>n</italic> × 1 stoichiometry vector <italic>ζ</italic><sub><italic>k</italic></sub> corresponding to edge <italic>k</italic> is defined such that <italic>ζ</italic><sub><italic>k</italic></sub>(<italic>i</italic>) = −1 and <italic>ζ</italic><sub><italic>k</italic></sub>(<italic>j</italic>) = +1, otherwise <italic>ζ</italic><sub><italic>k</italic></sub>(<italic>l</italic>) = 0; these vectors represent the effect of a transition along edge <italic>k</italic>. We use this notation to be consistent with the edge importance formula in the next subsection which is a sum of contributions to the variance of the observable state coming from each edge. Also, note that we will write the <italic>per capita</italic> transition rates either with double indexing denoting the source and destination nodes (<italic>α</italic><sub><italic>ij</italic></sub>) or with a single index denoting the reaction (<italic>α</italic><sub><italic>k</italic></sub>).</p>
<p>We represent the population state at time <italic>t</italic> with an integer-valued vector <bold>N</bold>(<italic>t</italic>) = (<italic>N</italic><sub>1</sub>(<italic>t</italic>), …, <italic>N</italic><sub><italic>n</italic></sub>(<italic>t</italic>))<sup>⊺</sup>, where <italic>N</italic><sub><italic>i</italic></sub>(<italic>t</italic>) ≥ 0 and <inline-formula id="pcbi.1006206.e059"><alternatives><graphic id="pcbi.1006206.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e059" xlink:type="simple"/><mml:math display="inline" id="M59"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup> <mml:msub><mml:mi>N</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>tot</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> for all <italic>t</italic>. In other words, <bold>N</bold>(<italic>t</italic>) is a discrete state continuous time Markov process. Such processes are ubiquitous in biology [<xref ref-type="bibr" rid="pcbi.1006206.ref001">1</xref>].</p>
<p>We denote by <bold>M</bold> a <italic>measurement vector</italic> indicating a direction in the state space along which there is an observable of interest. For instance, <italic>M</italic><sub><italic>i</italic></sub> ∈ {0, 1} could denote the conducting state ({closed, open}) in a multi-state ion channel model. We denote the observed process by <italic>Y</italic>(<italic>t</italic>) = <bold>M</bold><sup>⊺</sup><bold>N</bold>(<italic>t</italic>). The remainder of our set up follows standard nomenclature for representing a population process on a graph [<xref ref-type="bibr" rid="pcbi.1006206.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1006206.ref040">40</xref>–<xref ref-type="bibr" rid="pcbi.1006206.ref042">42</xref>].</p>
<p>Let <italic>L</italic> be the Laplacian of graph <inline-formula id="pcbi.1006206.e060"><alternatives><graphic id="pcbi.1006206.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e060" xlink:type="simple"/><mml:math display="inline" id="M60"><mml:mi mathvariant="script">G</mml:mi></mml:math></alternatives></inline-formula> which is the <italic>n</italic> × <italic>n</italic> matrix defined by <italic>L</italic> = (<italic>A</italic> − <italic>D</italic>)<sup>⊺</sup> where <italic>A</italic> is the weighted adjacency matrix and <italic>D</italic> is the diagonal matrix of node out-degrees. Specifically, the entries in <italic>A</italic> are <italic>A</italic><sub><italic>ij</italic></sub> = <italic>α</italic><sub><italic>ij</italic>(<italic>k</italic>)</sub> = <italic>α</italic><sub><italic>k</italic></sub> ≥ 0 and the diagonal entries in <italic>D</italic> are <inline-formula id="pcbi.1006206.e061"><alternatives><graphic id="pcbi.1006206.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e061" xlink:type="simple"/><mml:math display="inline" id="M61"><mml:mrow><mml:msub><mml:mi>D</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup> <mml:msub><mml:mi>A</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> for <italic>i</italic> ∈ {1, …, <italic>n</italic>}. Note that <italic>L</italic> = <italic>Q</italic><sup>⊺</sup> where <italic>Q</italic> is the standard generator matrix of the Markov process. It follows that, for any vector <inline-formula id="pcbi.1006206.e062"><alternatives><graphic id="pcbi.1006206.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e062" xlink:type="simple"/><mml:math display="inline" id="M62"><mml:mrow><mml:mi>x</mml:mi> <mml:mo>∈</mml:mo> <mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, <italic>L</italic> satisfies the following equation
<disp-formula id="pcbi.1006206.e063"><alternatives><graphic id="pcbi.1006206.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e063" xlink:type="simple"/><mml:math display="block" id="M63"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi> <mml:mi>x</mml:mi> <mml:mo>≡</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>m</mml:mi></mml:munderover> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(32)</label></disp-formula>
The stoichiometry vector <italic>ζ</italic><sub><italic>k</italic></sub> is a difference of two standard unit vectors, <italic>ζ</italic><sub><italic>k</italic></sub> = <italic>e</italic><sub><italic>j</italic>(<italic>k</italic>)</sub> − <italic>e</italic><sub><italic>i</italic>(<italic>k</italic>)</sub>. Although we do not assume that the graph Laplacian <italic>L</italic> must be a symmetric matrix, we do assume that the stationary system satisfies detailed balance, and that <italic>L</italic> has only real eigenvalues. Moreover, we assume that <italic>L</italic> has an expansion into real-valued biorthogonal eigentriples (<italic>w</italic><sub>λ</sub>, λ, <italic>v</italic><sub>λ</sub>) such that
<disp-formula id="pcbi.1006206.e064"><alternatives><graphic id="pcbi.1006206.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e064" xlink:type="simple"/><mml:math display="block" id="M64"><mml:mrow><mml:mi>L</mml:mi> <mml:msub><mml:mi>v</mml:mi> <mml:mo>λ</mml:mo></mml:msub></mml:mrow> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>λ</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mo>λ</mml:mo></mml:msub></mml:mrow></mml:math></alternatives> <label>(33)</label></disp-formula>
<disp-formula id="pcbi.1006206.e065"><alternatives><graphic id="pcbi.1006206.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e065" xlink:type="simple"/><mml:math display="block" id="M65"><mml:mrow><mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msub><mml:mi>w</mml:mi> <mml:mo>λ</mml:mo></mml:msub></mml:mrow> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>λ</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mo>λ</mml:mo></mml:msub></mml:mrow></mml:math></alternatives> <label>(34)</label></disp-formula>
<disp-formula id="pcbi.1006206.e066"><alternatives><graphic id="pcbi.1006206.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e066" xlink:type="simple"/><mml:math display="block" id="M66"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi> <mml:mo>λ</mml:mo> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>v</mml:mi> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:msub></mml:mrow> <mml:mo>=</mml:mo> <mml:mrow><mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mo>λ</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(35)</label></disp-formula>
We further assume that <inline-formula id="pcbi.1006206.e067"><alternatives><graphic id="pcbi.1006206.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e067" xlink:type="simple"/><mml:math display="inline" id="M67"><mml:mi mathvariant="script">G</mml:mi></mml:math></alternatives></inline-formula> is connected and the process is irreducible. The Perron-Frobenius theory guarantees the existence of a unique null eigenvector with nonnegative components summing to unity, corresponding to the stationary distribution on the graph. We denote the stationary probability vector <inline-formula id="pcbi.1006206.e068"><alternatives><graphic id="pcbi.1006206.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e068" xlink:type="simple"/><mml:math display="inline" id="M68"><mml:mrow><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> and the stationary mean flux along edge <italic>k</italic> by <italic>J</italic><sub><italic>k</italic></sub> = <italic>N</italic><sub>tot</sub><italic>α</italic><sub><italic>k</italic></sub><italic>π</italic><sub><italic>i</italic>(<italic>k</italic>)</sub>.</p>
<p>Let <italic>B</italic> be the <italic>n</italic> × <italic>m</italic> matrix defined such that
<disp-formula id="pcbi.1006206.e069"><alternatives><graphic id="pcbi.1006206.e069g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e069" xlink:type="simple"/><mml:math display="block" id="M69"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>B</mml:mi> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:msqrt> <mml:msub><mml:mi>ζ</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:msqrt> <mml:msub><mml:mi>ζ</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mo>⋯</mml:mo></mml:mtd> <mml:mtd><mml:mrow><mml:msqrt><mml:msub><mml:mi>J</mml:mi> <mml:mi>m</mml:mi></mml:msub></mml:msqrt> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(36)</label></disp-formula>
In other words, the <italic>k</italic><sup>th</sup> column of <italic>B</italic> is given by the square root of the stationary flux <italic>J</italic><sub><italic>k</italic></sub> multiplied by the stoichoimetry vector <italic>ζ</italic><sub><italic>k</italic></sub>. We can express <italic>B</italic> as a sum of matrices
<disp-formula id="pcbi.1006206.e070"><alternatives><graphic id="pcbi.1006206.e070g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e070" xlink:type="simple"/><mml:math display="block" id="M70"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>B</mml:mi> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>m</mml:mi></mml:munderover> <mml:msub><mml:mi>B</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(37)</label></disp-formula>
where all the entries of <italic>B</italic><sub><italic>k</italic></sub> are zero except for the <italic>k</italic><sup>th</sup> column. Moreover, we will exploit the fact that the product <italic>BB</italic><sup>⊺</sup> can be represented with a similar sum
<disp-formula id="pcbi.1006206.e071"><alternatives><graphic id="pcbi.1006206.e071g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e071" xlink:type="simple"/><mml:math display="block" id="M71"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>B</mml:mi> <mml:msup><mml:mi>B</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>m</mml:mi></mml:munderover> <mml:msub><mml:mi>B</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:msubsup><mml:mi>B</mml:mi> <mml:mi>k</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(38)</label></disp-formula>
This product appears on the right hand side of the Lyapunov equation (see <xref ref-type="disp-formula" rid="pcbi.1006206.e094">Eq 46</xref> below) and its decomposition into the above sum is a key factor in establishing the decomposition of the stationary variance into a sum over the edges.</p>
<p>Computations were done either by hand, or using Matlab or Mathematica.</p>
</sec>
<sec id="sec018">
<title>Summary of stochastic shielding in the Langevin case</title>
<p>In the Langevin approximation for a time homogeneous first-order transition network, the population fraction occupying states 1, …, <italic>n</italic> is a vector <inline-formula id="pcbi.1006206.e072"><alternatives><graphic id="pcbi.1006206.e072g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e072" xlink:type="simple"/><mml:math display="inline" id="M72"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi> <mml:mo>∈</mml:mo> <mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> satisfying
<disp-formula id="pcbi.1006206.e073"><alternatives><graphic id="pcbi.1006206.e073g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e073" xlink:type="simple"/><mml:math display="block" id="M73"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:mi mathvariant="bold">X</mml:mi></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mi>L</mml:mi> <mml:mi mathvariant="bold">X</mml:mi> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">E</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>B</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(39)</label></disp-formula>
where <italic>L</italic>, the graph Laplacian, captures the mean flux along each directed edge <inline-formula id="pcbi.1006206.e074"><alternatives><graphic id="pcbi.1006206.e074g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e074" xlink:type="simple"/><mml:math display="inline" id="M74"><mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">E</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. The matrix <italic>B</italic><sub><italic>k</italic></sub> gives the effects of fluctuations <italic>ξ</italic><sub><italic>k</italic></sub> around the mean flux along the <italic>k</italic><sup>th</sup> edge. The noise terms are independent, white and Gaussian, with 〈<italic>ξ</italic><sub><italic>k</italic></sub>(<italic>t</italic>)<italic>ξ</italic><sub><italic>k</italic>′</sub>(<italic>t</italic>′)〉 = <italic>δ</italic><sub><italic>kk</italic>′</sub> <italic>δ</italic>(<italic>t</italic> − <italic>t</italic>′), one for each directed edge. Given an observable of interest, represented by a vector <inline-formula id="pcbi.1006206.e075"><alternatives><graphic id="pcbi.1006206.e075g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e075" xlink:type="simple"/><mml:math display="inline" id="M75"><mml:mrow><mml:mi mathvariant="bold">M</mml:mi> <mml:mo>∈</mml:mo> <mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, the stochastic shielding approximation consists in finding a partition of the edge set, <inline-formula id="pcbi.1006206.e076"><alternatives><graphic id="pcbi.1006206.e076g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e076" xlink:type="simple"/><mml:math display="inline" id="M76"><mml:mrow><mml:mi mathvariant="script">E</mml:mi> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>∐</mml:mo> <mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, into edges of <italic>primary</italic> importance (<inline-formula id="pcbi.1006206.e077"><alternatives><graphic id="pcbi.1006206.e077g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e077" xlink:type="simple"/><mml:math display="inline" id="M77"><mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:math></alternatives></inline-formula>) and <italic>secondary</italic> importance (<inline-formula id="pcbi.1006206.e078"><alternatives><graphic id="pcbi.1006206.e078g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e078" xlink:type="simple"/><mml:math display="inline" id="M78"><mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:math></alternatives></inline-formula>) such that <inline-formula id="pcbi.1006206.e079"><alternatives><graphic id="pcbi.1006206.e079g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e079" xlink:type="simple"/><mml:math display="inline" id="M79"><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>≫</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and, at the same time <inline-formula id="pcbi.1006206.e080"><alternatives><graphic id="pcbi.1006206.e080g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e080" xlink:type="simple"/><mml:math display="inline" id="M80"><mml:mrow><mml:msub><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>→</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">Y</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>⪡</mml:mo> <mml:msub><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>→</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mrow><mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> (stationary variances), where <bold>Y</bold> is the approximate population vector satisfying
<disp-formula id="pcbi.1006206.e081"><alternatives><graphic id="pcbi.1006206.e081g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e081" xlink:type="simple"/><mml:math display="block" id="M81"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:mi mathvariant="bold">Y</mml:mi></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mi>L</mml:mi> <mml:mi mathvariant="bold">Y</mml:mi> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:munder> <mml:msub><mml:mi>B</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mspace width="1.em"/><mml:mi mathvariant="bold">Y</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(40)</label></disp-formula>
The noise samples <italic>ξ</italic><sub><italic>k</italic></sub> for <inline-formula id="pcbi.1006206.e082"><alternatives><graphic id="pcbi.1006206.e082g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e082" xlink:type="simple"/><mml:math display="inline" id="M82"><mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> are identical in the full and approximate models. Neglecting the noise forcing along the edges of secondary importance causes a pathwise discrepancy <bold>U</bold>(<italic>t</italic>) = <bold>Y</bold>(<italic>t</italic>) − <bold>X</bold>(<italic>t</italic>) that satisfies
<disp-formula id="pcbi.1006206.e083"><alternatives><graphic id="pcbi.1006206.e083g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e083" xlink:type="simple"/><mml:math display="block" id="M83"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:mi mathvariant="bold">U</mml:mi></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mi>L</mml:mi> <mml:mi mathvariant="bold">U</mml:mi> <mml:mo>-</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:munder> <mml:msub><mml:mi>B</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mspace width="1.em"/><mml:mi mathvariant="bold">U</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(41)</label></disp-formula>
The stochastic shielding <italic>effect</italic> consists in suppression of the resulting fluctuations in the observable process <bold>M</bold><sup>⊺</sup><bold>U</bold>(<italic>t</italic>) due to the filtering effects of the network—hence “stochastic shielding”.</p>
<p>The (stationary) mean squared pathwise approximation error can be written exactly as a sum of contributions <italic>R</italic><sub><italic>k</italic></sub> from each directed edge neglected in the approximation, <inline-formula id="pcbi.1006206.e084"><alternatives><graphic id="pcbi.1006206.e084g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e084" xlink:type="simple"/><mml:math display="inline" id="M84"><mml:mrow><mml:msub><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>→</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub> <mml:msub><mml:mi>R</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. This error is small compared to <inline-formula id="pcbi.1006206.e085"><alternatives><graphic id="pcbi.1006206.e085g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e085" xlink:type="simple"/><mml:math display="inline" id="M85"><mml:mrow><mml:msub><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>→</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">E</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>R</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub> <mml:msub><mml:mi>R</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">E</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub> <mml:msub><mml:mi>R</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. We call <italic>R</italic><sub><italic>k</italic></sub> the <italic>importance</italic> of the <italic>k</italic><sup>th</sup> directed edge (defined in the next section). As we show below, the decomposition holds exactly not only for the Langevin process but for the discrete population process as well.</p>
</sec>
<sec id="sec019">
<title>Edge importance measure</title>
<p>The general formula for the edge importance measure is as follows. For an arbitrary stationary population process <bold>N</bold>(<italic>t</italic>) satisfying detailed balance on a graph with <italic>n</italic> nodes, <italic>m</italic> edges, and measurement vector <bold>M</bold> (defining the observable states), <inline-formula id="pcbi.1006206.e086"><alternatives><graphic id="pcbi.1006206.e086g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e086" xlink:type="simple"/><mml:math display="inline" id="M86"><mml:mrow><mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>m</mml:mi></mml:msubsup> <mml:msub><mml:mi>R</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the stationary variance of the observable states where
<disp-formula id="pcbi.1006206.e087"><alternatives><graphic id="pcbi.1006206.e087g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e087" xlink:type="simple"/><mml:math display="block" id="M87"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>R</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>J</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:munderover> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:munderover> <mml:mo>(</mml:mo> <mml:mfrac><mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:msub><mml:mo>λ</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mo>λ</mml:mo> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msub><mml:mi>v</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>w</mml:mi> <mml:mi>i</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>ζ</mml:mi> <mml:mi>k</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>w</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>v</mml:mi> <mml:mi>j</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi mathvariant="bold">M</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(42)</label></disp-formula>
In this formula, λ<sub><italic>n</italic></sub> ≤ λ<sub><italic>n</italic>−1</sub> ≤ ⋯ ≤ λ<sub>2</sub> &lt; 0 are the nontrivial eigenvalues of the graph Laplacian <italic>L</italic> (which always has λ<sub>1</sub> ≡ 0); <italic>v</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>i</italic></sub> are the right and left eigenvectors of <italic>L</italic>, respectively. Here and henceforth, <italic>R</italic><sub><italic>k</italic></sub> is normalized to the variance due to a single random walker by dividing out <italic>N</italic><sub>tot</sub>.</p>
<p>The stationary variance <italic>R</italic> is related to the power spectral density (PSD) <italic>S</italic>(<italic>ω</italic>) of the observed process <bold>M</bold><sup>⊺</sup><bold>N</bold>. From the Wiener-Khinchin theorem, integrating the PSD gives the stationary variance: <inline-formula id="pcbi.1006206.e088"><alternatives><graphic id="pcbi.1006206.e088g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e088" xlink:type="simple"/><mml:math display="inline" id="M88"><mml:mrow><mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>S</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Moreover, since the stationary variance decomposes into a sum of contributions from each edge in the graph, the power spectral density decomposes as well. By introducing
<disp-formula id="pcbi.1006206.e089"><alternatives><graphic id="pcbi.1006206.e089g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e089" xlink:type="simple"/><mml:math display="block" id="M89"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>R</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:msub><mml:mi>S</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(43)</label></disp-formula>
we define a <italic>power-spectral edge importance</italic> such that the integral of <italic>S</italic><sub><italic>k</italic></sub>(<italic>ω</italic>), the power spectral density for the observed process with noise suppressed everywhere except edge <italic>k</italic>, gives the edge importance corresponding to edge <italic>k</italic>.</p>
<p>To see this, note that the power spectral density of the observed process is
<disp-formula id="pcbi.1006206.e090"><alternatives><graphic id="pcbi.1006206.e090g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e090" xlink:type="simple"/><mml:math display="block" id="M90"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>S</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">E</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>S</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="1.em"/><mml:mtext>where</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(44)</label></disp-formula>
<disp-formula id="pcbi.1006206.e091"><alternatives><graphic id="pcbi.1006206.e091g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e091" xlink:type="simple"/><mml:math display="block" id="M91"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>S</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:mfrac> <mml:msub><mml:mi>J</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>l</mml:mi> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:munderover> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:munderover> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msub><mml:mo>λ</mml:mo> <mml:mi>l</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msub><mml:mo>λ</mml:mo> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msup><mml:mi>M</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msub><mml:mi>v</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>l</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>ζ</mml:mi> <mml:mi>k</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>u</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>v</mml:mi> <mml:mi>j</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>M</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(45)</label></disp-formula>
provided <italic>ω</italic> &gt; 0. For more details, see §Numerical Methods: Calculation of power spectra, below. We can use this power spectral decomposition to explore how the spectral contributions differ between the typical cases (where edge importance ranking agrees with the stochastic shielding method) and in the edge importance reversal cases.</p>
</sec>
<sec id="sec020">
<title>Lyapunov equation</title>
<p>The Perron-Frobenius null eigenvector, suitably normalized, gives the stationary probability vector <inline-formula id="pcbi.1006206.e092"><alternatives><graphic id="pcbi.1006206.e092g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e092" xlink:type="simple"/><mml:math display="inline" id="M92"><mml:mrow><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> of Markov process <bold>N</bold>(<italic>t</italic>). Snapshots of the process <bold>N</bold>(<italic>t</italic>), taken under stationary conditions, are multinomial with parameters <inline-formula id="pcbi.1006206.e093"><alternatives><graphic id="pcbi.1006206.e093g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e093" xlink:type="simple"/><mml:math display="inline" id="M93"><mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mtext>tot</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>, so the covariance matrix <italic>C</italic> is known. In particular, each diagonal entry in <italic>C</italic> is the variance of state <italic>i</italic>, <italic>C</italic><sub><italic>ii</italic></sub> = <italic>N</italic><sub>tot</sub><italic>π</italic><sub><italic>i</italic></sub>(1 − <italic>π</italic><sub><italic>i</italic></sub>), and each off-diagonal entry in <italic>C</italic> is the covariance of states <italic>i</italic> and <italic>j</italic>, <italic>C</italic><sub><italic>ij</italic></sub> = −<italic>N</italic><sub>tot</sub><italic>π</italic><sub><italic>i</italic></sub><italic>π</italic><sub><italic>j</italic></sub> for <italic>i</italic> ≠ <italic>j</italic>.</p>
<p>The stationary covariance matrix <italic>C</italic> satisfies Lyapunov’s equation (a special case of Sylvester’s equation) [<xref ref-type="bibr" rid="pcbi.1006206.ref043">43</xref>]
<disp-formula id="pcbi.1006206.e094"><alternatives><graphic id="pcbi.1006206.e094g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e094" xlink:type="simple"/><mml:math display="block" id="M94"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi> <mml:mi>C</mml:mi> <mml:mo>+</mml:mo> <mml:mi>C</mml:mi> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mi>B</mml:mi> <mml:msup><mml:mi>B</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(46)</label></disp-formula>
The fact that <italic>C</italic> satisfies <xref ref-type="disp-formula" rid="pcbi.1006206.e094">Eq 46</xref> above is widely known for linear Gaussian processes such as multivariate Ornstein-Uhlenbeck processes [<xref ref-type="bibr" rid="pcbi.1006206.ref034">34</xref>], but it also holds for discrete state population processes in which the transition rates are linear functions of the population at each node, <italic>i.e.</italic> first-order transition networks, such as those we consider here (see [<xref ref-type="bibr" rid="pcbi.1006206.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1006206.ref044">44</xref>]).</p>
<p>Our system is an important special case of the general first-order reaction network presented in [<xref ref-type="bibr" rid="pcbi.1006206.ref008">8</xref>]; we only consider conversion type reactions (denoted by <italic>k</italic><sup>con</sup> in [<xref ref-type="bibr" rid="pcbi.1006206.ref008">8</xref>]). For our system <italic>P</italic><sub><italic>i</italic></sub> represents <inline-formula id="pcbi.1006206.e095"><alternatives><graphic id="pcbi.1006206.e095g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e095" xlink:type="simple"/><mml:math display="inline" id="M95"><mml:mrow><mml:msub><mml:mi>v</mml:mi> <mml:mo>λ</mml:mo></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mo>λ</mml:mo> <mml:mo>⊺</mml:mo></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, summed over all identical λ if they occur with multiplicity (we both assume semisimple eigenvalue spectra). The following parameters in [<xref ref-type="bibr" rid="pcbi.1006206.ref008">8</xref>] are zero for our system: <italic>C</italic>(<italic>i</italic>, <italic>k</italic>, <italic>l</italic>), <italic>k</italic><sup>cat</sup>, <italic>k</italic><sup>s</sup>, and <italic>k</italic><sup>d</sup>. This simplifies Equation 50 in [<xref ref-type="bibr" rid="pcbi.1006206.ref008">8</xref>] (representing the variance of the <italic>l</italic><sup><italic>th</italic></sup> reactant in the network) and is equivalent to our edge importance measure (<xref ref-type="disp-formula" rid="pcbi.1006206.e087">Eq 42</xref>). However, to our knowledge, we are the first to describe the unique decomposition of the stationary variance into a sum of contributions from each edge in the network, and [<xref ref-type="bibr" rid="pcbi.1006206.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006206.ref010">10</xref>] were the first to propose the stochastic shielding approximation and justify it based on this decomposition.</p>
<p>The Lyapunov equation has also been used in the context of stochastic gene networks under the name of “linear noise approximation” [<xref ref-type="bibr" rid="pcbi.1006206.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1006206.ref046">46</xref>]; in particular [<xref ref-type="bibr" rid="pcbi.1006206.ref045">45</xref>] (pg. 1, ¶5) further cites Eqs 3.46 and 6.115 in Risken [<xref ref-type="bibr" rid="pcbi.1006206.ref047">47</xref>] for additional details. See also [<xref ref-type="bibr" rid="pcbi.1006206.ref048">48</xref>] Supporting Information §4. For the linear networks we consider here, the equation is exact.</p>
</sec>
<sec id="sec021">
<title>Proof of Lemma 1</title>
<p>We restate the lemma for the reader’s convenience. Recall from Definition 1 that <italic>Y</italic> is the space of <italic>n</italic> × <italic>n</italic> symmetric matrices with columns (and rows) summing to zero.</p>
<p><bold>Lemma 1 (restated)</bold> <italic>Let L be an n</italic> × <italic>n real valued matrix with L</italic><sub><italic>ij</italic></sub> ≥ 0 <italic>for i</italic> ≠ <italic>j, and L</italic><sub><italic>ii</italic></sub> = −∑<sub><italic>i</italic>,<italic>i</italic> ≠ <italic>j</italic></sub> <italic>L</italic><sub><italic>ij</italic></sub> (<italic>so that</italic> <inline-formula id="pcbi.1006206.e096"><alternatives><graphic id="pcbi.1006206.e096g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e096" xlink:type="simple"/><mml:math display="inline" id="M96"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup> <mml:msub><mml:mi>L</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>) <italic>for j</italic> = 1, …, <italic>n, and satisfying dim</italic>(<italic>ker</italic>(<italic>L</italic>)) = 1, <italic>and with a null eigenvector Lv</italic> = 0 <italic>satisfying v</italic><sub><italic>i</italic></sub> ≥ 0 <italic>for i</italic> = 1, …, <italic>n. Then for any F</italic> ∈ <italic>Y, the equation</italic> <disp-formula id="pcbi.1006206.e097"><alternatives><graphic id="pcbi.1006206.e097g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e097" xlink:type="simple"/><mml:math display="block" id="M97"><mml:mrow><mml:mi>L</mml:mi> <mml:mi>C</mml:mi> <mml:mo>+</mml:mo> <mml:mi>C</mml:mi> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:mi>F</mml:mi></mml:mrow></mml:math></alternatives></disp-formula> <italic>has a unique solution C</italic> ∈ <italic>Y</italic>.</p>
<p><bold>Proof 2</bold> <italic>Proof of Lemma 1. Given L</italic> ∈ <italic>X, define the linear operator A by A</italic>: <italic>C</italic> → <italic>LC</italic> + <italic>CL</italic><sup>⊺</sup>. <italic>First, we show that A</italic>: <italic>Y</italic> → <italic>Y. If C</italic> ∈ <italic>Y then for all j</italic> = 1, …, <italic>n</italic>,
<disp-formula id="pcbi.1006206.e098"><alternatives><graphic id="pcbi.1006206.e098g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e098" xlink:type="simple"/><mml:math display="block" id="M98"><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:msup><mml:mi>L</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:math></alternatives> <label>(47)</label></disp-formula> <italic>because each sum over i is zero, by assumption. Moreover</italic>, (<italic>LC</italic> + <italic>CL</italic><sup>⊺</sup>)<sup>⊺</sup> = <italic>LC</italic> + <italic>CL</italic><sup>⊺</sup>. <italic>Therefore LC</italic> + <italic>CL</italic><sup>⊺</sup> ∈ <italic>Y whenever C</italic> ∈ <italic>Y, so A maps Y into itself</italic>.</p>
<p><italic>By the Fredholm alternative(cf. [<xref ref-type="bibr" rid="pcbi.1006206.ref049">49</xref>], Theorem 2.27), A(C) = F has a unique inverse for F</italic> ∈ <italic>Y provided F is in the range of A and the homogeneous equation A(C</italic>) = 0 <italic>has only the trivial solution C</italic> = 0.</p>
<p><italic>Let C</italic><sub>0</sub> ∈ <italic>Y be a solution of the homogeneous equation</italic>, <italic>LC</italic><sub>0</sub> + <italic>C</italic><sub>0</sub><italic>L</italic><sup>⊺</sup> = 0. <italic>Because C</italic><sub>0</sub> ∈ <italic>Y is symmetric and the nullspace of L is one dimensional, C</italic><sub>0</sub> <italic>must have the form C</italic><sub>0</sub> = (<italic>c</italic><sub>1</sub><italic>v</italic>|⋯|<italic>c</italic><sub><italic>n</italic></sub><italic>v) for constants c</italic><sub>1</sub>, …, <italic>c</italic><sub><italic>n</italic></sub>. <italic>However, the columns of C</italic><sub>0</sub> <italic>must sum to zero, and</italic> <inline-formula id="pcbi.1006206.e099"><alternatives><graphic id="pcbi.1006206.e099g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e099" xlink:type="simple"/><mml:math display="inline" id="M99"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup> <mml:msub><mml:mi>v</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, <italic>therefore c</italic><sub>1</sub> = … = <italic>c</italic><sub><italic>n</italic></sub> = 0, <italic>hence C</italic><sub>0</sub> = 0.</p>
<p><italic>To see that F is in the range of A, we construct an explicit solution as follows</italic>:
<disp-formula id="pcbi.1006206.e100"><alternatives><graphic id="pcbi.1006206.e100g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e100" xlink:type="simple"/><mml:math display="block" id="M100"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mstyle displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup> <mml:mi>F</mml:mi> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(48)</label></disp-formula> <italic>and we show that this integral is well defined whenever F</italic> ∈ <italic>Y. To see this, first note that if all eigenvalues of L have negative real part, then</italic> <disp-formula id="pcbi.1006206.e101"><alternatives><graphic id="pcbi.1006206.e101g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e101" xlink:type="simple"/><mml:math display="block" id="M101"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi> <mml:mi>C</mml:mi> <mml:mo>+</mml:mo> <mml:mi>C</mml:mi> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>S</mml:mi> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(49)</label></disp-formula> <italic>where</italic> <disp-formula id="pcbi.1006206.e102"><alternatives><graphic id="pcbi.1006206.e102g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e102" xlink:type="simple"/><mml:math display="block" id="M102"><mml:mi>S</mml:mi> <mml:mo>=</mml:mo> <mml:mrow><mml:mi>L</mml:mi> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup> <mml:mi>F</mml:mi> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup> <mml:mi>F</mml:mi> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:msup> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></alternatives> <label>(50)</label></disp-formula>
<disp-formula id="pcbi.1006206.e103"><alternatives><graphic id="pcbi.1006206.e103g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e103" xlink:type="simple"/><mml:math display="block" id="M103"><mml:mo>=</mml:mo> <mml:mrow><mml:mfrac><mml:mi>d</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup> <mml:mi>F</mml:mi> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives> <label>(51)</label></disp-formula> <italic>and the solution in</italic> <xref ref-type="disp-formula" rid="pcbi.1006206.e100">Eq 48</xref> <italic>follows from the fundamental theorem of calculus</italic>.</p>
<p><italic>It remains to show that the integral in</italic> <xref ref-type="disp-formula" rid="pcbi.1006206.e100">Eq 48</xref> <italic>is well defined whenever F</italic> ∈ <italic>Y. Assuming detailed balance, a unique null space, and that L is diagonalizable, we have that all eigenvalues of L are negative (and real) except</italic> λ<sub>1</sub> ≡ 0, <italic>and we can write</italic> <disp-formula id="pcbi.1006206.e104"><alternatives><graphic id="pcbi.1006206.e104g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e104" xlink:type="simple"/><mml:math display="block" id="M104"><mml:mi>L</mml:mi> <mml:mrow><mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mo>λ</mml:mo></mml:munder> <mml:msub><mml:mi>v</mml:mi> <mml:mo>λ</mml:mo></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mo>λ</mml:mo> <mml:mo>⊺</mml:mo></mml:msubsup></mml:mrow></mml:math></alternatives> <label>(52)</label></disp-formula>
<disp-formula id="pcbi.1006206.e105"><alternatives><graphic id="pcbi.1006206.e105g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e105" xlink:type="simple"/><mml:math display="block" id="M105"><mml:mrow><mml:mo>⇒</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mn>0</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mo>λ</mml:mo> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:munder> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>λ</mml:mo></mml:mrow></mml:msup> <mml:msub><mml:mi>v</mml:mi> <mml:mo>λ</mml:mo></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mo>λ</mml:mo> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(53)</label></disp-formula> <italic>Then</italic> <disp-formula id="pcbi.1006206.e106"><alternatives><graphic id="pcbi.1006206.e106g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e106" xlink:type="simple"/><mml:math display="block" id="M106"><mml:mi>C</mml:mi> <mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mstyle displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup> <mml:mi>F</mml:mi> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives> <label>(54)</label></disp-formula>
<disp-formula id="pcbi.1006206.e107"><alternatives><graphic id="pcbi.1006206.e107g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e107" xlink:type="simple"/><mml:math display="block" id="M107"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd> <mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mstyle displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mo>{</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msub><mml:mi>v</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mn>1</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>F</mml:mi> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msub><mml:mi>v</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mn>1</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msub><mml:mi>v</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mn>1</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>F</mml:mi> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>λ</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:munder></mml:mstyle> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>λ</mml:mi></mml:mrow></mml:msup> <mml:msub><mml:mi>v</mml:mi> <mml:mi>λ</mml:mi></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>λ</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(55)</label></disp-formula>
<disp-formula id="pcbi.1006206.e108"><alternatives><graphic id="pcbi.1006206.e108g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e108" xlink:type="simple"/><mml:math display="block" id="M108"><mml:mrow><mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:mi>λ</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:munder> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>λ</mml:mi></mml:mrow></mml:msup> <mml:msub><mml:mi>v</mml:mi> <mml:mi>λ</mml:mi></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>λ</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>F</mml:mi> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msub><mml:mi>v</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mn>1</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo>+</mml:mo> <mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle> <mml:mrow><mml:mi>λ</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:msup><mml:mi>λ</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:munder> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>λ</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi>λ</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:msub><mml:mi>v</mml:mi> <mml:mi>λ</mml:mi></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>λ</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>F</mml:mi> <mml:msub><mml:mi>u</mml:mi> <mml:msup><mml:mi>λ</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:msubsup><mml:mi>v</mml:mi> <mml:msup><mml:mi>λ</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mo>}</mml:mo> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives> <label>(56)</label></disp-formula>
<disp-formula id="pcbi.1006206.e109"><alternatives><graphic id="pcbi.1006206.e109g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e109" xlink:type="simple"/><mml:math display="block" id="M109"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd> <mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∫</mml:mo></mml:mstyle> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:msub><mml:mi>v</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:munder accentunder="true"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi> <mml:mn>1</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>F</mml:mi></mml:mrow> <mml:mo stretchy="true">_</mml:mo></mml:munder></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msub><mml:mi>u</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msubsup><mml:mi>v</mml:mi> <mml:mn>1</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:munder accentunder="true"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi> <mml:mn>1</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>F</mml:mi></mml:mrow> <mml:mo stretchy="true">_</mml:mo></mml:munder></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mstyle displaystyle="true" mathsize="140%"><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>λ</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:munder></mml:mstyle> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>λ</mml:mi></mml:mrow></mml:msup> <mml:msub><mml:mi>u</mml:mi> <mml:mi>λ</mml:mi></mml:msub> <mml:msubsup><mml:mi>v</mml:mi> <mml:mi>λ</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(57)</label></disp-formula>
<disp-formula id="pcbi.1006206.e110"><alternatives><graphic id="pcbi.1006206.e110g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e110" xlink:type="simple"/><mml:math display="block" id="M110"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd> <mml:mtd><mml:mrow><mml:mspace width="2pt"/><mml:mrow><mml:mrow><mml:mo>+</mml:mo> <mml:mstyle displaystyle="true" mathsize="140%"><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>λ</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:munder></mml:mstyle> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mi>λ</mml:mi></mml:mrow></mml:msup> <mml:msub><mml:mi>v</mml:mi> <mml:mi>λ</mml:mi></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>λ</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:munder accentunder="true"><mml:mrow><mml:mi>F</mml:mi> <mml:msub><mml:mi>u</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow> <mml:mo stretchy="true">_</mml:mo></mml:munder></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>v</mml:mi> <mml:mn>1</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mo>+</mml:mo> <mml:mstyle displaystyle="true" mathsize="140%"><mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>λ</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:msup><mml:mi>λ</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:munder></mml:mstyle> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>λ</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi>λ</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:msub><mml:mi>v</mml:mi> <mml:mi>λ</mml:mi></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>λ</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>F</mml:mi> <mml:msub><mml:mi>u</mml:mi> <mml:msup><mml:mi>λ</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:msubsup><mml:mi>v</mml:mi> <mml:msup><mml:mi>λ</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>⊺</mml:mo></mml:msubsup></mml:mrow> <mml:mo>}</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(58)</label></disp-formula>
<disp-formula id="pcbi.1006206.e111"><alternatives><graphic id="pcbi.1006206.e111g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e111" xlink:type="simple"/><mml:math display="block" id="M111"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mo>λ</mml:mo> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:munder> <mml:msub><mml:mi>v</mml:mi> <mml:mo>λ</mml:mo></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mo>λ</mml:mo> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>F</mml:mi> <mml:msub><mml:mi>u</mml:mi> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:msubsup><mml:mi>v</mml:mi> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mo>(</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>(</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>+</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(59)</label></disp-formula>
<disp-formula id="pcbi.1006206.e112"><alternatives><graphic id="pcbi.1006206.e112g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e112" xlink:type="simple"/><mml:math display="block" id="M112"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mo>λ</mml:mo> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mo>λ</mml:mo> <mml:mo>+</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfrac> <mml:msub><mml:mi>v</mml:mi> <mml:mo>λ</mml:mo></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mo>λ</mml:mo> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>F</mml:mi> <mml:msub><mml:mi>u</mml:mi> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:msubsup><mml:mi>v</mml:mi> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(60)</label></disp-formula> <italic>The underlined expressions in parentheses are all zero because the columns (and rows since F is a symmetric matrix) of F sum to zero by assumption</italic>; <inline-formula id="pcbi.1006206.e113"><alternatives><graphic id="pcbi.1006206.e113g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e113" xlink:type="simple"/><mml:math display="inline" id="M113"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi> <mml:mn>1</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mo>≡</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> <italic>is orthogonal to every column of F and u</italic><sub>1</sub> <italic>is orthogonal to every row of F and so</italic> <inline-formula id="pcbi.1006206.e114"><alternatives><graphic id="pcbi.1006206.e114g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e114" xlink:type="simple"/><mml:math display="inline" id="M114"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi> <mml:mn>1</mml:mn> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>F</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> <italic>and Fu</italic><sub>1</sub> = 0. <italic>Thus, the integral in</italic> <xref ref-type="disp-formula" rid="pcbi.1006206.e106">Eq 54</xref> <italic>is finite and</italic> <xref ref-type="disp-formula" rid="pcbi.1006206.e112">Eq 60</xref> <italic>gives an explicit expression for it</italic>.</p>
</sec>
<sec id="sec022">
<title>Numerical methods</title>
<sec id="sec023">
<title>Discrete state simulations</title>
<p>To represent the trajectory of the state or the measurement functional (<italic>e.g.</italic> ion channel conductance) due to a single random walker, as for instance in <xref ref-type="fig" rid="pcbi.1006206.g002">Fig 2</xref>, we used Gillespie’s exact stochastic simulation algorithm (SSA) [<xref ref-type="bibr" rid="pcbi.1006206.ref050">50</xref>] implemented in Matlab. Briefly, the SSA is a method for constructing simulated trajectories of finite populations in continuous time. If <italic>N</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is the number of individuals in state <italic>i</italic> (for <italic>i</italic> ∈ {1, …, <italic>n</italic>}) at time <italic>t</italic>, the SSA generates the state vector <bold>N</bold>(<italic>t</italic>) = (<italic>N</italic><sub>1</sub>(<italic>t</italic>), …, <italic>N</italic><sub><italic>n</italic></sub>(<italic>t</italic>)) given that the system was initially in state <bold>N</bold>(<italic>t</italic><sub>0</sub>) = <italic>x</italic><sub>0</sub> at time <italic>t</italic><sub>0</sub>. Reactions cause the state of the system to change over time. The SSA method samples the time <italic>τ</italic> to the next reaction and updates the state of the system accordingly.</p>
</sec>
<sec id="sec024">
<title>Continuous state simulations</title>
<p>To represent the trajectory of a population (<italic>N</italic><sub>tot</sub> = 500) of random walkers for the full processes or different fluctuation-suppressed approximations derived from the stochastic shielding method, as for instance in Figs <xref ref-type="fig" rid="pcbi.1006206.g004">4</xref> and <xref ref-type="fig" rid="pcbi.1006206.g008">8</xref>–<xref ref-type="fig" rid="pcbi.1006206.g010">10</xref>, we used a Langevin approximation. Briefly, we consider a linear Langevin equation with strictly additive noise, given by
<disp-formula id="pcbi.1006206.e115"><alternatives><graphic id="pcbi.1006206.e115g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e115" xlink:type="simple"/><mml:math display="block" id="M115"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>d</mml:mi> <mml:mi mathvariant="bold">X</mml:mi> <mml:mo>=</mml:mo> <mml:mi>L</mml:mi> <mml:mi mathvariant="bold">X</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>B</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi mathvariant="bold">W</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(61)</label></disp-formula>
where <inline-formula id="pcbi.1006206.e116"><alternatives><graphic id="pcbi.1006206.e116g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e116" xlink:type="simple"/><mml:math display="inline" id="M116"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:mi mathvariant="bold">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">N</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> and the graph Laplacian <italic>L</italic> and matrix <italic>B</italic> are those considered in Eqs <xref ref-type="disp-formula" rid="pcbi.1006206.e063">32</xref>–<xref ref-type="disp-formula" rid="pcbi.1006206.e069">36</xref>. See <xref ref-type="supplementary-material" rid="pcbi.1006206.s001">S1 Supporting Information</xref> §Connection to Gaussian approximation for more details, and note that Eq S40–S42 define <italic>L</italic> and <italic>B</italic> specifically for the 3-state process. We used the Euler-Maruyama method implemented in Matlab to numerically solve the SDE above.</p>
</sec>
<sec id="sec025">
<title>Calculation of power spectra</title>
<p>See Equation 4.5.78 in Gardiner §4.5.6 for the spectrum matrix of a stationary multivariate Ornstein-Uhlenbeck process [<xref ref-type="bibr" rid="pcbi.1006206.ref034">34</xref>]. The power spectrum of the observable process <bold>M</bold><sup>⊺</sup><bold>X</bold> is
<disp-formula id="pcbi.1006206.e117"><alternatives><graphic id="pcbi.1006206.e117g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e117" xlink:type="simple"/><mml:math display="block" id="M117"><mml:mrow><mml:mrow><mml:mi>S</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:mfrac> <mml:msup><mml:mi>M</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>L</mml:mi> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi>B</mml:mi> <mml:msup><mml:mi>B</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo>−</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi>M</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives> <label>(62)</label></disp-formula>
<disp-formula id="pcbi.1006206.e118"><alternatives><graphic id="pcbi.1006206.e118g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e118" xlink:type="simple"/><mml:math display="block" id="M118"><mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mo>λ</mml:mo></mml:munder> <mml:munder><mml:mo>∑</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:munder> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mo>λ</mml:mo> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">E</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>J</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msup><mml:mi>M</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msub><mml:mi>v</mml:mi> <mml:mo>λ</mml:mo></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>u</mml:mi> <mml:mo>λ</mml:mo> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>ζ</mml:mi> <mml:mi>k</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>u</mml:mi> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>v</mml:mi> <mml:mrow><mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:mrow> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>M</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives> <label>(63)</label></disp-formula>
<disp-formula id="pcbi.1006206.e119"><alternatives><graphic id="pcbi.1006206.e119g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e119" xlink:type="simple"/><mml:math display="block" id="M119"><mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">E</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>J</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:munder><mml:mo>∑</mml:mo> <mml:mo>λ</mml:mo></mml:munder> <mml:munder><mml:mo>∑</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:munder> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mo>λ</mml:mo> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msup><mml:mi>M</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msub><mml:mi>v</mml:mi> <mml:mo>λ</mml:mo></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>u</mml:mi> <mml:mo>λ</mml:mo> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>ζ</mml:mi> <mml:mi>k</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>u</mml:mi> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>v</mml:mi> <mml:mrow><mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:mrow> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>M</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives> <label>(64)</label></disp-formula>
<disp-formula id="pcbi.1006206.e120"><alternatives><graphic id="pcbi.1006206.e120g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e120" xlink:type="simple"/><mml:math display="block" id="M120"><mml:mrow><mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">E</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>S</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mspace width="4.pt"/><mml:mtext>where</mml:mtext> <mml:mspace width="4.pt"/></mml:mrow></mml:math></alternatives> <label>(65)</label></disp-formula>
<disp-formula id="pcbi.1006206.e121"><alternatives><graphic id="pcbi.1006206.e121g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e121" xlink:type="simple"/><mml:math display="block" id="M121"><mml:mrow><mml:msub><mml:mi>S</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:mfrac> <mml:msub><mml:mi>J</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:munder><mml:mo>∑</mml:mo> <mml:mo>λ</mml:mo></mml:munder> <mml:munder><mml:mo>∑</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:munder> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mo>λ</mml:mo> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mi>ω</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msup><mml:mi>M</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:msub><mml:mi>v</mml:mi> <mml:mo>λ</mml:mo></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>u</mml:mi> <mml:mo>λ</mml:mo> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>ζ</mml:mi> <mml:mi>k</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>u</mml:mi> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>v</mml:mi> <mml:mrow><mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:mrow> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mi>M</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives> <label>(66)</label></disp-formula>
provided <italic>ω</italic> &gt; 0. The left eigenvector for λ = 0 is orthogonal to <italic>ζ</italic><sub><italic>k</italic></sub> for each edge <italic>k</italic>, so the sum <italic>de facto</italic> excludes all terms with λ = 0 or λ′ = 0. Notice that the integral of the power spectrum corresponding to edge <italic>k</italic> gives the edge importance for edge <italic>k</italic>:
<disp-formula id="pcbi.1006206.e122"><alternatives><graphic id="pcbi.1006206.e122g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e122" xlink:type="simple"/><mml:math display="block" id="M122"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>R</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:msub><mml:mi>S</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>ω</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(67)</label></disp-formula></p>
<p>More generally, one could use the lagged covariance of the Gaussian process, given by Equation 4.5.71 in Gardiner §4.5.6 [<xref ref-type="bibr" rid="pcbi.1006206.ref034">34</xref>]
<disp-formula id="pcbi.1006206.e123"><alternatives><graphic id="pcbi.1006206.e123g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e123" xlink:type="simple"/><mml:math display="block" id="M123"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>⟨</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mo form="prefix">exp</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>L</mml:mi> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo form="prefix">exp</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1.em"/><mml:mo>+</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>∧</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo form="prefix">exp</mml:mo> <mml:mo>[</mml:mo> <mml:mi>L</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo> <mml:mi>B</mml:mi> <mml:msup><mml:mi>B</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo form="prefix">exp</mml:mo> <mml:mo>[</mml:mo> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo> <mml:mi>d</mml:mi> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(68)</label></disp-formula>
If we write instead (assuming <italic>s</italic> = <italic>t</italic> + <italic>τ</italic>, <italic>τ</italic> ≥ 0)
<disp-formula id="pcbi.1006206.e124"><alternatives><graphic id="pcbi.1006206.e124g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e124" xlink:type="simple"/><mml:math display="block" id="M124"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>〈</mml:mo> <mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>τ</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>〉</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mtext>exp</mml:mtext> <mml:mo stretchy="false">(</mml:mo> <mml:mi>L</mml:mi> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>〈</mml:mo> <mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle> <mml:mo stretchy="false">(</mml:mo> <mml:mi>a</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>a</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>〉</mml:mo> <mml:mtext>exp</mml:mtext> <mml:mo stretchy="false">(</mml:mo> <mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mi>τ</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:msubsup><mml:mstyle displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle> <mml:mi>a</mml:mi> <mml:mi>t</mml:mi></mml:msubsup> <mml:mtext>exp</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>L</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mi>B</mml:mi> <mml:msup><mml:mi>B</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mtext>exp</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:msup><mml:mi>L</mml:mi> <mml:mo>⊺</mml:mo></mml:msup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>−</mml:mo> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msup><mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(69)</label></disp-formula> 
and take the limit <italic>a</italic> → −∞, then we see that <italic>C</italic>(<italic>τ</italic>), the stationary lagged covariance at lag <italic>τ</italic>, satisfies <italic>C</italic>(<italic>τ</italic>) = ∑<sub><italic>k</italic></sub> <italic>C</italic><sub><italic>k</italic></sub>(<italic>τ</italic>), where
<disp-formula id="pcbi.1006206.e125"><alternatives><graphic id="pcbi.1006206.e125g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006206.e125" xlink:type="simple"/><mml:math display="block" id="M125"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mo>λ</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup> <mml:mo>&lt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:munder> <mml:mfrac><mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>λ</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mo>λ</mml:mo> <mml:mo>+</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfrac> <mml:msub><mml:mi>v</mml:mi> <mml:mo>λ</mml:mo></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mo>λ</mml:mo> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>B</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:msubsup><mml:mi>B</mml:mi> <mml:mi>k</mml:mi> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:msub><mml:mi>u</mml:mi> <mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:msubsup><mml:mi>v</mml:mi> <mml:mrow><mml:msup><mml:mo>λ</mml:mo> <mml:mo>′</mml:mo></mml:msup></mml:mrow> <mml:mo>⊺</mml:mo></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(70)</label></disp-formula>
Multiplying by the measurement vector <italic>M</italic> and taking the Fourier transform of this expression yields <italic>S</italic><sub><italic>k</italic></sub>(<italic>ω</italic>) above.</p>
</sec>
</sec>
</sec>
<sec id="sec026">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006206.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006206.s001" xlink:type="simple">
<label>S1 Supporting Information</label>
<caption>
<title/>
<p>We establish the decomposition of the stationary variance and calculate <italic>η</italic>, the fraction of variance of the observable state arising from the hidden edges, providing explicit calculations for the 3-state process. We also detail the connection between the population process and Gaussian approximations thereof, and derive the Lyapunov equation for the 3-state case.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>PJT thanks Oberlin College for research support.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006206.ref001">
<label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Bressloff</surname> <given-names>PC</given-names></name>. <source>Stochastic processes in cell biology</source>. <volume>vol. 41</volume>. <publisher-name>Springer</publisher-name>; <year>2014</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref002">
<label>2</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Meyn</surname> <given-names>SP</given-names></name>, <name name-style="western"><surname>Tweedie</surname> <given-names>RL</given-names></name>. <source>Markov chains and stochastic stability</source>. <publisher-name>Springer Science &amp; Business Media</publisher-name>; <year>2012</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref003">
<label>3</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Norris</surname> <given-names>JR</given-names></name>. <source>Markov Chains</source>. <publisher-name>Cambridge University Press</publisher-name>; <year>1998</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Shen</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Zong</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Hasty</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wolynes</surname> <given-names>PG</given-names></name>. <article-title>Statistics of cellular signal transduction as a race to the nucleus by multiple random walkers in compartment/phosphorylation space</article-title>. <source>Proc Natl Acad Sci</source>. <year>2006</year>;<volume>103</volume>(<issue>45</issue>):<fpage>16752</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0607698103" xlink:type="simple">10.1073/pnas.0607698103</ext-link></comment> <object-id pub-id-type="pmid">17071742</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Skaugen</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Walløe</surname> <given-names>L</given-names></name>. <article-title>Firing behaviour in a stochastic nerve membrane model based upon the Hodgkin-Huxley equations</article-title>. <source>Acta Physiol Scand</source>. <year>1979</year>;<volume>107</volume>(<issue>4</issue>):<fpage>343</fpage>–<lpage>63</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1748-1716.1979.tb06486.x" xlink:type="simple">10.1111/j.1748-1716.1979.tb06486.x</ext-link></comment> <object-id pub-id-type="pmid">543428</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McCandlish</surname> <given-names>DM</given-names></name>. <article-title>Visualizing fitness landscapes</article-title>. <source>Evolution</source>. <year>2011</year>;<volume>65</volume>(<issue>6</issue>):<fpage>1544</fpage>–<lpage>58</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1558-5646.2011.01236.x" xlink:type="simple">10.1111/j.1558-5646.2011.01236.x</ext-link></comment> <object-id pub-id-type="pmid">21644947</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cowen</surname> <given-names>RK</given-names></name>, <name name-style="western"><surname>Sponaugle</surname> <given-names>S</given-names></name>. <article-title>Larval dispersal and marine population connectivity</article-title>. <source>Ann Rev Mar Sci</source>. <year>2009</year>;<volume>1</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.marine.010908.163757" xlink:type="simple">10.1146/annurev.marine.010908.163757</ext-link></comment> <object-id pub-id-type="pmid">21141044</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gadgil</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>CH</given-names></name>, <name name-style="western"><surname>Othmer</surname> <given-names>HG</given-names></name>. <article-title>A stochastic analysis of first-order reaction networks</article-title>. <source>Bull Math Biol</source>. <year>2005</year>;<volume>67</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.bulm.2004.09.009" xlink:type="simple">10.1016/j.bulm.2004.09.009</ext-link></comment> <object-id pub-id-type="pmid">15998488</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schmandt</surname> <given-names>NT</given-names></name>, <name name-style="western"><surname>Galán</surname> <given-names>RF</given-names></name>. <article-title>Stochastic-shielding approximation of Markov chains and its application to efficiently simulate random ion-channel gating</article-title>. <source>Phys Rev Lett</source>. <year>2012</year>;<volume>109</volume>(<issue>11</issue>):<fpage>118101</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevLett.109.118101" xlink:type="simple">10.1103/PhysRevLett.109.118101</ext-link></comment> <object-id pub-id-type="pmid">23005678</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schmidt</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>PJ</given-names></name>. <article-title>Measuring edge importance: a quantitative analysis of the stochastic shielding approximation for random processes on graphs</article-title>. <source>J Math Neurosci</source>. <year>2014</year>;<volume>4</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>52</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Itzkovitz</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Levitt</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kashtan</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Milo</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Itzkovitz</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Alon</surname> <given-names>U</given-names></name>. <article-title>Coarse-graining and self-dissimilarity of complex networks</article-title>. <source>Phys Rev E</source>. <year>2005</year>;<volume>71</volume>(<issue>1</issue>):<fpage>016127</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevE.71.016127" xlink:type="simple">10.1103/PhysRevE.71.016127</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref012">
<label>12</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Gfeller</surname> <given-names>D</given-names></name>. <source>Simplifying complex networks: from a clustering to a coarse graining strategy</source>. <publisher-name>Swiss Federal Institute of Technology in Lausanne</publisher-name>; <year>2007</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gfeller</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>De Los Rios</surname> <given-names>P</given-names></name>. <article-title>Spectral coarse graining of complex networks</article-title>. <source>Phys Rev Lett</source>. <year>2007</year>;<volume>99</volume>:<fpage>038701</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevLett.99.038701" xlink:type="simple">10.1103/PhysRevLett.99.038701</ext-link></comment> <object-id pub-id-type="pmid">17678338</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref014">
<label>14</label>
<mixed-citation publication-type="other" xlink:type="simple">Bollobás B. In: Graph Theory and Combinatorics: Proceedings of the Cambridge Combinatorial Conference in Honour of Paul Erdös,[Trinity College, Cambridge, 21-25 March 1983]. Academic Press; 1984. p. 35.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Alvarez-Hamelin</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Dall’Asta</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Barrat</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Vespignani</surname> <given-names>A</given-names></name>. <article-title>K-Core Decomposition of Internet Graphs: Hierarchies, Self-Similarity and Measurement Biases</article-title>. <source>Netw Heterog Media</source>. <year>2008</year>;<volume>3</volume>(<issue>2</issue>):<fpage>371</fpage>–<lpage>393</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3934/nhm.2008.3.371" xlink:type="simple">10.3934/nhm.2008.3.371</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Girvan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Newman</surname> <given-names>ME</given-names></name>. <article-title>Community structure in social and biological networks</article-title>. <source>Proc Natl Acad Sci</source>. <year>2002</year>;<volume>99</volume>(<issue>12</issue>):<fpage>7821</fpage>–<lpage>7826</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.122653799" xlink:type="simple">10.1073/pnas.122653799</ext-link></comment> <object-id pub-id-type="pmid">12060727</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Reichardt</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bornholdt</surname> <given-names>S</given-names></name>. <article-title>Detecting fuzzy community structures in complex networks with a Potts model</article-title>. <source>Phys Rev Lett</source>. <year>2004</year>;<volume>93</volume>(<issue>21</issue>):<fpage>218701</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevLett.93.218701" xlink:type="simple">10.1103/PhysRevLett.93.218701</ext-link></comment> <object-id pub-id-type="pmid">15601068</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Donetti</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Munoz</surname> <given-names>MA</given-names></name>. <article-title>Detecting network communities: a new systematic and efficient algorithm</article-title>. <source>J Stat Mech: Theory Exp</source>. <year>2004</year>;<volume>2004</volume>(<issue>10</issue>):<fpage>P10012</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1088/1742-5468/2004/10/P10012" xlink:type="simple">10.1088/1742-5468/2004/10/P10012</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Palla</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Derényi</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Farkas</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Vicsek</surname> <given-names>T</given-names></name>. <article-title>Uncovering the overlapping community structure of complex networks in nature and society</article-title>. <source>Nature</source>. <year>2005</year>;<volume>435</volume>:<fpage>814</fpage>–<lpage>818</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature03607" xlink:type="simple">10.1038/nature03607</ext-link></comment> <object-id pub-id-type="pmid">15944704</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Newman</surname> <given-names>MEJ</given-names></name>. <article-title>Modularity and community structure in networks</article-title>. <source>Proc Natl Acad Sci</source>. <year>2006</year>;<volume>103</volume>(<issue>23</issue>):<fpage>8577</fpage>–<lpage>8582</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0601602103" xlink:type="simple">10.1073/pnas.0601602103</ext-link></comment> <object-id pub-id-type="pmid">16723398</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fortunato</surname> <given-names>S</given-names></name>. <article-title>Community detection in graphs</article-title>. <source>Phys Rep</source>. <year>2010</year>;<volume>486</volume>(<issue>3</issue>):<fpage>75</fpage>–<lpage>174</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.physrep.2009.11.002" xlink:type="simple">10.1016/j.physrep.2009.11.002</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref022">
<label>22</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Newman</surname> <given-names>MEJ</given-names></name>. <source>Networks: An Introduction</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>; <year>2010</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ullah</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Bruno</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Pearson</surname> <given-names>JE</given-names></name>. <article-title>Simplification of reversible Markov chains by removal of states with low equilibrium occupancy</article-title>. <source>J Theor Biol</source>. <year>2012</year>;<volume>311</volume>:<fpage>117</fpage>–<lpage>29</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kim</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Sontag</surname> <given-names>ED</given-names></name>. <article-title>Reduction of multiscale stochastic biochemical reaction networks using exact moment derivation</article-title>. <source>PLoS Comput Biol</source>. <year>2017</year>;<volume>13</volume>(<issue>6</issue>):<fpage>e1005571</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005571" xlink:type="simple">10.1371/journal.pcbi.1005571</ext-link></comment> <object-id pub-id-type="pmid">28582397</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zechner</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Koeppl</surname> <given-names>H</given-names></name>. <article-title>Uncoupled analysis of stochastic reaction networks in fluctuating environments</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>(<issue>12</issue>):<fpage>e1003942</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003942" xlink:type="simple">10.1371/journal.pcbi.1003942</ext-link></comment> <object-id pub-id-type="pmid">25473849</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref026">
<label>26</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Ermentrout</surname> <given-names>GB</given-names></name>, <name name-style="western"><surname>Terman</surname> <given-names>DH</given-names></name>. <source>Mathematical foundations of neuroscience</source>. <volume>vol. 35</volume>. <publisher-name>Springer Science &amp; Business Media</publisher-name>; <year>2010</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brejc</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>van Dijk</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Klaassen</surname> <given-names>RV</given-names></name>, <name name-style="western"><surname>Schuurmans</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>van Der Oost</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Smit</surname> <given-names>AB</given-names></name>, <etal>et al</etal>. <article-title>Crystal structure of an ACh-binding protein reveals the ligand-binding domain of nicotinic receptors</article-title>. <source>Nature</source>. <year>2001</year>;<volume>411</volume>(<issue>6835</issue>):<fpage>269</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/35077011" xlink:type="simple">10.1038/35077011</ext-link></comment> <object-id pub-id-type="pmid">11357122</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref028">
<label>28</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Purves</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Augustine</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Fitzpatrick</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Hall</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>LaMantia</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>McNamara</surname> <given-names>J</given-names></name>, <etal>et al</etal>., editors. <source>Neuroscience (6th Edition)</source>. <publisher-name>Sinauer Associates</publisher-name>; <year>2017</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hsiao</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Mihalak</surname> <given-names>KB</given-names></name>, <name name-style="western"><surname>Magleby</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Luetje</surname> <given-names>CW</given-names></name>. <article-title>Zinc potentiates neuronal nicotinic receptors by increasing burst duration</article-title>. <source>J Neurophysiol</source>. <year>2008</year>;<volume>99</volume>(<issue>2</issue>):<fpage>999</fpage>–<lpage>1007</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.01040.2007" xlink:type="simple">10.1152/jn.01040.2007</ext-link></comment> <object-id pub-id-type="pmid">18094103</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Colquhoun</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Hawkes</surname> <given-names>AG</given-names></name>. <article-title>On the stochastic properties of bursts of single ion channel openings and of clusters of bursts</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source>. <year>1982</year>;<volume>300</volume>(<issue>1098</issue>):<fpage>1</fpage>–<lpage>59</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rstb.1982.0156" xlink:type="simple">10.1098/rstb.1982.0156</ext-link></comment> <object-id pub-id-type="pmid">6131450</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Qin</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Auerbach</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sachs</surname> <given-names>F</given-names></name>. <article-title>Maximum likelihood estimation of aggregated Markov processes</article-title>. <source>Proc R Soc Lond B Biol Sci</source>. <year>1997</year>;<volume>264</volume>(<issue>1380</issue>):<fpage>375</fpage>–<lpage>383</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rspb.1997.0054" xlink:type="simple">10.1098/rspb.1997.0054</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stiles</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Kovyazina</surname> <given-names>IV</given-names></name>, <name name-style="western"><surname>Salpeter</surname> <given-names>EE</given-names></name>, <name name-style="western"><surname>Salpeter</surname> <given-names>MM</given-names></name>. <article-title>The temperature sensitivity of miniature endplate currents is mostly governed by channel gating: evidence from optimized recordings and Monte Carlo simulations</article-title>. <source>Biophys J</source>. <year>1999</year>;<volume>77</volume>(<issue>2</issue>):<fpage>1177</fpage>–<lpage>1187</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0006-3495(99)76969-9" xlink:type="simple">10.1016/S0006-3495(99)76969-9</ext-link></comment> <object-id pub-id-type="pmid">10423463</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bruno</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Pearson</surname> <given-names>JE</given-names></name>. <article-title>Using independent open-to-closed transitions to simplify aggregated Markov models of ion channel gating kinetics</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2005</year>;<volume>102</volume>(<issue>18</issue>):<fpage>6326</fpage>–<lpage>31</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0409110102" xlink:type="simple">10.1073/pnas.0409110102</ext-link></comment> <object-id pub-id-type="pmid">15843461</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref034">
<label>34</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Gardiner</surname> <given-names>CW</given-names></name>. <source>Stochastic methods: a handbook for the natural and social sciences</source>. <edition>4th ed</edition>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2009</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pezo</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Soudry</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Orio</surname> <given-names>P</given-names></name>. <article-title>Diffusion approximation-based simulation of stochastic ion channels: which method to use?</article-title> <source>Front Comput Neurosci</source>. <year>2014</year>;<volume>8</volume>:<fpage>139</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncom.2014.00139" xlink:type="simple">10.3389/fncom.2014.00139</ext-link></comment> <object-id pub-id-type="pmid">25404914</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Orio</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Soudry</surname> <given-names>D</given-names></name>. <article-title>Simple, fast and accurate implementation of the diffusion approximation algorithm for stochastic ion channels with multiple states</article-title>. <source>PLoS One</source>. <year>2012</year>;<volume>7</volume>(<issue>5</issue>):<fpage>e36670</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0036670" xlink:type="simple">10.1371/journal.pone.0036670</ext-link></comment> <object-id pub-id-type="pmid">22629320</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Puzerey</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Galán</surname> <given-names>RF</given-names></name>. <article-title>On how correlations between excitatory and inhibitory synaptic inputs maximize the information rate of neuronal firing</article-title>. <source>Front Comput Neurosci</source>. <year>2014</year>;<volume>8</volume>:<fpage>59</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncom.2014.00059" xlink:type="simple">10.3389/fncom.2014.00059</ext-link></comment> <object-id pub-id-type="pmid">24936182</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yu</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Dhingra</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Dick</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Galán</surname> <given-names>RF</given-names></name>. <article-title>Effects of ion channel noise on neural circuits: an application to the respiratory pattern generator to investigate breathing variability</article-title>. <source>J Neurophysiol</source>. <year>2016</year>;<volume>117</volume>(<issue>1</issue>):<fpage>230</fpage>–<lpage>242</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00416.2016" xlink:type="simple">10.1152/jn.00416.2016</ext-link></comment> <object-id pub-id-type="pmid">27760817</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Huisinga</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Meyn</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Schütte</surname> <given-names>C</given-names></name>. <article-title>Phase transitions and metastability in Markovian and molecular systems</article-title>. <source>Ann Appl Probab</source>. <year>2004</year>; p. <fpage>419</fpage>–<lpage>458</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref040">
<label>40</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Anderson</surname> <given-names>DF</given-names></name>, <name name-style="western"><surname>Kurtz</surname> <given-names>TG</given-names></name>. <chapter-title>Continuous time Markov chain models for chemical reaction networks</chapter-title>. In: <name name-style="western"><surname>Koeppl</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Densmore</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Setti</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>di</surname> <given-names>Bernardo M</given-names></name>, editors. <source>Design and Analysis of Biomolecular Circuits: Engineering Approaches to Systems and Synthetic Biology</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2011</year>. p. <fpage>1</fpage>–<lpage>44</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Anderson</surname> <given-names>DF</given-names></name>, <name name-style="western"><surname>Ermentrout</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>PJ</given-names></name>. <article-title>Stochastic representations of ion channel kinetics and exact stochastic simulation of neuronal dynamics</article-title>. <source>J Comput Neurosci</source>. <year>2015</year>;<volume>38</volume>(<issue>1</issue>):<fpage>67</fpage>–<lpage>82</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10827-014-0528-2" xlink:type="simple">10.1007/s10827-014-0528-2</ext-link></comment> <object-id pub-id-type="pmid">25408289</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref042">
<label>42</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Kurtz</surname> <given-names>TG</given-names></name>. <source>Approximation of population processes</source>. <volume>vol. 36</volume>. <publisher-name>SIAM</publisher-name>; <year>1981</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref043">
<label>43</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Meiss</surname> <given-names>JD</given-names></name>. <source>Differential Dynamical Systems</source>. <volume>vol. 14</volume>. <publisher-name>SIAM</publisher-name>; <year>2007</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lestas</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Paulsson</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ross</surname> <given-names>NE</given-names></name>, <name name-style="western"><surname>Vinnicombe</surname> <given-names>G</given-names></name>. <article-title>Noise in gene regulatory networks</article-title>. <source>IEEE Transactions on Automatic Control</source>. <year>2008</year>;<volume>53</volume>(<issue>Special Issue</issue>):<fpage>189</fpage>–<lpage>200</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TAC.2007.911347" xlink:type="simple">10.1109/TAC.2007.911347</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Paulsson</surname> <given-names>J</given-names></name>. <article-title>Summing up the noise in gene networks</article-title>. <source>Nature</source>. <year>2004</year>;<volume>427</volume>(<issue>6973</issue>):<fpage>415</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature02257" xlink:type="simple">10.1038/nature02257</ext-link></comment> <object-id pub-id-type="pmid">14749823</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Paulsson</surname> <given-names>J</given-names></name>. <article-title>Models of stochastic gene expression</article-title>. <source>Phys Life Rev</source>. <year>2005</year>;<volume>2</volume>(<issue>2</issue>):<fpage>157</fpage>–<lpage>175</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.plrev.2005.03.003" xlink:type="simple">10.1016/j.plrev.2005.03.003</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref047">
<label>47</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Risken</surname> <given-names>H</given-names></name>. <chapter-title>Fokker-planck equation</chapter-title>. In: <source>The Fokker-Planck Equation</source>. <publisher-name>Springer</publisher-name>; <year>1996</year>. p. <fpage>63</fpage>–<lpage>95</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Minas</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rand</surname> <given-names>DA</given-names></name>. <article-title>Long-time analytic approximation of large stochastic oscillators: Simulation, analysis and inference</article-title>. <source>PLoS Comput Biol</source>. <year>2017</year>;<volume>13</volume>(<issue>7</issue>):<fpage>e1005676</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005676" xlink:type="simple">10.1371/journal.pcbi.1005676</ext-link></comment> <object-id pub-id-type="pmid">28742083</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006206.ref049">
<label>49</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>McLean</surname> <given-names>WCH</given-names></name>. <source>Strongly elliptic systems and boundary integral equations</source>. <publisher-name>Cambridge University Press</publisher-name>; <year>2000</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006206.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gillespie</surname> <given-names>DT</given-names></name>. <article-title>Exact stochastic simulation of coupled chemical reactions</article-title>. <source>J Phys Chem</source>. <year>1977</year>;<volume>81</volume>:<fpage>2340</fpage>–<lpage>2361</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1021/j100540a008" xlink:type="simple">10.1021/j100540a008</ext-link></comment></mixed-citation>
</ref>
</ref-list>
</back>
</article>
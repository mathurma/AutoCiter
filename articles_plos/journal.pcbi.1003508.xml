<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-13-00384</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003508</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Dynamic Alignment Models for Neural Coding</article-title>
<alt-title alt-title-type="running-head">Dynamic Alignment Models for Neural Coding</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Kollmorgen</surname><given-names>Sepp</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Hahnloser</surname><given-names>Richard H. R.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
</contrib-group>
<aff id="aff1"><addr-line>Institute of Neuroinformatics, University of Zurich/ETH Zurich, Zurich, Switzerland</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Indiana University, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">skollmor@ini.phys.ethz.ch</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: SK RHRH. Analyzed the data: SK. Contributed reagents/materials/analysis tools: SK. Wrote the paper: SK RHRH.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>3</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>13</day><month>3</month><year>2014</year></pub-date>
<volume>10</volume>
<issue>3</issue>
<elocation-id>e1003508</elocation-id>
<history>
<date date-type="received"><day>3</day><month>3</month><year>2013</year></date>
<date date-type="accepted"><day>28</day><month>1</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Kollmorgen, Hahnloser</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Recently, there have been remarkable advances in modeling the relationships between the sensory environment, neuronal responses, and behavior. However, most models cannot encompass variable stimulus-response relationships such as varying response latencies and state or context dependence of the neural code. Here, we consider response modeling as a dynamic alignment problem and model stimulus and response jointly by a mixed pair hidden Markov model (MPH). In MPHs, multiple stimulus-response relationships (e.g., receptive fields) are represented by different states or groups of states in a Markov chain. Each stimulus-response relationship features temporal flexibility, allowing modeling of variable response latencies, including noisy ones. We derive algorithms for learning of MPH parameters and for inference of spike response probabilities. We show that some linear-nonlinear Poisson cascade (LNP) models are a special case of MPHs. We demonstrate the efficiency and usefulness of MPHs in simulations of both jittered and switching spike responses to white noise and natural stimuli. Furthermore, we apply MPHs to extracellular single and multi-unit data recorded in cortical brain areas of singing birds to showcase a novel method for estimating response lag distributions. MPHs allow simultaneous estimation of receptive fields, latency statistics, and hidden state dynamics and so can help to uncover complex stimulus response relationships that are subject to variable timing and involve diverse neural codes.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>The brain computes using electrical discharges of nerve cells, so called spikes. Specific sensory stimuli, for instance, tones, often lead to specific spiking patterns. The same is true for behavior: specific motor actions are generated by specific spiking patterns. The relationship between neural activity and stimuli or motor actions can be difficult to infer, because of dynamic dependencies and hidden nonlinearities. For instance, in a freely behaving animal a neuron could exhibit variable levels of sensory and motor involvements depending on the state of the animal and on current motor plans—a situation that cannot be accounted for by many existing models. Here we present a new type of model that is specifically designed to cope with such changing regularities. We outline the mathematical framework and show, through computer simulations and application to recorded neural data, how MPHs can advance our understanding of stimulus-response relationships.</p>
</abstract>
<funding-group><funding-statement>This work was funded by the Swiss National Science Foundation (grant 31003A_127024) and by the European Research Council under the European Community's Seventh Framework Programme (FP7/2007–2013/ERC Grant AdG 268911). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="19"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Neural response models are used to relate neural activity to sensory stimuli and motor behavior. A very common type of neural response model is comprised of a linear stage, at which one or more linear filters (often referred to as receptive fields) are applied to the stimulus, and a subsequent non-linear stage that converts the filter outputs into a spiking probability that feeds into a Poisson process generating the spikes <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>. More precisely, the spiking probability (i.e., the instantaneous rate of the Poisson process) of a neuron is modeled as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e001" xlink:type="simple"/></inline-formula>, where the column vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e002" xlink:type="simple"/></inline-formula> represents the stimulus, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e003" xlink:type="simple"/></inline-formula> the nonlinearity, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e004" xlink:type="simple"/></inline-formula> is a row vector containing the linear filter or a matrix in case of several filters. Variations of these linear-nonlinear Poisson cascade models (<italic>LNP models</italic>) have been studied extensively <xref ref-type="bibr" rid="pcbi.1003508-Sharpee1">[2]</xref>–<xref ref-type="bibr" rid="pcbi.1003508-Park1">[5]</xref>. Parameter estimation techniques range from spike triggered averaging in case of one linear filter and white noise stimuli, to spike triggered covariance <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Steveninck1">[6]</xref> in case of several linear filters, and maximally informative dimensions, in case of one or several linear filters and no restrictions on the distribution of stimuli <xref ref-type="bibr" rid="pcbi.1003508-Sharpee1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Paninski1">[4]</xref>. Although these techniques are effective in many domains, they fail in others, where the neural code might be more intricate (detailed below).</p>
<p>A crucial assumption about the relationship between stimulus and response inherent in these techniques is that the response latency of the cell, the filters (or receptive fields), and the non-linearity all are assumed to be the same throughout the experiment (<xref ref-type="fig" rid="pcbi-1003508-g001">Fig. 1A</xref>). This assumption of a <italic>fixed stimulus-response relationship</italic> is, however, not necessarily valid. On the one hand, the relationship between stimulus and response, the neural code, could vary in time (<xref ref-type="fig" rid="pcbi-1003508-g001">Fig. 1C</xref>). On the other hand, the response latency could be noisy or vary systematically (<xref ref-type="fig" rid="pcbi-1003508-g001">Fig. 1A</xref>).</p>
<fig id="pcbi-1003508-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003508.g001</object-id><label>Figure 1</label><caption>
<title>Varying response latencies and context dependent neural coding.</title>
<p>(A) <italic>Varying latencies</italic>. Sequence of 8 dimensional white noise stimuli (e.g. successive frames on a one dimensional screen with 8 pixels). An LNP model generates spikes (black bars) if a chunk of stimulus (dashed rectangles) is similar enough to its receptive field (dashed rectangles). Jitter-free or ideal spikes (vertical black bars, ‘ideal spiking’) are produced with some fixed latency (dashed diagonal lines). Jittered spikes (black bars, ‘observed spiking’) are produced by randomly jittering ideal spikes (gray bars) forward or backward in time (green arrows). The jitter of adjacent spikes can be independent or correlated. The jittered spikes are the basis for fitting neural response models. (B) Receptive field (RF) estimates using spike triggered stimulus averaging (STA) on unjittered spikes (true RF), jittered spikes (STA), and the MPH on jittered spikes (MPH). Noisy response latencies lead to blurring of STA RFs, but not of MPH RFs. (C) <italic>State-dependent coding</italic>. For the same white noise stimulus, spikes are generated from one of two LNP models depending on hidden states I and II (green lines) determining which model is used. (D) The true RFs are superimposed when estimated with STA. A two-states MPH can faithfully recover the two RFs.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003508.g001" position="float" xlink:type="simple"/></fig>
<p>The extent to which a <italic>fixed stimulus-response relationship</italic> applies to neurophysiological data is unclear. In terms of spike timing, a fixed relationship entails both constant response latency and an amount of spike-time-jitter that is smaller than the relevant temporal structure of the receptive field. However, noisy response latencies (<xref ref-type="fig" rid="pcbi-1003508-g001">Fig. 1A</xref>) are observed in almost all electrophysiological studies because neural systems are intrinsically noisy. Variations in response latency to a repeated stimulus (measured as the standard deviation of time of first spike after stimulus onset) in the range of 3–5 ms have been reported already at a very low stage of the visual system, in retinal ganglion cells <xref ref-type="bibr" rid="pcbi.1003508-Gollisch1">[7]</xref>. Variability in response latency can be notably larger in cortical areas. For instance, variations in first-spike latency (again measured as the standard deviation) of up to 12.5 ms have been observed in single cells in ferret primary visual cortex in response to flashed natural images <xref ref-type="bibr" rid="pcbi.1003508-Tolhurst1">[8]</xref>. Furthermore, systematically varying response latencies have been demonstrated in various model systems, e.g., image contrast modulates response latency both in retinal ganglion cells <xref ref-type="bibr" rid="pcbi.1003508-Levick1">[9]</xref> and in visual cortical neurons <xref ref-type="bibr" rid="pcbi.1003508-Gawne1">[10]</xref>–<xref ref-type="bibr" rid="pcbi.1003508-Gawne2">[12]</xref>, fueling discussions about the role of spike latency in neural coding <xref ref-type="bibr" rid="pcbi.1003508-Gawne2">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Oram1">[13]</xref>. In a recent study, latencies of cells in macaque inferotemporal cortex were found to systematically differ for primate and non-primate face stimuli, with latency differences on the order of tens of milliseconds <xref ref-type="bibr" rid="pcbi.1003508-Kiani1">[14]</xref>.</p>
<p>When latencies are strongly fluctuating or spike time-jitter is large, many modeling techniques that assume a <italic>fixed stimulus-response relationship</italic>, such as spike triggered averaging, yield suboptimal results <xref ref-type="bibr" rid="pcbi.1003508-Dimitrov1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Gollisch2">[16]</xref>: The estimated receptive fields are blurred and the accuracy of predicted responses to novel stimuli is low (<xref ref-type="fig" rid="pcbi-1003508-g001">Fig. 1B</xref>).</p>
<p><italic>Fixed stimulus-response relationships</italic> can also be violated in case of changes in intrinsic or hidden brain states <xref ref-type="bibr" rid="pcbi.1003508-Buonomano1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Destexhe1">[18]</xref>. For example, neurons in the primary somatosensory cortex of the rat undergo up and down states given by two separate membrane potentials. Spiking responses to whisker deflections in these cells are dependent on whether neurons are in the up or the down state: in the down state, a reliable response is observed, whereas in the up state activity is largely stimulus independent <xref ref-type="bibr" rid="pcbi.1003508-Sachdev1">[19]</xref>. Stimulus context can also induce changes in internal states. For instance, in an awake marmoset study of single-unit responses in the auditory cortex to sequences of 2 sound stimuli, responses to the second stimulus were not static but depended strongly on the first stimulus. This modulation in second-stimulus responses can last longer than 1.5 seconds <xref ref-type="bibr" rid="pcbi.1003508-Bartlett1">[20]</xref>. We illustrate dependence of neural computation on intrinsic states in a cartoon (<xref ref-type="fig" rid="pcbi-1003508-g001">Fig. 1C</xref>) in which the simulated neuron switches between 2 static receptive fields. Response switching has also been observed in the amphibian retina. Ganglion-cell activity is typically dominated by OFF responses. However, a large peripheral image shift (as occurs during head saccades) can induce a switch (for a few hundred milliseconds) from transmitting OFF signals to transmitting ON signals <xref ref-type="bibr" rid="pcbi.1003508-Geffen1">[21]</xref>. One of the most compelling examples of response switching has been observed in songbirds: many neurons in cortical motor and auditory areas are responsive to playback of sound stimuli except when birds are singing, at which times responses are locked to the song but not influenced by sound playback <xref ref-type="bibr" rid="pcbi.1003508-Keller1">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Schmidt1">[23]</xref>. Hence, if such neural responses were to be modeled across singing and non-singing states, anything but a two-state model would be inadequate. Indeed, many classical models fail in cases of response switching: the estimated classical receptive fields contain superimposed structures derived from the switched responses, which yields sub-optimal results (<xref ref-type="fig" rid="pcbi-1003508-g001">Fig. 1D</xref>).</p>
<p>To address variable response latencies and dynamic neural codes we consider the problem of neural response modeling as an alignment problem. We introduce mixed pair hidden Markov models (MPHs) as novel neural response models allowing for dynamic alignment of stimulus and response without <italic>fixed stimulus-response assumptions</italic>. In the case of varying spike latencies (e.g. when a neuron fires in response to a particular stimulus but with a variable latency or lag, <xref ref-type="fig" rid="pcbi-1003508-g001">Fig. 1A, B</xref>), MPHs help to detect corresponding stimulus-response parts by associating individual spikes with particular stimulus time points; and, they help to uncover stimulus-response relationships including the spike-jitter statistics and the receptive field of the neuron. In case of switching dynamics (e.g., when a neuron switches between being responsive to either one stimulus or another depending on the behavioral state of the animal or a cueing stimulus, <xref ref-type="fig" rid="pcbi-1003508-g001">Fig. 1C</xref>), MPHs help to identify parameters such as the receptive-field switching probabilities and the switching events. Our MPH approach to dynamic alignment combines response switching (<italic>context dependency</italic>) and spike-time jitter or systematically varying latencies (<italic>flexible timing</italic>) in one unified framework. We show how to use stimuli and neural responses to jointly estimate all model parameters including spike time jitter, systematically varying latencies, and switching probabilities. We demonstrate the benefits of dynamic alignment on simulated data and on extracellular data recorded in cortical brain areas of singing birds.</p>
</sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Mixed Pair Hidden Markov Models</title>
<p>We solve the alignment problem by jointly modeling stimulus and response by a mixed pair hidden Markov model (MPH), which is a generative model for both the stimulus and neural response. In MPHs, different neural codes, i.e. different relationships between neural activity and sensory input, can coexist as different states or groups of states in a Markov chain. MPHs are unlike classical hidden Markov models because they dynamically operate on pairs of sequences - neural activity and stimulus - instead of single sequences (i.e. a joint sequence of neural activity and stimulus). For a mathematically detailed introduction to MPHs (and an introduction to HMMs), see the <xref ref-type="sec" rid="s4">Materials and Methods</xref> section.</p>
<p>We explain the workings of MPHs in intuitive terms by considering first the special case of jittered spike times (<xref ref-type="fig" rid="pcbi-1003508-g001">Fig. 1A</xref>). We assume spikes are associated with the stimulus (i.e. a time window of the stimulus <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>) that precede the spikes by an average time lag <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e005" xlink:type="simple"/></inline-formula>. Instead of associating spikes and stimuli at a constant lag <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e006" xlink:type="simple"/></inline-formula> (such as is the case for standard spike triggered methods including STA, STC, maximally informative dimensions, etc..), MPHs associate an individual spike with a stimulus at the individual lag <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e007" xlink:type="simple"/></inline-formula> (in units of stimulus-response bins, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e008" xlink:type="simple"/></inline-formula> being an integer, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e009" xlink:type="simple"/></inline-formula> can be different for each spike). MPHs achieve this flexibility via three different types of hidden states and by keeping track of the momentary lag <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e010" xlink:type="simple"/></inline-formula> and its evolution. First, <italic>matching states (M-states)</italic> associate a spike with a stimulus at the current lag <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e011" xlink:type="simple"/></inline-formula> by modeling the joint probability distribution of spike and stimulus (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2A</xref>, middle). The simplest case are Gaussian stimulus models comprising two Gaussians, one of which models stimuli jointly occurring with spikes and the other models stimuli not occurring with spikes (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2A</xref>, middle). A model with only a single such M-state is bound to a fixed lag <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e012" xlink:type="simple"/></inline-formula> and is equivalent to an LNP model (under appropriate parameter constraints, see also the section on LNP equivalence below). To achieve a variable lag, we introduce two more types of states: X-states (X stands for the stimulus sequence) and R-states (R stands for response sequence). These states can change the momentary lag <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e013" xlink:type="simple"/></inline-formula> as follows. An X-state models the stimulus (but not the response) via some probability distribution, for instance a Gaussian (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2A</xref>, left). The X-state changes the current lag from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e014" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e015" xlink:type="simple"/></inline-formula>. Analogously, an R-state models only the spiking response (but not the stimulus) via a discrete probability distribution (e.g. spike or no-spike, <xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2A</xref>, right). An R-state changes the current lag from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e016" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e017" xlink:type="simple"/></inline-formula>. An MPH consisting of an M, X, and R state can thus model a spike-stimulus pair via the M state or via the X and the R state. In general fewer states are preferred as there is a cost associated with switching from one state to another. Thus, an MPH will try to keep the lag between stimulus and spike constant unless there is evidence for changing the lag via X and R states.</p>
<fig id="pcbi-1003508-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003508.g002</object-id><label>Figure 2</label><caption>
<title>Two minimal MPHs for flexible timing and context dependent coding.</title>
<p>(A) Architecture of the minimal MPH that allows for neural codes with varying latencies, i.e. flexible timing. This MPH has 3 hidden states, one X-state that models only the stimulus, one R-state that models only the neural response, and one M-state that jointly models stimulus and response. The probability distributions over stimuli (bottom) are illustrated as low dimensional projections (stimulus dimension 2 coincides with the receptive field of the M-state). (B) Hidden state sequences in that model correspond to paths in the alignment matrix: a diagonal step leading into position <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e018" xlink:type="simple"/></inline-formula> implies that stimulus and response at times <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e019" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e020" xlink:type="simple"/></inline-formula> are jointly modeled by an M-state, a horizontal step implies modeling of only the stimulus at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e021" xlink:type="simple"/></inline-formula>, and a vertical step implies modeling of only the response at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e022" xlink:type="simple"/></inline-formula> (deviations from the diagonal reflect jittered spikes detected by the model). Depicted stimulus and spiking responses are from <xref ref-type="fig" rid="pcbi-1003508-g001">figure 1A</xref>. (C) The minimal MPH for modeling state-dependent neural codes. The MPH can switch between several M-states, each of which represents a different RF. The (projected) stimulus distributions given a spike (spike triggered stimulus ensemble) are centered on the respective RFs (indicated by black arrows). (D) Adding states to the model turns the alignment matrix into an alignment tensor composed of several planes (strictly speaking, B depicts a tensor as well; we just projected all the states onto one plane). The switch from state 1 to State 2 is indicated (green arrow).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003508.g002" position="float" xlink:type="simple"/></fig>
<p>Intuitively, one can think of an MPH as a finite state automaton that processes symbols from two sequences at the same time, the stimulus (X-sequence) and the response sequence (R-sequence). Under this analogy, M-states process one symbol of each sequence (they match a symbol pair from X and R), X-states process only a stimulus symbol, and R-states process only a response-symbol. The automaton keeps track of two pointers that indicate the current position in the stimulus sequence as well as the current position in the response sequence. The pointer difference corresponds to the current lag dT+e (the “automaton” considers all possible lags, weighted probabilistically).</p>
<p>A sequence of hidden states in an MXR-MPH (M, X, and R states) can be depicted as a path in an alignment matrix that spans all possible pairings between stimulus and response (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2B</xref>): An M-State corresponds to diagonal movement along the matrix from position <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e023" xlink:type="simple"/></inline-formula>, i.e. position <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e024" xlink:type="simple"/></inline-formula> in the stimulus sequence and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e025" xlink:type="simple"/></inline-formula> in the response sequence, to position <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e026" xlink:type="simple"/></inline-formula>. An X-State corresponds to horizontal movement from position <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e027" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e028" xlink:type="simple"/></inline-formula> and an R-State corresponds to vertical movement from position <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e029" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e030" xlink:type="simple"/></inline-formula>. A change in the temporal relationship between stimulus and response (i.e. spike jitter) is reflected in non-diagonal (horizontal or vertical) steps in the alignment matrix (with step size provided by the discretization of stimulus and neural response sequences, <xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2B</xref>). This 3-state model will be applied to simulated and real data in the next section.</p>
<p>In order to handle state-dependent (switching) neural responses (<xref ref-type="fig" rid="pcbi-1003508-g001">Fig. 1C</xref>), we consider MPHs with several M-states (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2C</xref>). Multiple M states add another dimension to the alignment matrix, which we henceforth call alignment tensor (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2D</xref>). The simplest switching-enabling MPH has two M-states but no X or R states. Each M-state is associated with a particular receptive field to be estimated (here we use ‘receptive field’ in the most general way, independent of linearity and related assumptions). With several M states, spikes can be associated to stimuli via one of several joint probability distributions over spike and stimulus. Probabilistic transitions between M states allow the MPH to switch between receptive fields, which is shown on simulated and real data below.</p>
<p>The general MPH has several M-, X-, and R-States and thus simultaneously permits flexible timing and context dependency. The parameters defining probabilistic transitions into and out of hidden states are:</p>
<list list-type="simple"><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e031" xlink:type="simple"/></inline-formula>: Transition probability of transiting from hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e032" xlink:type="simple"/></inline-formula> to hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e033" xlink:type="simple"/></inline-formula>,</p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e034" xlink:type="simple"/></inline-formula>: Initial probability of hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e035" xlink:type="simple"/></inline-formula>,</p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e036" xlink:type="simple"/></inline-formula>: Final probability of hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e037" xlink:type="simple"/></inline-formula>.</p>
</list-item></list>
<p>The parameters defining emission probabilities are:</p>
<list list-type="simple"><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e038" xlink:type="simple"/></inline-formula>: Emission probability density of the stimulus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e039" xlink:type="simple"/></inline-formula> given hidden X-state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e040" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e041" xlink:type="simple"/></inline-formula> is a vector and typically spans a window of the stimulus around time <italic>t</italic>),</p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e042" xlink:type="simple"/></inline-formula>: Discrete emission probability distribution of the response <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e043" xlink:type="simple"/></inline-formula> given hidden R-state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e044" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e045" xlink:type="simple"/></inline-formula> is part of a discrete set, e.g. {0, 1} for spike or no spike),</p>
</list-item><list-item>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e046" xlink:type="simple"/></inline-formula>: Mixed discrete-continuous emission probability of stimulus-response pair <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e047" xlink:type="simple"/></inline-formula> given hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e048" xlink:type="simple"/></inline-formula></p>
</list-item></list>
<p>As emission probability densities associated with X and M states we use multivariate Gaussians or mixtures of Gaussians, respectively. For hidden X-state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e049" xlink:type="simple"/></inline-formula> we write the emission probability density as<disp-formula id="pcbi.1003508.e050"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e050" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e051" xlink:type="simple"/></inline-formula> is the weight of the <italic>k</italic><sup>th</sup> mixture component, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e052" xlink:type="simple"/></inline-formula> denotes the total number of mixture components (which may vary for different hidden states, i.e. some <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e053" xlink:type="simple"/></inline-formula> can be zero), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e054" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e055" xlink:type="simple"/></inline-formula> denote the Gaussian mean and covariance matrix of the <italic>k</italic><sup>th</sup> mixture component. For M states we keep track of one such multivariate Gaussian for each response state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e056" xlink:type="simple"/></inline-formula> (each response state is associated with a distinct stimulus emission).</p>
</sec><sec id="s2b">
<title>Special Cases of MPHs</title>
<p>In the following we present detailed analyses of the spike-jitter and response-switching MPH architectures. First, we discuss an MPH with only one M-state (<italic>M-MPH</italic>) and multivariate Gaussian stimulus models. We show that, under appropriate parameter constraints, such a model is equivalent to a 1-dimensional LNP model and describe its relation to linear regression and linear discriminant analysis and the resulting strengths and limitations. Second, we discuss an extension of that M-MPH to a model that also possesses an X- and an R-state (<italic>MXR-MPH</italic>). We illustrate in simulations how this model can account for spike time jitter and varying latencies on white noise and on natural stimuli. Third, we treat an extension of the M-MPH to multiple M-states (<italic>M<sup>n</sup>-MPH</italic>) and illustrate through simulations how this model can account for switching dynamics and context dependency. All of these models can be cascaded with an additional non-linearity so that they form NNP cascades (as opposed to LNP cascades). In the chapter that then follows, we apply these models to data recorded from single units of cells in the behaving bird.</p>
<sec id="s2b1">
<title>The M-MPH with multivariate Gaussian stimulus models and equal covariances</title>
<p>An MPH characterized by one M-state, multivariate Gaussian stimulus models with shared covariance matrix, and no X and R states is equivalent to an LNP model. In the following we calculate both the linear filter and the LNP non-linearity. Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e057" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e058" xlink:type="simple"/></inline-formula> be the parameters of an MPH with one M-state and Gaussian stimulus models, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e059" xlink:type="simple"/></inline-formula> are the mean and the covariance matrix of the stimulus given no spike is emitted and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e060" xlink:type="simple"/></inline-formula> are the mean and the covariance matrix of the stimulus given emission of a spike. In this section, we assume identical covariance matrices: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e061" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e062" xlink:type="simple"/></inline-formula> are the marginal (or prior) probabilities of a spike and no spike and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e063" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e064" xlink:type="simple"/></inline-formula> denotes the stimulus sequence and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e065" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e066" xlink:type="simple"/></inline-formula> the response sequence. In the examples to follow, stimulus and response have the same length, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e067" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e068" xlink:type="simple"/></inline-formula> can be useful too, for instance, when stimulus and spiking response are differently binned).</p>
<p>In this simple MPH the posterior probability of a spike at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e069" xlink:type="simple"/></inline-formula> is given by<disp-formula id="pcbi.1003508.e070"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e070" xlink:type="simple"/><label>(1)</label></disp-formula></p>
<p>By using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e071" xlink:type="simple"/></inline-formula> and rearranging terms, we can transform <xref ref-type="disp-formula" rid="pcbi.1003508.e070">Eq. 1</xref> to<disp-formula id="pcbi.1003508.e072"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e072" xlink:type="simple"/><label>(2)</label></disp-formula></p>
<p>By taking the logarithm on both sides of <xref ref-type="disp-formula" rid="pcbi.1003508.e072">Eq. 2</xref> we find<disp-formula id="pcbi.1003508.e073"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e073" xlink:type="simple"/><label>(3)</label></disp-formula></p>
<p>Hence, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e074" xlink:type="simple"/></inline-formula> is affine-linear in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e075" xlink:type="simple"/></inline-formula>. Equivalence between this simple MPH and linear non-linear neural response models follows after applying the sigmoid function, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e076" xlink:type="simple"/></inline-formula>, on both sides of (3) and assuming <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e077" xlink:type="simple"/></inline-formula>, which yields<disp-formula id="pcbi.1003508.e078"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e078" xlink:type="simple"/><label>(4)</label></disp-formula>where the constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e079" xlink:type="simple"/></inline-formula> is given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e080" xlink:type="simple"/></inline-formula>. Hence, the posterior spike probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e081" xlink:type="simple"/></inline-formula> for this MPH agrees with that of an LNP model with linear filter (or receptive field) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e082" xlink:type="simple"/></inline-formula> and non-linearity<disp-formula id="pcbi.1003508.e083"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e083" xlink:type="simple"/><label>(5)</label></disp-formula></p>
<p>For non-white stimuli, i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e084" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e085" xlink:type="simple"/></inline-formula> the identity matrix, the receptive field <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e086" xlink:type="simple"/></inline-formula> of the MPH is given by<disp-formula id="pcbi.1003508.e087"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e087" xlink:type="simple"/><label>(6)</label></disp-formula>which is known as reverse correlation, corrected spike triggered average <xref ref-type="bibr" rid="pcbi.1003508-Kouh1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Sen1">[25]</xref>, or simply as linear regression. Moreover, for white stimuli, i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e088" xlink:type="simple"/></inline-formula> the receptive field <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e089" xlink:type="simple"/></inline-formula> of the MPH is the spike triggered average (STA) - the mean of the spike triggered ensemble. Hence, the M-MPH performs a linear regression cascaded with a sigmoid non-linearity and is equivalent to a one dimensional LNP model with a sigmoid non-linearity (<xref ref-type="disp-formula" rid="pcbi.1003508.e083">Eq. 5</xref>).</p>
<p>Note that the M-MPH's receptive field (<xref ref-type="disp-formula" rid="pcbi.1003508.e087">Eq. 6</xref>) always corresponds to the linear regression solution. Consequently, the M-MPH's receptive field estimate is optimal whenever linear regression is the correct model. In particular, it follows that the MPH parameter estimates can be optimal even when the spike triggered ensemble and its complement are non-Gaussian – for instance in case of white noise stimuli and a threshold non-linearity <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Hastie1">[26]</xref>. The same is true when the overall stimulus distribution is non Gaussian – for instance for non-Gaussian natural stimuli and a linear “non-linearity” <xref ref-type="bibr" rid="pcbi.1003508-Hastie1">[26]</xref>. However, although the receptive field estimate does not depend on Gaussian assumptions, the non-linearity (<xref ref-type="disp-formula" rid="pcbi.1003508.e083">Eq. 5</xref>) does, see e.g. <xref ref-type="bibr" rid="pcbi.1003508-Hastie1">[26]</xref>. In <xref ref-type="bibr" rid="pcbi.1003508-Hastie1">[26]</xref>, the authors suggest to re-estimate the non-linearity (decision boundary) of a linear discriminant model to obtain a non-linearity estimate not corrupted by Gaussian assumptions.</p>
<p>Inspired by <xref ref-type="bibr" rid="pcbi.1003508-Hastie1">[26]</xref>, we cascade the MPH with an additional non-linearity that can be estimated from the data subsequent to the estimation of the MPH (compare <xref ref-type="sec" rid="s4">Materials and Methods</xref> for details of the estimation). Such cascading is standard practice for neural response models <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Theis1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Pillow1">[28]</xref> and is also part of LNP models. The cascaded M-MPH with shared covariance can fit any one-dimensional LNP model on white-noise data (provided that the operation of the LNP model leads to a change of mean of the spike triggered ensemble, which is the case for all monotone non-linearities and for most others) <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>. However, for non-white data and certain nonlinearities, the linear regression estimate can be biased <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Sharpee1">[2]</xref>, so that MPHs too will infer an incorrect receptive field (see also below, where we apply MPHs to natural stimuli). In these cases, using Gaussian mixtures as stimulus models might be advisable (see <xref ref-type="sec" rid="s3">discussion</xref>).</p>
</sec><sec id="s2b2">
<title>M-MPH with free covariance matrices and Gaussian mixture models</title>
<p>One interesting extension of that simple MPH results from assuming <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e090" xlink:type="simple"/></inline-formula>. This case is analogous to quadratic discriminant analysis <xref ref-type="bibr" rid="pcbi.1003508-Hastie1">[26]</xref>. The MPH implements a model quadratic in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e091" xlink:type="simple"/></inline-formula>. One further extension is to use mixtures of Gaussians as emission distributions instead of individual Gaussians (see <xref ref-type="sec" rid="s3">discussion</xref>), in which case <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e092" xlink:type="simple"/></inline-formula> is generally not quadratic anymore.</p>
</sec></sec><sec id="s2c">
<title>The MXR-MPH and Its Application to Simulated Data with Spike-Time-Jitter</title>
<p>In the following we demonstrate the ability of MXR-MPHs (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2A</xref>) to recover the correct receptive field (RF) on simulated data with noisy latencies, i.e. spike-time-jitter. When predicting spiking probabilities on novel data, the MXR-MPH outperforms purely spike-triggered methods.</p>
<p>For the MXR-MPH, we denote the stimulus means and covariance matrices in the M-State by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e093" xlink:type="simple"/></inline-formula> (non-spiking) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e094" xlink:type="simple"/></inline-formula>(spiking) and in the in the X-State by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e095" xlink:type="simple"/></inline-formula>. In accordance with the section on LNP equivalence and to simplify this general MPH, we introduce the following parameter constraints: First, we fix all covariance matrices to identity matrices: <disp-formula id="pcbi.1003508.e096"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e096" xlink:type="simple"/></disp-formula></p>
<p>Second, we fix the means <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e097" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e098" xlink:type="simple"/></inline-formula> to zero (equal to the mean of the stimulus ensemble). Third, we do not allow the R-state to generate spikes (zero spike emission probability) because we require that each spike is matched to a stimulus (note that if we allowed the R-state to generate spikes, the model would distinguish between spikes generated by the M-state and spikes generated by the R-state — such distinction could be used for distinguishing stimulus driven from spontaneous activity, which was not our focus). Given these parameter constraints, the remaining free parameters in the model are the receptive field <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e099" xlink:type="simple"/></inline-formula> (the mean of the spike triggered stimulus ensemble, <xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2C</xref>), and the transition probabilities among X, R, and M-state. After training the MPH, the jitter statistics are implicit in the model's parameters; below we show how to explicitly compute the jitter statistics for natural stimuli.</p>
<sec id="s2c1">
<title>Application to white data</title>
<p>To test the model, we first created artificial data by sampling spike trains from an LNP model in response to a white noise stimulus consisting of 10<sup>5</sup> time bins (arbitrary timescale), and 42 dimensions or stimulus channels (e.g. pixels on a one dimensional screen or frequency bands in a spectrogram). We split the stimulus into 500 sequences of equal duration and generated 25 trials of LNP spiking responses for each of those sequences (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3A</xref>). The LNP model was composed of one linear filter that spanned 11 time bins (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3C</xref>) and a sigmoid nonlinearity (red line in <xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3G</xref>). We generated a total of 28702 LNP spikes (∼0.015 spikes/bin). We randomly jittered the individual LNP spikes (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3A</xref>) with i.i.d. spike shifts drawn from a discretized log-normal distribution with zero mean (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3B</xref>). The variance of that distribution controls the total amount of jitter: As variance increases, the distribution becomes more asymmetric with a heavy right-side tail (we choose such an asymmetric jitter distribution to increase the difficulty of the problem). To 450 of the 500 stimulus-response sequences we fitted both an MXR-MPH and a reverse correlation model (resulting filters are depicted in <xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3C</xref>). The remaining 50 sequences served as validation set.</p>
<fig id="pcbi-1003508-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003508.g003</object-id><label>Figure 3</label><caption>
<title>The MXR-MPH applied to white noise stimuli and spike-time-jitter.</title>
<p>(A) A white noise stimulus (top) with spiking responses (black bars) generated by an LNP-type model neuron (LNP output, the LNP RF size is indicated by the black rectangle). The jittered versions (jittered) of the LNP spike trains with corresponding firing rate (thick gray line) are shown below. The MPH estimate of firing rate (black full line) is more accurate than the STA estimate (dashed line). (B) Applied spike jitter is i.i.d. among spikes and log-normally distributed with zero mean (3 different jitter distributions are shown; they differ in terms of variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e100" xlink:type="simple"/></inline-formula> and symmetric/asymmetric shape). Results for the jitter kernel with variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e101" xlink:type="simple"/></inline-formula> are shown in panels A, C and D. (C) RFs estimated through STA on unjittered spikes (true RF), STA on jittered spikes (STA), and MPH on jittered spikes (MPH). The STA RF is blurred whereas the MPH RF closely resembles the true RF. Dotted black lines indicate the midpoints of the RFs. (D) Projections of all stimuli (gray lines) and the spike triggered stimulus ensembles (black lines) onto the underlying (true) RF for the unjittered spikes (left), the jittered spikes (middle), and the MPH reconstruction (right, obtained via dynamic alignment using the generalized Viterbi algorithm). (E) <italic>Response prediction</italic>. To evaluate the models we computed correlation coefficients (CCs) between predicted and actual firing rates on the validation set and for different jitter variances. For small spike jitter, performances of STA and MPH are comparable. As the jitter magnitude increases, STA performance drops much more severely than does MPH performance. Also shown is an upper bound for the CC computed by sampling and cross-correlating jittered responses. (F) MPH robustness to jitter is demonstrated also when assessed as similarity between the estimated RF and the true RF (similarity computed as normalized scalar product, i.e. cosine of angle between RFs). (G) We assessed the influence of different non-linearities (labeled A–E, ordered by steepness) on prediction quality for both the MPH as well as the cascaded MPH (cMPH). (H) Shallow non-linearities decrease the upper bound of prediction quality (black line) as well as the MPH (red lines) and STA (green line) performance for the unjittered (left) and the jittered case (right). The cascaded MPH (red line) shows slight improvements over the non-cascaded one (dotted red line).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003508.g003" position="float" xlink:type="simple"/></fig>
<p>The STA, which is the optimal solution in case of jitter-free data, yielded a poor approximation of the true receptive field (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3C</xref>). The main problem for STA was that the (jittered) spike-triggered stimulus ensemble did not separate well from its complement (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3D</xref>, middle) when projected onto the underlying (true) RF. In contrast, the receptive field <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e102" xlink:type="simple"/></inline-formula> estimated using the MXR-MPH (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3C</xref>) was very close to the true RF, and the reconstructed spike-triggered ensemble (computed by aligning stimulus and response through the generalized Viterbi algorithm, see <xref ref-type="sec" rid="s4">Materials and Methods</xref>) was well separated from the full stimulus ensemble (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3D</xref>, right). We ran the spiking-probability inference algorithm outlined in <xref ref-type="sec" rid="s4">Materials and Methods</xref> on the independent validation set. The MPH-predicted spike responses were in general much better than STA-predicted responses (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3E</xref>, instead of using correlation coefficients, we could have evaluated performance through the average likelihood of the models given the data; we opted for CCs to ensure easy interpretability and connect to existing literature). For small jitter, MPH and STA responses were equally good; however, with increasing jitter, the MXR-MPH performance dropped much less than that of STA. Similar superiority of the MXR-MPH was also seen in RF estimation, evaluated in terms of the angle between estimated and true RFs (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3F</xref>, to discount for arbitrary shifts in RF position that could be induced by the asymmetric jitter kernels we also designed a shift-invariant measure by time-shifting the estimated RF relative to the true RF and considering only the minimal angles; this gave virtually identical results).</p>
<p>We elucidate the influence of various non-linearities, by having evaluated MPHs and STA-models for various sigmoidal non-linearities of the (true) LNP model (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3G</xref>, the non-linearities were chosen such that the resulting models each yield an average rate of about 0.015 spikes/bin). We found that RF estimation and response prediction of the MPH was the better the steeper the non-linearities (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3H</xref>). Furthermore, the difference between cascaded and non-cascaded MPH is not large (<xref ref-type="fig" rid="pcbi-1003508-g003">Fig. 3H</xref>). The improved performance for steep nonlinearities is to be expected because the non-linearity is needed to separate the action of the linear filter from the action of the jitter kernel in the underlying LNP model (i.e. without non-linearity the linear kernel of the LNP model and the jitter kernel simply act as two subsequent linear operations which no longer can be uniquely disentangled).</p>
</sec><sec id="s2c2">
<title>Application to natural stimuli</title>
<p>We also tested the MXR-MPH on jittered responses to natural stimuli (a problem that, to our knowledge, has not yet been addressed in the literature). We sampled spike trains from an LNP model in response to spectrograms of birdsongs (<xref ref-type="fig" rid="pcbi-1003508-g004">Fig. 4A</xref>). We used 250 zebra finch songs (50 of the songs served as a validation set), yielding a total of 66025 time bins (4 ms each) and 20332 generated spikes (mean rate/bin ∼0.012).</p>
<fig id="pcbi-1003508-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003508.g004</object-id><label>Figure 4</label><caption>
<title>The MPH applied to natural stimuli and jittered spike responses.</title>
<p>(A) An example log-spectrogram of zebra finch song (top, high sound amplitudes in red and low amplitudes in blue), spiking responses generated by an LNP-type model (middle, LNP output), their jittered versions (below), and the corresponding jittered firing rate (bottom, gray line). The MPH-predicted response (MPH, full line) of the jittered firing rate is more accurate than the reverse correlation prediction (RC, dashed line). (B) Applied spike jitter is i.i.d. among spikes and log-normally distributed with zero mean. Two different jitter distributions are shown, they differ in terms of variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e103" xlink:type="simple"/></inline-formula> and symmetric/asymmetric shape (gray curves <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e104" xlink:type="simple"/></inline-formula> left, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e105" xlink:type="simple"/></inline-formula> right). The MPH-estimated jitter kernels are shown in black. The MPH misses some jittered spikes (right), as revealed by the excessive peak at zero time lag. Results for the jitter kernel with variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e106" xlink:type="simple"/></inline-formula> are shown in panels A, C, and D. (C) RFs estimated through reverse correlation for unjittered data (true RF), jittered data (RC) as well as the MPH receptive field estimate (MPH). The STA RF is blurred whereas the MPH RF closely resembles the true RF. Dotted black lines indicate the midpoints of the RFs. (D) Projections of all stimuli (gray lines) and the spike triggered stimulus ensembles (black lines) onto the underlying (true) RF for the unjittered spikes (left), the jittered spikes (middle), as well the MPH reconstruction (right, obtained via dynamic alignment using the generalized Viterbi algorithm). (E) Correlation coefficients (CCs) between predicted and true firing rates on the validation set for different jitter variances. Also shown is an upper bound for the CC computed by sampling and cross-correlating jittered responses. For small overall jitter, performances of reverse correlation and MPH are comparable. As the overall jitter magnitude increases, reverse correlation performance drops much more severely than does MPH performance. (F) RC performance drops even stronger when assessed in terms of similarity between the estimated and the true RFs.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003508.g004" position="float" xlink:type="simple"/></fig>
<p>We fixed the model covariance matrices to the covariance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e107" xlink:type="simple"/></inline-formula> of the stimulus ensemble:<disp-formula id="pcbi.1003508.e108"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e108" xlink:type="simple"/></disp-formula></p>
<p>Furthermore, we fixed the means <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e109" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e110" xlink:type="simple"/></inline-formula> to the actual stimulus mean. As for white noise stimuli, the MPH performed better than reverse correlation on RF estimation and response prediction (<xref ref-type="fig" rid="pcbi-1003508-g004">Fig. 4E, 4F</xref>).</p>
<p>We computed the jitter statistics via the alignment kernel of the MXR-MPH (the alignment kernel is a weighted average of spike shift counts associated with each possible hidden state sequence (i.e. each path in the alignment tensor, <xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2B</xref>) where the weights correspond to the respective probabilities of the hidden state sequences given model and data, see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). Our simulations showed that the model did not over-fit the data by detecting jitter when none was present (<xref ref-type="fig" rid="pcbi-1003508-g004">Fig. 4B</xref>, left) and that the alignment kernel could be estimated quite well even when jitter was large (<xref ref-type="fig" rid="pcbi-1003508-g004">Fig. 4B</xref>, right).</p>
<p>The MPH allows for stimulus-response modeling both for correlated and uncorrelated jitter: Correlated jitter can be accounted for by decreasing the transition probabilities onto X and R-states, which in turn decreases the probability of non-diagonal movement in the alignment tensor (thus leading to correlated stimulus-response lags across successive spikes). To model uncorrelated jitter, the transition probabilities can be chosen such that the likelihood of a chunk of the stimulus-response pair being modeled with only X- and R-states equals the likelihood of modeling it with M-states only. In that case, constant time lags and changing time lags between successive spikes are equally likely and jitter is uncorrelated (provided that successive spikes are further apart than the jitter size).</p>
</sec></sec><sec id="s2d">
<title>The M<sup>2</sup>-MPH and Its Application to Simulated Data with Switching Dynamics</title>
<p>MPHs with several M states support <italic>context dependency</italic>. They can model multiple stimulus-response relationships associated, for instance, with distinct behavioral states of an animal. To demonstrate this flexibility of MPHs, we simulated a neuron that randomly switches (according to a Markov process with equal probabilities) between two linear-nonlinear models (each defined as in the previous section), i.e., neural responses were governed by a hidden state sequence that determined which receptive field was active at any given time (<xref ref-type="fig" rid="pcbi-1003508-g005">Fig. 5A</xref>). We generated responses of this artificial neuron to 100 white noise sequences, each spanning 1000 time bins (arbitrary timescale), and 21 dimensions or stimulus channels. For each sequence, spike responses were generated using the switching LNP model, resulting in a total of 4374 spikes on average (mean 0.044 spikes/bin). We generated and tested data for different RF combinations, characterized by different rotations in the plane of one of the RFs (<xref ref-type="fig" rid="pcbi-1003508-g005">Fig. 5B</xref>, left). To uncover the hidden switching dynamics and the two RFs, we trained a Gaussian M<sup>2</sup>-MPH with two M-states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e111" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e112" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2C</xref>). Gaussian parameters were constrained in the following way: First, we imposed zero means: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e113" xlink:type="simple"/></inline-formula>; and second, we fixed all covariance matrices to the identity matrix. The remaining free parameters of the model were the means <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e115" xlink:type="simple"/></inline-formula> of the spike-triggered ensembles (i.e., the receptive fields) and the transition probabilities between the two states (which reflect the switching statistics).</p>
<fig id="pcbi-1003508-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003508.g005</object-id><label>Figure 5</label><caption>
<title>The MPH applied to white noise stimuli and switched responses.</title>
<p>(A) A white noise stimulus (top), the randomly switched states of a switching LNP model (middle, black curve), and the observed spike train (middle, black rasters) and firing rate (bottom, gray line). The MPH-predicted firing rate (bottom, black line) to a test stimulus is closer to the observed firing rate than is the STA prediction (blue line) or the STC prediction (dotted green line). (B) The MPH RF estimates (MPH, 2<sup>nd</sup> column) capture well the underlying true RFs (True RFs, 1<sup>st</sup> column) for all relative angles, unlike the STA RF estimates (STA, 3<sup>rd</sup> column) or the STC RF estimates (STC, 4<sup>th</sup> column). (C) We evaluated the models by computing CCs between predicted and observed firing rates on a validation set and for different pairs of LNP filters that were generated by rotating one of the RFs. The cascaded MPH (black line) performs slightly better than the non-cascaded MPH (gray line). Both MPHs perform better than STC (green line) and STA (blue line). (D) Quality of RF reconstruction, shown is the cosine angle between true and model RFs (compare main text). The MPH reconstructed the true RFs more faithfully (black line) than did STA (blue line) and STC (green line). The occasional drops in MPH performance (larger error bars) are due to local optima that can be circumvented by starting the MPH-parameter optimization from different initial conditions (the orange line is from the best model – in terms of likelihood on the training set – out of 3 initial conditions). Both, panels (C) and (D) show average results from 10 simulations (with standard errors indicated).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003508.g005" position="float" xlink:type="simple"/></fig>
<p>We compared the MPH with STA and STC <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Steveninck1">[6]</xref> models. For all three models, we computed RF estimates and the response prediction performance. The trained MPH faithfully recovered both RFs, whereas the (single) RF estimated of STA consisted of a superposition of the two RFs, and the RFs estimated using STC were severely corrupted by noise in most cases (<xref ref-type="fig" rid="pcbi-1003508-g005">Fig. 5B</xref>). As a result, the MPH predicted responses better on an independent validation set than did STA and STC (<xref ref-type="fig" rid="pcbi-1003508-g005">Fig. 5C</xref>, averaged over 10 runs). We assessed the quality of the recovered RFs of all three methods and all 37 tested rotations by matching each original RF to the recovered RF with smallest distance and by averaging the two distances. The MPH recovers the RF much better then STA or STC (<xref ref-type="fig" rid="pcbi-1003508-g005">Fig. 5D</xref>, average over 10 runs; drops in MPH-reconstruction quality are due to local minima, compare figure text).</p>
<p>The degraded performance of the STC model has two reasons. First, the covariance of the spike triggered ensemble needs to be reliably estimated (with quadratically many degrees of freedom as there are stimulus dimensions compared to a linear number of degrees of freedom for the M<sup>2</sup>-MPH). Second, the linear filters uncovered by STC are orthogonal <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>, whereas the M<sup>2</sup>-MPH is not constrained in this way.</p>
<p>It is possible to show that the M<sup>2</sup>-MPH firing rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e116" xlink:type="simple"/></inline-formula> to a stimulus is given by<disp-formula id="pcbi.1003508.e117"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e117" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e118" xlink:type="simple"/></inline-formula> are two non-linearities and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e119" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e120" xlink:type="simple"/></inline-formula> are the prior probabilities of hidden states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e121" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e122" xlink:type="simple"/></inline-formula>, respectively. The STA model, on the other hand, is bound to model firing rates as<disp-formula id="pcbi.1003508.e123"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e123" xlink:type="simple"/></disp-formula></p>
<p>An extreme example that illustrates the failure of RF estimation with STAs is a neural response model that pools over two filters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e124" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e125" xlink:type="simple"/></inline-formula>. In that case the estimated RF using STA is uniform and has no predictive power at all, unlike the MPH (e.g. <xref ref-type="fig" rid="pcbi-1003508-g005">Fig. 5C</xref>, rotation angle 180°). A less extreme but potentially more relevant case is that of complex cells in primary visual cortex with overlapping excitatory and inhibitory oriented receptive subfields (such cells are often modeled by pooling over four oriented filters that are phase shifted <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e126" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e127" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e128" xlink:type="simple"/></inline-formula>, respectively <xref ref-type="bibr" rid="pcbi.1003508-Movshon1">[29]</xref>–<xref ref-type="bibr" rid="pcbi.1003508-Touryan1">[31]</xref>). A switching M<sup>4</sup>-MPH with four M-states can recover these phase shifted filters, whereas STA yields only a blurred RF.</p>
</sec><sec id="s2e">
<title>Application to Songbird Spike Data</title>
<p>To demonstrate that MPHs work well in practice even when the amount of available data is small and the true spike generating process is unknown, we apply the MXR- and the M<sup>n</sup>-MPH to extracellular spike data recorded in the forebrain nucleus interface of the nidopallium (NIf) of songbirds (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6A</xref>). NIf is a higher-order song-control nucleus; lesion and inactivation studies have shown that NIf exhibits both sensory and motor functions <xref ref-type="bibr" rid="pcbi.1003508-Naie1">[32]</xref>–<xref ref-type="bibr" rid="pcbi.1003508-Okanoya1">[35]</xref>. Multi-unit NIf activity is generally strongest shortly before and during syllable production and weakest during the times corresponding to silent intervals between syllables <xref ref-type="bibr" rid="pcbi.1003508-Lewandowski1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-McCasland1">[37]</xref>. These findings suggest a pre-vocal role of NIf spikes during song, prompting us to expect in singing birds a negative latency of NIf spikes relative to song (spikes precede sounds, as opposed to a positive latency that would result if NIf firing was sensory during vocal production). Due to the difficulty of recording in singing animals, available spike trains are relatively short (the average total spike train duration was 73 s per cell) and contain few spikes (∼1500 spikes per cell).</p>
<fig id="pcbi-1003508-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003508.g006</object-id><label>Figure 6</label><caption>
<title>The MXR- and M<sup>n</sup>-MPH applied to single-unit activity in NIF of a singing zebra finch.</title>
<p>(A) Raw extracellular voltage trace time-aligned to a log-power sound spectrogram of a zebra finch song (high sound amplitudes in red and low amplitudes in blue). (B) The MXR-MPH's RF estimate (left, high and low sound amplitudes in red and blue respectively). The red blob at about +30 ms is an indication that this cell is premotor. The width of the window is ∼0.25 s. The MXR-MPH's alignment kernel (right) is concentrated near −10 ms, yielding a total lead of NIf spikes on song of about 40 ms. (C) The RF estimated with reverse correlation (left) is similar to the MXR-MPH's RF. Middle: RF and jitter kernel of an MXR-MPH with much narrower RF window (about 10 ms wide). The total dimension of the RF is 605 (5 columns times 121 rows). Because the RF is so narrow, the spike latency is now clearly reflected in the alignment kernel (right), centered around a negative alignment shift of about 40 ms, implying that the model aligns spikes to portions of the song that occur about 40 ms after the spike. Hence, the alignment kernel strongly suggests a premotor function of this cell. (D) Predictions (5-fold cross validation) of the MXR-MPH (left, red bar) are similar to reverse correlation (blue bar). Using the non cascaded version (green bar) yields a slight drop in performance. An M<sup>n</sup>-MPH yields a modest improvement in prediction performance (right, peaking at 8 states) in both the cascaded (cMPH) and non-cascaded forms (MPH, error bars depict 95% confidence intervals). (E) Results for a different data set (a different cell producing 1659 spikes during about 54 s of song data containing about 60 song motifs). The RF estimated using RC reveals diffuse spectrotemporal tuning, making it nearly impossible to decide whether this cell is sensory or motor in function. By contrast, the MPH alignment kernel (right) quite clearly reveals a motor function in this cell, evidenced by the predominance of negative alignment shifts. Also, the MPH RF shows a rather narrow frequency tuning near 2.6 kHz (middle). (F) The MXR-MPH firing-rate predictions for this cell were comparable to reverse correlation predictions; M<sup>n</sup>-MPHs again yield a modest improvement in prediction performance.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003508.g006" position="float" xlink:type="simple"/></fig>
<p>To investigate latencies of NIf single-unit spikes relative to song, we first fitted an LNP model using reverse correlation (RC, <xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6C</xref>, left). To overcome problems of over-fitting (due to the limited amount of data available) we used a regularized version of the stimulus covariance matrix:<disp-formula id="pcbi.1003508.e129"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e129" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e130" xlink:type="simple"/></inline-formula> denotes the number of stimulus dimensions, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e131" xlink:type="simple"/></inline-formula> denotes the unregularized stimulus covariance matrix and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e132" xlink:type="simple"/></inline-formula> denotes its normalized trace (such regularization yielded better generalization performance). Next, we trained a <italic>MXR-MPH</italic> on large 0.25 s song spectrogram windows (with covariance matrices in M and X states fixed to the regularized stimulus covariance matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e133" xlink:type="simple"/></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1003508.e129">Eq. 7</xref>). The MPH RF was similar to the reverse correlation RF (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6B</xref>), but it reflected more clearly that the cell fired before sounds and not thereafter (consider for example the stronger inhibitory band near 10 ms). MPH and reverse correlation encoding performances on a test set were comparable (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6D</xref>, left data points). Note that by construction, differences between MXR-MPH and reverse correlation RFs arise from spike-time-jitter.</p>
<p>To characterize response latencies (and jitter) we estimated probability distributions of the temporal offset <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e134" xlink:type="simple"/></inline-formula> between stimulus and response in M-states via the <italic>alignment kernel</italic> (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6B</xref>, left). Negative lags in the alignment kernel imply that spikes occur before corresponding events in the stimulus, whereas positive lags imply that spikes occur thereafter. The alignment kernel was centered at a small negative time lag and exhibited a small temporal spread, revealing high temporal precision of NIf spike trains. Predicted responses (5-fold cross validation) for the reverse correlation model and the MXR-MPH were equally good (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6D</xref>, left data points), confirming high temporal precision of NIf spike trains.</p>
<p>The MPH allowed us to strongly reduce model complexity by shrinking linear filters (RF sizes) down to less than 30 ms. For such short RFs, the cell latency is reflected entirely in the alignment kernel. Based on the RF estimate in <xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6B and 6C</xref>, we expected the jitter kernel to be centered near −30 to −40 ms. Indeed, the kernel peaked near −40 ms (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6C</xref>, right), implying that the MPH aligned spikes to portions of the stimulus occuring about 40 ms after the spike, suggesting a premotor function of this cell and thus agreeing with the hypothesized premotor function of NIf.</p>
<p>Additionally we trained an M<sup>n</sup>-MPH with various numbers of states on the same NIf cell (unlike for the M<sup>2</sup>-MPH applied in the section on switching dynamics we did not constrain the means). The M<sup>n</sup>-MPH showed modest improvements over reverse correlation, its peak validation CC occurred at 8 states (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6D</xref>), suggesting that this NIf cell fires prior to several distinct song features.</p>
<p>We also analyzed data for another recording site in NIf, composed of 54 s of singing with concurrent spiking (1659 spikes, about 60 stereotyped song motifs). The RF estimated using reverse correlation (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig 6E</xref>, left) revealed diffuse spectrotemporal tuning, making it difficult to decide whether this cell is sensory or motor in function. By contrast, the MPH alignment kernel (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6E</xref>, right) quite clearly revealed a motor function in this cell, evidenced by the predominance of negative alignment shifts. The MPH RF showed a rather narrow frequency tuning near 2,6 kHz (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6E</xref>, middle). Encoding performance for the MXR-MPH with large RF was again similar to reverse correlation (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6H</xref>, left data points), yet an M<sup>n</sup>-MPH yielded slightly superior performance (<xref ref-type="fig" rid="pcbi-1003508-g006">Fig. 6H</xref>, right data points).</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>We introduced a novel technique for neural response modeling and receptive field estimation that overcomes limitations of fixed stimulus-response relationships. We proposed to view neural coding as an alignment problem that can be tackled by mixed pair hidden Markov models (MPHs), which jointly model stimulus and response and can naturally account for noisy or systematically varying latencies as well as for context dependent neural codes that depend on internal (hidden) states. Discrete pair HMMs have been used in the context of gene alignment to find corresponding parts in related gene sequences <xref ref-type="bibr" rid="pcbi.1003508-Durbin1">[38]</xref>. To our knowledge they have not yet been applied to response modeling.</p>
<p>We demonstrated that simple MPHs with Gaussian stimulus models and a fixed shared covariance matrix are equivalent to one dimensional LNP models with sigmoid non-linearity and we extended these basic MPHs to allow flexible timing and context dependency. Thereby MPHs endow standard RF estimation techniques such as spike triggered averaging (STA) and reverse correlation with <italic>flexible timing</italic> and <italic>context dependency</italic>. We tested our approach on simulated and real data and demonstrated the benefits of alignment in terms of improved predictability of simulated and real neural responses, improved receptive field estimates as well as the capability of estimating jitter latency statistics and switching states.</p>
<p>Key properties of MPHs are: 1) X- and R-states that model stimulus or response alone and allow for <italic>flexible timing</italic> via dynamic temporal alignment, and 2) M-states that allow for <italic>context dependency</italic> via model switching. Using our estimation techniques, these three types of states can be freely combined in a highly flexible approach to neural coding and decoding without the need to develop additional algorithms.</p>
<p>We derived MPH parameters estimation updates for Gaussian mixture models with unrestricted covariance matrices (<xref ref-type="sec" rid="s4">Materials and Methods</xref>). The (non-mixture) Gaussian MPHs we studied performed well in simulations (including natural stimuli), even though the assumption of Gaussian stimulus models can be violated by natural stimuli <xref ref-type="bibr" rid="pcbi.1003508-Kouh1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Singh1">[39]</xref>. In these cases, mixtures of Gaussians can be useful to approximate arbitrary stimulus distributions and overcome problems of receptive field biases <xref ref-type="bibr" rid="pcbi.1003508-Theis1">[27]</xref>. Beyond mixtures of Gaussians, EM update equations for other mixture families are known as well <xref ref-type="bibr" rid="pcbi.1003508-Rabiner1">[40]</xref> and could be adapted to MPHs.</p>
<p>Other modeling approaches have been pursued to estimate neural responses in the presence of spike time jitter <xref ref-type="bibr" rid="pcbi.1003508-Dimitrov1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Gollisch2">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Aldworth1">[41]</xref>. One approach is to simultaneously estimate the jitter distribution and the RF using the EM algorithm <xref ref-type="bibr" rid="pcbi.1003508-Gollisch2">[16]</xref>. This technique has been successfully applied to white noise stimuli (identity covariance) <xref ref-type="bibr" rid="pcbi.1003508-Gollisch2">[16]</xref>, but not to stimuli with non-identity covariance, i.e. natural stimuli. Furthermore, in <xref ref-type="bibr" rid="pcbi.1003508-Gollisch2">[16]</xref> the jitter of adjacent spikes is assumed to be independent – an assumption that might be violated in cases where jitter depends on slowly varying internal states or is correlated for other reasons. The dynamic alignment technique we present here generalizes these approaches in two ways. First, in MPHs there is no need to constrain the stimulus covariance matrix, so that natural stimuli can be readily processed. Second, MPHs can account for correlated as well as uncorrelated jitter among adjacent or nearby spikes and thus allow modeling of both systematically and slowly varying spike latencies. Furthermore, in <xref ref-type="bibr" rid="pcbi.1003508-Gollisch2">[16]</xref> the jitter distribution is explicitly assumed to be of Gaussian form whereas the jitter distribution of the MPH is implicit in the transition probabilities and has degrees of freedom commensurate with the number of hidden states and their transitions.</p>
<p>The ability of MPHs to emulate switching models is particularly useful given that switching dynamics are important in many neural systems. A number of other approaches have been introduced to handle response switching and context dependency. Several of them are based on hidden Markov models <xref ref-type="bibr" rid="pcbi.1003508-Gat1">[42]</xref>–<xref ref-type="bibr" rid="pcbi.1003508-Dan1">[48]</xref>. The hidden states in these models typically reflect neural activity but not the stimulus. Models with hidden states that reflect both stimulus and response, such as switching Kalman filters <xref ref-type="bibr" rid="pcbi.1003508-Ghahramani1">[49]</xref> or generalized linear models with hidden states <xref ref-type="bibr" rid="pcbi.1003508-Wu1">[50]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Lawhern1">[51]</xref>, have also been proposed. These models are similar to MPHs with only M-states but no X- and R-states. Furthermore, our approach extends these models in that stimulus-response relationships within each hidden state can be quadratic (single Gaussians, unconstrained covariance matrices) or formed by Gaussian mixtures. Another way of modeling context dependencies are “multi-linear” models encompassing a multiplicative context term (by itself modeled through a “multi-linear” model) that depends on the projection of the stimulus (in some time window) onto a set of basis functions <xref ref-type="bibr" rid="pcbi.1003508-Ahrens1">[52]</xref>. MPHs complement such approaches by allowing more complex types of contextual influence via the underlying Markov structure. This is also an advantage over techniques like spike triggered covariance that can recover multiple filters <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Steveninck1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Rust1">[53]</xref>–<xref ref-type="bibr" rid="pcbi.1003508-Eickenberg1">[55]</xref> but cannot attribute Markovian dynamics to the individual filters. For instance, MPHs allow for context effects over very long time scales, context effects depending on hidden neural states such as up and down states (in this case MPHs also allow to infer the up and down states, for instance through the generalized Viterbi algorithm), and left-to-right HMMs <xref ref-type="bibr" rid="pcbi.1003508-Rabiner1">[40]</xref> can incorporate behavioral context in stereotyped motor actions such as birdsong.</p>
<p>MPHs can bridge between data analysis and theories of neural function. Some theories of cortical function assume discrete modules of computation and representation <xref ref-type="bibr" rid="pcbi.1003508-Bienenstock1">[56]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Ikegaya1">[57]</xref>, for example synfire chains <xref ref-type="bibr" rid="pcbi.1003508-Weber1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Abeles2">[58]</xref> or, more generally, cell assemblies. In these theories, the role of neural activity does not only depend on the identity of the neuron but also on the (hidden) identity of modules the neuron belongs to at a certain time.</p>
<p>The MPHs we developed to align stimulus and neural response are based on stimuli represented with continuous probability densities and neural activity represented with discrete probabilities. It is noteworthy that both fully continuous pair HMMs that align two continuous sequences and fully discrete pair HMMs also have interesting applications. For instance, we have shown previously that a fully continuous pair HMM can be used to align the songs of a juvenile bird to the song of the bird's tutor in order to identify the parts of the song that were copied and the locations where insertions were made <xref ref-type="bibr" rid="pcbi.1003508-Blaettler1">[59]</xref>. We have also demonstrated how fully discrete pair HMMs can be used to align spike trains <xref ref-type="bibr" rid="pcbi.1003508-Blaettler1">[59]</xref>: by learning a discrete pair HMM on pairs of related spike trains, we obtained a “distance” measure between spike-trains, thereby generalizing state of the art spike train metrics <xref ref-type="bibr" rid="pcbi.1003508-Victor1">[60]</xref>.</p>
<p>MPHs are useful for both neural encoding and decoding. We presented algorithms for inferring neural responses and their probabilities given the stimulus (encoding). However, by symmetry of MPHs, the inference algorithms we designed can in principle be “inverted” to estimate the stimulus given neural activity (decoding) so that decoding and encoding of brain activity essentially have become the same problem.</p>
<p>MPHs are based on classical hidden Markov models and learning and inference algorithms other than the EM algorithm are readily available. For instance, for model parameter estimation we could have used (much faster) Viterbi training <xref ref-type="bibr" rid="pcbi.1003508-Durbin1">[38]</xref> or we could have optimized criteria other than data likelihood <xref ref-type="bibr" rid="pcbi.1003508-Ephraim1">[61]</xref>. Also, there exists a large variety of very powerful analytical and computational tools developed for classical hidden Markov models that can be adapted to MPHs <xref ref-type="bibr" rid="pcbi.1003508-Ephraim1">[61]</xref>–<xref ref-type="bibr" rid="pcbi.1003508-Stolcke1">[63]</xref>.</p>
<p>We will make a code package for fitting MPHs available through our website (<ext-link ext-link-type="uri" xlink:href="http://www.ini.ch/~skollmor" xlink:type="simple">www.ini.ch/~skollmor</ext-link>).</p>
</sec><sec id="s4" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Ethics Statement</title>
<p>All experiments were carried out in accordance with protocols approved by the Veterinary Office of the Canton of Zurich, Switzerland.</p>
</sec><sec id="s4b">
<title>Short Introduction to Hidden Markov Models</title>
<p>We provide a short introduction to “normal” hidden Markov models and the associated terminology for readers unfamiliar with them.</p>
<p>Consider two dies at a game of chance, one with equal probabilities for its six faces (fair die) and the other with unequal probabilities (loaded die). Suppose that their holders can exchange dies for one another without you knowing. Suppose furthermore that these die switches occur randomly. All you observe is the sequence of faces without knowing whether the fair or loaded die is in place: the identity of the die is hidden from you. Hidden Markov models (HMMs) account for exactly these kinds of situations involving hidden variables. In the die example we can use an HMM with two states, <italic>L</italic> (loaded) and <italic>F</italic> (fair), for the two dies. At any point in time the HMM is in one of the two <italic>states</italic> corresponding to the die that is in use. Associated with each of the two states are the probabilities for the different faces to come up. These <italic>emission probabilities</italic> are unknown and can be learned from observations (the distribution is uniform for the fair die and non-uniform for the loaded one). Transitions between states (dies) are governed by unknown <italic>transitions probabilities</italic> that model how likely the die holders switch dies at any time. For two states, transitions are modeled by an unknown 2 by 2 <italic>transition matrix</italic> that can also be learned from observations.</p>
<p>An HMM can produce observations by randomly choosing transitions (die switches) and <italic>observations</italic> or <italic>emissions</italic> (faces that come up) which results in an <italic>observation sequence</italic> and an underlying <italic>hidden state sequence</italic>. However, HMMs are so useful because they can be applied in reverse: given an observation sequence, we can estimate good parameters (emission and transition probabilities) for the underlying HMM as well as the underlying hidden state sequence, which we never directly observed.</p>
<p>In a classical HMM (applied to stimulus-response modeling) the time lag between the stimulus and the response is fixed and together stimulus and response probabilistically depend on some hidden (non-observed) variable with Markov dynamics.</p>
<p>In an MPH, spike and stimuli also probabilistically depend on some hidden variable, but rather than being paired at a fixed time lag, spike and stimulus pairing is dynamic, governed by a probabilistic process. Note that MPHs are different from factorial hidden Markov models which employ a distributed state representation but model a single (possibly multidimensional) observation sequence <xref ref-type="bibr" rid="pcbi.1003508-Ghahramani2">[64]</xref>.</p>
</sec><sec id="s4c">
<title>Formal Definition of the MPH</title>
<p>In the following, we present a precise definition of the MPH architecture and its learning and inference algorithms.</p>
<p>We denote the stimulus sequence by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e135" xlink:type="simple"/></inline-formula> and the spiking response by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e136" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e137" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e138" xlink:type="simple"/></inline-formula> are their respective durations (typically <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e139" xlink:type="simple"/></inline-formula>). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e140" xlink:type="simple"/></inline-formula> are real vectors (e.g. sound spectrograms) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e141" xlink:type="simple"/></inline-formula> are integers (e.g., number of spikes, typically <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e142" xlink:type="simple"/></inline-formula> in small time bins with zero or one spike). We denote a position in the combined stimulus-response alignment matrix as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e143" xlink:type="simple"/></inline-formula>, <xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2c</xref>. The model has three types of hidden states: X-states, which model only the stimulus, R-States which model only the response, and M-States which jointly model stimulus and response (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2c</xref>). We denote the sets of these states by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e144" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e145" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e146" xlink:type="simple"/></inline-formula>. Additionally we define the union of states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e147" xlink:type="simple"/></inline-formula>. We denote sequences of hidden states by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e148" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e149" xlink:type="simple"/></inline-formula> and use the notation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e150" xlink:type="simple"/></inline-formula> to refer to the hidden state occupied at sequence position <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e151" xlink:type="simple"/></inline-formula>. Note that in general <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e152" xlink:type="simple"/></inline-formula> because all of stimulus, response, and hidden state sequences may be of different length. The parameters of the MPH are defined in the following.</p>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e153" xlink:type="simple"/></inline-formula>: Matrix of transition probabilities. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e154" xlink:type="simple"/></inline-formula> denotes the probability of transiting from hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e155" xlink:type="simple"/></inline-formula> to hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e156" xlink:type="simple"/></inline-formula></p>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e157" xlink:type="simple"/></inline-formula>: Initial probability of hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e158" xlink:type="simple"/></inline-formula></p>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e159" xlink:type="simple"/></inline-formula>: Final probability of hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e160" xlink:type="simple"/></inline-formula></p>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e161" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e162" xlink:type="simple"/></inline-formula>: Emission probability density of the stimulus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e163" xlink:type="simple"/></inline-formula> given hidden X-state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e164" xlink:type="simple"/></inline-formula></p>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e165" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e166" xlink:type="simple"/></inline-formula>: Discrete emission probability distribution of the response <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e167" xlink:type="simple"/></inline-formula> given hidden R-state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e168" xlink:type="simple"/></inline-formula></p>
<p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e169" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e170" xlink:type="simple"/></inline-formula>: Mixed discrete-continuous emission probability of stimulus-response pair <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e171" xlink:type="simple"/></inline-formula> given hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e172" xlink:type="simple"/></inline-formula></p>
<p>As emission probability densities associated with X and M states we use multivariate Gaussians or mixtures of Gaussians, respectively:<disp-formula id="pcbi.1003508.e173"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e173" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e174" xlink:type="simple"/></inline-formula> is the weight of the <italic>k</italic><sup>th</sup> mixture component, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e175" xlink:type="simple"/></inline-formula> denotes the total number of mixture components (which may vary for different hidden states but this freedom is not reflected in our notation), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e176" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e177" xlink:type="simple"/></inline-formula> denote Gaussian mean and covariance matrix of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e178" xlink:type="simple"/></inline-formula>th mixture component. For M states we keep track of one such density for each possible value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e179" xlink:type="simple"/></inline-formula> (distinct stimulus emission for each spiking state).</p>
<p>In the following, we define algorithms for inference in MPHs. Some of them are generalizations of well-known algorithms for normal HMMs. To infer the spiking response for a given stimulus, we derive new algorithms. In the following we denote conditional probabilities of the form <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e180" xlink:type="simple"/></inline-formula> simply by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e181" xlink:type="simple"/></inline-formula>, i.e., for readability we will omit the dependence on model parameters.</p>
</sec><sec id="s4d">
<title>Generalized Viterbi Algorithm</title>
<p>Assume that we have trained MPH model parameters on some data and now would like to apply the MPH to novel stimulus-response pairs. In a switching model (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2e</xref>), we would like to estimate the most likely hidden state sequence given the data to identify the switching events. In a flexible timing model (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2b</xref>) we would like to determine the optimal alignment between stimulus and response to estimate the jitter of individual spikes. In that latter case, the alignment consists of temporal offsets between stimulus and response on a moment-to-moment basis.</p>
<p>The generalized Viterbi algorithm for MPHs can be applied in both situations to efficiently compute the most likely hidden state sequence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e182" xlink:type="simple"/></inline-formula> for a given stimulus-response sequence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e183" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003508.e184"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e184" xlink:type="simple"/></disp-formula></p>
<p>We apply an extension of the Viterbi algorithm for classical HMMs <xref ref-type="bibr" rid="pcbi.1003508-Durbin1">[38]</xref>. First, let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e185" xlink:type="simple"/></inline-formula> be the probability of the most likely sequence that models the stimulus up to (and including) time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e186" xlink:type="simple"/></inline-formula>, the response up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e187" xlink:type="simple"/></inline-formula>, and that ends in hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e188" xlink:type="simple"/></inline-formula>. Additionally, for any state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e189" xlink:type="simple"/></inline-formula> and sequence position <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e190" xlink:type="simple"/></inline-formula>, we keep track of the most likely precursor state in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e191" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e192" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e193" xlink:type="simple"/></inline-formula> can be computed recursively (<xref ref-type="table" rid="pcbi-1003508-t001">Table 1</xref>).</p>
<table-wrap id="pcbi-1003508-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003508.t001</object-id><label>Table 1</label><caption>
<title>The generalized Viterbi algorithm.</title>
</caption><alternatives><graphic id="pcbi-1003508-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003508.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Initialization:</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e194" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Recursion:</bold></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e195" xlink:type="simple"/></inline-formula>:</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e196" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e197" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e198" xlink:type="simple"/></inline-formula>:</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e199" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e200" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e201" xlink:type="simple"/></inline-formula>:</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e202" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e203" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Termination:</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e204" xlink:type="simple"/></inline-formula></td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p>A good way to visualize the generalized Viterbi algorithm is to think of it as filling up an <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e205" xlink:type="simple"/></inline-formula> alignment tensor (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2f</xref>). The final state of the most likely hidden state sequence is then given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e206" xlink:type="simple"/></inline-formula> and the complete state sequence can be obtained by iteratively back-tracking the most likely precursor states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e207" xlink:type="simple"/></inline-formula></p>
</sec><sec id="s4e">
<title>Generalized Forward Algorithm</title>
<p>In many cases, we are interested in computing statistics over all possible sequences. For instance, to compute the probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e208" xlink:type="simple"/></inline-formula> of generating a sequence pair <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e209" xlink:type="simple"/></inline-formula> given a particular MPH (for example to compare different MPHs), we need to consider the overall probability of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e210" xlink:type="simple"/></inline-formula> independent of the alignment. Hence we have to consider all possible hidden state sequences and not just the one with maximal likelihood. First, let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e211" xlink:type="simple"/></inline-formula> be the probability of observing the stimulus up to (and including) time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e212" xlink:type="simple"/></inline-formula>, the response up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e213" xlink:type="simple"/></inline-formula>, and of ending in hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e214" xlink:type="simple"/></inline-formula>. The computation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e215" xlink:type="simple"/></inline-formula> is very similar to the computation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e216" xlink:type="simple"/></inline-formula>, except that the max operation is replaced with a summation (to take all hidden state sequences into account, <xref ref-type="table" rid="pcbi-1003508-t002">Table 2</xref>).</p>
<table-wrap id="pcbi-1003508-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003508.t002</object-id><label>Table 2</label><caption>
<title>The generalized forward algorithm.</title>
</caption><alternatives><graphic id="pcbi-1003508-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003508.t002" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Initialization:</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e217" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Recursion:</bold></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e218" xlink:type="simple"/></inline-formula>:</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e219" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e220" xlink:type="simple"/></inline-formula>:</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e221" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e222" xlink:type="simple"/></inline-formula>:</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e223" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Termination:</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e224" xlink:type="simple"/></inline-formula></td>
</tr>
</tbody>
</table>
</alternatives></table-wrap></sec><sec id="s4f">
<title>Generalized Backward Algorithm</title>
<p>The backward algorithm is analogues to the forward algorithm. We present it here because it is an integral part of the EM algorithm for MPHs and the computation of posterior probabilities (see below). The backward probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e225" xlink:type="simple"/></inline-formula> is the probability of observing the stimulus from time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e226" xlink:type="simple"/></inline-formula> to the end and the response from time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e227" xlink:type="simple"/></inline-formula> to the end (excluding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e228" xlink:type="simple"/></inline-formula>), beginning at position <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e229" xlink:type="simple"/></inline-formula> and in hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e230" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e231" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e232" xlink:type="simple"/></inline-formula> is computed recursively (<xref ref-type="table" rid="pcbi-1003508-t003">Table 3</xref>).</p>
<table-wrap id="pcbi-1003508-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003508.t003</object-id><label>Table 3</label><caption>
<title>The generalized backward algorithm.</title>
</caption><alternatives><graphic id="pcbi-1003508-t003-3" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003508.t003" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Initialization:</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e233" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Recursion:</bold></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e234" xlink:type="simple"/></inline-formula>:</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e235" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e236" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e237" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e238" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e239" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Termination:</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e240" xlink:type="simple"/></inline-formula></td>
</tr>
</tbody>
</table>
</alternatives></table-wrap></sec><sec id="s4g">
<title>Computing Posterior Probabilities</title>
<p>Assume we have trained an MPH on some data and want to determine the probability distribution over hidden states for a given stimulus-response pair and sequence position <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e241" xlink:type="simple"/></inline-formula>. Building on the definitions of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e242" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e243" xlink:type="simple"/></inline-formula> (<xref ref-type="table" rid="pcbi-1003508-t002">Table 2</xref> and <xref ref-type="table" rid="pcbi-1003508-t003">3</xref>), the posterior probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e244" xlink:type="simple"/></inline-formula> of being in hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e245" xlink:type="simple"/></inline-formula> at sequence position <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e246" xlink:type="simple"/></inline-formula> given sequence-pair <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e247" xlink:type="simple"/></inline-formula> can be expressed in terms of forward and backward probabilities:<disp-formula id="pcbi.1003508.e248"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e248" xlink:type="simple"/><label>(8)</label></disp-formula></p>
</sec><sec id="s4h">
<title>Computing Alignment Kernels</title>
<p>Intuitively, the alignment kernel <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e249" xlink:type="simple"/></inline-formula> is a histogram of spike shifts over all possible state paths weighted by their respective probability.<disp-formula id="pcbi.1003508.e250"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e250" xlink:type="simple"/></disp-formula></p>
<p>The alignment kernel is easily computed using posterior probabilities (<xref ref-type="disp-formula" rid="pcbi.1003508.e248">Eq. 8</xref>) in M- and R-States at all sequence positions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e251" xlink:type="simple"/></inline-formula> which fulfill <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e252" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003508.e253"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e253" xlink:type="simple"/></disp-formula></p>
<p>Negative lags <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e254" xlink:type="simple"/></inline-formula> in the alignment kernel imply that spikes occur before corresponding events in the stimulus, whereas positive lags imply that spikes occur thereafter.</p>
</sec><sec id="s4i">
<title>Learning Model Parameters</title>
<p>To train an MPH on a set of stimulus-response pairs, we apply a generalization of the EM algorithm. That algorithm is analogous to its normal HMM counterpart <xref ref-type="bibr" rid="pcbi.1003508-Durbin1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Rabiner1">[40]</xref>. In the expectation step, the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e255" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e256" xlink:type="simple"/></inline-formula> (<xref ref-type="table" rid="pcbi-1003508-t002">Table 2</xref> and <xref ref-type="table" rid="pcbi-1003508-t003">3</xref>) are used to compute the probability of each state at each sequence position, as well as the expected number of transitions between hidden state pairs. The model parameters are then re-estimated in such a way as to locally maximize the likelihood of the stimulus-response pair. For simplicity of notation we define <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e257" xlink:type="simple"/></inline-formula> as the probability of transiting from state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e258" xlink:type="simple"/></inline-formula> to state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e259" xlink:type="simple"/></inline-formula> at sequence position (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e260" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003508.e261"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e261" xlink:type="simple"/></disp-formula></p>
<p>Based on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e262" xlink:type="simple"/></inline-formula>, the new transition probabilities are given by<disp-formula id="pcbi.1003508.e263"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e263" xlink:type="simple"/></disp-formula></p>
<p>Initial probabilities are updated similarly:<disp-formula id="pcbi.1003508.e264"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e264" xlink:type="simple"/></disp-formula></p>
<p>The new discrete emission probabilities for R-States are given by<disp-formula id="pcbi.1003508.e265"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e265" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e266" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e267" xlink:type="simple"/></inline-formula>.</p>
<p>The update of emission density parameters for X states depends on the type of continuous probability distribution used. For Gaussian mixtures with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e268" xlink:type="simple"/></inline-formula> mixture components, new means and covariance matrices for the components can be computed as follows. For simplicity, we first define <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e269" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e270" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e271" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003508.e272"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e272" xlink:type="simple"/></disp-formula></p>
<p>The updated mixture weights, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e273" xlink:type="simple"/></inline-formula>, the means, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e274" xlink:type="simple"/></inline-formula>, and the covariance matrices <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e275" xlink:type="simple"/></inline-formula> are then computed as follows:<disp-formula id="pcbi.1003508.e276"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e276" xlink:type="simple"/></disp-formula><disp-formula id="pcbi.1003508.e277"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e277" xlink:type="simple"/></disp-formula><disp-formula id="pcbi.1003508.e278"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e278" xlink:type="simple"/></disp-formula></p>
<p>The updates for M-states are analogous. To compute the updated parameters of the mixture associated with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e279" xlink:type="simple"/></inline-formula> (where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e280" xlink:type="simple"/></inline-formula> is the number of possible neural responses, i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e281" xlink:type="simple"/></inline-formula> is the maximum number of spikes per time bin), we sum only over those sequence positions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e282" xlink:type="simple"/></inline-formula> that fulfill <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e283" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4j">
<title>Most Likely Pair of Response and Hidden State Sequences</title>
<p>Given an MPH that was trained on some stimulus-response pairs, we can predict spiking responses to novel stimuli. This is known as encoding. Conversely, we can reconstruct stimuli from spiking responses, known as decoding. In the following, we derive two encoding algorithms for MPHs. First, we show how to compute the most likely pair of hidden-state and neural response sequences, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e284" xlink:type="simple"/></inline-formula>, for a given stimulus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e285" xlink:type="simple"/></inline-formula>. This algorithm is an extension of the generalized Viterbi algorithm (<xref ref-type="table" rid="pcbi-1003508-t001">Table 1</xref>). We only present the algorithm for encoding. By symmetry, a decoding algorithm can be derived analogously.</p>
<p>Let again <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e286" xlink:type="simple"/></inline-formula> be the probability of the most likely hidden state sequence that models the stimulus up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e287" xlink:type="simple"/></inline-formula> and the response up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e288" xlink:type="simple"/></inline-formula> and ends in state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e289" xlink:type="simple"/></inline-formula>. We want to compute a neural response <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e290" xlink:type="simple"/></inline-formula> such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e291" xlink:type="simple"/></inline-formula> is maximized, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e292" xlink:type="simple"/></inline-formula> denotes the most likely state path for the sequence pair <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e293" xlink:type="simple"/></inline-formula> (<xref ref-type="table" rid="pcbi-1003508-t001">Table 1</xref>). This is accomplished by always choosing the instantaneous neural response <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e294" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e295" xlink:type="simple"/></inline-formula> such that it maximizes the emission probability in the recursion equations (<xref ref-type="table" rid="pcbi-1003508-t004">Table 4</xref>).</p>
<table-wrap id="pcbi-1003508-t004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003508.t004</object-id><label>Table 4</label><caption>
<title>Extended Viterbi algorithm to compute most likely pair of hidden state and neural response sequences for a given stimulus.</title>
</caption><alternatives><graphic id="pcbi-1003508-t004-4" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003508.t004" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Initialization:</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e296" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Recursion:</bold></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e297" xlink:type="simple"/></inline-formula>:</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e298" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e299" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e300" xlink:type="simple"/></inline-formula>:</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e301" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e302" xlink:type="simple"/></inline-formula>:</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e303" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e304" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>Termination:</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e305" xlink:type="simple"/></inline-formula></td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p>As in the generalized Viterbi algorithm (<xref ref-type="table" rid="pcbi-1003508-t001">Table 1</xref>), we keep track of the most likely precursor states in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e306" xlink:type="simple"/></inline-formula>. Additionally, we store the emissions that maximize the first factor on the right hand side of the recursion equations as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e307" xlink:type="simple"/></inline-formula>. We recover the most likely pair of hidden state sequence and neural response by considering the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e308" xlink:type="simple"/></inline-formula> associated with the most likely state at that position (we assume that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e309" xlink:type="simple"/></inline-formula>; generalization to unknown <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e310" xlink:type="simple"/></inline-formula> is possible, but irrelevant for our purposes).</p>
<p>This encoding strategy yields a spike train which depends on the most likely hidden state sequence. Such dependence can be a problem if many pairs of hidden state sequences exist with similarly high probability. Also, another caveat is that this algorithm does not provide spiking probabilities. Ideally, we would like to account for all possible hidden state sequences and compute an overall spiking or response probability for each point in time. Such improvement can be done through an extension of the forward algorithm, presented next.</p>
</sec><sec id="s4k">
<title>Computing the Response Probability Distribution as a Function of Time</title>
<p>Here we compute the probability distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e311" xlink:type="simple"/></inline-formula> of the response <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e312" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e313" xlink:type="simple"/></inline-formula> given a stimulus sequence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e314" xlink:type="simple"/></inline-formula> We can retrieve this probability as a posterior (using <xref ref-type="disp-formula" rid="pcbi.1003508.e248">Eq. 8</xref>) after rewriting our model in the following way.</p>
<list list-type="order"><list-item>
<p>Replace each M-State by X- and R-states. If the response is encoded using the two symbols <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e315" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e316" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e317" xlink:type="simple"/></inline-formula>, an M-State is replaced by two X-states, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e318" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e319" xlink:type="simple"/></inline-formula>, representing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e320" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e321" xlink:type="simple"/></inline-formula> respectively and two R-states: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e322" xlink:type="simple"/></inline-formula> which never generates a spike, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e323" xlink:type="simple"/></inline-formula> which always generates a spike. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e324" xlink:type="simple"/></inline-formula> is connected to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e325" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e326" xlink:type="simple"/></inline-formula> is connected to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e327" xlink:type="simple"/></inline-formula> (with probability 1 in both cases). Each connection onto the former M-state is now replaced by a pair of connections to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e328" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e329" xlink:type="simple"/></inline-formula>, with transition probabilities each given by the product of the original transition probability and the marginal probability of a non-spike (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e330" xlink:type="simple"/></inline-formula>) or spike (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e331" xlink:type="simple"/></inline-formula>) (computed by integrating the emission density of the M-state). By construction the model that results from applying this step is equivalent to the original model as far as inference is concerned.</p>
</list-item><list-item>
<p>Replace each of the R states in the model (except those that have been generated in step 1) by two R-states:<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e332" xlink:type="simple"/></inline-formula> that never emits a spike and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e333" xlink:type="simple"/></inline-formula> that always emits a spike. As in Step 1, the probability of spiking is encoded in the new transitions onto <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e334" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e335" xlink:type="simple"/></inline-formula><sub>.</sub> By construction, the resulting model is equivalent as far as inference is concerned.</p>
</list-item></list>
<p>With this reformulation, we can now easily express <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e336" xlink:type="simple"/></inline-formula> using sums over posterior probabilities of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e337" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e338" xlink:type="simple"/></inline-formula> states:<disp-formula id="pcbi.1003508.e339"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e339" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e340" xlink:type="simple"/></inline-formula> denotes the posterior probability of hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e341" xlink:type="simple"/></inline-formula> in the rewritten model, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e342" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e343" xlink:type="simple"/></inline-formula> denote the sets of all ‘spiking’ and non-spiking R-states, respectively. Note that by construction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e344" xlink:type="simple"/></inline-formula> is independent of the response <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e345" xlink:type="simple"/></inline-formula>. In this paper we always use this algorithm for inferring spiking probabilities in MPHs.</p>
<sec id="s4k1">
<title>Cascaded MPHs</title>
<p>Inspired by <xref ref-type="bibr" rid="pcbi.1003508-Hastie1">[26]</xref> and the standard practice of forming model cascades in neural response modeling <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Theis1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003508-Pillow1">[28]</xref>, we cascade the MPH, forming an NNP (non-linear-non-linear) model. For the M-MPH (section on LNP equivalence), we can realize arbitrary LNP non-linearities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e346" xlink:type="simple"/></inline-formula>. Given <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e347" xlink:type="simple"/></inline-formula> we define a mapping <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e348" xlink:type="simple"/></inline-formula> operating on the posterior spike probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e349" xlink:type="simple"/></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1003508.e078">Eq. 4</xref>. Applying this mapping <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e350" xlink:type="simple"/></inline-formula> to <xref ref-type="disp-formula" rid="pcbi.1003508.e078">Eq. 4</xref> yields the desired spike probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e351" xlink:type="simple"/></inline-formula>.</p>
<p>Alternatively, we can estimate the optimal mapping <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e352" xlink:type="simple"/></inline-formula> that yields the nonlinearity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e353" xlink:type="simple"/></inline-formula> that best describes the data. We estimate this mapping from the data using the conditional probability<disp-formula id="pcbi.1003508.e354"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003508.e354" xlink:type="simple"/><label>(9)</label></disp-formula></p>
<p>Thus, the optimal (discretized) mapping <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e355" xlink:type="simple"/></inline-formula> corresponds to point-wise division of two histograms, the histogram of posterior spiking probabilities given an actual spike in the numerator and the histogram of all posterior spiking probabilities in the denominator (see also <xref ref-type="bibr" rid="pcbi.1003508-Schwartz1">[1]</xref>).</p>
<p>In practice, we first estimate the MPH parameters and then re-estimate the non-linearity via the mapping <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e356" xlink:type="simple"/></inline-formula> in (<xref ref-type="disp-formula" rid="pcbi.1003508.e354">Eq. 9</xref>). When applying this cascaded MPH, we first compute the posterior spiking probabilities and then remap these using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e357" xlink:type="simple"/></inline-formula>. These response predictions are bound to give better results on the training set and will also improve validation performance (unless the mapping <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e358" xlink:type="simple"/></inline-formula> is over-fitted).</p>
</sec></sec><sec id="s4l">
<title>Computational Complexity and Optimization of the Algorithms</title>
<p>Filling out the alignment tensor used to compute forward and backward probabilities (<xref ref-type="fig" rid="pcbi-1003508-g002">Fig. 2f</xref>) in a fully connected model requires <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e359" xlink:type="simple"/></inline-formula> computations and additional <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e360" xlink:type="simple"/></inline-formula> computations for emission probabilities in M and X states (as before, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e361" xlink:type="simple"/></inline-formula> denotes the length of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e362" xlink:type="simple"/></inline-formula> sequence (stimulus), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e363" xlink:type="simple"/></inline-formula> the length of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e364" xlink:type="simple"/></inline-formula> sequence (response); and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e365" xlink:type="simple"/></inline-formula> is the number of hidden states). We usually reduce this complexity by limiting the allowed temporal offset between stimulus and response to a maximal lag set by a parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e366" xlink:type="simple"/></inline-formula>. In that case, we compute only the part of the alignment tensor within a band of width <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e367" xlink:type="simple"/></inline-formula> around the diagonal. Hence, the complexity reduces to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e368" xlink:type="simple"/></inline-formula>. In the EM algorithm, the computational complexity is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003508.e369" xlink:type="simple"/></inline-formula>.</p>
<p>The MPHs we studied had mostly constrained parameters, in particular constrained covariance matrices and means. We have found that free covariance matrices tend to make the models prone to over fitting and slow down training as more iterations of the EM algorithm are required (for instance, the M-MPH discussed in the section on LNP equivalence reaches the optimum in one iteration. Using free covariance matrices, convergence is gradual and it takes many more steps for the likelihood change to drop below a predefined threshold).</p>
<p>The EM algorithm only converges to local optima; we found that this problem can be alleviated by running the training several times from different initializations (compare <xref ref-type="fig" rid="pcbi-1003508-g005">Fig. 5D</xref> and the accompanying text).</p>
</sec><sec id="s4m">
<title>Subjects and Electrophysiology</title>
<p>All experiments were carried out in accordance with protocols approved by the Veterinary Office of the Canton of Zurich, Switzerland. Data were collected from juvenile male zebra finches (60–92 days old). The electrophysiological procedures are explained in detail elsewhere <xref ref-type="bibr" rid="pcbi.1003508-Fee1">[65]</xref>. Briefly, microdrives were implanted using methods previously described <xref ref-type="bibr" rid="pcbi.1003508-Fee1">[65]</xref>. After each experiment, the brain was removed for histological examination of unstained slices to verify the location of reference lesions. Cells were recorded during singing. During recording sessions, birds were housed in a sound isolation chamber equipped with a microphone. Extracellular voltage traces were digitized at 33 kHz and recorded for offline spike sorting.</p>
</sec></sec></body>
<back>
<ack>
<p>We thank Sylvia Schröder for very helpful discussions of the manuscript. We also thank Alexei Vyssotski and Georg Keller for providing the recorded spike trains in singing birds. Additionally, we thank Michael Pfeiffer and Florian Blättler for helpful discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003508-Schwartz1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Pillow</surname><given-names>JW</given-names></name>, <name name-style="western"><surname>Rust</surname><given-names>NC</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2006</year>) <article-title>Spike-triggered neural characterization</article-title>. <source>J Vis</source> <volume>6</volume>: <fpage>484</fpage>–<lpage>507</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/16889482" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/16889482</ext-link>. Accessed 17 February 2014.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Sharpee1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sharpee</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Rust</surname><given-names>NC</given-names></name>, <name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name> (<year>2004</year>) <article-title>Analyzing neural responses to natural signals: maximally informative dimensions</article-title>. <source>Neural Comput</source> <volume>16</volume>: <fpage>223</fpage>–<lpage>250</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/15006095" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/15006095</ext-link>. Accessed 17 February 2014.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Benda1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Benda</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Gollisch</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Machens</surname><given-names>CK</given-names></name>, <name name-style="western"><surname>Herz</surname><given-names>AV</given-names></name> (<year>2007</year>) <article-title>From response to stimulus: adaptive sampling in sensory physiology</article-title>. <source>Curr Opin Neurobiol</source> <volume>17</volume>: <fpage>430</fpage>–<lpage>436</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2007.07.009" xlink:type="simple">http://dx.doi.org/10.1016/j.conb.2007.07.009</ext-link>. Accessed 21 July 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Paninski1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Paninski</surname><given-names>L</given-names></name> (<year>2003</year>) <article-title>Convergence properties of three spike-triggered analysis techniques</article-title>. <source>Network</source> <volume>14</volume>: <fpage>437</fpage>–<lpage>464</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/12938766" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/12938766</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Park1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Park</surname><given-names>IM</given-names></name>, <name name-style="western"><surname>Archer</surname><given-names>EW</given-names></name>, <name name-style="western"><surname>Priebe</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Pillow</surname><given-names>JW</given-names></name> (<year>2013</year>) <article-title>Spectral methods for neural characterization using generalized quadratic models</article-title>. <source>Advances in Neural Information Processing Systems</source>. <fpage>2454</fpage>–<lpage>2462</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/4993-spectral-methods-for-neural-characterization-using-generalized-quadratic-models" xlink:type="simple">http://papers.nips.cc/paper/4993-spectral-methods-for-neural-characterization-using-generalized-quadratic-models</ext-link>. Accessed 22 January 2014.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Steveninck1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Steveninck</surname><given-names>RDRV</given-names></name>, <name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name> (<year>1988</year>) <article-title>Real-Time Performance of a Movement-Sensitive Neuron in the Blowfly Visual System: Coding and Information Transfer in Short Spike Sequences</article-title>. <source>Proc R Soc B Biol Sci</source> <volume>234</volume>: <fpage>379</fpage>–<lpage>414</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://rspb.royalsocietypublishing.org/content/234/1277/379.short" xlink:type="simple">http://rspb.royalsocietypublishing.org/content/234/1277/379.short</ext-link>. Accessed 7 July 2013.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Gollisch1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gollisch</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Meister</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>Rapid neural coding in the retina with relative spike latencies</article-title>. <source>Science</source> <volume>319</volume>: <fpage>1108</fpage>–<lpage>1111</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.sciencemag.org/content/319/5866/1108.abstract" xlink:type="simple">http://www.sciencemag.org/content/319/5866/1108.abstract</ext-link>. Accessed 4 July 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Tolhurst1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Smyth</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Thompson</surname><given-names>ID</given-names></name> (<year>2009</year>) <article-title>The sparseness of neuronal responses in ferret primary visual cortex</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>2355</fpage>–<lpage>2370</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.jneurosci.org/cgi/content/abstract/29/8/2355" xlink:type="simple">http://www.jneurosci.org/cgi/content/abstract/29/8/2355</ext-link>. Accessed 5 July 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Levick1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Levick</surname><given-names>WR</given-names></name> (<year>1973</year>) <article-title>Variation in the response latency of cat retinal ganglion cells</article-title>. <source>Vision Res</source> <volume>13</volume>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Gawne1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gawne</surname><given-names>TJ</given-names></name> (<year>2000</year>) <article-title>The simultaneous coding of orientation and contrast in the responses of V1 complex cells</article-title>. <source>Exp Brain Res</source> <volume>133</volume>: <fpage>293</fpage>–<lpage>302</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/10958519" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/10958519</ext-link>. Accessed 8 July 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Reich1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reich</surname><given-names>DS</given-names></name>, <name name-style="western"><surname>Mechler</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Victor</surname><given-names>JD</given-names></name> (<year>2001</year>) <article-title>Temporal Coding of Contrast in Primary Visual Cortex: When, What, and Why</article-title>. <source>J Neurophysiol</source> <volume>85</volume>: <fpage>1039</fpage>–<lpage>1050</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://jn.physiology.org/cgi/content/abstract/85/3/1039" xlink:type="simple">http://jn.physiology.org/cgi/content/abstract/85/3/1039</ext-link>. Accessed 6 July 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Gawne2"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gawne</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Kjaer</surname><given-names>TW</given-names></name>, <name name-style="western"><surname>Richmond</surname><given-names>BJ</given-names></name> (<year>1996</year>) <article-title>Latency: another potential code for feature binding in striate cortex</article-title>. <source>J Neurophysiol</source> <volume>76</volume>: <fpage>1356</fpage>–<lpage>1360</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://jn.physiology.org/cgi/content/abstract/76/2/1356" xlink:type="simple">http://jn.physiology.org/cgi/content/abstract/76/2/1356</ext-link>. Accessed 6 July 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Oram1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oram</surname><given-names>MW</given-names></name>, <name name-style="western"><surname>Xiao</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Dritschel</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Payne</surname><given-names>KR</given-names></name> (<year>2002</year>) <article-title>The temporal resolution of neural codes: does response latency have a unique role?</article-title> <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>357</volume>: <fpage>987</fpage>–<lpage>1001</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://rstb.royalsocietypublishing.org/cgi/content/abstract/357/1424/987" xlink:type="simple">http://rstb.royalsocietypublishing.org/cgi/content/abstract/357/1424/987</ext-link>. Accessed 22 July 2010.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Kiani1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kiani</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Esteky</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Tanaka</surname><given-names>K</given-names></name> (<year>2005</year>) <article-title>Differences in onset latency of macaque inferotemporal neural responses to primate and non-primate faces</article-title>. <source>J Neurophysiol</source> <volume>94</volume>: <fpage>1587</fpage>–<lpage>1596</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://jn.physiology.org/cgi/content/abstract/94/2/1587" xlink:type="simple">http://jn.physiology.org/cgi/content/abstract/94/2/1587</ext-link>. Accessed 7 September 2010.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Dimitrov1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dimitrov</surname><given-names>AG</given-names></name>, <name name-style="western"><surname>Sheiko</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Baker</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Yen</surname><given-names>S-C</given-names></name> (<year>2009</year>) <article-title>Spatial and temporal jitter distort estimated functional properties of visual sensory neurons</article-title>. <source>J Comput Neurosci</source> <volume>27</volume>: <fpage>309</fpage>–<lpage>319</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.springerlink.com/content/c1365573t6285360/" xlink:type="simple">http://www.springerlink.com/content/c1365573t6285360/</ext-link>. Accessed 12 April 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Gollisch2"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gollisch</surname><given-names>T</given-names></name> (<year>2006</year>) <article-title>Estimating receptive fields in the presence of spike-time jitter</article-title>. <source>Network</source> <volume>17</volume>: <fpage>103</fpage>–<lpage>129</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://informahealthcare.com/doi/abs/10.1080/09548980600569670" xlink:type="simple">http://informahealthcare.com/doi/abs/10.1080/09548980600569670</ext-link>. Accessed 12 April 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Buonomano1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buonomano</surname><given-names>DV</given-names></name>, <name name-style="western"><surname>Maass</surname><given-names>W</given-names></name> (<year>2009</year>) <article-title>State-dependent computations: spatiotemporal processing in cortical networks</article-title>. <source>Nat Rev Neurosci</source> <volume>10</volume>: <fpage>113</fpage>–<lpage>125</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/nrn/journal/v10/n2/full/nrn2558.html#B12" xlink:type="simple">http://www.nature.com/nrn/journal/v10/n2/full/nrn2558.html#B12</ext-link>. Accessed 6 July 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Destexhe1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Destexhe</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Contreras</surname><given-names>D</given-names></name> (<year>2006</year>) <article-title>Neuronal computations with stochastic network states</article-title>. <source>Science</source> <volume>314</volume>: <fpage>85</fpage>–<lpage>90</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.sciencemag.org/content/314/5796/85.abstract" xlink:type="simple">http://www.sciencemag.org/content/314/5796/85.abstract</ext-link>. Accessed 21 July 2010.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Sachdev1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sachdev</surname><given-names>RNS</given-names></name>, <name name-style="western"><surname>Ebner</surname><given-names>FF</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>CJ</given-names></name> (<year>2004</year>) <article-title>Effect of subthreshold up and down states on the whisker-evoked response in somatosensory cortex</article-title>. <source>J Neurophysiol</source> <volume>92</volume>: <fpage>3511</fpage>–<lpage>3521</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://jn.physiology.org/cgi/content/abstract/92/6/3511" xlink:type="simple">http://jn.physiology.org/cgi/content/abstract/92/6/3511</ext-link>. Accessed 18 July 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Bartlett1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bartlett</surname><given-names>EL</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>X</given-names></name> (<year>2005</year>) <article-title>Long-lasting modulation by stimulus context in primate auditory cortex</article-title>. <source>J Neurophysiol</source> <volume>94</volume>: <fpage>83</fpage>–<lpage>104</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://jn.physiology.org/cgi/content/abstract/94/1/83" xlink:type="simple">http://jn.physiology.org/cgi/content/abstract/94/1/83</ext-link>. Accessed 20 June 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Geffen1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Geffen</surname><given-names>MN</given-names></name>, <name name-style="western"><surname>De Vries</surname><given-names>SEJ</given-names></name>, <name name-style="western"><surname>Meister</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>Retinal Ganglion Cells Can Rapidly Change Polarity from Off to On</article-title>. <source>PLoS Biol</source> <volume>5</volume>: <fpage>11</fpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/17341132" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/17341132</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Keller1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Keller</surname><given-names>GB</given-names></name>, <name name-style="western"><surname>Hahnloser</surname><given-names>RHR</given-names></name> (<year>2009</year>) <article-title>Neural processing of auditory feedback during vocal practice in a songbird</article-title>. <source>Nature</source> <volume>457</volume>: <fpage>187</fpage>–<lpage>190</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07467" xlink:type="simple">http://dx.doi.org/10.1038/nature07467</ext-link>. Accessed 17 June 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Schmidt1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schmidt</surname><given-names>MF</given-names></name>, <name name-style="western"><surname>Konishi</surname><given-names>M</given-names></name> (<year>1998</year>) <article-title>Gating of auditory responses in the vocal control system of awake songbirds</article-title>. <source>Nat Neurosci</source> <volume>1</volume>: <fpage>513</fpage>–<lpage>518</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/10196550" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/10196550</ext-link>. Accessed 18 September 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Kouh1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kouh</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sharpee</surname><given-names>TO</given-names></name> (<year>2009</year>) <article-title>Estimating linear–nonlinear models using Rényi divergences</article-title>. <source>Network</source> <volume>20</volume>: <fpage>49</fpage>–<lpage>68</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://informahealthcare.com/doi/abs/10.1080/09548980902950891" xlink:type="simple">http://informahealthcare.com/doi/abs/10.1080/09548980902950891</ext-link>. Accessed 12 April 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Sen1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name>, <name name-style="western"><surname>Doupe a</surname><given-names>J</given-names></name> (<year>2001</year>) <article-title>Feature analysis of natural sounds in the songbird auditory forebrain</article-title>. <source>J Neurophysiol</source> <volume>86</volume>: <fpage>1445</fpage>–<lpage>1458</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/11535690" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/11535690</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Hastie1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hastie</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Tibshirani</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Friedman</surname><given-names>J</given-names></name> (<year>2009</year>) <article-title>The Elements of Statistical Learning</article-title>. <source>Elements</source> <volume>1</volume>: <fpage>337</fpage>–<lpage>387</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.springerlink.com/index/10.1007/b94608" xlink:type="simple">http://www.springerlink.com/index/10.1007/b94608</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Theis1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Theis</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Chagas</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Arnstein</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Schwarz</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Beyond GLMs: A Generative Mixture Modeling Approach to Neural System Identification</article-title>. <source>PLoS Comput Biol</source> <volume>9</volume>: <fpage>e1003356</fpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.1003356#pcbi.1003356.e057" xlink:type="simple">http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.1003356#pcbi.1003356.e057</ext-link>. Accessed 18 December 2013.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Pillow1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pillow</surname><given-names>JW</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2006</year>) <article-title>Dimensionality reduction in neural models: an information-theoretic generalization of spike-triggered average and covariance analysis</article-title>. <source>J Vis</source> <volume>6</volume>: <fpage>414</fpage>–<lpage>428</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/16889478" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/16889478</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Movshon1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Thompson</surname><given-names>ID</given-names></name>, <name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name> (<year>1978</year>) <article-title>Receptive field organization of complex cells in the cat's striate cortex</article-title>. <source>J Physiol</source> <volume>283</volume>: <fpage>79</fpage>–<lpage>99</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://jp.physoc.org/content/283/1/79.abstract?ijkey=17f32190a8f456a0d4124f1439738b91a9d161ff&amp;keytype2=tf_ipsecsha" xlink:type="simple">http://jp.physoc.org/content/283/1/79.abstract?ijkey=17f32190a8f456a0d4124f1439738b91a9d161ff&amp;keytype2=tf_ipsecsha</ext-link>. Accessed 17 December 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Adelson1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adelson</surname><given-names>EH</given-names></name>, <name name-style="western"><surname>Bergen</surname><given-names>JR</given-names></name> (<year>1985</year>) <article-title>Spatiotemporal energy models for the perception of motion</article-title>. <source>J Opt Soc Am A</source> <volume>2</volume>: <fpage>284</fpage>–<lpage>299</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/3973762" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/3973762</ext-link>. Accessed 2 December 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Touryan1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Touryan</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Felsen</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name> (<year>2005</year>) <article-title>Spatial structure of complex cell receptive fields measured with natural images</article-title>. <source>Neuron</source> <volume>45</volume>: <fpage>781</fpage>–<lpage>791</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/15748852" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/15748852</ext-link>. Accessed 17 June 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Naie1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Naie</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Hahnloser</surname><given-names>RHR</given-names></name> (<year>2011</year>) <article-title>Regulation of learned vocal behavior by an auditory motor cortical nucleus in juvenile zebra finches</article-title>. <source>J Neurophysiol</source> <volume>106</volume>: <fpage>291</fpage>–<lpage>300</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.01035.2010" xlink:type="simple">10.1152/jn.01035.2010</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1003508-Cardin1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cardin</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Raksin</surname><given-names>JN</given-names></name>, <name name-style="western"><surname>Schmidt</surname><given-names>MF</given-names></name> (<year>2005</year>) <article-title>Sensorimotor nucleus NIf is necessary for auditory processing but not vocal motor output in the avian song system</article-title>. <source>J Neurophysiol</source> <volume>93</volume>: <fpage>2157</fpage>–<lpage>2166</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://jn.physiology.org/content/93/4/2157.short" xlink:type="simple">http://jn.physiology.org/content/93/4/2157.short</ext-link>. Accessed 27 July 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Hosino1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hosino</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Okanoya</surname><given-names>K</given-names></name> (<year>2000</year>) <article-title>Lesion of a higher-order song nucleus disrupts phrase level complexity in Bengalese finches</article-title>. <source>Neuroreport</source> <volume>11</volume>: <fpage>2091</fpage>–<lpage>2095</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/10923650" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/10923650</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Okanoya1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Okanoya</surname><given-names>K</given-names></name> (<year>2004</year>) <article-title>The Bengalese finch: a window on the behavioral neurobiology of birdsong syntax</article-title>. <source>Ann N Y Acad Sci</source> <volume>1016</volume>: <fpage>724</fpage>–<lpage>735</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/15313802" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/15313802</ext-link>. Accessed 22 August 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Lewandowski1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lewandowski</surname><given-names>BC</given-names></name>, <name name-style="western"><surname>Schmidt</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>Short bouts of vocalization induce long-lasting fast γ oscillations in a sensorimotor nucleus</article-title>. <source>J Neurosci</source> <volume>31</volume>: <fpage>13936</fpage>–<lpage>13948</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.jneurosci.org/content/31/39/13936.short" xlink:type="simple">http://www.jneurosci.org/content/31/39/13936.short</ext-link>. Accessed 25 September 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-McCasland1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McCasland</surname><given-names>J</given-names></name> (<year>1987</year>) <article-title>Neuronal control of bird song production</article-title>. <source>J Neurosci</source> <volume>7</volume>: <fpage>23</fpage>–<lpage>39</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.jneurosci.org/content/7/1/23.short" xlink:type="simple">http://www.jneurosci.org/content/7/1/23.short</ext-link>. Accessed 25 September 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Durbin1"><label>38</label>
<mixed-citation publication-type="book" xlink:type="simple">Durbin R, Eddy S, Krogh A, Mitchison G (1999) Biological Sequence Analysis. Cambridge: Cambridge University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Singh1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Singh</surname><given-names>NC</given-names></name>, <name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name> (<year>2003</year>) <article-title>Modulation spectra of natural sounds and ethological theories of auditory processing</article-title>. <source>J Acoust Soc Am</source> <volume>114</volume>: <fpage>3394</fpage> Available: <ext-link ext-link-type="uri" xlink:href="http://link.aip.org/link/?JASMAN/114/3394/1" xlink:type="simple">http://link.aip.org/link/?JASMAN/114/3394/1</ext-link>. Accessed 21 May 2013.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Rabiner1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rabiner</surname><given-names>LR</given-names></name> (<year>1989</year>) <article-title>A tutorial on hidden Markov models and selected applications in speech recognition</article-title>. <source>Proc IEEE</source> <volume>77</volume>: <fpage>257</fpage>–<lpage>286</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=18626" xlink:type="simple">http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=18626</ext-link>. Accessed 27 July 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Aldworth1"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aldworth</surname><given-names>ZN</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Gedeon</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Cummins</surname><given-names>GI</given-names></name>, <name name-style="western"><surname>Dimitrov</surname><given-names>AG</given-names></name> (<year>2005</year>) <article-title>Dejittered spike-conditioned stimulus waveforms yield improved estimates of neuronal feature selectivity and spike-timing precision of sensory interneurons</article-title>. <source>J Neurosci</source> <volume>25</volume>: <fpage>5323</fpage>–<lpage>5332</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/15930380" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/15930380</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Gat1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gat</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Tishby</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Abeles</surname><given-names>M</given-names></name> (<year>1997</year>) <article-title>Hidden Markov modelling of simultaneously recorded cells in the associative cortex of behaving monkeys. Network: Comput</article-title>. <source>Neural Syst</source> <volume>897</volume>: <fpage>297</fpage>–<lpage>322</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://informahealthcare.com/doi/abs/10.1088/0954-898X_8_3_005" xlink:type="simple">http://informahealthcare.com/doi/abs/10.1088/0954-898X_8_3_005</ext-link>. Accessed 20 November 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Abeles1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abeles</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bergman</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Gat</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Meilijson</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Seidemann</surname><given-names>E</given-names></name>, <etal>et al</etal>. (<year>1995</year>) <article-title>Cortical activity flips among quasi-stationary states</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>92</volume>: <fpage>8616</fpage>–<lpage>8620</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=41017&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=41017&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. Accessed 4 July 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Camproux1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Camproux</surname><given-names>AC</given-names></name>, <name name-style="western"><surname>Saunier</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Chouvet</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Thalabard</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Thomas</surname><given-names>G</given-names></name> (<year>1996</year>) <article-title>A hidden Markov model approach to neuron firing patterns</article-title>. <source>Biophys J</source> <volume>71</volume>: <fpage>2404</fpage>–<lpage>2412</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://linkinghub.elsevier.com/retrieve/pii/S0006349596794341" xlink:type="simple">http://linkinghub.elsevier.com/retrieve/pii/S0006349596794341</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Radons1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Radons</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Becker</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Dülfer</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Krüger</surname><given-names>J</given-names></name> (<year>1994</year>) <article-title>Analysis, classification, and coding of multielectrode spike trains with hidden Markov models</article-title>. <source>Biol Cybern</source> <volume>71</volume>: <fpage>359</fpage>–<lpage>373</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/7948227" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/7948227</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Rainer1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rainer</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>EK</given-names></name> (<year>2000</year>) <article-title>Neural ensemble states in prefrontal cortex identified using a hidden Markov model with a modified EM algorithm</article-title>. <source>Neurocomputing</source> <volume>32–33</volume>: <fpage>961</fpage>–<lpage>966</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0925-2312(00)00266-6" xlink:type="simple">http://dx.doi.org/10.1016/S0925-2312(00)00266-6</ext-link>. Accessed 20 November 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Weber1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weber</surname><given-names>AP</given-names></name>, <name name-style="western"><surname>Hahnloser</surname><given-names>RHR</given-names></name> (<year>2007</year>) <article-title>Spike correlations in a songbird agree with a simple markov population model</article-title>. <source>PLoS Comput Biol</source> <volume>3</volume>: <fpage>e249</fpage> Available: <ext-link ext-link-type="uri" xlink:href="http://dx.plos.org/10.1371/journal.pcbi.0030249" xlink:type="simple">http://dx.plos.org/10.1371/journal.pcbi.0030249</ext-link>. Accessed 20 November 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Dan1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dan</surname><given-names>G</given-names></name> (<year>2006</year>) <article-title>Efficient estimation of hidden state dynamics from spike trains</article-title>. <source>Adv Neural Inf Process Syst</source> <volume>18 18</volume>: <fpage>227</fpage>–<lpage>234</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.7313&amp;rep=rep1&amp;type=pdf" xlink:type="simple">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.7313&amp;rep=rep1&amp;type=pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Ghahramani1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ghahramani</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Hinton</surname><given-names>GE</given-names></name> (<year>2000</year>) <article-title>Variational Learning for Switching State-Space Models</article-title>. <source>Neural Comput</source> <volume>12</volume>: <fpage>831</fpage>–<lpage>864</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.mitpressjournals.org/doi/abs/10.1162/089976600300015619" xlink:type="simple">http://www.mitpressjournals.org/doi/abs/10.1162/089976600300015619</ext-link>. Accessed 20 April 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Wu1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wu</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Kulkarni</surname><given-names>JE</given-names></name>, <name name-style="western"><surname>Hatsopoulos</surname><given-names>NG</given-names></name>, <name name-style="western"><surname>Paninski</surname><given-names>L</given-names></name> (<year>2009</year>) <article-title>Neural Decoding of Hand Motion Using a Linear State-Space Model With Hidden States</article-title>. <source>IEEE Trans Neural Syst Rehabil Eng</source> <volume>17</volume>: <fpage>370</fpage>–<lpage>378</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/19497822" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/19497822</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Lawhern1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lawhern</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Hatsopoulos</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Paninski</surname><given-names>L</given-names></name> (<year>2010</year>) <article-title>Population decoding of motor cortical activity using a generalized linear model with hidden states</article-title>. <source>J Neurosci Methods</source> <volume>189</volume>: <fpage>267</fpage>–<lpage>280</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2921213&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2921213&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Ahrens1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ahrens</surname><given-names>MB</given-names></name>, <name name-style="western"><surname>Linden</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>Nonlinearities and contextual influences in auditory cortical responses modeled with multilinear spectrotemporal methods</article-title>. <source>J Neurosci</source> <volume>28</volume>: <fpage>1929</fpage>–<lpage>1942</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.jneurosci.org/content/28/8/1929.short" xlink:type="simple">http://www.jneurosci.org/content/28/8/1929.short</ext-link>. Accessed 22 May 2013.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Rust1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rust</surname><given-names>NC</given-names></name>, <name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2005</year>) <article-title>Spatiotemporal elements of macaque v1 receptive fields</article-title>. <source>Neuron</source> <volume>46</volume>: <fpage>945</fpage>–<lpage>956</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.cell.com/neuron/fulltext/S0896-6273(05)00468-X" xlink:type="simple">http://www.cell.com/neuron/fulltext/S0896-6273(05)00468-X</ext-link>. Accessed 21 May 2013.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Touryan2"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Touryan</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Lau</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name> (<year>2002</year>) <article-title>Isolation of Relevant Visual Features from Random Stimuli for Cortical Complex Cells</article-title>. <source>J Neurosci</source> <volume>22</volume>: <fpage>10811</fpage>–<lpage>10818</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.jneurosci.org/content/22/24/10811.abstract?ijkey=75844c6092d5d53a05a047a1aa8a909ce7691529&amp;keytype2=tf_ipsecsha" xlink:type="simple">http://www.jneurosci.org/content/22/24/10811.abstract?ijkey=75844c6092d5d53a05a047a1aa8a909ce7691529&amp;keytype2=tf_ipsecsha</ext-link>. Accessed 17 December 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Eickenberg1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eickenberg</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Rowekamp</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Kouh</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sharpee</surname><given-names>TO</given-names></name> (<year>2012</year>) <article-title>Characterizing Responses of Translation-Invariant Neurons to Natural Stimuli: Maximally Informative Invariant Dimensions</article-title>. <source>Neural Comput</source> <volume>24</volume>: <fpage>2384</fpage>–<lpage>23421</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00330?journalCode=neco" xlink:type="simple">http://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00330?journalCode=neco</ext-link>. Accessed 7 July 2013.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Bienenstock1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bienenstock</surname><given-names>E</given-names></name> (<year>1995</year>) <article-title>A model of neocortex</article-title>. <source>Network: Comput Neural Syst</source> <volume>6</volume>: <fpage>179</fpage>–<lpage>224</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://informahealthcare.com/doi/abs/10.1088/0954-898X_6_2_004" xlink:type="simple">http://informahealthcare.com/doi/abs/10.1088/0954-898X_6_2_004</ext-link>. Accessed 3 November 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Ikegaya1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ikegaya</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Aaron</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Cossart</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Aronov</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Lampl</surname><given-names>I</given-names></name>, <etal>et al</etal>. (<year>2004</year>) <article-title>Synfire chains and cortical songs: temporal modules of cortical activity</article-title>. <source>Science</source> <volume>304</volume>: <fpage>559</fpage>–<lpage>564</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.sciencemag.org/content/304/5670/559.abstract" xlink:type="simple">http://www.sciencemag.org/content/304/5670/559.abstract</ext-link>. Accessed 5 July 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Abeles2"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abeles</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hayon</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Lehmann</surname><given-names>D</given-names></name> (<year>2004</year>) <article-title>Modeling compositionality by dynamic binding of synfire chains</article-title>. <source>J Comput Neurosci</source> <volume>17</volume>: <fpage>179</fpage>–<lpage>201</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.springerlink.com/content/t565584112517216/" xlink:type="simple">http://www.springerlink.com/content/t565584112517216/</ext-link>. Accessed 15 July 2011.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Blaettler1"><label>59</label>
<mixed-citation publication-type="other" xlink:type="simple">Blaettler F, Kollmorgen S, Herbst J, Hahnloser R (2011) Hidden Markov Models in the Neurosciences. In: Dymarski P, editor. Hidden Markov Models, Theory And Applications. InTech. pp. 169–186.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Victor1"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Victor</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Purpura</surname><given-names>KP</given-names></name> (<year>1998</year>) <article-title>Metric-space analysis of spike trains: theory, algorithms, and application</article-title>. <source>Netw Comput Neural Syst</source> <volume>8</volume>: <fpage>127</fpage>–<lpage>164</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/q-bio/0309031" xlink:type="simple">http://arxiv.org/abs/q-bio/0309031</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Ephraim1"><label>61</label>
<mixed-citation publication-type="other" xlink:type="simple">Ephraim Y, Dembo A, Rabiner L (1987) A minimum discrimination information approach for hidden Markov modeling. ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing. Institute of Electrical and Electronics Engineers, Vol. 12. pp. 25–28. Available: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1169727&amp;contentType=Conference+Publications" xlink:type="simple">http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1169727&amp;contentType=Conference+Publications</ext-link>. Accessed 25 September 2012.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Fine1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fine</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Singer</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Tishby</surname><given-names>N</given-names></name> (<year>1998</year>) <article-title>The Hierarchical Hidden Markov Model: Analysis and Applications</article-title>. <source>Computer (Long Beach Calif)</source> <volume>32</volume>: <fpage>41</fpage>–<lpage>62</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.springerlink.com/index/H7630R4U78J0XHU1.pdf" xlink:type="simple">http://www.springerlink.com/index/H7630R4U78J0XHU1.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Stolcke1"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stolcke</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Omohundro</surname><given-names>S</given-names></name> (<year>1993</year>) <article-title>Hidden Markov Model Induction by Bayesian Model Merging</article-title>. <source>Adv Neural Inf Process Syst</source> <volume>5</volume>: <fpage>11</fpage>–<lpage>18</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.470&amp;rep=rep1&amp;type=pdf" xlink:type="simple">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.470&amp;rep=rep1&amp;type=pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Ghahramani2"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ghahramani</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name> (<year>1997</year>) <article-title>Factorial Hidden Markov Models</article-title>. <source>Mach Learn</source> <volume>29</volume>: <fpage>245</fpage>–<lpage>273</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/16204097" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/16204097</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003508-Fee1"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fee</surname><given-names>MS</given-names></name>, <name name-style="western"><surname>Leonardo</surname><given-names>A</given-names></name> (<year>2001</year>) <article-title>Miniature motorized microdrive and commutator system for chronic neural recording in small animals</article-title>. <source>J Neurosci Methods</source> <volume>112</volume>: <fpage>83</fpage>–<lpage>94</lpage> Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/11716944" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/11716944</ext-link>. Accessed 22 January 2013.</mixed-citation>
</ref>
</ref-list></back>
</article>
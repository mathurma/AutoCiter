<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="review-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.1002075</article-id>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-14-04251</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Primer</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Multisensory Causal Inference in the Brain</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Kayser</surname>
<given-names>Christoph</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Shams</surname>
<given-names>Ladan</given-names>
</name>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Institute of Neuroscience and Psychology, University of Glasgow, Glasgow, United Kingdom</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Departments of Psychology and BioEngineering and the Interdepartmental Neuroscience Program, University of California, Los Angeles, Los Angeles, California, United States of America</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">christoph.kayser@glasgow.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>24</day>
<month>2</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="collection">
<month>2</month>
<year>2015</year>
</pub-date>
<volume>13</volume>
<issue>2</issue>
<elocation-id>e1002075</elocation-id>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Kayser, Shams</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.1002075" xlink:type="simple"/>
<related-article ext-link-type="uri" id="related001" related-article-type="companion" xlink:href="info:doi/10.1371/journal.pbio.1002073" xlink:type="simple">
<article-title>Cortical Hierarchies Perform Bayesian Causal Inference in Multisensory Perception</article-title>
</related-article>
<abstract>
<p>At any given moment, our brain processes multiple inputs from its different sensory modalities (vision, hearing, touch, etc.). In deciphering this array of sensory information, the brain has to solve two problems: (1) which of the inputs originate from the same object and should be integrated and (2) for the sensations originating from the same object, how best to integrate them. Recent behavioural studies suggest that the human brain solves these problems using optimal probabilistic inference, known as Bayesian causal inference. However, how and where the underlying computations are carried out in the brain have remained unknown. By combining neuroimaging-based decoding techniques and computational modelling of behavioural data, a new study now sheds light on how multisensory causal inference maps onto specific brain areas. The results suggest that the complexity of neural computations increases along the visual hierarchy and link specific components of the causal inference process with specific visual and parietal regions.</p>
</abstract>
<abstract abstract-type="toc">
<p>How does our brain organize and merge multisensory information? A new study localizes the brain regions underlying sensory fusion and causal inference by combining neuroimaging and computational modelling.</p>
</abstract>
<funding-group>
<funding-statement>CK is supported by BBSRC grant BB/L027534/1, LS by NSF grant 1057969. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="2"/>
<table-count count="0"/>
<page-count count="7"/>
</counts>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Our brain is continuously faced with a plethora of sensory inputs impinging on our senses. At any moment we see, hear, touch, and smell, and only the coordinated interplay of our senses allows us to properly interact with the environment [<xref rid="pbio.1002075.ref001" ref-type="bibr">1</xref>]. How the brain organizes all these sensory inputs into a coherent percept remains unclear. As shown in a new study by Rohe and Noppeney, important insights can be obtained by combining computational models with carefully crafted analysis of brain activity [<xref rid="pbio.1002075.ref002" ref-type="bibr">2</xref>].</p>
<p>The brain needs to solve several computational problems to make sense of its environment. Besides the analysis of specific sensory attributes (for example, to segment a scene into its constituent objects), two critical problems involve the inputs to different senses. One is the “multisensory integration problem”: how information is synthesized (or fused) across the senses. For instance, speech perception usually relies on the integration of auditory and visual information (listening to somebody’s voice while seeing his or her lips move). This integration problem can be challenging, as each sense only provides a noisy and possibly biased estimate of the respective attribute [<xref rid="pbio.1002075.ref003" ref-type="bibr">3</xref>,<xref rid="pbio.1002075.ref004" ref-type="bibr">4</xref>].</p>
<p>In addition, the brain needs to solve the “causal inference problem” [<xref rid="pbio.1002075.ref005" ref-type="bibr">5</xref>–<xref rid="pbio.1002075.ref007" ref-type="bibr">7</xref>]: it has to decide which sensory inputs likely originate from the same object and hence provide complementary evidence about this and which inputs originate from distinct objects and hence should be processed separately. One example is at a cocktail party, where many faces and voices can make it a challenge to know who called our name. Another example is at a ventriloquist’s performance, where we attribute the voice to the puppet rather than the actor. In practice, the tasks of inferring the causal structure and of obtaining precise estimates of sensory attributes are highly intertwined, as causal inference depends on the similarity of different sensory features, while the estimate of each attribute depends on the inferred causal origin. For example, the association of a face and a voice depends on both the perceived location of each as well as the match between sematic, social, or physical attributes derived from faces and voices. Hence, solving the causal inference problem has to rely on a number of factors such as spatial, temporal, and structural congruency, prior knowledge, and expectations.</p>
<p>In the 19th century, von Helmholtz already noted that perception requires solving multiple inference problems [<xref rid="pbio.1002075.ref008" ref-type="bibr">8</xref>]. Yet, laboratory studies on multisensory integration often avoid the causal inference problem by crafting multisensory stimuli that leave little doubt as to whether they provide evidence about the same sensory object. However, the brain mechanisms underlying multisensory perception in everyday tasks can probably only be understood by considering both the integration and causal inference problems [<xref rid="pbio.1002075.ref009" ref-type="bibr">9</xref>]. Fortunately, the field of Bayesian perception has provided a conceptual framework in which both can be cast in unified statistical terms [<xref rid="pbio.1002075.ref010" ref-type="bibr">10</xref>].</p>
</sec>
<sec id="sec002">
<title>Bayesian Approaches to Multisensory Perception</title>
<p>Bayesian statistics describes sensory representations in probabilistic terms, attributing likelihoods to each possible encoding of a sensory attribute [<xref rid="pbio.1002075.ref011" ref-type="bibr">11</xref>]. Moreover, it describes how different variables interact in determining the outcome, such as how prior knowledge affects perceptual estimates or how inputs from two senses combine. As shown in <xref rid="pbio.1002075.g001" ref-type="fig">Fig. 1A</xref>, when considered independently, each sensory modality can be conceptualized as providing a noisy (probabilistic) estimate of the same attribute. Yet, under the assumption of a common source, Bayesian inference predicts the multisensory estimate arising from the combination of both senses by weighing each input in proportion to its reliability (<xref rid="pbio.1002075.g001" ref-type="fig">Fig. 1B</xref>).</p>
<fig id="pbio.1002075.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002075.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Bayesian models of multisensory integration.</title>
<p>Schematic of different causal structures in the environment giving rise to visual and acoustic inputs (e.g., seeing a face and hearing a voice) that may or may not originate from the same speaker. The left panels display the inferred statistical causal structure, with S<sub>A</sub>, S<sub>V</sub>, and S denoting sources for acoustic, visual, or multisensory stimuli and X<sub>A</sub> and X<sub>V</sub> indicating the respective sensory representations (e.g., location). The right panels display the probability distributions of these sensory representations and the optimal estimate of stimulus attribute (e.g., location) derived from the Bayesian model under different assumptions about the environment. For the sake of simplicity of illustration, it is assumed that the prior probability of the stimulus attribute is uniform (and therefore not shown in the equations and figures). (A) Assuming separate sources (C = 2) leads to independent acoustic and visual estimates of stimulus location, with the optimal value matching the most likely unisensory location. (B) Assuming a common source (C = 1) leads to integration (fusion). The optimal Bayesian estimate is the combination of visual and acoustic estimates, each weighted by its relative reliability (with σ<sub>A</sub> and σ<sub>V</sub> denoting the inverse reliability of each sense). (C) In Bayesian causal inference (assuming a model-averaging decision strategy), the two different hypotheses about the causal structure (e.g., one or two sources) are combined, each weighted by its inferred probability given the visual and acoustic sensations. The optimal stimulus estimate is a mixture of the unisensory and fused estimates.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002075.g001" position="float" xlink:type="simple"/>
</fig>
<p>This approach has provided invaluable insights about various aspects of perceptual multisensory integration [<xref rid="pbio.1002075.ref003" ref-type="bibr">3</xref>,<xref rid="pbio.1002075.ref004" ref-type="bibr">4</xref>,<xref rid="pbio.1002075.ref012" ref-type="bibr">12</xref>,<xref rid="pbio.1002075.ref013" ref-type="bibr">13</xref>] and helped to identify the sensory computations likely to be carried out by the underlying neural processes [<xref rid="pbio.1002075.ref014" ref-type="bibr">14</xref>,<xref rid="pbio.1002075.ref015" ref-type="bibr">15</xref>]. For example, studies on visual-vestibular integration have shown that the mathematical rules by which neural populations combine visual-vestibular information follow Bayesian predictions and that the relative weights attributed to each modality in the neural code scale with sensory reliability analogous to the perceptual weights [<xref rid="pbio.1002075.ref016" ref-type="bibr">16</xref>].</p>
</sec>
<sec id="sec003">
<title>Probabilistic Models for Causal Inference</title>
<p>The Bayesian approach can be extended to model the causal inference problem by including inference about the environment’s causal structure (<xref rid="pbio.1002075.g001" ref-type="fig">Fig. 1C</xref>). Depending on the task that the nervous system has to solve, different perceptual decision-making strategies can be used to derive estimates of sensory attributes based on the probabilities of each possible causal structure [<xref rid="pbio.1002075.ref017" ref-type="bibr">17</xref>]. For example, when trying to minimize the error in the perceptual estimate, e.g., to precisely localize a speaker, the optimal estimate is the nonlinear weighted average of two terms: one estimate derived under the assumption that two inputs originate from a single source (fusion) and one derived under the assumption that they have separate sources (segregation), with each estimate weighted by the probability of the respective causal structure. This strategy is known as “model averaging” (<xref rid="pbio.1002075.g001" ref-type="fig">Fig. 1C</xref>).</p>
<p>In testing whether Bayesian causal inference can account for human perception, localization tasks have been proved useful (<xref rid="pbio.1002075.g002" ref-type="fig">Fig. 2</xref>) [<xref rid="pbio.1002075.ref006" ref-type="bibr">6</xref>,<xref rid="pbio.1002075.ref017" ref-type="bibr">17</xref>–<xref rid="pbio.1002075.ref019" ref-type="bibr">19</xref>]. When visual and acoustic stimuli are presented with a small spatial disparity (<xref rid="pbio.1002075.g002" ref-type="fig">Fig. 2A</xref>), they are likely perceived as originating from the same source, hence their evidence about the spatial location should be fused. In contrast, if their spatial disparity is large (<xref rid="pbio.1002075.g002" ref-type="fig">Fig. 2B</xref>), the two inputs likely arise from distinct sources and should be segregated. Interestingly, the model also predicts a more surprising behaviour in conditions in which spatial disparity is moderate (<xref rid="pbio.1002075.g002" ref-type="fig">Fig. 2C</xref>). In this case, the two senses get partially integrated, weighted by the relative likelihood of one or two origins [<xref rid="pbio.1002075.ref017" ref-type="bibr">17</xref>]—assuming that the brain adopts a model averaging strategy, which seems to be the case in many observers [<xref rid="pbio.1002075.ref019" ref-type="bibr">19</xref>]. Therefore, Bayesian causal inference successfully explains perceptual judgements across the range of discrepancies, spanning a continuum, from fusion to partial integration to segregation.</p>
<fig id="pbio.1002075.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002075.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Causal inference about stimulus location.</title>
<p>(A–C) Schematized spatial paradigm employed by several studies on audio-visual causal inference. Brief and simple visual (flashes) and auditory (noise bursts) stimuli are presented at varying locations along azimuth and varying degrees of discrepancy across trials. When stimuli are presented with large spatial discrepancy (panel A), they are typically perceived as independent events and are processed separately. When they are presented with no or little spatial discrepancy (panel B), they are typically perceived as originating from the same source and their spatial evidence is integrated (fused). Finally, when the spatial discrepancy is intermediate (panel C), causal inference can result in partial integration: the perceived locations of the two stimuli are pulled towards each other but do not converge. Please note that the probability distributions corresponding to each panel are shown in the respective panels in <xref rid="pbio.1002075.g001" ref-type="fig">Fig. 1</xref>. (D) Schematized summary of the results by Rohe and Noppeney. Early sensory areas mostly reflect the unisensory evidence corresponding to segregated representations, posterior parietal regions reflect the fused spatial estimate, and more anterior parietal regions reflect the overall causal inference estimate. This distributed pattern of sensory representations demonstrates the progression of causal inference computations along the cortical hierarchy.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002075.g002" position="float" xlink:type="simple"/>
</fig>
<p>Again, its success in describing human perception suggests that this Bayesian model could also provide a framework to map the underlying neural processes onto distinct sensory computations. For example, an important question is whether the same or distinct brain regions reflect the integration process and the causal inference computation. This is precisely what the study by Rohe and Noppeney addressed.</p>
</sec>
<sec id="sec004">
<title>Mapping Causal Inference onto Sensory Pathways</title>
<p>In their study, participants localized audiovisual signals that varied in spatial discrepancy and visual reliability while their brain activity was measured using functional magnetic resonance imaging (fMRI). The authors first fit the causal inference model to the perceptual data, which enabled them to investigate the mapping between brain activity and the different spatial estimates predicted by the model; the estimates were predicted by either unisensory input (corresponding to the distinct causal origins hypothesis), by the fusion of the two sensations (corresponding to the single causal origin hypothesis), or by the causal inference model (the weighted combination of fusion and segregation). Addressing this question required an additional step of data analysis: linking the selectivity to spatial information reflected in distributed patterns of fMRI activity to the spatial estimates predicted by each model component. Luckily, methods of decoding analysis provide a means to establish such a link [<xref rid="pbio.1002075.ref020" ref-type="bibr">20</xref>] and allowed the authors to associate each brain region of interest with the best-matching sensory estimate predicted by the inference model.</p>
<p>As may be expected, some regions (early visual and auditory cortices) predominantly reflected the unisensory inputs and hence were only a little affected by any multisensory computation (see <xref rid="pbio.1002075.g002" ref-type="fig">Fig. 2D</xref>). Other regions, e.g., those involved in establishing spatial maps (posterior regions in the intraparietal sulcus), reflected the fused estimate. Thus, in these regions, automatic integration processes seem to occur that merge the spatial evidence provided by different modalities, weighted by their reliability, but regardless of how likely it is that these relate to the same object. And finally, regions more anterior in the intraparietal sulcus encoded the spatial estimate as predicted by the causal inference model, hence adapting their sensory representation based on the likely causal origin.</p>
<p>Overall, the new results show that different neural processes along the sensory pathways reflect distinct estimates about the localization of sensory events. Some estimates seem to arise mostly in a simple unisensory manner, while others exhibit the computationally complex nature required for causal inference. In addition, they suggest that sensory fusion and causal inference, at least in the context of spatial perception, are distributed processes not necessarily occurring in the same regions. And finally, they reveal a gradual emergence of multisensory computations along “visual” pathways. The data support both the traditional notion that multisensory perception is mostly implemented by higher-level association regions and the more recent notion that early sensory regions also participate in multisensory encoding [<xref rid="pbio.1002075.ref021" ref-type="bibr">21</xref>,<xref rid="pbio.1002075.ref022" ref-type="bibr">22</xref>]. Most importantly, however, they show how model-driven neuroimaging studies allow us to map complex sensory operations such as causal inference onto the sensory hierarchies.</p>
<p>One conclusion from this and previous studies is that multisensory perception does not result from a single and localized process—that would fit the often and sometimes abused term “multisensory integration” [<xref rid="pbio.1002075.ref023" ref-type="bibr">23</xref>]. Rather, multisensory perception arises from the interplay of many processes and a network of interacting regions that implement these, each possibly relying on a different assumption about the causal structure of the environment and implementing a different sensory computation. Ultimately, it may be impossible to fully understand localized multisensory processes without considering them in the big picture of a possibly hierarchical but certainly distributed organization.</p>
</sec>
<sec id="sec005" sec-type="conclusions">
<title>Conclusions</title>
<p>As with any major step forward, the results pose many new questions. For example, judging the environment’s causal structure relies on prior knowledge and experience [<xref rid="pbio.1002075.ref007" ref-type="bibr">7</xref>,<xref rid="pbio.1002075.ref012" ref-type="bibr">12</xref>], but we don’t know whether the processes of causal inference and incorporating prior information are implemented by the same neural processes. It will also be important to see whether there are brain regions generically involved in multisensory inference and not specific to spatial attributes. Furthermore, it seems natural to look for similar gradual changes in multisensory computations along other sensory pathways. For example, our understanding of auditory pathways may benefit from such model-based decoding studies [<xref rid="pbio.1002075.ref024" ref-type="bibr">24</xref>]. Finally, the roles of attention and task relevance for multisensory perception remain controversial. Attentional selection modulates multisensory integration, and multisensory coincidences attract attention and amplify perception [<xref rid="pbio.1002075.ref025" ref-type="bibr">25</xref>]. It remains unclear how attentional state or task relevance influence which sensory variables are represented in any brain region, and recent studies reveal complex patterns of mixed selectivity to task- and sensory-related variables in higher association regions [<xref rid="pbio.1002075.ref026" ref-type="bibr">26</xref>]. Disentangling the impact of attention and task nature on multisensory encoding and what can actually be measured using neuroimaging signals remains a challenge for the future.</p>
<p>Neuroimaging studies provide critical insights into the large-scale organization of perception, but the underlying local mechanisms of neural population coding remain to be confirmed. Signatures of multisensory encoding at the single neuron level can be subtle [<xref rid="pbio.1002075.ref027" ref-type="bibr">27</xref>], and the mixed selectivity of higher-level sensory regions can render the link between neural populations and neuroimaging ambiguous [<xref rid="pbio.1002075.ref028" ref-type="bibr">28</xref>]. Again model-driven approaches may help, for example, by providing testable hypothesis about large-scale population codes that can be extracted from electrophysiological recordings or neuroimaging [<xref rid="pbio.1002075.ref014" ref-type="bibr">14</xref>].</p>
<p>On a methodological side, recent work has shown how combining fMRI with probabilistic models of cognition can be a very powerful tool for understanding brain function [<xref rid="pbio.1002075.ref029" ref-type="bibr">29</xref>,<xref rid="pbio.1002075.ref030" ref-type="bibr">30</xref>]. In line with this, Rohe and Noppeney show that the combination of statistical models of perception and brain decoding has the power to enlighten our understanding of perception far beyond more descriptive approaches. Yet, studies such as this require carefully crafted models and efficient paradigms to overcome the poor signal-to-noise ratio sometimes offered by neuroimaging. As a result, further advances in both perceptual models and signal understanding and analysis are required to eventually uncover why we sometimes benefit from seeing a speaker in a noisy environment and why we get fooled by the ventriloquist’s puppet.</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pbio.1002075.ref001"><label>1</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Stein</surname> <given-names>BE</given-names></name>, editor (<year>2012</year>) <source>The New Handbook of Multisensory Processing</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="pbio.1002075.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rohe</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Noppeney</surname> <given-names>U</given-names></name> (<year>2015</year>) <article-title>Cortical Hierarchies Perform Bayesian Causal Inference in Multisensory Perception</article-title>. <source>PLoS Biol</source> <volume>13</volume>: <fpage>e1002073</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1002055" xlink:type="simple">10.1371/journal.pbio.1002055</ext-link></comment> <object-id pub-id-type="pmid">25575020</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Gu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name> (<year>2009</year>) <article-title>Multisensory integration: psychophysics, neurophysiology, and computation</article-title>. <source>Curr Opin Neurobiol</source> <volume>19</volume>: <fpage>452</fpage>–<lpage>458</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2009.06.008" xlink:type="simple">10.1016/j.conb.2009.06.008</ext-link></comment> <object-id pub-id-type="pmid">19616425</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Bulthoff</surname> <given-names>HH</given-names></name> (<year>2004</year>) <article-title>Merging the senses into a robust percept</article-title>. <source>Trends Cogn Sci</source> <volume>8</volume>: <fpage>162</fpage>–<lpage>169</lpage>. <object-id pub-id-type="pmid">15050512</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Beierholm</surname> <given-names>UR</given-names></name> (<year>2010</year>) <article-title>Causal inference in perception</article-title>. <source>Trends Cogn Sci</source> <volume>14</volume>: <fpage>425</fpage>–<lpage>432</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2010.07.001" xlink:type="simple">10.1016/j.tics.2010.07.001</ext-link></comment> <object-id pub-id-type="pmid">20705502</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wallace</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Roberson</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Hairston</surname> <given-names>WD</given-names></name>, <name name-style="western"><surname>Stein</surname> <given-names>BE</given-names></name>, <name name-style="western"><surname>Vaughan</surname> <given-names>JW</given-names></name>, <etal>et al</etal>. (<year>2004</year>) <article-title>Unifying multisensory signals across time and space</article-title>. <source>Exp Brain Res</source> <volume>158</volume>: <fpage>252</fpage>–<lpage>258</lpage>. <object-id pub-id-type="pmid">15112119</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Roach</surname> <given-names>NW</given-names></name>, <name name-style="western"><surname>Heron</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>McGraw</surname> <given-names>PV</given-names></name> (<year>2006</year>) <article-title>Resolving multisensory conflict: a strategy for balancing the costs and benefits of audio-visual integration</article-title>. <source>Proc Biol Sci</source> <volume>273</volume>: <fpage>2159</fpage>–<lpage>2168</lpage>. <object-id pub-id-type="pmid">16901835</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref008"><label>8</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Hatfield</surname> <given-names>G</given-names></name> (<year>1990</year>) <source>The natural and the normative theories of spatial perception from Kant to Helmholtz</source>. <publisher-loc>Cambridge, Mass</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="pbio.1002075.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Beierholm</surname> <given-names>U</given-names></name> (<year>2005</year>) <article-title>Sound-induced flash illusion as an optimal percept</article-title>. <source>Neuroreport</source> <volume>16</volume>: <fpage>1923</fpage>–<lpage>1927</lpage>. <object-id pub-id-type="pmid">16272880</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref010"><label>10</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Beierholm</surname> <given-names>U</given-names></name> (<year>2011</year>) <chapter-title>Humans’ multisensory perception, from integration to segregation, follows Bayesian inference</chapter-title>. In: <name name-style="western"><surname>Trommershauser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kording</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>, editors. <source>Sensory Cue Integration</source>. <publisher-name>Oxford University Press</publisher-name>. pp. <fpage>251</fpage>–<lpage>262</lpage>.</mixed-citation></ref>
<ref id="pbio.1002075.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kersten</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Mamassian</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Yuille</surname> <given-names>A</given-names></name> (<year>2004</year>) <article-title>Object perception as Bayesian inference</article-title>. <source>Annu Rev Psychol</source> <volume>55</volume>: <fpage>271</fpage>–<lpage>304</lpage>. <object-id pub-id-type="pmid">14744217</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name> (<year>2007</year>) <article-title>Learning to integrate arbitrary signals from vision and touch</article-title>. <source>J Vis</source> <volume>7</volume>: <fpage>7 1</fpage>–<lpage>14</lpage>.</mixed-citation></ref>
<ref id="pbio.1002075.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name> (<year>2002</year>) <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title>. <source>Nature</source> <volume>415</volume>: <fpage>429</fpage>–<lpage>433</lpage>. <object-id pub-id-type="pmid">11807554</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Rahmati</surname> <given-names>M</given-names></name> (<year>2013</year>) <article-title>Towards a neural implementation of causal inference in cue combination</article-title>. <source>Multisens Res</source> <volume>26</volume>: <fpage>159</fpage>–<lpage>176</lpage>. <object-id pub-id-type="pmid">23713204</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Deneve</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Duhamel</surname> <given-names>JR</given-names></name> (<year>2002</year>) <article-title>A computational perspective on the neural basis of multisensory spatial representations</article-title>. <source>Nat Rev Neurosci</source> <volume>3</volume>: <fpage>741</fpage>–<lpage>747</lpage>. <object-id pub-id-type="pmid">12209122</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fetsch</surname> <given-names>CR</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name> (<year>2013</year>) <article-title>Bridging the gap between theories of sensory cue integration and the physiology of multisensory neurons</article-title>. <source>Nat Rev Neurosci</source> <volume>14</volume>: <fpage>429</fpage>–<lpage>442</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn3503" xlink:type="simple">10.1038/nrn3503</ext-link></comment> <object-id pub-id-type="pmid">23686172</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kording</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Beierholm</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Quartz</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tenenbaum</surname> <given-names>JB</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Causal inference in multisensory perception</article-title>. <source>PLoS ONE</source> <volume>2</volume>: <fpage>e943</fpage>. <object-id pub-id-type="pmid">17895984</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beierholm</surname> <given-names>UR</given-names></name>, <name name-style="western"><surname>Quartz</surname> <given-names>SR</given-names></name>, <name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name> (<year>2009</year>) <article-title>Bayesian priors are encoded independently from likelihoods in human multisensory perception</article-title>. <source>J Vis</source> <volume>9</volume>: <fpage>23</fpage>.<fpage>21</fpage>–<lpage>29</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/9.12.23" xlink:type="simple">10.1167/9.12.23</ext-link></comment> <object-id pub-id-type="pmid">20053114</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wozny</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Beierholm</surname> <given-names>UR</given-names></name>, <name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name> (<year>2010</year>) <article-title>Probability matching as a computational strategy used in perception</article-title>. <source>PLoS Comput Biol</source> <volume>6</volume>: <fpage>e1000871</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000871" xlink:type="simple">10.1371/journal.pcbi.1000871</ext-link></comment> <object-id pub-id-type="pmid">20700493</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name>, <name name-style="western"><surname>Connolly</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Guntupalli</surname> <given-names>JS</given-names></name> (<year>2014</year>) <article-title>Decoding Neural Representational Spaces Using Multivariate Pattern Analysis</article-title>. <source>Annual Review of Neuroscience</source> <volume>37</volume>: <fpage>435</fpage>–<lpage>456</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev-neuro-062012-170325" xlink:type="simple">10.1146/annurev-neuro-062012-170325</ext-link></comment> <object-id pub-id-type="pmid">25002277</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kayser</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Logothetis</surname> <given-names>NK</given-names></name>, <name name-style="western"><surname>Panzeri</surname> <given-names>S</given-names></name> (<year>2010</year>) <article-title>Visual enhancement of the information representation in auditory cortex</article-title>. <source>Curr Biol</source> <volume>20</volume>: <fpage>19</fpage>–<lpage>24</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2009.10.068" xlink:type="simple">10.1016/j.cub.2009.10.068</ext-link></comment> <object-id pub-id-type="pmid">20036538</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schroeder</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Lakatos</surname> <given-names>P</given-names></name> (<year>2009</year>) <article-title>Low-frequency neuronal oscillations as instruments of sensory selection</article-title>. <source>Trends Neurosci</source> <volume>32</volume>: <fpage>9</fpage>–<lpage>18</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tins.2008.09.012" xlink:type="simple">10.1016/j.tins.2008.09.012</ext-link></comment> <object-id pub-id-type="pmid">19012975</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stein</surname> <given-names>BE</given-names></name>, <name name-style="western"><surname>Burr</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Constantinidis</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Laurienti</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Alex Meredith</surname> <given-names>M</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Semantic confusion regarding the development of multisensory integration: a practical solution</article-title>. <source>Eur J Neurosci</source> <volume>31</volume>: <fpage>1713</fpage>–<lpage>1720</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1460-9568.2010.07206.x" xlink:type="simple">10.1111/j.1460-9568.2010.07206.x</ext-link></comment> <object-id pub-id-type="pmid">20584174</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shamma</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Fritz</surname> <given-names>J</given-names></name> (<year>2014</year>) <article-title>Adaptive auditory computations</article-title>. <source>Curr Opin Neurobiol</source> <volume>25</volume>: <fpage>164</fpage>–<lpage>168</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2014.01.011" xlink:type="simple">10.1016/j.conb.2014.01.011</ext-link></comment> <object-id pub-id-type="pmid">24525107</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Talsma</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Senkowski</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Soto-Faraco</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Woldorff</surname> <given-names>MG</given-names></name> (<year>2010</year>) <article-title>The multifaceted interplay between attention and multisensory integration</article-title>. <source>Trends Cogn Sci</source> <volume>14</volume>: <fpage>400</fpage>–<lpage>410</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2010.06.008" xlink:type="simple">10.1016/j.tics.2010.06.008</ext-link></comment> <object-id pub-id-type="pmid">20675182</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rigotti</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Barak</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Warden</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>XJ</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>The importance of mixed selectivity in complex cognitive tasks</article-title>. <source>Nature</source> <volume>497</volume>: <fpage>585</fpage>–<lpage>590</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature12160" xlink:type="simple">10.1038/nature12160</ext-link></comment> <object-id pub-id-type="pmid">23685452</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref027"><label>27</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Kayser</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Lakatos</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Meredith</surname> <given-names>MA</given-names></name> (<year>2012</year>) <chapter-title>Cellular Physiology of Cortical Multisensory Processing</chapter-title>. In: <name name-style="western"><surname>Stein</surname> <given-names>BE</given-names></name>, editor. <source>The New Handbook of Multisensory Processing</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>. pp. <fpage>115</fpage>–<lpage>134</lpage>.</mixed-citation></ref>
<ref id="pbio.1002075.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dahl</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Logothetis</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Kayser</surname> <given-names>C</given-names></name> (<year>2009</year>) <article-title>Spatial Organization of Multisensory Responses in Temporal Association Cortex</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>11924</fpage>–<lpage>11932</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3437-09.2009" xlink:type="simple">10.1523/JNEUROSCI.3437-09.2009</ext-link></comment> <object-id pub-id-type="pmid">19776278</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>Shimojo</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>O'Doherty</surname> <given-names>JP</given-names></name> (<year>2014</year>) <article-title>Neural computations underlying arbitration between model-based and model-free learning</article-title>. <source>Neuron</source> <volume>81</volume>: <fpage>687</fpage>–<lpage>699</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2013.11.028" xlink:type="simple">10.1016/j.neuron.2013.11.028</ext-link></comment> <object-id pub-id-type="pmid">24507199</object-id></mixed-citation></ref>
<ref id="pbio.1002075.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Payzan-LeNestour</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Dunne</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bossaerts</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>O'Doherty</surname> <given-names>JP</given-names></name> (<year>2013</year>) <article-title>The neural representation of unexpected uncertainty during value-based decision making</article-title>. <source>Neuron</source> <volume>79</volume>: <fpage>191</fpage>–<lpage>201</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2013.04.037" xlink:type="simple">10.1016/j.neuron.2013.04.037</ext-link></comment> <object-id pub-id-type="pmid">23849203</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005684</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-00488</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Behavior</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Analysis of variance</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Analysis of variance</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Learning curves</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Learning curves</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Learning curves</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject><subj-group><subject>Learning curves</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Optimization</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Economics</subject><subj-group><subject>Economic history</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Confirmation bias in human reinforcement learning: Evidence from counterfactual feedback processing</article-title>
<alt-title alt-title-type="running-head">Confirmation bias in human reinforcement learning</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5768-6646</contrib-id>
<name name-style="western">
<surname>Palminteri</surname>
<given-names>Stefano</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Lefebvre</surname>
<given-names>Germain</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0360-3769</contrib-id>
<name name-style="western">
<surname>Kilford</surname>
<given-names>Emma J.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Blakemore</surname>
<given-names>Sarah-Jayne</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Institute of Cognitive Neuroscience, University College London, London, United Kingdom</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Laboratoire de Neurosciences Cognitives, Institut National de la Santé et de la Recherche Médicale, Paris, FR</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Departement d’Études Cognitives, École Normale Supérieure, Paris, FR</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Institut d’Études de la Cognition, Université de Recherche Paris Sciences et Lettres, Paris, FR</addr-line></aff>
<aff id="aff005"><label>5</label> <addr-line>Laboratoire d’Économie Mathématique et de Microéconomie Appliquée, Université Panthéon-Assas, Paris, FR</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Haith</surname>
<given-names>Adrian M.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Johns Hopkins University, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">stefano.palminteri@ens.fr</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>11</day>
<month>8</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="collection">
<month>8</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>8</issue>
<elocation-id>e1005684</elocation-id>
<history>
<date date-type="received">
<day>29</day>
<month>3</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>14</day>
<month>7</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Palminteri et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005684"/>
<abstract>
<p>Previous studies suggest that <italic>factual</italic> learning, that is, learning from obtained outcomes, is biased, such that participants preferentially take into account positive, as compared to negative, prediction errors. However, whether or not the prediction error valence also affects <italic>counterfactual</italic> learning, that is, learning from forgone outcomes, is unknown. To address this question, we analysed the performance of two groups of participants on reinforcement learning tasks using a computational model that was adapted to test if prediction error valence influences learning. We carried out two experiments: in the factual learning experiment, participants learned from partial feedback (i.e., the outcome of the chosen option only); in the counterfactual learning experiment, participants learned from complete feedback information (i.e., the outcomes of both the chosen and unchosen option were displayed). In the factual learning experiment, we replicated previous findings of a valence-induced bias, whereby participants learned preferentially from positive, relative to negative, prediction errors. In contrast, for counterfactual learning, we found the opposite valence-induced bias: negative prediction errors were preferentially taken into account, relative to positive ones. When considering valence-induced bias in the context of both factual and counterfactual learning, it appears that people tend to preferentially take into account information that confirms their current choice.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>While the investigation of decision-making biases has a long history in economics and psychology, learning biases have been much less systematically investigated. This is surprising as most of the choices we deal with in everyday life are recurrent, thus allowing learning to occur and therefore influencing future decision-making. Combining behavioural testing and computational modeling, here we show that the valence of an outcome biases both factual and counterfactual learning. When considering factual and counterfactual learning together, it appears that people tend to preferentially take into account information that confirms their current choice. Increasing our understanding of learning biases will enable the refinement of existing models of value-based decision-making.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>European Research Council (BE)</institution>
</funding-source>
<award-id>PIEF-GA-2012 Grant 328822</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Blakemore</surname>
<given-names>Sarah-Jayne</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>ATIP-Avenir grant</institution>
</funding-source>
<award-id>R16069JS</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5768-6646</contrib-id>
<name name-style="western">
<surname>Palminteri</surname>
<given-names>Stefano</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution>Collaborative Research in Computational Neuroscience ANR-NSF grant</institution>
</funding-source>
<award-id>ANR-16-NEUC-0004</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5768-6646</contrib-id>
<name name-style="western">
<surname>Palminteri</surname>
<given-names>Stefano</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution>Jacobs Foundation</institution>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Blakemore</surname>
<given-names>Sarah-Jayne</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award005">
<funding-source>
<institution>Royal Society University Research Fellowship</institution>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Blakemore</surname>
<given-names>Sarah-Jayne</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>SP and the study were supported by a Marie Sklodowska-Curie Individual European Fellowship (PIEF-GA-2012 Grant 328822). SP is currently supported by an ATIP-Avenir grant (R16069JS) Collaborative Research in Computational Neuroscience ANR-NSF grant (ANR-16-NEUC-0004). GL was supported by a PHD fellowship of the Ministère de l'enseignement supérieur et de la recherche. EJK is supported by a Medical Research Council studentship. SJB is funded by a Royal Society University Research Fellowship, the Wellcome Trust and the Jacobs Foundation. The Institut d’Etude de la Cognition is supported financially by the LabEx IEC (ANR-10-LABX-0087 IEC) and the IDEX PSL* (ANR-10-IDEX-0001-02 PSL*). The funders had no role in the conceptualization, design, data collection, analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="1"/>
<page-count count="22"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2017-08-23</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data are available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.4265408.v1" xlink:type="simple">https://dx.doi.org/10.6084/m9.figshare.4265408.v1</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Goal-directed behaviour is composed of two core components [<xref ref-type="bibr" rid="pcbi.1005684.ref001">1</xref>]: one component is the decision-making process that starts with representing the available options and terminates in selecting the option with the highest expected value; the second component is reinforcement learning (RL), through which outcomes are used to refine value expectations, in order to improve decision-making. Human decision-making is subject to biases (i.e. deviations from the normative prescriptions), such as the framing effect [<xref ref-type="bibr" rid="pcbi.1005684.ref002">2</xref>]. While the investigation of decision-making biases has a long history in economics and psychology, learning biases have been much less systematically investigated [<xref ref-type="bibr" rid="pcbi.1005684.ref003">3</xref>]. This is surprising as most of the decisions we deal with in everyday life are experience-based and choice contexts are recurrent, thus allowing learning to occur and therefore influencing future decision-making. In addition, it is important to investigate learning biases as there is evidence that RL processes play a role in psychiatric conditions and maladaptive economic behaviour [<xref ref-type="bibr" rid="pcbi.1005684.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref005">5</xref>].</p>
<p>Standard RL algorithms learn action-outcome associations directly from obtained outcomes on a trial and error basis [<xref ref-type="bibr" rid="pcbi.1005684.ref006">6</xref>]. We refer to this direct form of learning as “factual learning”. Despite the fact that standard models, built around the notion of computational and statistical optimality, prescribe that an agent should learn equally well from positive and negative obtained outcomes [<xref ref-type="bibr" rid="pcbi.1005684.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1005684.ref009">9</xref>], previous studies have consistently shown that humans display a significant valence-induced bias. This bias generally goes in the direction of preferential learning from positive, compared to negative, outcome prediction errors [<xref ref-type="bibr" rid="pcbi.1005684.ref010">10</xref>–<xref ref-type="bibr" rid="pcbi.1005684.ref014">14</xref>]. This learning asymmetry could represent a RL counterpart of the “good news/bad news” effect that is observed for probabilistic reasoning [<xref ref-type="bibr" rid="pcbi.1005684.ref015">15</xref>].</p>
<p>However, human RL cannot be reduced simply to learning from obtained outcomes. Other sources of information can be successfully integrated in order to improve performance and RL has a multi-modular structure [<xref ref-type="bibr" rid="pcbi.1005684.ref016">16</xref>]. Amongst the more sophisticated learning processes that have already been demonstrated in humans is counterfactual learning. Counterfactual learning refers to the ability to learn from forgone outcomes (i.e. the outcomes of the option(s) that were not chosen) [<xref ref-type="bibr" rid="pcbi.1005684.ref017">17</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref018">18</xref>]. Whether or not a valence-induced bias also affects counterfactual learning remains unknown.</p>
<p>To address this question, we ran two experiments involving instrumental learning and computational model-based analyses. Two groups of healthy adults performed variants of a repeated two-armed bandit task involving probabilistic outcomes [<xref ref-type="bibr" rid="pcbi.1005684.ref019">19</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref020">20</xref>] (<bold><xref ref-type="fig" rid="pcbi.1005684.g001">Fig 1A</xref></bold>). We analysed the data using a modified Rescorla-Wagner model that assumes different learning rates for positive and negative, and factual and counterfactual, prediction errors (<bold><xref ref-type="fig" rid="pcbi.1005684.g001">Fig 1B</xref></bold>) [<xref ref-type="bibr" rid="pcbi.1005684.ref021">21</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref022">22</xref>].</p>
<fig id="pcbi.1005684.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005684.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Behavioural task variants and computational model.</title>
<p>(A) Behavioural task variants. In Experiment 1 (leftmost panel) participants were shown only the outcome of the chosen option. In Experiment 2 (rightmost panel) participants were shown the outcome of both the chosen and the unchosen options. (B) Computational models. The schematic summarises the value update stage of our computational model. The model contains two computational modules, a factual learning module (in red) to learn from chosen outcomes (R<sub>C</sub>) and a counterfactual learning module (in blue) to learn from unchosen outcomes (R<sub>U</sub>) (note that the counterfactual learning module does not apply to Experiment 1). Chosen (Q<sub>C</sub>) and unchosen (Q<sub>U</sub>) option values are updated with delta rules that use different learning rates for positive and negative factual (PE<sub>C</sub>) and counterfactual prediction errors (PE<sub>U</sub>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005684.g001" xlink:type="simple"/>
</fig>
<p>The first experiment aimed to replicate previous findings of a “positivity bias” at the level of factual learning. In this first experiment, participants were presented only with the obtained outcome (chosen outcome: R<sub>C</sub>; <bold><xref ref-type="fig" rid="pcbi.1005684.g001">Fig 1A</xref></bold>) [<xref ref-type="bibr" rid="pcbi.1005684.ref010">10</xref>]. In the second experiment, in order to investigate whether or not counterfactual learning rates are also affected by the valence of prediction errors, we used a variant of the same instrumental learning task, in which participants were also presented with the forgone outcome (unchosen outcome: R<sub>U</sub>; <bold><xref ref-type="fig" rid="pcbi.1005684.g001">Fig 1B</xref></bold>). Our design allowed us to test three competing hypotheses concerning the effect of valence on counterfactual learning (<bold><xref ref-type="fig" rid="pcbi.1005684.g002">Fig 2A</xref></bold>). The first hypothesis–“no bias”—was that unlike factual learning, counterfactual learning would be unbiased. The second hypothesis,—“positivity bias”—was that factual and counterfactual learning would present the same valence-induced bias, such that positive counterfactual prediction errors would be more likely to be taken into account than negative counterfactual prediction errors. In this scenario, factual and counterfactual learning biases would be consequences of a more general positivity bias, in which positive prediction errors have a greater impact on learning, regardless of whether the option was chosen or not. Finally, the third hypothesis–“confirmation bias”—was that valence would affect factual and counterfactual learning in opposing directions, such that negative unchosen prediction errors would be more likely to be taken into account than positive unchosen prediction errors. In this scenario, factual and counterfactual learning biases would be consequences of a more general confirmation bias, in which outcomes that support the current choice are preferentially taken into account.</p>
<fig id="pcbi.1005684.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005684.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Factual and counterfactual learning biases.</title>
<p>(A) Predicted results. Based on previous studies we expected that in Experiment 1 factual learning would display a “positivity” bias (i.e. the learning rate for the chosen positive outcomes would be relatively higher than that of the chosen negative outcomes (<inline-formula id="pcbi.1005684.e001"><alternatives><graphic id="pcbi.1005684.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>; note that in Experiment 1 the “positivity” and the “confirmation” bias are not discernible). In Experiment 2, one possibility was that this “positivity” bias would extend to counterfactual learning, whereby positive outcomes would be over-weighted regardless of whether the outcome was chosen or unchosen (“valence” bias) (<inline-formula id="pcbi.1005684.e002"><alternatives><graphic id="pcbi.1005684.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>). Another possibility was that counterfactual learning would present an opposite bias, whereby the learning rate for unchosen negative outcomes was higher than the learning rate of unchosen positive outcomes (<inline-formula id="pcbi.1005684.e003"><alternatives><graphic id="pcbi.1005684.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) (“confirmation” bias). (B) Actual results. Learning rate analysis of Experiment 1 data replicated previous findings, demonstrating that factual learning presents a “positivity” bias. Learning rate analysis of Experiment 2 indicated that counterfactual learning was also biased, in a direction that was consistent with a “confirmation” bias. ***<italic>P</italic>&lt;0.001 and *<italic>P</italic>&lt;0.05, two-tailed paired t-test.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005684.g002" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Behavioural task and full computational model</title>
<p>To investigate both factual and counterfactual reinforcement learning biases, we designed an instrumental task based on a previous paradigm, in which we showed a significant positivity bias in factual learning [<xref ref-type="bibr" rid="pcbi.1005684.ref010">10</xref>]. Here, we used two variants of the task, which differed in that the task used in Experiment 1 involved participants (N = 20) being shown only the outcome of their chosen option, whereas in Experiment 2 (N = 20) the outcome of the unchosen option was also displayed (<bold><xref ref-type="fig" rid="pcbi.1005684.g001">Fig 1A</xref></bold>). To test our hypotheses concerning valence-induced learning biases (<bold><xref ref-type="fig" rid="pcbi.1005684.g002">Fig 2A</xref></bold>) we fitted the data with a Rescorla-Wagner model assuming different learning rates for positive and negative outcomes, which respectively elicit positive and negative prediction errors (<bold><xref ref-type="fig" rid="pcbi.1005684.g001">Fig 1B</xref></bold>). The algorithm used to explain Experiment 1 data involved two learning rates for obtained outcomes (<inline-formula id="pcbi.1005684.e004"><alternatives><graphic id="pcbi.1005684.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005684.e005"><alternatives><graphic id="pcbi.1005684.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> for positive and negative prediction errors of the obtained outcomes, respectively). In addition to the obtained outcome learning rates, the algorithm used to explain Experiment 2 data also involved two learning rates for forgone outcomes (<inline-formula id="pcbi.1005684.e006"><alternatives><graphic id="pcbi.1005684.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005684.e007"><alternatives><graphic id="pcbi.1005684.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> for positive and negative prediction errors of the forgone outcomes, respectively).</p>
</sec>
<sec id="sec004">
<title>Learning rate analysis</title>
<p>Replicating previous findings, in Experiment 1 we found that the positive factual learning rate (<inline-formula id="pcbi.1005684.e008"><alternatives><graphic id="pcbi.1005684.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) was significantly higher than the negative one (<inline-formula id="pcbi.1005684.e009"><alternatives><graphic id="pcbi.1005684.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>; T(19) = 2.4; P = 0.03) (<bold><xref ref-type="fig" rid="pcbi.1005684.g002">Fig 2B</xref></bold>, left). In Experiment 2, we analysed learning rates using a repeated-measure ANOVA with prediction error valence (positive or negative) and prediction error type (factual or counterfactual) as within-subjects factors. Falsifying the “positivity bias” hypothesis, the ANOVA revealed no main effect of prediction error valence (F(1,19) = 0.2; P&gt;0.6). We also did not find any effect of prediction error type, indicating that, on average, factual and counterfactual learning were similar (F(1,19) = 0.5; P&gt;0.4). Consistent with the “confirmation bias” hypothesis, we found a significant interaction between valence and type (F(1,19) = 119.2; P = 1.3e-9). Post-hoc tests indicated that the interaction was driven by effects of valence on both factual (<inline-formula id="pcbi.1005684.e010"><alternatives><graphic id="pcbi.1005684.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>; T(19) = 3.6; P = 0.0017) and counterfactual learning rates (<inline-formula id="pcbi.1005684.e011"><alternatives><graphic id="pcbi.1005684.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>; T(19) = 6.2; P = 5.8e-06) (<bold><xref ref-type="fig" rid="pcbi.1005684.g002">Fig 2B</xref>,</bold> right).</p>
<p>To verify the robustness of this result in the context of different reward contingencies, we analysed learning rates in each task condition separately. In both experiments, our task included three different conditions (<bold><xref ref-type="supplementary-material" rid="pcbi.1005684.s001">S1 Fig</xref></bold>): a “Symmetric” condition, in which both options were associated with a 50% chance of getting a reward; an “Asymmetric” condition, in which one option was associated with a 75% chance of getting a reward, whereas the other option was associated with only a 25% chance; and a “Reversal” condition, in which one option was initially associated with a 83% chance of getting a reward and the other option was associated with a 17% chance of getting a reward, but after 12 trials the reward contingencies were reversed. For Experiment 1, we analysed factual learning rates using a repeated-measure ANOVA with prediction error valence (positive and negative) and task condition (Symmetric, Asymmetric and Reversal) as within-subjects factors (<bold><xref ref-type="supplementary-material" rid="pcbi.1005684.s001">S1B Fig</xref></bold>). Confirming the aggregate result, the ANOVA showed a significant main effect of valence (F(1,19) = 26.4, P = 5.8e-5), but no effect of condition (F(2,38) = 0.7, P&gt;0.5), and, crucially, no valence by condition interaction (F(2,38) = 0.8, P&gt;0.4). For Experiment 2, we analysed factual and counterfactual learning rates using a repeated-measure ANOVA with prediction error valence (positive and negative), prediction error type (factual or counterfactual) and condition (Symmetric, Asymmetric and Reversal) as within-subjects factors (<bold><xref ref-type="supplementary-material" rid="pcbi.1005684.s001">S1C Fig</xref></bold>). Confirming the aggregate result, the ANOVA showed no effect of prediction error type (F(1,19) = 0.0, P&gt;0.9), no effect of valence (F(1,19) = 0.3, P&gt;0.5), but a significant valence by type interaction (F(1,19) = 162.9, P = 9.1e-11). We also found an effect of condition (F(2,38) = 5.1, P = 0.01), reflecting lower average learning rates in the Reversal compared to the Asymmetric condition (T(19) = 2.99; P = 0.007), which was not modulated by valence (F(2,38) = 0.2, P&gt;0.7), or type (F(2,38) = 1.2, P&gt;0.3). The three-way interaction was not significant (F(2,38) = 1.8, P&gt;.1), indicating that learning biases were robust across different task contingencies.</p>
</sec>
<sec id="sec005">
<title>Dimensionality reduction with model comparison</title>
<p>To further test our hypotheses and verify theparsimony of our findings, we ran a model comparison analysis including the ‘Full’ model (i.e., the model with four learning rates; <bold><xref ref-type="fig" rid="pcbi.1005684.g001">Fig 1C</xref>,</bold> right) and reduced, alternative versions of it (<bold><xref ref-type="fig" rid="pcbi.1005684.g003">Fig 3A</xref></bold>). The first alternative model was obtained by reducing the number of learning rates along the dimension of the outcome type (factual or counterfactual). This ‘Information’ model has only two learning rates: one for the obtained outcomes (α<sub>C</sub>) and another for the forgone outcomes (α<sub>U</sub>). The second alternative model was obtained by reducing the number of learning rates along the dimension of the outcome valence (positive or negative). This ‘Valence’ model has only two learning rates (one for the positive outcomes (α<sub>+</sub>) and another for the negative outcomes (α<sub>-</sub>)) and should win according to the “positivity bias” hypothesis. Finally, the third alternative model was obtained by reducing the learning rate as a function of the outcome event being confirmatory (positive obtained or negative forgone) or disconfirmatory (negative obtained or positive forgone). This ‘Confirmation’ model has only two learning rates (one for confirmatory outcomes (α<sub>CON</sub>) and another for the disconfirmatory outcomes (α<sub>DIS</sub>)) and should win according to the “confirmation bias” hypothesis.</p>
<fig id="pcbi.1005684.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005684.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Dimensionality reduction with model comparison.</title>
<p>(A) Model space. The figure represents how the number of parameters (learning rates) are reduced moving from the ‘Full’ model to more simple ones. (B) Model comparison. The panel represents the posterior probability (PP) of the models, the calculation of which is based on the BIC, which penalisses model complexity. The dashed line represents random posterior probability (0.25). (C) Model parameters. The panel represents the learning rate for the best fitting model (i.e., the ‘Confirmation’) model. α<sub>CON</sub>: learning rate for positive obtained and negative forgone outcomes; α<sub>DIS</sub>: learning rate for negative obtained and positive forgone outcomes. ***<italic>P</italic>&lt;0.001, two-tailed paired t-test.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005684.g003" xlink:type="simple"/>
</fig>
<p>Bayesian Information Criterion (BIC) analysis indicated that the ‘Full’ model better accounted for the data compared to both the ‘Information’ and the ‘Valence’ models (both comparisons: T(19)&gt;4.2; P&lt;0.0005; <bold><xref ref-type="table" rid="pcbi.1005684.t001">Table 1</xref></bold>). However the ‘Confirmation’ model better accounted for the data compared to the ‘Full’ model (T(19) = 9.9; P = 6.4e-9). The posterior probability (PP) of belonging to each model, calculated for each subject, (i.e., the averaged individual model attributions) of the ‘Confirmation’ model was higher than chance (.0.25 for a model space including 4 models; T(19) = 13.5; P = 3.3e-11) and higher than the posterior probability all the other models (all comparisons: T(19)&gt;9.0; P&lt;2.1e-8) (<bold><xref ref-type="fig" rid="pcbi.1005684.g003">Fig 3B</xref></bold>). The learning rate for confirmatory outcomes was significantly higher than that for disconfirmatory outcomes (α<sub>CON</sub>&gt;α<sub>DIS</sub>; T(19) = 11.7; P = 3.9e-10) (<bold><xref ref-type="fig" rid="pcbi.1005684.g003">Fig 3C</xref></bold>). These results support the “confirmation bias” hypothesis and further indicate that, at least at the behavioural level, chosen and unchosen outcomes may be processed by the same learning systems.</p>
<table-wrap id="pcbi.1005684.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005684.t001</object-id>
<label>Table 1</label> <caption><title>Model comparison.</title> <p>The “winning” model is the “Confirmation” model for which the learning rates are displayed in <bold><xref ref-type="fig" rid="pcbi.1005684.g003">Fig 3C</xref></bold>. The second best model is the Full model, for which the learning rates are displayed in <bold><xref ref-type="fig" rid="pcbi.1005684.g002">Fig 2B</xref></bold>.</p></caption>
<alternatives>
<graphic id="pcbi.1005684.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005684.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Model</th>
<th align="center">Full (5df)</th>
<th align="center">Information (3df)</th>
<th align="center">Valence (3df)</th>
<th align="center">Confirmation (3df)</th>
<th align="center">Perseveration (4df)</th>
<th align="center">One (2df)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><bold>BIC</bold></td>
<td align="center">162.0±13.4</td>
<td align="center">178.2±13.0</td>
<td align="center">180.7±11.8</td>
<td align="center">155.0±13.2</td>
<td align="center">165.2±13.6</td>
<td align="center">179.1±11.8</td>
</tr>
<tr>
<td align="center"><bold>PP</bold></td>
<td align="center">0.02±0.02</td>
<td align="center">0.00±0.00</td>
<td align="center">0.05±0.05</td>
<td align="center">0.89±0.06</td>
<td align="center">0.01±0.01</td>
<td align="center">0.04±0.03</td>
</tr>
<tr>
<td align="center"><bold>XP</bold></td>
<td align="center">0.00</td>
<td align="center">0.0</td>
<td align="center">0.0</td>
<td align="center">1.0</td>
<td align="center">0.0</td>
<td align="center">0.0</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p>BIC: Bayesian Information Criterion; PP: posterior probability; XP: exceedance probability; df: degrees of freedom.</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec006">
<title>Comparison between the learning curves and the model estimates</title>
<p>To evaluate the capacity of our models to reproduce the learning curves, we plotted and analysed the trial-by-trial model estimates of choice probabilities (<bold><xref ref-type="fig" rid="pcbi.1005684.g004">Fig 4</xref></bold>) [<xref ref-type="bibr" rid="pcbi.1005684.ref023">23</xref>]. The model estimates were generated using the best fitting set of parameters for each individual and model. In the Symmetric condition (where there is no correct response), we considered the preferred option choice rate (i.e., the option/symbol that was chosen more than &gt;50%). In the Asymmetric condition we considered the correct choice rate. In the Reversal condition (where the correct response is reversed after the first half of the trials) we considered the choice rate of the initially more advantageous option (i.e., the correct option during the first half). Qualitative observation of the learning curves indicated that the biased models (Experiment 1: <inline-formula id="pcbi.1005684.e012"><alternatives><graphic id="pcbi.1005684.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>≠</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>; Experiment 2: α<sub>CON</sub>≠α<sub>DIS</sub>) tended to reproduce the learning curves more closely. To quantify this, we compared the average square distance between the biased and the unbiased models (Experiment 1: <inline-formula id="pcbi.1005684.e013"><alternatives><graphic id="pcbi.1005684.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>; Experiment 2: α<sub>CON</sub> = α<sub>DIS</sub>). We found that the square distance was shorter for the biased models compared to the unbiased models in both experiments (Experiment 1: 0.074 vs. 0.085, T(19) = 3.5 P = 0.0022; Experiment 2: 0.056 vs. 0.064, T(19) = 3.5 P = 0.0016).</p>
<fig id="pcbi.1005684.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005684.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Learning curves and model estimates.</title>
<p>(A) Task conditions. (B) and (C) Learning curves as a function of the task conditions in Experiment 1 and Experiment 2, respectively. Each panel displays the result of the corresponding condition presented in (A). The black dots and the error bars represent the actual data ± s.e.m. The green lines represent the model estimates of the biased models (Experiment 1: <inline-formula id="pcbi.1005684.e014"><alternatives><graphic id="pcbi.1005684.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>≠</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>; Experiment 2:α<sub>CON</sub>≠α<sub>DIS</sub>), the grey lines represent the model estimates of the unbiased models (Experiment 1: <inline-formula id="pcbi.1005684.e015"><alternatives><graphic id="pcbi.1005684.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>; Experiment 2: α<sub>CON</sub> = α<sub>DIS</sub>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005684.g004" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec007">
<title>Parameter correlation and parameter recovery</title>
<p>We calculated the Pearson correlation between the parameters (<bold><xref ref-type="fig" rid="pcbi.1005684.g005">Fig 5A</xref></bold>) and found no significant correlation when correcting for multiple comparisons (corrected P value = 0.05÷6 = 0.008; lowest uncorrected P value = 0.01, highest P<sup>2</sup> = 0.30). The correlation between α<sub>CON</sub> and α<sub>DIS</sub> was weak, but positive, which rules out the possibility that the significant difference between these two learning rates was driven by an anti-correlation induced by the model fitting procedure.</p>
<fig id="pcbi.1005684.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005684.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Parameter correlation and recovery.</title>
<p>(A) Correlation matrix of the free parameters for Experiment 1 (left) and Experiment 2 (right). Dark blue or dark red values of R indicate a strong correlation and therefore a problem in parameter identifiability. (B) Correlation matrix of the free parameters used to generate the simulated data (‘Fitted on real data’) and obtained by applying the parameter estimation procedure on the simulated data (‘Fitted on simulated data’). Dark red values of R indicate a strong correlation between the true and the retrieved parameter value and therefore a good parameter recovery.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005684.g005" xlink:type="simple"/>
</fig>
<p>We then applied the same model fitting procedure to the synthetic datasets and calculated the correlation between the true and the retrieved parameters (<bold><xref ref-type="fig" rid="pcbi.1005684.g005">Fig 5B</xref></bold>). We found that, on average, all parameters in both experiments were well recovered (0.70 ≤ R ≤ 0.89) and that our model fitting procedure introduced no spurious correlations between the other parameters (|R| ≤ 0.5).</p>
<p>We also checked the parameter recovery for discrete sets of parameter values (<bold><xref ref-type="supplementary-material" rid="pcbi.1005684.s002">S2</xref> </bold>&amp; <bold><xref ref-type="supplementary-material" rid="pcbi.1005684.s003">S3</xref> Figs</bold>). For Experiment 1, we simulated unbiased (<inline-formula id="pcbi.1005684.e016"><alternatives><graphic id="pcbi.1005684.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) and biased (<inline-formula id="pcbi.1005684.e017"><alternatives><graphic id="pcbi.1005684.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) participants. For Experiment 2, we simulated unbiased (<inline-formula id="pcbi.1005684.e018"><alternatives><graphic id="pcbi.1005684.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005684.e019"><alternatives><graphic id="pcbi.1005684.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>), semi-biased (<inline-formula id="pcbi.1005684.e020"><alternatives><graphic id="pcbi.1005684.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005684.e021"><alternatives><graphic id="pcbi.1005684.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) and biased (<inline-formula id="pcbi.1005684.e022"><alternatives><graphic id="pcbi.1005684.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005684.e023"><alternatives><graphic id="pcbi.1005684.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) participants. We simulated N = 100 virtual participants per set of parameters. The results of these analyses are presented in the supplementary materials and confirm the capacity of our parameter optimisation procedure to correctly recover the true parameters, regardless of the presence (or absence) of learning rate biases.</p>
</sec>
<sec id="sec008">
<title>Behavioural signatures of learning biases</title>
<p>To investigate the behavioural consequences of the learning biases, we median-split the participants from each experiment into two groups according to their normalised learning rate differences. We reasoned that the effects of learning biases on behavioural performance could be highlighted by comparing participants who differed in the extent they expressed the bias itself. Experiment 1 participants were split according to their normalised factual learning rate bias: <inline-formula id="pcbi.1005684.e024"><alternatives><graphic id="pcbi.1005684.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, from which we obtained a high (M = 0.76±0.05) and a low bias (M = 0.11±0.14) group. Experiment 2 participants were split according their normalised confirmation bias: <inline-formula id="pcbi.1005684.e025"><alternatives><graphic id="pcbi.1005684.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mo>[</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>]</mml:mo><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, from which we also obtained a high bias group (M = 0.72±0.04) and a low bias group (M = 0.36±0.04).</p>
<p>From the Symmetric condition we extracted preferred choice rate as a dependent variable, which was the choice rate of the most frequently chosen option (i.e. the option that was chosen on &gt;50% of trials) (<bold><xref ref-type="fig" rid="pcbi.1005684.g006">Fig 6A</xref></bold>). We hypothesised that higher biases were associated with an increased tendency to develop a preferred choice, even in the absence of a “correct” option, which naturally emerges from overweighting positive factual (and/or negative counterfactual) outcomes, as observed in our previous study [<xref ref-type="bibr" rid="pcbi.1005684.ref010">10</xref>]. We submitted the preferred choice rate to an ANOVA with experiment (1 vs. 2) and bias level (high vs. low) as between-subjects factors. The ANOVA showed a significant main effect of bias level (F(1,36) = 8.8, P = 0.006). There was no significant main effect of experiment (F(1,36) = 0.6, P&gt;0.6) and no significant interaction between experiment and bias level (F(1,36) = 0.3, P&gt;0.5). Replicating previous findings, the main effect of bias level was driven by higher preferred choice rate in the high, compared to the low bias group in both Experiment 1 (T(18) = 1.8 P = 0.08) and Experiment 2 (T(18) = 2.3 P = 0.03) (<bold><xref ref-type="fig" rid="pcbi.1005684.g006">Fig 6B &amp; 6C</xref></bold>).</p>
<fig id="pcbi.1005684.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005684.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Behavioural signatures distinguishing “low” and “high” bias participants.</title>
<p>(A) Task conditions. The ‘Symmetric’ condition was characterised by a stable reward contingency and no correct option, because the two options had equal reward probabilities. The ‘Asymmetric conditions’ were also characterised by a stable reward contingency but had a correct option, since one option had a higher reward probability than the other. The ‘Reversal’ condition was characterised by an unstable reward contingency: after 12 trials the reward probability reversed across symbols, so that the former correct option became the incorrect one, and vice versa. Note that the number of trials refers to one session and participants performed two sessions, each involving new pairs of stimuli (192 trials in total). (B) and (C) Behavioural results as a function of the task conditions in Experiment 1 and Experiment 2, respectively. Each column presents the result of the corresponding condition presented in (A). In the Symmetric condition, where there was no correct option, we calculated the “preferred choice rate”, which was the choice rate of the most frequently chosen option (by definition, this was always greater than 0.5). In the Asymmetric and the Reversal conditions we calculated the correct choice rate. In the Reversal condition the correct choice rate was split between the two learning phases. ***<italic>P</italic>&lt;0.001 and *<italic>P</italic>&lt;0.05, two-tailed paired t-test.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005684.g006" xlink:type="simple"/>
</fig>
<p>From the remaining conditions we extracted the correct choice rate, which was the choice rate of the most frequently rewarded option. In the Reversal condition, correct choice rate was split across the first half of the trial (i.e., before the reversal of the contingencies) and second half (i.e., after the reversal of the contingencies) (<bold><xref ref-type="fig" rid="pcbi.1005684.g006">Fig 6A</xref></bold>). We hypothesised that in the second half of the Reversal condition, where correct choice rate depends on un-learning previous associations based on negative factual prediction errors (and positive counterfactual prediction errors, in Experiment 2), high bias subjects will display reduced performance. We submitted the correct choice rate to a mixed ANOVA with experiment (1 vs. 2) and bias group (high vs. low) as between-subjects factors, and condition (Asymmetric, Reversal: first half, and Reversal: second half) as a within-subjects factor. There was a main effect of experiment (F(1,36) = 4.1, P = 0.05), indicating that correct choice rate was higher in Experiment 2 than Experiment 1, which is consistent with previous studies showing that counterfactual feedback enhances learning[<xref ref-type="bibr" rid="pcbi.1005684.ref020">20</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref024">24</xref>]. We also found a significant effect of bias level (F(1,36) = 10.8, P = 0.002), a significant effect of condition (F(2,72) = 99.5, P = 2.0e-16), and a significant bias level by condition interaction (F(2,72) = 9.6, P = 0.0002). Indeed, in both experiments, the correct choice rate in the second half of the Reversal condition was lower in the high bias compared to the low bias group (Experiment 1: T(18) = 3.9 P = 0.0003; Experiment 2: T(18) = 2.5 P = 0.02) (<bold><xref ref-type="fig" rid="pcbi.1005684.g006">Fig 6B &amp; 6C</xref></bold>).</p>
<p>Importantly, we found that the temperature did not differ between low and high bias subjects in Experiment 1 (low vs. high: 3.38±0.82 vs. 3.78±0.67; T(18) = 0.4, P = 0.7078) or in Experiment 2 (low vs. high. 3.29±0.56 vs. 2.13±0.36; T(18) = 1.7, P = 0.0973). Of note, the difference in temperature goes in two different directions in the two experiments, whereas the behavioural effects (i.e., increased preferred response rate in the Symmetric condition and decreased performance in the second half of the Reversal condition) go in the same direction. Finally, we used Pearson’s correlations to verify that the relevant results remained significant when assessed as continuous variables. As predicted, the normalised learning biases were significantly and positively correlated with the preferred choice rate in the Symmetric condition in both experiments (Experiment 1: R = 0.54, P = 0.013; Experiment 2: R = 0.46, P = 0.040). Similarly, the normalised learning biases were significantly and negatively correlated with the correct choice rate in the second half of the Reversal condition (Experiment 1: R = -0.66, P = 0.0015; Experiment 2: R = -0.47, P = 0.033).</p>
</sec>
</sec>
<sec id="sec009" sec-type="conclusions">
<title>Discussion</title>
<p>Two groups of healthy adult participants performed two variants of an instrumental learning task, involving factual (Experiment 1) and counterfactual (Experiments 1 &amp; 2) reinforcement learning. We found that prediction error valence biased factual and counterfactual learning in opposite directions. Replicating previous findings, we found that, when learning from obtained outcomes (factual learning), the learning rate for positive prediction errors was higher than the learning rate for negative prediction errors. In contrast, when learning from forgone outcomes (counterfactual learning), the learning rate for positive prediction errors was lower than that of negative prediction errors. This result proved stable across different reward contingency conditions and was further supported by model comparison analyses, which indicated that the most parsimonious model was a model with different learning rates for confirmatory and disconfirmatory events, regardless of outcome type (factual or counterfactual) and valence (positive or negative). Finally, behavioural analyses showed that participants with a higher valence-induced learning bias displayed poorer learning performance, specifically when it was necessary to adjust their behaviour in response to a reversal of reward contingencies. These learning biases were therefore significantly associated with reduced learning performance and can be considered maladaptive in the context or our experimental tasks.</p>
<p>Our results demonstrated a factual learning bias, which replicates previous findings by showing that, in simple instrumental learning tasks, participants preferentially learn from positive compared to negative prediction errors [<xref ref-type="bibr" rid="pcbi.1005684.ref011">11</xref>–<xref ref-type="bibr" rid="pcbi.1005684.ref013">13</xref>]. However, in contrast to previous studies, in which this learning bias had no negative impact on behavioural performance (i.e., correct choice rate and therefore final payoff), here we demonstrated that this learning bias is still present in situations in which it has a negative impact on performance. In fact, whereas low and high bias participants performed equally well in conditions with stable reward contingencies, in conditions with unstable reward contingencies we found that high bias participants showed a relatively reduced correct choice rate. When reward contingencies were changed, learning to successfully reverse the response in the second half of the trials was mainly driven by negative factual (and positive counterfactual) prediction errors. Thus in this case, participants displaying higher biases exhibited a lower correct choice rate. In other words, these learning biases significantly undermined participants’ capacity to flexibly adapt their behaviour in changing, uncertain environments.</p>
<p>In addition to reduced reversal learning, and in accordance with a previous study [<xref ref-type="bibr" rid="pcbi.1005684.ref010">10</xref>], another behavioural feature that distinguished higher and lower bias participants was the preferred response rate in the Symmetric condition. In the Symmetric condition, both cues had the same reward probabilities (50%), such that there was no intrinsic “correct” response. This allowed us to calculate the preferred response rate for each participant (defined as the choice rate of the option most frequently selected by a given participant, i.e. the option selected in &gt; 50% of trials). The preferred response rate can therefore be taken as a measure of the tendency to overestimate the value of one cue compared to the other, in the absence of actual outcome-based evidence. In both experiments, higher bias participants showed higher preferred response rates, a behavioural pattern that is consistent with an increased tendency to discount negative factual (and positive counterfactual) prediction errors. This can result in one considering a previously rewarded chosen option as better than it really is and an increased preference for this choice. Thus, these results illustrate that the higher the learning bias for a given participant, the higher his/her behavioural perseveration (the tendency to repeat a previous choice), despite the possible acquisition of new evidence in the form of negative feedback.</p>
<p>Previous studies have been unable to distinguish whether this valence-induced factual learning bias is a “positivity bias” or a “confirmation bias”. In other words, do participants preferentially learn from positive prediction errors because they are positively valenced or because the outcome confirms the choice they have just made? To address this question we designed Experiment 2 in which, by including counterfactual feedback, we were able to separate the influence of prediction error valence (positive vs. negative) from the influence of prediction error type (chosen vs. unchosen outcome). Crucially, whereas the two competing hypotheses (“positivity bias” vs. “confirmation bias”) predicted the same result concerning factual learning rates, they predicted opposite effects of valence on counterfactual learning rates. The results from Experiment 2 support the confirmation bias hypothesis: participants preferentially took into account the outcomes that confirmed their current behavioural policy (positive chosen and negative unchosen outcomes) and discounted the outcomes that contradicted it (negative chosen and positive unchosen outcomes). Our results therefore support the idea that confirmation biases are pervasive in human cognition [<xref ref-type="bibr" rid="pcbi.1005684.ref025">25</xref>].</p>
<p>It should be noted that, from an orthodox Bayesian perspective, a confirmation bias would involve reinforcing one's own initial beliefs or preferences. Previous studies have investigated how prior information—in the form of explicit task instructions or advice—influences the learning of reinforcement statistics and have provided evidence of a confirmation bias [<xref ref-type="bibr" rid="pcbi.1005684.ref026">26</xref>–<xref ref-type="bibr" rid="pcbi.1005684.ref028">28</xref>]. However, consistent with our study, their computational and neural results suggest that this instruction-induced confirmation bias operates at the level of outcome processing and not at the level of initial preferences or at the level of the decision-making process [<xref ref-type="bibr" rid="pcbi.1005684.ref029">29</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref030">30</xref>]. Here, we take a slightly different perspective by extending the notion of confirmation bias to the implicit reinforcement of one's own current choice, by preferentially learning from desirable outcomes, independently from explicit prior information.</p>
<p>We performed a learning rate analysis separately for each task condition and the results proved robust and were not driven by any particular reward contingency condition. Our results contrast with previous studies that have found learning rates adapt as a function of task contingencies, showing increases when task contingencies were unstable [<xref ref-type="bibr" rid="pcbi.1005684.ref031">31</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref032">32</xref>]. Several differences between these tasks and ours may explain this discrepancy. First, in previous studies, the stable and unstable phases were clearly separated, whereas in our design, participants were simultaneously tested in the three reward contingency conditions. Second, we did not explicitly tell participants to monitor the stability of the reward contingency. Finally, since in our task the Reversal condition represented only one quarter of the trials, participants may not have explicitly realised that changing learning rates were adaptive in some cases.</p>
<p>To date, two different views of counterfactual learning have been proposed. According to one view, factual and counterfactual learning are underpinned by different systems that could be computationally and anatomically mapped onto subcortical, model-free modules, and prefrontal, model-based modules [<xref ref-type="bibr" rid="pcbi.1005684.ref017">17</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref018">18</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref033">33</xref>]. In contrast, according to another view, factual and counterfactual outcomes are processed by the same learning system, involving the dopaminergic nuclei and their projections [<xref ref-type="bibr" rid="pcbi.1005684.ref034">34</xref>–<xref ref-type="bibr" rid="pcbi.1005684.ref036">36</xref>]. Our dimensionality reduction model comparison result sheds new light on this debate. If the first view was correct, and factual and counterfactual learning are based on different systems, different learning rates for positive and negative prediction errors would have better accounted for the data (the ‘Information’ model). In contrast, our results showed that the winning model was one in which the learning process was assumed to be different across desirable and undesirable outcomes, but shared across obtained and forgone outcomes (as in the “Confirmation” model), This supports the second view that factual and counterfactual learning are different facets of the same system.</p>
<p>Overall, we found that correct choice rate was higher in Experiment 2 than in Experiment 1, indicating that the presence of complete feedback information improved performance. Previous literature in psychology and economics suggest that this beneficial effect of counterfactual information is conditional on the payoff structure of the task. Specifically, studies have shown that the presence of rare positive outcomes could impair performance in the presence of complete feedback [<xref ref-type="bibr" rid="pcbi.1005684.ref037">37</xref>–<xref ref-type="bibr" rid="pcbi.1005684.ref040">40</xref>]. Further research is needed to assess whether or not the learning biases we identified extend to these payoff schemes and how they relate to the observed performance impairment.</p>
<p>Another series of studies in psychology and economics have used paradigms that dissociate information sampling (i.e., choosing an option to discover its value without getting the outcome) from actual choice (i.e., choosing an option in order to obtain the associated outcome) [<xref ref-type="bibr" rid="pcbi.1005684.ref003">3</xref>]. Other paradigms have been used to investigate learning from outcomes derived from choices performed by either a computer or another player (i.e., observational learning) [<xref ref-type="bibr" rid="pcbi.1005684.ref041">41</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref042">42</xref>]. Future research should assess whether or not information sampling and observational learning present similar valence-induced learning biases.</p>
<p>Why do these learning biases exist? One possibility is that these learning biases arise from neurobiological constraints, which limit human learning capacity. However, we believe this interpretation is unlikely because we see no clear reason why such limits would differentially affect learning from positive and negative prediction errors. In other words, we would predict that neurobiological constraints on learning rate would limit all learning rates in a similar way and therefore not produce valence-induced learning asymmetries. A second possibility is that these learning biases are not maladaptive. For instance, it has been shown that in certain reward conditions agents displaying valence-induced learning biases may outperform unbiased agents [<xref ref-type="bibr" rid="pcbi.1005684.ref009">9</xref>]. Thus, a possible explanation for these learning biases is that they have been positively selected because they can be adaptive in the context of the natural environment in which the learning system evolved [<xref ref-type="bibr" rid="pcbi.1005684.ref043">43</xref>]. A third, intermediate possibility is that these learning biases can be maladaptive in the context of learning performance, but due to their adaptive effects in other domains of cognition, overall they have a net adaptive value. For example, these biases may also manifest as “self-serving”, choice-supportive biases, which result in individuals tending to ascribe success to their own abilities and efforts, but relatively tending to neglect their own failures [<xref ref-type="bibr" rid="pcbi.1005684.ref044">44</xref>]. Accordingly, we could speculate that these learning biases may help promote self-esteem and confidence, both of which have been associated with overall favourable real life outcomes [<xref ref-type="bibr" rid="pcbi.1005684.ref045">45</xref>].</p>
<p>In summary, by investigating both factual and counterfactual learning, the current experiments demonstrate that, when presented with new evidence, people tend to discard information that suggests they have made a mistake. This selective neglect of useful information may have adaptive value, by increasing self-confidence and self-esteem. However, this low level reinforcement-learning bias may represent a computational building block for higher level cognitive biases such as belief perseverance, that is, the phenomenon that beliefs are remarkably resilient in the face of empirical challenges that logically contradict them [<xref ref-type="bibr" rid="pcbi.1005684.ref046">46</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref047">47</xref>].</p>
</sec>
<sec id="sec010" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec011">
<title>Participants</title>
<p>The study included two experiments. Each experiment involved N = 20 participants (Experiment 1: 7 males, mean age 23.9 ± 0.7; Experiment 2: 4 males, mean age 22.8 ± 0.7). The local ethics committee approved the study. All participants gave written informed consent before inclusion in the study, which was carried out in accordance with the declaration of Helsinki (1964, revised 2013). The inclusion criteria were being older than 18 years and reporting no history of neurological or psychiatric disorders.</p>
</sec>
<sec id="sec012">
<title>Behavioural tasks</title>
<p>Participants performed a probabilistic instrumental learning task based on previous studies [<xref ref-type="bibr" rid="pcbi.1005684.ref019">19</xref>,<xref ref-type="bibr" rid="pcbi.1005684.ref020">20</xref>] (<bold><xref ref-type="fig" rid="pcbi.1005684.g001">Fig 1A</xref></bold>). Briefly, the task involved choosing between two cues that were presented in fixed pairs and therefore represented fixed choice contexts. Cues were associated with stationary outcome probabilities in three out of four contexts. In the remaining context the outcome probability was non-stationary. The possible outcomes were either winning or losing a point. To allow learning, each context was presented in 24 trials. Each session comprised the four learning contexts and therefore included 96 trials. The whole experiment involved two sessions, each including the same number of contexts and conditions, but a different set of stimuli. Thus, the total experiment included 192 trials. The four learning contexts (i.e. fixed pairs of cues) were divided in three conditions (<bold><xref ref-type="supplementary-material" rid="pcbi.1005684.s001">S1 Fig</xref></bold>). In the “Symmetric” condition each cue was associated with a .50 probability of winning one point. In the “Asymmetric” condition one cue was associated with a .75 probability of winning a point and the other cue was associated with a .25 probability of winning a point. The Asymmetric condition was implemented in two choice contexts in each session. Finally, in the “Reversal” condition one cue was associated with a .83 probability of winning a point and the other cue was associated with a .17 probability of winning a point during the first 12 trials, and these contingencies were reversed thereafter. We chose a bigger probability difference in the Reversal compared to the Asymmetric condition in order to ensure that participants were able to reach a plateau within the first 12 trials. Participants were encouraged to accumulate as many points as possible and were informed that some cues would result in winning more often than others. Participants were given no explicit information regarding reward probabilities, which they had to learn through trial and error.</p>
<p>At each trial, after a fixation cross, the choice context was presented. Participants made their choice by pressing left or right arrow keys with their right hand (the choice time was self-paced). The two experiments differed in the fact that in the Experiment 1 participants were only informed about the outcome of their own choice (chosen outcome), whereas in the Experiment 2 participants were informed about both the obtained and the forgone outcome (i.e. counterfactual feedback). In Experiment 1 positive outcomes were presented at the top and negative outcomes at the bottom of the screen. The participant was required to press the key corresponding to the position of the outcome on the screen (top/bottom) in order to move to the subsequent trial. In Experiment 2 the obtained outcomes were presented in the same place as the chosen cues and the forgone outcomes in the same place as the unchosen cues. To move to the subsequent trial, participants had to match the position of the outcome with a key press (right/left). Importantly for our computational analyses, outcome probabilities (although on average anti-correlated in the Asymmetric and Reversal conditions) were truly independent across cues, so that in the Symmetric condition, in a given trial, the obtained and forgone outcomes were the same in 50% of trials; in the Asymmetric condition this was the case in 37.5% of trials; finally, in the Reversal condition this was the case in 28.2% of trials.</p>
</sec>
<sec id="sec013">
<title>Behavioural variables</title>
<p>We extracted the correct response rate, that is, the rate of the trials in which the participants chose the most rewarding response, from the Asymmetric and the Reversal conditions. The correct response rate in the Reversal condition was calculated separately for the two phases: before (“first half”) and after (“second half”) the contingency reversal. In the Symmetric condition, we calculated the so-called “preferred” response rate. The preferred response was defined as the most frequently chosen option, i.e. that chosen by the participant on more than 50% of the trials. This quantity was therefore, by definition, greater than 0.5. To investigate the behavioural consequences of learning biases on performance, we median-split the participants from each experiment into two groups according to their normalised learning rate difference (Experiment 1: <inline-formula id="pcbi.1005684.e026"><alternatives><graphic id="pcbi.1005684.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>; Experiment 2: <inline-formula id="pcbi.1005684.e027"><alternatives><graphic id="pcbi.1005684.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mo>[</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>]</mml:mo><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>), from which we obtained ‘low’ and ‘high’ bias participants[<xref ref-type="bibr" rid="pcbi.1005684.ref048">48</xref>]. The preferred response rate in the Symmetric condition was submitted to an ANOVA with experiment (1 vs. 2) and bias level (high vs. low) as between-subjects factors. The correct choice rate in the remaining conditions was submitted to an ANOVA with experiment (1 vs. 2) and bias level (high vs. low) as between-subjects factors and condition (Asymmetric, Reversal first half and Reversal second half) as within-subject factors. The effects of interest identified by the ANOVAs were also confirmed using Pearson’s correlations.</p>
</sec>
<sec id="sec014">
<title>Computational models</title>
<p>We fitted the data with a standard Q-learning model, including different learning rates following positive and negative prediction errors and containing two different modules (<bold><xref ref-type="fig" rid="pcbi.1005684.g001">Fig 1C</xref></bold>): a factual learning module to learn from chosen outcomes (R<sub>c</sub>) and a counterfactual learning module to learn from unchosen outcomes (R<sub>u</sub>) (note that counterfactual learning applies only to Experiment 2). For each pair of cues (choice context), the model estimates the expected values of the two options (Q-values). These Q-values essentially represent the expected reward obtained by choosing a particular option in a given context. In both experiments, Q-values were set at 0 before learning, corresponding to the a priori expectation of a 50% chance of winning 1 point, plus a 50% chance of losing 1 point. After every trial <italic>t</italic>, the value of the chosen option is updated according to the following rule (factual learning module):
<disp-formula id="pcbi.1005684.e028">
<alternatives>
<graphic id="pcbi.1005684.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e028" xlink:type="simple"/>
<mml:math display="block" id="M28">
<mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula></p>
<p>In this first equation, <italic>PE</italic><sub><italic>c</italic></sub>(<italic>t</italic>) is the prediction error of the chosen option, calculated as:
<disp-formula id="pcbi.1005684.e029">
<alternatives>
<graphic id="pcbi.1005684.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e029" xlink:type="simple"/>
<mml:math display="block" id="M29">
<mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
where <italic>R</italic><sub><italic>c</italic></sub>(<italic>t</italic>) is the reward obtained as an outcome of choosing <italic>c</italic> at trial <italic>t</italic>. In other words, the prediction error <italic>PE</italic><sub><italic>c</italic></sub>(<italic>t</italic>) is the difference between the expected outcome <italic>Q</italic><sub><italic>c</italic></sub>(<italic>t</italic>) and the actual outcome <italic>R</italic><sub><italic>c</italic></sub>(<italic>t</italic>).</p>
<p>In Experiment 2 the unchosen option value is also updated according to the following rule (counterfactual learning module):
<disp-formula id="pcbi.1005684.e030">
<alternatives>
<graphic id="pcbi.1005684.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e030" xlink:type="simple"/>
<mml:math display="block" id="M30">
<mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>In this second equation, <italic>PE</italic><sub><italic>u</italic></sub>(<italic>t</italic>) is the prediction error of the unchosen option, calculated as:
<disp-formula id="pcbi.1005684.e031">
<alternatives>
<graphic id="pcbi.1005684.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e031" xlink:type="simple"/>
<mml:math display="block" id="M31">
<mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
where <italic>R</italic><sub><italic>u</italic></sub>(<italic>t</italic>) is the reward that could have been obtained as an outcome of having chosen <italic>u</italic> at trial <italic>t</italic>. In other words, the prediction error <italic>PE</italic><sub><italic>u</italic></sub>(<italic>t</italic>) is the difference between the expected outcome <italic>Q</italic><sub><italic>u</italic></sub>(<italic>t</italic>) and the actual outcome <italic>R</italic><sub><italic>u</italic></sub>(<italic>t</italic>) of the unchosen option.</p>
<p>The learning rates <inline-formula id="pcbi.1005684.e032"><alternatives><graphic id="pcbi.1005684.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005684.e033"><alternatives><graphic id="pcbi.1005684.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> are scaling parameters that adjust the amplitude of value changes from one trial to the next when prediction errors of chosen and unchosen options, respectively, are positive (when the actual reward <italic>R</italic>(<italic>t</italic>) is better than the expected reward <italic>Q</italic>(<italic>t</italic>)). The learning rates <inline-formula id="pcbi.1005684.e034"><alternatives><graphic id="pcbi.1005684.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005684.e035"><alternatives><graphic id="pcbi.1005684.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> do the same when prediction errors are negative. Thus, our model allows for the amplitude of value updates to be different following positive and negative prediction errors, and for both chosen and unchosen options. It therefore allows for the existence of valence-dependent learning biases.</p>
<p>Finally, the probability (or likelihood) of selecting the chosen option was estimated with a soft-max rule as follows:
<disp-formula id="pcbi.1005684.e036">
<alternatives>
<graphic id="pcbi.1005684.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e036" xlink:type="simple"/>
<mml:math display="block" id="M36">
<mml:mi>P</mml:mi><mml:mi>c</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mi mathvariant="normal">*</mml:mi><mml:mi>β</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mi mathvariant="normal">*</mml:mi><mml:mi>β</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mi mathvariant="normal">*</mml:mi><mml:mi>β</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula></p>
<p>This is a standard stochastic decision rule that calculates the probability of selecting one of a set of options according to their associated values. The temperature, <italic>β</italic>, is another scaling parameter that adjusts the stochasticity of decision-making.</p>
<p>In addition to this ‘Full’ model, we also considered alternative versions with a reduced number of learning rates (<bold><xref ref-type="fig" rid="pcbi.1005684.g003">Fig 3A</xref></bold>): the ‘Information’ model, where <inline-formula id="pcbi.1005684.e037"><alternatives><graphic id="pcbi.1005684.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005684.e038"><alternatives><graphic id="pcbi.1005684.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>; the ‘Valence’ model, where <inline-formula id="pcbi.1005684.e039"><alternatives><graphic id="pcbi.1005684.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005684.e040"><alternatives><graphic id="pcbi.1005684.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>; and the ‘Confirmation’ model, where <inline-formula id="pcbi.1005684.e041"><alternatives><graphic id="pcbi.1005684.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005684.e042"><alternatives><graphic id="pcbi.1005684.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. For the model comparison, we also considered a very simple model (the ‘One’) model, with only one learning rate (<inline-formula id="pcbi.1005684.e043"><alternatives><graphic id="pcbi.1005684.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>), and a ‘Perseveration’ model where an additional parameter (–Inf &lt; π &lt; +Inf) biases the decision-making process by increasing (positive values) or decreasing (negative values) the likelihood of repeating the same choice, regardless of the previous outcome (<bold><xref ref-type="table" rid="pcbi.1005684.t001">Table 1</xref></bold>).</p>
</sec>
<sec id="sec015">
<title>Parameter optimisation and model comparison</title>
<p>In a first analysis, we optimised model parameters by minimising the negative log-likelihood of the data, given different parameter settings, using Matlab’s fmincon function (ranges: 0&lt;<italic>β</italic>&lt;Infinite, and 0&lt; <italic>α</italic><sub><italic>n</italic></sub>&lt;1):
<disp-formula id="pcbi.1005684.e044">
<alternatives>
<graphic id="pcbi.1005684.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e044" xlink:type="simple"/>
<mml:math display="block" id="M44">
<mml:mi>L</mml:mi><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula></p>
<p>Negative log-likelihoods (LL) were used to compute the Bayesian information criterion (BIC) at the individual level (random effects) for each model, as follows:
<disp-formula id="pcbi.1005684.e045">
<alternatives>
<graphic id="pcbi.1005684.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e045" xlink:type="simple"/>
<mml:math display="block" id="M45">
<mml:mi>B</mml:mi><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>*</mml:mo><mml:mi>d</mml:mi><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>*</mml:mo><mml:mi>L</mml:mi><mml:mi>L</mml:mi>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula></p>
<p>BIC were compared between biased and unbiased models to verify that the utilisation of the biased model was justified, even accounting for its extra-complexity. As an approximation of the model evidence, individual BICs were fed into the mbb-vb-toolbox [<xref ref-type="bibr" rid="pcbi.1005684.ref049">49</xref>], a procedure that estimates the exceedance probability and the model attributions for each model within a set of models, given the data gathered from all participants. Exceedance probability (denoted XP) is the probability that a given model fits the data better than all other models in the set, i.e. has the highest XP (<bold><xref ref-type="table" rid="pcbi.1005684.t001">Table 1</xref></bold>). The toolbox also allows the estimation of the individual model attributions, i.e. the posterior probability (PP), for each subject, of belonging to each model. The individual model attributions can be compared to chance (defined as 1/the total number of models), compared to each other, and can also be averaged to obtain the model frequency for the population.</p>
<p>In a second analysis, we optimised model parameters by minimising the logarithm of the Laplace approximation to the model evidence (or log posterior probability: LPP):
<disp-formula id="pcbi.1005684.e046">
<alternatives>
<graphic id="pcbi.1005684.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e046" xlink:type="simple"/>
<mml:math display="block" id="M46">
<mml:mi>L</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo>⁡</mml:mo><mml:mo>(</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula></p>
<p>Because LPP maximisation includes priors over the parameters (temperature: gamma(1.2,5); learning rates beta(1.1,1.1)) [<xref ref-type="bibr" rid="pcbi.1005684.ref050">50</xref>], it avoids degenerate parameter estimates. Therefore, learning rate analyses have been performed on the values retrieved with this procedure. To avoid bias in learning rate comparisons, the same priors were used for all learning rates. In the main analysis, a single set of parameters was used to fit all conditions. In a control analysis, different sets of parameters were used to fit each condition (“Symmetric”, “Asymmetric” and “Reversal”).</p>
</sec>
<sec id="sec016">
<title>Parameter correlation and parameter recovery</title>
<p>To validate our results, and more specifically to verify that valence-induced differences in learning rates reflected true differences in learning, as opposed to an artefact of the parameter optimisation procedure, we checked the correlations between the free parameters (Experiment 1: β, <inline-formula id="pcbi.1005684.e047"><alternatives><graphic id="pcbi.1005684.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005684.e047" xlink:type="simple"/><mml:math display="inline" id="M47"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>; Experiment 2: β, α<sub>CON</sub>, α<sub>DIS</sub>) and the capacity of recovering the correct parameters using simulated datasets. To check the capacity of recovering the correct parameters using simulated datasets, we simulated performance on our behavioural task using virtual participants with parameters values corresponding to those retrieved from our experimental participants [<xref ref-type="bibr" rid="pcbi.1005684.ref023">23</xref>]. We simulated N = 100 virtual experiments.</p>
</sec>
</sec>
<sec id="sec017">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005684.s001" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005684.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Stability of learning biases across task conditions.</title>
<p>(A) Task conditions. The ‘Symmetric’ condition was characterised by a stable reward contingency and no correct option, because the two options had equal reward probabilities. The ‘Asymmetric condition’ was also characterised by a stable reward contingency and a correct option, since one option had a higher reward probability than the other. The ‘Reversal’ condition was characterised by an instable reward contingency: after 12 trials the reward probability reversed across symbols, so that the former correct option became the incorrect one, and vice versa. Note that the number of trials refers to one session and participants performed two sessions, each involving new pairs of stimuli (192 trials in total). (B) and (C) Computational results as a function of the task conditions in Experiment 1 and Experiment 2, respectively. Each column presents the result of the corresponding condition presented in (A).</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005684.s002" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005684.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Parameter recovery in Experiment 1.</title>
<p>“True values”: learning rates used to simulate the data. “Recovered values”: learning rates obtained from the simulations once the same parameter optimisation was applied as for the experimental data. “Case: unbiased”: no learning rate bias. “Case: biased”: positivity learning rate bias.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005684.s003" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005684.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Parameter recovery in Experiment 2.</title>
<p>“True values”: learning rates used to simulate the data. “Recovered values”: learning rates obtained from the simulations once the same parameter optimisation was applied as for the experimental data. “Case: unbiased”: no learning rate bias. “Case: semi-biased”: learning rate bias only concerning factual learning. “Case biased”: confirmation bias involving both factual and counterfactual learning.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>Anahit Mkrtchian and Anders Jespersen helped performing the experiments. We thank Bahador Bahrami and Valerian Chambon for helpful feedback. We thank Vasilisa Skvortsova and Héloïse Théro for discussions on the data analysis.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005684.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rangel</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Camerer</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>. <article-title>A framework for studying the neurobiology of value-based decision making</article-title>. <source>Nat Rev Neurosci</source>. <year>2008</year>;<volume>9</volume>: <fpage>545</fpage>–<lpage>556</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn2357" xlink:type="simple">10.1038/nrn2357</ext-link></comment> <object-id pub-id-type="pmid">18545266</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>DellaVigna</surname> <given-names>S</given-names></name>. <article-title>Psychology and Economics: Evidence from the Field</article-title>. <source>J Econ Lit</source>. <year>2009</year>;<volume>47</volume>: <fpage>315</fpage>–<lpage>372</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1257/jel.47.2.315" xlink:type="simple">10.1257/jel.47.2.315</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1005684.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hertwig</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Erev</surname> <given-names>I</given-names></name>. <article-title>The description-experience gap in risky choice</article-title>. <source>Trends Cogn Sci</source>. <year>2009</year>;<volume>13</volume>: <fpage>517</fpage>–<lpage>23</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2009.09.004" xlink:type="simple">10.1016/j.tics.2009.09.004</ext-link></comment> <object-id pub-id-type="pmid">19836292</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maia</surname> <given-names>T V</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>. <article-title>From reinforcement learning models to psychiatric and neurological disorders</article-title>. <source>Nat Neurosci</source>. Nature Publishing Group; <year>2011</year>;<volume>14</volume>: <fpage>154</fpage>–<lpage>62</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2723" xlink:type="simple">10.1038/nn.2723</ext-link></comment> <object-id pub-id-type="pmid">21270784</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haushofer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Fehr</surname> <given-names>E</given-names></name>. <article-title>On the psychology of poverty</article-title>. <source>Science</source> (80-). <year>2014</year>;<volume>344</volume>: <fpage>862</fpage>–<lpage>867</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1232491" xlink:type="simple">10.1126/science.1232491</ext-link></comment> <object-id pub-id-type="pmid">24855262</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doya</surname> <given-names>K</given-names></name>. <article-title>Metalearning and neuromodulation</article-title>. <source>Neural Netw</source>. <year>2002</year>;<volume>15</volume>: <fpage>495</fpage>–<lpage>506</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/12371507" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/12371507</ext-link> <object-id pub-id-type="pmid">12371507</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref007"><label>7</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>. <source>Reinforcement Learning: An Introduction</source>. <publisher-loc>Cambridge</publisher-loc>. <publisher-name>MIT Press</publisher-name>; <year>1998</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TNN.1998.712192" xlink:type="simple">10.1109/TNN.1998.712192</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1005684.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kiebel</surname> <given-names>SJ</given-names></name>. <article-title>Reinforcement learning or active inference?</article-title> <source>PLoS One</source>. <year>2009</year>;<volume>4</volume>: <fpage>e6421</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0006421" xlink:type="simple">10.1371/journal.pone.0006421</ext-link></comment> <object-id pub-id-type="pmid">19641614</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cazé</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>van der Meer</surname> <given-names>MAA</given-names></name>. <article-title>Adaptive properties of differential learning rates for positive and negative outcomes</article-title>. <source>Biol Cybern</source>. <year>2013</year>;<volume>107</volume>: <fpage>711</fpage>–<lpage>719</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00422-013-0571-5" xlink:type="simple">10.1007/s00422-013-0571-5</ext-link></comment> <object-id pub-id-type="pmid">24085507</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lefebvre</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Lebreton</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Meyniel</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Bourgeois-Gironde</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>. <article-title>Behavioural and neural characterization of optimistic reinforcement learning</article-title>. <source>Nat Hum Behav</source>. Macmillan Publishers Limited, part of Springer Nature.; <year>2017</year>;<volume>67</volume>: <fpage>1</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41562-017-0067" xlink:type="simple">10.1038/s41562-017-0067</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1005684.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>den Ouden</surname> <given-names>HEM</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Fernandez</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Elshout</surname> <given-names>J a</given-names></name>, <name name-style="western"><surname>Rijpkema</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hoogman</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Dissociable effects of dopamine and serotonin on reversal learning</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>80</volume>: <fpage>1090</fpage>–<lpage>100</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.08.030" xlink:type="simple">10.1016/j.neuron.2013.08.030</ext-link></comment> <object-id pub-id-type="pmid">24267657</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Moustafa</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Haughey</surname> <given-names>HM</given-names></name>, <name name-style="western"><surname>Curran</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Hutchison</surname> <given-names>KE</given-names></name>. <article-title>Genetic triple dissociation reveals multiple roles for dopamine in reinforcement learning</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2007</year>;<volume>104</volume>: <fpage>16311</fpage>–<lpage>16316</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0706111104" xlink:type="simple">10.1073/pnas.0706111104</ext-link></comment> <object-id pub-id-type="pmid">17913879</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Bos</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>MX</given-names></name>, <name name-style="western"><surname>Kahnt</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Crone</surname> <given-names>E a</given-names></name>. <article-title>Striatum-medial prefrontal cortex connectivity predicts developmental changes in reinforcement learning</article-title>. <source>Cereb Cortex</source>. Oxford University Press; <year>2012</year>;<volume>22</volume>: <fpage>1247</fpage>–<lpage>55</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhr198" xlink:type="simple">10.1093/cercor/bhr198</ext-link></comment> <object-id pub-id-type="pmid">21817091</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aberg</surname> <given-names>KC</given-names></name>, <name name-style="western"><surname>Doell</surname> <given-names>KC</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>S</given-names></name>. <article-title>Linking individual learning styles to approach-avoidance motivational traits and computational aspects of reinforcement learning</article-title>. <source>PLoS One</source>. <year>2016</year>;<volume>11</volume>: <fpage>1</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0166675" xlink:type="simple">10.1371/journal.pone.0166675</ext-link></comment> <object-id pub-id-type="pmid">27851807</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sharot</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Garrett</surname> <given-names>N</given-names></name>. <article-title>Forming Beliefs: Why Valence Matters</article-title>. <source>Trends Cogn Sci</source>. Elsevier Ltd; <year>2016</year>;<volume>20</volume>: <fpage>25</fpage>–<lpage>33</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2015.11.002" xlink:type="simple">10.1016/j.tics.2015.11.002</ext-link></comment> <object-id pub-id-type="pmid">26704856</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>McNamee</surname> <given-names>D</given-names></name>. <article-title>The structure of reinforcement-learning mechanisms in the human brain</article-title>. <source>Curr Opin Behav Sci</source>. Elsevier Ltd; <year>2015</year>;<volume>1</volume>: <fpage>94</fpage>–<lpage>100</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cobeha.2014.10.004" xlink:type="simple">10.1016/j.cobeha.2014.10.004</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1005684.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boorman</surname> <given-names>ED</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MF</given-names></name>. <article-title>Counterfactual Choice and Learning in a Neural Network Centered on Human Lateral Frontopolar Cortex</article-title>. <source>PLoS Biol</source>. <year>2011</year>;<volume>9</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1001093" xlink:type="simple">10.1371/journal.pbio.1001093</ext-link></comment> <object-id pub-id-type="pmid">21738446</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fischer</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Ullsperger</surname> <given-names>M</given-names></name>. <article-title>Real and fictive outcomes are processed differently but converge on a common adaptive mechanism</article-title>. <source>Neuron</source>. Elsevier Inc.; <year>2013</year>;<volume>79</volume>: <fpage>1243</fpage>–<lpage>55</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.07.006" xlink:type="simple">10.1016/j.neuron.2013.07.006</ext-link></comment> <object-id pub-id-type="pmid">24050408</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Boraud</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Lafargue</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Dubois</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>. <article-title>Brain hemispheres selectively track the expected value of contralateral options</article-title>. <source>J Neurosci</source>. <year>2009</year>;<volume>29</volume>: <fpage>13465</fpage>–<lpage>13472</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1500-09.2009" xlink:type="simple">10.1523/JNEUROSCI.1500-09.2009</ext-link></comment> <object-id pub-id-type="pmid">19864559</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Khamassi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Joffily</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Coricelli</surname> <given-names>G</given-names></name>. <article-title>Contextual modulation of value signals in reward and punishment learning</article-title>. <source>Nat Commun</source>. Nature Publishing Group; <year>2015</year>;<volume>6</volume>: <fpage>8096</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ncomms9096" xlink:type="simple">10.1038/ncomms9096</ext-link></comment> <object-id pub-id-type="pmid">26302782</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref021"><label>21</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Rescorla</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>AR</given-names></name>. <chapter-title>A Theory of Pavlovian Conditioning: Variations in the Effectiveness of Reinforcement and Nonreinforcement</chapter-title>. In: <name name-style="western"><surname>Black</surname> <given-names>AH</given-names></name>, <name name-style="western"><surname>Prokasy</surname> <given-names>WF</given-names></name>, editors. <source>Classical conditioning II: current research and theory</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Applenton-Century-Crofts</publisher-name>; <year>1972</year>. pp. <fpage>64</fpage>–<lpage>99</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005684.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Watkins</surname> <given-names>CJCH</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Q-learning</article-title>. <source>Mach Learn</source>. <year>1992</year>;<volume>8</volume>: <fpage>279</fpage>–<lpage>292</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00992698" xlink:type="simple">10.1007/BF00992698</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1005684.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wyart</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Koechlin</surname> <given-names>E</given-names></name>. <article-title>The Importance of Falsification in Computational Cognitive Modeling</article-title>. <source>Trends Cogn Sci</source>. <year>2017</year>;<volume>21</volume>: <fpage>425</fpage>–<lpage>433</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2017.03.011" xlink:type="simple">10.1016/j.tics.2017.03.011</ext-link></comment> <object-id pub-id-type="pmid">28476348</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kilford</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Coricelli</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Blakemore S-</surname> <given-names>J</given-names></name>. <article-title>The computational development of reinforcement learning during adolescence</article-title>. <source>PLoS Comput Biol</source>. <year>2016</year>;</mixed-citation></ref>
<ref id="pcbi.1005684.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nickerson</surname> <given-names>R</given-names></name>. <article-title>Confirmation bias: a ubiquitous phenomenon in many guises</article-title>. <source>Rev Gen Psychol</source>. <year>1998</year>;<volume>2</volume>: <fpage>175</fpage>–<lpage>220</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005684.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Staudinger</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Buchel</surname> <given-names>C</given-names></name>. <article-title>How initial confirmatory experience potentiates the detrimental influence of bad advice</article-title>. <source>Neuroimage</source>. <year>2013</year>;<volume>76</volume>: <fpage>125</fpage>–<lpage>133</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.02.074" xlink:type="simple">10.1016/j.neuroimage.2013.02.074</ext-link></comment> <object-id pub-id-type="pmid">23507392</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doll</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Jacobs</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Sanfey</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>. <article-title>Instructional control of reinforcement learning: a behavioral and neurocomputational investigation</article-title>. <source>Brain Res</source>. Elsevier B.V.; <year>2009</year>;<volume>1299</volume>: <fpage>74</fpage>–<lpage>94</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.brainres.2009.07.007" xlink:type="simple">10.1016/j.brainres.2009.07.007</ext-link></comment> <object-id pub-id-type="pmid">19595993</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Biele</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rieskamp</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gonzalez</surname> <given-names>R</given-names></name>. <article-title>Computational models for the combination of advice and individual learning</article-title>. <source>Cogn Sci</source>. <year>2009</year>;<volume>33</volume>: <fpage>206</fpage>–<lpage>242</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1551-6709.2009.01010.x" xlink:type="simple">10.1111/j.1551-6709.2009.01010.x</ext-link></comment> <object-id pub-id-type="pmid">21585468</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doll</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Hutchison</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>. <article-title>Dopaminergic Genes Predict Individual Differences in Susceptibility to Confirmation Bias</article-title>. <year>2011</year>;<volume>31</volume>: <fpage>6188</fpage>–<lpage>6198</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.6486-10.2011" xlink:type="simple">10.1523/JNEUROSCI.6486-10.2011</ext-link></comment> <object-id pub-id-type="pmid">21508242</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Biele</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rieskamp</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Krugel</surname> <given-names>LK</given-names></name>, <name name-style="western"><surname>Heekeren</surname> <given-names>HR</given-names></name>. <article-title>The Neural basis of following advice</article-title>. <source>PLoS Biol</source>. <year>2011</year>;<volume>9</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1001089" xlink:type="simple">10.1371/journal.pbio.1001089</ext-link></comment> <object-id pub-id-type="pmid">21713027</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Behrens</surname> <given-names>TEJ</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Walton</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MFS</given-names></name>. <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source>. <year>2007</year>;<volume>10</volume>: <fpage>1214</fpage>–<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1954" xlink:type="simple">10.1038/nn1954</ext-link></comment> <object-id pub-id-type="pmid">17676057</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Browning</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Jocham</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Reilly</surname> <given-names>JXO</given-names></name>, <name name-style="western"><surname>Bishop</surname> <given-names>SJ</given-names></name>. <article-title>Anxious individuals have difficulty learning the causal statistics of aversive environments Michael Browning</article-title>. <source>Nat Neurosci</source>. Nature Publishing Group; <year>2015</year>;<volume>18</volume>: <fpage>1</fpage>–<lpage>50</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3916" xlink:type="simple">10.1038/nn.3916</ext-link></comment> <object-id pub-id-type="pmid">25547471</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boorman</surname> <given-names>ED</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>TEJ</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MFS</given-names></name>. <article-title>How Green Is the Grass on the Other Side? Frontopolar Cortex and the Evidence in Favor of Alternative Courses of Action</article-title>. <source>Neuron</source>. Elsevier Ltd; <year>2009</year>;<volume>62</volume>: <fpage>733</fpage>–<lpage>743</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2009.05.014" xlink:type="simple">10.1016/j.neuron.2009.05.014</ext-link></comment> <object-id pub-id-type="pmid">19524531</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kishida</surname> <given-names>KT</given-names></name>, <name name-style="western"><surname>Saez</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Lohrenz</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Witcher</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Laxton</surname> <given-names>AW</given-names></name>, <name name-style="western"><surname>Tatter</surname> <given-names>SB</given-names></name>, <etal>et al</etal>. <article-title>Subsecond dopamine fluctuations in human striatum encode superposed error signals about actual and counterfactual reward</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2015</year>; 1513619112-. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1513619112" xlink:type="simple">10.1073/pnas.1513619112</ext-link></comment> <object-id pub-id-type="pmid">26598677</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lohrenz</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>McCabe</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Camerer</surname> <given-names>CF</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>. <article-title>Neural signature of fictive learning signals in a sequential investment task</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2007</year>;<volume>104</volume>: <fpage>9493</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0608842104" xlink:type="simple">10.1073/pnas.0608842104</ext-link></comment> <object-id pub-id-type="pmid">17519340</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>Signals in Human Striatum Are Appropriate for Policy Update Rather than Value Prediction</article-title>. <source>J Neurosci</source>. <year>2011</year>;<volume>31</volume>: <fpage>5504</fpage>–<lpage>5511</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.6316-10.2011" xlink:type="simple">10.1523/JNEUROSCI.6316-10.2011</ext-link></comment> <object-id pub-id-type="pmid">21471387</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ross Otto</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Love</surname> <given-names>B</given-names></name>. <article-title>You don’t want to know what you’re missing: When information about forgone rewards impedes dynamic decision making</article-title>. <source>Judgm Decis Mak</source>, <volume>5</volume> pp <fpage>1</fpage>–<lpage>10</lpage>. <year>2010</year>; Available: <ext-link ext-link-type="uri" xlink:href="http://discovery.ucl.ac.uk/1361909/" xlink:type="simple">http://discovery.ucl.ac.uk/1361909/</ext-link></mixed-citation></ref>
<ref id="pcbi.1005684.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ert</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Erev</surname> <given-names>I</given-names></name>. <article-title>Replicated alternatives and the role of confusion, chasing, and regret in decisions from experience</article-title>. <source>J Behav Decis Mak</source>. John Wiley &amp; Sons, Ltd.; <year>2007</year>;<volume>20</volume>: <fpage>305</fpage>–<lpage>322</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/bdm.556" xlink:type="simple">10.1002/bdm.556</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1005684.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grosskopf</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Erev</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Yechiam</surname> <given-names>E</given-names></name>. <article-title>Foregone with the Wind: Indirect Payoff Information and its Implications for Choice</article-title>. <source>Int J Game Theory</source>. Springer-Verlag; <year>2006</year>;<volume>34</volume>: <fpage>285</fpage>–<lpage>302</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00182-006-0015-8" xlink:type="simple">10.1007/s00182-006-0015-8</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1005684.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yechiam</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Busemeyer</surname> <given-names>JR</given-names></name>. <article-title>The effect of foregone payoffs on underweighting small probability events</article-title>. <source>J Behav Decis Mak</source>. John Wiley &amp; Sons, Ltd.; <year>2006</year>;<volume>19</volume>: <fpage>1</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/bdm.509" xlink:type="simple">10.1002/bdm.509</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1005684.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bellebaum</surname> <given-names>C</given-names></name>. <article-title>Dissociation between Active and Observational Learning from Positive and Negative Feedback in Parkinsonism</article-title>. <year>2012</year>;<volume>7</volume>: <fpage>1</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0050250" xlink:type="simple">10.1371/journal.pone.0050250</ext-link></comment> <object-id pub-id-type="pmid">23185586</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burke</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Tobler</surname> <given-names>PN</given-names></name>, <name name-style="western"><surname>Baddeley</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Neural mechanisms of observational learning</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2010</year>;<volume>107</volume>: <fpage>14431</fpage>–<lpage>14436</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1003111107" xlink:type="simple">10.1073/pnas.1003111107</ext-link></comment> <object-id pub-id-type="pmid">20660717</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fawcett</surname> <given-names>TW</given-names></name>, <name name-style="western"><surname>Fallenstein</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Higginson</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Houston</surname> <given-names>AI</given-names></name>, <name name-style="western"><surname>Mallpress</surname> <given-names>DEW</given-names></name>, <name name-style="western"><surname>Trimmer</surname> <given-names>PC</given-names></name>, <etal>et al</etal>. <article-title>The evolution of decision rules in complex environments</article-title>. <source>Trends Cogn Sci</source>. Elsevier Ltd; <year>2014</year>;<volume>18</volume>: <fpage>153</fpage>–<lpage>161</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2013.12.012" xlink:type="simple">10.1016/j.tics.2013.12.012</ext-link></comment> <object-id pub-id-type="pmid">24467913</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref044"><label>44</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Blaine</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Crocker</surname> <given-names>J</given-names></name>. <chapter-title>Self-Esteem and Self-Serving Biases in Reactions to Positive and Negative Events: An Integrative Review</chapter-title>. In: <name name-style="western"><surname>Baumeister</surname> <given-names>RF</given-names></name>, editor. <source>Self-Esteem</source>. <publisher-name>The Springer Series in Social Clinical Psychology</publisher-name>; <year>1993</year>. p. pp <fpage>55</fpage>–<lpage>85</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005684.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weinstein</surname> <given-names>ND</given-names></name>. <article-title>Unrealistic Optimism About Future Life events</article-title>. <source>J Pers Soc Psychol</source>. <year>1980</year>;<volume>39</volume>: <fpage>806</fpage>–<lpage>820</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0020997" xlink:type="simple">10.1037/a0020997</ext-link></comment> <object-id pub-id-type="pmid">21058872</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kuhn</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Lao</surname> <given-names>J</given-names></name>. <article-title>Effects of Evidence on Attitudes: Is Polarization the Norm?</article-title> <source>Psychol Sci</source>. <year>1996</year>;<volume>7</volume>: <fpage>115</fpage>–<lpage>120</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1467-9280.1996.tb00340.x" xlink:type="simple">10.1111/j.1467-9280.1996.tb00340.x</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1005684.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ross</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Lepper</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Hubbard</surname> <given-names>M</given-names></name>. <article-title>Perseverance in self-perception and social perception: biased attributional processes in the debriefing paradigm</article-title>. <source>J Pers Soc Psychol</source>. <year>1975</year>;<volume>32</volume>: <fpage>880</fpage>–<lpage>92</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/1185517" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/1185517</ext-link> <object-id pub-id-type="pmid">1185517</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Edlund</surname> <given-names>JJ a</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>O’Doherty</surname> <given-names>JJP</given-names></name>, <name name-style="western"><surname>Doherty</surname> <given-names>JPO</given-names></name>. <article-title>Neural prediction errors reveal a risk-sensitive reinforcement-learning process in the human brain</article-title>. <source>J Neurosci</source>. <year>2012</year>;<volume>32</volume>: <fpage>551</fpage>–<lpage>562</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.5498-10.2012" xlink:type="simple">10.1523/JNEUROSCI.5498-10.2012</ext-link></comment> <object-id pub-id-type="pmid">22238090</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Adam</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Rigoux</surname> <given-names>L</given-names></name>. <article-title>VBA: A Probabilistic Treatment of Nonlinear Models for Neurobiological and Behavioural Data</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>: <fpage>e1003441</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003441" xlink:type="simple">10.1371/journal.pcbi.1003441</ext-link></comment> <object-id pub-id-type="pmid">24465198</object-id></mixed-citation></ref>
<ref id="pcbi.1005684.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname> <given-names>NDD</given-names></name>, <name name-style="western"><surname>Gershman</surname> <given-names>SJJ</given-names></name>, <name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJJ</given-names></name>. <article-title>Model-based influences on humans’ choices and striatal prediction errors</article-title>. <source>Neuron</source>. Elsevier; <year>2011</year>;<volume>69</volume>: <fpage>1204</fpage>–<lpage>1215</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2011.02.027" xlink:type="simple">10.1016/j.neuron.2011.02.027</ext-link></comment> <object-id pub-id-type="pmid">21435563</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
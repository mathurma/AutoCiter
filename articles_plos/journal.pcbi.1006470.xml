<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-00285</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006470</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain mapping</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Diagnostic medicine</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Radiology and imaging</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Algebra</subject><subj-group><subject>Linear algebra</subject><subj-group><subject>Vector spaces</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Linking signal detection theory and encoding models to reveal independent neural representations from neuroimaging data</article-title>
<alt-title alt-title-type="running-head">Independent neural representation</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1001-679X</contrib-id>
<name name-style="western">
<surname>Soto</surname> <given-names>Fabian A.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Vucovich</surname> <given-names>Lauren E.</given-names></name>
<role content-type="http://credit.casrai.org/">Investigation</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Ashby</surname> <given-names>F. Gregory</given-names></name>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Department of Psychology, Florida International University, Miami, Florida, United States of America</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Psychological and Brain Sciences, University of California, Santa Barbara, Santa Barbara, California, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Diedrichsen</surname> <given-names>Jörn</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Western University, CANADA</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">fabian.soto@fiu.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>10</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="epub">
<day>1</day>
<month>10</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>10</issue>
<elocation-id>e1006470</elocation-id>
<history>
<date date-type="received">
<day>17</day>
<month>2</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>29</day>
<month>8</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Soto et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006470"/>
<abstract>
<p>Many research questions in visual perception involve determining whether stimulus properties are represented and processed independently. In visual neuroscience, there is great interest in determining whether important object dimensions are represented independently in the brain. For example, theories of face recognition have proposed either completely or partially independent processing of identity and emotional expression. Unfortunately, most previous research has only vaguely defined what is meant by “independence,” which hinders its precise quantification and testing. This article develops a new quantitative framework that links signal detection theory from psychophysics and encoding models from computational neuroscience, focusing on a special form of independence defined in the psychophysics literature: perceptual separability. The new theory allowed us, for the first time, to precisely define separability of neural representations and to theoretically link behavioral and brain measures of separability. The framework formally specifies the relation between these different levels of perceptual and brain representation, providing the tools for a truly integrative research approach. In particular, the theory identifies exactly what valid inferences can be made about independent encoding of stimulus dimensions from the results of multivariate analyses of neuroimaging data and psychophysical studies. In addition, commonly used operational tests of independence are re-interpreted within this new theoretical framework, providing insights on their correct use and interpretation. Finally, we apply this new framework to the study of separability of brain representations of face identity and emotional expression (neutral/sad) in a human fMRI study with male and female participants.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>A common question in vision research is whether certain stimulus properties, like face identity and expression, are represented and processed independently. We develop a theoretical framework that allowed us, for the first time, to link behavioral and brain measures of independence. Unlike previous approaches, our framework formally specifies the relation between these different levels of perceptual and brain representation, providing the tools for a truly integrative research approach in the study of independence. This allows to identify what kind of inferences can be made about brain representations from multivariate analyses of neuroimaging data or psychophysical studies. We apply this framework to the study of independent processing of face identity and expression.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000183</institution-id>
<institution>Army Research Office</institution>
</institution-wrap>
</funding-source>
<award-id>W911NF-07-1-0072</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Ashby</surname> <given-names>F. Gregory</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000025</institution-id>
<institution>National Institute of Mental Health</institution>
</institution-wrap>
</funding-source>
<award-id>2R01MH063760</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Ashby</surname> <given-names>F. Gregory</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported in part by grant no. W911NF-07-1-0072 to FGA from the U.S. Army Research Office through the Institute for Collaborative Biotechnologies, and by grant 2R01MH063760 to FGA from the National Institute of Mental Health. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="0"/>
<page-count count="42"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-10-11</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Linking signal detection theory and encoding models to reveal independent neural representations from neuroimaging data (pcbi.1006470) can be downloaded from the following OSF page: <ext-link ext-link-type="uri" xlink:href="https://osf.io/qrupw/?view_only=e9ed7b7dcbfb41ea8b302e84548d8d6a" xlink:type="simple">https://osf.io/qrupw/?view_only=e9ed7b7dcbfb41ea8b302e84548d8d6a</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>A common goal in perceptual science is to determine whether some stimulus dimensions or components are processed and represented independently from other types of information. In visual neuroscience, much research has focused on determining whether there is independent processing of object and spatial visual information [<xref ref-type="bibr" rid="pcbi.1006470.ref001">1</xref>], of object shape and viewpoint [<xref ref-type="bibr" rid="pcbi.1006470.ref002">2</xref>], of different face dimensions [<xref ref-type="bibr" rid="pcbi.1006470.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref004">4</xref>], etc. A common approach is to use operational definitions of independence, which are linked to rather vague conceptual definitions. This approach has the disadvantage that different researchers use different operational definitions for independence, often leading to contradictory conclusions. For example, in the study of whether face identity and emotional expression are processed independently, evidence for both independence and interactivity has been found across a variety of operational tests. Evidence for independence was found by most lesion studies [<xref ref-type="bibr" rid="pcbi.1006470.ref005">5</xref>], by lack of correlation between fMRI patterns related to identity and expression [<xref ref-type="bibr" rid="pcbi.1006470.ref006">6</xref>], by single neuron invariance [<xref ref-type="bibr" rid="pcbi.1006470.ref007">7</xref>], by selective fMRI adaptation release in fusiform face area (FFA) and middle superior temporal sulcus (STS) [<xref ref-type="bibr" rid="pcbi.1006470.ref008">8</xref>], and by selective fMRI decoding of identity from anterior FFA and medial temporal gyrus [<xref ref-type="bibr" rid="pcbi.1006470.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref010">10</xref>], and of expression from STS [<xref ref-type="bibr" rid="pcbi.1006470.ref010">10</xref>]. Evidence for a lack of independence has been provided by overlapping fMRI activation during filtering tasks [<xref ref-type="bibr" rid="pcbi.1006470.ref011">11</xref>], by non-selective fMRI adaptation release in posterior STS [<xref ref-type="bibr" rid="pcbi.1006470.ref008">8</xref>] and in FFA–when adaptation is calculated based on perception [<xref ref-type="bibr" rid="pcbi.1006470.ref012">12</xref>]–, and by non-selective fMRI decoding from right FFA [<xref ref-type="bibr" rid="pcbi.1006470.ref009">9</xref>].</p>
<p>Because the different operational definitions are not linked to one another through a theoretical framework, the interpretation of such contradictory results is very difficult and necessarily post-hoc. Even more difficult is to link the neurobiological results to the psychophysics literature on independence of face dimensions, which itself is plagued by similar issues (for a review, see [<xref ref-type="bibr" rid="pcbi.1006470.ref013">13</xref>]).</p>
<p>General recognition theory (GRT) [<xref ref-type="bibr" rid="pcbi.1006470.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref015">15</xref>] is a multidimensional extension of signal detection theory that has solved such problems in psychophysics, by providing a unified theoretical framework in which notions of independence can be defined and linked to operational tests. Hundreds of studies have applied GRT to a wide variety of phenomena, including face perception [<xref ref-type="bibr" rid="pcbi.1006470.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref017">17</xref>], recognition and source memory [<xref ref-type="bibr" rid="pcbi.1006470.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref019">19</xref>], source monitoring [<xref ref-type="bibr" rid="pcbi.1006470.ref020">20</xref>], object recognition [<xref ref-type="bibr" rid="pcbi.1006470.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref022">22</xref>], perception/action interactions [<xref ref-type="bibr" rid="pcbi.1006470.ref023">23</xref>], speech perception [<xref ref-type="bibr" rid="pcbi.1006470.ref024">24</xref>], haptic perception [<xref ref-type="bibr" rid="pcbi.1006470.ref025">25</xref>], the perception of sexual interest [<xref ref-type="bibr" rid="pcbi.1006470.ref026">26</xref>], and many others.</p>
<p>Here we present an extension of GRT to the study of independence of brain representations, by relating it to encoding models and decoding methods from computational neuroscience [<xref ref-type="bibr" rid="pcbi.1006470.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref028">28</xref>]. Past neuroimaging studies have been limited to choosing between decoding methods, which try to determine what stimulus information is processed in a brain region while ignoring the form of the underlying representation, and encoding models, which assume a specific representation and compare its predictions against data. [<xref ref-type="bibr" rid="pcbi.1006470.ref029">29</xref>]. We propose the concept of encoding separability as a fundamental way in which brain representations of stimulus properties can be considered independent, and we identify the specific conditions in which a decoding analysis of neuroimaging data or a psychophysical study allow inferences to be made about encoding separability. In doing so, we show that decoding methods (and under some assumptions, psychophysics) can be useful to make valid inferences about encoding. We also re-interpret previously-proposed tests of independence within our new theoretical framework, and provide guides on their correct use. Finally, we apply this new framework to the study of separability of brain representations of face identity and expression.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Extending general recognition theory to the study of brain representations</title>
<p>GRT is a multivariate extension of signal detection theory to cases in which stimuli vary on more than one dimension [<xref ref-type="bibr" rid="pcbi.1006470.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref015">15</xref>]. As in signal detection theory, the theory assumes that different presentations of the same stimulus produce slightly different perceptual representations. For example, as shown in <xref ref-type="fig" rid="pcbi.1006470.g001">Fig 1</xref>, repeated presentations of a face identity produce a variety of values on the “identity” dimension (orange and red dots), which follow a probability distribution (red and orange curves). According to GRT, there are many ways in which processing of a dimension of interest, or target dimension, can be influenced by variations in a second, irrelevant dimension. GRT formally defines such dimensional interactions and links them to operational tests of independence. This allows researchers to determine whether a test can dissociate between different forms of independence, and to create new tests specifically designed to target a specific form of independence.</p>
<fig id="pcbi.1006470.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006470.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Stimulus representation and definition of perceptual separability in GRT.</title>
<p>The representation of a given identity changes randomly from trial to trial (dots at the bottom) according to some perceptual distribution (bell-shaped distributions at the top). Perceptual separability of identity from emotional expression (neutral vs. sad) holds if the perceptual distribution for identity does not change with emotional expression (left), and it fails if the perceptual distribution for identity does change with emotional expression (right).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006470.g001" xlink:type="simple"/>
</fig>
<p>Here we will consider the special case in which stimuli vary along two stimulus dimensions (or more generally, components or properties), represented by <italic>A</italic> and <italic>B</italic>. However, the theory can easily be extended to a larger number of dimensions. Specific values of dimension <italic>A</italic> used in an experiment are indexed by <italic>i</italic> = 1, 2, …<italic>L</italic><sub><italic>A</italic></sub>, and the specific values of dimension <italic>B</italic> are indexed by <italic>j</italic> = 1, 2, …<italic>L</italic><sub><italic>B</italic></sub>. A stimulus in the experiment is represented by a combination of these dimension levels, <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>. This stimulus produces a random perceptual effect in a two-dimensional perceptual space [<italic>x</italic>, <italic>y</italic>], where <italic>x</italic> represents the perceptual effect of property <italic>A</italic> and <italic>y</italic> the perceptual effect of property <italic>B</italic>. The random vector [<italic>x</italic>, <italic>y</italic>] can be described through a two-dimensional joint probability density <italic>p</italic>(<italic>x</italic>, <italic>y</italic>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>), with <italic>p</italic>(<italic>x</italic>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>) and <italic>p</italic>(<italic>y</italic>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>) representing the marginal densities of the perceptual effects associated with components <italic>A</italic> and <italic>B</italic>, respectively (the distributions shown in <xref ref-type="fig" rid="pcbi.1006470.g001">Fig 1</xref> are examples of such marginal densities).</p>
<sec id="sec004">
<title>Perceptual separability and perceptual independence</title>
<p>A particularly important form of independence defined in GRT is <italic>perceptual separability</italic>, which holds when the perception of the target dimension is not affected by variations in the irrelevant dimension. In <xref ref-type="fig" rid="pcbi.1006470.g001">Fig 1</xref>, an identity is presented with a neutral expression (in red) or with a sad expression (in orange). When perceptual separability holds, the orange and red perceptual distributions overlap, and the face is just as easy to identify in both cases. When perceptual separability fails, the orange and red perceptual distributions do not overlap, and the face is easier to identify when the expression is sad (there is more evidence for the identity in this case).</p>
<p>Here we focus on perceptual separability because it is considered a particularly important form of independence, for two reasons. First, because many questions in perceptual neuroscience can be understood as questions about separability of object dimensions. For example, the question of whether object representations are invariant across changes in identity-preserving variables like rotation and translation is equivalent to the question of whether object representations are perceptually separable from such variables [<xref ref-type="bibr" rid="pcbi.1006470.ref030">30</xref>]. In face perception, configural or holistic face perception has been defined as non-separable processing of different face features [<xref ref-type="bibr" rid="pcbi.1006470.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref032">32</xref>], and the question of whether or not different face dimensions are processed independently is usually investigated using tests of perceptual separability [<xref ref-type="bibr" rid="pcbi.1006470.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref033">33</xref>–<xref ref-type="bibr" rid="pcbi.1006470.ref035">35</xref>]. The second reason for the importance of perceptual separability is that higher-level cognitive mechanisms seem to be applied differently when stimuli differ along separable dimensions rather than along non-separable dimensions. For example, selective attention is deployed more easily to separable dimensions than to non-separable dimensions [<xref ref-type="bibr" rid="pcbi.1006470.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref037">37</xref>], sources of predictive and causal knowledge may be combined differently if they differ along separable versus non-separable dimensions [<xref ref-type="bibr" rid="pcbi.1006470.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref039">39</xref>], and the performance cost of storing objects in visual working memory is different depending on whether such objects differ from one another in separable versus non-separable dimensions [<xref ref-type="bibr" rid="pcbi.1006470.ref040">40</xref>].</p>
<p>Formally, perceptual separability of dimension <italic>A</italic> from dimension <italic>B</italic> occurs when the perceptual effect of stimuli on dimension <italic>A</italic> does not change with the value of the stimulus on dimension <italic>B</italic> [<xref ref-type="bibr" rid="pcbi.1006470.ref014">14</xref>]–that is, if and only if, for all values of <italic>x</italic> and <italic>i</italic>:
<disp-formula id="pcbi.1006470.e001"><alternatives><graphic id="pcbi.1006470.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>…</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:msub><mml:mi>L</mml:mi> <mml:mi>B</mml:mi></mml:msub></mml:msub> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula></p>
<p>Perceptual separability of dimension <italic>B</italic> from dimension <italic>A</italic> is defined analogously.</p>
<p>Another form of independence defined within GRT is <italic>perceptual independence</italic>. Perceptual independence of components A and B holds in stimulus <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub> if and only if the perceptual effects of A and B are statistically independent; that is, if and only if:
<disp-formula id="pcbi.1006470.e002"><alternatives><graphic id="pcbi.1006470.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>y</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>y</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula></p>
<p>Unlike perceptual separability, which is a form of independence involving the representation of multiple stimuli, perceptual independence refers to dimensional interactions in the representation of a single stimulus.</p>
</sec>
<sec id="sec005">
<title>Neural encoding and encoding separability</title>
<p>Extending GRT to the study of neural representation requires linking it to our current understanding on how dimensions are represented by neuronal populations. In the computational neuroscience literature, an encoding model is a formal representation of the relation between sensory stimuli and the response of a single neuron or a group of neurons [<xref ref-type="bibr" rid="pcbi.1006470.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref041">41</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref042">42</xref>]. In the case of stimulus dimensions, an encoding model represents how changes in a dimension of interest are related to changes in neural responses. Encoding models have been applied to describe neural responses at a variety of scales, from single neurons to the average activity of thousands of neurons [<xref ref-type="bibr" rid="pcbi.1006470.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref041">41</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref043">43</xref>]. To discuss these models in their more general form, it is convenient to introduce the abstract concept of a <italic>channel</italic>, which can be used as a placeholder for a single neuron, a population of neurons with similar properties, or as an abstract construct to model the behavior of a human observer. A channel is essentially a detector, sensitive to a particular stimulation pattern. It responds maximally to that target pattern and progressively less to other patterns as they become different from the target. In other words, the most important property of a channel is that it has tuning. The tuning of a channel can be modeled in many ways, but perhaps the simplest is to choose a physical dimension of interest and model the channel’s response as a function of the value of a stimulus on that dimension. For example, if we are interested in dimension <italic>A</italic> (equivalent definitions can be given for <italic>B</italic>), then the response <italic>r</italic><sub><italic>c</italic></sub> of the channel <italic>c</italic> to a stimulus <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub> is determined by a tuning function:
<disp-formula id="pcbi.1006470.e003"><alternatives><graphic id="pcbi.1006470.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e003" xlink:type="simple"/><mml:math display="block" id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mi>c</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mi>c</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula></p>
<p>Common choices for <italic>f</italic><sub><italic>c</italic></sub>(<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>) in the literature are bell-shaped and sigmoidal functions [<xref ref-type="bibr" rid="pcbi.1006470.ref028">28</xref>]. The channel response on a given trial may also be influenced by stochastic internal noise, which can be assumed to be additive (independent of the channel’s response) or multiplicative (scaling with the channel’s response). Common choices for the distribution of this noise in the literature are Gaussian and Poisson [<xref ref-type="bibr" rid="pcbi.1006470.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref042">42</xref>]. Because the noise is a random variable, the response of the channel <italic>r</italic><sub><italic>c</italic></sub> itself becomes a random variable that follows a probability distribution:
<disp-formula id="pcbi.1006470.e004"><alternatives><graphic id="pcbi.1006470.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>c</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>∼</mml:mo> <mml:mi>η</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mi>c</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
where ∼ means “distributed as”, and <italic>η</italic>() is just a placeholder that stands for any probability distribution (e.g., Gaussian) that depends on the channel’s tuning function and on a set of parameters <italic>θ</italic> describing noise.</p>
<p>Researchers agree that encoding of a stimulus dimension requires a model with multiple channels, or multichannel model. For example, the “standard model” of dimension encoding in the computational neuroscience literature is such a multichannel model (implementing a “population code” [<xref ref-type="bibr" rid="pcbi.1006470.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref041">41</xref>]), and most applications in the neuroscience and psychophysics literature use at least two channels to describe encoding of stimulus dimensions [<xref ref-type="bibr" rid="pcbi.1006470.ref044">44</xref>]. <xref ref-type="fig" rid="pcbi.1006470.g002">Fig 2</xref> shows encoding of a stimulus dimension with four channels, each with its own tuning model represented by a curve of different color. The tuning model is a formalization of how the channel responds to different stimulus values: each channel responds maximally to its preferred dimensional value and less to other values. The figure shows the response of a multi-channel model to a stimulus with a value of 3 on the target dimension. A channel’s noise model describes the stochasticity in the channel’s responses through a probability distribution. In <xref ref-type="fig" rid="pcbi.1006470.g002">Fig 2</xref>, the average response of each channel is perturbed by random additive noise, represented by the dice. The final channel output is equal to the average response (from the tuning model) plus noise (randomly drawn from the noise model).</p>
<fig id="pcbi.1006470.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006470.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Schematic representation of multiple channels encoding a stimulus with a value of “3” in a target dimension.</title>
<p>If a stimulus with value “3” is presented, each channel gives an average response equivalent to the height of the tuning function at that stimulus value (i.e., the height at the dotted line). The vector of average responses is perturbed by random noise, producing the final channel output.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006470.g002" xlink:type="simple"/>
</fig>
<p>A multichannel model encodes information about dimension <italic>A</italic> through the combined response of <italic>N</italic> channels [<xref ref-type="bibr" rid="pcbi.1006470.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref041">41</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref044">44</xref>], indexed by <italic>c</italic> = 1, 2, …<italic>N</italic>. On each trial, the model produces a (column) random vector of channel responses <bold>r</bold> = [<italic>r</italic><sub>1</sub>, <italic>r</italic><sub>2</sub>, … <italic>r<sub>N</sub></italic>]<bold><sup>⊺</sup></bold>, where <sup>⊺</sup> denotes matrix transpose. Note that <bold>r</bold> depends on the stimulus <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub> according to a set of tuning functions:
<disp-formula id="pcbi.1006470.e005"><alternatives><graphic id="pcbi.1006470.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mi>N</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo></mml:mrow> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula></p>
<p>The probability distribution of <bold>r</bold> also depends on noise parameters <italic>θ</italic>:
<disp-formula id="pcbi.1006470.e006"><alternatives><graphic id="pcbi.1006470.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e006" xlink:type="simple"/><mml:math display="block" id="M6"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi mathvariant="bold">r</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>∼</mml:mo> <mml:mi>η</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula></p>
<p>As indicated earlier, additive Gaussian noise is a common choice for the channel noise model. In that case, the multichannel encoding model is described by a multivariate Gaussian distribution:
<disp-formula id="pcbi.1006470.e007"><alternatives><graphic id="pcbi.1006470.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e007" xlink:type="simple"/><mml:math display="block" id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi mathvariant="bold">r</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:mo mathvariant="bold">Σ</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
where <bold>Σ</bold>(<italic>A<sub>i</sub>B<sub>j</sub></italic>) is an <italic>N</italic> × <italic>N</italic> covariance matrix describing channel noise. In most applications, noise is also assumed to be independently distributed across channels, and all non-diagonal cells in <bold>Σ</bold>(<italic>A<sub>i</sub>B<sub>j</sub></italic>) are zero.</p>
<p>This discussion suggests that a new form of separability can be defined for the neural representation of a dimension: <italic>encoding separability</italic>. When a target dimension is encoded in the exact same way across variations of an irrelevant dimension, we say that the former shows encoding separability from the latter. For encoding separability to hold, both the tuning and noise models of all channels must be equivalent across changes in the irrelevant dimension, which is equivalent to having a single encoding model representing the target dimension, independently of the value of the irrelevant dimension.</p>
<p>Formally, encoding separability of dimension <italic>A</italic> from dimension <italic>B</italic> holds when encoding of the value of <italic>A</italic> does not change with the stimulus’ value on <italic>B</italic>. That is, if and only if, for all values of <bold>r</bold> and <italic>i</italic>:
<disp-formula id="pcbi.1006470.e008"><alternatives><graphic id="pcbi.1006470.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e008" xlink:type="simple"/><mml:math display="block" id="M8"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi mathvariant="bold">r</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi mathvariant="bold">r</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>…</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi mathvariant="bold">r</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:msub><mml:mi>L</mml:mi> <mml:mi>B</mml:mi></mml:msub></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula></p>
<p>Encoding separability of dimension <italic>B</italic> from dimension <italic>A</italic> is defined analogously.</p>
<p>Violations of encoding separability can happen for two reasons. The first possibility is that one or more of the tuning functions in <bold>f</bold> change with the value of <italic>B</italic>. <italic>Tuning separability</italic> of dimension <italic>A</italic> from dimension <italic>B</italic> holds when all tuning functions that encode dimension <italic>A</italic> depend only on the value of <italic>A</italic>–that is, if and only if, for all channels <italic>c</italic> and stimuli <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>:
<disp-formula id="pcbi.1006470.e009"><alternatives><graphic id="pcbi.1006470.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e009" xlink:type="simple"/><mml:math display="block" id="M9"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mi>c</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mi>c</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula></p>
<p>Tuning separability of dimension <italic>B</italic> from dimension <italic>A</italic> is defined analogously. Because <italic>p</italic>(<bold>r</bold>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>, <italic>θ</italic>) depends on <bold>f</bold> (see <xref ref-type="disp-formula" rid="pcbi.1006470.e006">Eq 6</xref>), violations of tuning separability produce violations of encoding separability.</p>
<p>The second reason for a violation of encoding separability is that the noise for one or more channels is distributed differently for different levels of <italic>B</italic>.</p>
<p>Because the Gaussian encoding model described in <xref ref-type="disp-formula" rid="pcbi.1006470.e007">Eq 7</xref> is completely characterized by the mean vector <bold>f</bold>(<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>) and the covariance matrix <bold>Σ</bold>(<italic>A<sub>i</sub>B<sub>j</sub></italic>), encoding separability of <italic>A</italic> from <italic>B</italic> holds if the following two conditions are true for all stimuli <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>:
<disp-formula id="pcbi.1006470.e010"><alternatives><graphic id="pcbi.1006470.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e010" xlink:type="simple"/><mml:math display="block" id="M10"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>f</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>B</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>f</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mo mathvariant="bold">Σ</mml:mo></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>A</mml:mtext><mml:mtext>i</mml:mtext></mml:msub><mml:msub><mml:mtext>B</mml:mtext><mml:mtext>j</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mo mathvariant="bold">Σ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>A</mml:mtext><mml:mtext>i</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula></p>
<p>Encoding separability is a concept describing the way in which stimulus information is represented by single neurons or populations of neurons with similar characteristics. Thus, it can be directly tested only when we have access to direct measurements of <bold>r</bold> (e.g., firing rates from single cell recordings or a measure of the activity of a homogeneous neural population), and a sample size large enough to precisely estimate <italic>p</italic>(<bold>r</bold>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>, <italic>θ</italic>) for all values of <italic>i</italic> and <italic>j</italic>. However, in most cases we do not have access to such direct measurements, but to indirect measures of neural activity contaminated with measurement error, as is the case in fMRI and EEG experiments. Measures of activity in neuroimaging studies result from an unknown, perhaps non-linear transformation of <bold>r</bold>. The encoding distributions <italic>p</italic>(<bold>r</bold>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>, <italic>θ</italic>) cannot be estimated from such indirect measures, but we will show that there are ways to make valid inferences about encoding separability from indirect tests. For that, we must first introduce the concepts of <italic>decoding</italic> and <italic>decoding separability</italic>.</p>
</sec>
<sec id="sec006">
<title>Decoding separability</title>
<p>The term neural decoding refers both to a series of methods used by researchers to extract information about a stimulus from neural data [<xref ref-type="bibr" rid="pcbi.1006470.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref045">45</xref>] and to the mechanisms used by readout neurons to extract similar information, which is later used for decision making and other cognitive processes [<xref ref-type="bibr" rid="pcbi.1006470.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref046">46</xref>]. If dimension <italic>A</italic> is encoded by <italic>N</italic> channels, according to the scheme summarized in <xref ref-type="disp-formula" rid="pcbi.1006470.e006">Eq 6</xref> and depicted in <xref ref-type="fig" rid="pcbi.1006470.g002">Fig 2</xref>, then the decoded estimate of a dimensional value <inline-formula id="pcbi.1006470.e011"><alternatives><graphic id="pcbi.1006470.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, will be some function of the channel responses:
<disp-formula id="pcbi.1006470.e012"><alternatives><graphic id="pcbi.1006470.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>g</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">r</mml:mi> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
where <italic>g</italic>() is a function from <inline-formula id="pcbi.1006470.e013"><alternatives><graphic id="pcbi.1006470.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>N</mml:mi></mml:msup></mml:math></alternatives></inline-formula> to <inline-formula id="pcbi.1006470.e014"><alternatives><graphic id="pcbi.1006470.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mi mathvariant="double-struck">R</mml:mi></mml:math></alternatives></inline-formula> (i.e., from the multidimensional space of the channel responses to the unidimensional space of the decoded dimension). Because <bold>r</bold> is a random vector (see <xref ref-type="disp-formula" rid="pcbi.1006470.e006">Eq 6</xref>), the decoded value <inline-formula id="pcbi.1006470.e015"><alternatives><graphic id="pcbi.1006470.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is a random value that follows a probability distribution <inline-formula id="pcbi.1006470.e016"><alternatives><graphic id="pcbi.1006470.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. In many cases, knowledge about the encoding distribution from <xref ref-type="disp-formula" rid="pcbi.1006470.e006">Eq 6</xref> and the decoder from <xref ref-type="disp-formula" rid="pcbi.1006470.e012">Eq 11</xref> allows one to derive an expression for <inline-formula id="pcbi.1006470.e017"><alternatives><graphic id="pcbi.1006470.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Note also that <inline-formula id="pcbi.1006470.e018"><alternatives><graphic id="pcbi.1006470.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is a continuous variable, despite the fact that it is estimated as a response to stimuli with discrete levels in the stimulus dimension <italic>A</italic>.</p>
<p>There are many possible decoding schemes, but the most popular among researchers [<xref ref-type="bibr" rid="pcbi.1006470.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref047">47</xref>], due to their simplicity and neurobiological plausibility, are simple linear decoders
<disp-formula id="pcbi.1006470.e019"><alternatives><graphic id="pcbi.1006470.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e019" xlink:type="simple"/><mml:math display="block" id="M19"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>β</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">r</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
where <italic>β</italic> is a scalar and <bold>b</bold> is a (column) vector of weights.</p>
<p>With a Gaussian encoding model like the one described by <xref ref-type="disp-formula" rid="pcbi.1006470.e007">Eq 7</xref>, the distribution of linearly-decoded estimates of values on dimension <italic>A</italic> is:
<disp-formula id="pcbi.1006470.e020"><alternatives><graphic id="pcbi.1006470.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e020" xlink:type="simple"/><mml:math display="block" id="M20"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mi>β</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mo mathvariant="bold">Σ</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mi mathvariant="bold">b</mml:mi> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula>
When channel noise is independent, the variance of the decoded variable <inline-formula id="pcbi.1006470.e021"><alternatives><graphic id="pcbi.1006470.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is simply <inline-formula id="pcbi.1006470.e022"><alternatives><graphic id="pcbi.1006470.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup> <mml:msubsup><mml:mi>b</mml:mi> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1006470.e023"><alternatives><graphic id="pcbi.1006470.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> represents the <italic>N</italic> diagonal elements of <bold>Σ</bold>(<italic>A<sub>i</sub>B<sub>j</sub></italic>).</p>
<p>We define <italic>decoding separability</italic> as the situation in which the distribution of decoded values on the target dimension is invariant across changes in the stimulus on a second, irrelevant dimension. That is, decoding separability of dimension <italic>A</italic> from dimension <italic>B</italic> holds when the distribution of decoded values of <italic>A</italic> does not change with the value of <italic>B</italic> in the stimulus–that is, if and only if, for all values of <inline-formula id="pcbi.1006470.e024"><alternatives><graphic id="pcbi.1006470.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <italic>i</italic>:
<disp-formula id="pcbi.1006470.e025"><alternatives><graphic id="pcbi.1006470.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e025" xlink:type="simple"/><mml:math display="block" id="M25"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>…</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:msub><mml:mi>L</mml:mi> <mml:mi>B</mml:mi></mml:msub></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula></p>
<p>Decoding separability of dimension <italic>B</italic> from dimension <italic>A</italic> is defined analogously.</p>
</sec>
<sec id="sec007">
<title>Relation between encoding separability and decoding separability</title>
<p>Decoding separability is easy to check by directly decoding dimensional values from a neuronal population. Moreover, if the same decoding scheme is used for all values of the irrelevant dimension, then the relations between encoding separability and decoding separability shown in <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref> hold, as we show in this section.</p>
<fig id="pcbi.1006470.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006470.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Summary of the relation between encoding separability and decoding separability, according to our extension to GRT.</title>
<p>Arrows should be interpreted as conditional statements of the form “if X, then Y”. These relations mean that a failure of encoding separability is a valid inference from the observation of a failure of decoding separability. However, the presence of encoding separability cannot be validly inferred from an observation of decoding separability.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006470.g003" xlink:type="simple"/>
</fig>
<p><bold>If encoding separability holds, then decoding separability must also hold</bold>. This proposition is represented by the green arrow in <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref>. When encoding separability holds (see <xref ref-type="disp-formula" rid="pcbi.1006470.e008">Eq 8</xref>), <italic>p</italic>(<bold>r</bold>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>, <italic>θ</italic>) = <italic>p</italic>(<bold>r</bold>|<italic>A</italic><sub><italic>i</italic></sub>, <italic>θ</italic>) for all values of <bold>r</bold> and <italic>j</italic>. Because we have assumed that decoding depends only on the value of <bold>r</bold> (<xref ref-type="disp-formula" rid="pcbi.1006470.e012">Eq 11</xref>), the function <italic>g</italic>() is also independent of the value of <italic>B</italic><sub><italic>j</italic></sub>. Thus, regardless of the shape of <italic>p</italic>(<bold>r</bold>|<italic>A</italic><sub><italic>i</italic></sub>, <italic>θ</italic>) and <italic>g</italic>(), the distribution of the decoded variable <inline-formula id="pcbi.1006470.e026"><alternatives><graphic id="pcbi.1006470.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is independent of the value of <italic>B</italic><sub><italic>j</italic></sub>, and decoding separability (<xref ref-type="disp-formula" rid="pcbi.1006470.e025">Eq 14</xref>) holds. In other words, for all values of <italic>B</italic><sub><italic>j</italic></sub> the same decoding transformation <italic>g</italic>() is applied to the same encoding distribution <italic>p</italic>(<bold>r</bold>|<italic>A</italic><sub><italic>i</italic></sub>, <italic>θ</italic>), resulting in the same decoding distribution <inline-formula id="pcbi.1006470.e027"><alternatives><graphic id="pcbi.1006470.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p><bold>If encoding separability fails, then decoding separability may fail or hold</bold>. This is represented by the red arrows in <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref>. Our strategy to prove this proposition will be to disprove two universal statements through counterexamples.</p>
<p>We start by offering a counterexample disproving the following universal statement: <italic>if encoding separability fails, then decoding separability must fail</italic>. Suppose that a dimension <italic>A</italic> is encoded through the model with Gaussian channel noise described by <xref ref-type="disp-formula" rid="pcbi.1006470.e007">Eq 7</xref>, and that we use a linear decoder to estimate <inline-formula id="pcbi.1006470.e028"><alternatives><graphic id="pcbi.1006470.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, as described by <xref ref-type="disp-formula" rid="pcbi.1006470.e019">Eq 12</xref>. Also suppose that there are violations of tuning separability (<xref ref-type="disp-formula" rid="pcbi.1006470.e009">Eq 9</xref>) of <italic>A</italic> from <italic>B</italic> in the encoding model. Without loss of generality, suppose that those violations are differences in the tuning functions of <italic>A</italic><sub>1</sub><italic>B</italic><sub>1</sub> and <italic>A</italic><sub>1</sub><italic>B</italic><sub>2</sub>:
<disp-formula id="pcbi.1006470.e029"><alternatives><graphic id="pcbi.1006470.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>≠</mml:mo> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
or equivalently
<disp-formula id="pcbi.1006470.e030"><alternatives><graphic id="pcbi.1006470.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e030" xlink:type="simple"/><mml:math display="block" id="M30"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold-italic">δ</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <bold><italic>δ</italic></bold> represents a <italic>N</italic> × 1 vector of deviations from tuning separability, and <bold><italic>δ</italic></bold> ≠ <bold>0</bold>.</p>
<p>Under the assumptions listed above, the tuning functions only affect the mean of the decoded variable (see <xref ref-type="disp-formula" rid="pcbi.1006470.e020">Eq 13</xref>), so we can ignore its variance. Now suppose that in this model decoding separability holds. In that case, we have that:
<disp-formula id="pcbi.1006470.e031"><alternatives><graphic id="pcbi.1006470.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>β</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>β</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold-italic">δ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold-italic">δ</mml:mi></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula></p>
<p>For any given <bold><italic>δ</italic></bold> ≠ <bold>0</bold>, there are an infinite number of <bold>b</bold> ≠ <bold>0</bold> that satisfy this equation, yielding a model in which encoding separability fails and decoding separability holds. The universal statement <italic>if encoding separability fails, then decoding separability must fail</italic> is false.</p>
<p>We now offer a counterexample to disprove the alternate universal statement: <italic>if encoding separability fails, then decoding separability must hold</italic>. Following the same line of reasoning as before, we get that if decoding separability fails then:
<disp-formula id="pcbi.1006470.e032"><alternatives><graphic id="pcbi.1006470.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e032" xlink:type="simple"/><mml:math display="block" id="M32"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>β</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>β</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi>d</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mo>[</mml:mo> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold-italic">δ</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi>d</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold-italic">δ</mml:mi></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>d</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
where <italic>d</italic> represents a scalar deviation from decoding separability in the mean of the decoding distributions. As before, for any given <bold><italic>δ</italic></bold> ≠ <bold>0</bold> and <italic>d</italic> ≠ 0, there are an infinite number of <bold>b</bold> ≠ <bold>0</bold> that satisfy this equation, yielding a model in which encoding separability fails and decoding separability fails. The universal statement <italic>if encoding separability fails, then decoding separability must hold</italic> is false.</p>
<p>In summary, if encoding separability fails, then decoding separability may hold or fail. While no universal statements can be made about decoding separability when encoding separability fails, a more specific relation may hold for particular combinations of encoding models and decoding schemes. For example, it might be that for some specific combination of an encoding model and decoding scheme, a failure of encoding separability necessarily leads to a failure of decoding separability, eliminating the diagonal arrow in <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref>. If that was the case, it would be possible to infer encoding separability from a finding of decoding separability. We will not explore these possibilities here and instead will leave them for future work. However, note that the counterexamples offered here involve normally-distributed channel noise and a linear decoder, both of which are common choices in the literature on encoding and decoding. That is, under common assumptions and methods it is not possible to infer encoding separability from a finding of decoding separability.</p>
<p>One general result that must hold true is the following: if encoding separability fails and <inline-formula id="pcbi.1006470.e033"><alternatives><graphic id="pcbi.1006470.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>g</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">r</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is an injective (one-to-one) mapping, then decoding separability must fail. This is the case because when encoding separability fails (without loss of generality) <italic>p</italic>(<bold>r</bold>|<italic>A</italic><sub>1</sub><italic>B</italic><sub>1</sub>, <italic>θ</italic>) ≠ <italic>p</italic>(<bold>r</bold>|<italic>A</italic><sub>1</sub><italic>B</italic><sub>2</sub>, <italic>θ</italic>) for at least one <bold>r</bold>. If <italic>g</italic>() is injective, then this difference in probability at <bold>r</bold> will translate to a difference in probability at the corresponding transformed variable <inline-formula id="pcbi.1006470.e034"><alternatives><graphic id="pcbi.1006470.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. However, because <italic>g</italic>() is a transformation from <inline-formula id="pcbi.1006470.e035"><alternatives><graphic id="pcbi.1006470.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>N</mml:mi></mml:msup></mml:math></alternatives></inline-formula> to <inline-formula id="pcbi.1006470.e036"><alternatives><graphic id="pcbi.1006470.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mi mathvariant="double-struck">R</mml:mi></mml:math></alternatives></inline-formula>, it is in most cases not injective. For example, a linear <italic>g</italic>() from <inline-formula id="pcbi.1006470.e037"><alternatives><graphic id="pcbi.1006470.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>N</mml:mi></mml:msup></mml:math></alternatives></inline-formula> to <inline-formula id="pcbi.1006470.e038"><alternatives><graphic id="pcbi.1006470.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:mi mathvariant="double-struck">R</mml:mi></mml:math></alternatives></inline-formula> cannot be injective.</p>
</sec>
<sec id="sec008">
<title>Inferring encoding separability from tests of decoding separability</title>
<p>From the results of the previous section, which are summarized in <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref>, we can conclude that the observation of a violation of decoding separability in a particular brain region is diagnostic of a corresponding violation of encoding separability. This is because a violation of decoding separability cannot be produced when encoding separability holds. On the other hand, when decoding separability holds nothing can be concluded about encoding separability, as both encoding separability and failures of encoding separability can lead to decoding separability, depending on features of the decoder. This allows an indirect test of encoding separability, which is useful for cases where directly observing encoding separability is difficult (e.g., when indirect measures of neural activity are used, as in fMRI).</p>
</sec>
<sec id="sec009">
<title>Perceptual separability as a form of decoding separability</title>
<p>The concepts of encoding and decoding separability can be linked back to GRT by assuming that perception of a dimensional value is a form of decoding. That is, the key is to assume that the perceptual representation of a stimulus dimension in GRT (the “perceived identity” in <xref ref-type="fig" rid="pcbi.1006470.g001">Fig 1</xref>) is the outcome of decoding a dimensional value from the activity of many channels distributed across the brain (like those shown in <xref ref-type="fig" rid="pcbi.1006470.g002">Fig 2</xref>). This assumption is not new and has proven useful in applications of signal detection theory in the past [<xref ref-type="bibr" rid="pcbi.1006470.ref044">44</xref>].</p>
<p>More specifically, assume that the perceived value of dimension <italic>A</italic>, <italic>x</italic>, is the result of decoding a dimensional value from the activity of many channels distributed across the brain, as in <xref ref-type="disp-formula" rid="pcbi.1006470.e012">Eq 11</xref>. In other words, the perceived value <italic>x</italic> is a special case of the decoded variable <inline-formula id="pcbi.1006470.e039"><alternatives><graphic id="pcbi.1006470.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, but estimated by readout neurons with the goal of guiding behavioral responses in a perceptual task. Denote the decoding function used by these readout neurons to obtain the perceived value <italic>x</italic> as <italic>g</italic><sub><italic>R</italic></sub>(), so that
<disp-formula id="pcbi.1006470.e040"><alternatives><graphic id="pcbi.1006470.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e040" xlink:type="simple"/><mml:math display="block" id="M40"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>x</mml:mi> <mml:mo>=</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">r</mml:mi> <mml:mo>)</mml:mo> <mml:mo>;</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula>
this is just a special case of the more general decoding function shown in <xref ref-type="disp-formula" rid="pcbi.1006470.e012">Eq 11</xref>, but limited only to the decoding schemes that can be implemented by real neurons. We have that
<disp-formula id="pcbi.1006470.e041"><alternatives><graphic id="pcbi.1006470.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e041" xlink:type="simple"/><mml:math display="block" id="M41"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">r</mml:mi> <mml:mo>)</mml:mo> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(18)</label></disp-formula>
is the marginal distribution of perceptual effects along <italic>x</italic>. Under these assumptions, perceptual separability (<xref ref-type="disp-formula" rid="pcbi.1006470.e001">Eq 1</xref>) is a form of decoding separability (<xref ref-type="disp-formula" rid="pcbi.1006470.e025">Eq 14</xref>). As a consequence, from <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref> we know that <italic>any failure of perceptual separability documented in the literature should be reflected in a failure of encoding separability, in brain areas providing useful information for perceptual identification of dimensional values</italic>. The exact brain regions that provide information to solve a particular task are usually unknown, but we can assume that they encode such information in a relatively transparent (easily decodable) way. The set of potential candidates can be reduced to areas known to provide useful information for behavioral performance. Novel methods to identify such areas, which combine information about decoded values in a dimension and behavioral response times, have been recently developed [<xref ref-type="bibr" rid="pcbi.1006470.ref048">48</xref>] and seem very promising. For neuroscientists, this opens the opportunity to link new research on the separability of neural representations with decades of accumulated psychophysical research on perceptual separability [<xref ref-type="bibr" rid="pcbi.1006470.ref015">15</xref>].</p>
<p>In addition, as we have seen in the previous section, the common assumption of a Gaussian distribution of perceptual effects [<xref ref-type="bibr" rid="pcbi.1006470.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref015">15</xref>] is met when the encoding model has additive Gaussian noise and the decoder is linear (see <xref ref-type="disp-formula" rid="pcbi.1006470.e020">Eq 13</xref>), two assumptions that are common in the literature.</p>
</sec>
<sec id="sec010">
<title>Encoding and decoding independence</title>
<p>Here we have focused mostly on the concept of separability. As explained earlier, this concept is particularly important because it captures features of representations, such as invariance and configurality, that are widely studied in vision science. Still, our extended GRT framework allows to define dimensional interactions that are analogous to the concept of perceptual independence from the traditional GRT, but at the level of encoding model and decoded variables. Here we define these forms of independence and very briefly discuss their relation under special assumptions about decoding. We leave a more complete treatment for future work.</p>
<p>Suppose that there are two different sets of channels, with responses <bold>r</bold><sub><italic>A</italic></sub> and <bold>r</bold><sub><italic>B</italic></sub>, encoding stimulus components <italic>A</italic> and <italic>B</italic>, respectively. The distribution of neural responses <bold>r</bold><sub><italic>A</italic></sub> to stimulus <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub> is represented by <italic>p</italic>(<bold>r</bold><sub><italic>A</italic></sub>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>, <italic>θ</italic>), and the distribution of responses <bold>r</bold><sub><italic>B</italic></sub> to stimulus <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub> is represented by <italic>p</italic>(<bold>r</bold><sub><italic>B</italic></sub>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>, <italic>θ</italic>). Given this, <italic>encoding independence</italic> of components <italic>A</italic> and <italic>B</italic> holds in stimulus <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub> if and only if the two encoding distributions are statistically independent; that is, if and only if:
<disp-formula id="pcbi.1006470.e042"><alternatives><graphic id="pcbi.1006470.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e042" xlink:type="simple"/><mml:math display="block" id="M42"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">r</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">r</mml:mi> <mml:mi>B</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">r</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">r</mml:mi> <mml:mi>B</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(19)</label></disp-formula></p>
<p>Now suppose that there are also two separate decoders, <italic>g</italic><sub><italic>A</italic></sub>() to obtain estimate <inline-formula id="pcbi.1006470.e043"><alternatives><graphic id="pcbi.1006470.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <italic>g</italic><sub><italic>B</italic></sub>() to obtain estimate <inline-formula id="pcbi.1006470.e044"><alternatives><graphic id="pcbi.1006470.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. Each of these decoded values is a random variable that follows a probability distribution, represented by <inline-formula id="pcbi.1006470.e045"><alternatives><graphic id="pcbi.1006470.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e046"><alternatives><graphic id="pcbi.1006470.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Given this, <italic>decoding independence</italic> of estimates <inline-formula id="pcbi.1006470.e047"><alternatives><graphic id="pcbi.1006470.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e047" xlink:type="simple"/><mml:math display="inline" id="M47"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e048"><alternatives><graphic id="pcbi.1006470.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e048" xlink:type="simple"/><mml:math display="inline" id="M48"><mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> holds in stimulus <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub> if and only if the two decoding distributions are statistically independent; that is, if and only if:
<disp-formula id="pcbi.1006470.e049"><alternatives><graphic id="pcbi.1006470.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e049" xlink:type="simple"/><mml:math display="block" id="M49"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(20)</label></disp-formula></p>
<p>What is the relation between encoding and decoding independence? We can start by answering this question for the simple case in which the two decoding functions <italic>g</italic><sub><italic>A</italic></sub> and <italic>g</italic><sub><italic>B</italic></sub>, from which <inline-formula id="pcbi.1006470.e050"><alternatives><graphic id="pcbi.1006470.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e050" xlink:type="simple"/><mml:math display="inline" id="M50"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e051"><alternatives><graphic id="pcbi.1006470.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> are estimated, have completely separated domains, meaning that the domain of <italic>g</italic><sub><italic>A</italic></sub> does not include any of the channels in <bold>r</bold><sub><italic>B</italic></sub> and the domain of <italic>g</italic><sub><italic>B</italic></sub> does not include any of the channels in <bold>r</bold><sub><italic>A</italic></sub>. Under this assumption, <italic>if encoding independence holds, then decoding independence must hold</italic>. If <bold>r</bold><sub><italic>A</italic></sub> and <bold>r</bold><sub><italic>B</italic></sub> are independent random vectors and the decoding functions <italic>g</italic><sub><italic>A</italic></sub> and <italic>g</italic><sub><italic>B</italic></sub> used to obtain <inline-formula id="pcbi.1006470.e052"><alternatives><graphic id="pcbi.1006470.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e052" xlink:type="simple"/><mml:math display="inline" id="M52"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e053"><alternatives><graphic id="pcbi.1006470.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e053" xlink:type="simple"/><mml:math display="inline" id="M53"><mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> are borel-measurable functions, then <inline-formula id="pcbi.1006470.e054"><alternatives><graphic id="pcbi.1006470.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e054" xlink:type="simple"/><mml:math display="inline" id="M54"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e055"><alternatives><graphic id="pcbi.1006470.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e055" xlink:type="simple"/><mml:math display="inline" id="M55"><mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> must be independent. On the other hand, <italic>if encoding independence fails, then decoding independence may hold or fail</italic>. We prove this statement by giving two rather trivial counterexamples to universal statements. Suppose that encoding independence fails due to a failure of pairwise independence, in which variables <italic>r</italic><sub><italic>A</italic>1</sub> and <italic>r</italic><sub><italic>B</italic>1</sub> are statistically dependent. Then one can choose linear <italic>g</italic><sub><italic>A</italic></sub> and <italic>g</italic><sub><italic>B</italic></sub> so that all or most of the variability in <inline-formula id="pcbi.1006470.e056"><alternatives><graphic id="pcbi.1006470.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is due to <italic>r</italic><sub><italic>A</italic>1</sub> and all or most of the variability in <inline-formula id="pcbi.1006470.e057"><alternatives><graphic id="pcbi.1006470.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e057" xlink:type="simple"/><mml:math display="inline" id="M57"><mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is due to <italic>r</italic><sub><italic>B</italic>1</sub> (e.g., through strong weights for the target channels and small weights for all other channels). Under such circumstances, <inline-formula id="pcbi.1006470.e058"><alternatives><graphic id="pcbi.1006470.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e058" xlink:type="simple"/><mml:math display="inline" id="M58"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e059"><alternatives><graphic id="pcbi.1006470.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e059" xlink:type="simple"/><mml:math display="inline" id="M59"><mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> will also be dependent and we have a counterexample to the universal statement <italic>if encoding independence fails, then decoding independence must hold</italic>. One can also choose linear <italic>g</italic><sub><italic>A</italic></sub> and <italic>g</italic><sub><italic>B</italic></sub> so that <italic>r</italic><sub><italic>A</italic>1</sub> and <italic>r</italic><sub><italic>B</italic>1</sub> are assigned a weight of zero and have no influence on the decoded variables <inline-formula id="pcbi.1006470.e060"><alternatives><graphic id="pcbi.1006470.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e060" xlink:type="simple"/><mml:math display="inline" id="M60"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e061"><alternatives><graphic id="pcbi.1006470.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e061" xlink:type="simple"/><mml:math display="inline" id="M61"><mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. Because in this example all channels in <bold>r</bold><sub><italic>A</italic></sub> are independent from all channels in <bold>r</bold><sub><italic>B</italic></sub> except for <italic>r</italic><sub><italic>A</italic>1</sub> and <italic>r</italic><sub><italic>B</italic>1</sub>, getting rid of the influence of those two channels over the decoded variables <inline-formula id="pcbi.1006470.e062"><alternatives><graphic id="pcbi.1006470.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e062" xlink:type="simple"/><mml:math display="inline" id="M62"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e063"><alternatives><graphic id="pcbi.1006470.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e063" xlink:type="simple"/><mml:math display="inline" id="M63"><mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> makes them independent (for the same reason that encoding independence implies decoding independence).</p>
<p>Note also that the same assumptions that allowed us to propose that perceptual separability is a form of decoding separability, allow us to conclude that perceptual independence is a form of decoding independence.</p>
</sec>
</sec>
<sec id="sec011">
<title>Direct and indirect tests of decoding separability</title>
<sec id="sec012">
<title>Direct tests of decoding separability and perceptual separability</title>
<p>Assume that <bold>r</bold> is a vector of neural responses encoding dimension <italic>A</italic> in the brain. If we had access to direct measurements of <bold>r</bold> (e.g., firing rates from single cell recordings or a measure of the activity of a homogeneous neural population), we could use an experimenter-defined decoding function <inline-formula id="pcbi.1006470.e064"><alternatives><graphic id="pcbi.1006470.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e064" xlink:type="simple"/><mml:math display="inline" id="M64"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>E</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">r</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> to estimate dimensional values. Obtaining a large number of decoded values <inline-formula id="pcbi.1006470.e065"><alternatives><graphic id="pcbi.1006470.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e065" xlink:type="simple"/><mml:math display="inline" id="M65"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> for each stimulus <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub> allows one to obtain a kernel density estimate (KDE) of <inline-formula id="pcbi.1006470.e066"><alternatives><graphic id="pcbi.1006470.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e066" xlink:type="simple"/><mml:math display="inline" id="M66"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, represented by <inline-formula id="pcbi.1006470.e067"><alternatives><graphic id="pcbi.1006470.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e067" xlink:type="simple"/><mml:math display="inline" id="M67"><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Comparison of such KDEs constitutes a direct test of decoding separability (<xref ref-type="disp-formula" rid="pcbi.1006470.e025">Eq 14</xref>).</p>
<p>Because perceptual separability is a form of decoding separability (<xref ref-type="disp-formula" rid="pcbi.1006470.e041">Eq 18</xref>), the same procedure can be used to obtain the first available direct test of perceptual separability, when a number of conditions are met. First, the vector <bold>r</bold> should include all neural responses encoding dimension <italic>A</italic> in the brain. Second, for all values of <bold>r</bold>, <italic>g</italic><sub><italic>E</italic></sub>(<bold>r</bold>) = <italic>g</italic><sub><italic>R</italic></sub>(<bold>r</bold>), so that <italic>g</italic><sub><italic>E</italic></sub>(<bold>r</bold>) = <italic>x</italic> (each experimentally-decoded value is equal to the perceptual effect). As the vector <bold>r</bold> cannot be identified and measured using currently available methods and <italic>g</italic><sub><italic>R</italic></sub>(<bold>r</bold>) is unknown, both assumptions appear very difficult to meet.</p>
</sec>
<sec id="sec013">
<title>Indirect tests of decoding separability from neuroimaging data</title>
<p>The relations between encoding separability and decoding separability summarized in <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref> hold for any decoder, but it can be shown that using a linear decoder allows for a valid test of decoding separability even when indirect measures of neural activity contaminated with measurement error are used, as is the case with fMRI data.</p>
<p>We have assumed that the channel output <italic>r</italic><sub><italic>c</italic></sub> represents neural activity in a single neuron or a group of neurons with similar properties (e.g., same tuning). Often we do not have access to such direct recordings; rather, we obtain indirect measures of neural activity, which are some function of the activity of several different neural channels. Let <italic>a</italic><sub><italic>m</italic></sub> represent an indirect measure of neural activity, where <italic>m</italic> = 1, 2, …<italic>M</italic> indexes different instances of the same type of measure (e.g., different voxels in an fMRI experiment or electrodes in an EEG experiment). The measures can be represented by a vector <bold>a</bold> = [<italic>a</italic><sub>1</sub>, <italic>a</italic><sub>2</sub>, …<italic>a</italic><sub><italic>M</italic></sub>], which is a function of the activity of all channels in the encoding model:
<disp-formula id="pcbi.1006470.e068"><alternatives><graphic id="pcbi.1006470.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e068" xlink:type="simple"/><mml:math display="block" id="M68"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">a</mml:mi> <mml:mo>=</mml:mo> <mml:mi>φ</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">r</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">e</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(21)</label></disp-formula>
where <bold>e</bold> is a random vector representing measurement error:
<disp-formula id="pcbi.1006470.e069"><alternatives><graphic id="pcbi.1006470.e069g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e069" xlink:type="simple"/><mml:math display="block" id="M69"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>∼</mml:mo> <mml:mi>ϵ</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(22)</label></disp-formula> <italic>ϵ</italic> denotes the probability distribution of measurement error, which depends on a set of parameters <italic>θ</italic><sub><italic>e</italic></sub>. Together, Eqs <xref ref-type="disp-formula" rid="pcbi.1006470.e068">21</xref> and <xref ref-type="disp-formula" rid="pcbi.1006470.e069">22</xref> describe the <italic>measurement model</italic> for <bold>a</bold>.</p>
<p>In a typical multivariate analysis of neuroimaging data, we decode an estimate of a dimensional value <inline-formula id="pcbi.1006470.e070"><alternatives><graphic id="pcbi.1006470.e070g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e070" xlink:type="simple"/><mml:math display="inline" id="M70"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> directly from <bold>a</bold>. We can choose to use a linear decoder for this task, so that
<disp-formula id="pcbi.1006470.e071"><alternatives><graphic id="pcbi.1006470.e071g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e071" xlink:type="simple"/><mml:math display="block" id="M71"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>β</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">a</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>β</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mo>(</mml:mo> <mml:mi>φ</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">r</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">e</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>β</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi>φ</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">r</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">e</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(23)</label></disp-formula></p>
<p>We can think of the estimate <inline-formula id="pcbi.1006470.e072"><alternatives><graphic id="pcbi.1006470.e072g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e072" xlink:type="simple"/><mml:math display="inline" id="M72"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> as the sum of two independent random variables: <inline-formula id="pcbi.1006470.e073"><alternatives><graphic id="pcbi.1006470.e073g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e073" xlink:type="simple"/><mml:math display="inline" id="M73"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>β</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi>φ</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">r</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, which depends exclusively on the distribution of <bold>r</bold>, and <inline-formula id="pcbi.1006470.e074"><alternatives><graphic id="pcbi.1006470.e074g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e074" xlink:type="simple"/><mml:math display="inline" id="M74"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:mi mathvariant="bold">e</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, which depends exclusively on the error distribution from <xref ref-type="disp-formula" rid="pcbi.1006470.e069">Eq 22</xref>. The variable <inline-formula id="pcbi.1006470.e075"><alternatives><graphic id="pcbi.1006470.e075g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e075" xlink:type="simple"/><mml:math display="inline" id="M75"><mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub></mml:math></alternatives></inline-formula> depends on <bold>r</bold> through a composite function. We can think of this composite function as a decoder: <italic>g</italic>(<bold>r</bold>) = <italic>β</italic> + <bold>b</bold><sup>⊺</sup> <italic>φ</italic>(<bold>r</bold>) and use <inline-formula id="pcbi.1006470.e076"><alternatives><graphic id="pcbi.1006470.e076g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e076" xlink:type="simple"/><mml:math display="inline" id="M76"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> to test for decoding separability. Unfortunately, our measurements are contaminated by the variable <inline-formula id="pcbi.1006470.e077"><alternatives><graphic id="pcbi.1006470.e077g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e077" xlink:type="simple"/><mml:math display="inline" id="M77"><mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub></mml:math></alternatives></inline-formula> with distribution <inline-formula id="pcbi.1006470.e078"><alternatives><graphic id="pcbi.1006470.e078g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e078" xlink:type="simple"/><mml:math display="inline" id="M78"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Because <inline-formula id="pcbi.1006470.e079"><alternatives><graphic id="pcbi.1006470.e079g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e079" xlink:type="simple"/><mml:math display="inline" id="M79"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is the sum of two independent random variables, the distribution of <inline-formula id="pcbi.1006470.e080"><alternatives><graphic id="pcbi.1006470.e080g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e080" xlink:type="simple"/><mml:math display="inline" id="M80"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is a convolution of the distribution of each of its components:
<disp-formula id="pcbi.1006470.e081"><alternatives><graphic id="pcbi.1006470.e081g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e081" xlink:type="simple"/><mml:math display="block" id="M81"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>*</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(24)</label></disp-formula>
where * denotes the convolution integral.</p>
<p>Thus, KDEs obtained from <inline-formula id="pcbi.1006470.e082"><alternatives><graphic id="pcbi.1006470.e082g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e082" xlink:type="simple"/><mml:math display="inline" id="M82"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> decoded from neuroimaging data reflect the target decoding distribution convolved with an error distribution. This means that obtaining direct estimates of GRT perceptual distributions from neuroimaging data may not be possible. Still, it is possible to obtain a valid measure of violations of decoding separability.</p>
<p>Without loss of generality, suppose that we want to measure differences between the distributions <inline-formula id="pcbi.1006470.e083"><alternatives><graphic id="pcbi.1006470.e083g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e083" xlink:type="simple"/><mml:math display="inline" id="M83"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e084"><alternatives><graphic id="pcbi.1006470.e084g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e084" xlink:type="simple"/><mml:math display="inline" id="M84"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. A number of measures of the distance between two probability densities (such as the <italic>L</italic>1, <italic>L</italic>2 and <italic>L</italic>∞ distances, see [<xref ref-type="bibr" rid="pcbi.1006470.ref049">49</xref>]) start by computing a difference function:
<disp-formula id="pcbi.1006470.e085"><alternatives><graphic id="pcbi.1006470.e085g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e085" xlink:type="simple"/><mml:math display="block" id="M85"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(25)</label></disp-formula></p>
<p>From neuroimaging data, we obtain estimates of the distributions <inline-formula id="pcbi.1006470.e086"><alternatives><graphic id="pcbi.1006470.e086g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e086" xlink:type="simple"/><mml:math display="inline" id="M86"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>*</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e087"><alternatives><graphic id="pcbi.1006470.e087g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e087" xlink:type="simple"/><mml:math display="inline" id="M87"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>*</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, where we have assumed that the measurement error model does not change with the value of the stimulus in dimension <italic>B</italic>. The difference function between these two distributions is:
<disp-formula id="pcbi.1006470.e088"><alternatives><graphic id="pcbi.1006470.e088g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e088" xlink:type="simple"/><mml:math display="block" id="M88"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>*</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>*</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>[</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo> <mml:mo>*</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>*</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(26)</label></disp-formula></p>
<p>Thus, the difference between noisy KDEs <inline-formula id="pcbi.1006470.e089"><alternatives><graphic id="pcbi.1006470.e089g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e089" xlink:type="simple"/><mml:math display="inline" id="M89"><mml:mrow><mml:mover accent="true"><mml:mi>δ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo> <mml:mo>≈</mml:mo> <mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is an estimate of the target difference function <inline-formula id="pcbi.1006470.e090"><alternatives><graphic id="pcbi.1006470.e090g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e090" xlink:type="simple"/><mml:math display="inline" id="M90"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> convolved with the error kernel <inline-formula id="pcbi.1006470.e091"><alternatives><graphic id="pcbi.1006470.e091g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e091" xlink:type="simple"/><mml:math display="inline" id="M91"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Note first that if decoding separability holds, then <inline-formula id="pcbi.1006470.e092"><alternatives><graphic id="pcbi.1006470.e092g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e092" xlink:type="simple"/><mml:math display="inline" id="M92"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and we expect <inline-formula id="pcbi.1006470.e093"><alternatives><graphic id="pcbi.1006470.e093g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e093" xlink:type="simple"/><mml:math display="inline" id="M93"><mml:mrow><mml:mover accent="true"><mml:mi>δ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> to approximate zero for all values of <inline-formula id="pcbi.1006470.e094"><alternatives><graphic id="pcbi.1006470.e094g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e094" xlink:type="simple"/><mml:math display="inline" id="M94"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> as sample size increases. Any deviations from a constant zero function indicate violations of decoding separability. If decoding separability does not hold and <inline-formula id="pcbi.1006470.e095"><alternatives><graphic id="pcbi.1006470.e095g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e095" xlink:type="simple"/><mml:math display="inline" id="M95"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>≠</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> for some <inline-formula id="pcbi.1006470.e096"><alternatives><graphic id="pcbi.1006470.e096g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e096" xlink:type="simple"/><mml:math display="inline" id="M96"><mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, then the shape of the error kernel determines how it affects <inline-formula id="pcbi.1006470.e097"><alternatives><graphic id="pcbi.1006470.e097g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e097" xlink:type="simple"/><mml:math display="inline" id="M97"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Under the common assumption that measurement error <bold>e</bold> is Gaussian with zero mean and covariance matrix <inline-formula id="pcbi.1006470.e098"><alternatives><graphic id="pcbi.1006470.e098g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e098" xlink:type="simple"/><mml:math display="inline" id="M98"><mml:msub><mml:mo mathvariant="bold">Σ</mml:mo> <mml:mi>e</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1006470.e099"><alternatives><graphic id="pcbi.1006470.e099g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e099" xlink:type="simple"/><mml:math display="inline" id="M99"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>e</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> will also be Gaussian with zero mean and variance <inline-formula id="pcbi.1006470.e100"><alternatives><graphic id="pcbi.1006470.e100g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e100" xlink:type="simple"/><mml:math display="inline" id="M100"><mml:mrow><mml:msup><mml:mi mathvariant="bold">b</mml:mi> <mml:mo mathvariant="bold">⊺</mml:mo></mml:msup> <mml:msub><mml:mo mathvariant="bold">Σ</mml:mo> <mml:mi>e</mml:mi></mml:msub> <mml:mi mathvariant="bold">b</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. In this case, the convolution attenuates high-frequency fluctuations in the difference function <inline-formula id="pcbi.1006470.e101"><alternatives><graphic id="pcbi.1006470.e101g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e101" xlink:type="simple"/><mml:math display="inline" id="M101"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. In general, the difference <inline-formula id="pcbi.1006470.e102"><alternatives><graphic id="pcbi.1006470.e102g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e102" xlink:type="simple"/><mml:math display="inline" id="M102"><mml:mrow><mml:mover accent="true"><mml:mi>δ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> will capture some deviations from decoding separability, but not necessarily all of them.</p>
<p>In sum, as the number of data points used to obtain KDEs increases, a distance measure based on the function <inline-formula id="pcbi.1006470.e103"><alternatives><graphic id="pcbi.1006470.e103g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e103" xlink:type="simple"/><mml:math display="inline" id="M103"><mml:mrow><mml:mover accent="true"><mml:mi>δ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> will be approximately zero when there are no violations of decoding separability, and any non-zero value will be the consequence of a violation of decoding separability. This makes such a measure a valid indicator of violations of decoding separability. One measure based on <inline-formula id="pcbi.1006470.e104"><alternatives><graphic id="pcbi.1006470.e104g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e104" xlink:type="simple"/><mml:math display="inline" id="M104"><mml:mrow><mml:mover accent="true"><mml:mi>δ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the L1 norm:
<disp-formula id="pcbi.1006470.e105"><alternatives><graphic id="pcbi.1006470.e105g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e105" xlink:type="simple"/><mml:math display="block" id="M105"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi> <mml:mn>1</mml:mn> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mo>|</mml:mo> <mml:mover accent="true"><mml:mi>δ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo> <mml:mo>|</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(27)</label></disp-formula>
which is the basis for the statistic that we use in our test to measure deviations from decoding separability (DDS statistic; see <xref ref-type="sec" rid="sec027">Materials and methods</xref> section).</p>
<p>Note that the property described by <xref ref-type="disp-formula" rid="pcbi.1006470.e088">Eq 26</xref> holds for distance measures based on the simple difference function <inline-formula id="pcbi.1006470.e106"><alternatives><graphic id="pcbi.1006470.e106g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e106" xlink:type="simple"/><mml:math display="inline" id="M106"><mml:mrow><mml:mover accent="true"><mml:mi>δ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Other commonly-used measures of the distance between two distributions, such as the Kullback-Leibler divergence, are not influenced by measurement error in this straightforward manner, and thus their interpretation is more difficult.</p>
<p>Linear decoders, which are necessary to obtain a valid indirect test of decoding separability, are also the most widely used in the MVPA literature [<xref ref-type="bibr" rid="pcbi.1006470.ref047">47</xref>]. This allows us to link our framework to this line of research in neuroimaging.</p>
</sec>
</sec>
<sec id="sec014">
<title>Relation to previous operational definitions of neural independence</title>
<sec id="sec015">
<title>Orthogonality of neural representations</title>
<p>Suppose that there are two vectors in the space of encoding channels, <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub>, representing important summary statistics of how <italic>A</italic> and <italic>B</italic> are encoded, respectively. We can interpret <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> as an estimate of the direction along which dimension <italic>A</italic> is encoded, and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub> as an estimate of the direction along which dimension <italic>B</italic> is encoded. We can define <italic>encoding vector orthogonality</italic> as the situation in which these two vectors are orthogonal from each other:
<disp-formula id="pcbi.1006470.e107"><alternatives><graphic id="pcbi.1006470.e107g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e107" xlink:type="simple"/><mml:math display="block" id="M107"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ρ</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>⊥</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">ρ</mml:mi> <mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(28)</label></disp-formula></p>
<p>Each choice of statistic <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub> produces a different form of encoding vector orthogonality. For example, one might be interested in two mean vectors summarizing the encoding distributions for stimuli along the dimensions <italic>A</italic> and <italic>B</italic>. In that case, a simple possibility would be to use stimuli without any value in dimension <italic>A</italic>, represented by <italic>A</italic><sub>0</sub>, and stimuli without any value in dimension <italic>B</italic>, represented by <italic>B</italic><sub>0</sub>. Thus, <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub>0</sub> would represent a stimulus with a value in dimension <italic>A</italic> only, and <italic>A</italic><sub>0</sub><italic>B</italic><sub><italic>j</italic></sub> would represent a stimulus with a value in dimension <italic>B</italic> only. We might be interested on the mean response of encoding channels to such stimuli, so that <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> = <bold>f</bold>(<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub>0</sub>) and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub> = <bold>f</bold>(<italic>A</italic><sub>0</sub><italic>B</italic><sub><italic>j</italic></sub>), or perhaps on the average responses when any level of the dimensions is presented, so that <inline-formula id="pcbi.1006470.e108"><alternatives><graphic id="pcbi.1006470.e108g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e108" xlink:type="simple"/><mml:math display="inline" id="M108"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ρ</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>L</mml:mi> <mml:mi>A</mml:mi></mml:msub></mml:mfrac> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>L</mml:mi> <mml:mi>A</mml:mi></mml:msub></mml:msubsup> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e109"><alternatives><graphic id="pcbi.1006470.e109g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e109" xlink:type="simple"/><mml:math display="inline" id="M109"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ρ</mml:mi> <mml:mi>B</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>L</mml:mi> <mml:mi>B</mml:mi></mml:msub></mml:mfrac> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>L</mml:mi> <mml:mi>B</mml:mi></mml:msub></mml:msubsup> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Of course, other possibilities exist (e.g., computing expectations on marginal distributions), and in each case <xref ref-type="disp-formula" rid="pcbi.1006470.e107">Eq 28</xref> offers a different definition of encoding vector orthogonality.</p>
<p>Linear decoders (<xref ref-type="disp-formula" rid="pcbi.1006470.e019">Eq 12</xref>) also provide estimates of directions in space along which dimensions vary. We might obtain one of such decoders for each dimension, each with its own weight vector <bold>b</bold>, so that <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> = <bold>b</bold><sub><italic>A</italic></sub> and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub> = <bold>b</bold><sub><italic>B</italic></sub>. Again, different decoders provide different definitions of encoding vector orthogonality. Note that this is a form of <italic>encoding</italic> vector orthogonality, as the weights are defined in the space of the encoding channels (i.e., <inline-formula id="pcbi.1006470.e110"><alternatives><graphic id="pcbi.1006470.e110g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e110" xlink:type="simple"/><mml:math display="inline" id="M110"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>N</mml:mi></mml:msup></mml:math></alternatives></inline-formula>) rather than the decoded variables <inline-formula id="pcbi.1006470.e111"><alternatives><graphic id="pcbi.1006470.e111g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e111" xlink:type="simple"/><mml:math display="inline" id="M111"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006470.e112"><alternatives><graphic id="pcbi.1006470.e112g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e112" xlink:type="simple"/><mml:math display="inline" id="M112"><mml:mover accent="true"><mml:mi>B</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. Decoding vector orthogonality cannot be defined, as the decoded variables are scalars.</p>
<p>Neuroscientists have shown great interest in measuring different forms of measurement vector orthogonality, although in many cases they use indirect tests. That is, experimenters usually test the orthogonality of two vectors, <bold>h</bold><sub><italic>A</italic></sub> and <bold>h</bold><sub><italic>B</italic></sub> (summarizing information about dimensions <italic>A</italic> and <italic>B</italic>, respectively), defined in a <italic>measurement space</italic> that is a transformation of the original neural <italic>encoding space</italic>. We represent this transformation with <italic>φ</italic><sub><italic>h</italic></sub>(), to highlight its relation to the measurement model defined in <xref ref-type="disp-formula" rid="pcbi.1006470.e068">Eq 21</xref>. The transformation <italic>φ</italic><sub><italic>h</italic></sub>() may be known. For example, Kayaert et al. [<xref ref-type="bibr" rid="pcbi.1006470.ref050">50</xref>] submitted patterns of neural firing rates to multidimensional scaling, and tested the orthogonality of two vectors in the solution space, each representing changes in a dimension of interest. In many cases, however, <italic>φ</italic><sub><italic>h</italic></sub>() is unknown. This is the case when the test is carried out in a space of indirect activity measures from neuroimaging, as represented by <xref ref-type="disp-formula" rid="pcbi.1006470.e068">Eq 21</xref>. For example, Hadj-Bouziane et al. [<xref ref-type="bibr" rid="pcbi.1006470.ref006">6</xref>] tested the orthogonality of two vectors of unidimensional fMRI contrasts (one for faces &gt; objects and one for expressive face &gt; neutral face). Another possibility would be to obtain weight vectors representing directions that separate classes best in such measurement space (see below). Although vectors of unidimensional contrasts (like those used by Hadj Bouziane et al. [<xref ref-type="bibr" rid="pcbi.1006470.ref006">6</xref>]) and weight vectors do not have the same interpretation [<xref ref-type="bibr" rid="pcbi.1006470.ref051">51</xref>] (in most cases, they will be completely different vectors), they are both defined within the same measurement space of fMRI voxels or EEG channels. In other cases, the test is carried out in the physical space of the measurements. For example, Baumann et al. [<xref ref-type="bibr" rid="pcbi.1006470.ref052">52</xref>] estimated <bold>h</bold><sub><italic>A</italic></sub> and <bold>h</bold><sub><italic>B</italic></sub> as directions in the physical space of a brain region (the inferior colliculus) along which two dimensions of sound were encoded. In this case, although <italic>φ</italic><sub><italic>h</italic></sub>() is unknown, the measurement space itself might be interesting and studying it could result in a better understanding of brain function.</p>
<p>More generally, we can define measurement vector orthogonality as the case in which the following relation holds:
<disp-formula id="pcbi.1006470.e113"><alternatives><graphic id="pcbi.1006470.e113g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e113" xlink:type="simple"/><mml:math display="block" id="M113"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>⊥</mml:mo> <mml:msub><mml:mi mathvariant="bold">h</mml:mi> <mml:mi>B</mml:mi></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(29)</label></disp-formula></p>
<p>Note that <xref ref-type="disp-formula" rid="pcbi.1006470.e113">Eq 29</xref> holds if <bold>h</bold><sub><italic>A</italic></sub> and <bold>h</bold><sub><italic>B</italic></sub> are mean-centered and their Pearson correlation is zero, as the Pearson correlation of two mean-centered vectors equals the cosine of their angle. Previous researchers have used both the angle between vectors [<xref ref-type="bibr" rid="pcbi.1006470.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref052">52</xref>] and their correlation [<xref ref-type="bibr" rid="pcbi.1006470.ref006">6</xref>] as measures of orthogonality.</p>
<p>Many researchers seem to make the implicit assumption that the measurement space (e.g., the estimated activity patterns in an fMRI study) can be directly interpreted as the encoding space. In that case, different choices for <bold>h</bold><sub><italic>A</italic></sub> and <bold>h</bold><sub><italic>B</italic></sub> have widely different interpretations (e.g., contrast vectors versus classifier weights; see [<xref ref-type="bibr" rid="pcbi.1006470.ref051">51</xref>]). However, we believe that this assumption is untenable in general, and particularly difficult to justify in the case of neuroimaging, where the transformation <italic>φ</italic><sub><italic>h</italic></sub>() is known to involve a series of complicated physical and biological processes.</p>
<p>We suspect that neuroscientists apply the different tests in the hope of learning something about the underlying neural representations at the level of encoding. To understand whether and how that goal can be achieved, the important issue is not so much what version of the test is used or what form of encoding vector orthogonality one is interested in. Rather, the important question is what can be inferred about encoding vector orthogonality in general from the results of any indirect test. That is, given a choice of <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub> as encoding vectors of interest, a choice of <bold>h</bold><sub><italic>A</italic></sub> and <bold>h</bold><sub><italic>B</italic></sub> as measurement vectors of interest, and a particular transformation <italic>φ</italic><sub><italic>h</italic></sub>() from the encoding space to the measurement space: What does observing measurement vector orthogonality (<xref ref-type="disp-formula" rid="pcbi.1006470.e113">Eq 29</xref>) tell us about encoding vector orthogonality (<xref ref-type="disp-formula" rid="pcbi.1006470.e107">Eq 28</xref>). The answer is: in most cases, nothing, even when one makes the simplifying assumption that <bold>h</bold><sub><italic>A</italic></sub> = <italic>φ</italic><sub><italic>h</italic></sub>(<italic>ρ</italic><sub><italic>A</italic></sub>) and <bold>h</bold><sub><italic>B</italic></sub> = <italic>φ</italic><sub><italic>h</italic></sub>(<italic>ρ</italic><sub><italic>B</italic></sub>).</p>
<p>The reason is that encoding vector orthogonality is defined as a 90-degree angle between <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub> (<xref ref-type="disp-formula" rid="pcbi.1006470.e107">Eq 28</xref>), and only rigid transformations (i.e., not even all linear transformations) can preserve this angle. Thus, when <italic>φ</italic><sub><italic>h</italic></sub>() is unknown and involves more than rigid transformations (the most common case), a 90-degree angle between <bold>h</bold><sub><italic>A</italic></sub> and <bold>h</bold><sub><italic>B</italic></sub> could be accompanied by any angle value between <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub>, depending on the specifics of the unknown <italic>φ</italic><sub><italic>h</italic></sub>(). The test might be uninformative even in the rare case in which <italic>φ</italic><sub><italic>h</italic></sub>() is known and linear, as computing the angle between <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub> from <bold>h</bold><sub><italic>A</italic></sub> and <bold>h</bold><sub><italic>B</italic></sub> would require for <italic>φ</italic><sub><italic>h</italic></sub>() to have an inverse. In all the examples from the literature discussed earlier, an observation of measurement vector orthogonality does not provide any information about encoding vector orthogonality. However, as indicated above, the test might provide useful information about other aspects of brain representation different from encoding, as is the case when the measurement space of <bold>h</bold><sub><italic>A</italic></sub> and <bold>h</bold><sub><italic>B</italic></sub> is itself interesting (e.g., physical space in studies of functional brain topography, see [<xref ref-type="bibr" rid="pcbi.1006470.ref052">52</xref>]).</p>
<p>It is possible to link a specific form of encoding vector orthogonality to the concept of perceptual independence (<xref ref-type="disp-formula" rid="pcbi.1006470.e002">Eq 2</xref>) from GRT. When stimulus <italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub> is presented, it is represented as a new vector <bold>r</bold> in the same encoding space that contains <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub>. If we assume that (i) the projection of this vector onto <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub> corresponds to the perceived values of dimensions <italic>A</italic> and <italic>B</italic>, then measurement vector orthogonality is equivalent to <italic>dimensional orthogonality</italic> [<xref ref-type="bibr" rid="pcbi.1006470.ref053">53</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref054">54</xref>]. One case in which this assumption is met is when the readout functions from <xref ref-type="disp-formula" rid="pcbi.1006470.e040">Eq 17</xref> (i.e., the functions used by readout neurons to decode perceptual effects from neural activities) are linear. In that case, the weight vectors of the linear decoders correspond to <bold><italic>ρ</italic></bold><sub><italic>A</italic></sub> and <bold><italic>ρ</italic></bold><sub><italic>B</italic></sub> and their orthogonality is equivalent to orthogonality of the perceptual dimensions within the encoding space. Ashby and Townsend [<xref ref-type="bibr" rid="pcbi.1006470.ref014">14</xref>] showed that if, in addition, (ii) the trial-by-trial perceptual effects have a multivariate Gaussian distribution, <inline-formula id="pcbi.1006470.e114"><alternatives><graphic id="pcbi.1006470.e114g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e114" xlink:type="simple"/><mml:math display="inline" id="M114"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>y</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">μ</mml:mi> <mml:mo>,</mml:mo> <mml:mo mathvariant="bold">Σ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, and (iii) <inline-formula id="pcbi.1006470.e115"><alternatives><graphic id="pcbi.1006470.e115g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e115" xlink:type="simple"/><mml:math display="inline" id="M115"><mml:mo mathvariant="bold">Σ</mml:mo></mml:math></alternatives></inline-formula> does not depend on the stimulus (i.e., all perceptual distributions have identical variance-covariance matrices), then dimensional orthogonality and perceptual independence (as defined in <xref ref-type="disp-formula" rid="pcbi.1006470.e002">Eq 2</xref>) are equivalent.</p>
<p>Assumptions (i)-(iii) also allow one to link measurement vector orthogonality and perceptual independence. However, in this case the assumptions seem extremely strong and hard to meet. Although assumptions (ii) and (iii) are common in the psychophysics literature and they may be justifiable, assumption (i) is very problematic, as there seems to be no way to guarantee that the estimates <bold>h</bold><sub><italic>A</italic></sub> and <bold>h</bold><sub><italic>B</italic></sub> must correspond to perceived stimulus dimensions. In addition, note that dimensional orthogonality must be defined in a particular space of interest. Determining whether the two perceptual dimensions are orthogonal within the original encoding space seems like an interesting question worth pursuing. On the other hand, determining whether the two perceptual dimensions are orthogonal within some arbitrary measurement space does not carry the same weight.</p>
<p>Finally, the problems with the measurement vector orthogonality test are not restricted to their difficult interpretation. In addition, there are practical issues with the way in which the tests are applied. In particular, orthogonality tests are best suited to provide evidence of violations of orthogonality, but they are usually applied to provide evidence of its presence. More specifically, if <bold>h</bold><sub><italic>A</italic></sub> and <bold>h</bold><sub><italic>B</italic></sub> were random vectors, then one would expect their correlation to be close to zero (i.e., orthogonal vectors), especially for high-dimensional vectors such as those studied by Hadj-Bouziane et al. [<xref ref-type="bibr" rid="pcbi.1006470.ref006">6</xref>]. Under such circumstances, a finding of orthogonality is expected even from completely random data. In addition, orthogonality corresponds to a single value (zero correlation or 90-degree angle) and therefore evidence of orthogonality requires special statistical tests that can provide evidence for that specific value (e.g., evidence for the null in a Bayes factor test, or a small confidence interval containing the target value). Such tests have not been used in previous tests of orthogonality. Here, we will explore whether it is possible to find <italic>violations</italic> of orthogonality in our data, rather than trying to find evidence <italic>for</italic> orthogonality as in previous studies.</p>
<p>In sum, measurement vector orthogonality is an operational test of independence of neural representations, and several researchers have used some version of it in past studies. In general, the results of this test cannot be related to a corresponding property of stimulus encoding, which we named encoding vector orthogonality. If some strong assumptions are met, the test can be related to the concept of perceptual independence from GRT, which is conceptually distinct from the several forms of separability on which we have focused here. In particular, perceptual independence is a property of a single stimulus. It holds if different stimulus components are processed independently of each other. In contrast, separability is a property of an ensemble of stimuli. It holds if processing of one component is unaffected by changes in other components. In practical terms, we would expect that violations of measurement representation orthogonality would be unrelated to violations of decoding and encoding separability, as they measure completely different concepts.</p>
</sec>
<sec id="sec016">
<title>Classification accuracy invariance and generalization</title>
<p>A second operational test of independence of neural representations, more closely related to the separability measures investigated in this article, has been recently used in research on invariance of face representation. In this test, activity patterns in a given brain region are classified according to some target dimension. For example, activity patterns in visual cortex could be classified according to the identity of faces presented during an experiment. Then the classifier is tested with new patterns, produced during presentations of the same identities but with changes in some irrelevant face dimension, such as viewpoint or expression [<xref ref-type="bibr" rid="pcbi.1006470.ref055">55</xref>–<xref ref-type="bibr" rid="pcbi.1006470.ref057">57</xref>]. If the classifier’s accuracy is significantly above chance, it is concluded that the representations of the target dimension (face identity) are invariant to changes in the irrelevant dimension. A simpler version of the test simply checks for significant classification accuracy using all data [<xref ref-type="bibr" rid="pcbi.1006470.ref009">9</xref>], but this is much less informative than a test based on generalization after changes in the irrelevant dimension [<xref ref-type="bibr" rid="pcbi.1006470.ref055">55</xref>].</p>
<p>Formally, let <italic>ℓ</italic><sub><italic>i</italic></sub> represent a label returned by the classifier indicating that it has estimated that level <italic>i</italic> of dimension <italic>A</italic> has been presented, and suppose the experiment includes a total of <italic>L</italic><sub><italic>A</italic></sub> different levels of dimension A. Then <italic>classification accuracy generalization</italic> is defined in the following way:
<disp-formula id="pcbi.1006470.e116"><alternatives><graphic id="pcbi.1006470.e116g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e116" xlink:type="simple"/><mml:math display="block" id="M116"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>if</mml:mtext></mml:mrow></mml:mtd> <mml:mtd><mml:mspace width="1.em"/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>ℓ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>&gt;</mml:mo></mml:mtd> <mml:mtd><mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>L</mml:mi> <mml:mi>A</mml:mi></mml:msub></mml:mfrac></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mtext>then</mml:mtext></mml:mtd> <mml:mtd><mml:mspace width="1.em"/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>ℓ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>&gt;</mml:mo></mml:mtd> <mml:mtd><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>L</mml:mi> <mml:mi>A</mml:mi></mml:msub></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(30)</label></disp-formula>
for all <italic>i</italic> and <italic>j</italic>. That is, if the probability of correct classification of the level of <italic>A</italic> is higher than chance (<inline-formula id="pcbi.1006470.e117"><alternatives><graphic id="pcbi.1006470.e117g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e117" xlink:type="simple"/><mml:math display="inline" id="M117"><mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>L</mml:mi> <mml:mi>A</mml:mi></mml:msub></mml:mfrac></mml:math></alternatives></inline-formula>) at level 1 of dimension <italic>B</italic>, then it must be higher than chance at all levels of <italic>B</italic> for classification accuracy generalization to hold.</p>
<p>It is possible to indirectly relate classification accuracy generalization to encoding separability, through its clear relation to decoding separability. We do this first for the case in which there is access to direct measures of neural activity that are used to estimate <inline-formula id="pcbi.1006470.e118"><alternatives><graphic id="pcbi.1006470.e118g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e118" xlink:type="simple"/><mml:math display="inline" id="M118"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, as in <xref ref-type="disp-formula" rid="pcbi.1006470.e012">Eq 11</xref>. Because <inline-formula id="pcbi.1006470.e119"><alternatives><graphic id="pcbi.1006470.e119g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e119" xlink:type="simple"/><mml:math display="inline" id="M119"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is a noisy estimate that can assume any value in <inline-formula id="pcbi.1006470.e120"><alternatives><graphic id="pcbi.1006470.e120g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e120" xlink:type="simple"/><mml:math display="inline" id="M120"><mml:mi mathvariant="double-struck">R</mml:mi></mml:math></alternatives></inline-formula>, a classifier partitions this space into <italic>L</italic><sub><italic>A</italic></sub> regions, one for each of the values of dimension <italic>A</italic> included in the experiment. Let <inline-formula id="pcbi.1006470.e121"><alternatives><graphic id="pcbi.1006470.e121g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e121" xlink:type="simple"/><mml:math display="inline" id="M121"><mml:msub><mml:mi mathvariant="script">R</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula> represent the region associated with label <italic>ℓ</italic><sub><italic>i</italic></sub>, so that the classifier assigns this label to a neural pattern when <inline-formula id="pcbi.1006470.e122"><alternatives><graphic id="pcbi.1006470.e122g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e122" xlink:type="simple"/><mml:math display="inline" id="M122"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">R</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Each <inline-formula id="pcbi.1006470.e123"><alternatives><graphic id="pcbi.1006470.e123g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e123" xlink:type="simple"/><mml:math display="inline" id="M123"><mml:msub><mml:mi mathvariant="script">R</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula> may be a single continuous interval in <inline-formula id="pcbi.1006470.e124"><alternatives><graphic id="pcbi.1006470.e124g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e124" xlink:type="simple"/><mml:math display="inline" id="M124"><mml:mi mathvariant="double-struck">R</mml:mi></mml:math></alternatives></inline-formula> or composed of several such intervals, and the union of all <inline-formula id="pcbi.1006470.e125"><alternatives><graphic id="pcbi.1006470.e125g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e125" xlink:type="simple"/><mml:math display="inline" id="M125"><mml:mrow><mml:mi mathvariant="script">R</mml:mi> <mml:msub><mml:mrow/><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> completely covers the real line <inline-formula id="pcbi.1006470.e126"><alternatives><graphic id="pcbi.1006470.e126g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e126" xlink:type="simple"/><mml:math display="inline" id="M126"><mml:mi mathvariant="double-struck">R</mml:mi></mml:math></alternatives></inline-formula>. When the decoding distribution is known, classification accuracy for level <italic>i</italic> of dimension <italic>A</italic> is:
<disp-formula id="pcbi.1006470.e127"><alternatives><graphic id="pcbi.1006470.e127g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e127" xlink:type="simple"/><mml:math display="block" id="M127"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>ℓ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∫</mml:mo> <mml:msub><mml:mi mathvariant="script">R</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:msub> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(31)</label></disp-formula></p>
<p>
<xref ref-type="disp-formula" rid="pcbi.1006470.e127">Eq 31</xref> relates classification accuracy to the distribution of decoded values on the target dimension <italic>A</italic>. From this we know that <italic>if decoding separability holds, then classification accuracy generalization must hold</italic>. This is true because when decoding separability holds, the distribution <inline-formula id="pcbi.1006470.e128"><alternatives><graphic id="pcbi.1006470.e128g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e128" xlink:type="simple"/><mml:math display="inline" id="M128"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> inside the integral in <xref ref-type="disp-formula" rid="pcbi.1006470.e127">Eq 31</xref> is the same for all values of <italic>j</italic>, <italic>P</italic>(<italic>ℓ</italic><sub><italic>i</italic></sub>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>) is therefore the same for all values of <italic>j</italic> and the relation in <xref ref-type="disp-formula" rid="pcbi.1006470.e116">Eq 30</xref> holds. On the other hand, <italic>if decoding separability fails, then classification generalization may hold or fail</italic>. Without loss of generality, assume that decoding separability fails because <inline-formula id="pcbi.1006470.e129"><alternatives><graphic id="pcbi.1006470.e129g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e129" xlink:type="simple"/><mml:math display="inline" id="M129"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>≠</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Regardless of the shape of <inline-formula id="pcbi.1006470.e130"><alternatives><graphic id="pcbi.1006470.e130g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e130" xlink:type="simple"/><mml:math display="inline" id="M130"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and the region covered by <inline-formula id="pcbi.1006470.e131"><alternatives><graphic id="pcbi.1006470.e131g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e131" xlink:type="simple"/><mml:math display="inline" id="M131"><mml:msub><mml:mi mathvariant="script">R</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, there are an infinite number of other shapes for <inline-formula id="pcbi.1006470.e132"><alternatives><graphic id="pcbi.1006470.e132g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e132" xlink:type="simple"/><mml:math display="inline" id="M132"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> that will preserve the area under the curve inside region <inline-formula id="pcbi.1006470.e133"><alternatives><graphic id="pcbi.1006470.e133g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e133" xlink:type="simple"/><mml:math display="inline" id="M133"><mml:msub><mml:mi mathvariant="script">R</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula> constant, making the value of <italic>P</italic>(<italic>ℓ</italic><sub><italic>i</italic></sub>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>) constant across changes in <italic>j</italic>, which ensures that the relation in <xref ref-type="disp-formula" rid="pcbi.1006470.e116">Eq 30</xref> holds. Alternatively, regardless of the shape of <inline-formula id="pcbi.1006470.e134"><alternatives><graphic id="pcbi.1006470.e134g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e134" xlink:type="simple"/><mml:math display="inline" id="M134"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and the region covered by <inline-formula id="pcbi.1006470.e135"><alternatives><graphic id="pcbi.1006470.e135g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e135" xlink:type="simple"/><mml:math display="inline" id="M135"><mml:msub><mml:mi mathvariant="script">R</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, there are also an infinite number of other shapes for <inline-formula id="pcbi.1006470.e136"><alternatives><graphic id="pcbi.1006470.e136g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e136" xlink:type="simple"/><mml:math display="inline" id="M136"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> that will change the area under the curve inside region <inline-formula id="pcbi.1006470.e137"><alternatives><graphic id="pcbi.1006470.e137g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e137" xlink:type="simple"/><mml:math display="inline" id="M137"><mml:msub><mml:mi mathvariant="script">R</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, making the value of <italic>P</italic>(<italic>ℓ</italic><sub><italic>i</italic></sub>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>) change across changes in <italic>j</italic>. Under such circumstances, the relation in <xref ref-type="disp-formula" rid="pcbi.1006470.e116">Eq 30</xref> may or may not hold, depending on whether or not the shape of <inline-formula id="pcbi.1006470.e138"><alternatives><graphic id="pcbi.1006470.e138g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e138" xlink:type="simple"/><mml:math display="inline" id="M138"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> produces an area under the curve inside <inline-formula id="pcbi.1006470.e139"><alternatives><graphic id="pcbi.1006470.e139g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e139" xlink:type="simple"/><mml:math display="inline" id="M139"><mml:msub><mml:mi mathvariant="script">R</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula> that is larger than <inline-formula id="pcbi.1006470.e140"><alternatives><graphic id="pcbi.1006470.e140g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e140" xlink:type="simple"/><mml:math display="inline" id="M140"><mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>L</mml:mi> <mml:mi>A</mml:mi></mml:msub></mml:mfrac></mml:math></alternatives></inline-formula>.</p>
<p>These considerations point toward an intermediate kind of invariance between decoding separability and classification accuracy generalization, which we call <italic>classification accuracy invariance</italic>, defined as the case in which classification accuracy for levels of dimension <italic>A</italic> is invariant across changes in the stimulus on a second, irrelevant dimension. That is, classification accuracy invariance of dimension <italic>A</italic> with respect to dimension <italic>B</italic> holds if and only if, for all values of <italic>i</italic> and <italic>j</italic>:
<disp-formula id="pcbi.1006470.e141"><alternatives><graphic id="pcbi.1006470.e141g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e141" xlink:type="simple"/><mml:math display="block" id="M141"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>ℓ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>ℓ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>…</mml:mo> <mml:mo>=</mml:mo> <mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>ℓ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:msub><mml:mi>L</mml:mi> <mml:mi>B</mml:mi></mml:msub></mml:msub> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(32)</label></disp-formula></p>
<p>Decoding separability (<xref ref-type="disp-formula" rid="pcbi.1006470.e025">Eq 14</xref>), classification accuracy invariance (<xref ref-type="disp-formula" rid="pcbi.1006470.e141">Eq 32</xref>), and classification accuracy generalization (<xref ref-type="disp-formula" rid="pcbi.1006470.e116">Eq 30</xref>) are related to one another as described in <xref ref-type="fig" rid="pcbi.1006470.g004">Fig 4</xref>. The proofs offered earlier relating decoding separability and classification accuracy generalization already include classification accuracy invariance as an intermediate form of invariance for which the relations in <xref ref-type="fig" rid="pcbi.1006470.g004">Fig 4</xref> hold.</p>
<fig id="pcbi.1006470.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006470.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Summary of the relation between decoding separability, classification accuracy invariance and classification accuracy generalization, according to our extension to GRT.</title>
<p>Arrows should be interpreted as conditional statements of the form “if X, then Y”.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006470.g004" xlink:type="simple"/>
</fig>
<p>What happens when classification accuracy invariance and generalization are evaluated through indirect measures of neural activity, such as those obtained from neuroimaging? This is the way in which such tests have been most commonly applied [<xref ref-type="bibr" rid="pcbi.1006470.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref055">55</xref>–<xref ref-type="bibr" rid="pcbi.1006470.ref057">57</xref>]. Remember that in this case, the addition of measurement and noise models (Eqs <xref ref-type="disp-formula" rid="pcbi.1006470.e068">21</xref> and <xref ref-type="disp-formula" rid="pcbi.1006470.e069">22</xref>) considerably changes the distribution of <inline-formula id="pcbi.1006470.e142"><alternatives><graphic id="pcbi.1006470.e142g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e142" xlink:type="simple"/><mml:math display="inline" id="M142"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> estimates obtained from a linear decoder, which is the result of convolving a distribution of decoded values and the distribution of measurement error. This is likely to change the specific classification accuracies <italic>P</italic>(<italic>ℓ</italic><sub><italic>i</italic></sub>|<italic>A</italic><sub><italic>i</italic></sub><italic>B</italic><sub><italic>j</italic></sub>) but it should not change their relations as defined in Eqs <xref ref-type="disp-formula" rid="pcbi.1006470.e116">30</xref> and <xref ref-type="disp-formula" rid="pcbi.1006470.e141">32</xref>, under the assumption that the measurement error model does not change with the value of the stimulus on dimension <italic>B</italic>.</p>
<p>The theoretical results summarized in <xref ref-type="fig" rid="pcbi.1006470.g004">Fig 4</xref> reveal two issues with the classification accuracy generalization test as it is currently applied in the neuroimaging literature. The first and most important issue is that finding that classification accuracy generalization holds does not provide any information about encoding separability. On the contrary, what provides information about violations of encoding separability is finding a <italic>violation</italic> of classification accuracy generalization. Thus, while this test seems to be valid and useful, it is currently applied and interpreted in the wrong way [<xref ref-type="bibr" rid="pcbi.1006470.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref055">55</xref>–<xref ref-type="bibr" rid="pcbi.1006470.ref057">57</xref>]. It is possible that finding classification accuracy generalization may provide information about other properties of encoding, but such properties are yet to be identified within a formal framework like the one presented here. Another possibility is that classification accuracy generalization could provide information about encoding separability in special circumstances (i.e., for a specific choice of encoding, decoding, measurement and error models), but again such possibilities are yet to be shown. The second issue with the classification accuracy generalization test is that, given the relations shown in Figs <xref ref-type="fig" rid="pcbi.1006470.g003">3</xref> and <xref ref-type="fig" rid="pcbi.1006470.g004">4</xref>, it provides less information about encoding separability than the decoding separability test proposed in the previous section. In <xref ref-type="fig" rid="pcbi.1006470.g004">Fig 4</xref>, each logical step away from decoding separability implies that a number of violations of encoding separability might go undetected, due to the up-diagonal arrow at each step. Thus, the classification accuracy generalization test is likely to be less sensitive to violations of encoding separability than a decoding separability test. If the goal of a study is to learn about encoding separability, then the wiser decision is to focus on a test of decoding separability, rather than on tests of classification accuracy. An aspect of the lack of sensitivity of the classification accuracy generalization test is the fact that it requires accuracies significantly above chance to be applied and thus should always be applied using an optimal classifier. On the other hand, the decoding separability test offers a sensitive measure of deviations from encoding separability regardless of what decoder is used, including situations in which the decoder is not optimal and/or does not achieve significant classification accuracy.</p>
</sec>
<sec id="sec017">
<title>Pattern difference invariance</title>
<p>The work of Allefeld and Haynes [<xref ref-type="bibr" rid="pcbi.1006470.ref058">58</xref>] suggests another way to indirectly test encoding separability in neuroimaging. These authors have proposed the multivariate general linear model (MGLM) as an alternative to decoding for the analysis of the multivariate activity patterns typically measured with neuroimaging. One feature of the MGLM is that it allows researchers to test both main effects and interactions in an experimental design. For example, if we are studying the effect of variations in the level of dimensions <italic>A</italic> and <italic>B</italic> on observed multivariate patterns, a main effect might answer the question of how multivariate patterns change with variations in the level of <italic>A</italic>. On the other hand, an interaction effect answers the question of how the pattern difference between different levels of <italic>A</italic> changes with variations in the level of <italic>B</italic>.</p>
<p>Thus, we can define <italic>pattern difference invariance</italic> of dimension <italic>A</italic> with respect to dimension <italic>B</italic> as the case in which the pattern difference produced by changes in the level of <italic>A</italic> does not change with the level of dimension <italic>B</italic>. Within the MGLM framework, failures of pattern difference invariance can be tested through the interaction between factors <italic>A</italic> and <italic>B</italic>. This test has not been applied or proposed for the study of independence of neural representations in the past, but it seems like a straightforward application of the more general MGLM framework advanced by Allefeld and Haynes [<xref ref-type="bibr" rid="pcbi.1006470.ref058">58</xref>].</p>
<p>It is important to note here that the MGLM approach has been proposed as a way to analyze neuroimaging data, and therefore the pattern difference invariance test would be applied to data that is only indirectly related to the underlying neural activity patterns <bold>r</bold>, and that is contaminated with measurement error. Thus, we must determine whether this is a valid test of properties of encoding such as encoding separability. To simplify our discussion, assume that the parameter vectors estimated by the MGLM represent estimates of the activity patterns <bold>a</bold> defined within our framework (see measurement model in <xref ref-type="disp-formula" rid="pcbi.1006470.e068">Eq 21</xref>). Under the assumption that the measurement model is the same across changes in the level of the irrelevant dimension, we know that <italic>if encoding separability holds, then pattern difference invariance must hold</italic>, as identical encoding distributions should produce identical distributions of measured activity patterns <bold>a</bold>. On the other hand, <italic>if encoding separability fails, then pattern difference invariance may hold or fail</italic>. This is easy to prove by counterexamples, as we did previously when linking encoding separability and decoding separability. As before, we assume that dimension <italic>A</italic> is encoded through the model with Gaussian channel noise (<xref ref-type="disp-formula" rid="pcbi.1006470.e007">Eq 7</xref>). We also assume a linear measurement model (<xref ref-type="disp-formula" rid="pcbi.1006470.e068">Eq 21</xref>), which is very common in the neuroimaging literature:
<disp-formula id="pcbi.1006470.e143"><alternatives><graphic id="pcbi.1006470.e143g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e143" xlink:type="simple"/><mml:math display="block" id="M143"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">a</mml:mi> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">r</mml:mi> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">e</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(33)</label></disp-formula></p>
<p>Finally, as before, we suppose that encoding separability fails due to a difference in the tuning functions of <italic>A</italic><sub>1</sub><italic>B</italic><sub>1</sub> and <italic>A</italic><sub>1</sub><italic>B</italic><sub>2</sub>, whereas the tuning functions of <italic>A</italic><sub>2</sub><italic>B</italic>1 and <italic>A</italic><sub>2</sub><italic>B</italic><sub>2</sub> are identical:
<disp-formula id="pcbi.1006470.e144"><alternatives><graphic id="pcbi.1006470.e144g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e144" xlink:type="simple"/><mml:math display="block" id="M144"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold-italic">δ</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
<p>Under the assumptions listed above, the tuning functions only affect the mean of the measured activity patterns. The variance of each measure of neural activity is a linear combination of channel noise variances plus the measurement error variance. Those variances can be ignored, as they are not affected by differences in the tuning functions and, in addition, they are assumed to be identical across stimuli in the MGLM framework. When pattern difference invariance holds, we have that:
<disp-formula id="pcbi.1006470.e145"><alternatives><graphic id="pcbi.1006470.e145g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e145" xlink:type="simple"/><mml:math display="block" id="M145"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold-italic">δ</mml:mi></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mn mathvariant="bold">0</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(34)</label></disp-formula>
whereas when pattern difference invariance fails, we can show that:
<disp-formula id="pcbi.1006470.e146"><alternatives><graphic id="pcbi.1006470.e146g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e146" xlink:type="simple"/><mml:math display="block" id="M146"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mi>B</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">d</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold-italic">δ</mml:mi></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold">d</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(35)</label></disp-formula>
where <bold>d</bold> represents a difference vector. For any given <bold><italic>δ</italic></bold>, Eqs <xref ref-type="disp-formula" rid="pcbi.1006470.e145">34</xref> and <xref ref-type="disp-formula" rid="pcbi.1006470.e146">35</xref> both can be satisfied by an infinite number of matrices <bold>B</bold>, yielding a model in which encoding separability fails and pattern difference invariance either holds (<xref ref-type="disp-formula" rid="pcbi.1006470.e145">Eq 34</xref>) or fails (<xref ref-type="disp-formula" rid="pcbi.1006470.e146">Eq 35</xref>).</p>
<p>Thus, the pattern difference invariance test has the same logical relation to encoding separability as decoding separability (<xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref>). Unfortunately, pattern difference invariance is not directly related to decoding separability, as was the case for classification accuracy generalization. Without considerable more work, it is difficult to determine which of the two tests will prove to be more useful in different situations. However, we believe that the decoding separability test proposed earlier is a better choice in most cases, for two reasons. The first reason is that the decoding separability test does not make any assumptions about the multivariate distribution of the data, besides assuming that measurement error is additive. Using a linear decoder ensures that the test is valid (we have used <xref ref-type="disp-formula" rid="pcbi.1006470.e071">Eq 23</xref> as the starting point to showing that this is the case), but such a decoder can be obtained using methods that do not make strong assumptions about the data distribution, such as support vector machines. On the other hand, a test based on the MGLM makes the strong assumption that the data is multivariate normal with equal variance-covariance matrix across conditions (i.e., stimuli). The second reason is that a test based on the MGLM is based on a comparison between parameter differences, and thus is insensitive to differences between distributions in higher-order moments. When enough data are collected, the decoding separability test is also sensitive to differences in higher-order moments of the decoding distributions (i.e., variance, kurtosis, etc.). Still, the two tests are based on different approaches (one compares activity pattern distributions, the other compares decoding distributions), so only future work will determine their relative usefulness.</p>
<p>An additional theoretical relation between the MGLM framework and GRT can be established. Allefeld and Haynes [<xref ref-type="bibr" rid="pcbi.1006470.ref058">58</xref>] define <italic>pattern distinctness</italic> as a measure that quantifies the difference between two multivariate activity distributions. When there are only two distributions being compared, the pattern distinctness is related to the Mahalanobis distance between the two activity distributions (e.g., <italic>A</italic><sub>1</sub><italic>B</italic><sub>1</sub> and <italic>A</italic><sub>2</sub><italic>B</italic><sub>1</sub>). Thomas [<xref ref-type="bibr" rid="pcbi.1006470.ref059">59</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref060">60</xref>] has shown that in some cases the Mahalanobis distance between two distributions can be related to a generalized <italic>d</italic>′ measure that quantifies sensitivity for multivariate distributions, which provides a theoretical link between the way in which discriminability is measured in the MGLM and multidimensional signal detection theory.</p>
</sec>
</sec>
<sec id="sec018">
<title>Summary of theoretical results</title>
<p>Here we summarize the previous theoretical results, with an emphasis on how they can be applied to the empirical study of perceptual independence by psychologists and neuroscientists. A summary of all the theoretical relations described in previous sections can be seen in <xref ref-type="fig" rid="pcbi.1006470.g005">Fig 5</xref>.</p>
<fig id="pcbi.1006470.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006470.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Summary of the theoretical relations found here.</title>
<p>Yellow rectangles represent tests that can be applied to neuroimaging data. Red rectangles represent properties of neural encoding. Green rectangles represent properties of perceptual representations. Solid directional arrows indicate that if the concept where the arrow starts is true, then the concept where the arrow ends must be true as well. Dotted directional arrows indicate that if the concept where the arrow starts is false, then the concept where the arrow ends must be false as well. Bidirectional arrows indicate that the two concepts are equivalent. Asterisks are displayed on relations or tests that depend on relatively strong assumptions (see main text for details).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006470.g005" xlink:type="simple"/>
</fig>
<p>First, because perceptual separability can be considered a form of decoding separability, and due to the relations summarized in <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref>, any failure of perceptual separability should be reflected in a failure of encoding separability somewhere in the brain. This means that any psychophysical study reporting a failure of perceptual separability provides a hypothesis to be tested by a neuroscientific study: that a corresponding failure of encoding separability should be found, probably in sensory areas thought to encode the target dimension. Second, such neuroscientific studies can be performed using direct measures of neural activity, such as those provided by single-cell recordings or local field potentials, or indirect measures of neural activity contaminated by measurement error, such as those provided by EEG and fMRI. Using traditional linear decoding strategies on indirect measures of neural activity, the decoded dimensional values still offer a basis for a valid test of decoding separability, and any violation of decoding separability found within a given brain region reflects a violation of encoding separability by the neural population in that region. It must be stressed that a failure of encoding separability is a valid inference that can be made from decoding of neuroimaging data, but such data do not provide a basis to make any strong inferences about the presence of encoding separability. A weak inference can be made, based on the lack of evidence for a violation, but this is analogous to accepting the null in a traditional statistical test. A relatively stronger inference of encoding separability could be made on the basis of assumptions about the neuroimaging measurement model, but researchers should clearly identify such assumptions. Our recommendation to researchers is to be cautious about concluding that separability (or “invariance”) holds at the neural level from neuroimaging data, or even from decoding of direct measures of neural activity (e.g. [<xref ref-type="bibr" rid="pcbi.1006470.ref061">61</xref>]; a related point was made in [<xref ref-type="bibr" rid="pcbi.1006470.ref062">62</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref063">63</xref>]).</p>
<p>Finally, we have shown that operational tests of independence available in the literature can be formally defined and re-interpreted within the framework presented here. We showed that, when some strong assumptions are met, the measurement vector orthogonality test [<xref ref-type="bibr" rid="pcbi.1006470.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref052">52</xref>] is related to the concept of perceptual independence from the traditional GRT, but it is unlikely to be related to a corresponding property of stimulus encoding. On the other hand, the classification accuracy generalization test promoted by Anzellotti and Caramazza [<xref ref-type="bibr" rid="pcbi.1006470.ref055">55</xref>–<xref ref-type="bibr" rid="pcbi.1006470.ref057">57</xref>] can lead to valid inferences about encoding separability. However, the way in which the test has been applied might lead to conclusions of invariance or separability that are in general unjustified, unless one is interested in decoding separability only, and not in the separability of underlying brain representations. In addition, the classification accuracy generalization test is likely to provide less information than our decoding separability test. The MGLM approach proposed by Allefeld and Haynes [<xref ref-type="bibr" rid="pcbi.1006470.ref058">58</xref>] suggests an alternative way to indirectly test encoding separability in neuroimaging. The resulting pattern difference invariance test seems like a valid test of violations of encoding separability, but it is based on strong assumptions about the distribution of the neuroimaging data that are not necessary when the decoding separability test is applied.</p>
</sec>
<sec id="sec019">
<title>An application to the study of encoding separability of face identity and expression</title>
<p>Here we present an application of our framework to the study of encoding separability of face identity and expression. This application serves as a way to illustrate the kind of question that this framework can help answer and the concrete steps that researchers should take to apply the framework in their research.</p>
<p>Information about a number of properties can be extracted from a single face, including identity and emotional expression. The influential model of Bruce and Young [<xref ref-type="bibr" rid="pcbi.1006470.ref003">3</xref>] proposed that these two face dimensions are processed independently, motivating a large number of psychophysical studies aimed at testing this hypothesis [<xref ref-type="bibr" rid="pcbi.1006470.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref033">33</xref>–<xref ref-type="bibr" rid="pcbi.1006470.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref064">64</xref>–<xref ref-type="bibr" rid="pcbi.1006470.ref072">72</xref>]. Neurobiological theories of visual face processing [<xref ref-type="bibr" rid="pcbi.1006470.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref073">73</xref>] also propose relatively independent processing of face emotion and identity, through anatomically and functionally differentiated pathways. A ventral pathway projecting from the occipital face area (OFA) to the fusiform face area (FFA) would mediate the processing of invariant aspects of faces, such as identity. A dorsal pathway projecting from the OFA to the posterior superior temporal sulcus (pSTS) would mediate the processing of changeable aspects of faces, such as emotional expression. Recent reviews [<xref ref-type="bibr" rid="pcbi.1006470.ref074">74</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref075">75</xref>] conclude that the two pathways are indeed relatively separated and functionally differentiated, with the ventral pathway being involved in the representation of face form information–including invariant aspects of face shape such as identity–, and the dorsal pathway involved in the representation of face motion information–including rapidly changeable aspects of faces such as expression. According to this revised framework, both identity and expression information may be encoded in either pathway, but exactly what information about each dimension is encoded would differ between pathways.</p>
<p>The psychophysical and neurobiological lines of research in this area have remained relatively independent across the years, with no attempt to integrate results across levels of analysis despite the similarity of the central questions guiding their research. In addition, both lines have relied largely on operational definitions of independence that, while having face validity, are usually not linked to any theoretical definition. As indicated in the introduction, this approach makes it difficult to interpret contradictory results.</p>
<p>Thus, the study of independence of face identity and expression is a particularly good example of an area in which our extended GRT framework can provide helpful research tools. Our theory can provide a much-needed theoretical integration across levels of analysis and tests, as well as more rigorous definitions of independence and ways to measure it. We have recently performed a GRT analysis of psychophysical data to study the perceptual separability of identity and expression [<xref ref-type="bibr" rid="pcbi.1006470.ref013">13</xref>]. The results suggested that, for the stimuli used in that study and after accounting for decisional factors, emotional expression was perceptually separable from identity, but identity was not perceptually separable from emotional expression. From these results, our current framework (see <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref>) predicts that encoding separability of identity from expression must fail somewhere in the areas representing face information, and that we should be able to find evidence of failures of decoding separability in those areas. The predictions regarding encoding separability of emotional expression are less straightforward: as there are no violations of perceptual separability in the behavioral data, violations of encoding separability seem unlikely, but are still possible.</p>
<p>Here, we acquired fMRI data from participants while they looked at the same stimuli and completed the same task as in our previous psychophysical study (see <xref ref-type="sec" rid="sec027">Materials and methods</xref>). The stimuli were images of four faces, which resulted from two different male identities showing two different emotional expressions (neutral and sad). Participants performed a simple stimulus identification task. In each trial, a single stimulus was flashed in the screen and the participant had to identify the specific combination of identity and emotional expression that had been shown. This required participants to pay attention to both identity and expression to attain good performance. The participants received feedback about the correctness of their responses. The task was given to participants in runs that lasted around 10 minutes, during which each image was repeated 25 times. Participants completed three of such runs, and in addition they completed a standard functional localizer run [<xref ref-type="bibr" rid="pcbi.1006470.ref076">76</xref>] that allowed to obtain the approximate location of face-related regions.</p>
<p>Performance in the task during the scanning session was high, with a mean of 81.67% (SE = 5.18%). Single-trial estimates of stimulus-related activity were used as input to the decoding separability test described earlier. Because we did not have specific hypotheses about the location of areas showing failures of encoding separability, we performed a whole-brain searchlight analysis [<xref ref-type="bibr" rid="pcbi.1006470.ref077">77</xref>], to determine which small circular regions (radius of 3 voxels) showed violations of decoding separability, and therefore violations of encoding separability. To spatially localize violations of encoding separability relative to areas in the face network, we found such areas with the help of a standard functional localizer.</p>
<p>The results from this analysis did not reveal any significant violations of decoding separability, either for identity or emotion. Further exploration revealed that our standardized DDS index was consistently negative in the full-brain maps, suggesting that our method of standardization might have produced an index that was too conservative. That is, the DDS was standardized to represent a percentile value (ranging from 0 to 100) re-centered around the middle of the distribution (i.e., ranging from -50 to 50). Under the null hypothesis of decoding separability, the distribution of this DDS would be driven only by noise in the data, and we would expect the standardized measure to hover around zero, with similar areas of the brain maps being positive and negative. On the other hand, we would not expect values consistently lower than zero, as this would mean that the estimated decoding distributions are consistently more similar to one another than expected under decoding separability. As the expectation under decoding separability is that the distributions are identical, this seemed like a problem. We reasoned that one solution would be to use the difference in DDS index between the identity and emotion analyses as the main test statistic, to allow one map to serve as control for the other. We must underscore that this is an exploratory analysis, and its results should be confirmed by future research. Increasing power with a larger sample (either a larger number of participants or a larger number of trials) would be helpful to obtain reliable results with a conservative test. <xref ref-type="fig" rid="pcbi.1006470.g006">Fig 6</xref> shows the main results of this analysis, displayed over a flat cortical map. Face-selective areas found through the functional localizer are outlined in the figure. Outlined in green are face-selective areas showing higher activity during the presentation of faces than during the presentation of other objects. Outlined in red are areas showing higher activity during the presentation of emotional faces than during the presentation of neutral faces. The figure also shows clusters of significant violations of decoding separability, depicted in red-yellow for the identity &gt; emotion contrast. A single large cluster (483 2mm voxels) was found to be significant, covering parts of the left STS and superior temporal gyrus (peak location in MNI coordinates: -60, -14, 2). This cluster only slightly overlapped with an area of the face network in the pSTS (green contour). No significant violations were found for the emotion &gt; identity contrast.</p>
<fig id="pcbi.1006470.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006470.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Results of the searchlight decoding separability test.</title>
<p>Yellow-red clusters represent regions in which violations of decoding separability of identity were stronger than violations of decoding separability of emotional expression. There were no regions in which violations of decoding separability of emotional expression were stronger than violations of decoding separability of identity. Green and red lines delimit face areas from the functional localizer. “L” and “R” represent left and right hemispheres, respectively.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006470.g006" xlink:type="simple"/>
</fig>
<p>The results shown in <xref ref-type="fig" rid="pcbi.1006470.g006">Fig 6</xref> are in line with the previous psychophysical results [<xref ref-type="bibr" rid="pcbi.1006470.ref013">13</xref>] and the relations depicted in <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref>, as they provide evidence of stronger violations of decoding separability for identity than for emotional expression, but not the other way around. This asymmetry in the separability of neural representations is analogous to the asymmetry in perceptual separability found in our previous psychophysical study, and thus makes intuitive sense. Although this asymmetry was not a strong prediction from the theory (which simply predicts violations of decoding separability for identity, but is ambiguous about violations of decoding separability for emotional expression), it suggests that there is at least an empirical correspondence between asymmetries of separability in perceptual and brain representations.</p>
<sec id="sec020">
<title>Comparison with measurement vector orthogonality</title>
<p>We implemented a version of the measurement vector orthogonality test [<xref ref-type="bibr" rid="pcbi.1006470.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref052">52</xref>] discussed earlier. At each searchlight, we measured representation orthogonality by correlating the weights from the classifier used in the previous analyses of identity and emotion. A correlation of zero is equivalent to orthogonality of the two weight vectors, and therefore any deviation from a zero correlation is indicative of a violation of measurement vector orthogonality. As mentioned earlier, finding such violations of orthogonality is more informative than finding evidence for orthogonality. The resulting individual orthogonality maps were submitted to the same permutation test previously used for separability maps. No violations of measurement vector orthogonality were found in this analysis.</p>
<p>Note that this finding of measurement vector orthogonality has been taken by other researchers to mean that information about face identity and emotional expression is represented independently in the visual system [<xref ref-type="bibr" rid="pcbi.1006470.ref006">6</xref>]. Our theoretical results allow us to draw a different conclusion: measurement vector orthogonality cannot be easily linked to a corresponding property of stimulus encoding, as even a linear transformation from the space of the encoding model to the space of indirect measures of neural activity does not necessarily preserve angles.</p>
<p>From the point of view of GRT, decoding separability and measurement vector orthogonality seem to measure unrelated properties of perception and neural encoding. From the point of view of perception, decoding separability is related to the GRT concept of perceptual separability, whereas measurement vector orthogonality is related to the GRT concept of perceptual independence. In both cases, however, the tests are related to the corresponding GRT concepts through a number of strong assumptions. From the point of view of encoding, decoding separability is related to the concept of encoding separability, whereas measurement vector orthogonality seems difficult to relate to any property of encoding. For these reasons, we expected the magnitude of violations of orthogonality and violations of separability to be unrelated. To test this hypothesis, we took the group statistical maps obtained from the permutation test in the analysis of decoding separability and computed their Pearson correlation with the corresponding maps from the current analysis of representation orthogonality. There was a small but significant correlation between the orthogonality map and both the map of deviations of separability for identity, <italic>r</italic> = -0.1162 (<italic>p</italic>&lt;0.0001), and the map of deviations of separability for emotion, <italic>r</italic> = 0.0666 (<italic>p</italic>&lt;0.0001). These correlations are significant due to the large number of voxels used to calculate them, but their magnitudes are very small. With these correlations, only 1.35% of the variability in the separability map for identity and 0.44% of the variability in the separability map for expression can be explained by variability in the orthogonality map. Still, the fact that the correlations are significant in real data is important, and some unknown relation between measurement vector orthogonality and decoding separability may underlie these results. Future theoretical work will be necessary to clarify these points.</p>
</sec>
<sec id="sec021">
<title>ROI-based decoding separability test</title>
<p>An additional ROI-based analysis was performed, with three goals in mind. First, we wanted to determine whether directly testing face-selective regions would result in some evidence of violations of decoding separability, as the only cluster showing such deviations in the searchlight analysis overlapped very little with face-selective regions from the localizer (see <xref ref-type="fig" rid="pcbi.1006470.g006">Fig 6</xref>). Second, we wanted to more clearly determine whether there are meaningful variations in the amount of separability between different regions. Finally, we wanted to explore the behavior of our decoding separability analysis in control regions. The included ROIs are face-selective areas (OFA, FFA, STS) and two control regions: V1, which is known to be sensitive to low-level visual features and thus might show deviations of decoding separability (any change in the faces would produce changes in low-level features), and the lateral ventricles, which give us information about the behavior of our statistic when there is very little underlying signal. Some information may be available at the ventricle ROIs that is leaked from adjacent regions, but we would expect that here our statistic should show decoding separability, as the decoding distributions should be almost completely determined by measurement noise.</p>
<p>Results are shown in <xref ref-type="fig" rid="pcbi.1006470.g007">Fig 7</xref>. <xref ref-type="fig" rid="pcbi.1006470.g007">Fig 7</xref> shows mean standardized DDS values across all ROIs included in the analysis, with error bars representing standard errors of the mean. The scale of the statistic displayed in <xref ref-type="fig" rid="pcbi.1006470.g007">Fig 7</xref> is different from that of the full-brain maps, as proportions rather than percentiles are used and the median has not been subtracted. We tested whether any of these means was significantly higher than the value of 0.5 expected under decoding separability through <italic>t</italic>-tests (directional, uncorrected). The only ROIs showing significant violations of decoding separability were the left V1 in the analysis of identity, <italic>t</italic>(15) = 2.04, <italic>p</italic>&lt;.05, and the right STS in the analysis of emotion, <italic>t</italic>(20) = 2.05, <italic>p</italic>&lt;.05. Due to the large number of tests and the fact that our experiment was not originally designed with ROI-based analyses in mind, none of the tests is significant after the application of a correction for multiple comparisons. For this reason, the results shown in <xref ref-type="fig" rid="pcbi.1006470.g007">Fig 7</xref> should be taken as only suggestive and exploratory. Still, the evidence is encouraging as it suggests that: (1) deviations from decoding separability are not significant in the control areas assumed to include mostly measurement noise (left and right ventricles), (2) deviations from decoding separability are significant in one of the control areas thought to involve such deviations (left V1), and (3) deviations from separability were very low across face-selective areas, with the exception of the right STS, which showed a significant deviation from decoding separability of emotion from identity. Also note that, for most face-selective regions, the mean DDS is consistently below the value of 0.5 which, as mentioned earlier, suggests that the DDS is a conservative measure of failures of decoding separability, at least in areas thought to encode the dimensions under study.</p>
<fig id="pcbi.1006470.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006470.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Results of the ROI-based decoding separability test.</title>
<p>The y-axis reports the standardized deviations from decoding separability (DDS) statistic. The points represent mean values and the error bars represent standard error of the mean. When decoding separability holds, this index should have a value around 0.5, which is represented with a horizontal dotted line. Mean statistics that were found to be significant (<italic>t</italic>-test, uncorrected) are marked with an asterisk.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006470.g007" xlink:type="simple"/>
</fig>
</sec>
</sec>
</sec>
<sec id="sec022" sec-type="conclusions">
<title>Discussion</title>
<p>Here we have linked multidimensional signal detection theory from psychophysics and encoding models from computational neuroscience within a single theoretical framework. This allowed us, for the first time, to link the results from psychophysical and neurobiological studies aimed at determining independent processing of stimulus properties. Unlike previous approaches, our framework formally specifies the relation between behavioral and neural tests of separability, providing the tools for a truly integrative research approach in the study of independence.</p>
<p>In the past, neuroimaging studies have been limited to a choice between decoding and encoding approaches to data analysis [<xref ref-type="bibr" rid="pcbi.1006470.ref029">29</xref>]. Decoding approaches focus on answering questions about <italic>what</italic> is encoded in a given brain region, while making no assumptions about <italic>how</italic> exactly that information is encoded; this lack of commitment to an encoding model is both their strength, as they provide useful results regardless of how information is encoded, and their weakness, as they are limited regarding what kind of question they can answer. In contrast, encoding approaches focus on answering questions about <italic>how</italic> a specific stimulus property is encoded in a brain region, but they do this by assuming the encoding model and determining whether it can help to accurately predict data. Their weakness is that there are a very large number of models that could be tested, and no way of knowing a priori whether the best model is included in the analysis. The theory presented here allowed us to identify some properties of encoding models (i.e., encoding separability) that can be inferred from the results of a decoding study. We hope that future theoretical research in this line will allow researchers to link other properties of encoding models to the results of decoding tests, and more generally to the results of any analysis involving measures that are some transformation of the underlying neural activity, as is the case in fMRI and psychophysics.</p>
<p>Although we focused on developing a decoding separability test, the GRT framework presented here is useful to understand the results of other tests of independence as well [<xref ref-type="bibr" rid="pcbi.1006470.ref004">4</xref>–<xref ref-type="bibr" rid="pcbi.1006470.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref057">57</xref>]. Here, we re-interpreted two operational tests of independence previously applied in the literature within our extended GRT framework. We showed that, when some strong assumptions are met, the measurement vector orthogonality test [<xref ref-type="bibr" rid="pcbi.1006470.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref052">52</xref>] is related to the concept of perceptual independence from the traditional GRT, but it is unlikely to be related to a corresponding property of stimulus encoding. On the other hand, a test based on generalization of classification accuracy [<xref ref-type="bibr" rid="pcbi.1006470.ref055">55</xref>–<xref ref-type="bibr" rid="pcbi.1006470.ref057">57</xref>] can provide information about encoding separability. However, the test is likely to provide less information than a decoding separability test and it has been applied incorrectly, yielding conclusions of separability (invariance) that are in general unjustified. Application of our framework to additional operational tests may require the development of models linking neural activity to the specific measurements made in each test.</p>
<p>The framework and test proposed here are applicable not only to fMRI data, but also to the analysis of single-cell recordings, LFPs, EEG and MEG. This breadth of scope across operational definitions and levels of analysis (single neurons, neural populations at many scales, perception, and behavior), which is rarely seen in neuroscience, is a very important contribution of the present work.</p>
<p>We applied our new framework to the study of independent representation of face identity and emotional expression. Previous research found that, for the set of stimuli studied here, identity is not perceptually separable from emotional expression, whereas emotional expression is perceptually separable from identity [<xref ref-type="bibr" rid="pcbi.1006470.ref013">13</xref>]. Our results revealed that such lack of perceptual separability is reflected in stronger violations of decoding separability for identity than for emotion in the left temporal cortex, but no stronger violations of decoding separability for emotion than for identity in any brain region.</p>
<p>Several previous fMRI studies have explored the question of whether emotional expression and identity are represented independently in the brain, and an important question is what value is added by a study based on our extended GRT. We believe that our framework provides at least two advantages. The first advantage is the provision of clear links between the results of neuroimaging and behavioral studies using the same stimuli. No previous study could directly link behavior to neural representation in a meaningful way, as in our application of the extended GRT framework. We started our study with clear hypotheses about how fMRI results should reflect the behavioral results, which is preferable to the approach of linking neural and behavioral results through post-hoc theorizing. The second advantage offered by our framework is that it improves our ability to interpret new results in the light of previous results. For example, our data suggest violations of decoding separability of identity from emotion. This does not contradict previous reports of orthogonality of neural representations [<xref ref-type="bibr" rid="pcbi.1006470.ref006">6</xref>], as we know that decoding separability and measurement vector orthogonality measure different concepts. Researchers have also found that emotion can be decoded from areas linked to processing of identity [<xref ref-type="bibr" rid="pcbi.1006470.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref078">78</xref>], and identity can be decoded from areas linked to processing of emotion [<xref ref-type="bibr" rid="pcbi.1006470.ref079">79</xref>]. The issue of whether or not a particular kind of information can be decoded from a brain region is orthogonal to the issue of whether or not it shows encoding separability. Accurate decoding from a particular area indicates that information about a dimension is present in that area but, as indicated earlier, decoding methods are agnostic as to how that information is encoded. The same is true about inaccurate decoding from a particular area. On the other hand, an example of a test that is related to encoding separability is the classification accuracy generalization test of Anzellotti and Caramazza [<xref ref-type="bibr" rid="pcbi.1006470.ref055">55</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref057">57</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref079">79</xref>]. However, this test has not been applied to the study of independence of identity and emotional expression, but rather to the study of identity across changes in viewpoint and modality.</p>
<sec id="sec023">
<title>Non-linear decoders and measurement models</title>
<p>We have shown that a decoding separability test operating on indirect measures of neural activity can validly detect violations of encoding separability, but one of the conditions in our treatment of this issue was using a linear decoder. When a linear decoder is used, the relation between the target difference between decoding distributions <inline-formula id="pcbi.1006470.e147"><alternatives><graphic id="pcbi.1006470.e147g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e147" xlink:type="simple"/><mml:math display="inline" id="M147"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi mathvariant="bold">r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and the measured difference <inline-formula id="pcbi.1006470.e148"><alternatives><graphic id="pcbi.1006470.e148g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e148" xlink:type="simple"/><mml:math display="inline" id="M148"><mml:mrow><mml:mover accent="true"><mml:mi>δ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is straightforward (see <xref ref-type="disp-formula" rid="pcbi.1006470.e088">Eq 26</xref>), which allows us to know exactly what violations of decoding separability the test can and cannot detect. We believe that the use of a linear decoder is a reasonable requirement for the test, as they are easier to use and interpret than non-linear decoders, and decoding studies in neuroimaging have almost exclusively used linear decoders. However, one open question is to what extent using a different decoder might change the test’s ability to detect specific violations of encoding separability. That is, perhaps a specific type of violation of encoding separability is hidden by a linear decoder, but shown by a non-linear decoder, or vice-versa. This question requires considerable additional theoretical and simulation work. However, we do know that, regardless of what type of decoder is used, if encoding separability holds, then decoding separability must necessarily hold. Thus, finding a violation of decoding separability with any decoder reflects either a violation of encoding separability or a statistical error. Thus, one strategy that might prove useful in the future is performing several decoding separability tests, each using a different decoder. However, such a test should fulfill two requirements: (1) the decoders should be chosen based on previous work showing that they can detect different violations of encoding separability, and (2) a correction for multiple tests should be applied, to control for the family-wise type I error.</p>
<p>Similarly, we linked encoding separability violations to a pattern difference invariance test by assuming a linear measurement model. This was helpful to prove that in general a violation of encoding separability may or may not lead to a violation of pattern difference invariance, but it is not clear whether some specific measurement models yield a different result. Importantly, it is unlikely that the true measurement model linking neural activity and neuroimaging measurements is simply linear. Thus, more work is necessary to reach a better understanding of exactly what violations of encoding separability can and cannot be detected using the pattern difference invariance test.</p>
</sec>
<sec id="sec024">
<title>What about encoding modeling?</title>
<p>Faced with the problem of operationalism in the study of neural independence, here our approach has been to propose a very general theoretical framework in which most operational tests can be interpreted and related to properties of encoding such as separability. A different approach would involve building, fitting and selecting among competing encoding models [<xref ref-type="bibr" rid="pcbi.1006470.ref027">27</xref>]. More specifically, this approach requires building several different encoding models, choosing in each case features such as the number of channels, the shape of the tuning functions, the distribution of neural noise, etc. Encoding separability would hold for some of these models and it would fail for others. The output of each model in terms of neural activities must be linked to neuroimaging data (e.g., estimates of activity from fMRI or EEG) through a formal measurement model. This formal link would allow to derive or numerically approximate a probability distribution of the data given a particular model and parameter set. Once data are obtained, this probability distribution can be used to estimate the parameters of the encoding model and the measurement model that provide the best fit to the data, through maximum likelihood estimation (or Bayesian inference, if priors are added). After estimation, standard model selection procedures (e.g., by AIC, BIC or predictive accuracy in a cross-validation scheme) would allow to determine what model provides the best explanation for the data. The properties of the chosen encoding model, including its status regarding encoding separability, provide the best explanation for the data.</p>
<p>This approach allows to explicitly test specific features of encoding, and some researchers argue that encoding modeling is the best way to reach valid conclusions about representation in a given brain region from neuroimaging studies [<xref ref-type="bibr" rid="pcbi.1006470.ref080">80</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref081">81</xref>]. Here we have shown that valid inferences about representation can be made from decoding studies, but we do believe that answering specific questions about representation may be easier through encoding modeling.</p>
<p>However, there are three important challenges faced by anybody wanting to apply encoding models in this way. The first challenge is that this approach will pick the best model among those tested. Thus, a poor selection of competing models will lead to the wrong inferences. Building and fitting encoding models in this way requires an important level of knowledge about what stimulus properties are encoded and how they are encoded [<xref ref-type="bibr" rid="pcbi.1006470.ref080">80</xref>]. Relatedly, fitting specific models may allow to draw more precise inferences regarding encoding separability, but such inferences cannot be generalized to situations outside those included in the tested models. In contrast, a failure of decoding separability signals a failure of encoding separability regardless of the unknown specific details of the encoding and measurement models. The second challenge is that the process of fitting the models itself may require considerable technical expertise and computational resources. Likelihood functions must be derived or numerically approximated for each model, problems of model mimicry and identifiability must be assessed and solved, simplifying assumptions and constraints must sometimes be placed on the models. The consequences of decisions regarding each of these issues–and the way in which they affect inferences–might not be clear for researchers that are not experienced with modeling. The third challenge has to do with inference and interpretation. It is not always very clear what can and cannot be concluded from the fit of encoding models to data, and recent work suggests that common interpretations of the results of encoding modeling are incorrect [<xref ref-type="bibr" rid="pcbi.1006470.ref082">82</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref083">83</xref>]. This is complicated further by the fact that many researchers using encoding models are not explicit about their modeling assumptions. For example, many applications involve using multiple linear regression with least squares estimation of weight parameters, where the independent variables are stimulus features assumed to be encoded and the dependent variable is the measured activity in an fMRI voxel or EEG channel. Although never explicitly stated, the assumption behind these models is that there is no neural noise (independent variables in linear regression are not random), the measurement model is linear, and measurement noise is Gaussian and additive. Any conclusion reached using these popular models must be qualified by this set of assumptions.</p>
<p>Overall, we believe that encoding modeling is an excellent way to study the properties of neural encoding using neuroimaging. However, for the reasons outlined before, it seems unlikely to be adopted by experimentalists without a computational background. Indeed, researchers without such a background are probably wise to keep away from it. On the other hand, we have shown here that decoding approaches can lead to valid inferences about the independence of neural representations without being difficult to apply and interpret. We believe that using a decoding separability test offers an improvement over the operational tests of independence commonly used in the literature, without requiring a high level of expertise from researchers.</p>
</sec>
<sec id="sec025">
<title>Limitations and future work</title>
<p>Our application to face perception research is useful to highlight the kinds of questions that can be answered with the new framework and the type of analysis that should be performed to answer such questions. However, there are limitations of the present study that should be noted. First, results were obtained using a small set of naturalistic stimuli, so they should not be over-generalized. There is no guarantee that the same results will hold for other stimulus sets, and more research is needed before reaching any general conclusion about the separability of identity and emotional expression. Second, our experiment and analyses were performed at the group level. This was done to obtain a statistically-powerful test that is sensitive to violations of separability that are consistent across participants. However, the results may not be representative of individual subjects. We expect that the study of encoding separability at the individual level will require obtaining more data from each participant than what was acquired in the present study.</p>
<p>Our theoretical work might also require further refinement. In particular, the decoding separability test can detect when encoding separability is violated, but it cannot detect when encoding separability holds (see <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref>).</p>
<p>Decoding separability itself is difficult to prove, as the decoding separability test is a null hypothesis test. Other approaches are necessary to prove the null of decoding separability, such as an arbitrarily small confidence interval around no effect. Such confidence intervals could be computed using resampling methods, such as bootstrapping. Providing evidence favoring the null in this way is usually difficult, as obtaining small confidence intervals requires a large amount of data. Furthermore, there is not much to gain from proving the null of decoding separability, because concluding that decoding separability holds does not lead to conclusions about encoding separability (see <xref ref-type="fig" rid="pcbi.1006470.g003">Fig 3</xref>). Thus, when using the decoding separability test (or any of the other operational tests that we have discussed here), researchers should focus only on obtaining evidence of its failure.</p>
<p>For many researchers, concluding that a dimension is encoded in a separable manner in a given brain region might be considered more interesting; still, an important contribution of our work is showing that this is in general not possible through indirect measures of neural activity or psychophysics. Perhaps specific assumptions about the measurement model producing the data will make it possible to establish a more direct link between decoding and encoding separability, but such assumptions need to be clearly spelled out by researchers, and data should be provided to back them up. One way in which it is possible to directly compare the evidence in favor of encoding separability versus the evidence against encoding separability is within the encoding modeling framework described earlier. As indicated earlier, this framework allows to compare two encoding models that are identical in all respects except their assumption of encoding separability. Unlike in null hypothesis testing, there is no problem with selecting the simpler model in which encoding separability holds, as long as it provides a better explanation for the data.</p>
<p>Although our framework provides a link between neural and perceptual forms of separability, some researchers might consider this link rather weak, as we have only shown that a violation of perceptual separability should be reflected in a failure of encoding separability. Although simply indicating that encoding separability must fail is not very informative about exactly how and where it fails, it is important to understand that here precision has been traded-off for generality. That is, perceptual separability allows to conclude that encoding separability fails, <italic>regardless of how the dimension is encoded by the brain or how it is decoded for performance in a task</italic>. There is a long tradition in vision of linking neural encoding and psychophysics, and more precise conclusions can be reached by making stronger assumptions about encoding and decoding. For example, a common assumption in this literature is optimal decoding through maximum likelihood estimation [<xref ref-type="bibr" rid="pcbi.1006470.ref084">84</xref>–<xref ref-type="bibr" rid="pcbi.1006470.ref086">86</xref>]. The addition of an encoding model that is constrained by results from neurophysiology allows one to make inferences about how many neurons contribute to perception from psychophysical thresholds [<xref ref-type="bibr" rid="pcbi.1006470.ref084">84</xref>], or about changes in neural tuning functions from changes in threshold-versus-noise functions [<xref ref-type="bibr" rid="pcbi.1006470.ref086">86</xref>]. Similarly, future research could strengthen the link between neural and perceptual forms of independence for specific dimensions, by including known features of the underlying neurobiology in the encoding models and stronger assumptions about decoding (e.g., optimal decoding), an approach that has not been explored yet in the study of independence.</p>
<p>We must also note that the approach of trading-off precision for generality is entirely within the tradition of how GRT has been developed in the past. That is, most initial work in GRT had the goal of establishing general links between operational tests and different definitions of independence [<xref ref-type="bibr" rid="pcbi.1006470.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006470.ref087">87</xref>–<xref ref-type="bibr" rid="pcbi.1006470.ref089">89</xref>]. We believe that this groundwork is necessary before developing more powerful applications to specific problems in vision science.</p>
</sec>
<sec id="sec026">
<title>Conclusion</title>
<p>The notion of independent processing is central to many theories in perceptual and cognitive neuroscience, but its study has lacked the rigor and integration offered by a formal framework, like the one presented here. This framework allows development of theoretically-driven tests of independence of neural representations, which are more clear and rigorous than the operational tests used thus far. The availability of more rigorous definitions and tests to study separability is likely to advance knowledge in a number of areas in visual neuroscience interested in the notions of independence of processing and representation.</p>
</sec>
</sec>
<sec id="sec027" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec028">
<title>Ethics statement</title>
<p>This study was approved by the Human Subjects Committee at the University of California, Santa Barbara, and written informed consent was obtained from all participants.</p>
</sec>
<sec id="sec029">
<title>Participants</title>
<p>Twenty-one male and female right-handed students at the University of California Santa Barbara were recruited to participate in this study. Each participant received a monetary compensation at a rate of US$20/hour.</p>
</sec>
<sec id="sec030">
<title>Experimental task</title>
<p>The stimuli and task were identical to those used in a previous behavioral study of separability of face identity and expression [<xref ref-type="bibr" rid="pcbi.1006470.ref013">13</xref>]. Stimuli were four grayscale images of male faces, part of the California Facial Expression database (<ext-link ext-link-type="uri" xlink:href="http://cseweb.ucsd.edu/∼gary/CAFE/" xlink:type="simple">http://cseweb.ucsd.edu/∼gary/CAFE/</ext-link>). Each face showed one of two identities with either a neutral or sad emotional expression. The faces were shown through an elliptical aperture in a homogeneous gray screen; this presentation revealed only inner facial features and hid non-facial information, such as hairstyle and color.</p>
<p>Participants performed an identification task both outside and inside the MRI scanner. Each stimulus was assigned to a specific response key and the participant’s task was to identify the image presented in each trial. Each trial started with the presentation of a white crosshair in the middle of the screen for 200 ms, followed by stimulus presentation for a single frame (i.e., 16.667 ms at a 60 Hz refreshing rate). Stimulus presentation was short to make it identical to that used in our previous behavioral study. After stimulus presentation, participants pressed a response key; 500 ms later, feedback about the correctness of their response was displayed on the screen for 500 ms (“Correct” in green font color or “Incorrect” in red font color). If the participant took longer than 5 s to respond, the words “Too Slow” were presented on the screen and the trial stopped. Feedback was followed by a variable inter-trial interval, obtained by randomly sampling a value from a geometric distribution with parameter 0.5 and truncated at 5, and multiplying that value by 1,530 ms (the TR value, see below). To obtain estimates of stimulus-related activity with other events in the trial (crosshair and response) unmixed, we used a partial trials design in which 25% of the trials included the presentation of the white crosshair not followed by a stimulus. Participants were instructed to randomly choose a response on these partial trials.</p>
<p>Stimulus presentation, feedback and response recording were controlled using MATLAB augmented with the Psychophysics Toolbox (<ext-link ext-link-type="uri" xlink:href="http://psychtoolbox.org" xlink:type="simple">psychtoolbox.org</ext-link>), running on Mackintosh computers. Participants practiced the identification task on personal Mackintosh computers outside the MRI scanner for about 20 mins. During this training, participants responded on a keyboard. During scanning, participants responded using the Lumina Response Pad System (model LU400-Pair), with the same finger-stimulus mapping as during pre-training.</p>
</sec>
<sec id="sec031">
<title>Functional imaging</title>
<p>Images were obtained using a 3T Siemens TIM TRIO MRI scanner with a 12-channel head coil at the University of California, Santa Barbara Brain Imaging Center. Cushions were placed around the head to minimize head motion. A T1-weighted high-resolution anatomical scan was acquired using an MPRAGE sequence (TR: 2,300 ms; TE: 2.98 ms; FA: 9°; 160 sagittal slices; 1 × 1 × 1 mm voxel size; FOV: 256 mm). Additional scans included a localizer and a GRE field map, neither of which were used in the analyses presented here.</p>
<p>Functional scans used a T2*-weighted single shot gradient echo, echo-planar sequence sensitive to BOLD contrast (TR: 1,530 ms; TE: 28 ms; FA: 61°; FOV: 192 mm) with generalized auto-calibrating partially parallel acquisitions (GRAPPA). Each volume consisted of 28 slices (interleaved acquisition, 2.5 mm thick with a 0.5 mm gap; 2.5 × 2.5 mm in-plane resolution) acquired at a near-axial orientation, manually adjusted to cover the ventral visual stream and lateral prefrontal cortex. There were a total of four functional runs per participant (with the exception of five participants who completed three functional runs).</p>
<p>The first run was a standard functional localizer for face regions [<xref ref-type="bibr" rid="pcbi.1006470.ref076">76</xref>]. Neutral faces, emotional faces and non-face objects were each presented in different stimulus blocks, separated by fixation blocks. Sixteen images of the same type were presented within a stimulus block, each with a duration of 500 ms and a 250 ms inter-stimulus-interval. Fixation blocks consisted of the presentation of a black screen with a white fixation cross in the middle. The sequence started with a fixation block, followed by 6 blocks of each image category (18 total), each followed by a fixation block, for a total of 37 blocks. Blocks lasted for 12 seconds, and the whole scan lasted about 7.5 mins. The order of image types (e.g., neutral-emotional-object) was counterbalanced across blocks. To ensure attention to the stimuli, participants were asked to push a button whenever an image was repeated in the sequence. Four of the 15 stimuli in a block were repetitions, randomly positioned in the stimulus sequence.</p>
<p>In all other functional runs, which lasted about 10 mins each, participants performed the identification task described earlier, without feedback. Each of the four images was repeated 25 times, for a total of 100 trials per run. Stimuli were viewed through a mirror mounted on the head coil and a back projection screen.</p>
</sec>
<sec id="sec032">
<title>Statistical analyses</title>
<sec id="sec033">
<title>Anatomical scans</title>
<p>Processing of structural scans was done using FSL (<ext-link ext-link-type="uri" xlink:href="http://www.fmrib.ox.ac.uk/fsl" xlink:type="simple">www.fmrib.ox.ac.uk/fsl</ext-link>), and included brain extraction using BET and nonlinear registration to MNI 2mm standard space using FNIRT nonlinear registration. The inverse transformation was obtained to transform volumes from standard space back to subject space. For visualization purposes, some statistical maps were converted from MNI standard space to the PALS-B12 surface-based atlas using CARET v.5.65 (<ext-link ext-link-type="uri" xlink:href="http://www.nitrc.org/projects/caret/" xlink:type="simple">www.nitrc.org/projects/caret/</ext-link>) and selecting the options <italic>average of the mapping to all multi-fiducial cases</italic> and <italic>enclosing voxel algorithm</italic>.</p>
</sec>
<sec id="sec034">
<title>Preprocessing of functional scans</title>
<p>Preprocessing of the functional scans was conducted using FEAT (fMRI Expert Analysis Tool) version 6.00, part of FSL (<ext-link ext-link-type="uri" xlink:href="http://www.fmrib.ox.ac.uk/fsl" xlink:type="simple">www.fmrib.ox.ac.uk/fsl</ext-link>). Volumes from all three runs of the main identification task were concatenated into a single series using <italic>fslmerge</italic>. Preprocessing included motion correction using MCFLIRT, slice timing correction (via Fourier time-series phase-shifting), BET brain extraction, grand-mean intensity normalization of the entire 4D dataset by a single multiplicative factor, and a high-pass temporal filtering (Gaussian-weighted least-squares straight line fitting, with sigma = 50.0s). The data from the functional localizer were spatially smoothed with a Gaussian kernel of FWHM 4.0mm. The data used in the main separability analysis were not spatially smoothed during preprocessing. Each functional scan was registered to the corresponding structural scan using boundary-based registration (BBR) in FLIRT with default parameters.</p>
</sec>
<sec id="sec035">
<title>Neural activity estimates</title>
<p>After preprocessing of the functional scans, estimates of single-trial stimulus-related activity were obtained for the faces in the main identification task. We used the iterative FBR (finite BOLD response) method described by Turner et al. [<xref ref-type="bibr" rid="pcbi.1006470.ref090">90</xref>] to deconvolve the BOLD activity related to each stimulus presentation. This method avoids assumptions about the hemodynamic response function that are inherent to parametric estimation methods and it is more successful than the latter in unmixing the responses to temporally adjacent events in event-related designs [<xref ref-type="bibr" rid="pcbi.1006470.ref090">90</xref>]. Instead of assuming a particular shape of the hemodynamic response function, the full shape of the BOLD response to a stimulus is estimated through a set of 12 FBR regressors that are ordered in sequence. In the regression matrix, each event is represented by a set of 12 ones, starting at the beginning of the event. The method is called “iterative” because it iterates through each trial to estimate the BOLD activity related to the stimulus presentation in that trial only. To do this, a group of 12 regressors is created for the target stimulus, and separate groups of 12 regressors are created for the four stimulus classes in the experiment (the target trial was excluded from the regressor of its class), and for the conjunction of crosshair presentation and response. This results in the estimation of 12 regression coefficients for the target stimulus, which are kept while all other regressors are discarded (they are included only to unmix their influence from the target estimates of the BOLD response). As indicated above, the process is iterated for each trial, resulting in a set of spatiotemporal maps (one for each stimulus presentation), representing estimates of the BOLD activity in each voxel and each of 12 TRs starting at the time of stimulus presentation. The algorithm was implemented in MATLAB (The MathWorks, Natick, MA, USA).</p>
</sec>
<sec id="sec036">
<title>Decoding separability test</title>
<p>Here we describe the procedures used to implement a decoding separability test. Theoretical results linking this test to the notions of decoding separability, encoding separability and perceptual separability, as well as a justification for the application of this test to neuroimaging data, can be found in the Results section.</p>
<p><xref ref-type="fig" rid="pcbi.1006470.g008">Fig 8</xref> is a schematic representation of the decoding separability test. In this simplified example, we consider only two voxels. The estimates of activity are thus represented in a two-dimensional voxel space. Each point represents activity on a different trial, with each color representing a different stimulus that has been repeatedly presented during the experiment. Decoding facial expression from these two voxels using a linear classifier involves finding a hyperplane in the activity space that best separates trials in which a neutral face was shown from trials in which a sad face was shown (the dotted line in <xref ref-type="fig" rid="pcbi.1006470.g008">Fig 8</xref>). The line orthogonal to the classification bound (sometimes called the classifier’s “decision variable”) represents the direction in voxel space that best discriminates one expression from the other. Thus, it is reasonable to assume that this is the direction in this specific voxel space along which expression is encoded. Using that specific direction in voxel space is not a requirement of the decoding separability test to be valid (the only requirement is that a linear decoding scheme is used; see <xref ref-type="sec" rid="sec002">Results</xref> section), but it allows us to link the present work to more traditional MVPA techniques. If we take all the observed data points and project them onto this “expression”dimension, we can use these projected points to estimate a distribution of decoded values. <italic>Decoding separability</italic> holds if this distribution of decoded values is invariant across changes in the stimulus on a second, irrelevant dimension. To test for decoding separability, the two distributions of points for a given expression (e.g., the orange and green distributions for “sad”), each corresponding to a different identity, can be compared to one another.</p>
<fig id="pcbi.1006470.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006470.g008</object-id>
<label>Fig 8</label>
<caption>
<title>A schematic representation of a test of decoding separability for neuroimaging data, implemented as an extension to traditional linear decoding procedures.</title>
<p>The simplified example considers the representation of four stimuli in two voxels. Each point represents activity on a different trial, and each color represents a different stimulus that has been repeatedly presented during the experiment. The dotted line represents a classification bound that separates trials according to emotional expression. The line orthogonal to this bound represents the direction in voxel space that best discriminates one expression from the other. Decoding separability holds if the distributions along this dimension for a given value of the target dimension (emotional expression) are equivalent across changes in the irrelevant dimension (identity). Adapted from: <ext-link ext-link-type="uri" xlink:href="http://figshare.com/articles/Test-of-separabilityof-neural-representations/1385406" xlink:type="simple">http://figshare.com/articles/Test-of-separabilityof-neural-representations/1385406</ext-link>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006470.g008" xlink:type="simple"/>
</fig>
<p>In the Results section, we link this decoding separability test to our main theory, and show that it is a valid test of violations of separability in neural representations, even when it is applied to indirect and noisy measures of brain activity, like those obtained from fMRI.</p>
<p>In two separate analyses, we tested the separability of emotion from identity and the separability of identity from emotion; because both analyses are identical, we will describe the analysis in terms of decoding separability of a “target” dimension from an “irrelevant” dimension. Each of the regression coefficients obtained in the previous step were standardized by column. We used a searchlight procedure [<xref ref-type="bibr" rid="pcbi.1006470.ref077">77</xref>] with a spherical mask that had a radius of three voxels. In each step of the analysis, the searchlight was centered on a different brain voxel and the selected data were used to train a linear support vector machine (SVM, using the <italic>LinearNuSVMC</italic> classifier included in pyMVPA) to decode the target dimension using all the available data. Then the data were projected to the normal line to the classification hyperplane to obtain a number of decoded values on the target dimension. Using Python augmented with the SciPy ecosystem, the group of decoded values for each stimulus was used to obtain kernel density estimates (KDEs) of their underlying probability distribution. A gaussian kernel and automatic bandwidth determination were used as implemented in the SciPy function <italic>gaussian_kde</italic>. Let <inline-formula id="pcbi.1006470.e149"><alternatives><graphic id="pcbi.1006470.e149g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e149" xlink:type="simple"/><mml:math display="inline" id="M149"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> represent the KDE for a stimulus with value <italic>i</italic> on the target dimension and value <italic>j</italic> on the irrelevant dimension, evaluated at point <inline-formula id="pcbi.1006470.e150"><alternatives><graphic id="pcbi.1006470.e150g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e150" xlink:type="simple"/><mml:math display="inline" id="M150"><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. The index <italic>i</italic> can take one of two values representing, for example, “sad” and “neutral” when the target dimension is emotional expression, as in the example given in <xref ref-type="fig" rid="pcbi.1006470.g008">Fig 8</xref>. Similarly, the index <italic>j</italic> can take one of two values representing “identity 1” and “identity 2”, as in this example identity is the irrelevant dimension. Then an index of deviations from decoding separability (<italic>DDS</italic>) was computed from all four KDEs obtained from the target dimension (in this example, emotional expression), according to the following equation:
<disp-formula id="pcbi.1006470.e151"><alternatives><graphic id="pcbi.1006470.e151g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e151" xlink:type="simple"/><mml:math display="block" id="M151"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>D</mml:mi> <mml:mi>D</mml:mi> <mml:mi>S</mml:mi> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mn>2</mml:mn></mml:munderover> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>000</mml:mn></mml:mrow></mml:munderover> <mml:mo>|</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mn>2</mml:mn></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>|</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(36)</label></disp-formula></p>
<p>Each KDE was evaluated at 1,000 evenly-spaced points <inline-formula id="pcbi.1006470.e152"><alternatives><graphic id="pcbi.1006470.e152g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e152" xlink:type="simple"/><mml:math display="inline" id="M152"><mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, indexed by <italic>k</italic> = 1, 2…1, 000, starting at the minimum data point minus half the data range, and finishing at the maximum data point plus half the data range. Note that the value <inline-formula id="pcbi.1006470.e153"><alternatives><graphic id="pcbi.1006470.e153g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006470.e153" xlink:type="simple"/><mml:math display="inline" id="M153"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mn>2</mml:mn></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> represents the difference between two distributions of decoded values, both related to stimuli with the same value in the target dimension (e.g., “sad”, represented by the index <italic>i</italic>) but different values in the irrelevant dimension (e.g., “identity 1” and “identity 2”, represented by the indexes 1 and 2 in the equation). The index uses the absolute value of the difference between a pair of distributions, which by definition is the <italic>L</italic>1 distance between the two (discretized) distributions (see <xref ref-type="disp-formula" rid="pcbi.1006470.e105">Eq 27</xref> below). If separability holds, then the distance between distributions should be zero. However, this is only true if we had access to the true distributions. Any error in the KDEs should produce differences between distributions that are added to the <italic>DDS</italic>. This makes it difficult to statistically test for deviations of separability, as the data from multiple participants cannot be combined (differences in the estimation error of the KDEs produces differences in scale of the statistic) and the expected value of the statistic under the null hypothesis is unknown. Under the assumption of decoding separability, two distributions that share the same level of the target dimension but different levels of the irrelevant dimension are identical. That is, data points from those distributions are exchangeable. Taking this into account, we standardized the statistic in the following way: (1) we shuffled the level of the irrelevant dimension for each data point 200 times (separately for each level of the target dimension); (2) each time we computed the <italic>DDS</italic>, yielding an empirical distribution function (EDF) of the statistic under the assumption of decoding separability; (3) the final standardized value was the percentile of the observed <italic>DDS</italic> in the EDF minus 50, representing percentile deviation from the median of the EDF.</p>
<p>Repeating this process for all searchlights resulted in a <italic>DDS</italic> map for each participant, which were converted to the participant’s anatomical space using FSL’s FLIRT linear registration and then to MNI 2mm standard space using FSL’s FNIRT nonlinear registration. The resulting <italic>DDS</italic> maps in standard space were submitted to a nonparametric permutation test using FSL’s <italic>randomise</italic> program [<xref ref-type="bibr" rid="pcbi.1006470.ref091">91</xref>], with the option <italic>clusterm</italic> for correction for multiple comparisons (which uses the distribution of the maximum cluster mass in the permutation test), a cluster threshold of 2.53 (corresponding to <italic>p</italic> = 0.01, uncorrected), variance smoothing with a sigma of 5 mm, and 5,000 permutations.</p>
<p>For visualization purposes, the volumes with significant statistics obtained from the permutation test were converted to the PALS-B12 surface-based atlas using CARET v.5.65 (<ext-link ext-link-type="uri" xlink:href="http://www.nitrc.org/projects/caret/" xlink:type="simple">www.nitrc.org/projects/caret/</ext-link>), and displayed together with the borders of face-selective areas from the localizer scan.</p>
</sec>
<sec id="sec037">
<title>Face-selective regions</title>
<p>Face-selective regions were defined using the data from the functional localizer. Low-level analyses were performed separately on the data from each participant. Three explanatory variables (EVs) were defined: Neutral Faces, Emotional Faces and Objects, each corresponding to a boxcar function covering the corresponding blocks in the functional scan (see Functional Localizer description above). These boxcar functions were convolved with the default Gamma hemodynamic response function in FSL, which has a mean lag of 6s and a standard deviation of 3s. A temporal derivative and temporal filtering were added to the design matrix. Two contrasts were formed: Faces (Neutral Faces + Emotional Faces) &gt; Objects, to define regions selective to face information in general, and Emotional Faces &gt; Neutral Faces, to define regions selective to face emotional expression more specifically. Each of these contrasts resulted on a separate map of <italic>z</italic> statistics for each participant. The individual <italic>z</italic> statistical maps were used as input to a high-level analysis, using a mixed-effects model (the option FLAME 1+2 in FSL), to generate a group map for each contrast. Clusters were first identified by thresholding the maps at <italic>z</italic> = 2.3; the experiment-wise false positive rate (<italic>α</italic> = 0.05) was controlled by using a threshold on cluster size derived from Gaussian random field theory.</p>
<p>The volumes with significant clusters obtained from the two contrasts were converted to the PALS-B12 surface-based atlas and their borders were manually drawn using CARET v.5.65 (<ext-link ext-link-type="uri" xlink:href="http://www.nitrc.org/projects/caret/" xlink:type="simple">http://www.nitrc.org/projects/caret/</ext-link>). These region borders were used as rough landmarks for the interpretation of the main results of the decoding separability analysis.</p>
<p>The Faces &gt; Objects contrast was additionally used to define face-selective functional regions of interest (ROIs) using the Group-Constrained Subject-Specific (GSS) described by [<xref ref-type="bibr" rid="pcbi.1006470.ref092">92</xref>]. First, individual maps were thresholded at <italic>p</italic> &lt; 0.05, uncorrected, and the resulting thresholded images were binarized. It was necessary to use a much more liberal threshold than that used by Julian et al. (<italic>p</italic> &lt; 0.0001) to obtain ROI masks in most participants (even at this low threshold, we did not obtain an ROI for the OFA in one participant), because our study was designed to carry out analyses at the group level (see below) and therefore the contrast had less power than that of Julian et al. at the level of individual participants. Second, we took the group-level “parcels” provided by Julian et al. in MNI 2mm standard space (available at <ext-link ext-link-type="uri" xlink:href="http://web.mit.edu/bcs/nklab/GSS.shtml" xlink:type="simple">http://web.mit.edu/bcs/nklab/GSS.shtml</ext-link>), and transformed them to the participant’s functional space using FNIRT. Third, we intersected the individual binary maps and the group-level parcels to define ROIs corresponding to the fusiform face area (FFA), occipital face area (OFA) and superior temporal sulcus face area (STS) in each individual participant.</p>
<p>Additional anatomical ROIs were obtained, to serve as controls and explore the behavior of our decoding separability test in different conditions. We obtained an ROI corresponding to primary visual cortex (PVC) from the Juelich Histological Atlas, and an ROI corresponding to the lateral ventricles from the Harvard-Oxfor Subcortical Structural Atlas; both atlas are included with FSL. The obtained ROIs were thresholded at a value of 20 using <italic>fslmaths</italic> and binarized. These final ROI masks, which were in MNI 2mm standard space, were transformed to each participant’s functional space using FNIRT.</p>
<p>All ROIs were obtained for both the left and right hemispheres.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1006470.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name>, <name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name>. <article-title>‘What’ and ‘where’ in the human brain</article-title>. <source>Curr Opin Neurobiol</source>. <year>1994</year>;<volume>4</volume>(<issue>2</issue>):<fpage>157</fpage>–<lpage>165</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0959-4388(94)90066-3" xlink:type="simple">10.1016/0959-4388(94)90066-3</ext-link></comment> <object-id pub-id-type="pmid">8038571</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rust</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Stocker</surname> <given-names>AA</given-names></name>. <article-title>Ambiguity and invariance: Two fundamental challenges for visual processing</article-title>. <source>Curr Opin Neurobiol</source>. <year>2010</year>;<volume>20</volume>(<issue>3</issue>):<fpage>382</fpage>–<lpage>388</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006470.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bruce</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Young</surname> <given-names>A</given-names></name>. <article-title>Understanding face recognition</article-title>. <source>Br J Psychol</source>. <year>1986</year>;<volume>77</volume>(<issue>3</issue>):<fpage>305</fpage>–<lpage>327</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.2044-8295.1986.tb02199.x" xlink:type="simple">10.1111/j.2044-8295.1986.tb02199.x</ext-link></comment> <object-id pub-id-type="pmid">3756376</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name>, <name name-style="western"><surname>Hoffman</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Gobbini</surname> <given-names>MI</given-names></name>. <article-title>The distributed human neural system for face perception</article-title>. <source>Trends Cogn Sci</source>. <year>2000</year>;<volume>4</volume>(<issue>6</issue>):<fpage>223</fpage>–<lpage>232</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S1364-6613(00)01482-0" xlink:type="simple">10.1016/S1364-6613(00)01482-0</ext-link></comment> <object-id pub-id-type="pmid">10827445</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bate</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bennetts</surname> <given-names>R</given-names></name>. <article-title>The independence of expression and identity in face-processing: evidence from neuropsychological case studies</article-title>. <source>Front Psychol</source>. <year>2015</year>;<volume>6</volume>:<fpage>770</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2015.00770" xlink:type="simple">10.3389/fpsyg.2015.00770</ext-link></comment> <object-id pub-id-type="pmid">26106348</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hadj-Bouziane</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Bell</surname> <given-names>AH</given-names></name>, <name name-style="western"><surname>Knusten</surname> <given-names>TA</given-names></name>, <name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name>, <name name-style="western"><surname>Tootell</surname> <given-names>RBH</given-names></name>. <article-title>Perception of emotional expressions is independent of face selectivity in monkey inferior temporal cortex</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2008</year> <month>Apr</month>;<volume>105</volume>(<issue>14</issue>):<fpage>5591</fpage>–<lpage>5596</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0800489105" xlink:type="simple">10.1073/pnas.0800489105</ext-link></comment> <object-id pub-id-type="pmid">18375769</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hasselmo</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Rolls</surname> <given-names>ET</given-names></name>, <name name-style="western"><surname>Baylis</surname> <given-names>GC</given-names></name>. <article-title>The role of expression and identity in the face-selective responses of neurons in the temporal visual cortex of the monkey</article-title>. <source>Behav Brain Res</source>. <year>1989</year>;<volume>32</volume>(<issue>3</issue>):<fpage>203</fpage>–<lpage>218</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0166-4328(89)80054-3" xlink:type="simple">10.1016/S0166-4328(89)80054-3</ext-link></comment> <object-id pub-id-type="pmid">2713076</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Winston</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Henson</surname> <given-names>RNA</given-names></name>, <name name-style="western"><surname>Fine-Goulden</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>fMRI-adaptation reveals dissociable neural representations of identity and expression in face perception</article-title>. <source>J Neurophysiol</source>. <year>2004</year>;<volume>92</volume>(<issue>3</issue>):<fpage>1830</fpage>–<lpage>1839</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00155.2004" xlink:type="simple">10.1152/jn.00155.2004</ext-link></comment> <object-id pub-id-type="pmid">15115795</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nestor</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Plaut</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Behrmann</surname> <given-names>M</given-names></name>. <article-title>Unraveling the distributed neural code of facial identity through spatiotemporal pattern analysis</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2011</year>;<volume>108</volume>(<issue>24</issue>):<fpage>9998</fpage>–<lpage>10003</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1102433108" xlink:type="simple">10.1073/pnas.1102433108</ext-link></comment> <object-id pub-id-type="pmid">21628569</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zhang</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Japee</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Nolan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Chu</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name>. <article-title>Face-selective regions differ in their ability to classify facial expressions</article-title>. <source>Neuroimage</source>. <year>2016</year> <month>Apr</month>;<volume>130</volume>:<fpage>77</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2016.01.045" xlink:type="simple">10.1016/j.neuroimage.2016.01.045</ext-link></comment> <object-id pub-id-type="pmid">26826513</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ganel</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Valyear</surname> <given-names>KF</given-names></name>, <name name-style="western"><surname>Goshen-Gottstein</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Goodale</surname> <given-names>MA</given-names></name>. <article-title>The involvement of the “fusiform face area” in processing facial expression</article-title>. <source>Neuropsychologia</source>. <year>2005</year>;<volume>43</volume>(<issue>11</issue>):<fpage>1645</fpage>–<lpage>1654</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuropsychologia.2005.01.012" xlink:type="simple">10.1016/j.neuropsychologia.2005.01.012</ext-link></comment> <object-id pub-id-type="pmid">16009246</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fox</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Moon</surname> <given-names>SY</given-names></name>, <name name-style="western"><surname>Iaria</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Barton</surname> <given-names>JJS</given-names></name>. <article-title>The correlates of subjective perception of identity and expression in the face network: An fMRI adaptation study</article-title>. <source>Neuroimage</source>. <year>2009</year> <month>Jan</month>;<volume>44</volume>(<issue>2</issue>):<fpage>569</fpage>–<lpage>580</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2008.09.011" xlink:type="simple">10.1016/j.neuroimage.2008.09.011</ext-link></comment> <object-id pub-id-type="pmid">18852053</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Soto</surname> <given-names>FA</given-names></name>, <name name-style="western"><surname>Vucovich</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Musgrave</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ashby</surname> <given-names>FG</given-names></name>. <article-title>General recognition theory with individual differences: A new method for examining perceptual and decisional interactions with an application to face perception</article-title>. <source>Psychon Bull Rev</source>. <year>2015</year>;<volume>22</volume>(<issue>1</issue>):<fpage>88</fpage>–<lpage>111</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13423-014-0661-y" xlink:type="simple">10.3758/s13423-014-0661-y</ext-link></comment> <object-id pub-id-type="pmid">24841236</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ashby</surname> <given-names>FG</given-names></name>, <name name-style="western"><surname>Townsend</surname> <given-names>JT</given-names></name>. <article-title>Varieties of perceptual independence</article-title>. <source>Psychol Rev</source>. <year>1986</year> <month>Apr</month>;<volume>93</volume>(<issue>2</issue>):<fpage>154</fpage>–<lpage>179</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.93.2.154" xlink:type="simple">10.1037/0033-295X.93.2.154</ext-link></comment> <object-id pub-id-type="pmid">3714926</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref015">
<label>15</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Ashby</surname> <given-names>FG</given-names></name>, <name name-style="western"><surname>Soto</surname> <given-names>FA</given-names></name>. <chapter-title>Multidimensional signal detection theory</chapter-title>. In: <name name-style="western"><surname>Busemeyer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Townsend</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>ZJ</given-names></name>, <name name-style="western"><surname>Eidels</surname> <given-names>A</given-names></name>, editors. <source>Oxford Handbook of Computational and Mathematical Psychology</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>; <year>2015</year>. p. <fpage>13</fpage>–<lpage>34</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006470.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Thomas</surname> <given-names>R</given-names></name>. <article-title>Perceptual interactions of facial dimensions in speeded classification and identification</article-title>. <source>Atten Percept Psychophys</source>. <year>2001</year>;<volume>63</volume>(<issue>4</issue>):<fpage>625</fpage>–<lpage>650</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03194426" xlink:type="simple">10.3758/BF03194426</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wenger</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Ingvalson</surname> <given-names>EM</given-names></name>. <article-title>A decisional component of holistic encoding</article-title>. <source>J Exp Psychol Learn Mem Cogn</source>. <year>2002</year>;<volume>28</volume>(<issue>5</issue>):<fpage>872</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0278-7393.28.5.872" xlink:type="simple">10.1037/0278-7393.28.5.872</ext-link></comment> <object-id pub-id-type="pmid">12219796</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Banks</surname> <given-names>WP</given-names></name>. <article-title>Recognition and source memory as multivariate decision processes</article-title>. <source>Psychol Sci</source>. <year>2000</year>;<volume>11</volume>(<issue>4</issue>):<fpage>267</fpage>–<lpage>273</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/1467-9280.00254" xlink:type="simple">10.1111/1467-9280.00254</ext-link></comment> <object-id pub-id-type="pmid">11273383</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rotello</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Macmillan</surname> <given-names>NA</given-names></name>, <name name-style="western"><surname>Reeder</surname> <given-names>JA</given-names></name>. <article-title>Sum-difference theory of remembering and knowing: a two-dimensional signal-detection model</article-title>. <source>Psychol Rev</source>. <year>2004</year>;<volume>111</volume>(<issue>3</issue>):<fpage>588</fpage>–<lpage>616</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.111.3.588" xlink:type="simple">10.1037/0033-295X.111.3.588</ext-link></comment> <object-id pub-id-type="pmid">15250777</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>DeCarlo</surname> <given-names>LT</given-names></name>. <article-title>Source monitoring and multivariate signal detection theory, with a model for selection</article-title>. <source>J Math Psychol</source>. <year>2003</year>;<volume>47</volume>(<issue>3</issue>):<fpage>292</fpage>–<lpage>303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0022-2496(03)00005-1" xlink:type="simple">10.1016/S0022-2496(03)00005-1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cohen</surname> <given-names>DJ</given-names></name>. <article-title>Visual detection and perceptual independence: Assessing color and form</article-title>. <source>Atten Percept Psychophys</source>. <year>1997</year>;<volume>59</volume>(<issue>4</issue>):<fpage>623</fpage>–<lpage>635</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03211870" xlink:type="simple">10.3758/BF03211870</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Demeyer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Zaenen</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wagemans</surname> <given-names>J</given-names></name>. <article-title>Low-level correlations between object properties and viewpoint can cause viewpoint-dependent object recognition</article-title>. <source>Spat Vis</source>. <year>2007</year>;<volume>20</volume>(<issue>1-2</issue>):<fpage>79</fpage>–<lpage>106</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1163/156856807779369760" xlink:type="simple">10.1163/156856807779369760</ext-link></comment> <object-id pub-id-type="pmid">17357717</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Amazeen</surname> <given-names>EL</given-names></name>, <name name-style="western"><surname>DaSilva</surname> <given-names>F</given-names></name>. <article-title>Psychophysical test for the independence of perception and action</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>2005</year>;<volume>31</volume>(<issue>1</issue>):<fpage>170</fpage>–<lpage>182</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0096-1523.31.1.170" xlink:type="simple">10.1037/0096-1523.31.1.170</ext-link></comment> <object-id pub-id-type="pmid">15709871</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Silbert</surname> <given-names>NH</given-names></name>. <article-title>Syllable structure and integration of voicing and manner of articulation information in labial consonant identification</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>2012</year>;<volume>131</volume>(<issue>5</issue>):<fpage>4076</fpage>–<lpage>4086</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.3699209" xlink:type="simple">10.1121/1.3699209</ext-link></comment> <object-id pub-id-type="pmid">22559380</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Giordano</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Visell</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Yao</surname> <given-names>HY</given-names></name>, <name name-style="western"><surname>Hayward</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Cooperstock</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>McAdams</surname> <given-names>S</given-names></name>. <article-title>Identification of walked-upon materials in auditory, kinesthetic, haptic, and audio-haptic conditions a</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>2012</year>;<volume>131</volume>(<issue>5</issue>):<fpage>4002</fpage>–<lpage>4012</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.3699205" xlink:type="simple">10.1121/1.3699205</ext-link></comment> <object-id pub-id-type="pmid">22559373</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Farris</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Viken</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Treat</surname> <given-names>TA</given-names></name>. <article-title>Perceived association between diagnostic and non-diagnostic cues of women’s sexual interest: General Recognition Theory predictors of risk for sexual coercion</article-title>. <source>J Math Psychol</source>. <year>2010</year>;<volume>54</volume>(<issue>1</issue>):<fpage>137</fpage>–<lpage>149</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jmp.2008.10.001" xlink:type="simple">10.1016/j.jmp.2008.10.001</ext-link></comment> <object-id pub-id-type="pmid">20607097</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref027">
<label>27</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Ashby</surname> <given-names>FG</given-names></name>, <name name-style="western"><surname>Soto</surname> <given-names>FA</given-names></name>. <chapter-title>The neural basis of general recognition theory</chapter-title>. In: <name name-style="western"><surname>Houpt</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Blaha</surname> <given-names>LM</given-names></name>, editors. <source>Mathematical models of perception and cognition, Volume II: A festschrift for James T. Townsend</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Routledge</publisher-name>; <year>2016</year>. p. <fpage>1</fpage>–<lpage>31</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006470.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Zemel</surname> <given-names>RS</given-names></name>. <article-title>Inference and computation with population codes</article-title>. <source>Annual Review of Neuroscience</source>. <year>2003</year>;<volume>26</volume>(<issue>1</issue>):<fpage>381</fpage>–<lpage>410</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.neuro.26.041002.131112" xlink:type="simple">10.1146/annurev.neuro.26.041002.131112</ext-link></comment> <object-id pub-id-type="pmid">12704222</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Naselaris</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Kay</surname> <given-names>KN</given-names></name>, <name name-style="western"><surname>Nishimoto</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name>. <article-title>Encoding and decoding in fMRI</article-title>. <source>Neuroimage</source>. <year>2011</year>;<volume>56</volume>(<issue>2</issue>):<fpage>400</fpage>–<lpage>410</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2010.07.073" xlink:type="simple">10.1016/j.neuroimage.2010.07.073</ext-link></comment> <object-id pub-id-type="pmid">20691790</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stankiewicz</surname> <given-names>BJ</given-names></name>. <article-title>Empirical evidence for independent dimensions in the visual representation of three-dimensional shape</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>2002</year>;<volume>28</volume>(<issue>4</issue>):<fpage>913</fpage>–<lpage>932</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0096-1523.28.4.913" xlink:type="simple">10.1037/0096-1523.28.4.913</ext-link></comment> <object-id pub-id-type="pmid">12190258</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mestry</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Wenger</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Donnelly</surname> <given-names>N</given-names></name>. <article-title>Identifying sources of configurality in three face processing tasks</article-title>. <source>Front Psychol</source>. <year>2012</year>;<volume>3</volume>:<fpage>456</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2012.00456" xlink:type="simple">10.3389/fpsyg.2012.00456</ext-link></comment> <object-id pub-id-type="pmid">23162505</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Richler</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Gauthier</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Wenger</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Palmeri</surname> <given-names>TJ</given-names></name>. <article-title>Holistic processing of faces: Perceptual and decisional components</article-title>. <source>J Exp Psychol Hum Learn</source>. <year>2008</year>;<volume>34</volume>(<issue>2</issue>):<fpage>328</fpage>–<lpage>342</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0278-7393.34.2.328" xlink:type="simple">10.1037/0278-7393.34.2.328</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fitousi</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Wenger</surname> <given-names>MJ</given-names></name>. <article-title>Variants of independence in the perception of facial identity and expression</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>2013</year>;<volume>39</volume>(<issue>1</issue>):<fpage>133</fpage>–<lpage>155</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0028001" xlink:type="simple">10.1037/a0028001</ext-link></comment> <object-id pub-id-type="pmid">22564158</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ganel</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Goshen-Gottstein</surname> <given-names>Y</given-names></name>. <article-title>Effects of familiarity on the perceptual integrality of the identity and expression of faces: The parallel-route hypothesis revisited</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>2004</year>;<volume>30</volume>(<issue>3</issue>):<fpage>583</fpage>–<lpage>596</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0096-1523.30.3.583" xlink:type="simple">10.1037/0096-1523.30.3.583</ext-link></comment> <object-id pub-id-type="pmid">15161388</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schweinberger</surname> <given-names>SR</given-names></name>, <name name-style="western"><surname>Soukup</surname> <given-names>GR</given-names></name>. <article-title>Asymmetric relationships among perceptions of facial identity, emotion, and facial speech</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>1998</year>;<volume>24</volume>(<issue>6</issue>):<fpage>1748</fpage>–<lpage>1765</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0096-1523.24.6.1748" xlink:type="simple">10.1037/0096-1523.24.6.1748</ext-link></comment> <object-id pub-id-type="pmid">9861721</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref036">
<label>36</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Garner</surname> <given-names>WR</given-names></name>. <source>The processing of information and structure</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Lawrence Erlbaum Associates</publisher-name>; <year>1974</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006470.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Goldstone</surname> <given-names>RL</given-names></name>. <article-title>Influences of categorization on perceptual discrimination</article-title>. <source>J Exp Psychol Gen</source>. <year>1994</year>;<volume>123</volume>(<issue>2</issue>):<fpage>178</fpage>–<lpage>200</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0096-3445.123.2.178" xlink:type="simple">10.1037/0096-3445.123.2.178</ext-link></comment> <object-id pub-id-type="pmid">8014612</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Soto</surname> <given-names>FA</given-names></name>, <name name-style="western"><surname>Gershman</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>. <article-title>Explaining compound generalization in associative and causal learning through rational principles of dimensional generalization</article-title>. <source>Psychol Rev</source>. <year>2014</year>;<volume>121</volume>(<issue>3</issue>):<fpage>526</fpage>–<lpage>558</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0037018" xlink:type="simple">10.1037/a0037018</ext-link></comment> <object-id pub-id-type="pmid">25090430</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Soto</surname> <given-names>FA</given-names></name>, <name name-style="western"><surname>Quintana</surname> <given-names>GR</given-names></name>, <name name-style="western"><surname>Pérez-Acosta</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Ponce</surname> <given-names>FP</given-names></name>, <name name-style="western"><surname>Vogel</surname> <given-names>EH</given-names></name>. <article-title>Why are some dimensions integral? Testing two hypotheses through causal learning experiments</article-title>. <source>Cognition</source>. <year>2015</year> <month>Oct</month>;<volume>143</volume>:<fpage>163</fpage>–<lpage>177</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cognition.2015.07.001" xlink:type="simple">10.1016/j.cognition.2015.07.001</ext-link></comment> <object-id pub-id-type="pmid">26163820</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bae</surname> <given-names>GY</given-names></name>, <name name-style="western"><surname>Flombaum</surname> <given-names>JI</given-names></name>. <article-title>Two items remembered as precisely as one: How integral features can improve visual working memory</article-title>. <source>Psychol Sci</source>. <year>2013</year> <month>Aug</month>;<volume>24</volume>:<fpage>2038</fpage>–<lpage>2047</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797613484938" xlink:type="simple">10.1177/0956797613484938</ext-link></comment> <object-id pub-id-type="pmid">23938276</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Zemel</surname> <given-names>R</given-names></name>. <article-title>Information processing with population codes</article-title>. <source>Nat Rev Neurosci</source>. <year>2000</year>;<volume>1</volume>(<issue>2</issue>):<fpage>125</fpage>–<lpage>132</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/35039062" xlink:type="simple">10.1038/35039062</ext-link></comment> <object-id pub-id-type="pmid">11252775</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Signal detection theory, uncertainty, and Poisson-like population codes</article-title>. <source>Vision Res</source>. <year>2010</year> <month>Oct</month>;<volume>50</volume>(<issue>22</issue>):<fpage>2308</fpage>–<lpage>2319</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2010.08.035" xlink:type="simple">10.1016/j.visres.2010.08.035</ext-link></comment> <object-id pub-id-type="pmid">20828581</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brouwer</surname> <given-names>GJ</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>. <article-title>Decoding and reconstructing color from responses in human visual cortex</article-title>. <source>J Neurosci</source>. <year>2009</year> <month>Nov</month>;<volume>29</volume>(<issue>44</issue>):<fpage>13992</fpage>–<lpage>14003</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3577-09.2009" xlink:type="simple">10.1523/JNEUROSCI.3577-09.2009</ext-link></comment> <object-id pub-id-type="pmid">19890009</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>. <article-title>Neural computations that underlie decisions about sensory stimuli</article-title>. <source>Trends Cogn Sci</source>. <year>2001</year>;<volume>5</volume>(<issue>1</issue>):<fpage>10</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S1364-6613(00)01567-9" xlink:type="simple">10.1016/S1364-6613(00)01567-9</ext-link></comment> <object-id pub-id-type="pmid">11164731</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Quiroga</surname> <given-names>RQ</given-names></name>, <name name-style="western"><surname>Panzeri</surname> <given-names>S</given-names></name>. <article-title>Extracting information from neuronal populations: information theory and decoding approaches</article-title>. <source>Nat Rev Neurosci</source>. <year>2009</year> <month>Mar</month>;<volume>10</volume>(<issue>3</issue>):<fpage>173</fpage>–<lpage>185</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn2578" xlink:type="simple">10.1038/nrn2578</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Seung</surname> <given-names>HS</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>. <article-title>Simple models for reading neuronal population codes</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1993</year> <month>Nov</month>;<volume>90</volume>(<issue>22</issue>):<fpage>10749</fpage>–<lpage>10753</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.90.22.10749" xlink:type="simple">10.1073/pnas.90.22.10749</ext-link></comment> <object-id pub-id-type="pmid">8248166</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pereira</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Mitchell</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Botvinick</surname> <given-names>M</given-names></name>. <article-title>Machine learning classifiers and fMRI: A tutorial overview</article-title>. <source>Neuroimage</source>. <year>2009</year> <month>Mar</month>;<volume>45</volume>(<issue>1</issue>):<fpage>S199</fpage>–<lpage>S209</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2008.11.007" xlink:type="simple">10.1016/j.neuroimage.2008.11.007</ext-link></comment> <object-id pub-id-type="pmid">19070668</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref048">
<label>48</label>
<mixed-citation publication-type="other" xlink:type="simple">Grootswagers T, Cichy RM, Carlson T. Finding decodable information that is read out in behaviour. bioRxiv. 2018 Jan;p. 248583.</mixed-citation>
</ref>
<ref id="pcbi.1006470.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Martinez-Camblor</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>de Uña-Alvarez</surname> <given-names>J</given-names></name>. <article-title>Non-parametric k-sample tests: Density functions vs distribution functions</article-title>. <source>Computational Statistics &amp; Data Analysis</source>. <year>2009</year> <month>Jul</month>;<volume>53</volume>(<issue>9</issue>):<fpage>3344</fpage>–<lpage>3357</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.csda.2009.02.009" xlink:type="simple">10.1016/j.csda.2009.02.009</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kayaert</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Biederman</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Op de Beeck</surname> <given-names>HP</given-names></name>. <article-title>Tuning for shape dimensions in macaque inferior temporal cortex</article-title>. <source>Eur J Neurosci</source>. <year>2005</year>;<volume>22</volume>:<fpage>212</fpage>–<lpage>224</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1460-9568.2005.04202.x" xlink:type="simple">10.1111/j.1460-9568.2005.04202.x</ext-link></comment> <object-id pub-id-type="pmid">16029211</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Haufe</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Meinecke</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Görgen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dähne</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Haynes</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Blankertz</surname> <given-names>B</given-names></name>, <etal>et al</etal>. <article-title>On the interpretation of weight vectors of linear models in multivariate neuroimaging</article-title>. <source>Neuroimage</source>. <year>2014</year>;<volume>87</volume>:<fpage>96</fpage>–<lpage>110</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.10.067" xlink:type="simple">10.1016/j.neuroimage.2013.10.067</ext-link></comment> <object-id pub-id-type="pmid">24239590</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Baumann</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Griffiths</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Sun</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Petkov</surname> <given-names>CI</given-names></name>, <name name-style="western"><surname>Thiele</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rees</surname> <given-names>A</given-names></name>. <article-title>Orthogonal representation of sound dimensions in the primate midbrain</article-title>. <source>Nat Neurosci</source>. <year>2011</year> <month>Apr</month>;<volume>14</volume>(<issue>4</issue>):<fpage>423</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2771" xlink:type="simple">10.1038/nn.2771</ext-link></comment> <object-id pub-id-type="pmid">21378972</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tanner</surname> <given-names>WP</given-names></name>. <article-title>Theory of recognition</article-title>. <source>J Acoust Soc Am</source>. <year>1956</year>;<volume>28</volume>:<fpage>882</fpage>–<lpage>888</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.1908504" xlink:type="simple">10.1121/1.1908504</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tucker</surname> <given-names>LR</given-names></name>. <article-title>Relations between multidimensional scaling and three-mode factor analysis</article-title>. <source>Psychometrika</source>. <year>1972</year> <month>Mar</month>;<volume>37</volume>(<issue>1</issue>):<fpage>3</fpage>–<lpage>27</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF02291410" xlink:type="simple">10.1007/BF02291410</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Anzellotti</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Caramazza</surname> <given-names>A</given-names></name>. <article-title>The neural mechanisms for the recognition of face identity in humans</article-title>. <source>Front Psychol</source>. <year>2014</year>;<volume>5</volume>:<fpage>672</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2014.00672" xlink:type="simple">10.3389/fpsyg.2014.00672</ext-link></comment> <object-id pub-id-type="pmid">25018745</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Anzellotti</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Caramazza</surname> <given-names>A</given-names></name>. <article-title>From parts to identity: invariance and sensitivity of face representations to different face halves</article-title>. <source>Cereb Cortex</source>. <year>2016</year>;<volume>26</volume>(<issue>5</issue>):<fpage>1900</fpage>–<lpage>1909</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhu337" xlink:type="simple">10.1093/cercor/bhu337</ext-link></comment> <object-id pub-id-type="pmid">25628344</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Anzellotti</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Fairhall</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Caramazza</surname> <given-names>A</given-names></name>. <article-title>Decoding representations of face identity that are tolerant to rotation</article-title>. <source>Cereb Cortex</source>. <year>2014</year> <month>Aug</month>;<volume>24</volume>(<issue>8</issue>):<fpage>1988</fpage>–<lpage>1995</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bht046" xlink:type="simple">10.1093/cercor/bht046</ext-link></comment> <object-id pub-id-type="pmid">23463339</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Allefeld</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Haynes</surname> <given-names>JD</given-names></name>. <article-title>Searchlight-based multi-voxel pattern analysis of fMRI by cross-validated MANOVA</article-title>. <source>Neuroimage</source>. <year>2014</year> <month>Apr</month>;<volume>89</volume>:<fpage>345</fpage>–<lpage>357</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.11.043" xlink:type="simple">10.1016/j.neuroimage.2013.11.043</ext-link></comment> <object-id pub-id-type="pmid">24296330</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Thomas</surname> <given-names>RD</given-names></name>. <article-title>Assessing sensitivity in a multidimensional space: Some problems and a definition of a general d’</article-title>. <source>Psychon Bull Rev</source>. <year>1999</year> <month>Jun</month>;<volume>6</volume>(<issue>2</issue>):<fpage>224</fpage>–<lpage>238</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03212328" xlink:type="simple">10.3758/BF03212328</ext-link></comment> <object-id pub-id-type="pmid">12199209</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Thomas</surname> <given-names>RD</given-names></name>. <article-title>Further considerations of a general d’ in multidimensional space</article-title>. <source>J Math Psychol</source>. <year>2003</year> <month>Apr</month>;<volume>47</volume>(<issue>2</issue>):<fpage>220</fpage>–<lpage>224</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0022-2496(02)00029-9" xlink:type="simple">10.1016/S0022-2496(02)00029-9</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hung</surname> <given-names>CP</given-names></name>, <name name-style="western"><surname>Kreiman</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Poggio</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>DiCarlo</surname> <given-names>JJ</given-names></name>. <article-title>Fast readout of object identity from macaque inferior temporal cortex</article-title>. <source>Science</source>. <year>2005</year>;<volume>310</volume>(<issue>5749</issue>):<fpage>863</fpage>–<lpage>866</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1117593" xlink:type="simple">10.1126/science.1117593</ext-link></comment> <object-id pub-id-type="pmid">16272124</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Goris</surname> <given-names>RLT</given-names></name>, <name name-style="western"><surname>Op de Beeck</surname> <given-names>HP</given-names></name>. <article-title>Neural representations that support invariant object recognition</article-title>. <source>Front Comput Neurosci</source>. <year>2009</year>;<volume>3</volume>:<fpage>1</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/neuro.10.003.2009" xlink:type="simple">10.3389/neuro.10.003.2009</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Goris</surname> <given-names>RLT</given-names></name>, <name name-style="western"><surname>Op de Beeck</surname> <given-names>HP</given-names></name>. <article-title>Invariance in visual object recognition requires training: a computational argument</article-title>. <source>Front Neurosci</source>. <year>2010</year> <month>May</month>;<volume>4</volume>(<issue>1</issue>):<fpage>71</fpage>–<lpage>78</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/neuro.01.012.2010" xlink:type="simple">10.3389/neuro.01.012.2010</ext-link></comment> <object-id pub-id-type="pmid">20589239</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Baudouin</surname> <given-names>JY</given-names></name>, <name name-style="western"><surname>Martin</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Tiberghien</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Verlut</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Franck</surname> <given-names>N</given-names></name>. <article-title>Selective attention to facial emotion and identity in schizophrenia</article-title>. <source>Neuropsychologia</source>. <year>2002</year>;<volume>40</volume>(<issue>5</issue>):<fpage>503</fpage>–<lpage>511</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0028-3932(01)00114-2" xlink:type="simple">10.1016/S0028-3932(01)00114-2</ext-link></comment> <object-id pub-id-type="pmid">11749980</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fox</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Barton</surname> <given-names>JJS</given-names></name>. <article-title>What is adapted in face adaptation? The neural representations of expression in the human visual system</article-title>. <source>Brain Res</source>. <year>2007</year> <month>Jan</month>;<volume>1127</volume>:<fpage>80</fpage>–<lpage>89</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.brainres.2006.09.104" xlink:type="simple">10.1016/j.brainres.2006.09.104</ext-link></comment> <object-id pub-id-type="pmid">17109830</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fox</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Oruç</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Barton</surname> <given-names>JJS</given-names></name>. <article-title>It doesn’t matter how you feel. The facial identity aftereffect is invariant to changes in facial expression</article-title>. <source>J Vis</source>. <year>2008</year>;<volume>8</volume>(<issue>3</issue>):<fpage>1</fpage>–<lpage>13</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/8.3.11" xlink:type="simple">10.1167/8.3.11</ext-link></comment> <object-id pub-id-type="pmid">18484817</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gao</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Maurer</surname> <given-names>D</given-names></name>. <article-title>A comparison of spatial frequency tuning for the recognition of facial identity and facial expressions in adults and children</article-title>. <source>Vision Res</source>. <year>2011</year> <month>Mar</month>;<volume>51</volume>(<issue>5</issue>):<fpage>508</fpage>–<lpage>519</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2011.01.011" xlink:type="simple">10.1016/j.visres.2011.01.011</ext-link></comment> <object-id pub-id-type="pmid">21277319</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref068">
<label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lander</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Butcher</surname> <given-names>N</given-names></name>. <article-title>Independence of face identity and expression processing: exploring the role of motion</article-title>. <source>Front Psychol</source>. <year>2015</year>;<volume>6</volume>:<fpage>255</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2015.00255" xlink:type="simple">10.3389/fpsyg.2015.00255</ext-link></comment> <object-id pub-id-type="pmid">25821441</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref069">
<label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pell</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Richards</surname> <given-names>A</given-names></name>. <article-title>Overlapping facial expression representations are identity-dependent</article-title>. <source>Vision Res</source>. <year>2013</year>;<volume>79</volume>(<issue>7</issue>):<fpage>1</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2012.12.009" xlink:type="simple">10.1016/j.visres.2012.12.009</ext-link></comment> <object-id pub-id-type="pmid">23274648</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Soto</surname> <given-names>FA</given-names></name>, <name name-style="western"><surname>Wasserman</surname> <given-names>EA</given-names></name>. <article-title>Asymmetrical interactions in the perception of face identity and emotional expression are not unique to the primate visual system</article-title>. <source>J Vis</source>. <year>2011</year>;<volume>11</volume>(<issue>3:24</issue>):<fpage>1</fpage>–<lpage>18</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006470.ref071">
<label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stoesz</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Jakobson</surname> <given-names>LS</given-names></name>. <article-title>A sex difference in interference between identity and expression judgments with static but not dynamic faces</article-title>. <source>J Vis</source>. <year>2013</year> <month>Apr</month>;<volume>13</volume>(<issue>5</issue>):<fpage>26</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/13.5.26" xlink:type="simple">10.1167/13.5.26</ext-link></comment> <object-id pub-id-type="pmid">23625643</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref072">
<label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Fu</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Johnston</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Yan</surname> <given-names>Z</given-names></name>. <article-title>Discriminability effect on Garner interference: evidence from recognition of facial identity and expression</article-title>. <source>Front Psychol</source>. <year>2013</year>;<volume>4</volume>:<fpage>943</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2013.00943" xlink:type="simple">10.3389/fpsyg.2013.00943</ext-link></comment> <object-id pub-id-type="pmid">24391609</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>O’Toole</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Roark</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Abdi</surname> <given-names>H</given-names></name>. <article-title>Recognizing moving faces: A psychological and neural synthesis</article-title>. <source>Trends Cogn Sci</source>. <year>2002</year>;<volume>6</volume>(<issue>6</issue>):<fpage>261</fpage>–<lpage>266</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S1364-6613(02)01908-3" xlink:type="simple">10.1016/S1364-6613(02)01908-3</ext-link></comment> <object-id pub-id-type="pmid">12039608</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref074">
<label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Duchaine</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Yovel</surname> <given-names>G</given-names></name>. <article-title>A revised neural rramework for face processing</article-title>. <source>Annu Rev Vis Sci</source>. <year>2015</year>;<volume>1</volume>(<issue>1</issue>):<fpage>393</fpage>–<lpage>416</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-vision-082114-035518" xlink:type="simple">10.1146/annurev-vision-082114-035518</ext-link></comment> <object-id pub-id-type="pmid">28532371</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref075">
<label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bernstein</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Yovel</surname> <given-names>G</given-names></name>. <article-title>Two neural pathways of face processing: A critical evaluation of current models</article-title>. <source>Neurosci Biobehav Rev</source>. <year>2015</year> <month>Aug</month>;<volume>55</volume>:<fpage>536</fpage>–<lpage>546</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neubiorev.2015.06.010" xlink:type="simple">10.1016/j.neubiorev.2015.06.010</ext-link></comment> <object-id pub-id-type="pmid">26067903</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref076">
<label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fox</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Iaria</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Barton</surname> <given-names>JJS</given-names></name>. <article-title>Defining the face processing network: optimization of the functional localizer in fMRI</article-title>. <source>Hum Brain Mapp</source>. <year>2009</year> <month>May</month>;<volume>30</volume>(<issue>5</issue>):<fpage>1637</fpage>–<lpage>1651</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hbm.20630" xlink:type="simple">10.1002/hbm.20630</ext-link></comment> <object-id pub-id-type="pmid">18661501</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref077">
<label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kriegeskorte</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Goebel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bandettini</surname> <given-names>P</given-names></name>. <article-title>Information-based functional brain mapping</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2006</year> <month>Mar</month>;<volume>103</volume>(<issue>10</issue>):<fpage>3863</fpage>–<lpage>3868</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0600244103" xlink:type="simple">10.1073/pnas.0600244103</ext-link></comment> <object-id pub-id-type="pmid">16537458</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref078">
<label>78</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Skerry</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Saxe</surname> <given-names>R</given-names></name>. <article-title>A common neural code for perceived and inferred emotion</article-title>. <source>J Neurosci</source>. <year>2014</year>;<volume>34</volume>(<issue>48</issue>):<fpage>15997</fpage>–<lpage>16008</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1676-14.2014" xlink:type="simple">10.1523/JNEUROSCI.1676-14.2014</ext-link></comment> <object-id pub-id-type="pmid">25429141</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref079">
<label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Anzellotti</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Caramazza</surname> <given-names>A</given-names></name>. <article-title>Multimodal representations of person identity individuated with fMRI</article-title>. <source>Cortex</source>. <year>2017</year>;<volume>89</volume>:<fpage>85</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cortex.2017.01.013" xlink:type="simple">10.1016/j.cortex.2017.01.013</ext-link></comment> <object-id pub-id-type="pmid">28242496</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref080">
<label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Davis</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>LaRocque</surname> <given-names>KF</given-names></name>, <name name-style="western"><surname>Mumford</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Norman</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name>. <article-title>What do differences between multi-voxel and univariate analysis mean? How subject-, voxel-, and trial-level variance impact fMRI analysis</article-title>. <source>Neuroimage</source>. <year>2014</year> <month>Aug</month>;<volume>97</volume>:<fpage>271</fpage>–<lpage>283</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2014.04.037" xlink:type="simple">10.1016/j.neuroimage.2014.04.037</ext-link></comment> <object-id pub-id-type="pmid">24768930</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref081">
<label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Naselaris</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Kay</surname> <given-names>KN</given-names></name>. <article-title>Resolving ambiguities of MVPA using explicit models of representation</article-title>. <source>Trends Cogn Sci</source>. <year>2015</year> <month>Oct</month>;<volume>19</volume>(<issue>10</issue>):<fpage>551</fpage>–<lpage>554</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2015.07.005" xlink:type="simple">10.1016/j.tics.2015.07.005</ext-link></comment> <object-id pub-id-type="pmid">26412094</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref082">
<label>82</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Cable</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Gardner</surname> <given-names>JL</given-names></name>. <article-title>Inverted encoding models of human population response conflate noise and neural tuning width</article-title>. <source>J Neurosci</source>. <year>2018</year> <month>Jan</month>;<volume>38</volume>(<issue>2</issue>):<fpage>398</fpage>–<lpage>408</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2453-17.2017" xlink:type="simple">10.1523/JNEUROSCI.2453-17.2017</ext-link></comment> <object-id pub-id-type="pmid">29167406</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref083">
<label>83</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Diedrichsen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kriegeskorte</surname> <given-names>N</given-names></name>. <article-title>Representational models: A common framework for understanding encoding, pattern-component, and representational-similarity analysis</article-title>. <source>PLoS Comput Biol</source>. <year>2017</year> <month>Apr</month>;<volume>13</volume>(<issue>4</issue>):<fpage>e1005508</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005508" xlink:type="simple">10.1371/journal.pcbi.1005508</ext-link></comment> <object-id pub-id-type="pmid">28437426</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref084">
<label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Paradiso</surname> <given-names>MA</given-names></name>. <article-title>A theory for the use of visual orientation information which exploits the columnar structure of striate cortex</article-title>. <source>Biol Cybern</source>. <year>1988</year>;<volume>58</volume>(<issue>1</issue>):<fpage>35</fpage>–<lpage>49</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00363954" xlink:type="simple">10.1007/BF00363954</ext-link></comment> <object-id pub-id-type="pmid">3345319</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref085">
<label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Deneve</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Reading population codes: a neural implementation of ideal observers</article-title>. <source>Nat Neurosci</source>. <year>1999</year> <month>Aug</month>;<volume>2</volume>(<issue>8</issue>):<fpage>740</fpage>–<lpage>745</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/11205" xlink:type="simple">10.1038/11205</ext-link></comment> <object-id pub-id-type="pmid">10412064</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref086">
<label>86</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ling</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name>. <article-title>How spatial and feature-based attention affect the gain and tuning of population responses</article-title>. <source>Vision Res</source>. <year>2009</year>;<volume>49</volume>(<issue>10</issue>):<fpage>1194</fpage>–<lpage>1204</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2008.05.025" xlink:type="simple">10.1016/j.visres.2008.05.025</ext-link></comment> <object-id pub-id-type="pmid">18590754</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref087">
<label>87</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Kadlec</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Townsend</surname> <given-names>JT</given-names></name>. <chapter-title>Signal detection analysis of multidimensional interactions</chapter-title>. In: <name name-style="western"><surname>Ashby</surname> <given-names>FG</given-names></name>, editor. <source>Multidimensional Models of Perception and Cognition</source>. <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum Associates</publisher-name>; <year>1992</year>. p. <fpage>181</fpage>–<lpage>231</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006470.ref088">
<label>88</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kadlec</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Townsend</surname> <given-names>JT</given-names></name>. <article-title>Implications of marginal and conditional detection parameters for the separabilities and independence of perceptual dimensions</article-title>. <source>J Math Psychol</source>. <year>1992</year> <month>Sep</month>;<volume>36</volume>(<issue>3</issue>):<fpage>325</fpage>–<lpage>374</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0022-2496(92)90027-5" xlink:type="simple">10.1016/0022-2496(92)90027-5</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref089">
<label>89</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ashby</surname> <given-names>FG</given-names></name>, <name name-style="western"><surname>Maddox</surname> <given-names>WT</given-names></name>. <article-title>A response time theory of separability and integrality in speeded classification</article-title>. <source>J Math Psychol</source>. <year>1994</year>;<volume>38</volume>(<issue>4</issue>):<fpage>423</fpage>–<lpage>466</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/jmps.1994.1032" xlink:type="simple">10.1006/jmps.1994.1032</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref090">
<label>90</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Turner</surname> <given-names>BO</given-names></name>, <name name-style="western"><surname>Mumford</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Ashby</surname> <given-names>FG</given-names></name>. <article-title>Spatiotemporal activity estimation for multivoxel pattern analysis with rapid event-related designs</article-title>. <source>Neuroimage</source>. <year>2012</year> <month>Sep</month>;<volume>62</volume>(<issue>3</issue>):<fpage>1429</fpage>–<lpage>1438</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2012.05.057" xlink:type="simple">10.1016/j.neuroimage.2012.05.057</ext-link></comment> <object-id pub-id-type="pmid">22659443</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref091">
<label>91</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Winkler</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Ridgway</surname> <given-names>GR</given-names></name>, <name name-style="western"><surname>Webster</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Nichols</surname> <given-names>TE</given-names></name>. <article-title>Permutation inference for the general linear model</article-title>. <source>Neuroimage</source>. <year>2014</year>;<volume>92</volume>:<fpage>381</fpage>–<lpage>397</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2014.01.060" xlink:type="simple">10.1016/j.neuroimage.2014.01.060</ext-link></comment> <object-id pub-id-type="pmid">24530839</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006470.ref092">
<label>92</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Julian</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Fedorenko</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Webster</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>. <article-title>An algorithmic method for functionally defining regions of interest in the ventral visual pathway</article-title>. <source>Neuroimage</source>. <year>2012</year> <month>May</month>;<volume>60</volume>(<issue>4</issue>):<fpage>2357</fpage>–<lpage>2364</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2012.02.055" xlink:type="simple">10.1016/j.neuroimage.2012.02.055</ext-link></comment> <object-id pub-id-type="pmid">22398396</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
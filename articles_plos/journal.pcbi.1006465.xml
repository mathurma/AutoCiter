<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006465</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-01443</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Imperfect Bayesian inference in visual perception</article-title>
<alt-title alt-title-type="running-head">Imperfect Bayesian inference in visual perception</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3359-0097</contrib-id>
<name name-style="western">
<surname>Stengård</surname>
<given-names>Elina</given-names>
</name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7353-5960</contrib-id>
<name name-style="western">
<surname>van den Berg</surname>
<given-names>Ronald</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Department of Psychology, University of Uppsala, Uppsala, Sweden</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Einhäuser</surname>
<given-names>Wolfgang</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Technische Universitat Chemnitz, GERMANY</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">ronald.vandenberg@psyk.uu.se</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>18</day>
<month>4</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<month>4</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>4</issue>
<elocation-id>e1006465</elocation-id>
<history>
<date date-type="received">
<day>20</day>
<month>8</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>8</day>
<month>3</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Stengård, van den Berg</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006465"/>
<abstract>
<p>Optimal Bayesian models have been highly successful in describing human performance on perceptual decision-making tasks, such as cue combination and visual search. However, recent studies have argued that these models are often overly flexible and therefore lack explanatory power. Moreover, there are indications that neural computation is inherently imprecise, which makes it implausible that humans would perform optimally on any non-trivial task. Here, we reconsider human performance on a visual-search task by using an approach that constrains model flexibility and tests for computational imperfections. Subjects performed a target detection task in which targets and distractors were tilted ellipses with orientations drawn from Gaussian distributions with different means. We varied the amount of overlap between these distributions to create multiple levels of external uncertainty. We also varied the level of sensory noise, by testing subjects under both short and unlimited display times. On average, empirical performance—measured as <italic>d</italic>’—fell 18.1% short of optimal performance. We found no evidence that the magnitude of this suboptimality was affected by the level of internal or external uncertainty. The data were well accounted for by a Bayesian model with imperfections in its computations. This “imperfect Bayesian” model convincingly outperformed the “flawless Bayesian” model as well as all ten heuristic models that we tested. These results suggest that perception is founded on Bayesian principles, but with suboptimalities in the implementation of these principles. The view of perception as imperfect Bayesian inference can provide a middle ground between traditional Bayesian and anti-Bayesian views.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>The main task of perceptual systems is to make truthful inferences about the environment. The sensory input to these systems is often astonishingly imprecise, which makes human perception prone to error. Nevertheless, numerous studies have reported that humans often perform as accurately as is possible given these sensory imprecisions. This suggests that the brain makes optimal use of the sensory input and computes without error. The validity of this claim has recently been questioned for two reasons. First, it has been argued that a lot of the evidence for optimality comes from studies that used overly flexible models. Second, optimality in human perception is implausible due to limitations inherent to neural systems. In this study, we reconsider optimality in a standard visual perception task by devising a research method that addresses both concerns. In contrast to previous studies, we find clear indications of suboptimalities. Our data are best explained by a model that is based on the optimal decision strategy, but with imperfections in its execution.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100004359</institution-id>
<institution>Vetenskapsrådet</institution>
</institution-wrap>
</funding-source>
<award-id>2015-00371</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7353-5960</contrib-id>
<name name-style="western">
<surname>van den Berg</surname>
<given-names>Ronald</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>RVDB acknowledges support from the Swedish Research Council (Vetenskapsrådet; reg.nr. 2015-00371; <ext-link ext-link-type="uri" xlink:href="http://www.vr.se" xlink:type="simple">www.vr.se</ext-link>) and Marie Sklodowska Curie Actions, Cofund (project INCA 600398; <ext-link ext-link-type="uri" xlink:href="https://ec.europa.eu/research" xlink:type="simple">https://ec.europa.eu/research</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="5"/>
<table-count count="4"/>
<page-count count="27"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The experimental data and Matlab code to reproduce the main figures and to fit the models are available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/dkavj/" xlink:type="simple">https://osf.io/dkavj/</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>An important function of the visual system is to make inferences about the environment from noisy sensory input. It is often claimed that human performance on perceptual inference tasks is optimal or “Bayesian” [<xref ref-type="bibr" rid="pcbi.1006465.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1006465.ref005">5</xref>], meaning that subjects supposedly perform as well as theoretically possible given the amount of sensory noise in their observations. Evidence for this claim has mainly come from tasks in which subjects integrate two sensory cues to estimate a common source. The optimal strategy in these tasks is to compute a weighted average of the two cues, where each weight depends on the cue’s reliability: the more reliable the cue, the more strongly it weighs in on the decision [<xref ref-type="bibr" rid="pcbi.1006465.ref006">6</xref>]. Reliability-based weighting is a hallmark of Bayesian observers and predicts that a subject’s estimates are biased towards the more reliable cue. This prediction has been confirmed in a wide range of experiments in which two sensory cues need to be combined to estimate a common source. Examples include integration of a visual and haptic cue to estimate the height of an object [<xref ref-type="bibr" rid="pcbi.1006465.ref007">7</xref>], a visual and proprioceptive [<xref ref-type="bibr" rid="pcbi.1006465.ref008">8</xref>] or auditory [<xref ref-type="bibr" rid="pcbi.1006465.ref009">9</xref>] cue to estimate object location, and two visual cues to estimate object depth [<xref ref-type="bibr" rid="pcbi.1006465.ref010">10</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref011">11</xref>] or object slant [<xref ref-type="bibr" rid="pcbi.1006465.ref012">12</xref>]. More recent work has reported that optimality in perception extends to tasks with as many as eight cues and with highly non-linear optimal decision rules, including visual search [<xref ref-type="bibr" rid="pcbi.1006465.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1006465.ref017">17</xref>], categorization [<xref ref-type="bibr" rid="pcbi.1006465.ref018">18</xref>], change detection [<xref ref-type="bibr" rid="pcbi.1006465.ref019">19</xref>], change localization [<xref ref-type="bibr" rid="pcbi.1006465.ref020">20</xref>], and sameness discrimination [<xref ref-type="bibr" rid="pcbi.1006465.ref021">21</xref>] tasks.</p>
<p>While these studies have provided valuable insights into basic mechanisms of perception, they have also been criticized. One criticism is that the emphasis on optimality has led to an underreporting and underemphasizing of studies that have found violations of optimality [<xref ref-type="bibr" rid="pcbi.1006465.ref022">22</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref023">23</xref>]. Another, more fundamental criticism is that optimal models often lack explanatory power due to being overly flexible [<xref ref-type="bibr" rid="pcbi.1006465.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1006465.ref026">26</xref>]. The risk of too much flexibility is that it may allow an optimal model to account for data from suboptimal observers. For example, when sensory noise levels are fitted as free parameters—as in most studies—an optimal model may account for suboptimalities in inference by overestimating these noise levels. Similarly, a freely fitted lapse rate may help an optimal model to explain away errors that were in reality caused by poor decision making. In addition to this methodological concern, several recent studies have suggested that neural computation is inherently imprecise [<xref ref-type="bibr" rid="pcbi.1006465.ref027">27</xref>–<xref ref-type="bibr" rid="pcbi.1006465.ref031">31</xref>], which makes it a priori implausible that humans perform optimally on any non-trivial task.</p>
<p>Here, we revisit optimality in perception by using a method that takes note of the concerns described above in three ways. First, we constrain flexibility of the optimal model by imposing prior distributions on its parameters; this reduces the risk that the optimal model explains away decision suboptimalities as sensory noise or attentional lapses. Second, for each model that we test, we also include a variant with computational imperfections. Such imperfections may produce suboptimal behavior, even when subjects use a decision strategy that is based on Bayesian principles. By including these models in our analyses, we can distinguish performance loss caused by using a wrong decision rule from performance loss due to imperfect execution of a rule. Third, besides only testing which kind of model accounts best for behavior, we will also quantify performance loss and partition this loss into different sources (see [<xref ref-type="bibr" rid="pcbi.1006465.ref027">27</xref>] for a similar approach).</p>
<p>We choose visual search as our experimental task. Despite the complexity of the optimal decision rule for this task, several previous studies have reported that humans perform near-optimally [<xref ref-type="bibr" rid="pcbi.1006465.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1006465.ref015">15</xref>]. We include experimental conditions in which stimuli are corrupted by external noise, which makes the task more consistent with naturalistic conditions, where inference often involves dealing with both internal and external sources of uncertainty [<xref ref-type="bibr" rid="pcbi.1006465.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref033">33</xref>]. We fit several Bayesian model variants as well as ten heuristic models to the experimental data. To preview our main result, we find no evidence for perfect optimality, nor for any of the heuristic-based strategies. Instead, the data are best explained by an “imperfect Bayesian”, in which decisions are based on Bayesian principles, but subject to imperfections in the implementation of these principles.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec003">
<title>Ethics statement</title>
<p>The study was approved by the Regional Ethical Review Board in Uppsala and conducted according to the Declaration of Helsinki Principles. Study subjects gave written informed consent prior to their enrollment in the experiment.</p>
</sec>
<sec id="sec004">
<title>Data and code sharing</title>
<p>The experimental data and Matlab code to reproduce the main figures and to fit the models are available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/dkavj/" xlink:type="simple">https://osf.io/dkavj/</ext-link>.</p>
</sec>
<sec id="sec005">
<title>Subjects</title>
<p>Thirty subjects were recruited via advertisements at the psychology department of Uppsala University in Sweden and received payment in the form of cinema tickets or gift vouchers. All subjects had self-reported normal or corrected-to-normal vision and gave informed consent before the start of the experiment. No subjects were excluded from any of the analyses.</p>
</sec>
<sec id="sec006">
<title>Stimuli</title>
<p>Stimuli were black ellipses (0.35 cd/m<sup>2</sup>) with an area of 0.60 deg<sup>2</sup> presented on a gray background (71 cd/m<sup>2</sup>; <xref ref-type="fig" rid="pcbi.1006465.g001">Fig 1A</xref>). The task-relevant feature in all experiments was ellipse orientation, with 0° defined as vertical. The eccentricity of the ellipses differed across stimuli and conditions. Ellipse eccentricity is formally defined as <inline-formula id="pcbi.1006465.e001"><alternatives><graphic id="pcbi.1006465.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mrow><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>a</italic> and <italic>b</italic> specify the ellipse’s semi-major axis and semi-minor axis, respectively. To avoid confusion with visual field eccentricity, we will refer to this eccentricity as “elongation”. Differences in elongation were used to create differences in the level of sensory noise across stimuli (<xref ref-type="fig" rid="pcbi.1006465.g001">Fig 1B</xref>). Stimuli were generated using the Psychophysics Toolbox [<xref ref-type="bibr" rid="pcbi.1006465.ref034">34</xref>] for Matlab and presented at fixed locations along an invisible circle at the center of the screen and with a radius of 7 degrees of visual angle.</p>
<fig id="pcbi.1006465.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006465.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Experimental design.</title>
<p>(A) Illustration of a trial in the discrimination task. Subjects reported on each trial the tilt direction of a single ellipse (“clockwise” or “counterclockwise” relative to vertical). The elongation of the stimulus could take two values. We refer to the most elongated type of ellipse as a “high reliability” stimulus and the less elongated type as a “low reliability” stimulus. Feedback was provided by briefly turning the fixation cross red (error) or green (correct) after the response was given. (B) The subject-averaged data (filled circles) and model fits (curves) reveal that sensitivity was higher for stimuli with high reliability (black) compared to those with low reliability (red). Error bars represent 1 s.e.m. (C) Illustration of a trial in the visual search task with brief stimulus presentation time. (D) Top: examples of target-present displays under the four different levels of external uncertainty. Bottom: distributions from which the stimuli in the example displays were drawn. In all four examples, the ellipse at the “north” location is a target and the other three are distractors.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.g001" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec007">
<title>General procedure</title>
<p>Each subject completed multiple experimental sessions that lasted about one hour each. At the start of the first session, they received general information about the experiment. Thereafter, they performed a discrimination task (<xref ref-type="fig" rid="pcbi.1006465.g001">Fig 1A</xref>) followed by one condition of the visual search task. In the remaining sessions, they only performed the visual search task (<xref ref-type="fig" rid="pcbi.1006465.g001">Fig 1C</xref>). We created eight conditions for the visual search task by using a 2×4 factorial design (<xref ref-type="table" rid="pcbi.1006465.t001">Table 1</xref>). The factors specify the stimulus presentation time (short <italic>vs</italic>. unlimited) and the level of external uncertainty (none, 5%, 10%, and 15%; explained below). Different groups of subjects performed different subsets of these conditions.</p>
<table-wrap id="pcbi.1006465.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006465.t001</object-id>
<label>Table 1</label> <caption><title>Overview of visual search task conditions and experimental subject groups.</title> <p>Each group consisted of 10 subjects. The condition with unlimited stimulus time and no external uncertainty was excluded from the experiment, because subjects are expected to perform 100% correct on it.</p></caption>
<alternatives>
<graphic id="pcbi.1006465.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="2"/>
<th align="left" rowspan="2"/>
<th align="center" colspan="4">Level of external uncertainty</th>
</tr>
<tr>
<th align="center">None</th>
<th align="center">5%</th>
<th align="center">10%</th>
<th align="center">15%</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" rowspan="4">Stimulus display time</td>
<td align="center" rowspan="2"><bold>Short (67 ms)</bold></td>
<td align="center">A</td>
<td align="center">B</td>
<td align="center">C</td>
<td align="center">D</td>
</tr>
<tr>
<td align="center">Group 1</td>
<td align="center">Group 2</td>
<td align="center">Group 1</td>
<td align="center">Group 3</td>
</tr>
<tr>
<td align="center" rowspan="2"><bold>Unlimited</bold></td>
<td align="center">-</td>
<td align="center">E</td>
<td align="center">F</td>
<td align="center">G</td>
</tr>
<tr>
<td align="center"/>
<td align="center">Group 2</td>
<td align="center">Group 1</td>
<td align="center">Group 3</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec008">
<title>Discrimination task</title>
<p>On each trial, the subject was presented with a single ellipse (67 ms) and reported whether it was tilted clockwise or counterclockwise with respect to vertical (<xref ref-type="fig" rid="pcbi.1006465.g001">Fig 1A</xref>). Trial-to-trial feedback was provided by briefly turning the fixation cross in the inter-trial screen green (correct) or red (incorrect). The elongation of the stimulus was 0.80 on half of the trials (“low reliability”) and 0.94 on the other half (“high reliability”), randomly intermixed. The stimulus location was randomly drawn on each trial from the set of four cardinal locations (“north”, “east”, “south”, and “west”). On the first 20 trials, the orientation of the stimulus was drawn from a uniform distribution on the range −5° to +5°. In the remaining trials, a cumulative Gaussian was fitted to the data collected thus far and the orientation for the next trial was then randomly drawn from the domain corresponding to the 55–95% correct range. This adaptive procedure increased the information obtained from each trial by reducing the number of extremely easy and difficult trials. Subjects completed 500 trials of this task.</p>
</sec>
<sec id="sec009">
<title>Visual search without external uncertainty (condition A)</title>
<p>In this condition, subjects were on each trial presented with four oriented ellipses. On half of the trials, all ellipses were distractors. On the other half, three ellipses were distractors and one was a target. The task was to report whether a target was present. Targets were tilted <italic>μ</italic><sub>target</sub> degrees in clockwise direction from vertical and distractors were tilted <italic>μ</italic><sub>target</sub> degrees in <italic>counterclockwise</italic> direction. The value of <italic>μ</italic><sub>target</sub> was customized for each subject (<xref ref-type="table" rid="pcbi.1006465.t002">Table 2</xref>) such that an optimal observer with sensory-noise levels equal to the ones estimated from the subject’s discrimination-task data had a predicted accuracy of 85% correct (averaged over trials with different combinations of low and high reliability stimuli). Stimulus display time was 67 ms and each stimulus was presented with an ellipse elongation of either 0.80 (“low reliability”) or 0.94 (“high reliability”). On each trial, the number of high-reliability stimuli was drawn from a uniform distribution on integers 0 to 4 and reliability values were then randomly distributed across the four stimuli. The four stimuli always appeared at the four cardinal locations (“north”, “east”, “south”, and “west”). Feedback was provided in the same way as in the discrimination task. The task consisted of 1500 trials divided equally over 12 blocks with short forced breaks between blocks.</p>
<table-wrap id="pcbi.1006465.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006465.t002</object-id>
<label>Table 2</label> <caption><title>Estimated sensory noise levels in the discrimination task (<inline-formula id="pcbi.1006465.e002"><alternatives><graphic id="pcbi.1006465.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mtext>low</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1006465.e003"><alternatives><graphic id="pcbi.1006465.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mtext>high</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>) and the customized experimental parameters (<italic>μ</italic><sub>target</sub>, <italic>σ</italic><sub>external</sub>) in the visual search task.</title></caption>
<alternatives>
<graphic id="pcbi.1006465.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Level of external uncertainty (%)</th>
<th align="center">Subj ID</th>
<th align="center"><inline-formula id="pcbi.1006465.e004"><alternatives><graphic id="pcbi.1006465.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mtext>low</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>(°)</th>
<th align="center"><inline-formula id="pcbi.1006465.e005"><alternatives><graphic id="pcbi.1006465.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mtext>high</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>(°)</th>
<th align="center"><italic>μ</italic><sub>target</sub> (°)</th>
<th align="center"><italic>σ</italic><sub>external</sub>(°)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">0</td>
<td align="center">1</td>
<td align="char" char=".">7.1</td>
<td align="char" char=".">4.6</td>
<td align="char" char=".">8.0</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center">2</td>
<td align="char" char=".">5.5</td>
<td align="char" char=".">2.0</td>
<td align="char" char=".">5.0</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center">3</td>
<td align="char" char=".">6.4</td>
<td align="char" char=".">2.3</td>
<td align="char" char=".">5.8</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center">4</td>
<td align="char" char=".">3.8</td>
<td align="char" char=".">1.8</td>
<td align="char" char=".">3.8</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center">5</td>
<td align="char" char=".">4.6</td>
<td align="char" char=".">2.2</td>
<td align="char" char=".">4.5</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center">6</td>
<td align="char" char=".">4.0</td>
<td align="char" char=".">3.3</td>
<td align="char" char=".">5.0</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center">7</td>
<td align="char" char=".">3.1</td>
<td align="char" char=".">1.3</td>
<td align="char" char=".">2.9</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center">8</td>
<td align="char" char=".">6.8</td>
<td align="char" char=".">2.8</td>
<td align="char" char=".">6.4</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center">9</td>
<td align="char" char=".">3.3</td>
<td align="char" char=".">2.4</td>
<td align="char" char=".">3.9</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center" style="border-bottom:dashed">0</td>
<td align="center" style="border-bottom:dashed">10</td>
<td align="char" char="." style="border-bottom:dashed">4.5</td>
<td align="char" char="." style="border-bottom:dashed">3.0</td>
<td align="char" char="." style="border-bottom:dashed">5.1</td>
<td align="center" style="border-bottom:dashed">0</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">11</td>
<td align="char" char=".">4.4</td>
<td align="char" char=".">3.4</td>
<td align="char" char=".">5.3</td>
<td align="center">2.4</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">12</td>
<td align="char" char=".">3.7</td>
<td align="char" char=".">3.0</td>
<td align="char" char=".">4.5</td>
<td align="center">2.1</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">13</td>
<td align="char" char=".">4.2</td>
<td align="char" char=".">2.6</td>
<td align="char" char=".">4.6</td>
<td align="center">2.1</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">14</td>
<td align="char" char=".">3.9</td>
<td align="char" char=".">2.2</td>
<td align="char" char=".">4.1</td>
<td align="center">1.9</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">15</td>
<td align="char" char=".">4.3</td>
<td align="char" char=".">3.1</td>
<td align="char" char=".">4.9</td>
<td align="center">2.3</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">16</td>
<td align="char" char=".">6.5</td>
<td align="char" char=".">2.4</td>
<td align="char" char=".">5.9</td>
<td align="center">2.8</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">17</td>
<td align="char" char=".">6.2</td>
<td align="char" char=".">3.3</td>
<td align="char" char=".">6.4</td>
<td align="center">2.9</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">18</td>
<td align="char" char=".">3.8</td>
<td align="char" char=".">2.0</td>
<td align="char" char=".">3.9</td>
<td align="center">1.8</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">19</td>
<td align="char" char=".">5.1</td>
<td align="char" char=".">3.0</td>
<td align="char" char=".">5.4</td>
<td align="center">2.5</td>
</tr>
<tr>
<td align="center" style="border-bottom:dashed">5</td>
<td align="center" style="border-bottom:dashed">20</td>
<td align="char" char="." style="border-bottom:dashed">4.6</td>
<td align="char" char="." style="border-bottom:dashed">2.6</td>
<td align="char" char="." style="border-bottom:dashed">4.8</td>
<td align="center" style="border-bottom:dashed">2.2</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">1</td>
<td align="char" char=".">7.1</td>
<td align="char" char=".">4.6</td>
<td align="char" char=".">8.0</td>
<td align="center">5.6</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">2</td>
<td align="char" char=".">5.5</td>
<td align="char" char=".">2.0</td>
<td align="char" char=".">5.0</td>
<td align="center">3.4</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">3</td>
<td align="char" char=".">6.4</td>
<td align="char" char=".">2.3</td>
<td align="char" char=".">5.8</td>
<td align="center">4.1</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">4</td>
<td align="char" char=".">3.8</td>
<td align="char" char=".">1.8</td>
<td align="char" char=".">3.8</td>
<td align="center">2.6</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">5</td>
<td align="char" char=".">4.6</td>
<td align="char" char=".">2.2</td>
<td align="char" char=".">4.5</td>
<td align="center">3.1</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">6</td>
<td align="char" char=".">4.0</td>
<td align="char" char=".">3.3</td>
<td align="char" char=".">5.0</td>
<td align="center">3.4</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">7</td>
<td align="char" char=".">3.1</td>
<td align="char" char=".">1.3</td>
<td align="char" char=".">2.9</td>
<td align="center">2.1</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">8</td>
<td align="char" char=".">6.8</td>
<td align="char" char=".">2.8</td>
<td align="char" char=".">6.4</td>
<td align="center">4.3</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">9</td>
<td align="char" char=".">3.3</td>
<td align="char" char=".">2.4</td>
<td align="char" char=".">3.9</td>
<td align="center">2.7</td>
</tr>
<tr>
<td align="center" style="border-bottom:dashed">10</td>
<td align="center" style="border-bottom:dashed">10</td>
<td align="char" char="." style="border-bottom:dashed">4.5</td>
<td align="char" char="." style="border-bottom:dashed">3.0</td>
<td align="char" char="." style="border-bottom:dashed">5.1</td>
<td align="center" style="border-bottom:dashed">3.4</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">21</td>
<td align="char" char=".">6.2</td>
<td align="char" char=".">2.6</td>
<td align="char" char=".">5.9</td>
<td align="center">5.8</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">22</td>
<td align="char" char=".">7.7</td>
<td align="char" char=".">2.4</td>
<td align="char" char=".">6.8</td>
<td align="center">6.7</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">23</td>
<td align="char" char=".">6.9</td>
<td align="char" char=".">4.2</td>
<td align="char" char=".">7.5</td>
<td align="center">7.1</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">24</td>
<td align="char" char=".">6.7</td>
<td align="char" char=".">4.8</td>
<td align="char" char=".">7.9</td>
<td align="center">7.5</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">25</td>
<td align="char" char=".">7.5</td>
<td align="char" char=".">4.5</td>
<td align="char" char=".">8.2</td>
<td align="center">7.8</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">26</td>
<td align="char" char=".">5.1</td>
<td align="char" char=".">3.6</td>
<td align="char" char=".">5.8</td>
<td align="center">5.7</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">27</td>
<td align="char" char=".">4.1</td>
<td align="char" char=".">2.3</td>
<td align="char" char=".">4.3</td>
<td align="center">4.3</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">28</td>
<td align="char" char=".">8.1</td>
<td align="char" char=".">3.3</td>
<td align="char" char=".">7.7</td>
<td align="center">7.4</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">29</td>
<td align="char" char=".">7.2</td>
<td align="char" char=".">5.2</td>
<td align="char" char=".">8.5</td>
<td align="center">8.1</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">30</td>
<td align="char" char=".">7.1</td>
<td align="char" char=".">3.3</td>
<td align="char" char=".">6.9</td>
<td align="center">6.8</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec010">
<title>Visual search with external uncertainty and short display time (conditions B-D)</title>
<p>The three visual search conditions with external uncertainty and short display time were identical to condition A, except that the orientations of the target and distractors were not fixed, but instead drawn from partly overlapping Gaussian distributions (<xref ref-type="fig" rid="pcbi.1006465.g001">Fig 1D</xref>). These distributions had means <italic>μ</italic><sub>target</sub> and −<italic>μ</italic><sub>target</sub> (see above), respectively, and a standard deviation <italic>σ</italic><sub>external</sub>. The value of <italic>σ</italic><sub>external</sub> was customized for each subject (<xref ref-type="table" rid="pcbi.1006465.t002">Table 2</xref>) such that the accuracy of an optimal observer would drop by 5, 10, or 15% compared to the same condition with <italic>σ</italic><sub>external</sub> = 0 (no external uncertainty). We refer to these percentages as <italic>levels of external uncertainty</italic>. Subjects completed 1500 trials divided equally over 12 blocks with short forced breaks between blocks.</p>
</sec>
<sec id="sec011">
<title>Visual search with external uncertainty and unlimited display time (conditions E-G)</title>
<p>These three conditions were identical to conditions B-D, except for the following two differences. First, stimuli were presented with an ellipse elongation of 0.97 and stayed on the screen until a response was provided, such that the sensory noise levels were reduced to a presumably negligible level. Second, this condition contained 500 instead of 1500 trials. Each subject completed this condition before the equivalent condition with short display times.</p>
</sec>
<sec id="sec012">
<title>Statistical analyses</title>
<p>All statistical tests were performed using the JASP software package [<xref ref-type="bibr" rid="pcbi.1006465.ref035">35</xref>]. Besides <italic>p</italic> values we also report Bayes factors, which specify the ratio between how likely the data are under one hypothesis (e.g., the null hypothesis) compared to how likely they are under an alternative hypothesis. An advantage of Bayes factors is that they can be used to both reject and support a hypothesis, whereas <italic>p</italic> values can only reject. All reported Bayes factors were computed using the default settings for the effect size priors (Cauchy scale parameter = 0.707; <italic>r</italic> scale for fixed effects = 0.5).</p>
</sec>
</sec>
<sec id="sec013" sec-type="materials|methods">
<title>Models</title>
<p>This section describes the models that we will fit to the data from the visual search task. An overview of these models is presented in <xref ref-type="table" rid="pcbi.1006465.t003">Table 3</xref>.</p>
<table-wrap id="pcbi.1006465.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006465.t003</object-id>
<label>Table 3</label> <caption><title>Overview of models and their free parameters for the visual search task with short display time.</title> <p>Parameters <italic>σ</italic><sub>low</sub> and <italic>σ</italic><sub>high</sub> only exist when the models are applied to conditions with short display time; in conditions with unlimited display time, the sensory noise level is fixed to a prespecified value (explained in Results).</p></caption>
<alternatives>
<graphic id="pcbi.1006465.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.t003" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Model ID</th>
<th align="center">Label</th>
<th align="center">Free parameters</th>
<th align="center">#</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1</td>
<td align="left">Flawless Bayesian</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic></td>
<td align="center">3</td>
</tr>
<tr>
<td align="center">2</td>
<td align="left">Imperfect Bayesian</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, <italic>μ</italic><sub>late</sub>, <italic>σ</italic><sub>late</sub></td>
<td align="center">5</td>
</tr>
<tr>
<td align="center">3</td>
<td align="left">Ignorant Bayesian</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, σ<sub>single</sub></td>
<td align="center">4</td>
</tr>
<tr>
<td align="center" style="border-bottom:thick">4</td>
<td align="left" style="border-bottom:thick">Imperfect ignorant Bayesian</td>
<td align="left" style="border-bottom:thick"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, σ<sub>single</sub>, <italic>μ</italic><sub>late</sub>, <italic>σ</italic><sub>late</sub></td>
<td align="center" style="border-bottom:thick">6</td>
</tr>
<tr>
<td align="center">5</td>
<td align="left">Maximum of observations</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, <italic>c</italic></td>
<td align="center">4</td>
</tr>
<tr>
<td align="center">6</td>
<td align="left">Minimum deviation from target</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, <italic>c</italic></td>
<td align="center">4</td>
</tr>
<tr>
<td align="center">7</td>
<td align="left">Minkowski distance from target</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, <italic>c</italic>, <italic>β</italic></td>
<td align="center">5</td>
</tr>
<tr>
<td align="center">8</td>
<td align="left">Mean of observations</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, <italic>c</italic></td>
<td align="center">4</td>
</tr>
<tr>
<td align="center">9</td>
<td align="left">Variance of observations</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, <italic>c</italic></td>
<td align="center">4</td>
</tr>
<tr>
<td align="center">10</td>
<td align="left">Imperfect maximum-of-observations</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, <italic>c</italic>, <italic>σ</italic><sub>late</sub></td>
<td align="center">5</td>
</tr>
<tr>
<td align="center">11</td>
<td align="left">Imperfect minimum-deviation-from-target</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, <italic>c</italic>, <italic>σ</italic><sub>late</sub></td>
<td align="center">5</td>
</tr>
<tr>
<td align="center">12</td>
<td align="left">Imperfect Minkowski-distance-from-target</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, <italic>c</italic>, <italic>β</italic>, <italic>σ</italic><sub>late</sub></td>
<td align="center">6</td>
</tr>
<tr>
<td align="center">13</td>
<td align="left">Imperfect mean-of-observations</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, <italic>c</italic>, <italic>σ</italic><sub>late</sub></td>
<td align="center">5</td>
</tr>
<tr>
<td align="center">14</td>
<td align="left">Imperfect variance-of-observations</td>
<td align="left"><italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, <italic>λ</italic>, <italic>c</italic>, <italic>σ</italic><sub>late</sub></td>
<td align="center">5</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<sec id="sec014">
<title>Optimal Bayesian decision variable</title>
<p>Before introducing the models, we derive the Bayesian decision variable for our visual search task. We denote target presence by a binary variable <italic>T</italic> (0 = absent, 1 = present), set size by <italic>N</italic>, the stimulus values by <bold>s</bold> = {<italic>s</italic><sub>1</sub>, <italic>s</italic><sub>2</sub>, …, <italic>s</italic><sub><italic>N</italic></sub>}, and the observer’s noisy observations of the stimulus values by <bold>x</bold> = {<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, …, <italic>x</italic><sub><italic>N</italic></sub>}. We make the common assumption that each stimulus observation, <italic>x</italic><sub><italic>i</italic></sub>, is corrupted by zero-mean Gaussian noise, i.e., <italic>x</italic><sub><italic>i</italic></sub> = <italic>s</italic><sub><italic>i</italic></sub>+<italic>ε</italic>, where <italic>ε</italic> is a Gaussian random variable with a mean of zero. The standard deviation of this noise distribution, denoted <italic>σ</italic><sub><italic>i</italic></sub>, is assumed to depend on the reliability of the stimulus, which in our experiment differed across locations (low <italic>vs</italic>. high reliability). The Bayesian observer reports “target present” if the posterior probability of target presence exceeds that of target absence, <italic>p</italic>(<italic>T</italic> = 1|<bold>x</bold>)&gt;<italic>p</italic>(<italic>T</italic> = 0|<bold>x</bold>). This strategy is equivalent to reporting “target present” if the log posterior ratio exceeds 0,
<disp-formula id="pcbi.1006465.e006">
<alternatives>
<graphic id="pcbi.1006465.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:mtext>log</mml:mtext><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>|</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>d</italic>(<bold>x</bold>) is referred to as the global decision variable. Under the generative model for our task (<xref ref-type="supplementary-material" rid="pcbi.1006465.s002">S1 Fig</xref>) this evaluates to
<disp-formula id="pcbi.1006465.e007">
<alternatives>
<graphic id="pcbi.1006465.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mtext>local</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where
<disp-formula id="pcbi.1006465.e008">
<alternatives>
<graphic id="pcbi.1006465.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mtext>local</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mtext>T</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mtext>T</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>external</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
is referred to as the local decision variable (see <xref ref-type="supplementary-material" rid="pcbi.1006465.s001">S1 Appendix</xref> for a derivation). Hence, the optimal decision variable is the log of an average of local decision variables, each of which represents the evidence (posterior ratio) for target presence: <italic>d</italic><sub>local</sub>(<italic>x</italic><sub><italic>i</italic></sub>)&lt;1 is evidence for a distractor at location <italic>i</italic> and <italic>d</italic><sub>local</sub>(<italic>x</italic><sub><italic>i</italic></sub>)&gt;1 is evidence for a target; a value of exactly 1 represents equal evidence for both options. We mentioned earlier that optimal observers weight each cue by its reliability. In (<xref ref-type="disp-formula" rid="pcbi.1006465.e008">Eq 2</xref>), this weighting occurs through sensory noise levels <italic>σ</italic><sub><italic>i</italic></sub>: the larger <italic>σ</italic><sub><italic>i</italic></sub>, the closer the local evidence associated to stimulus <italic>x</italic><sub><italic>i</italic></sub> is to 1.</p>
<sec id="sec015">
<title>Note about the sensory noise distribution</title>
<p>Since our stimulus domain is circular, the choice of a non-circular (Gaussian) noise distribution may seem poorly motivated. A theoretically better choice would have been to use a Von Mises distribution, as we have done in previous work (e.g., [<xref ref-type="bibr" rid="pcbi.1006465.ref015">15</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref019">19</xref>]). However, the sensory noise levels in our study are relatively low, in which case the Gaussian is a near-perfect approximation to the Von Mises. Because of its analytical and computational convenience, we decided to use a Gaussian rather than Von Mises noise distribution.</p>
</sec>
</sec>
<sec id="sec016">
<title>Model 1: The flawless Bayesian</title>
<p>The first model that we consider is the Bayesian observer without any imperfections beyond sensory noise. This observer—which we refer to as the “flawless Bayesian”—is assumed to have perfect knowledge of the statistical structure of the task and to use (<xref ref-type="disp-formula" rid="pcbi.1006465.e007">Eq 1</xref>) to compute its decision variable. Moreover, the flawless Bayesian is assumed to compute without error. The model’s only free parameters are the sensory noise levels <italic>σ</italic><sub><italic>i</italic></sub>. In conditions with unlimited display time, we fix <italic>σ</italic><sub><italic>i</italic></sub> either to 0 (no noise) or to a value obtained from a control experiment (explained in Results). In conditions with short display time, we fit <italic>σ</italic><sub><italic>i</italic></sub> separately for stimuli with low reliability (<italic>σ</italic><sub>low</sub>) and stimuli with high reliability (<italic>σ</italic><sub>high</sub>). Heeding the concern that an excess of flexibility in optimal models can make suboptimal behavior look optimal [<xref ref-type="bibr" rid="pcbi.1006465.ref023">23</xref>], we constrain these parameters by imposing prior distributions on their values (see <xref ref-type="supplementary-material" rid="pcbi.1006465.s001">S1 Appendix</xref>). Moreover, we refrain from adding a bias parameter to this model, for two reasons. First, while many previous studies—including some of our own (e.g. [<xref ref-type="bibr" rid="pcbi.1006465.ref019">19</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref021">21</xref>])–have not considered it problematic to allow for bias when testing for optimality, being biased is strictly speaking a violation of optimality. Second, and more importantly, a response bias can be confounded with biases caused by other, less obvious kinds of suboptimalities, as we will explain in our presentation of Model 2.</p>
</sec>
<sec id="sec017">
<title>Model 2: The imperfect Bayesian</title>
<p>Our second model is a Bayesian observer with imperfections in the computation of the decision variable. Such imperfections may produce suboptimalities in performance and could be caused by many different factors, such as noise in the neural mechanisms that compute the decision variable, incomplete knowledge of the statistical structure of the task, uncertainty about the experimental parameters, and suboptimal cue weighting. To get an idea of how computational imperfections affect a Bayesian observer’s decisions, we perform simulations with imperfect variants of Model 1. The imperfections in these variants create errors in the model’s decision variable, as compared to the decision variable of the flawless Bayesian observer. We simulate a large number of trials and find that for all tested imperfections, the distribution of this error is reasonably well approximated by a Gaussian distribution (<xref ref-type="fig" rid="pcbi.1006465.g002">Fig 2</xref>). Importantly, the mean of this Gaussian is not always zero, which indicates that computational imperfections may produce a systematic error in the decision variable, i.e., a bias. Since this computational bias is indistinguishable from a simple response bias, the two can easily be confounded, which is the main reason why we did not include a response bias in the flawless Bayesian model.</p>
<fig id="pcbi.1006465.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006465.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Simulated effects of four computational imperfections.</title>
<p>(A) Schematic illustration of a single trial in the simulation that was aimed at assessing how computational imperfections affect the optimal observer’s decision variable. On each trial, a stimulus set s and stimulus observations x were drawn from the generative model for the visual search task with 10% external uncertainty. Next, x was provided as input to the Flawless Bayesian model and to a variant of this model with a computational imperfection (e.g., a wrong belief about experimental parameter <italic>σ</italic><sub>external</sub>). Both models produce a decision variable, <italic>d</italic>(x). We denote the difference between these two decision variables by Δ<italic>d</italic>(x), which can be thought of as a computational error. A total of 1 million trials were simulated using four different types of computational imperfection: (1) Gaussian noise on the local decision variables; (2) an overestimated value of <italic>σ</italic><sub>external</sub>; (3) overestimated values of <italic>σ</italic><sub>low</sub> and <italic>σ</italic><sub>high</sub>; (4) item-to-item and trial-to-trial noise on <italic>σ</italic><sub>low</sub> and <italic>σ</italic><sub>high</sub>. (B) The distribution of Δ<italic>d</italic>(x) under each simulated computational imperfection (gray areas). In all four cases, this distribution is reasonably well approximated by a Gaussian distribution (black curves). The percentages indicate the accuracy loss caused by the computational imperfection; parameters <italic>μ</italic> and <italic>σ</italic> indicate the mean and standard deviation of the Gaussian fitted to each distribution. (C) The distribution of Δ<italic>d</italic>(x) in a model that contains all four tested imperfections simultaneously.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.g002" xlink:type="simple"/>
</fig>
<p>The finding that different kinds of suboptimality produce similar errors in the decision variable implies that it will be difficult to distinguish between them in model comparison. However, the upside of this similarity is that it allows us to test for computational imperfections in a rather <italic>general</italic> way: instead of implementing a separate model for each possible computational imperfection, we can test for a range of different imperfections by using a single model with Gaussian noise on the optimal decision variable. We implement this “imperfect Bayesian” model by adding a noise term <italic>η</italic> to (<xref ref-type="disp-formula" rid="pcbi.1006465.e007">Eq 1</xref>),
<disp-formula id="pcbi.1006465.e009">
<alternatives>
<graphic id="pcbi.1006465.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mtext>local</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>We denote the mean (bias) and standard deviation of this “late” noise by <italic>μ</italic><sub>late</sub> and <italic>σ</italic><sub>late</sub>, respectively, which are fitted as free parameters.</p>
</sec>
<sec id="sec018">
<title>Models 3 and 4: The ignorant Bayesian</title>
<p>The first two models weight each stimulus by its reliability, which is a hallmark of Bayesian observers. Model 3 is a variant that ignores differences in cue reliabilities and instead weighs them equally. In this model, (<xref ref-type="disp-formula" rid="pcbi.1006465.e008">Eq 2</xref>) is replaced with
<disp-formula id="pcbi.1006465.e010">
<alternatives>
<graphic id="pcbi.1006465.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mtext>local</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mtext>T</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mtext>T</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>single</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>external</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
where <italic>σ</italic><sub>single</sub> is a free parameter that determines the weight assigned to every stimulus. For lack of a better term, we refer to this model as the “ignorant Bayesian”. Model 4 is a variant of this model in which we add computational imperfections in the same way as in Model 2, i.e., by adding biased Gaussian noise to the global decision variable.</p>
</sec>
<sec id="sec019">
<title>Models 5–9: Heuristic models</title>
<p>In Models 1–4, decisions were made based on the optimal decision variable or an impoverished variant of it. We next introduce five models with heuristic decision strategies. Just as in the Bayesian models, the decision rule in these models consists of comparing a decision variable <italic>d</italic>(<bold>x</bold>) with some criterion <italic>c</italic>. However, <italic>d</italic>(<bold>x</bold>) is now computed using simple heuristics rather than being derived from Bayesian decision theory. Moreover, criterion <italic>c</italic> is fitted as a free parameter in the heuristic models, while in the Bayesian models the optimal criterion was 0 by construction.</p>
<p>The first heuristic model that we consider uses the maximum-of-output or “max” decision rule, which has its origin in signal detection theory [<xref ref-type="bibr" rid="pcbi.1006465.ref036">36</xref>] and is a commonly used heuristic in models of visual search (e.g., [<xref ref-type="bibr" rid="pcbi.1006465.ref016">16</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref037">37</xref>–<xref ref-type="bibr" rid="pcbi.1006465.ref039">39</xref>]). In the present task, the rationale is that since target orientations are on average larger than distractor orientations, one might perform well by reporting “target present” whenever the maximum observation, <italic>x</italic><sub><italic>i</italic></sub>, exceeds some threshold, <italic>c</italic>. The decision variable of the Max model is thus simply the maximum stimulus observation,
<disp-formula id="pcbi.1006465.e011">
<alternatives>
<graphic id="pcbi.1006465.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>max</mml:mtext><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>The next two heuristic models make decisions based on how much the stimulus observations deviate from the expected target value, which on average is smaller when a target is present. Model 6 uses the minimum absolute deviation as its decision variable,
<disp-formula id="pcbi.1006465.e012">
<alternatives>
<graphic id="pcbi.1006465.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e012" xlink:type="simple"/>
<mml:math display="block" id="M12">
<mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>min</mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mtext>target</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
which again is compared with a decision criterion <italic>c</italic>. Similarly, Model 7 uses the Minkowski distance between any stimulus observation and the expected target value as its decision variable,
<disp-formula id="pcbi.1006465.e013">
<alternatives>
<graphic id="pcbi.1006465.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mtext>target</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:msup></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>β</italic> is a free parameter. Since Models 6 and 7 are both based on <italic>absolute</italic> deviations from the target, the sign of the deviation does not matter for the amount of evidence that an observation gives for target presence. This differs from the decision strategy in the Bayesian models, where a deviation in the direction of the distractor always constitutes less evidence for a target than a deviation in the direction away from the distractor.</p>
<p>The next and final two heuristics are inspired by previous findings that the visual system represents summary statistics of the stimuli that it observes, including their mean and variance [<xref ref-type="bibr" rid="pcbi.1006465.ref040">40</xref>–<xref ref-type="bibr" rid="pcbi.1006465.ref042">42</xref>]. These statistics could be used to solve detection tasks of the kind used in our experiment, where both the mean and variance of the stimulus observations are expected to be larger on trials with a target compared to trials without a target. Therefore, Model 8 uses the mean of observations as the decision variable,
<disp-formula id="pcbi.1006465.e014">
<alternatives>
<graphic id="pcbi.1006465.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e014" xlink:type="simple"/>
<mml:math display="block" id="M14">
<mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
and Model 9 uses the variance,
<disp-formula id="pcbi.1006465.e015">
<alternatives>
<graphic id="pcbi.1006465.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e015" xlink:type="simple"/>
<mml:math display="block" id="M15">
<mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <inline-formula id="pcbi.1006465.e016"><alternatives><graphic id="pcbi.1006465.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is the average of the stimulus observations.</p>
<sec id="sec020">
<title>Free parameters</title>
<p>Just as in the Bayesian models, sensory noise levels <italic>σ</italic><sub>low</sub> and <italic>σ</italic><sub>high</sub> are fitted as free parameters. In addition, since heuristic strategies do not dictate the value of the decision criterion, <italic>c</italic>, it is fitted as a free parameter as well (in Bayesian models, the decision criterion is 0 by design). The Minkowski model has an additional free parameter <italic>β</italic>. We fit all these parameters in an entirely unconstrained way. This means that we give more flexibility to the heuristic models than to the Bayesian models, in which parameters are constrained by imposing prior distributions. This way, we ensure that if we find evidence for Bayesian models, then it is unlikely to be due to them being more flexible than alternative models.</p>
</sec>
</sec>
<sec id="sec021">
<title>Models 10–14: Imperfect heuristic models</title>
<p>The final five models that we consider are imperfect variants of the heuristic models. In these models, the decision variable is corrupted in the same way as in the imperfect Bayesian models. However, since bias in heuristic models is already captured in the criterion value, <italic>c</italic>, we fix <italic>μ</italic><sub>late</sub> to 0 and only fit <italic>σ</italic><sub>late</sub> as a free parameter.</p>
</sec>
<sec id="sec022">
<title>Lapse rate</title>
<p>Models of perceptual decision-making tasks often include a lapse rate to account for random guesses caused by attentional lapses. In such models, it is assumed that responses on some of the trials were the result of guessing rather than a decision strategy. The lapse rate parameter specifies the estimated proportion of guessing trials. If we do not include a lapse rate in our models, then we run the risk of underestimating how good the subjects’ decision strategies were, because guessing behavior can then only be accounted for as suboptimalities in their decision strategies. On the other hand, if we <italic>do</italic> include a lapse rate, then we give models a possibility to explain away decision suboptimalities as lapses, which brings along the opposite risk: we might <italic>overestimate</italic> how good subjects’ decision strategies were. In an attempt to minimize both risks, we include a lapse rate in all models, but in the Bayesian models we constrain this parameter by imposing a prior distribution on its values (see <xref ref-type="supplementary-material" rid="pcbi.1006465.s001">S1 Appendix</xref>).</p>
</sec>
<sec id="sec023">
<title>Model fitting and model comparison</title>
<p>We use an adaptive Bayesian optimization method [<xref ref-type="bibr" rid="pcbi.1006465.ref043">43</xref>] to find maximum-likelihood estimates of model parameters, at the level of individual subjects. Model evidence is measured as the Akaike Information Criterion [<xref ref-type="bibr" rid="pcbi.1006465.ref044">44</xref>] and interpreted using the rules of thumb provided by Burnham &amp; Anderson [<xref ref-type="bibr" rid="pcbi.1006465.ref045">45</xref>]. We performed a model recovery analysis [<xref ref-type="bibr" rid="pcbi.1006465.ref046">46</xref>] to verify that the models make sufficiently diverging predictions to distinguish them in a model comparison (see <xref ref-type="supplementary-material" rid="pcbi.1006465.s003">S2 Fig</xref>).</p>
</sec>
</sec>
<sec id="sec024" sec-type="results">
<title>Results</title>
<sec id="sec025">
<title>Discrimination task</title>
<p>Under the assumption that stimulus observations are corrupted by Gaussian noise, the predicted proportion of “clockwise” responses in the discrimination task is a cumulative Gaussian function of stimulus orientation. We refer to the standard deviation of this Gaussian as the sensory noise level. To verify that differences in stimulus elongation caused differences in sensory noise levels, we fitted two cumulative Gaussian models to the data. In the first model, the noise level is independent of ellipse elongation and fitted as a single free parameter. In the second model, the sensory noise levels are fitted as separate parameters for the low- and high-reliability stimuli, which we denote by <inline-formula id="pcbi.1006465.e017"><alternatives><graphic id="pcbi.1006465.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mtext>low</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006465.e018"><alternatives><graphic id="pcbi.1006465.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mtext>high</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, respectively. The second model accounts well for the data (<xref ref-type="fig" rid="pcbi.1006465.g001">Fig 1B</xref>) and model comparison favors this model for every subject (ΔAIC range: 0.50 to 22.3; mean±sem: 8.6±1.3). Moreover, for every subject the estimated noise level is higher for the low-reliability stimulus than for the high-reliability stimulus (<xref ref-type="table" rid="pcbi.1006465.t002">Table 2</xref>). Hence, the stimulus-reliability manipulation works as intended. We use noise estimates <inline-formula id="pcbi.1006465.e019"><alternatives><graphic id="pcbi.1006465.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mtext>low</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006465.e020"><alternatives><graphic id="pcbi.1006465.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mtext>high</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to customize the target and distractor distributions in the visual search experiment (<xref ref-type="table" rid="pcbi.1006465.t002">Table 2</xref>) and to constrain the Bayesian models fitted to the data from that experiment (<xref ref-type="supplementary-material" rid="pcbi.1006465.s001">S1 Appendix</xref>).</p>
<p>While previous studies (e.g., [<xref ref-type="bibr" rid="pcbi.1006465.ref047">47</xref>]) have reported that performance on discrimination tasks is sometimes better for stimuli at the vertical meridian (“north”/“south” locations) than for stimuli at the horizontal meridian (“east”/“west” locations), we do not find evidence for such an effect in the present experiment. Performance differed little across locations, ranging from 74.3±1.1% correct at the “east” location to 75.0±1.0% at the “north” location. A Bayesian one-way ANOVA provides strong evidence for the null hypothesis of there being no effect (BF<sub>01</sub> = 20.5, <italic>p</italic> = .97).</p>
</sec>
<sec id="sec026">
<title>Visual search with unlimited display time</title>
<p>We assume for the moment that sensory noise in the visual search conditions with unlimited display time was negligible, i.e., <italic>σ</italic><sub><italic>i</italic></sub> = 0. Under this assumption, the stimulus observations are identical to the true stimulus values, <bold>x</bold> = <bold>s</bold>, which allows us to write the optimal decision variable, (<xref ref-type="disp-formula" rid="pcbi.1006465.e007">Eq 1</xref>), directly as a function of <bold>s</bold>,
<disp-formula id="pcbi.1006465.e021">
<alternatives>
<graphic id="pcbi.1006465.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e021" xlink:type="simple"/>
<mml:math display="block" id="M21">
<mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>s</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mtext>target</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mtext>target</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>external</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula></p>
<p>Since there are no unknowns in this equation, we can compute the optimal decision variable for each trial that was presented to a subject. The flawless Bayesian responds “target present” on each trial with <italic>d</italic>(<bold>s</bold>)&gt;0 and “target absent” otherwise. Hence, if subjects are optimal, then their proportion of “target present” responses should be a step function of <italic>d</italic>(<bold>s</bold>), transitioning from 0 to 1 at <italic>d</italic>(<bold>s</bold>) = 0. In all three conditions, subjects clearly deviate from this prediction (<xref ref-type="fig" rid="pcbi.1006465.g003">Fig 3B</xref>, circles).</p>
<fig id="pcbi.1006465.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006465.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Results from the visual search conditions with unlimited display time.</title>
<p>(A) Left: AIC-based model comparison at the level of single subjects. Each column is a subject and each row is a model. The best model for each subject is indicated in dark blue (ΔAIC = 0). Right: Subject-averaged AIC values relative to the overall best model. The red dashed line indicates the ΔAIC≥10, which is interpreted as “no support”. (B) The subject data (black markers) are well accounted for by the “Imperfect Bayesian” and “Imperfect Max” models (black curves; the fits of both models are visually indistinguishable). Note that the distribution of <italic>d</italic>(<bold>s</bold>) (purple areas) becomes more concentrated around zero as the level of external uncertainty increases, due to the evidence generally being weaker in the tasks with more external uncertainty. (C) In all three conditions, the empirical <italic>d</italic>’ values (black) are lower than the values predicted by the Flawless Bayesian model (red). The average ratio between the <italic>d</italic>’ values is 0.834±0.017.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.g003" xlink:type="simple"/>
</fig>
<sec id="sec027">
<title>Model fits</title>
<p>To obtain insight into the possible nature of this apparent suboptimality, we fit the models listed in <xref ref-type="table" rid="pcbi.1006465.t003">Table 3</xref> to the individual datasets. Assuming that sensory noise is absent in these conditions, we set <italic>σ</italic><sub>i</sub> = 0 for all stimuli. Models 3 and 4 are excluded from the analysis, because they are identical to Models 1 and 2, respectively, when there is no sensory noise. Model comparison (<xref ref-type="fig" rid="pcbi.1006465.g003">Fig 3A</xref>) selects the Imperfect Max model as the preferred model, closely followed by the Imperfect Bayesian model (ΔAIC = 4.4±1.5). Both models account well for the data (<xref ref-type="fig" rid="pcbi.1006465.g003">Fig 3B</xref>, curves) and all other models are rejected (ΔAIC≥48.0±3.1 relative to the selected model). The slight advantage of the Max model in model comparison seems to be entirely due to its flexibility in fitting the lapse rate parameter: when constraining this parameter in the same way as in the Bayesian model, the difference changes to ΔAIC = 2.7±2.1 in favor of the Bayesian model.</p>
<p>We draw three conclusions from these model comparison results. First, the Max and Bayesian models are indistinguishable in these conditions (which was expected, as explained below). Second, the results provide strong evidence against the other four heuristics as well as against the flawless Bayesian. Third, whichever decision strategy was used, it seems that there were computational imperfections in its execution. Model comparison using cross validation instead of AIC gives the same results and conclusion (<xref ref-type="supplementary-material" rid="pcbi.1006465.s004">S3 Fig</xref>).</p>
</sec>
<sec id="sec028">
<title>Optimality index</title>
<p>While the above analysis suggests a deviation from optimality, it does not quantify the magnitude of this deviation. To estimate this magnitude, we introduce an optimality index <italic>I</italic> based on sensitivity indices,
<disp-formula id="pcbi.1006465.e022">
<alternatives>
<graphic id="pcbi.1006465.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e022" xlink:type="simple"/>
<mml:math display="block" id="M22">
<mml:mrow><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mtext>empirical</mml:mtext></mml:mrow><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mo>′</mml:mo></mml:mstyle></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mtext>optimal</mml:mtext></mml:mrow><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mo>′</mml:mo></mml:mstyle></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula></p>
<p>The numerator is the empirical sensitivity index, which we compute as the difference between the z-scores of the hit and false alarm rates in the subject data. The denominator is the sensitivity index of the optimal observer, which we compute in the same way, but based on simulated response data from the Flawless Bayesian model. In these simulations, we set the values of <italic>μ</italic><sub>target</sub> and <italic>σ</italic><sub>external</sub> to the subject’s customized values (<xref ref-type="table" rid="pcbi.1006465.t002">Table 2</xref>) and lapse rate <italic>λ</italic> to the maximum-likelihood estimate of the best-fitting model.</p>
<p>The subject-averaged optimality index across all three conditions is 0.834±0.017 (<xref ref-type="fig" rid="pcbi.1006465.g003">Fig 3C</xref>, bottom), which corresponds to a deviation of 16.6±1.7% from optimal. A Bayesian one-way ANOVA provides moderate evidence against the hypothesis that the optimality index depends on the level of external uncertainty (BF<sub>01</sub> = 4.03; <italic>p</italic> = .79).</p>
</sec>
<sec id="sec029">
<title>Accounting for possible sensory noise</title>
<p>Despite the unlimited display time, it is possible—and perhaps even likely—that there was still some noise in the subjects’ encoding of stimulus orientations. If that is the case, then our assumption <italic>σ</italic><sub><italic>i</italic></sub> = 0 was wrong and the above analysis will have underestimated the optimality index. Unfortunately, we cannot fit <italic>σ</italic><sub><italic>i</italic></sub> as a free parameter, because that creates identifiability problems in models with a <italic>σ</italic><sub>late</sub> parameter. Therefore, we instead estimate it using a separate experiment. This control experiment is identical to the discrimination experiment (<xref ref-type="fig" rid="pcbi.1006465.g001">Fig 1A</xref>), except that the stimulus has an ellipse elongation of 0.97 and stays on the screen until a response is given. By fitting a cumulative Gaussian to the data from twelve (new) observers, we find an estimate <italic>σ</italic><sub><italic>i</italic></sub> = 0.875±0.097.</p>
<p>We fit the models again, but now with <italic>σ</italic><sub><italic>i</italic></sub> fixed to 0.875 instead of 0. Model comparison gives very similar results as before: the imperfect variants of the Max and Bayesian models are very close to each other (ΔAIC = 5.0±1.5 in favor of the Max model) and none of the other models is supported (ΔAIC&gt;47.8±8.2 relative to the best-fitting model). However, we now find a slightly higher optimality index, <italic>I</italic> = 0.879±0.019, which corresponds to a 12.1±1.9% deviation from optimal. A Bayesian one-way ANOVA again suggests that there is no effect of the level of external uncertainty on the optimality index (BF<sub>01</sub> = 2.40; <italic>p</italic> = .36).</p>
</sec>
</sec>
<sec id="sec030">
<title>Visual search with short display times</title>
<p>Next, we fit the models to the data from the conditions with short display times. Model comparison (<xref ref-type="fig" rid="pcbi.1006465.g004">Fig 4A</xref>) selects the Imperfect Bayesian as the preferred model and rejects all other models with large margins (ΔAIC≥19.6±4.0). This result is consistent with the results above, except that both Max models are now convincingly rejected. The main conclusion that we draw from this model-comparison result is that subjects neither seem to behave optimally, nor do they seem to use a heuristic decision strategy. Instead, their decisions seem to be based on Bayesian principles that are implemented or executed imperfectly. Model comparison using cross-validation gives near-identical results (<xref ref-type="supplementary-material" rid="pcbi.1006465.s004">S3 Fig</xref>).</p>
<fig id="pcbi.1006465.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006465.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Results from the visual search conditions with short display time.</title>
<p>(A) Left: AIC-based model comparison at the level of single subjects. Each column is a subject and each row is a model. The best model for each subject is indicated in dark blue (ΔAIC = 0). Right: Subject-averaged AIC values relative to the overall best model. The red dashed line indicates the ΔAIC≥10, which is interpreted as “no support”. (B) False-alarm rates (red) and hit rates conditioned on whether the target had high reliability (blue) or low reliability (green). The subject data (markers) are well accounted for by the Imperfect Bayesian (curves). (C) In all four conditions, the empirical <italic>d</italic>’ values (black) are lower than the values predicted by the Flawless Bayesian model (red). The average ratio between the <italic>d</italic>’ values is 0.808±0.037.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.g004" xlink:type="simple"/>
</fig>
<p>The reason why the Max and Bayesian model were tied in the conditions with unlimited display time is that they make near-identical predictions when all stimuli have the same reliability, as we have observed in earlier work [<xref ref-type="bibr" rid="pcbi.1006465.ref048">48</xref>]. Therefore, it is important to use mixed-reliability designs when testing these two models against each other: while reliability-based weighting is an inherent property of Bayesian decision making, there is no natural way to incorporate such weighting in a Max model. Our finding that only a Bayesian model accounts well for data from mixed-reliability conditions strongly suggests that humans take stimulus reliability into account during perceptual decision making.</p>
<p>It is worth noting that it is unlikely that the superiority of the Imperfect Bayesian was due to it being overly flexible. First, it does not have more parameters than most of the heuristic models (<xref ref-type="table" rid="pcbi.1006465.t003">Table 3</xref>). Second, while parameters in the heuristic models were entirely unconstrained, we imposed prior distribution on parameters of the Bayesian models. Third, a model recovery analysis (<xref ref-type="supplementary-material" rid="pcbi.1006465.s003">S2 Fig</xref>) showed that the Imperfect Bayesian is never selected when data are generated from one of the other 13 models.</p>
<sec id="sec031">
<title>Optimality index</title>
<p>We use the earlier introduced optimality index, (<xref ref-type="disp-formula" rid="pcbi.1006465.e022">Eq 6</xref>), to estimate how much subjects deviate from optimality. We again use the Flawless Bayesian to compute <inline-formula id="pcbi.1006465.e023"><alternatives><graphic id="pcbi.1006465.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mtext>optimal</mml:mtext></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, with <italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, and lapse rate <italic>λ</italic> set to the subject’s maximum-likelihood estimates in the best-fitting model. Averaged across all subjects in the conditions with brief display times, we find <italic>I</italic> = 0.808±0.037, which corresponds to a 19.2±3.7% deviation from optimal performance (<xref ref-type="fig" rid="pcbi.1006465.g004">Fig 4C</xref>). A one-way ANOVA reveals moderate evidence against an effect of the level of external uncertainty (BF<sub>01</sub> = 5.05; <italic>p</italic> = .70). A two-way Bayesian ANOVA that also includes the optimality indices from the conditions with unlimited display time reveals moderate evidence against an effect of the level of internal uncertainty (BF<sub>inclusion</sub> = 0.20; <italic>p</italic> = .47) and strong evidence against an effect of the level of external uncertainty (BF<sub>inclusion</sub> = 0.07; <italic>p</italic> = .79). Averaged across all 7 experimental conditions, we find an optimality index of 0.819±0.022, which corresponds to an 18.1±2.2% deviation from optimality.</p>
</sec>
</sec>
<sec id="sec032">
<title>Comparison with effects of sensory noise</title>
<p>The optimality indices reported above estimate how much performance was lost due to computational imperfections. For comparison, we also estimate performance loss caused by sensory noise. To this end, we compute a variant of the earlier introduced optimality index, (<xref ref-type="disp-formula" rid="pcbi.1006465.e022">Eq 6</xref>). In this variant, we “turn off” the sensory noise when computing <inline-formula id="pcbi.1006465.e024"><alternatives><graphic id="pcbi.1006465.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mtext>optimal</mml:mtext></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, by fixing <italic>σ</italic><sub><italic>i</italic></sub> to 0. This new optimality index expresses empirical performance relative to an optimal observer without sensory noise. We refer to our original index as the “relative optimality” index and to this new index as the “absolute optimality” index [<xref ref-type="bibr" rid="pcbi.1006465.ref003">3</xref>]. The difference between these two indices gives an estimate of the amount of optimality loss due to sensory noise. To illustrate this, consider an example in which a subject has a relative optimality index <italic>I</italic><sub>relative</sub> = 0.80 and an absolute optimality index <italic>I</italic><sub>absolute</sub> = 0.70. In this example, the subject has an optimality loss of 0.20 when sensory noise is not considered to be a form of suboptimality and a loss of 0.30 when it is. We would in this case conclude that sensory noise accounted for 33.3% of the optimality loss (0.10 out of a total loss of 0.30) and computational imperfections for 66.7% (0.20 out of 0.30).</p>
<p>When applying this method to the data from conditions with unlimited display time, we find that computational imperfections account for an estimated 92.6±3.8% of the performance loss and sensory noise for the remaining 7.4±3.8%. In conditions with short display time, we find that computational imperfections account for 27.0±5.1% of the performance loss and sensory noise for 73.0±5.1%. As expected, when sensory noise levels are low, performance loss is almost entirely attributed to computational imperfections. Nevertheless, even in conditions with considerable levels of sensory noise, we estimate that almost a third of the performance loss was due to computational imperfections.</p>
</sec>
<sec id="sec033">
<title>Analysis of parameter estimates</title>
<p>Next, we have a look at the best-fitting parameter estimates in the Imperfect Bayesian model. One-way ANOVAs suggest that there is an effect of the level of external uncertainty on both <italic>σ</italic><sub>low</sub> (BF<sub>10</sub> = 9.06; <italic>p</italic> = .005) and <italic>σ</italic><sub>high</sub> (BF<sub>10</sub> = 1.78; <italic>p</italic> = .042). Visual inspection of the parameter estimates (<xref ref-type="fig" rid="pcbi.1006465.g005">Fig 5</xref>) reveals that this is mainly due to the condition with the highest level of external uncertainty, in which the sensory noise estimates are visibly higher than in the other conditions. However, the stimuli were extremely similar between the different conditions, which makes it implausible that there were large differences in sensory noise levels. Hence, despite our efforts to constrain these parameters, they may still have been overestimated in the condition with the highest level of external uncertainty. This means that we might have underestimated the magnitude of the deviation from optimality in that condition. For the two parameters that control the late noise distribution, we find neither an effect of the level of internal uncertainty (BF<sub>inclusion</sub> = 0.25 for both <italic>μ</italic><sub>late</sub> and <italic>σ</italic><sub>late</sub>) nor of the level of external uncertainty (<italic>μ</italic><sub>late</sub>: BF<sub>inclusion</sub> = 0.52; <italic>σ</italic><sub>late</sub>: BF<sub>inclusion</sub> = 0.10). Finally, for the lapse rate parameter we find evidence against an effect of the level of internal uncertainty (BF<sub>inclusion</sub> = 0.56) and in favor of an effect of the level of external uncertainty (BF<sub>inclusion</sub> = 1.22). However, the evidence for this effect is very weak and the estimated lapse rates are very small in all conditions, so we do not consider this finding to be of any significance.</p>
<fig id="pcbi.1006465.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006465.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Maximum likelihood estimates of the parameters in the imperfect Bayesian model.</title>
<p>The reported parameters for conditions with unlimited display time were obtained with the model variant in which <italic>σ</italic><sub><italic>i</italic></sub> was fixed to 0.875.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec034">
<title>Reanalysis without pop-out trials</title>
<p>While the use of mixed reliabilities is a powerful way to test predictions that are unique to Bayesian models, it has the side effect that a stimulus may “pop out” when its reliability differs from that of all other stimuli. Stimuli that pop out may inadvertently draw attention and be given more weight, which would cause a suboptimality in performance, because the optimal weight is entirely determined by the reliability of a stimulus. We find that accuracy was slightly higher on trials in which the target popped out (72.5% correct) than on trials in which it did not (69.4% correct), which suggests that pop-out items indeed drew subjects’ attention. A t-test supports that there is a difference in accuracy between these two groups of trials (BF<sub>10</sub> = 4.92; <italic>p</italic> = .008). To verify that the deviation from optimality in the conditions with short display time were not entirely caused by this pop-out effect, we fit the models again after filtering out pop-out trials. In this analysis, we thus only consider trials with 0, 2, or 4 high-reliability stimuli (60% of the data). Note that only a third of the trials in this modified dataset has mixed reliability.</p>
<p>As before, we find that model comparison selects the Imperfect Bayesian as the preferred model. However, the difference with the Max models is smaller now (Flawless Max: ΔAIC = 7.0±2.2; Imperfect Max: ΔAIC = 9.3±2.3; the difference with all other heuristic models is still large, ΔAIC≥48.8±7.9). This was to be expected, because we filtered out most of the mixed-reliability trials and we already established that the Max and Bayesian decision rules are indistinguishable on single-reliability data. When we constrain the parameters in the Max model in the same way as in the Bayesian models—which makes a fairer comparison—the Imperfect Bayesian outperforms both Max models with decent margins (Flawless Max: ΔAIC = 10.3±2.5; Imperfect Max: ΔAIC = 15.6±2.6). The optimality index in this analysis is 0.797±0.026, which is nearly identical to the value we obtained in the analysis that included all trials (0.808±0.037). Indeed, a t-test provides moderate evidence for the null hypothesis that there is no difference (BF<sub>01</sub> = 3.58, <italic>p</italic> = .52). Altogether, our conclusions are largely the same under inclusion and exclusion of pop-out trials, which suggests that pop-out effects play a relatively minor role in explaining the identified suboptimalities.</p>
</sec>
<sec id="sec035">
<title>Reanalysis without a lapse rate</title>
<p>So far, we have included a lapse rate in all our models. To assess whether our conclusions would have been different if we had not included a lapse rate, we rerun all analyses with lapse rates fixed to 0. The model comparison results are very similar to the results reported above: in conditions with unlimited display time, the imperfect Max and Bayesian models are indistinguishable (ΔAIC = 1.29±0.95 in favor of Bayes) and all other models are strongly rejected (ΔAIC≥96±12); in conditions with short display time, the imperfect Bayesian is selected as the preferred model and all other models are again strongly rejected (ΔAIC≥32.2±4.4). However, the optimality indices are now slightly lower: <italic>I</italic> = 0.876±0.018 (13.3±1.8% deviation from optimality) in conditions with unlimited display time and <italic>I</italic> = 0.796±0.037 (20.4±3.7% deviation from optimality) in conditions with brief display time. This was to be expected, because errors that were explained as lapses in our original analysis can now only be explained by suboptimalities in the decision strategy. As before, a two-way Bayesian ANOVA suggests that there is no effect of the level of external uncertainty (BF<sub>inclusion</sub> = 0.167) nor of the level of internal uncertainty (BF<sub>inclusion</sub> = 0.842) on the optimality index. Altogether, we conclude that removing the lapse rate from the models does not significantly change our conclusions.</p>
</sec>
<sec id="sec036">
<title>Reanalysis without constraints on model parameters</title>
<p>Finally, we check what happens to the results when we remove the constraints on the parameters of the Bayesian models, by refitting Models 1–4 without prior distributions on parameters <italic>σ</italic><sub>low</sub>, <italic>σ</italic><sub>high</sub>, and <italic>λ</italic>. The model comparison result is again very similar to our previous results: in conditions with unlimited display time, the imperfect Max and Bayesian models are indistinguishable (ΔAIC = 1.4±1.1 in favor of Bayes) and all other models are strongly rejected (ΔAIC≥49.4±3.7); in conditions with short display time, the imperfect Bayesian model convincingly outperforms all other models, including the Max models (ΔAIC≥21.9±3.9). Also, we again find no evidence for an effect of the level of internal or external uncertainty on the optimality index (BF<sub>inclusion</sub> = 0.56 and 0.19, respectively). However, the estimated deviation from optimality is now 11.7±2.1%, which is substantially lower than the 18.1±2.2% that we found with constrained parameter fits. This was to be expected, because without parameter constraints, models may explain away some of the computational suboptimalities by overestimating the lapse rate and/or sensory noise levels. Indeed, the average estimated lapse rate is now 13.7±2.2%, compared to 3.7±1.1% in the constrained fits (BF<sub>+0</sub> = 582; <italic>p</italic> &lt;.001). For some subjects the estimated lapse rate is now even over 50%, which seems unrealistically high. Hence, it appears that lapse rates are overestimated in the unconstrained fit. The estimated sensory noise levels, on the other hand, are very similar to the estimates obtained with the constrained fitting method (<italic>σ</italic><sub>low</sub> = 6.58±0.55 <italic>vs</italic>. 6.75±0.54; <italic>σ</italic><sub>high</sub> = 2.67±0.38 <italic>vs</italic>. 3.35±0.37). Indeed, a t-test supports the hypothesis that there is no difference (BF<sub>01</sub> = 4.43; <italic>p</italic> = 0.44). We speculate that the richness of data from mixed-reliability experiments is itself a sufficient constraint on the parameter values, in particular when subjects use a decision strategy that is sensitive to reliability differences between stimuli.</p>
</sec>
<sec id="sec037">
<title>Comparison with a Bayesian sampling model</title>
<p>A summary of our results so far is presented in <xref ref-type="table" rid="pcbi.1006465.t004">Table 4</xref>. Taken together, these results strongly suggest that our experimental subjects used a strategy that resembles the Bayesian one, but with imperfections in its execution. While model identifiability problems (<xref ref-type="fig" rid="pcbi.1006465.g002">Fig 2</xref>) discouraged us from testing specific theories about the origin of such imperfections, there is one proposal that we believe is worth testing explicitly here, because it has some precedence in the literature. It has been argued that instead of performing exact Bayesian inference, humans may be drawing samples from the posterior distribution, which often is computationally cheaper and more tractable [<xref ref-type="bibr" rid="pcbi.1006465.ref049">49</xref>–<xref ref-type="bibr" rid="pcbi.1006465.ref054">54</xref>]. In the limit of an unlimited number of samples, Bayesian sampling is equivalent to exact Bayesian inference. However, for finite numbers of samples, Bayesian sampling leads to imperfections and biases in the observer’s decisions.</p>
<table-wrap id="pcbi.1006465.t004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006465.t004</object-id>
<label>Table 4</label> <caption><title>Summary of results.</title> <p>Models 2 and 10 are the Imperfect Bayesian and Imperfect Max models, respectively. Bayes factor BF<sub>inclusion</sub> indicates whether there is evidence for an effect of internal or external uncertainty on the optimality index. All Bayes factors are smaller than 1, indicating evidence <italic>against</italic> an effect.</p></caption>
<alternatives>
<graphic id="pcbi.1006465.t004g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.t004" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" rowspan="2"/>
<th align="center" colspan="2" style="border-right:thick">Preferred model(s)</th>
<th align="center" colspan="3" style="border-right:thick">Optimality index, <italic>I</italic></th>
<th align="center" colspan="2">Two-way ANOVA results on <italic>I</italic> (BF<sub>inclusion</sub>)</th>
</tr>
<tr>
<th align="center"><italic>t</italic> = ∞</th>
<th align="center" style="border-right:thick"><italic>t</italic> = 67ms</th>
<th align="center"><italic>t</italic> = ∞</th>
<th align="center"><italic>t</italic> = 67ms</th>
<th align="center" style="border-right:thick">All</th>
<th align="center">Internal uncertainty</th>
<th align="center">External uncertainty</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><bold>Main analysis</bold></td>
<td align="center">2, 10</td>
<td align="center" style="border-right:thick">2</td>
<td align="char" char=".">0.834</td>
<td align="char" char=".">0.808</td>
<td align="char" char="." style="border-right:thick">0.818</td>
<td align="char" char=".">0.200</td>
<td align="char" char=".">0.076</td>
</tr>
<tr>
<td align="center"><bold>No pop-out trials</bold></td>
<td align="center">2, 10</td>
<td align="center" style="border-right:thick">2</td>
<td align="char" char=".">0.827</td>
<td align="char" char=".">0.770</td>
<td align="char" char="." style="border-right:thick">0.794</td>
<td align="char" char=".">0.306</td>
<td align="char" char=".">0.134</td>
</tr>
<tr>
<td align="center"><bold>No lapse rate</bold></td>
<td align="center">2, 10</td>
<td align="center" style="border-right:thick">2</td>
<td align="char" char=".">0.867</td>
<td align="char" char=".">0.796</td>
<td align="char" char="." style="border-right:thick">0.827</td>
<td align="char" char=".">0.487</td>
<td align="char" char=".">0.191</td>
</tr>
<tr>
<td align="center"><bold>No parameter constraints</bold></td>
<td align="center">2, 10</td>
<td align="center" style="border-right:thick">2</td>
<td align="char" char=".">0.922</td>
<td align="char" char=".">0.854</td>
<td align="char" char="." style="border-right:thick">0.883</td>
<td align="char" char=".">0.565</td>
<td align="char" char=".">0.183</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>To test whether Bayesian sampling may explain the decision imperfections that we observed in our data, we implemented a variant of the Flawless Bayesian model in which <italic>d</italic>(<bold>x</bold>) is transformed into the posterior probabilities for “target presence” and “target absent” through <inline-formula id="pcbi.1006465.e025"><alternatives><graphic id="pcbi.1006465.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006465.e026"><alternatives><graphic id="pcbi.1006465.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006465.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>|</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. While the Flawless Bayesian reports “target present” whenever <italic>p</italic>(<italic>T</italic> = 1|<bold>x</bold>)&gt;<italic>p</italic>(<italic>T</italic> = 0|<bold>x</bold>), the Bayesian sampling model draws <italic>n</italic> samples from a Bernoulli distribution with a success rate equal to <italic>p</italic>(<italic>T</italic> = 1|<bold>x</bold>) and reports “target present” when the number of success samples exceeds the number of failures, where <italic>n</italic> is a free integer parameter. We find that the Bayesian sampling model convincingly outperforms the Flawless Bayesian (Model 1) with an AIC difference of 20.6±3.2. However, it does not account for the data as well as the Imperfect Bayesian (Model 2) does (ΔAIC = 20.3±8.4 in favor of the Imperfect Bayesian). Therefore, we conclude that while Bayesian sampling may explain some of the decision imperfections, it cannot explain all of it.</p>
</sec>
</sec>
<sec id="sec038" sec-type="conclusions">
<title>Discussion</title>
<p>In this study we re-examined optimality of human perception by using a standard visual search task. In contrast to previous claims that humans perform near-optimally on this task [<xref ref-type="bibr" rid="pcbi.1006465.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1006465.ref016">16</xref>], we found no support for the Flawless Bayesian model. More specifically, we estimated that empirical performance deviated on average 18.1% from optimal performance. Interestingly, the estimated magnitude of this deviation did not depend on the level of internal uncertainty, nor on the level of external uncertainty. This stability may be a sign that the estimates were accurate, which would mean that our method successfully dissociated computational sources of suboptimality from sensory sources. Our data are best described by a model that is based on Bayesian principles, but with imperfections in the implementation of these principles. We believe that such “Imperfect Bayesian” models can provide a fruitful middle ground in the debate between Bayesian and anti-Bayesian views on human perception.</p>
<sec id="sec039">
<title>Suboptimal behavior does not necessarily imply heuristic-based decision making</title>
<p>Deviations from optimality are often taken as evidence for heuristic decision making. However, this is not necessarily true: Bayesian observers can also be suboptimal. In particular, it has been argued that imprecisions in neural systems and the need to use deterministic approximations in complex computations may be the main reason why humans are unable to perform optimally on many tasks [<xref ref-type="bibr" rid="pcbi.1006465.ref027">27</xref>–<xref ref-type="bibr" rid="pcbi.1006465.ref031">31</xref>]. Such imperfections are orthogonal to the underlying decision strategy, because they may apply to both Bayesian and heuristic decision strategies. However, most previous work has only compared models with the optimal decision strategy against models with heuristic strategies, without testing for computational imprecisions. Claims of optimality made in those works are probably too strong, because evidence for a Bayesian decision strategy does not imply optimality. To avoid such overly strong claims, we advocate using a factorial modeling approach by crossing the decision strategy (Bayesian <italic>vs</italic>. heuristic-based strategies) with the absence or presence of computational imprecisions. Such an approach can decompose suboptimality into two different sources: using a fundamentally wrong decision strategy and having imperfections in the execution of this strategy. Only evidence for Bayesian decision-making without imprecisions should be considered as evidence for optimal behavior.</p>
</sec>
<sec id="sec040">
<title>Decomposing sources of suboptimality</title>
<p>It has recently been argued that instead of focusing on the binary question whether or not a particular behavior is optimal, it would be more fruitful to start building process models that precisely characterize the sources that make humans prone to errors [<xref ref-type="bibr" rid="pcbi.1006465.ref023">23</xref>]. The approach that we took here can be seen as a step in this direction, as it aims at distinguishing between different kinds of suboptimality and quantifying the amount of performance loss caused by each of them. A similar approach was recently developed by Drugowitsch and colleagues [<xref ref-type="bibr" rid="pcbi.1006465.ref027">27</xref>], who examined sources of suboptimality in a visual categorization task. They estimated that about 90% of the performance loss was caused by imprecisions in mental inference and the remaining 10% by stochasticity in sensory input and response selection. In our visual search task, we found a numerically similar contribution of computational imprecisions in the conditions with unlimited display time (92.6%). However, in the conditions with brief display time, we found that only about a third of the optimality loss was due to computational imprecisions. This can be understood by considering that sensory noise levels were probably higher in our experiment, due to a difference in stimulus presentation time (67 ms to encode four stimuli in our study <italic>vs</italic>. 333 ms per stimulus in the study by Drugowitsch et al.). We tried to further decompose suboptimalities into more specific sources, such as “noise in the computation of local decision variables”, “incorrect knowledge of the experimental parameters”, and “suboptimal cue weighting”. However, as demonstrated by the simulation results presented in <xref ref-type="fig" rid="pcbi.1006465.g002">Fig 2</xref>, different types of suboptimalities have near-identical effects on the response data, due to which we were unable to reliably distinguish between them using model comparison. Future studies may try to solve this model-identifiability problem by using experimental paradigms that provide a richer kind of behavioral data to further constrain the models (e.g., by collecting confidence ratings [<xref ref-type="bibr" rid="pcbi.1006465.ref055">55</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref056">56</xref>]). Moreover, we believe that it may be fruitful to further investigate the Bayesian sampling hypothesis as a possible source of suboptimality in our task. Although we found that Bayesian sampling alone cannot explain the observed decision imperfections, we did not test any models that combine sampling with other sources of suboptimality.</p>
</sec>
<sec id="sec041">
<title>The importance of using mixed reliability designs</title>
<p>While reliability-based cue weighting is an inherent property of Bayesian observers, heuristic models do not have a natural way of taking reliability into account. Therefore, within-display manipulation of stimulus reliability provides a strong tool to distinguish between the Bayesian model and heuristic-based models in model comparison. Indeed, we found that we were unable to distinguish between the Bayesian and Max models in conditions with fixed stimulus reliability, while the Max model was convincingly rejected in conditions with mixed reliabilities. These results strongly suggest that humans—just like Bayesians—take into account stimulus reliability during perceptual decision making. This finding is consistent with previous studies that have drawn a similar conclusion in the context of not only visual search [<xref ref-type="bibr" rid="pcbi.1006465.ref013">13</xref>], but also categorization [<xref ref-type="bibr" rid="pcbi.1006465.ref018">18</xref>], change detection [<xref ref-type="bibr" rid="pcbi.1006465.ref019">19</xref>], and same/different discrimination [<xref ref-type="bibr" rid="pcbi.1006465.ref021">21</xref>] tasks. However, unlike those previous studies, we do not interpret this finding as evidence for near-optimality, because we also found evidence for substantial suboptimalities that are seemingly caused by computational imperfections.</p>
</sec>
<sec id="sec042">
<title>Suboptimality in perceptual decision making</title>
<p>Although reports of optimality have dominated perceptual decision-making literature, we are certainly not the first to report evidence for suboptimalities. For example, numerous sensory cue combination studies have reported overweighting of one of the sensory cues [<xref ref-type="bibr" rid="pcbi.1006465.ref057">57</xref>–<xref ref-type="bibr" rid="pcbi.1006465.ref064">64</xref>]; Bhardwaj et al. [<xref ref-type="bibr" rid="pcbi.1006465.ref065">65</xref>] found that visual search performance is suboptimal when stimuli are correlated; Ackermann and Landy [<xref ref-type="bibr" rid="pcbi.1006465.ref066">66</xref>] reported that subjects fail to maximize reward in a visual search task with unequal rewards across target locations; and Qamar et al. [<xref ref-type="bibr" rid="pcbi.1006465.ref067">67</xref>] found that both humans and monkeys performed suboptimally in a relatively simple visual categorization task. However, none of those studies used the factorial modeling design that we proposed and, therefore, could not distinguish between suboptimalities due to a fundamentally wrong decision strategy and suboptimalities due to computational precisions.</p>
</sec>
<sec id="sec043">
<title>Late noise in models of perceptual decision making</title>
<p>An important aspect of our analysis is that we included models with “late noise” on the decision variable. We are not the first to do so. An example of our own previous work—in which we referred to it as “decision noise”—is the change detection study by Keshvari et al. [<xref ref-type="bibr" rid="pcbi.1006465.ref019">19</xref>], where we found that inclusion of late noise did not substantially improve the model fits. However, sensory noise levels in that study were fitted in an entirely unconstrained way, while it is conceivable that there was a trade-off between effects of noise on the decision variable and effects of sensory noise on model predictions. Moreover, in that study we assumed random variability in encoding precision, which a later study showed may be confounded with decision noise [<xref ref-type="bibr" rid="pcbi.1006465.ref068">68</xref>]. Therefore, it is possible that computational imperfections in the study by Keshvari et al. went unnoticed due to confounding them with sensory noise or variability in precision.</p>
<p>Another body of work that has considered noise on the decision variable are the studies by Summerfield and colleagues (e.g., [<xref ref-type="bibr" rid="pcbi.1006465.ref069">69</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref070">70</xref>]). They have shown that in the presence of late noise, subjects can—and often do—obtain performance benefits by using “robust averaging”, i.e., down-weighting outlier cues when computing the global decision variable. From an optimal-observer perspective, our task can also be conceived of as an averaging task, even though the averaging is over local posterior evidence values, (<xref ref-type="disp-formula" rid="pcbi.1006465.e008">Eq 2</xref>), rather than directly over stimulus values. We performed simulations to examine whether robust averaging also gives performance benefits in our task, but we did not find any evidence for this.</p>
<p>While late noise seems to be an important factor in explaining behavior on our visual search task, it seems to play no role in explaining behavior on classical cue combination tasks [<xref ref-type="bibr" rid="pcbi.1006465.ref012">12</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref063">63</xref>]. There are two differences between these tasks that may explain the difference in findings. First, subjects in our task had to combine four cues instead of two. Second, and perhaps more importantly, the optimal decision rule in our task is substantially more complex: while optimality on cue combination tasks can be achieved using only linear operations, our visual search task required non-linear computations, (<xref ref-type="disp-formula" rid="pcbi.1006465.e008">Eq 2</xref>). Previous work has suggested that information processing in the human brain proceeds mostly by linear additive integration (e.g., [<xref ref-type="bibr" rid="pcbi.1006465.ref071">71</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref072">72</xref>]), which would lead to suboptimalities if the optimal strategy requires non-linear computations. It would be interesting to investigate in future work whether subjects are perhaps using linear approximations to optimal decision rules in complex tasks such as visual search.</p>
</sec>
<sec id="sec044">
<title>The effect of external uncertainty on performance</title>
<p>A difference between most laboratory stimuli and naturalistic stimuli is that the former are typically deterministic, while the latter are often probabilistic [<xref ref-type="bibr" rid="pcbi.1006465.ref032">32</xref>]. In the present study, we mimicked the probabilistic character of naturalistic stimuli by adding external uncertainty. While we are not the first to do so in a perceptual decision-making task (e.g., [<xref ref-type="bibr" rid="pcbi.1006465.ref027">27</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref067">67</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref073">73</xref>,<xref ref-type="bibr" rid="pcbi.1006465.ref074">74</xref>]), we are unaware of any previous work that has systematically varied this level of uncertainty to them. Moreover, previous work did not examine the relation between the magnitude of the external uncertainty and the magnitude of deviations from optimality. None of our analyses provided evidence that external uncertainty affects how much performance deviates from optimality. This is somewhat surprising, because the stimulus distributions in our experiment were arbitrary and entirely novel to our subjects. It is worth noting, however, that this robustness of the degree of suboptimality under different stimulus conditions is similar to findings in an earlier study by Acerbi, Vijayakumar, and Wolpert [<xref ref-type="bibr" rid="pcbi.1006465.ref054">54</xref>]. A possible explanation could be that the brain may be familiar with Gaussian-like stimulus ambiguity and can therefore quickly incorporate novel kinds of external uncertainty, as long as it follows a Gaussian distribution. An interesting direction for future work would be to further investigate the relation between different types of external uncertainty and optimality in human decision making.</p>
</sec>
</sec>
<sec id="sec045">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006465.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.s001" xlink:type="simple">
<label>S1 Appendix</label>
<caption>
<title>Supplementary methods.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006465.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.s002" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Generative model for the visual search task.</title>
<p>Circles represent random variables, rectangles represent constants, and arrows represent causal relationships. Gray shades represent variables and constants that are under control of the experimenter. On each trial, <italic>N</italic> = 4 stimuli are presented to the observer. A target is either absent (<italic>T</italic> = 0) or present (<italic>T</italic> = 1) among these stimuli. Each location <italic>L</italic> ϵ {1, 2, …, <italic>N</italic>} has equal probability of containing the target on target-present trials. On target-absent trials, each stimulus orientation, <italic>s</italic><sub><italic>i</italic></sub>, is drawn from the distractor distribution, which is a Gaussian with a mean −<italic>μ</italic><sub>target</sub> and a standard deviation <italic>σ</italic><sub>external</sub>. On target-present trials, the stimulus at the target location is drawn from a Gaussian distribution with mean <italic>μ</italic><sub>target</sub> and standard deviation <italic>σ</italic><sub>external</sub>, while the remaining <italic>N</italic>−1 stimuli are drawn from the distractor distribution. We assume that stimulus observations are corrupted by Gaussian noise, such that each observation, <italic>x</italic><sub><italic>i</italic></sub>, is a Gaussian random variable with mean <italic>s</italic><sub><italic>i</italic></sub> and standard deviation <italic>σ</italic><sub><italic>i</italic></sub>.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006465.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.s003" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Model recovery results.</title>
<p>Ten synthetic datasets were generated from each model, by simulating its responses in trials from the condition with 10% external uncertainty. Each dataset had the same number of trials as a subject dataset. Parameter values were drawn from a multivariate Gaussian distribution with the same mean and covariance as the maximum-likelihood estimates obtained from fitting subject data. Hence, the synthetic datasets had the same size and similar statistics as empirical datasets. Each model was fitted to each of the 140 synthetic datasets. The matrix shows for each generating model the average AIC value (across all ten generated datasets from the model) relative to the best-fitting model. In each row, the overall best-fitting model is indicated with a red dot. In most cases, the generating model is the best-fitting model (red dots on diagonal) and most other models are rejected. There are a few wrong classifications (red dots off-diagonal), which indicates that some model pairs cannot reliably be distinguished from each other. Importantly, the model that was most successful in accounting for subject data—the Imperfect Bayesian model—never is selected as the preferred model when data were generated from another model. Hence, it is unlikely that the success of the Imperfect Bayesian model on empirical data was caused by it being overly flexible.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006465.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006465.s004" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Model comparison results based on five-fold cross validation.</title>
<p>Each individual dataset was fitted 5 times. In each of these fits, a different subset of 20% of the trials was left out. The log likelihood of these left out data were computed using the maximum-likelihood estimates obtained from fitting the other 80% of the data. We summed the 5 log likelihood obtained for each subject to compute a single “cross-validated log likelihood” (CVLL). (A) Results from fitting the conditions with unlimited display time. (B) Results from fitting the conditions with brief display time.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1006465.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>The Bayesian brain: The role of uncertainty in neural coding and computation</article-title>. <source>Trends in Neurosciences</source>. <year>2004</year>. pp. <fpage>712</fpage>–<lpage>719</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2004.10.007" xlink:type="simple">10.1016/j.tins.2004.10.007</ext-link></comment> <object-id pub-id-type="pmid">15541511</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref002"><label>2</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Richards</surname> <given-names>W</given-names></name>, editors. <source>Perception as Bayesian Inference</source>. <publisher-name>Cambridge University Press</publisher-name>; <year>1996</year>.</mixed-citation></ref>
<ref id="pcbi.1006465.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Organizing probabilistic models of perception</article-title>. <source>Trends Cogn Sci</source>. <year>2012</year>;<volume>16</volume>: <fpage>511</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2012.08.010" xlink:type="simple">10.1016/j.tics.2012.08.010</ext-link></comment> <object-id pub-id-type="pmid">22981359</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Geisler</surname> <given-names>WS</given-names></name>. <article-title>Contributions of ideal observer theory to vision research</article-title>. <source>Vision Research</source>. <year>2011</year>. pp. <fpage>771</fpage>–<lpage>781</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2010.09.027" xlink:type="simple">10.1016/j.visres.2010.09.027</ext-link></comment> <object-id pub-id-type="pmid">20920517</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Trommershäuser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Körding</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>. <article-title>Sensory Cue Integration</article-title>. <source>Sensory Cue Integration</source>. <year>2012</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/acprof:oso/9780195387247.001.0001" xlink:type="simple">10.1093/acprof:oso/9780195387247.001.0001</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>. <article-title>Ideal-Observer Models of Cue Integration</article-title>. <source>Sensory Cue Integration</source>. <year>2012</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/acprof:oso/9780195387247.003.0001" xlink:type="simple">10.1093/acprof:oso/9780195387247.003.0001</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>. <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title>. <source>Nature</source>. <year>2002</year>;<volume>415</volume>: <fpage>429</fpage>–<lpage>33</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/415429a" xlink:type="simple">10.1038/415429a</ext-link></comment> <object-id pub-id-type="pmid">11807554</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Beers</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Sittig</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Gon</surname> <given-names>JJ</given-names></name>. <article-title>Integration of proprioceptive and visual position-information: An experimentally supported model</article-title>. <source>J Neurophysiol</source>. <year>1999</year>;<volume>81</volume>: <fpage>1355</fpage>–<lpage>1364</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1999.81.3.1355" xlink:type="simple">10.1152/jn.1999.81.3.1355</ext-link></comment> <object-id pub-id-type="pmid">10085361</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alais</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Burr</surname> <given-names>D</given-names></name>. <article-title>The ventriloquist effect results from near-optimal bimodal integration</article-title>. <source>Curr Biol. Elsevier</source>; <year>2004</year>;<volume>14</volume>: <fpage>257</fpage>–<lpage>62</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2004.01.029" xlink:type="simple">10.1016/j.cub.2004.01.029</ext-link></comment> <object-id pub-id-type="pmid">14761661</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jacobs</surname> <given-names>RA</given-names></name>. <article-title>Optimal integration of texture and motion cues to depth</article-title>. <source>Vision Res</source>. <year>1999</year>;<volume>39</volume>: <fpage>3621</fpage>–<lpage>3629</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0042-6989(99)00088-7" xlink:type="simple">10.1016/S0042-6989(99)00088-7</ext-link></comment> <object-id pub-id-type="pmid">10746132</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Maloney</surname> <given-names>LT</given-names></name>, <name name-style="western"><surname>Johnston</surname> <given-names>EB</given-names></name>, <name name-style="western"><surname>Young</surname> <given-names>M</given-names></name>. <article-title>Measurement and modeling of depth cue combination: in defense of weak fusion</article-title>. <source>Vision Res</source>. <year>1995</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0042-6989(94)00176-M" xlink:type="simple">10.1016/0042-6989(94)00176-M</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hillis</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Watt</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>. <article-title>Slant from texture and disparity cues: Optimal cue combination</article-title>. <source>J Vis</source>. <year>2004</year>;<volume>4</volume>: <fpage>1</fpage>.</mixed-citation></ref>
<ref id="pcbi.1006465.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Navalpakkam</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Berg van den</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Behavior and neural basis of near-optimal visual search</article-title>. <source>Nat Neurosci</source>. <year>2011</year>;<volume>14</volume>: <fpage>783</fpage>–<lpage>790</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2814" xlink:type="simple">10.1038/nn.2814</ext-link></comment> <object-id pub-id-type="pmid">21552276</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vincent</surname> <given-names>BT</given-names></name>, <name name-style="western"><surname>Baddeley</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Troscianko</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Gilchrist</surname> <given-names>ID</given-names></name>. <article-title>Optimal feature integration in visual search</article-title>. <source>J Vis</source>. <year>2009</year>;<volume>9</volume>: <fpage>15.1</fpage>–<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/9.5.15" xlink:type="simple">10.1167/9.5.15</ext-link></comment> <object-id pub-id-type="pmid">19757893</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mazyar</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>van den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Does precision decrease with set size?</article-title> <source>J Vis</source>. <year>2012</year>;<volume>12</volume>: <fpage>10</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/12.6.10" xlink:type="simple">10.1167/12.6.10</ext-link></comment> <object-id pub-id-type="pmid">22685337</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palmer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Verghese</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Pavel</surname> <given-names>M</given-names></name>. <article-title>The psychophysics of visual search</article-title>. <source>Vision Research</source>. <year>2000</year>. pp. <fpage>1227</fpage>–<lpage>1268</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0042-6989(99)00244-8" xlink:type="simple">10.1016/S0042-6989(99)00244-8</ext-link></comment> <object-id pub-id-type="pmid">10788638</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Navalpakkam</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Perona</surname> <given-names>P</given-names></name>. <article-title>Homo economicus in visual search</article-title>. <source>J Vis</source>. <year>2009</year>;<volume>9</volume>(<issue>1</issue>): <fpage>1</fpage>–<lpage>16</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006465.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shen</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>A detailed comparison of optimality and simplicity in perceptual decision making</article-title>. <source>Psychol Rev</source>. <year>2016</year>;<volume>123</volume>: <fpage>452</fpage>–<lpage>480</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/rev0000028" xlink:type="simple">10.1037/rev0000028</ext-link></comment> <object-id pub-id-type="pmid">27177259</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Keshvari</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>van den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Probabilistic computation in human perception under variability in encoding precision</article-title>. <source>PLoS One</source>. <year>2012</year>;<volume>7</volume>.</mixed-citation></ref>
<ref id="pcbi.1006465.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Shin</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Chou</surname> <given-names>W-C</given-names></name>, <name name-style="western"><surname>George</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Variability in encoding precision accounts for visual short-term memory limitations</article-title>. <source>Proc Natl Acad Sci</source>. <year>2012</year>;<volume>109</volume>: <fpage>8780</fpage>–<lpage>8785</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1117465109" xlink:type="simple">10.1073/pnas.1117465109</ext-link></comment> <object-id pub-id-type="pmid">22582168</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Vogel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Josic</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJJ</given-names></name>, <name name-style="western"><surname>Josić</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJJ</given-names></name>. <article-title>Optimal inference of sameness</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2012</year>;<volume>109</volume>: <fpage>3178</fpage>–<lpage>83</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1108790109" xlink:type="simple">10.1073/pnas.1108790109</ext-link></comment> <object-id pub-id-type="pmid">22315400</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rosas</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wichmann</surname> <given-names>FA</given-names></name>. <article-title>Cue Combination: Beyond Optimality</article-title>. <source>Sensory Cue Integration</source>. <year>2012</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/acprof:oso/9780195387247.003.0008" xlink:type="simple">10.1093/acprof:oso/9780195387247.003.0008</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rahnev</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Denison</surname> <given-names>RN</given-names></name>. <article-title>Suboptimality in Perceptual Decision Making</article-title>. <source>Behavioral and Brain Sciences</source>. <year>2018</year>: <fpage>1</fpage>–<lpage>107</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1017/S0140525X18000936" xlink:type="simple">10.1017/S0140525X18000936</ext-link></comment> <object-id pub-id-type="pmid">29485020</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jones</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Love</surname> <given-names>BC</given-names></name>. <article-title>Bayesian Fundamentalism or Enlightenment? On the explanatory status and theoretical contributions of Bayesian models of cognition</article-title>. <source>Behav Brain Sci. Cambridge University Press</source>; <year>2011</year>;<volume>34</volume>: <fpage>169</fpage>–<lpage>88</lpage>; disuccsion 188–231. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1017/S0140525X10003134" xlink:type="simple">10.1017/S0140525X10003134</ext-link></comment> <object-id pub-id-type="pmid">21864419</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bowers</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>CJ</given-names></name>. <article-title>Bayesian just-so stories in psychology and neuroscience</article-title>. <source>Psychol Bull</source>. <year>2012</year>;<volume>138</volume>: <fpage>389</fpage>–<lpage>414</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0026450" xlink:type="simple">10.1037/a0026450</ext-link></comment> <object-id pub-id-type="pmid">22545686</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marcus</surname> <given-names>GF</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>E</given-names></name>. <article-title>How Robust Are Probabilistic Models of Higher-Level Cognition?</article-title> <source>Psychol Sci</source>. <year>2013</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797613495418" xlink:type="simple">10.1177/0956797613495418</ext-link></comment> <object-id pub-id-type="pmid">24084039</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Drugowitsch</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wyart</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Devauchelle</surname> <given-names>A-DD</given-names></name>, <name name-style="western"><surname>Koechlin</surname> <given-names>E</given-names></name>. <article-title>Computational Precision of Mental Inference as Critical Source of Human Choice Suboptimality</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>92</volume>: <fpage>1398</fpage>–<lpage>1411</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2016.11.005" xlink:type="simple">10.1016/j.neuron.2016.11.005</ext-link></comment> <object-id pub-id-type="pmid">27916454</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Pitkow</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Not Noisy, Just Wrong: The Role of Suboptimal Inference in Behavioral Variability</article-title>. <source>Neuron</source>. <year>2012</year>. pp. <fpage>30</fpage>–<lpage>39</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2012.03.016" xlink:type="simple">10.1016/j.neuron.2012.03.016</ext-link></comment> <object-id pub-id-type="pmid">22500627</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Faisal</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Selen</surname> <given-names>LPJ</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>. <article-title>Noise in the nervous system</article-title>. <source>Nat Rev Neurosci</source>. <year>2008</year>;<volume>9</volume>: <fpage>292</fpage>–<lpage>303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn2258" xlink:type="simple">10.1038/nrn2258</ext-link></comment> <object-id pub-id-type="pmid">18319728</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Renart</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Machens</surname> <given-names>CK</given-names></name>. <article-title>Variability in neural activity and behavior</article-title>. <source>Current Opinion in Neurobiology</source>. <year>2014</year>. pp. <fpage>211</fpage>–<lpage>220</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2014.02.013" xlink:type="simple">10.1016/j.conb.2014.02.013</ext-link></comment> <object-id pub-id-type="pmid">24632334</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wyart</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Koechlin</surname> <given-names>E</given-names></name>. <article-title>Choice variability and suboptimality in uncertain environments</article-title>. <source>Current Opinion in Behavioral Sciences</source>. <year>2016</year>. pp. <fpage>109</fpage>–<lpage>115</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cobeha.2016.07.003" xlink:type="simple">10.1016/j.cobeha.2016.07.003</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Juslin</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Olsson</surname> <given-names>H</given-names></name>. <article-title>Thurstonian and Brunswikian origins of uncertainty in judgment: a sampling model of confidence in sensory discrimination</article-title>. <source>Psychol Rev</source>. <year>1997</year>;<volume>104</volume>: <fpage>344</fpage>–<lpage>366</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.104.2.344" xlink:type="simple">10.1037/0033-295X.104.2.344</ext-link></comment> <object-id pub-id-type="pmid">9162950</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Voskuilen</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>McKoon</surname> <given-names>G</given-names></name>. <article-title>Internal and external sources of variability in perceptual decision-making</article-title>. <source>Psychol Rev</source>. <year>2018</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/rev0000080" xlink:type="simple">10.1037/rev0000080</ext-link></comment> <object-id pub-id-type="pmid">29035076</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brainard</surname> <given-names>DH</given-names></name>. <article-title>The Psychophysics Toolbox</article-title>. <source>Spat Vis</source>. <year>1997</year>;<volume>10</volume>: <fpage>433</fpage>–<lpage>436</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1163/156856897X00357" xlink:type="simple">10.1163/156856897X00357</ext-link></comment> <object-id pub-id-type="pmid">9176952</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref035"><label>35</label><mixed-citation publication-type="other" xlink:type="simple">JASP Team. JASP (Version 0.8.4.0) [Computer program]. 2018.</mixed-citation></ref>
<ref id="pcbi.1006465.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Green</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Swets</surname> <given-names>JA</given-names></name>. <article-title>Signal detection theory and psychophysics</article-title>. <source>Society</source>. <year>1966</year>;<volume>1</volume>: <fpage>521</fpage>.</mixed-citation></ref>
<ref id="pcbi.1006465.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koopman</surname> <given-names>BO</given-names></name>. <article-title>The theory of search—II. target detection</article-title>. <source>J Oper Res</source>. <year>1956</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1287/opre.4.5.503" xlink:type="simple">10.1287/opre.4.5.503</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pelli</surname> <given-names>DG</given-names></name>. <article-title>Uncertainty explains many aspects of visual contrast detection and discrimination</article-title>. <source>J Opt Soc Am A</source>. <year>1985</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1364/JOSAA.2.001508" xlink:type="simple">10.1364/JOSAA.2.001508</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Swensson</surname> <given-names>RG</given-names></name>, <name name-style="western"><surname>Judy</surname> <given-names>PF</given-names></name>. <article-title>Detection of noisy visual targets: Models for the effects of spatial uncertainty and signal-to-noise ratio</article-title>. <source>Percept Psychophys</source>. <year>1981</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03207369" xlink:type="simple">10.3758/BF03207369</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alvarez</surname> <given-names>GA</given-names></name>, <name name-style="western"><surname>Oliva</surname> <given-names>A</given-names></name>. <article-title>The representation of simple ensemble visual features outside the focus of attention</article-title>. <source>Psychol Sci</source>. <year>2008</year>;<volume>19</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1467-9280.2008.02098.x" xlink:type="simple">10.1111/j.1467-9280.2008.02098.x</ext-link></comment> <object-id pub-id-type="pmid">18399893</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref041"><label>41</label><mixed-citation publication-type="other" xlink:type="simple">Rosenholtz R. What your visual system sees where you are not looking. SPIE: Human Vision and Electronic Imaging XVI. 2011.</mixed-citation></ref>
<ref id="pcbi.1006465.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Parkes</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Lund</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Angelucci</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Solomon</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Morgan</surname> <given-names>M</given-names></name>. <article-title>Compulsory averaging of crowded orientation signals in human vision</article-title>. <source>Nat Neurosci</source>. <year>2001</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/89532" xlink:type="simple">10.1038/89532</ext-link></comment> <object-id pub-id-type="pmid">11426231</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search</article-title>. <source>Advances in Neural Information Processing Systems 30</source>. <year>2017</year>. pp. <fpage>1836</fpage>–<lpage>1846</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/150052" xlink:type="simple">https://doi.org/10.1101/150052</ext-link></mixed-citation></ref>
<ref id="pcbi.1006465.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Akaike</surname> <given-names>H</given-names></name>. <article-title>A new look at the statistical model identification</article-title>. <source>IEEE Trans Automat Contr</source>. <year>1974</year>;<volume>19</volume>: <fpage>716</fpage>–<lpage>723</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TAC.1974.1100705" xlink:type="simple">10.1109/TAC.1974.1100705</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burnham</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>DR</given-names></name>. <article-title>Multimodel inference: Understanding AIC and BIC in model selection</article-title>. <source>Sociological Methods and Research</source>. <year>2004</year>. pp. <fpage>261</fpage>–<lpage>304</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0049124104268644" xlink:type="simple">10.1177/0049124104268644</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wyart</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Koechlin</surname> <given-names>E</given-names></name>. <article-title>The Importance of Falsification in Computational Cognitive Modeling</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2017</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2017.03.011" xlink:type="simple">10.1016/j.tics.2017.03.011</ext-link></comment> <object-id pub-id-type="pmid">28476348</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cameron</surname> <given-names>EL</given-names></name>, <name name-style="western"><surname>Tai</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name>. <article-title>Covert attention affects the psychometric function of contrast sensitivity</article-title>. <source>Vision Res</source>. <year>2002</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0042-6989(02)00039-1" xlink:type="simple">10.1016/S0042-6989(02)00039-1</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Shen</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Dziugaite</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>van den Berg</surname> <given-names>R</given-names></name>. <article-title>Requiem for the max rule?</article-title> <source>Vision Res</source>. <year>2015</year>;<volume>116</volume>: <fpage>179</fpage>–<lpage>193</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2014.12.019" xlink:type="simple">10.1016/j.visres.2014.12.019</ext-link></comment> <object-id pub-id-type="pmid">25584425</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sanborn</surname> <given-names>AN</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>. <article-title>Bayesian Brains without Probabilities</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2016</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2016.10.003" xlink:type="simple">10.1016/j.tics.2016.10.003</ext-link></comment> <object-id pub-id-type="pmid">28327290</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vul</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Goodman</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Griffiths</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Tenenbaum</surname> <given-names>JB</given-names></name>. <article-title>One and done? Optimal decisions from very few samples</article-title>. <source>Cogn Sci</source>. <year>2014</year>;<volume>38</volume>: <fpage>599</fpage>–<lpage>637</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/cogs.12101" xlink:type="simple">10.1111/cogs.12101</ext-link></comment> <object-id pub-id-type="pmid">24467492</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vul</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Pashler</surname> <given-names>H</given-names></name>. <article-title>Measuring the crowd within: Probabilistic representations within individuals: Short report</article-title>. <source>Psychol Sci</source>. <year>2008</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1467-9280.2008.02136.x" xlink:type="simple">10.1111/j.1467-9280.2008.02136.x</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fiser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Berkes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Orbán</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Statistically optimal perception and learning: from behavior to neural representations</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2010</year>. pp. <fpage>119</fpage>–<lpage>130</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2010.01.003" xlink:type="simple">10.1016/j.tics.2010.01.003</ext-link></comment> <object-id pub-id-type="pmid">20153683</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sundareswara</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Schrater</surname> <given-names>PR</given-names></name>. <article-title>Perceptual multistability predicted by search model for Bayesian decisions</article-title>. <source>J Vis</source>. <year>2008</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/8.5.12" xlink:type="simple">10.1167/8.5.12</ext-link></comment> <object-id pub-id-type="pmid">18842083</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Vijayakumar</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>. <article-title>On the Origins of Suboptimality in Human Probabilistic Inference</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003661" xlink:type="simple">10.1371/journal.pcbi.1003661</ext-link></comment> <object-id pub-id-type="pmid">24945142</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cabrera</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Lu</surname> <given-names>ZL</given-names></name>, <name name-style="western"><surname>Dosher</surname> <given-names>BA</given-names></name>. <article-title>Separating decision and encoding noise in signal detection tasks</article-title>. <source>Psychol Rev</source>. <year>2015</year>;<volume>122</volume>: <fpage>429</fpage>–<lpage>460</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0039348" xlink:type="simple">10.1037/a0039348</ext-link></comment> <object-id pub-id-type="pmid">26120907</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adler</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Comparing Bayesian and non-Bayesian accounts of human confidence reports</article-title>. <source>PLoS Comput Biol</source>. <year>2018</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1006572" xlink:type="simple">10.1371/journal.pcbi.1006572</ext-link></comment> <object-id pub-id-type="pmid">30422974</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Battaglia</surname> <given-names>PW</given-names></name>, <name name-style="western"><surname>Jacobs</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Aslin</surname> <given-names>RN</given-names></name>. <article-title>Bayesian integration of visual and auditory signals for spatial localization</article-title>. <source>J Opt Soc Am A</source>. <year>2003</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1364/JOSAA.20.001391" xlink:type="simple">10.1364/JOSAA.20.001391</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burr</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Morrone</surname> <given-names>MC</given-names></name>. <article-title>Auditory dominance over vision in the perception of interval duration</article-title>. <source>Exp Brain Res</source>. <year>2009</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00221-009-1933-z" xlink:type="simple">10.1007/s00221-009-1933-z</ext-link></comment> <object-id pub-id-type="pmid">19597804</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maiworm</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Röder</surname> <given-names>B</given-names></name>. <article-title>Suboptimal auditory dominance in audiovisual integration of temporal cues</article-title>. <source>Tsinghua Sci Technol</source>. <year>2011</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S1007-0214(11)70019-0" xlink:type="simple">10.1016/S1007-0214(11)70019-0</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fetsch</surname> <given-names>CR</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Deangelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>. <article-title>Neural correlates of reliability-based cue weighting during multisensory integration</article-title>. <source>Nat Neurosci</source>. <year>2012</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2983" xlink:type="simple">10.1038/nn.2983</ext-link></comment> <object-id pub-id-type="pmid">22101645</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Prsa</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gale</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Blanke</surname> <given-names>O</given-names></name>. <article-title>Self-motion leads to mandatory cue fusion across sensory modalities</article-title>. <source>J Neurophysiol</source>. <year>2012</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00439.2012" xlink:type="simple">10.1152/jn.00439.2012</ext-link></comment> <object-id pub-id-type="pmid">22832567</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Battaglia</surname> <given-names>PW</given-names></name>, <name name-style="western"><surname>Kersten</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Schrater</surname> <given-names>PR</given-names></name>. <article-title>How haptic size sensations improve distance perception</article-title>. <source>PLoS Comput Biol</source>. <year>2011</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002080" xlink:type="simple">10.1371/journal.pcbi.1002080</ext-link></comment> <object-id pub-id-type="pmid">21738457</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Saunders</surname> <given-names>JA</given-names></name>. <article-title>Do humans optimally integrate stereo and texture information for judgments of surface slant?</article-title> <source>Vision Res</source>. <year>2003</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0042-6989(03)00458-9" xlink:type="simple">10.1016/S0042-6989(03)00458-9</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rosas</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wichmann</surname> <given-names>FA</given-names></name>, <name name-style="western"><surname>Wagemans</surname> <given-names>J</given-names></name>. <article-title>Texture and object motion in slant discrimination: failure of reliability-based weighting of cues may be evidence for strong fusion</article-title>. <source>J Vis</source>. <year>2007</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/7.6.3" xlink:type="simple">10.1167/7.6.3</ext-link></comment> <object-id pub-id-type="pmid">17685786</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bhardwaj</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Van Den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Josic</surname> <given-names>K</given-names></name>. <article-title>Do people take stimulus correlations into account in visual search?</article-title> <source>PLoS One</source>. <year>2016</year>;<volume>11</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0149402" xlink:type="simple">10.1371/journal.pone.0149402</ext-link></comment> <object-id pub-id-type="pmid">26963498</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ackermann</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>. <article-title>Suboptimal decision criteria are predicted by subjectively weighted probabilities and rewards</article-title>. <source>Attention, Perception, Psychophys</source>. <year>2015</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13414-014-0779-z" xlink:type="simple">10.3758/s13414-014-0779-z</ext-link></comment> <object-id pub-id-type="pmid">25366822</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Qamar</surname> <given-names>AT</given-names></name>, <name name-style="western"><surname>Cotton</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>George</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Prezhdo</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Laudano</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Trial-to-trial, uncertainty-based adjustment of decision boundaries in visual categorization</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2013</year>;<volume>110</volume>: <fpage>20332</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1219756110" xlink:type="simple">10.1073/pnas.1219756110</ext-link></comment> <object-id pub-id-type="pmid">24272938</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shen</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Variable precision in visual perception</article-title>. <source>bioRxiv</source>. <year>2018</year>; 153650. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/153650" xlink:type="simple">10.1101/153650</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Gardelle</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Summer</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>de Gardelle</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Summerfield</surname> <given-names>C</given-names></name>. <article-title>Robust averaging during perceptual judgment</article-title>. <source>Proc Natl Acad Sci</source>. <year>2011</year>;<volume>108</volume>: <fpage>13341</fpage>–<lpage>13346</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1104517108" xlink:type="simple">10.1073/pnas.1104517108</ext-link></comment> <object-id pub-id-type="pmid">21788517</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Herce Castañón</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Solomon</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Vandormael</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Summerfield</surname> <given-names>C</given-names></name>. <article-title>Robust averaging protects decisions from noise in neural computations</article-title>. <source>PLoS Comput Biol</source>. <year>2017</year>;<volume>13</volume>: <fpage>e1005723</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005723" xlink:type="simple">10.1371/journal.pcbi.1005723</ext-link></comment> <object-id pub-id-type="pmid">28841644</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Juslin</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Nilsson</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Winman</surname> <given-names>A</given-names></name>. <article-title>Probability theory, not the very guide of life</article-title>. <source>Psychol Rev</source>. <year>2009</year>;<volume>116</volume>: <fpage>856</fpage>–<lpage>874</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0016979" xlink:type="simple">10.1037/a0016979</ext-link></comment> <object-id pub-id-type="pmid">19839686</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shanteau</surname> <given-names>JC</given-names></name>. <article-title>An additive model for sequential decision making</article-title>. <source>J Exp Psychol</source>. <year>1970</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0029552" xlink:type="simple">10.1037/h0029552</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006465.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baldassi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Verghese</surname> <given-names>P</given-names></name>. <article-title>Comparing integration rules in visual search</article-title>. <source>J Vis</source>. <year>2002</year>;<volume>2</volume>: <fpage>3</fpage>–<lpage>3</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/2.8.3" xlink:type="simple">10.1167/2.8.3</ext-link></comment> <object-id pub-id-type="pmid">12678639</object-id></mixed-citation></ref>
<ref id="pcbi.1006465.ref074"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mazyar</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Van den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Seilheimer</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Independence is elusive: Set size effects on encoding precision in visual search</article-title>. <source>J Vis</source>. <year>2013</year>;<volume>13</volume>: <fpage>1</fpage>–<lpage>14</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article article-type="other" dtd-version="3.0" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.1002331</article-id>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-15-02112</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Meta-Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Where Have All the Rodents Gone? The Effects of Attrition in Experimental Research on Cancer and Stroke</article-title>
<alt-title alt-title-type="running-head">Attrition in Experimental Biomedical Research</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Holman</surname>
<given-names>Constance</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Piper</surname>
<given-names>Sophie K.</given-names>
</name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Grittner</surname>
<given-names>Ulrike</given-names>
</name>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Diamantaras</surname>
<given-names>Andreas Antonios</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Kimmelman</surname>
<given-names>Jonathan</given-names>
</name>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Siegerink</surname>
<given-names>Bob</given-names>
</name>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Dirnagl</surname>
<given-names>Ulrich</given-names>
</name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff006"><sup>6</sup></xref>
<xref ref-type="aff" rid="aff007"><sup>7</sup></xref>
<xref ref-type="aff" rid="aff008"><sup>8</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Medical Neurosciences Program, Charité Universitätsmedizin Berlin, Berlin, Germany</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>NeuroCure Clinical Research Center, Charité Universitätsmedizin Berlin, Berlin, Germany</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Center for Stroke Research, Charité Universitätsmedizin Berlin, Berlin, Germany</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Department for Biostatistics and Clinical Epidemiology, Charité Universitätsmedizin Berlin, Berlin, Germany</addr-line></aff>
<aff id="aff005"><label>5</label> <addr-line>Biomedical Ethics Unit, McGill University, Montréal, Canada</addr-line></aff>
<aff id="aff006"><label>6</label> <addr-line>Department of Experimental Neurology, Charité Universitätsmedizin Berlin, Berlin, Germany</addr-line></aff>
<aff id="aff007"><label>7</label> <addr-line>German Center for Neurodegenerative Diseases (DZNE), Berlin, Germany</addr-line></aff>
<aff id="aff008"><label>8</label> <addr-line>Berlin Institute of Health, Berlin, Germany</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: CH SKP UG AAD JK BS UD. Performed the experiments: CH AAD SKP UG BS. Analyzed the data: CH AAD SKP UG BS. Wrote the paper: CH SKP UG AAD JK BS UD.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">ulrich.dirnagl@charite.de</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>4</day>
<month>1</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<month>1</month>
<year>2016</year>
</pub-date>
<volume>14</volume>
<issue>1</issue>
<elocation-id>e1002331</elocation-id>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Holman et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.1002331"/>
<related-article ext-link-type="uri" id="related001" related-article-type="companion" xlink:href="info:doi/10.1371/journal.pbio.1002333" xlink:type="simple">
<article-title>Reproducible Research Practices and Transparency across the Biomedical Literature</article-title>
</related-article>
<related-article ext-link-type="uri" id="related002" related-article-type="companion" xlink:href="info:doi/10.1371/journal.pbio.1002334" xlink:type="simple">
<article-title>Meta-Research: Broadening the Scope of <italic>PLOS Biology</italic></article-title>
</related-article>
<abstract>
<p>Given small sample sizes, loss of animals in preclinical experiments can dramatically alter results. However, effects of attrition on distortion of results are unknown. We used a simulation study to analyze the effects of random and biased attrition. As expected, random loss of samples decreased statistical power, but biased removal, including that of outliers, dramatically increased probability of false positive results. Next, we performed a meta-analysis of animal reporting and attrition in stroke and cancer. Most papers did not adequately report attrition, and extrapolating from the results of the simulation data, we suggest that their effect sizes were likely overestimated.</p>
</abstract>
<abstract abstract-type="toc">
<p>Using a combination of simulation and meta-analysis of stroke and cancer studies, this article highlights the potentially seriously misleading consequences of failing to report the loss of animals in preclinical studies.</p>
</abstract>
<funding-group>
<funding-statement>UG was supported by Charité and the Steinbeis Foundation. UD and BS would like to acknowledge the financial support of the German Federal Ministry of Education and Research (BMBF 01 EO 08 01). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="4"/>
<table-count count="0"/>
<page-count count="12"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data for this project are available from Figshare using the following DOIs: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.6084/m9.figshare.1448747" xlink:type="simple">http://dx.doi.org/10.6084/m9.figshare.1448747</ext-link>; <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.6084/m9.figshare.1448748" xlink:type="simple">http://dx.doi.org/10.6084/m9.figshare.1448748</ext-link>; <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.6084/m9.figshare.1448749" xlink:type="simple">http://dx.doi.org/10.6084/m9.figshare.1448749</ext-link>; <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.6084/m9.figshare.1448750" xlink:type="simple">http://dx.doi.org/10.6084/m9.figshare.1448750</ext-link>; <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.6084/m9.figshare.1448751" xlink:type="simple">http://dx.doi.org/10.6084/m9.figshare.1448751</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<disp-quote>
<p><italic>Where have all the rodents gone</italic>?</p>
<p><italic>Ooh ooh</italic>, <italic>ooh ooh</italic>, <italic>ooh</italic></p>
<p><italic>To non-random attrition</italic>, <italic>every one</italic></p>
<p><italic>When will they ever learn</italic>?</p>
<p>—with apologies to Pete Seeger, 1955</p>
</disp-quote>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Research systems worldwide spend billions of dollars every year on developing new drugs [<xref ref-type="bibr" rid="pbio.1002331.ref001">1</xref>], yet failure to translate laboratory findings into clinical applications has driven many to question the robustness and predictive value of preclinical research [<xref ref-type="bibr" rid="pbio.1002331.ref002">2</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref003">3</xref>]. Much of this criticism centers on selection of animal models, internal validity [<xref ref-type="bibr" rid="pbio.1002331.ref004">4</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref005">5</xref>], statistical power [<xref ref-type="bibr" rid="pbio.1002331.ref006">6</xref>–<xref ref-type="bibr" rid="pbio.1002331.ref008">8</xref>], reporting, and publication bias [<xref ref-type="bibr" rid="pbio.1002331.ref003">3</xref>].</p>
<p>An essential element of the reporting of any preclinical study is the number of samples. These numbers are essential for assessing the statistical power and robustness of results, as well as for including the studies in systematic reviews [<xref ref-type="bibr" rid="pbio.1002331.ref009">9</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref010">10</xref>]. If done properly, the reporting of animal numbers provides a full account of all animals lost during the experiment. Attrition not only diminishes statistical power but may also represent a nexus for other forms as bias. For example, non-blinded allocation or outcome assessment allows unwanted data to be identified and excluded via reporting bias. Furthermore, in some studies, attrition from the treatment group may be indicative of side effects or toxicity of new treatments. Unreported loss of these animals, therefore, is a potentially harmful form of selection bias.</p>
<p>In clinical research, several meta-analyses show that patient attrition can introduce a form of selection bias that favors positive outcomes [<xref ref-type="bibr" rid="pbio.1002331.ref011">11</xref>–<xref ref-type="bibr" rid="pbio.1002331.ref013">13</xref>]. To understand the effects of this bias, full disclosure of missing data is needed. Reporting standards, such as the Consolidated Standards of Reporting Trials (CONSORT) and Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) guidelines, require reporting of all dropouts over the course of a study [<xref ref-type="bibr" rid="pbio.1002331.ref014">14</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref015">15</xref>]. While there are many ongoing attempts to align preclinical research with clinical reporting standards [<xref ref-type="bibr" rid="pbio.1002331.ref016">16</xref>–<xref ref-type="bibr" rid="pbio.1002331.ref018">18</xref>], compliance with these guidelines is poor [<xref ref-type="bibr" rid="pbio.1002331.ref019">19</xref>]. Despite the probable effect of attrition on power in small animal studies [<xref ref-type="bibr" rid="pbio.1002331.ref020">20</xref>], its extent and the consequences of attrition in animal research have not, to our knowledge, been studied.</p>
<p>In this study, we set out to demonstrate the consequences and prevalence of attrition in preclinical research. First, we used simulated data and compared the results with and without animal loss. We focused on two kinds of attrition: random loss and biased removal. Here, we investigated the potential impact of animal attrition on detection of clinical promise by examining the probability of false positives and negatives and whether effect size became inflated. Second, we used meta-analytic methods on a sample of preclinical stroke and cancer studies to assess the prevalence of attrition reporting and to determine whether attrition was associated with reported effect size.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Simulation Studies</title>
<p>To explore the effects of attrition in preclinical studies, we simulated data for a two-armed trial (e.g., treatment versus control) beginning with a sample size of eight animals per group, a typical size reported in preclinical research [<xref ref-type="bibr" rid="pbio.1002331.ref021">21</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref022">22</xref>]. We used scenarios with different true standardized effect sizes: d = 0 (no true difference between groups), d = 0.875 (a common preclinical reported effect size, [<xref ref-type="bibr" rid="pbio.1002331.ref022">22</xref>]) and d = 1.5 (a strong effect for which 8 versus 8 is adequately powered). We simulated two forms of attrition: random loss (i.e., elimination of animals irrespective of group or outcome value) and biased removal (i.e., elimination of animal data points that undermine the expected effect). Biased removal of samples maximized the difference between experimental groups, irrespective of group membership (treatment versus control). Figs <xref ref-type="fig" rid="pbio.1002331.g001">1</xref> and <xref ref-type="fig" rid="pbio.1002331.g002">2</xref> show the probability of declaring statistically significant differences between simulation group means. The level of attrition in both treatment groups is stated as “8 + 8” without attrition and “7 + 8” to “6 + 7” as the total number of animals used decreases from left to right.</p>
<fig id="pbio.1002331.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002331.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Simulation results for random and non-random attrition.</title>
<p>Column 1 + 2: rows represent the results of a different effect size (Cohen’s d) scenario, indicated left. The level of attrition in either treatment group is stated (left to right) as “8 + 8” without attrition and “7 + 8” to “6 + 7” with the total number of missing animals increasing from one to three. Column 1 + 2: probability of positive trials after random loss (first column) or non-random attrition of extremes that are not in favor of the effect (second column) for different effect sizes (rows 1–3). Colors represent the proportion of trials out of 10,000 simulations that are significant (1) independent of attrition (orange) or significant (2) only in the case of attrition (red), non-significant (1) independent of attrition (cyan), or non-significant (2) only in the case of attrition (dark blue). Column 3: ratio of type 1 error rates (falsely accepting the alternative (H<sub>1</sub>) hypothesis if there is no true effect, first row) or type 2 error rates (falsely failing to reject the null hypothesis if there is a true effect, second and third row), respectively, for different levels of attrition relative to the rates acquired with the full sample (“8 + 8”). Ratios for random attrition are colored in black, and ratios for non-random attrition are colored in red, in arbitrary units (a.u.). Fourth column: effect size estimated from positive trials only. Mean estimated effect sizes are displayed in black (+) for random attrition and in red (×) for non-random attrition.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.g001" xlink:type="simple"/>
</fig>
<fig id="pbio.1002331.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002331.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Simulation results for attrition of outliers.</title>
<p>Column 1 + 2: rows represent the results of a different effect size (d) scenario, indicated left. The level of attrition in either treatment group is stated as “8 + 8” without attrition and “7 + 8” and “7 + 7” with the number of missing animals increasing from left to right. Probability of positive trials before and after attrition of outliers in the samples that are not in favor (first column) or in favor (second column) of the expected effect. Colors represent the proportion of trials out of 10,000 simulations that are significant (1) independent of attrition (orange) or significant (2) only in the case of attrition (red), non-significant (1) independent of attrition (cyan), or non-significant (2) only in the case of attrition (dark blue). Column 3: ratio of type 1 error rates (falsely accepting the H<sub>1</sub> hypothesis if there is no true effect, first row) or type 2 error rates (falsely failing to reject the null hypothesis if there is a true effect, second and third row), respectively, with increasing attrition relative to the rates acquired with the full sample (“8 + 8”). Ratios for attrition of outliers that are in favor of the effect are colored in black, and ratios for attrition of outlier that are not in favor of the effect are colored in red, in arbitrary units (a.u.).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.g002" xlink:type="simple"/>
</fig>
<p>In the first set of simulations (<xref ref-type="fig" rid="pbio.1002331.g001">Fig 1</xref>, row 1), we assumed there was no real effect (Cohen’s effect size d = 0, top row). Under these conditions, random attrition (first column) did not alter the false discovery rate of 5%. The effects of non-random attrition are reflected in the second column. Here, with removal of three samples disfavoring an expected effect (third column, attrition scenario “6 + 7”), the proportion of trials declaring statistically significant trials increased from 5% to 23%.</p>
<p>Though no true effect was present (d = 0), we also examined the impact of attrition on effect size estimates from statistically significant results. For significant experiments, (fourth column, first row), we observed a small increase in estimated effect size when three animals were randomly excluded d<sub>est ‘6+7’</sub> = 0.09 (SE: 0.64). For non-random attrition, the estimated effect sizes were strikingly larger (e.g., d<sub>est ‘6+7,’</sub> = 1.67 [SE: 0.66]).</p>
<p>In our second set of simulations (<xref ref-type="fig" rid="pbio.1002331.g001">Fig 1</xref>, row 2), we simulated a preclinical study with a commonly observed effect size of Cohen’s d = 0.875 [<xref ref-type="bibr" rid="pbio.1002331.ref021">21</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref022">22</xref>]. Here we see that with random loss of animals the risk for type 2 error decreased from 63% to 20%. However, this apparent advantage is offset by the loss in power and corresponding increase in false negative rate (from 63% without attrition to 73% for a loss of three animals, attrition scenario “6 + 7”). Biased removal of animals led to an artificial increase in the true positive rate from 37% without attrition to about 80% in the last scenario (“6 + 7”). Even with a true effect size of 0.875, the mean estimated effect size of significant trials was d<sub>est’8+8’</sub> = 1.52 (SE: 0.57), an inflation of 175%. With attrition, this further increased to d<sub>est’6+7’</sub> = 1.73 (SE: 0.66) with random attrition and to d<sub>est’6+7’</sub> = 2.17 (SE: 0.71) with non-random attrition of three samples, corresponding to a striking 197% and 248% increase of the true effect size, respectively. These results follow from an increase in false negative rates due to the loss in power, in which only large effects can be detected. More information on the overestimation of effect size estimates for all attrition scenarios may be found in <xref ref-type="supplementary-material" rid="pbio.1002331.s001">S1 Fig</xref> of the supporting information.</p>
<p>The third set of simulations (<xref ref-type="fig" rid="pbio.1002331.g001">Fig 1</xref>, row 3) showed similar effects of attrition when we assumed a large true effect size (Cohen’s d = 1.5). Again, random loss decreased power and increased the false negative rate, accompanied by an inflated average effect size estimate among the significant experiments (d<sub>est’6+7’</sub> = 1.97, SE: 0.69). Biased removal artificially increased the true positive rate from 79% to 98% when three samples were selectively dropped, with a corresponding decrease in type 2 error from 21% to 2%. The mean estimated effect size from significant trials was d<sub>est’6+7’</sub> = 2.79 (SE: 0.80), which corresponded to 186% of the effect size in the total body of simulated studies.</p>
<p>In addition to attrition due to reasons such as illness or data loss, researchers often exclude measurements with extreme values (outliers). We therefore simulated the effects of removing outliers with random loss or biased removal. As expected, the impact of excluding outliers depended on whether the removed outliers were supportive of the expected effect (<xref ref-type="fig" rid="pbio.1002331.g002">Fig 2</xref>, second column) or not (<xref ref-type="fig" rid="pbio.1002331.g002">Fig 2</xref>, first column). When no effect is present (row 1), removal of outliers resulted in changes in effect sizes, especially when a low extreme value was removed from one group, and a high extreme from the other. Here, the false positive rate rose from 4.7% to 46%. In addition to striking type 1 error, estimated effect sizes from trials where d = 0 (no effect) were as much as d<sub>est’7+7’</sub> = 1.85 (SE: 0.66). If a true effect was present (<xref ref-type="fig" rid="pbio.1002331.g002">Fig 2</xref>, second and third row), attrition of outliers that opposed the effect simultaneously increased the true positive rate and decreased the risk for type 2 error from 63% to 5% and from 21% to almost 0% for an effect size of 0.875 or 1.5, respectively. The estimation of these effect sizes for positive trials inflated to d<sub>est’7+7’</sub> = 2.88 (SE: 0.79) and d<sub>est’7+7’</sub> = 3.98 (SE: 0.96), respectively. In contrast, attrition of outliers that formerly supported an effect decreased the true positive rate from 36% to 30% or from 79% to 69% for an underlying effect size of 0.875 or 1.5, respectively. Type 2 error also increased from 64% to 70% and from 21% to 31% (a risk ratio of 1.1 and 1.5).</p>
<p>Finally, we also simulated the effects of attrition on groups with larger sample sizes of 12, 16, 20, 24, and 30 animals (for details, see <xref ref-type="supplementary-material" rid="pbio.1002331.s008">S1 Text</xref>). First, we explored the effects of losing three animals (or most severe scenario, above) in a random or targeted fashion in these larger groups. Here, the proportion of falsely significant trials decreased as sample sizes increased (<xref ref-type="supplementary-material" rid="pbio.1002331.s002">S2</xref> and <xref ref-type="supplementary-material" rid="pbio.1002331.s003">S3</xref> Figs), following from an increase in power. However, when a constant proportion (20%) of animals was removed from each comparison, larger group sizes could not protect against overestimation of effect size (<xref ref-type="supplementary-material" rid="pbio.1002331.s004">S4</xref> and <xref ref-type="supplementary-material" rid="pbio.1002331.s005">S5</xref> Figs).</p>
<p>By and large, the results of our simulation not only show that random exclusion of animals decreases the sample size and thus statistical power but also demonstrate that the exclusion of animals a targeted fashion, including removal of outliers, can have extreme consequences with regard to false positives and skewed interpretation.</p>
</sec>
</sec>
<sec id="sec004">
<title>Meta-analysis of Preclinical Studies</title>
<p>To complement the results from our simulation study, we estimated the frequency and impact of attrition in a series of recent preclinical studies in cancer and stroke. Our meta-analyses employed two pre-existing datasets that have been described in detail elsewhere: Collaborative Approach to Meta-Analysis and Review of Animal Data from Experimental Studies (CAMARADES) [<xref ref-type="bibr" rid="pbio.1002331.ref021">21</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref022">22</xref>] and Studies of Translation, Ethics and Medicine (STREAM) (<xref ref-type="supplementary-material" rid="pbio.1002331.s009">S2 Text</xref>). Our search returned 100 papers on the topic of stroke and cancer, containing 316 experiments on infarct volume and 206 experiments on tumor shrinkage, respectively. To assess the presence of attrition, we compared reported numbers of animals in the methods and results section for each experiment. Experiments for which these numbers were reported as identical were coded as “Matched” (although unreported losses or exclusions cannot be completely ruled out), and experiments for which these numbers differed were coded as “Attrition.” Experiments for which this comparison was not possible were coded as “Unclear” (for more details, please see <xref ref-type="supplementary-material" rid="pbio.1002331.s008">S1 Text</xref>).</p>
<p>In both indication areas, animal numbers in more than half of the experiments had “Unclear” animal numbers, followed by those categorized as “Matched” and a small number with reported “Attrition” (see <xref ref-type="fig" rid="pbio.1002331.g003">Fig 3</xref>). Within the category of “Attrition,” we differentiated between explained (exact numbers of animals lost and reasons given) and unexplained forms of animal loss. Among studies with documented attrition, numbers of missing animals were only explained in a small proportion of experiments (1/15 in cancer and 13/38 in stroke). To test whether papers with detected attrition were not exceptionally detailed reports, we checked all publications against a simple rubric of reporting quality concerning blinding practices. There was a significant difference between types of animal flow reporting and presence of blinding practices, indicated by a larger proportion of blinding reporting in the “Attrition” category, as well as a larger proportion without reporting of blinding in the “Unclear” group (Fisher’s exact: <italic>p</italic> &lt; 0.001, <xref ref-type="supplementary-material" rid="pbio.1002331.s006">S6 Fig</xref>).</p>
<fig id="pbio.1002331.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002331.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Procedure from meta-analysis for classifying papers based on type of animal reporting employed.</title>
<p>All experiments were compared using the numbers of animals reported in the methods and results section. If this comparison was impossible, experiments were coded as “Unclear.” If these numbers were identical, experiments were coded as “Matched.” If there was a discrepancy between these numbers, then experiments were coded as “Attrition,” which could either be explained (via information in text or figure legends of the paper) or unexplained.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.g003" xlink:type="simple"/>
</fig>
<p>To see whether differences in reporting were associated with experimental effect size, we compared effect sizes across experiments coded as “Unclear,” “Matched,” and “Attrition.” In our sample, the vast majority of studies (152/206 in cancer, 276/316 in stroke) reported a “desired” effect, i.e., a better outcome for animals in the treatment group. All effect sizes, regardless of direction, were used in comparison between groups. In both stroke and cancer, “Matched” experiments displayed the highest median effect sizes (cancer: median d = 0.84, stroke: median d = 1.42 see <xref ref-type="fig" rid="pbio.1002331.g004">Fig 4</xref>). Experiments coded as “Attrition” produced medium effect sizes in cancer (median d = 0.82) and the lowest median effect sizes in stroke (median d = 1.10). Finally, papers that were coded as “Unclear” reported the lowest median effect size in cancer (median d = 0.39) and an intermediate value in stroke (median d = 1.19). We identified a significant association between effect size and category of experimental reporting for cancer (Χ<sup>2</sup>(df = 2, <italic>n</italic> = 206) = 7.62, <italic>p</italic> = 0.022) but not for stroke (Χ<sup>2</sup>(df = 2, <italic>n</italic> = 316) = 2.70, <italic>p</italic> = 0.259). Within experiments that contained attrition, those with unexplained attrition had higher median effect sizes (median d = 0.97 interquartile range [IQR] [0.33–1.73]) than experiments in which the attrition was accounted for in the text (median d = 0.67 IQR [0.05–1.25]). This difference, however, was not significant in our data sample pooled across cancer and stroke (<italic>p</italic> = 0.343).</p>
<fig id="pbio.1002331.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002331.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Effect sizes in experiments with different forms of animal reporting in stroke (left) and cancer (right).</title>
<p>Boxes represent second to third quartiles, and red lines in the middle are the median. Whiskers represent first and fourth quartiles.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.g004" xlink:type="simple"/>
</fig>
<p>To check if our simulation study used realistic scenarios of animal loss (1/16–3/16 animals, i.e., 6.25%–18.75% loss), we examined what proportion of animals were lost experiments with detectable attrition. Almost half (47.1%, or 25/53) of experiments with attrition reported 25% animal loss or more. This is equivalent to or greater than the proportion of animals in our “worst case” attrition scenario (i.e., 3/16 animals, or 18.75% loss, see Figs <xref ref-type="fig" rid="pbio.1002331.g001">1</xref> and <xref ref-type="fig" rid="pbio.1002331.g002">2</xref>, <xref ref-type="supplementary-material" rid="pbio.1002331.s007">S1 Table</xref>). As may be seen in <xref ref-type="fig" rid="pbio.1002331.g001">Fig 1</xref>, this can lead to effect sizes inflated by 25% to 175% amongst experiments with statistically significant results.</p>
<p>Next, we looked for markers that could be indicative of unreported missing animals in our sample. Here, we examined the symmetry of group sizes, i.e., whether there are the same number of animals in control and treatment groups. Since an equal number of animals in the different groups is the most efficient use in order to optimize power, any difference in group size can be regarded as a proxy for attrition (either random or biased) or even as a post-hoc addition of animals to grow statistical power or significance. In total, 219 experiments or 42.0% of our datasets had uneven group sizes, with a higher proportion of experiments with smaller sample size in the treatment groups (58%) compared to control groups (95% CI: 52%–65%). When attrition was fully reported, 64.1% of experiments appear to have lost animals in the treatment group.</p>
</sec>
<sec id="sec005" sec-type="conclusions">
<title>Discussion</title>
<p>Through statistical modelling and meta-analysis, we have shown that the loss of a few animals, as may often occur in preclinical studies, can distort true effects. Random loss of animals increases the occurrence of false negatives due to a decrease in sample size and statistical power (<xref ref-type="fig" rid="pbio.1002331.g001">Fig 1</xref>), already a problem in small sample studies [<xref ref-type="bibr" rid="pbio.1002331.ref008">8</xref>]. However, biased removal (<xref ref-type="fig" rid="pbio.1002331.g001">Fig 1</xref>), which can occur because of subconscious bias, leads to an even greater probability of false positive results, particularly in settings in which real effect sizes are subtle to nil (<xref ref-type="fig" rid="pbio.1002331.g001">Fig 1</xref>) [<xref ref-type="bibr" rid="pbio.1002331.ref012">12</xref>]. Here, the negative effects of loss of power are exacerbated by potential for selection and other biases, severely undermining statistical inference. Increasing group sizes, therefore, helped to diminish these effects (<xref ref-type="supplementary-material" rid="pbio.1002331.s002">S2 Fig</xref>). Dropping outliers, a common practice in many laboratories, can also have substantial effects (<xref ref-type="fig" rid="pbio.1002331.g002">Fig 2</xref>). Though the impact of outlier attrition on average effect of all experiments might be minimal (since only ~5% of normally distributed values have outliers), its effect on this group is disproportionally large. Results of attrition in all scenarios may be further compounded by the fact that many studies show a preponderance of preclinical publications reporting statistically significant effects [<xref ref-type="bibr" rid="pbio.1002331.ref007">7</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref021">21</xref>]. This may reflect publication bias, whereby studies failing to show statistical significance are not published. Thus, publication of predominantly positive experiments with biased attrition magnifies the distortion of treatment effects even more.</p>
<p>Although not unexpected, the finding that non-random attrition can decrease the number of false negatives is also of interest (<xref ref-type="fig" rid="pbio.1002331.g001">Fig 1</xref>). Our simulations showed that non-random attrition can artificially overestimate detected effects sizes, which leads to an artificial increase in power by effectively testing a bigger but biased effect and thus results in a decrease of false negatives. This decrease in type 2 errors might be perceived as a positive benefit, but it is just due to bias caused by non-random attrition. Because of the typical, low sample sizes in experimental research, most studies are highly underpowered even without attrition, and scientists are even more at serious risk of missing smaller, more subtle effects when attrition is present [<xref ref-type="bibr" rid="pbio.1002331.ref006">6</xref>–<xref ref-type="bibr" rid="pbio.1002331.ref008">8</xref>].</p>
<p>Ultimately, the impact of attrition is dependent on the total sample size of the experiment at hand. In our simulation, our starting point was a sample size of 8 + 8, which is representative of many published experiments [<xref ref-type="bibr" rid="pbio.1002331.ref021">21</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref022">22</xref>]. We would like to stress that although an increase in sample size does help to counteract the impact of attrition to some extent (<xref ref-type="supplementary-material" rid="pbio.1002331.s002">S2</xref>–<xref ref-type="supplementary-material" rid="pbio.1002331.s005">S5</xref> Figs), it is not a safeguard to this phenomenon, especially when the attrition is done in a biased fashion.</p>
<p>When attrition was reported in experiments in our meta-analysis, the loss was often more than 25% of subjects. Yet, as shown in our simulations, even more moderate loss can have serious consequences that are not significantly diminished when group sizes are larger (Figs <xref ref-type="fig" rid="pbio.1002331.g001">1</xref> and <xref ref-type="fig" rid="pbio.1002331.g002">2</xref>, <xref ref-type="supplementary-material" rid="pbio.1002331.s003">S3</xref> and <xref ref-type="supplementary-material" rid="pbio.1002331.s004">S4</xref> Figs). For example, animals in the treatment group may die because of drug toxicity, especially if they are weakened because of a strong experimental intervention. Since these animals cannot be considered “treatment successes” in any form, this guarantees bias unless there is some way of adjusting data for toxicity-induced loss. An example of this phenomenon from the field of neurovascular medicine may be found in [<xref ref-type="bibr" rid="pbio.1002331.ref023">23</xref>]. Indeed, more attrition in our sample occurred in treatment groups compared to control groups, and treatment groups were also unexpectedly smaller when animal use was “Matched” or “Unclear.”</p>
<p>The latter finding is worrisome but underlies a limitation in our data: verifiable presence of attrition was impossible to judge in roughly 50% and 75% of “Unclear” experiments in cancer and stroke, respectively (see <xref ref-type="fig" rid="pbio.1002331.g003">Fig 3</xref>). Detection of attrition using comparison of reported numbers from methods and results is only effective when group sizes are reported completely (i.e., numbers instead of ranges) and when the methods section is not altered after an experiment is completed. Our criteria for declaring non-attrition were permissive: we cannot rule out the possibility that even in cases of “Matched” animal reporting, attrition may have occurred but the prospectively intended group sizes were never reported. Hidden attrition in “Matched” experiments could be one reason why median effect sizes were highest in this category (<xref ref-type="fig" rid="pbio.1002331.g004">Fig 4</xref>).</p>
<p>Notwithstanding the limitations of our data, we can use the results of our simulations to extrapolate on the effects detected in our meta-analysis. Within our sample, 235 experiments in stroke and cancer, or 44.9% of the total, reported uneven group sizes suggestive of attrition. Median effect size in these experiments was 1.2 (IQR: 0.3–1.8). If we assume that there was a distortion of results due to attrition in half of these experiments (with effect sizes &gt; 0, <italic>n</italic> = 199) resulting in an overestimation of effect sizes of 80%, the median of the true effect sizes of all 235 experiments would be 0.7 (IQR: 0.3–1.5) instead of 1.2.</p>
<p>Despite preliminary exploration of uneven group sizes in our sample, our conclusions about effects of attrition in published literature must remain limited. Without access to initial protocols and the ability to view deviations from them, using group asymmetries to uncover attrition remains strictly speculative. Therefore, the true burden of attrition in preclinical research remains unknown, and our results here are most likely an underestimation. Until transparent reporting becomes the rule, rather than the exception, we must instead focus on productive ways to deal with animal loss.</p>
<p>Attrition is also a problem in clinical trials [<xref ref-type="bibr" rid="pbio.1002331.ref011">11</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref013">13</xref>]. However, one major difference from preclinical work is the presence of well-established standards for reporting patient flow (i.e., [<xref ref-type="bibr" rid="pbio.1002331.ref014">14</xref>]) and imputing missing data points [<xref ref-type="bibr" rid="pbio.1002331.ref024">24</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref025">25</xref>]. Neither are routinely practiced in preclinical research, although interest in strategies for dealing with missing data is growing [<xref ref-type="bibr" rid="pbio.1002331.ref018">18</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref026">26</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref027">27</xref>]. Animal Research: Reporting of In Vivo Experiments (ARRIVE) reporting guidelines for animal research, for example, mandate monitoring animal flow over the course of an experiment.</p>
<p>Attrition of animals is often unforeseen and does not reflect willful bias. However, there are several simple steps that the scientific community can use to diminish inferential threats due to animal attrition. First, we recommend that authors prespecify inclusion and exclusion criteria, as well as reasons for exclusion of animals. For example, the use of flowcharts to track animals from initial allocation until analysis, with attrition noted, improves the transparency of preclinical reporting. An added benefit of this approach lies in the ability to track systemic issues with experimental design or harmful side effects of treatment. Journal referees can also encourage such practices by demanding them in study reports. Finally, many simple statistical tools used in medicine could be adopted to properly impute (and report) missing data [<xref ref-type="bibr" rid="pbio.1002331.ref027">27</xref>,<xref ref-type="bibr" rid="pbio.1002331.ref028">28</xref>]. Overall, compliance with ARRIVE guidelines will aid in most, if not all, of the issues inherent to missing data in preclinical research and help structure a better standard for animal use and reporting.</p>
</sec>
<sec id="sec006">
<title>Supporting Information</title>
<supplementary-material id="pbio.1002331.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Change of effect size with attrition estimated from significant trials only.</title>
<p>Left column: mean estimated effect sizes for random (black) and non-random attrition (red). Right column: overestimation in percent compared to the simulated “true” effect size d = 0.875 and d = 1.5 (corresponding to 100%), respectively.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002331.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Simulation results for random and non-random attrition of three samples (one from control group, two from treatment group) in dependence of increasing sample size.</title>
<p>Rows represents the results of a different effect size (d) scenario as indicated on the left. The number of samples after attrition in either treatment group is given on the bottom (e.g., “6 + 7”), with the total number of samples before attrition given in brackets (e.g., “(8 + 8)”). Column 1 + 2: probability of positive trials after random attrition (first column) or non-random attrition of extremes that are not in favor of the effect (second column) for different effect sizes (rows 1–3). Colors represent the proportion of trials out of 10,000 simulations that are significant (1) independent of attrition (orange) or significant (2) only in the case of attrition (red), non-significant (1) independent of attrition (cyan), or non-significant (2) only in the case of attrition (dark blue).</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002331.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Effect size estimated from positive trials only.</title>
<p>Mean estimated effect sizes are displayed in black (+) for random attrition and in red (×) for non-random attrition, in arbitrary units (a.u.).</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002331.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.s004" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Simulation results for random and non-random attrition of 20% of samples (about 12.5% in the control group and about 25% in the treatment group) in dependence of increasing sample size.</title>
<p>Each row represents the results of a different effect size (d) scenario as indicated on the left. The number of samples after attrition in either treatment group is given on the bottom (e.g., “6 + 7”), with the total number of samples before attrition given in brackets (e.g., “(8 + 8)”). Column 1 + 2: probability of positive trials after random attrition (first column) or non-random attrition of extremes that are not in favor of the effect (second column) for different effect sizes (row 1–3). Colors represent the proportion of trials out of 10,000 simulations that are significant (1) independent of attrition (orange) or significant (2) only in the case of attrition (red), non-significant (1) independent of attrition (cyan), or non-significant (2) only in the case of attrition (dark blue).</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002331.s005" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.s005" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Effect size estimated from positive trials only.</title>
<p>Mean estimated effect sizes are displayed in black (+) for random attrition and in red (×) for non-random attrition, in arbitrary units (a.u.).</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002331.s006" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.s006" xlink:type="simple">
<label>S6 Fig</label>
<caption>
<title>Proportion of experiments with different animal flow reporting noted as employing different blinding practices.</title>
<p>Fisher’s exact X<sup>2</sup> test revealed a significant difference between types of animal flow reporting and presence of blinding practices Χ<sup>2</sup>(df = 4 <italic>n</italic> = 522) = 19.935, <italic>p</italic> &lt; 0.001.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002331.s007" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.s007" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Simulation scenarios.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002331.s008" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.s008" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Materials and methods.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002331.s009" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002331.s009" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Structure of STREAM Preclinical Cancer Database.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We would like to acknowledge Malcolm MacLeod and Emily Sena for unrestricted access to the CAMARADES database, as well as Valerie Henderson for her help with the STREAM database.</p>
</ack>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>ARRIVE</term>
<def><p>Animal Research: Reporting of In Vivo Experiments</p></def>
</def-item>
<def-item><term>CAMARADES</term>
<def><p>Collaborative Approach to Meta-Analysis and Review of Animal Data from Experimental Studies</p></def>
</def-item>
<def-item><term>CONSORT</term>
<def><p>Consolidated Standards of Reporting Trials</p></def>
</def-item>
<def-item><term>H<sub>1</sub> hypothesis</term>
<def><p>alternative hypothesis</p></def>
</def-item>
<def-item><term>IQR</term>
<def><p>interquartile range</p></def>
</def-item>
<def-item><term>STREAM</term>
<def><p>Studies of Translation, Ethics and Medicine</p></def>
</def-item>
<def-item><term>STROBE</term>
<def><p>Strengthening the Reporting of Observational Studies in Epidemiology</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.1002331.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Røttingen</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Regmi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Eide</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Young</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Viergever</surname> <given-names>RF</given-names></name>, <name name-style="western"><surname>Ardal</surname> <given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Mapping of available health research and development data: What's there, what's missing, and what role is there for a global observatory?</article-title> <source>Lancet</source>. <year>2013</year>; <volume>382</volume>: <fpage>1286</fpage>–<lpage>307</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0140-6736(13)61046-6" xlink:type="simple">10.1016/S0140-6736(13)61046-6</ext-link></comment> <object-id pub-id-type="pmid">23697824</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Macleod</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Michie</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Roberts</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Dirnagl</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Chalmers</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>, <etal>et al</etal>. <article-title>Biomedical research: increasing value, reducing waste</article-title>. <source>Lancet</source>. <year>2014</year>; <volume>383</volume>: <fpage>101</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0140-6736(13)62329-6" xlink:type="simple">10.1016/S0140-6736(13)62329-6</ext-link></comment> <object-id pub-id-type="pmid">24411643</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van der Worp</surname> <given-names>HB</given-names></name>, <name name-style="western"><surname>Howells</surname> <given-names>DW</given-names></name>, <name name-style="western"><surname>Sena</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Porritt</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Rewell</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Can Animal Models of Disease Reliably Inform Human Studies?</article-title> <source>PLoS Med</source> <year>2010</year>; <volume>7</volume>: <fpage>e1000245</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pmed.1000245" xlink:type="simple">10.1371/journal.pmed.1000245</ext-link></comment> <object-id pub-id-type="pmid">20361020</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Howells</surname> <given-names>DW</given-names></name>, <name name-style="western"><surname>Sena</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Macleod</surname> <given-names>MR</given-names></name>. <article-title>Bringing rigour to translational medicine</article-title> <source>Nat Rev Neurol</source>. <year>2014</year>; <volume>10</volume>: <fpage>37</fpage>–<lpage>43</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrneurol.2013.232" xlink:type="simple">10.1038/nrneurol.2013.232</ext-link></comment> <object-id pub-id-type="pmid">24247324</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sena</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>van der Worp</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Howells</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>MacLeod</surname> <given-names>M</given-names></name>. <article-title>How can we improve the pre-clinical development of drugs for stroke?</article-title> <source>Trends Neurosci</source> <year>2007</year>; <volume>30</volume>: <fpage>433</fpage>–<lpage>439</lpage>. <object-id pub-id-type="pmid">17765332</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>. <article-title>Why most published research findings are false</article-title>. <source>PLoS Med</source>. <year>2005</year>; <volume>2</volume>: <fpage>e124</fpage>. <object-id pub-id-type="pmid">16060722</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsilidis</surname> <given-names>KK</given-names></name>, <name name-style="western"><surname>Panagiotou</surname> <given-names>OA</given-names></name>, <name name-style="western"><surname>Sena</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Aretouli</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Evangelou</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Howells</surname> <given-names>DW</given-names></name>, <etal>et al</etal>. <article-title>Evaluation of excess significance bias in animal studies of neurological diseases</article-title>. <source>PLoS Biol</source>. <year>2013</year>; <volume>11</volume>: <fpage>e1001609</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1001609" xlink:type="simple">10.1371/journal.pbio.1001609</ext-link></comment> <object-id pub-id-type="pmid">23874156</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Button</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Mokrysz</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Nosek</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Flint</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Robinson</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Munafò</surname> <given-names>MR</given-names></name>. <article-title>Power failure: why small sample size undermines the reliability of neuroscience</article-title>. <source>Nat Rev Neurosci</source>. <year>2013</year>; <volume>14</volume>: <fpage>365</fpage>–<lpage>76</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn3475" xlink:type="simple">10.1038/nrn3475</ext-link></comment> <object-id pub-id-type="pmid">23571845</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hooijmans</surname> <given-names>CR</given-names></name>, <name name-style="western"><surname>Ritskes-Hoitinga</surname> <given-names>M</given-names></name>. <article-title>Progress in using systematic reviews of animal studies to improve translational research</article-title>. <source>PLoS Med</source>. <year>2013</year>; <volume>10</volume>: <fpage>e1001482</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pmed.1001482" xlink:type="simple">10.1371/journal.pmed.1001482</ext-link></comment> <object-id pub-id-type="pmid">23874162</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Luijk</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bakker</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Rovers</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ritskes-Hoitinga</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>de Vries</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Leenaars</surname> <given-names>M</given-names></name>. <article-title>Systematic reviews of animal studies: Missing link in translational research?</article-title> <source>PLoS ONE</source> <year>2014</year>;<volume>9</volume>: <fpage>e89981</fpage>.</mixed-citation></ref>
<ref id="pbio.1002331.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nüesch</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Trelle</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Reichenbach</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rutjes</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bürgi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Scherer</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>The effects of excluding patients from the analysis in randomised controlled trials: meta-epidemiological study</article-title>. <source>BMJ</source> <year>2009</year>; <volume>339</volume>:<fpage>b 3244</fpage></mixed-citation></ref>
<ref id="pbio.1002331.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shun-Shin</surname> <given-names>MJ</given-names></name> <name name-style="western"><surname>Francis</surname> <given-names>DP</given-names></name>. <article-title>Why Even More Clinical Research Studies May Be False: Effect of Asymmetrical Handling of Clinically Unexpected Values</article-title>. <source>PLoS ONE</source>. <year>2013</year>; <volume>8</volume>(<issue>6</issue>): <fpage>e65323</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0065323" xlink:type="simple">10.1371/journal.pone.0065323</ext-link></comment> <object-id pub-id-type="pmid">23825524</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tierney</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Stewart</surname> <given-names>L</given-names></name>. <article-title>Investigating patient exclusion bias in meta-analysis</article-title>. <source>Int J Epidemiol</source>. <year>2005</year> <month>Feb</month>;<volume>34</volume>:<fpage>79</fpage>–<lpage>87</lpage> <object-id pub-id-type="pmid">15561753</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Begg</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Cho</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Eastwood</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Horton</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Moher</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Olkin</surname> <given-names>I</given-names></name>, <etal>et al</etal>. <article-title>Improving the quality of reporting of randomized controlled trials. The CONSORT statement</article-title>. <source>JAMA</source>. <year>1996</year>;<volume>276</volume>: <fpage>637</fpage>–<lpage>9</lpage> <object-id pub-id-type="pmid">8773637</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vandenbroucke</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>von Elm</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Altman</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Gøtzsche</surname> <given-names>PC</given-names></name>, <name name-style="western"><surname>Mulrow</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Pocock</surname> <given-names>SJ</given-names></name>, <etal>et al</etal>.<collab>STROBE Initiative</collab>. <article-title>Strengthening the Reporting of Observational Studies in Epidemiology (STROBE): Explanation and elaboration</article-title>. <source>Epidemiology</source>. <year>2007</year>;<volume>18</volume>:<fpage>805</fpage>–<lpage>35</lpage>. <object-id pub-id-type="pmid">18049195</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple">The ARRIVE Guidelines. <ext-link ext-link-type="uri" xlink:href="http://www.nc3rs.org.uk/ARRIVEpdf" xlink:type="simple">http://www.nc3rs.org.uk/ARRIVEpdf</ext-link>. Last accessed 10.7.2014</mixed-citation></ref>
<ref id="pbio.1002331.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kilkenny</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Browne</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Cuthill</surname> <given-names>IC</given-names></name>, <name name-style="western"><surname>Emerson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Altman</surname> <given-names>DG</given-names></name>. <article-title>Improving bioscience research reporting: the ARRIVE guidelines for reporting animal research</article-title>. <source>PLoS Biol</source>. <year>2010</year>; <volume>8</volume>: <fpage>e1000412</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1000412" xlink:type="simple">10.1371/journal.pbio.1000412</ext-link></comment> <object-id pub-id-type="pmid">20613859</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Henderson</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Kimmelman</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Fergusson</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Grimshaw</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hackam</surname> <given-names>D</given-names></name>. <article-title>Threats to validity in the design and conduct of preclinical efficacy studies: A systematic review of guidelines for in vivo animal experiments</article-title>. <source>PLoS Med</source> <year>2013</year>;<volume>10</volume>: <fpage>e1001489</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pmed.1001489" xlink:type="simple">10.1371/journal.pmed.1001489</ext-link></comment> <object-id pub-id-type="pmid">23935460</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baker</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Lidster</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Sottomayor</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Amor</surname> <given-names>S</given-names></name>. <article-title>Two years later: journals are not yet enforcing the ARRIVE guidelines on reporting standards for pre-clinical animal studies</article-title>. <source>PLoS Biol</source> <year>2013</year>; <volume>11</volume>: <fpage>e1001756</fpage></mixed-citation></ref>
<ref id="pbio.1002331.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Glasziou</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Altman</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Bossuyt</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Boutron</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Clarke</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Julious</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Reducing waste from incomplete or unusable reports of biomedical research</article-title>. <source>Lancet</source>. <year>2014</year>; <volume>383</volume>: <fpage>267</fpage>–<lpage>76</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0140-6736(13)62228-X" xlink:type="simple">10.1016/S0140-6736(13)62228-X</ext-link></comment> <object-id pub-id-type="pmid">24411647</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sena</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>van der Worp</surname> <given-names>HB</given-names></name>, <name name-style="western"><surname>Bath</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Howells</surname> <given-names>DW</given-names></name>, <name name-style="western"><surname>Macleod</surname> <given-names>MR</given-names></name>. <article-title>Publication bias in reports of animal stroke studies leads to major overstatement of efficacy</article-title>. <source>PLoS Biol</source>. <year>2010</year>; <volume>8</volume>:<fpage>e1000344</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1000344" xlink:type="simple">10.1371/journal.pbio.1000344</ext-link></comment> <object-id pub-id-type="pmid">20361022</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref022"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">CAMARDES. Review of animal data from experimental studies [Internet]. Edinburgh: CAMARDES; 2014 [cited May 14th, 2015]. <ext-link ext-link-type="uri" xlink:href="http://www.dcn.ed.ac.uk/camarades/" xlink:type="simple">http://www.dcn.ed.ac.uk/camarades/</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002331.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Couzin-Frankel</surname> <given-names>J</given-names></name>. <article-title>When Mice Mislead</article-title>. <source>Science</source>. <year>2013</year>; <volume>342</volume>: <fpage>922</fpage>–<lpage>3</lpage> <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.342.6161.922" xlink:type="simple">10.1126/science.342.6161.922</ext-link></comment> <object-id pub-id-type="pmid">24264972</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dziura</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Post</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Zhao</surname> <given-names>Q</given-names></name>, <name name-style="western"><surname>Fu</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Peducci</surname> <given-names>P</given-names></name>. <article-title>Strategies for dealing with Missing data in clinical trials: From design to analysis</article-title>. <source>Yale JBiol Med</source> <year>2013</year>; <volume>86</volume>: <fpage>343</fpage>–<lpage>358</lpage>.</mixed-citation></ref>
<ref id="pbio.1002331.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Little</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>D'Agostino</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Dickersin</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Emerson</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Farrar</surname> <given-names>JT</given-names></name>, <etal>et al</etal>. <article-title>The Prevention and Treatment of Missing Data in Clinical Trials</article-title>. <source>N Engl J Med</source> <year>2012</year>; <volume>367</volume>:<fpage>1355</fpage>–<lpage>1360</lpage> <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1056/NEJMsr1203730" xlink:type="simple">10.1056/NEJMsr1203730</ext-link></comment> <object-id pub-id-type="pmid">23034025</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kimmelman</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Mogil</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Dirnagl</surname> <given-names>U</given-names></name>. <article-title>Distinguishing between exploratory and confirmatory preclinical research will improve translation</article-title>. <source>PLoS Biol</source> <year>2014</year>; <volume>12</volume>: <fpage>e1001863</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1001863" xlink:type="simple">10.1371/journal.pbio.1001863</ext-link></comment> <object-id pub-id-type="pmid">24844265</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Muhlhausler</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Bloomfield</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Gilman</surname> <given-names>M</given-names></name>. <article-title>Whole Animal Experiments Should Be More Like Human Randomized Controlled Trials</article-title>. <source>PLoS Biol</source> <year>2013</year>;<volume>11</volume>: <fpage>e1001481</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1001481" xlink:type="simple">10.1371/journal.pbio.1001481</ext-link></comment> <object-id pub-id-type="pmid">23424284</object-id></mixed-citation></ref>
<ref id="pbio.1002331.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dong</surname> <given-names>Y</given-names></name> and <name name-style="western"><surname>Peng</surname> <given-names>C</given-names></name>. <article-title>Principled missing data methods for researchers</article-title>. <source>SpringerPlus</source> <year>2013</year>; <volume>2</volume>: <fpage>222</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/2193-1801-2-222" xlink:type="simple">10.1186/2193-1801-2-222</ext-link></comment> <object-id pub-id-type="pmid">23853744</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
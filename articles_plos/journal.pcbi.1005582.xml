<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-16-01121</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005582</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuronal tuning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory receptors</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory receptors</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory receptors</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Signal transduction</subject><subj-group><subject>Sensory receptors</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory cues</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory cues</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory cues</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Signal transduction</subject><subj-group><subject>Cell signaling</subject><subj-group><subject>Signal inhibition</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject><subj-group><subject>Sensory neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject><subj-group><subject>Sensory neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Sensory noise predicts divisive reshaping of receptive fields</article-title>
<alt-title alt-title-type="running-head">Sensory noise predicts divisive reshaping of receptive fields</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7782-4436</contrib-id>
<name name-style="western">
<surname>Chalk</surname> <given-names>Matthew</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2001-7515</contrib-id>
<name name-style="western">
<surname>Masset</surname> <given-names>Paul</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Deneve</surname> <given-names>Sophie</given-names></name>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Gutkin</surname> <given-names>Boris</given-names></name>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Institute of Science and Technology Austria, Klosterneuburg, Austria</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Neuroscience, Cold Spring Harbor Laboratory, Cold Spring Harbor, New York, United States of America</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Watson School of Biological Sciences, Cold Spring Harbor, New York, United States of America</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>National Research University Higher School of Economics, Center for Cognition and Decision Making, Moscow, Russia</addr-line>
</aff>
<aff id="aff005">
<label>5</label>
<addr-line>Group for Neural Theory, LNC INSERM U960, Departement d’Etudes Cognitive, Ecole Normale Superieure PSL* University, Paris, France</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Einhäuser</surname> <given-names>Wolfgang</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Technische Universitat Chemnitz, GERMANY</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con">
<p>
<list list-type="simple">
<list-item>
<p><bold>Conceptualization:</bold> MC PM BG SD.</p>
</list-item>
<list-item>
<p><bold>Formal analysis:</bold> PM MC.</p>
</list-item>
<list-item>
<p><bold>Funding acquisition:</bold> SD BG.</p>
</list-item>
<list-item>
<p><bold>Investigation:</bold> PM MC.</p>
</list-item>
<list-item>
<p><bold>Methodology:</bold> MC PM SD BG.</p>
</list-item>
<list-item>
<p><bold>Project administration:</bold> SD BG.</p>
</list-item>
<list-item>
<p><bold>Software:</bold> MC.</p>
</list-item>
<list-item>
<p><bold>Supervision:</bold> BG SD.</p>
</list-item>
<list-item>
<p><bold>Visualization:</bold> MC SD BG.</p>
</list-item>
<list-item>
<p><bold>Writing – original draft:</bold> MC SD BG.</p>
</list-item>
<list-item>
<p><bold>Writing – review &amp; editing:</bold> MC SD BG.</p>
</list-item>
</list>
</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">mattewjchalk@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>6</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="epub">
<day>16</day>
<month>6</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>6</issue>
<elocation-id>e1005582</elocation-id>
<history>
<date date-type="received">
<day>12</day>
<month>7</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>10</day>
<month>5</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Chalk et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005582"/>
<abstract>
<p>In order to respond reliably to specific features of their environment, sensory neurons need to integrate multiple incoming noisy signals. Crucially, they also need to compete for the interpretation of those signals with other neurons representing similar features. The form that this competition should take depends critically on the noise corrupting these signals. In this study we show that for the type of noise commonly observed in sensory systems, whose variance scales with the mean signal, sensory neurons should selectively divide their input signals by their predictions, suppressing ambiguous cues while amplifying others. Any change in the stimulus context alters which inputs are suppressed, leading to a deep dynamic reshaping of neural receptive fields going far beyond simple surround suppression. Paradoxically, these highly variable receptive fields go alongside and are in fact required for an invariant representation of external sensory features. In addition to offering a normative account of context-dependent changes in sensory responses, perceptual inference in the presence of signal-dependent noise accounts for ubiquitous features of sensory neurons such as divisive normalization, gain control and contrast dependent temporal dynamics.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Perception involves using incoming sensory signals to infer which objects or features are present in the surroundings. To do this, sensory systems must perform two basic operations: (i) combination of noisy sensory cues, and (ii) competition between different percepts. Here we show that the optimal form of competition depends on how sensory signals are corrupted by noise. Moreover, for the type of noise commonly observed in sensory systems, whose variance scales with the signal amplitude, competition should occur between different sensory cues <italic>before</italic> they are combined. Implemented neurally, this results in a highly flexible representation, in which neural receptive fields change dynamically depending on the stimulus context. Further we show that competition should take the form of divisive inhibition from the surround, accounting for why divisive normalisation, gain control and contrast dependent temporal dynamics appear so ubiquitous in sensory areas.</p>
</abstract>
<funding-group>
<funding-statement>This work was funded by SD’s James McDonnell foundation award (<ext-link ext-link-type="uri" xlink:href="http://www.jsmf.org" xlink:type="simple">www.jsmf.org</ext-link>), European research council consolidation grant (erc.europa.eu) “Predispike”, and l’Agence Nationale de Recherche (<ext-link ext-link-type="uri" xlink:href="http://www.agence-nationale-recherche.fr" xlink:type="simple">www.agence-nationale-recherche.fr</ext-link>) grants ANR-10-LABX-0087 IEC and ANR-10-IDEX- 0001-02 PSL. BG was funded by the Russian federal academic excellence program 5-100 to the NRU HSE. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="0"/>
<page-count count="26"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2017-07-13</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The code used to generate the figures in the paper has been uploaded onto a public repository: <ext-link ext-link-type="uri" xlink:href="https://sourceforge.net/projects/divnorm/" xlink:type="simple">https://sourceforge.net/projects/divnorm/</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>A fundamental goal of any perceptual system is to infer the state of the environment from received sensory signals. These signals are generally noisy and unreliable, so that the same signal can correspond to many different states of the world. For example, the sound of a bell may mean my mobile phone is ringing or there is someone at the door. Contextual cues, such as a vibration in my pocket, can resolve such ambiguities, in this case suggesting that my phone is ringing, and not the doorbell (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1a</xref>). Such competition between different explanations of sensory signals is called ‘explaining away’ and is a basic requirement for a perceptual system to discriminate between similar features. Neurally, it implies that groups of neurons which encode different (but overlapping) stimuli (such as the ‘telephone’ and ‘door’) should actively compete, via recurrent suppression [<xref ref-type="bibr" rid="pcbi.1005582.ref001">1</xref>].</p>
<fig id="pcbi.1005582.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005582.g001</object-id>
<label>Fig 1</label>
<caption>
<title>‘Explaining away’ in sensory perception.</title>
<p>(a) The presumed goal of perception is to infer the state of the external world from received sensory cues. Here, two possible events (someone arriving at the door, and a telephone call) can give rise to three sensory cues (a knocking sound, ringing sound, or vibration). The ringing sound is ambiguous: it can come from either the door bell or the phone. Cues, such as a vibrating telephone, can resolve this ambiguity: here, increasing the chances that the phone is ringing, while decreasing the chances that there is someone at the door. Such competition between different explanations for received sensory cues is called ‘explaining away’. (b-c) In sensory neural circuits, explaining away results in suppression from non-preferred stimuli in the surround. Its effects vary dramatically, depending on whether inhibition acts (b) globally on the neural responses or (c) selectively, on certain neural inputs. (d-e) Hypothetical response of ‘door’ and ‘phone’ selective neurons, in response to different combinations of sensory cues. The qualitative effects of explaining away depend on whether it (d) globally suppresses the response of one or other detector, or (e) selectively suppresses the influence of certain cues.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.g001" xlink:type="simple"/>
</fig>
<p>The way this competition is implemented has a crucial impact on how neural responses are modulated by stimulus context.</p>
<p>In many ‘classical’ models of early visual processing, visual neurons are assumed to integrate inputs from within their receptive field, before undergoing divisive or subtractive inhibition from the surround (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1b</xref>) [<xref ref-type="bibr" rid="pcbi.1005582.ref002">2</xref>]. In this case, non-preferred stimuli produce a general suppression of neural responses, but no changes to neural RF and/or tuning curve shapes (only a general suppression). Returning to our previous example, this would predict a general suppression of ‘door selective’ neurons when the phone was vibrating. In other words, the phone vibration would equally suppress the response of these neurons to ringing <italic>and</italic> knocking sounds (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1d</xref>).</p>
<p>However, explaining away as described above requires a markedly different form of competition, with inhibition from non-preferred stimuli targeting specific neural inputs, before they are combined (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1c</xref>). In this case, suppression would cause neurons to become unresponsive to certain inputs, but not others, resulting in a qualitative modulation of their receptive field (RF) shapes and/or tuning curves. For example, if the phone is vibrating, suggesting someone is calling, then the ringing sound (now explained by another cause) should not activate the door selective neurons. However, this should not affect how these neurons respond to other cues, such as a knocking sound (since the phone might be ringing whilst someone is also knocking on the door; <xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1e</xref>).</p>
<p>Here, we show that the specific form that this input-specific suppression should take depends on how incoming signals are corrupted by noise. In turn, this will deeply affect the predicted dynamics and integrative properties of sensory neurons. For example, if the noise was Gaussian with a fixed variance independent of the signal strength, a sensory neuron should subtract from the other neuron’s inputs its prediction of these inputs. Because this operation is linear, the overall effect is equivalent to a global subtractive suppression by the surround (i.e. the sum of all subtractive inhibitions from other neurons), bringing us back to ‘classical’ models of sensory processing (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1b</xref>).</p>
<p>However, sensory receptor responses and neural firing rates generally exhibit <italic>signal-dependent noise</italic>, whose variance scales proportionally with their amplitude [<xref ref-type="bibr" rid="pcbi.1005582.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1005582.ref005">5</xref>]. We show that in this case, competition should take the specific form of divisive suppression, where <italic>each individual neural input</italic> is divided by its prediction from other neurons. Since this occurs <italic>before</italic> these inputs are combined (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1c</xref>), it is in no way equivalent to a global surround suppression (either divisive or subtractive). Instead, the receptive fields of individual neurons are dynamically and selectively reshaped by the surround.</p>
<p>Divisive inhibition of each input by the surround accounts for experimental evidence showing that neural receptive fields are constantly reshaped by the spatiotemporal context of presented stimuli [<xref ref-type="bibr" rid="pcbi.1005582.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1005582.ref009">9</xref>]. Importantly, these contextual changes in neural RFs and tuning curves do not imply variations in the stimulus features encoded by each neuron. Rather, variable receptive fields are <italic>required</italic> in order to maintain an invariant neural code that can be read-out consistently by downstream neurons.</p>
<p>Note that this framework is normative and does not depend on how it is implemented at the neuronal level. However, in order to provide more specific predictions, we show that optimal estimation can be performed within a plausible neural circuit in which excitatory neurons undergo divisive inhibition from local interneurons. Neurons in that circuit exhibit general properties of sensory neural responses including response saturation, gain modulation by background stimuli and contrast-dependent temporal dynamics. For a subclass of ‘simple’ stimuli, the responses of excitatory neurons in this network can be phenomenologically described using the canonical divisive normalization model of Heeger et al. [<xref ref-type="bibr" rid="pcbi.1005582.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref010">10</xref>–<xref ref-type="bibr" rid="pcbi.1005582.ref014">14</xref>]. This accounts for why divisive normalization appears so ubiquitously across different sensory areas and organisms. It further suggests avenues for how this canonical model may need to be extended to account for the richness and selectivity of surround suppression and contextual modulation in general.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Competition &amp; integration in perceptual inference</title>
<p>To interact effectively with our environment, we need to know ‘what’s there’. Thus, perception can be viewed as an inference problem, in which sensory systems infer which combination of stimuli is the most likely, given the noisy signals they receive. Perceptual inference requires basic assumptions about how sensory signals are generated by external stimuli, which can be expressed mathematically using a ‘generative model’. Here, we consider a simple generative model, in which multiple positive stimulus features, <bold><italic>x</italic></bold> = (<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, …, <italic>x</italic><sub><italic>n</italic></sub>), combine linearly to activate a population of neural inputs, <bold><italic>s</italic></bold> = (<italic>s</italic><sub>1</sub>, <italic>s</italic><sub>2</sub>, …, <italic>s</italic><sub><italic>n</italic></sub>). The mean expected response of the <italic>j</italic><sup><italic>th</italic></sup> input to a stimulus, <bold><italic>x</italic></bold>, is:
<disp-formula id="pcbi.1005582.e001"><alternatives><graphic id="pcbi.1005582.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mrow><mml:mrow><mml:mo>〈</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:mfenced close=")" open="("><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mfenced> <mml:mo>〉</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:munder> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>x</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>w</italic><sub><italic>jk</italic></sub> describes how strongly the <italic>j</italic><sup><italic>th</italic></sup> input is activated by the <italic>k</italic><sup><italic>th</italic></sup> stimulus feature and <italic>w</italic><sub>0</sub> describes its mean activity when all stimulus features are zero. The presumed goal of sensory processing is to estimate stimulus features, <inline-formula id="pcbi.1005582.e002"><alternatives><graphic id="pcbi.1005582.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, from the received input, <bold><italic>s</italic></bold>.</p>
<p>Consider a population of neurons that encodes stimulus features, <inline-formula id="pcbi.1005582.e003"><alternatives><graphic id="pcbi.1005582.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, via their firing rates, <inline-formula id="pcbi.1005582.e004"><alternatives><graphic id="pcbi.1005582.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. While the stimulus features cannot usually be estimated directly by pooling the neural inputs, we can set up dynamics of the network so that the encoded features, <inline-formula id="pcbi.1005582.e005"><alternatives><graphic id="pcbi.1005582.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, converge to the most likely solution. This will be satisfied if the encoded stimulus features vary in time according to,
<disp-formula id="pcbi.1005582.e006"><alternatives><graphic id="pcbi.1005582.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e006" xlink:type="simple"/><mml:math display="block" id="M6"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mi>η</mml:mi> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mspace width="1pt"/> <mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula>
where <inline-formula id="pcbi.1005582.e007"><alternatives><graphic id="pcbi.1005582.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:mi>p</mml:mi> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> describes the probability that a stimulus, <inline-formula id="pcbi.1005582.e008"><alternatives><graphic id="pcbi.1005582.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, would give rise to neural inputs <bold><italic>s</italic></bold>, and <italic>η</italic> is a free parameter determining how quickly the estimates vary in time. These dynamics ensure that the encoded stimulus features, <inline-formula id="pcbi.1005582.e009"><alternatives><graphic id="pcbi.1005582.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, converge on a local maximum of <inline-formula id="pcbi.1005582.e010"><alternatives><graphic id="pcbi.1005582.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mrow><mml:mi>p</mml:mi> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> [<xref ref-type="bibr" rid="pcbi.1005582.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref016">16</xref>].</p>
<p>The neural dynamics required to implement the <xref ref-type="disp-formula" rid="pcbi.1005582.e006">Eq 2</xref> will depend critically on the input statistics, described by <inline-formula id="pcbi.1005582.e011"><alternatives><graphic id="pcbi.1005582.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mrow><mml:mi>p</mml:mi> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. In particular, different assumptions about the <italic>reliability</italic> of the neural inputs will lead to qualitatively very different predictions.</p>
<p>A common experimental observation is that sensory neurons exhibit <italic>signal-dependent noise</italic>, in which the trial-by-trial variance in single neuron firing rates scales proportionally with their mean firing rate [<xref ref-type="bibr" rid="pcbi.1005582.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref005">5</xref>]. When neural inputs are corrupted by independent <italic>Poisson</italic> noise (a paradigmatic signal-dependent distribution), <xref ref-type="disp-formula" rid="pcbi.1005582.e006">Eq 2</xref> becomes:
<disp-formula id="pcbi.1005582.e012"><alternatives><graphic id="pcbi.1005582.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mi>η</mml:mi> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>k</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula></p>
<p>Thus, the estimate of each stimulus feature varies in time according to a linear sum of ‘fractional prediction errors’, <inline-formula id="pcbi.1005582.e013"><alternatives><graphic id="pcbi.1005582.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:mfrac><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>〈</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo> <mml:mo>〉</mml:mo></mml:mrow></mml:mfrac> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, equal to the ratio between the received input and the mean predicted input (given the current estimate), minus one (see section 1 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref> for derivation). If the received input is equal to the predicted input, then the fractional prediction error is zero, and the estimate does not change. However, if the received input is larger or smaller than the predicted input, then the estimate is updated to reduce the error.</p>
<p>Importantly, dividing the received input by the predicted input is necessary to perform optimal estimation given many different types of signal-dependent noise—as long as the variance in each input is proportional to its mean (section 1 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>). Poisson input is but one example of such signal-dependent noise statistics. Furthermore, while noise correlations will introduce further terms to <xref ref-type="disp-formula" rid="pcbi.1005582.e012">Eq 3</xref>, these additional terms also require dividing the received input by the predicted input (section 2 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>).</p>
<p>We note that ‘noise’ in our model refers to trial-by-trial variability of neural inputs, <italic>s</italic>, given fixed external stimulus features, <italic>x</italic>. In contrast, the dynamics of the model network, described by <xref ref-type="disp-formula" rid="pcbi.1005582.e012">Eq 3</xref>, are deterministic (see <xref ref-type="sec" rid="sec009">Discussion</xref>).</p>
<p>In <xref ref-type="disp-formula" rid="pcbi.1005582.e012">Eq 3</xref>, each input (<italic>s</italic><sub><italic>j</italic></sub>) is divided by a different factor <inline-formula id="pcbi.1005582.e014"><alternatives><graphic id="pcbi.1005582.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>〈</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo> <mml:mo>〉</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, before being combined with other inputs. Thus, any neural network implementation of <xref ref-type="disp-formula" rid="pcbi.1005582.e012">Eq 3</xref> will need to normalize different inputs separately, <italic>before</italic> they are combined (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1c</xref>).</p>
<p>For comparison, let us consider an artificial example with the input signal corrupted by constant Gaussian noise, whose magnitude is independent of the signal strength. In such a scenario, the estimate of each feature would evolve as a function of the <italic>absolute</italic> (rather than the ‘fractional’) prediction errors, <inline-formula id="pcbi.1005582.e015"><alternatives><graphic id="pcbi.1005582.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. <xref ref-type="disp-formula" rid="pcbi.1005582.e012">Eq 3</xref> could then be separated into two linear terms: a feedforward input and a subtractive lateral inhibition term (see <xref ref-type="sec" rid="sec017">Methods</xref>). Moreover, steady neural responses could be described as applying a ‘center-surround’ feedforward receptive field to the stimulus. Thus, if sensory noise was constant Gaussian and not signal dependent, competition between encoded features would result in a global ‘inhibitory surround’, separable from a static feed-forward ‘center’ (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1b</xref>).</p>
<p>In the rest of the paper we refer to the network assuming constant Gaussian noise as the ‘subtractive model’, as opposed to the model assuming signal-dependent noise, which we call the ‘divisive’ model.</p>
</sec>
<sec id="sec004">
<title>Reshaping of sensory receptive fields and tuning curves by the context</title>
<p>To relate the estimation algorithm described in the previous section to neural data, we make the basic assumption that each neuron encodes a single stimulus feature, with firing rate proportional to the estimated feature (<inline-formula id="pcbi.1005582.e016"><alternatives><graphic id="pcbi.1005582.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>∝</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>; see later for neural implementation).</p>
<p>The divisive model described by <xref ref-type="disp-formula" rid="pcbi.1005582.e012">Eq 3</xref> requires selective inhibition of specific neural inputs, before they are combined. Thus, if certain inputs are predicted by the stimulus context, they will be inhibited, and the neuron will become differentially less responsive to them. As a result, a neuron’s stimulus selectivity will be reshaped by the context. In contrast, in the subtractive model (see <xref ref-type="sec" rid="sec017">Methods</xref>), inhibition acts globally to alter the magnitude of neural responses, but not their stimulus selectivity.</p>
<p>To illustrate this, we first consider a simple generative model, where each stimulus feature is assumed to activate two neighbouring sensory inputs. This results in the network shown in <xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2a</xref>, where each neuron receives two equal strength inputs from neighbouring locations in the previous layer. With both subtractive and divisive models, each neuron responds equally strongly to both its inputs (‘no context’ condition; <xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2b</xref>), while being suppressed by contextual ‘surround’ stimuli, that do not elicit a response when presented alone. However, in the divisive model inhibition selectively targets certain inputs, so that a surround stimulus only suppresses a neuron’s response to <italic>nearby</italic> inputs (that are ‘predicted’ by the surround). As a result, neurons respond less strongly to stimuli presented in parts of their receptive field that are near the surround (‘adjoint context’; <xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2b</xref>), than to stimuli presented far from the surround (‘disjoint context’). In contrast, the subtractive model predicts the same degree of surround suppression, regardless of the location of stimuli within the cell’s receptive field.</p>
<fig id="pcbi.1005582.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005582.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Input-targeted inhibition alters neural selectivity.</title>
<p>(a) Schematic of neural network, with input-targeted feedback. (b) Steady-state response responses of recorded neuron, predicted by model with input-targeted divisive feedback, or subtractive inhibition. There are three stimulus conditions: (i) ‘no context’ condition, with a single stimulus within the cell’s RF; (ii) ‘adjoint context’ condition, with a second stimulus in the surround, near to the stimulus within the RF and (iii) ‘disjoint context’ condition, with a second stimulus in the surround, far from the stimulus within the RF. (c) Contextual shifts in neural tuning curves. Each neuron encodes a stimulus features (e.g. orientation, or motion direction) with a given preferred value. The mean response of a single neuron is plotted against the presented stimulus value, in the absence (black) or presence of an overlapping mask, to the right or left of the neuron’s preferred stimulus (blue and red). (c, lower panel) As above, but for an LN model. (d) Simulation of network in which cells encode stimuli in a circular region of space. (top panel) Estimated RF, with random sparse stimulus. (lower panel) Estimated RF in presence of vertical mask. The measured RF is elongated in the horizontal direction. (e) As for panel d, but for an LN model.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.g002" xlink:type="simple"/>
</fig>
<p>A further and related consequence of input-targeted inhibition, is that neural tuning curves are reshaped by contextual stimulation. To illustrate this effect, we considered a generative model in which stimulus features activate nearby sensory inputs, arranged along a single dimension (e.g. representing the orientation of a presented visual stimulus). In the resulting network, neurons responded with bell shaped tuning curves to presented stimuli (<xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2c</xref>, top left panel; see <xref ref-type="sec" rid="sec017">Methods</xref>). An overlapping ‘mask’ stimulus, that did not activate a given neuron when presented alone, selectively inhibits inputs to the neuron that overlap with the mask. As a result, the neuron’s tuning curve was reduced in magnitude and shifted <italic>away</italic> from the mask (<xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2c</xref>, top left panel). This effect is qualitatively similar to contextual shifts in neural tuning curves observed experimentally in cat primary visual cortex (<xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2c</xref>, top right panel) [<xref ref-type="bibr" rid="pcbi.1005582.ref006">6</xref>].</p>
<p>As a control, we considered a ‘linear-nonlinear’ (LN) model, with responses obtained by a filter followed by a threshold non-linearity: <italic>r</italic><sub><italic>i</italic></sub> = <italic>f</italic>(∑<sub><italic>j</italic></sub> <italic>v</italic><sub><italic>ji</italic></sub><italic>s</italic><sub><italic>j</italic></sub>). Linear weights were fitted to match, as closely as possible, the responses of the divisive model across all three stimulus conditions (see <xref ref-type="sec" rid="sec017">Methods</xref>). As shown in <xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2c</xref> (lower panel) an LN model was unable to produce the shifts in neural tuning curves observed with the divisive model.</p>
<p>In addition to shifting neural tuning curves, input-targeted divisive inhibition also results in dynamic reshaping of neural receptive fields (RFs). To illustrate this, we extended our previous generative model, to consider the case where presented stimulus features activate sensory inputs, arranged along <italic>two</italic> spatial dimensions. Neural RFs, estimated using reverse correlation with random sparse stimuli (see <xref ref-type="sec" rid="sec017">Methods</xref>), exhibited a ‘centre-surround’ structure, with a central excitatory region surrounded by an inhibitory region (<xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2d</xref>, above). However, simultaneously presenting an overlapping grating stimulus dramatically reshaped the estimated RFs, which were elongated orthogonal to the grating (<xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2d</xref>, below). No such contextual shifts in RFs was observed with an LN model (<xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2e</xref>).</p>
<p>Previously, Meister et al. showed that presenting an orientated grating stimulus over a period of several seconds leads to a reshaping of retinal ganglion cell RFs, qualitatively similar to what we observed in our model [<xref ref-type="bibr" rid="pcbi.1005582.ref017">17</xref>]. (However, note that to properly model the effects of temporal adaption would require extending our work to consider optimal estimation of temporally dynamic stimuli) [<xref ref-type="bibr" rid="pcbi.1005582.ref018">18</xref>].</p>
<p>In early visual areas, where neural RFs are localized within a single region of space, our model predicts simple shifts in neural RFs, as shown in <xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2d</xref>. However, in other sensory modalities (e.g. olfaction/audition), where neural RFs have a more complex structure, contextual reshaping of neural RFs could be more complex [<xref ref-type="bibr" rid="pcbi.1005582.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref020">20</xref>]. To illustrate this, we considered a generative model in which individual sensory features (e.g. presented odors) produce a distributed and multi-modal activation of sensory receptors, as shown in <xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3a</xref> (upper panels; see <xref ref-type="sec" rid="sec017">Methods</xref>). We measured the RFs of neurons in response to a random sparse stimulus plus a contextual mask that activated a small subset of nearby receptors. The contextual mask led to complex changes in neural RFs that could not be characterised as a simple repulsive shift away from the context (<xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3a</xref>). Moreover, the observed reshaping of neural RFs was highly non-local: contextual activation of nearby receptors affected distant regions of a cell’s RF.</p>
<fig id="pcbi.1005582.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005582.g003</object-id>
<label>Fig 3</label>
<caption>
<title/>
<p>(a) Contextual reshaping of multimodal RFs. Each neuron encodes a stimulus feature (e.g. an odor) that is assumed to elicit a multimodal pattern of sensory activity (upper panels). Neural RFs are measured in the presence of a mask stimulus that activates a small number of nearby receptors. For the three cells shown, recorded RFs undergo complex, non-local changes in the presence of the contextual mask. (b) Reshaping of neural RFs in a simplified network of three neurons, which encode the letters ‘V’, ‘I’, and ‘A’. (c) The RF of a neuron encoding the letter ‘I’ is significantly altered by a contextual stimulus designed to selectively activate one of the other two neurons in the network.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.g003" xlink:type="simple"/>
</fig>
<p>To explain intuitively this contextual reshaping of neural RFs, we considered a toy generative model consisting of three stimulus features, which produce patterns of sensory activation resembling the letters ‘V’ ‘A’ and ‘I’, respectively (<xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3b</xref>). We measured the RF of the neuron encoding the letter ‘I’ in response to random sparse stimuli, and in the presence of an overlapping contextual stimulus (<xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3c</xref>). Because of the simplicity of this network, we can understand how the contextual stimuli reshape the neuron’s RF. For example, the first contextual stimulus strongly activated the neuron encoding the letter ‘A’ (<xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3c</xref>, top left) leading to targeted inhibition of neural inputs that overlap with the letter ‘A’. As a result, the recorded neuron became insensitive to these inputs, and they did not form part of its recorded RF (<xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3c</xref>, top right). An analogous effect occurred with a contextual stimulus designed to activate the neuron encoding the letter ‘V’ (<xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3c</xref>, lower panels). Note that this contextual reshaping of neural RFs occurred because inhibition was targeted on a subset of neural inputs (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1c</xref>); it would not occur in a network with global inhibition, that acted directly on neural responses (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1b</xref>).</p>
</sec>
<sec id="sec005">
<title>Adaptive receptive fields alongside invariant neural code</title>
<p>The observation that neurons have highly variable RFs could lead one to conclude that the neural code also varies with stimulus context. However, note that each neuron always encodes a fixed stimulus feature, as defined by the generative weights <italic>w</italic><sub><italic>ij</italic></sub>. As a result, the neural responses can always be read-out in the same way by the downstream neurons, by interpreting the activity of each neuron as indicating the presence of its preferred feature. For this same reason, our model can be extended to hierarchical frameworks where each layer predicts the responses of the layer below (section 3 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>). The resulting neural code is thus ‘fixed’ (as defined by the features <italic>w</italic><sub><italic>ij</italic></sub>), and the neural representation is ‘invariant’ (in the sense that sensory neurons always represent the same objects, regardless of context). However, in order to maintain this fixed code, neurons in the network need to have variable RFs, that adapt depending on the stimulus context (<xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4a</xref>).</p>
<fig id="pcbi.1005582.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005582.g004</object-id>
<label>Fig 4</label>
<caption>
<title/>
<p>(a) Schematic illustrating how contextual shifts in neural tuning curves required for a context-invariant neural code. (b) Contextual mask presented in each condition. (c, left panel) Tuning curve of a model neuron in the presence of the three different stimulus masks (tuning curves are rescaled, to have zero mean and unitary standard-deviation). (right panel) Inferred readout filters for the same neuron in each condition. (d) As for panel c, but for an LN model. (e) Mean squared difference in (rescaled) tuning curves across the different stimulus contexts. Each cell corresponds to one data point. The example cell, plotted in panels c-d is shown in red. (f) Identical analysis to panel e, but applied to the linear readout filters. (g) Normalized reconstruction error using ‘correct’ readout filters for each stimulus condition (blue bars), or ‘mismatched’ decoders, inferred in other stimulus conditions.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.g004" xlink:type="simple"/>
</fig>
<p>To illustrate this idea, we return to our earlier simulation with bell-shaped tuning curves, shown in <xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2c</xref>. This time, however, we plotted neural tuning curves in the presence of three different ‘contexts’ (<xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4b</xref>; each context was a ‘mask’, constructed from a random combination of ‘background’ stimulus features; these masks were constantly added to the inputs used to measure the tuning curve and estimate the read-out weights). As before, the tuning curves were shifted by the context (<xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4c</xref>, left panel; tuning curves are rescaled and shifted to have the same magnitude and zero mean). Next, we trained ‘readout filters’ to linearly reconstruct the inputs from the neural responses (see <xref ref-type="sec" rid="sec017">Methods</xref>). As could be expected, these were similar to the actual read-out weights <italic>w</italic><sub><italic>ij</italic></sub>. In particular, and in sharp contrast with the tuning curves, which were shifted by context, readout filters were almost completely invariant to changes in context (<xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4c</xref>, right panel).</p>
<p>For comparison, we repeated the same procedure with an LN model (<xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4d</xref>). As seen previously, in this model neural tuning curves are not shifted by context (only their gain is changed, which does not appear on the re-scaled tuning curves). However, readout filters <italic>were</italic> altered by context, meaning that in each context, downstream neurons would have to integrate responses from the network differently (depending to the context) in order to reconstruct the stimulus.</p>
<p>As shown in <xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4e and 4f</xref>, the same qualitative effects were observed for the tuning curves and readout filters across the entire neural population, in addition to the example cell shown in <xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4c and 4d</xref>.</p>
<p>Finally, we quantified the reconstruction error across all three conditions (normalized rms error), obtained with the ‘correct’ readout filter (i.e. trained on responses obtained with the same mask; <xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4g</xref>, blue bars), compared with a ‘mismatched’ decoder (trained in different conditions; <xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4g</xref>, red bars). In the input-targeted inhibition model, similar performance was achieved in either case, as the readout filter did not change significantly across conditions. In contrast, in the LN model performance was drastically reduced when using a mismatched decoder, learned in a different context.</p>
<p>Our results suggest that, rather than trying to describe neural responses using a static ‘encoder model’ (e.g. tuning curves or RFs) one may be able to fit a simpler context-invariant ‘decoder model’, describing how to reconstruct the stimulus from neural responses. Experimental support for this is provided by Marre et al. who were able recover a highly accurate reconstruction of a moving bar stimulus from a simple linear readout of retinal ganglion cell responses [<xref ref-type="bibr" rid="pcbi.1005582.ref021">21</xref>]. In contrast, neural responses in their experiment were poorly described by an LN model.</p>
<p>The advantages of input-targeted divisive inhibition are also seen when discriminating between similar features, presented together. To demonstrate this, we returned to the earlier model with multimodal distributed features, shown in <xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3a</xref>. We considered neural responses to combinations of three similar stimulus features, encoded by different neurons in the network (<xref ref-type="fig" rid="pcbi.1005582.g005">Fig 5a</xref>): feature 1 presented alone, and alongside feature 2 or 3 (<xref ref-type="fig" rid="pcbi.1005582.g005">Fig 5b</xref>). <xref ref-type="fig" rid="pcbi.1005582.g005">Fig 5c</xref> plots the response of five feature-selective neurons. Despite the fact that the three features activated highly overlapping sets of receptors, neural responses were highly specific, with only neurons that encode the presented odors responding on a given trial. In contrast, an LN model could not achieve this degree of specificity (<xref ref-type="fig" rid="pcbi.1005582.g005">Fig 5d</xref>).</p>
<fig id="pcbi.1005582.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005582.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Input-targeted inhibition allows for discrimination of similar stimulus features.</title>
<p>(a) Three different stimulus features (e.g. odors) encoded by different neurons in the network. The plots show the overlapping pattern of receptor activation elicited by each feature. (b) Three different combinations of features presented to the network. (c) Neural responses to each feature combination, obtained from the input-targeted divisive inhibition model. The response of each neuron is highly specific to its encoded feature, even with multiple overlapping features presented simultaneously. (d) As for panel c, but with an LN model, trained to match the responses of the divisive input model, to a range of different presented feature combinations. In contrast to before, neurons respond non-specifically when similar featue are presented together.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec006">
<title>Neural implementation</title>
<p>The estimation algorithm described by <xref ref-type="disp-formula" rid="pcbi.1005582.e012">Eq 3</xref> could be implemented in more than one way within a neural network. The most direct implementation would be for each neuron to encode a single stimulus feature, with firing rate proportional to the estimated feature (<inline-formula id="pcbi.1005582.e017"><alternatives><graphic id="pcbi.1005582.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>∝</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>). In this case each neuron needs to selectively inhibit the input synapses of neurons encoding different features, as shown in <xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6a</xref>. The response of each neuron evolves in time according to:
<disp-formula id="pcbi.1005582.e018"><alternatives><graphic id="pcbi.1005582.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e018" xlink:type="simple"/><mml:math display="block" id="M18"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>∝</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mfenced close=")" open="("><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mfenced> <mml:mspace width="1pt"/><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mtext>const</mml:mtext></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
where <inline-formula id="pcbi.1005582.e019"><alternatives><graphic id="pcbi.1005582.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">r</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is an ‘effective input weight’, obtained by dividing the feed-forward weight, <italic>w</italic><sub><italic>ji</italic></sub>, by the responses of other neurons in the network, according to: <inline-formula id="pcbi.1005582.e020"><alternatives><graphic id="pcbi.1005582.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mspace width="1pt"/> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">r</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>r</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. As a result, feedback connections alter the effective weighting of each input, thereby altering neural stimulus selectivity.</p>
<fig id="pcbi.1005582.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005582.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Proposed neural implementation.</title>
<p>(a) Example network in which each stimulus feature is encoded by an excitatory neuron that projects to higher level areas. Divisive inhibition acts on individual synaptic inputs. (b) Example network with two neural populations: excitatory neurons encode the ratio between the received and predicted input, <inline-formula id="pcbi.1005582.e021"><alternatives><graphic id="pcbi.1005582.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mfrac><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>〈</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo> <mml:mo>〉</mml:mo></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>, while inhibitory neurons encode estimated stimulus features, <inline-formula id="pcbi.1005582.e022"><alternatives><graphic id="pcbi.1005582.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>. (c) Example of a hierarchical network. The fractional prediction error encoded in a given layer is integrated by downstream neurons, which encode more complex stimulus features. (d) Divisive gain control. (left) A ‘test’ stimulus activates the input to the recorded neuron (indicated with arrow), while a mask stimulus activates the input to the other neuron. Response of recorded neuron is plotted versus amplitude of the test stimulus. Each plot corresponds to a different amplitude mask (see legend).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.g006" xlink:type="simple"/>
</fig>
<p>There are two reasons why neural dynamics described by <xref ref-type="disp-formula" rid="pcbi.1005582.e018">Eq 4</xref> may not be biologically plausible, at least in the cortex. First, the network violates Dale’s law: neurons are required to send both excitatory projection to higher sensory layers and inhibitory feedback to other neurons in the same area. Second, it requires a highly selective form of feedback, targeted on individual synapses (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6a</xref>).</p>
<p>To overcome these issues, we propose an alternative network that consists of two distinct neural populations: excitatory neurons that encode the ratio between the received and predicted input, <inline-formula id="pcbi.1005582.e023"><alternatives><graphic id="pcbi.1005582.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:mfrac><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>〈</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo> <mml:mo>〉</mml:mo></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>, and inhibitory neurons that encode stimulus features, <inline-formula id="pcbi.1005582.e024"><alternatives><graphic id="pcbi.1005582.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula> (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6b</xref>). Each excitatory neuron receives feed-forward input from one receptor type, and lateral inhibition from interneurons. Its response evolves in time as:
<disp-formula id="pcbi.1005582.e025"><alternatives><graphic id="pcbi.1005582.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e025" xlink:type="simple"/><mml:math display="block" id="M25"><mml:mrow><mml:mi>a</mml:mi> <mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>x</mml:mi> <mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>w</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:munder> <mml:mspace width="1pt"/><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>n</mml:mi> <mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mfenced> <mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>x</mml:mi> <mml:mi>c</mml:mi></mml:mrow></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula>
where <italic>a</italic> is a constant that (along with the magnitude of inhibition) determines the of timescale of excitatory responses.</p>
<p>Inhibition acts multiplicatively on the leak term in the firing rate dynamics (see <xref ref-type="sec" rid="sec009">Discussion</xref> for biophysical mechanism). These dynamics ensure that in the steady state the response of each excitatory neuron is equal to the <italic>ratio</italic> of its excitatory and inhibitory input: <inline-formula id="pcbi.1005582.e026"><alternatives><graphic id="pcbi.1005582.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>x</mml:mi> <mml:mi>c</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:msub><mml:mi>w</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>n</mml:mi> <mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. (Note that, unlike classical subtractive predictive coding, in the case where sensory inputs are perfectly predicted by the network, excitatory responses are equal to unity, not zero).</p>
<p>Inhibitory neurons receive lateral input from nearby excitatory neurons. Their responses evolve in time according to:
<disp-formula id="pcbi.1005582.e027"><alternatives><graphic id="pcbi.1005582.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e027" xlink:type="simple"/><mml:math display="block" id="M27"><mml:mrow><mml:mi>b</mml:mi> <mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>n</mml:mi> <mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mspace width="1pt"/><mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>x</mml:mi> <mml:mi>c</mml:mi></mml:mrow></mml:msubsup> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(6)</label></disp-formula>
where <italic>b</italic> determines the rate that inhibitory neurons integrate their input. In the steady state (i.e. when <inline-formula id="pcbi.1005582.e028"><alternatives><graphic id="pcbi.1005582.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:msub><mml:mi>w</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>n</mml:mi> <mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>), this equation is equivalent to the optimal estimation algorithm shown in <xref ref-type="disp-formula" rid="pcbi.1005582.e012">Eq 3</xref>. Thus, in the steady state, the response of each inhibitory neuron will be proportional to an encoded feature, <inline-formula id="pcbi.1005582.e029"><alternatives><graphic id="pcbi.1005582.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>n</mml:mi> <mml:mi>h</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mi>o</mml:mi> <mml:mi>p</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. Both excitatory and inhibitory neural responses are constrained to be positive.</p>
<p>Stimulus features can be recovered by neurons in higher-level areas by temporally integrating the responses of the excitatory neurons (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6c</xref> and section 3 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>). Thus, the network implements a form of ‘predictive coding’, in which the <italic>fractional prediction errors</italic>, rather than the estimated stimulus features themselves, are communicated to higher level sensory areas [<xref ref-type="bibr" rid="pcbi.1005582.ref001">1</xref>]. In the following sections we will explore the implications of input-targeted divisive inhibition in the context of this ‘predictive coding’ network.</p>
</sec>
<sec id="sec007">
<title>Sensory gain control</title>
<p>We investigated how divisive inhibition modulates the steady state responses of excitatory neurons, which encode the fractional prediction error. We first considered a very simple model composed of only two sensory receptors, both activated by a single stimulus feature. The corresponding neural network consists of two excitatory neurons that connect with equal strength to one inhibitory neuron (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6d</xref>, left).</p>
<p>In this network, the sustained response of each excitatory neuron is simply equal to its feed-forward input, divided by the total rectified input to the network (section 4 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>):
<disp-formula id="pcbi.1005582.e030"><alternatives><graphic id="pcbi.1005582.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e030" xlink:type="simple"/><mml:math display="block" id="M30"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>x</mml:mi> <mml:mi>c</mml:mi></mml:mrow></mml:msubsup> <mml:mo>∝</mml:mo> <mml:mfrac><mml:msub><mml:mi>s</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula>
This equation bears strong similarity to the canonical divisive normalization equation, developed by Heeger et al. [<xref ref-type="bibr" rid="pcbi.1005582.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref022">22</xref>]. Thus, our normative framework parsimoniously predicts the nonlinearities seen in previous phenomenological models of divisive normalization.</p>
<p>When the feed-forward input to neuron 1 is very weak (i.e. <italic>s</italic><sub>1</sub> ≪ <italic>s</italic><sub>2</sub>), the denominator of <xref ref-type="disp-formula" rid="pcbi.1005582.e030">Eq 7</xref> is constant, and the neuron’s responses increases linearly with input strength. When the feed-forward input to neuron 1 is very strong (i.e. <italic>s</italic><sub>1</sub> ≫ <italic>s</italic><sub>2</sub>), on the other hand, the numerator and denominator of <xref ref-type="disp-formula" rid="pcbi.1005582.e030">Eq 7</xref> approach equality, and the neuron’s response saturates. Plotted on a logarithmic scale, this gives rise to a sigmoidal input-response curve (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6d</xref>) [<xref ref-type="bibr" rid="pcbi.1005582.ref002">2</xref>].</p>
<p>Lateral inhibition from a ‘mask’ stimulus that does not provide direct input to neuron 1 (i.e. it activates <italic>s</italic><sub>2</sub> only), suppresses the neuron’s response [<xref ref-type="bibr" rid="pcbi.1005582.ref045">45</xref>]. When <italic>s</italic><sub>1</sub> ≫ <italic>w</italic><sub>0</sub>, the effect of the mask is to add an additional constant to the denominator of <xref ref-type="disp-formula" rid="pcbi.1005582.e030">Eq 7</xref>, shifting the neuron’s input-response curve to the right on a logarithmic scale (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6d</xref>). Consequently, a stronger feed-forward input is required to elicit the same neural response.</p>
<p>A mask stimulus that provides weak input to neuron 1 and strong input to neuron 2 (i.e. it weakly activates <italic>s</italic><sub>1</sub>, and strongly activates <italic>s</italic><sub>2</sub>, as shown on <xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6e</xref>) can both suppress or facilitate the response of neuron 1, depending on the strength of the neuron’s feed-forward input [<xref ref-type="bibr" rid="pcbi.1005582.ref002">2</xref>]. When the feed-forward input to neuron 1 is very weak, the denominator of <xref ref-type="disp-formula" rid="pcbi.1005582.e031">Eq 8</xref> is constant (due to rectification), and the neuron linearly sums its feed-forward inputs. As a result, its response is facilitated by the mask (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6e</xref>). When the feed-forward input to neuron 1 is strong, the mask increases the size of the denominator, suppressing the neuron’s response (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6e</xref>).</p>
<p>The results described above also apply to larger networks consisting of many excitatory and inhibitory neurons. Indeed, for “simple” inputs that do not activate multiple overlapping feature detectors, the sustained response of each excitatory neuron is approximately equal to its feed-forward input, divided by the summed input to nearby neurons (Section 4 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>):
<disp-formula id="pcbi.1005582.e031"><alternatives><graphic id="pcbi.1005582.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>x</mml:mi> <mml:mi>c</mml:mi></mml:mrow></mml:msubsup> <mml:mo>∝</mml:mo> <mml:mfrac><mml:msub><mml:mi>s</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo form="prefix" movablelimits="true">max</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(8)</label></disp-formula></p>
<p>Thus, the classical normalization model [<xref ref-type="bibr" rid="pcbi.1005582.ref010">10</xref>], that was originally designed to provide a phenomenological description of non-linearities in neural responses, emerges as a special case of our proposed dynamics.</p>
</sec>
<sec id="sec008">
<title>Temporal dynamics of neural responses</title>
<p>We next investigated the temporal dynamics of excitatory and inhibitory neural responses to a constant stimulus in the simple, two neuron network described in the previous section (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6d</xref>, left panel). Following stimulus onset, the response of the activated excitatory neuron, encoding the fractional error signal, exhibited a transient peak in activity followed by a decay (<xref ref-type="fig" rid="pcbi.1005582.g007">Fig 7a</xref>). At the same time, the response of the inhibitory neuron, which encoded the sensory estimate, increased continuously towards the steady state (<xref ref-type="fig" rid="pcbi.1005582.g007">Fig 7b</xref>). This qualitative behaviour is a general property of predictive coding, and thus also occurred for the subtractive model, where excitatory neurons encoded the absolute (rather than the fractional) error (<xref ref-type="fig" rid="pcbi.1005582.g007">Fig 7c and 7d</xref>).</p>
<fig id="pcbi.1005582.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005582.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Predicted temporal response profile.</title>
<p>(a, left) Temporal response profile of excitatory neuron, to a constant feed-forward input of varying strength. (right) Instantaneous response of the excitatory neuron versus amplitude of feed-forward input. Each plot corresponds to a fixed time after stimulus presentation (indicated by vertical dashed lines in left panel). (b) Same as (a), but for an inhibitory model neuron. (c-d) Same as a-b, but for a model with subtractive, rather than divisive inhibition.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.g007" xlink:type="simple"/>
</fig>
<p>What distinguishes the subtractive and divisive models was the input-depencence of the neural dynamics. For the divisive model, the timescale of excitatory neural responses decreased with the sensory input, resulting in a shorter time to peak response with higher amplitude inputs (<xref ref-type="fig" rid="pcbi.1005582.g007">Fig 7a</xref>). This is because the leak term in the excitatory neural dynamics (which implements divisive inhibition) is proportional to its inhibitory input <xref ref-type="disp-formula" rid="pcbi.1005582.e025">Eq (5)</xref>. Thus, the greater a neuron’s inhibitory input, the quicker its response varies in time. In contrast, the temporal dynamics of the subtractive model were input-invariant.</p>
<p>Recent experiments using voltage sensitive dye to measure V1 responses reported contrast-dependent temporal dynamics, consistent with our model [<xref ref-type="bibr" rid="pcbi.1005582.ref023">23</xref>]. Similarly, Albrecht et al. [<xref ref-type="bibr" rid="pcbi.1005582.ref024">24</xref>] observed that the time to peak firing rate response decreases with visual contrast. However, Albrecht et al also reported that temporally shifting firing rate responses to compensate for contrast-dependent variations in onset latency resulted in temporal response profiles that were approximately contrast invariant. This discrepancy between voltage data and firing rate data could be accounted for by including a firing threshold into our model.</p>
<p>When put into the context of a larger, topographically organized sensory layer, the temporal dynamics of the divisive model could parsimoniously account for the presence of ‘traveling waves’ observed in the visual cortex, where a presented stimulus generates a wave of activity that spreads gradually outwards from a single cortical location (<xref ref-type="fig" rid="pcbi.1005582.g008">Fig 8a</xref>) [<xref ref-type="bibr" rid="pcbi.1005582.ref025">25</xref>]. According to our model, traveling waves will occur when the input generated by a stimulus varies in strength with cortical location [<xref ref-type="bibr" rid="pcbi.1005582.ref026">26</xref>] (<xref ref-type="fig" rid="pcbi.1005582.g008">Fig 8b</xref>). Neurons that receive strongest feed-forward input will respond quickest, followed by nearby neurons that receive weaker input. The resultant effect is a damped traveling wave that spreads outwards from neurons most strongly activated by the stimulus (<xref ref-type="fig" rid="pcbi.1005582.g008">Fig 8c</xref>). In contrast, with subtractive inhibition, the timecourse of neural responses does not depend on their distance from the input (<xref ref-type="fig" rid="pcbi.1005582.g008">Fig 8d</xref>).</p>
<fig id="pcbi.1005582.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005582.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Traveling waves in the visual cortex.</title>
<p>(a) Schematic of topographic model network, in which each inhibitory neuron connects with equal strength to two neighbouring excitatory neurons. The feed-forward input decreases with distance from the centre. (b) Heat map of excitatory neural responses, normalized by peak amplitude. Each row shows the response of a neuron at a specified distance from the centre. Filled and solid diamonds indicate at what time each neuron’s response is 70% of its maximum. The right panel indicates the maximum response of each neuron. (c) Same as c, but with subtractive, rather than divisive inhibition.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.g008" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec009" sec-type="conclusions">
<title>Discussion</title>
<sec id="sec010">
<title>Functional role of divisive inhibition</title>
<p>It has long been thought that divisive inhibition performs a kind of gain control, that keeps neural firing rates within their available dynamic range [<xref ref-type="bibr" rid="pcbi.1005582.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref028">28</xref>]. Here we provide an alternative interpretation, that divisive inhibition occurs as a consequence of optimal cue combination given sensory noise. When the variance of each input depends on its mean, some signals become more reliable than others. Divisive inhibition insures that each signal is weighted appropriately, before these signals are combined by downstream neurons.</p>
<p>In that sense, our work places itself in the more general framework of optimal cue combination [<xref ref-type="bibr" rid="pcbi.1005582.ref029">29</xref>] where each cue should be weighted according to its reliability before being combined. Human subjects are indeed able to perform such optimal cue combination [<xref ref-type="bibr" rid="pcbi.1005582.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref031">31</xref>], and are also able to implement explaining away, e.g. to resolve ambiguities by assigning inputs to their most likely sources [<xref ref-type="bibr" rid="pcbi.1005582.ref032">32</xref>]. Our model proposes that optimal cue combination and explaining away are already implemented at a microscopic level by sensory networks, through selective divisive gain modulation of sensory neural responses.</p>
<p>In contrast to the gain-control hypothesis, our framework precisely specifies the form of divisive inhibition required for optimal estimation, which should occur <italic>before</italic> individual inputs are combined (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1c</xref>). For simple stimuli, which activate only one feature detector at a time, the predicted neural responses are consistent with the classical divisive normalization model (Figs <xref ref-type="fig" rid="pcbi.1005582.g006">6</xref> and <xref ref-type="fig" rid="pcbi.1005582.g007">7</xref>). However, for more complex stimuli, which activate multiple overlapping feature detectors, input-targeted divisive inhibition results in dynamic changes in neural tuning properties and receptive field shapes (Figs <xref ref-type="fig" rid="pcbi.1005582.g002">2</xref> and <xref ref-type="fig" rid="pcbi.1005582.g003">3</xref>), not captured by the classical divisive normalization model.</p>
<p>A prediction of our model is that sensory normalisation will vary with changes in neural variability. Thus, future experimental tests of our work could investigate whether divisive normalisation is altered as expected by stimulus-dependent modulations in neural Fano-factor (see section 1.2 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>) and noise correlations (see section 2 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>) [<xref ref-type="bibr" rid="pcbi.1005582.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref034">34</xref>].</p>
</sec>
<sec id="sec011">
<title>Comparison with other functional accounts of divisive inhibition</title>
<p>Previously, Schwartz and Simoncelli showed that divisive normalisation can serve to remove statistical redundancies between neural responses, leading to a more efficient code [<xref ref-type="bibr" rid="pcbi.1005582.ref035">35</xref>]. In a later extension to this work, they showed that divisive normalisation can be interpreted as implementing ‘explaining away’ of global stimulus features (e.g. global image contrast) so as to permit optimal inference of local stimulus features (e.g local reflectance) [<xref ref-type="bibr" rid="pcbi.1005582.ref036">36</xref>].</p>
<p>While in both our model and that of Schwartz et al., divisive normalisation implements explaining away, their underlying assumptions are very different. In Schwartz et al.’s model, normalisation is predicted because of the assumed high-level structure of sensory signals, as being produced by multiplying local and global stimulus features. In contrast, in our model, divisive normalisation is predicted due to the biophysics of sensory signal transduction, which leads to sensory signals being corrupted by signal-dependent (and not Gaussian) noise.</p>
<p>Schwartz &amp; Simoncelli’s model also belongs to a broader class of normalisation models in which divisive occurs after sensory inputs have been combined [<xref ref-type="bibr" rid="pcbi.1005582.ref002">2</xref>]. In contrast, our model predicts that divisive normalisation should act directly on the inputs, before combination. As we showed (<xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2</xref>), such pre-combination divisive inhibition leads to flexible RFs, which are dynamically shifted by the stimulus context. In contrast, output-targetted divisive normalisation will only lead to such shifts in neural RFs when sensory inputs undergo an additional (e.g. quadratic) non-linearity before normalisation.</p>
<p>Previously Beck et al. proposed a new role for divisive normalisation in performing a probabilistic compuation known as ‘marginilisation’ [<xref ref-type="bibr" rid="pcbi.1005582.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref038">38</xref>]. This computation is required for many different tasks, in which one wants to infer a subset of ‘relevant’ stimulus features, while disregarding (i.e. marginilising) other irrelevant features. At some level, this explanation is related to Schwartz et al.’s work, where normalisation was assumed to factor out (i.e. marginilise) global fluctuations in the sensory input, so as to allow inferences about local features. However, Beck et al.’s model differs from both Schwartz et al. and our work, in that marginilisation is predicted as a result of a particular type of probabilistic neural population code.</p>
<p>In previous work, we proposed a model in which input-targeted divisive inhibition implements competition between different stimulus features. However, this model relied on a number of assumptions about sensory stimuli (e.g. that they were produced by binary stimulus features that had Markov temporal dynamics), as well as assumptions about the spiking neural code [<xref ref-type="bibr" rid="pcbi.1005582.ref018">18</xref>]. Here we show that input-targeted divisive inhibition emerges very generally, and irrespective of additional assumptions about the neural code and signal dynamics, so long as the sensory noise scales with the magnitude of the signal.</p>
<p>Recent experimental work suggested that in the ferret auditory cortex, neural responses adapt to the stimulus statistics in such a way as to allow behaviourally relevant signals to be extracted from background noise [<xref ref-type="bibr" rid="pcbi.1005582.ref039">39</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref040">40</xref>]. Interestingly, Mesgarini et al. showed that their results could be explained by top-down divisive feed-back. While the details of our model differ from that of Mesgarini et al. (e.g. they assumed that divisive inhibition acts after inputs are combined) it gives a suggestion as to why top-down divisive feed-back could result in the noise-invariant neural responses observed in their data.</p>
</sec>
<sec id="sec012">
<title>Divisive versus subtractive predictive coding</title>
<p>Predictive coding implies that, rather than directly encoding sensory stimuli, feed-forward neurons encode a prediction error that can be used to update the internal representation in higher-level areas [<xref ref-type="bibr" rid="pcbi.1005582.ref001">1</xref>]. Here we show that, given signal-dependent sensory noise, this error signal should take a fractional form, implying divisive inhibition.</p>
<p>Previously, Spratling et al. showed that a predictive coding network that minimizes fractional prediction errors can account for a number of classical and extra-classical response properties of neurons in visual area V1 [<xref ref-type="bibr" rid="pcbi.1005582.ref041">41</xref>]. We provide a normative interpretation of Spratling’s model, as implementing optimal estimation of presented stimulus features given signal-dependent noise. We find that, for a large family of distributions in which the variance in each input is proportional to its mean (including, but not limited to Poisson noise), the prediction errors take a fractional form, implying divisive predictive coding (see section 1 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>).</p>
<p>With the exception of Spratling’s work, previous predictive coding models have usually assumed that sensory neurons encode the <italic>difference</italic> between their received and predicted input [<xref ref-type="bibr" rid="pcbi.1005582.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref042">42</xref>]. This type of code will be optimal only if the the variance in each sensory input is constant, irrespective of its mean. Subtractive predictive coding results in qualitatively different neural response properties, compared to divisive predictive coding. It predicts that: (i) the time course of neural responses is independent of stimulus strength; (ii) neural responses vary linearly with their feed-forward input, and thus, do not saturate; (iii) neural RFs are largely invariant to changes in stimulus context (see section 4 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>). In summary, subtractive predictive coding cannot account for many of the non-linear response properties observed in sensory neurons, and that are explained by divisive predictive coding.</p>
</sec>
<sec id="sec013">
<title>The sources of neural noise</title>
<p>Here, we show that the optimal form of neural gain control depends on how neural inputs are corrupted by noise. Specifically, signal-dependent noise requires input-targeted divisive inhibition, in contrast to gaussian noise, which requires global subtractive inhibition.</p>
<p>‘Noise’ here refers to the trial-by-trial variability of neural inputs, given a fixed stimulus. Generally, multiple noise sources combine to produce neural variability, including external noise sources (e.g. random fluctuations in light intensity), and internal noise sources (e.g. spike failure). The model is agnostic to these details, as long as the trial-by-trial variability of inputs to the network scales monotonically with their amplitude.</p>
<p>In contrast, the model network itself has deterministic dynamics: for a given input, the neural responses are always be the same. However, while this choice was made for simplicity, related work on networks of spiking neurons shows how optimal estimation can be performed in a network of neurons that exhibit Poisson-like spiking statistics [<xref ref-type="bibr" rid="pcbi.1005582.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref043">43</xref>]. In these models, internal noise fluctuations that alter the spike times of single neurons are compensated by recurrent connections in the network, such that the read-out from the population response is relatively stable.</p>
</sec>
<sec id="sec014">
<title>Circuits and mechanisms underlying divisive inhibition</title>
<p>The effects presented here come about as a result of optimal estimation with signal-dependent noise, and are thus largely independent of the specific neural mechanism that implements divisive inhibition. For example, contextual reshaping of neural RFs (Figs <xref ref-type="fig" rid="pcbi.1005582.g002">2</xref> and <xref ref-type="fig" rid="pcbi.1005582.g003">3</xref>) occurs because ‘explaining away’ takes place at the level of the inputs, before they have been combined, while gain modulation of neural responses (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6</xref>) is a property of the fractional prediction error.</p>
<p>Nonetheless, in order to make concrete predictions about sensory neural responses we proposed a simple network architecture, in which excitatory neurons encode a fractional prediction error, and receive lateral inhibition from local interneurons that encode individual stimulus features (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6b</xref>). However, note that there is more than one way to implement the optimal estimation described by <xref ref-type="disp-formula" rid="pcbi.1005582.e012">Eq 3</xref>. For example, divisive inhibition could be mediated via top-down feed-back from higher-level areas [<xref ref-type="bibr" rid="pcbi.1005582.ref001">1</xref>], or via lateral inhibition of individual synaptic inputs [<xref ref-type="bibr" rid="pcbi.1005582.ref018">18</xref>] (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6a</xref>). However, as they share the same normative structure to our model, these different network architectures result in very similar predictions for the neural responses.</p>
<p>In our proposed network, excitatory neurons at the first level of processing each receive input from one type of receptor, and divisive inhibition from lateral interneurons. This closely matches the observed anatomy of both fly and mouse olfactory system, where mitral cells (or 2nd-order PNs in fly) receive feed-forward input from one type of olfactory receptor, and lateral inhibitory feed-back that depends on the responses of many receptors [<xref ref-type="bibr" rid="pcbi.1005582.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref044">44</xref>]. Furthermore, recent experiments have shown that in the fly, inhibition from lateral neurons is well described by the exact same divisive formula as obtained with our model [<xref ref-type="bibr" rid="pcbi.1005582.ref045">45</xref>].</p>
<p>Recently, researchers have reported how various interneuron types play different roles in sharpening and/or globally suppressing visual neural responses [<xref ref-type="bibr" rid="pcbi.1005582.ref046">46</xref>–<xref ref-type="bibr" rid="pcbi.1005582.ref049">49</xref>]. While generally, our simplified model is not designed to address this level of detail, it is worth noting that when implemented in a hierarchy (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6c</xref>), interneurons at different levels of processing will have qualitatively different effects on the tuning curves of excitatory neurons. Specifically, interneurons in the previous layer to a recorded neuron, that target its <italic>inputs</italic>, will act to sharpen and reshape the neuron’s selectivity, whereas interneurons in the same layer, that provide direct lateral inhibition, will lead to a global suppression (but no sharpening) of its responses.</p>
<p>In our model, divisive inhibition is implemented via lateral feedback from inhibitory interneurons, which multiplicatively increases the ‘leak’ term in the dynamics of the excitatory neural responses <xref ref-type="disp-formula" rid="pcbi.1005582.e025">Eq (5)</xref>. A potential candidate for this gain modulation is shunting inhibition [<xref ref-type="bibr" rid="pcbi.1005582.ref002">2</xref>] (although see [<xref ref-type="bibr" rid="pcbi.1005582.ref050">50</xref>–<xref ref-type="bibr" rid="pcbi.1005582.ref052">52</xref>]). More generally however, current experiments suggest that there is not one unique neural mechanism that implements divisive inhibition [<xref ref-type="bibr" rid="pcbi.1005582.ref022">22</xref>]. Rather a host of different mechanisms, such as synaptic depression [<xref ref-type="bibr" rid="pcbi.1005582.ref053">53</xref>], ongoing network dynamics [<xref ref-type="bibr" rid="pcbi.1005582.ref054">54</xref>], and neuromodulatory feedback [<xref ref-type="bibr" rid="pcbi.1005582.ref055">55</xref>] may be responsible for divisive inhibition in different sensory areas and species. This is consistent with our framework, which suggests that it is the computation performed by divisive inhibition, rather than its neural implementation, that is conserved across sensory systems in order to optimally infer the state of the environment.</p>
</sec>
<sec id="sec015">
<title>Predicted differences between excitatory and inhibitory responses</title>
<p>The proposed neural network predicts several qualitative differences between the responses of excitatory neurons, which encode fractional prediction errors, and inhibitory neurons, which encode stimulus features. These differences are: (i) long-range (i.e. between cortical regions) signals are normalized, while short-range (i.e. within region) signals are not; (ii) inhibitory neurons respond to more complex non-local features than excitatory neurons in the same area (they are thus expected to exhibit wider, apparently less selective tuning curves, as indeed observed experimentally [<xref ref-type="bibr" rid="pcbi.1005582.ref056">56</xref>]); (iii) inhibitory responses are less transient than excitatory neural responses.</p>
<p>Recent experiments, using optogenetic techniques, have shown that parvalbumin (PV)-expressing inhibitory cells can have a divisive effect on excitatory responses to sensory stimuli. Interestingly, PV cells appear to fulfil many qualitative criteria required by inhibitory cells in our model, such as broad stimulus tuning, temporally sustained responses, and minimal contrast normalisation (relative to layer 2/3 excitatory neurons, to which they provide input) [<xref ref-type="bibr" rid="pcbi.1005582.ref048">48</xref>]. Future research will be required to quantify more precisely how the activity of PV cells compares to the predictions of our model.</p>
</sec>
<sec id="sec016">
<title>The role of feedback</title>
<p>Our model can easily be extended to consider sensory processing in a hierarchy, with neurons at each layer of the network reconstructing stimulus features of increasing complexity based on the inputs they receive from the previous layer (see <xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6c</xref> and section 3 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>). In this case, optimal estimation also requires using high-level knowledge to constrain and shape the low-level sensory representation. This can be easily incorporated into our framework, in the form of top-down feedback. As well as carrying information about the stimulus features encoded by higher-level areas, this top-down feed-back could also carry information about the organism’s prior experience and task-demands. Future work could investigate whether such top-down feedback is able to account for the experience-dependent and attention-dependent shifts in neural tuning curves that are observed experimentally [<xref ref-type="bibr" rid="pcbi.1005582.ref057">57</xref>, <xref ref-type="bibr" rid="pcbi.1005582.ref058">58</xref>].</p>
<p>In summary, our model suggests a highly dynamic system, in which neural RFs and tuning curves are continuously reshaped by the spatiotemporal context of presented stimuli, as well as the organism’s prior experience and task-demands. However, the neural code is context invariant: neurons always represent the same external feature, and thus their response can be read the same way by downstream neurons, regardless of the stimulus context.</p>
</sec>
</sec>
<sec id="sec017" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec018">
<title>Subtractive model</title>
<p>In addition to the model described in the main text, we also considered an artificial example, where the input signal is corrupted by constant Gaussian noise (whose magnitude is independent of the signal strength). In this case, encoded features vary in time according to:
<disp-formula id="pcbi.1005582.e032"><alternatives><graphic id="pcbi.1005582.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e032" xlink:type="simple"/><mml:math display="block" id="M32"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mi>η</mml:mi> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mspace width="1pt"/><mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:munder> <mml:mspace width="1pt"/><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>k</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula>
Thus, the estimate of each feature evolves in time according to a sum of ‘absolute prediction errors’, <inline-formula id="pcbi.1005582.e033"><alternatives><graphic id="pcbi.1005582.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>〈</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo> <mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, equal to the difference between received and predicted inputs.</p>
<p>Note that because of the linearity of this equation, the left hand-side can be rewritten as the sum of a feed-forward input term ∑<sub><italic>j</italic></sub> <italic>w</italic><sub><italic>ji</italic></sub><italic>s</italic><sub><italic>j</italic></sub> and a lateral subtractive inhibition term <inline-formula id="pcbi.1005582.e034"><alternatives><graphic id="pcbi.1005582.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mspace width="1pt"/><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>k</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. In the particular case of constant gaussian noise, lateral inhibition is thus separable and can be seen as occurring “after combination” of these input signals. Similarly, in the steady state, the estimated features can be obtained by a weighted linear sum of feed-forward inputs: <inline-formula id="pcbi.1005582.e035"><alternatives><graphic id="pcbi.1005582.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:msub> <mml:mspace width="1pt"/><mml:msub><mml:mi>v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, with feed-forward weights <bold><italic>v</italic></bold><sub><italic>i</italic></sub> directly related to the encoded features <bold><italic>w</italic></bold><sub><italic>i</italic></sub> (i.e. <inline-formula id="pcbi.1005582.e036"><alternatives><graphic id="pcbi.1005582.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>). In that interpretation, competition between encoded features adds a subtractive component (an inhibitory surround) to a static feed-forward filter (<xref ref-type="fig" rid="pcbi.1005582.g001">Fig 1b</xref>).</p>
</sec>
<sec id="sec019">
<title>Comparison between subtractive and divisive models</title>
<p>For the initial simulations shown in Figs <xref ref-type="fig" rid="pcbi.1005582.g002">2</xref>–<xref ref-type="fig" rid="pcbi.1005582.g005">5</xref>, we sought to investigate the general implications of divisive versus subtractive inhibition Eqs <xref ref-type="disp-formula" rid="pcbi.1005582.e012">(3)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005582.e032">(9)</xref>, irrespective of the specific neural implementation. Although we assumed that neurons encode individual stimulus features, with firing rate proportional to the encoded feature (<inline-formula id="pcbi.1005582.e037"><alternatives><graphic id="pcbi.1005582.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>∝</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>), the qualitative results would also be the same for a distributed code, in which each neurons encode a linear combination of stimulus features, according to, <inline-formula id="pcbi.1005582.e038"><alternatives><graphic id="pcbi.1005582.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>∝</mml:mo> <mml:mo>∑</mml:mo> <mml:msub><mml:mi>q</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Note that for the simulations used to generate Figs <xref ref-type="fig" rid="pcbi.1005582.g002">2</xref>–<xref ref-type="fig" rid="pcbi.1005582.g005">5</xref> the dimensions are essentially arbitrary, and thus all parameters are quoted in unit-less dimensions. Encoded features were initialized at zero, and updated using <xref ref-type="disp-formula" rid="pcbi.1005582.e012">Eq 3</xref> for the divisive algorithm, and <xref ref-type="disp-formula" rid="pcbi.1005582.e032">Eq 9</xref> for the subtractive algorithm. The update rate, <italic>η</italic>, was set to ensure smooth dynamics, while the number of iterations, <italic>N</italic>, was chosen to allow the estimates to converge on steady state values. The background rate, <italic>w</italic><sub>0</sub>, was set to 0.01. In our framework, the generative model describing how external stimulus features activate sensory receptors determines the network connectivity. Furthermore, in the case where each neuron encodes a separate stimulus feature, there is a one-to-one correspondence between the structure of the generative model (parameterized by <bold><italic>w</italic></bold>) and the feed-forward connectivity in the network. Specifically, the parameter <italic>w</italic><sub><italic>ji</italic></sub>, that determines how strongly the <italic>i</italic><sup><italic>th</italic></sup> feature activates the <italic>j</italic><sup><italic>th</italic></sup> receptor, also determines the connection strength between the <italic>i</italic><sup><italic>th</italic></sup> neuron and the <italic>j</italic><sup><italic>th</italic></sup> receptor.</p>
</sec>
<sec id="sec020">
<title>Comparison between input-targeted divisive inhibition and LN models</title>
<p>We compared the input-targetted divisive inhibition model to a linear-nonlinear (LN) model, with responses obtained by linearly filtering the sensory inputs then applying a static non-linearity: <italic>r</italic><sub><italic>i</italic></sub> = <italic>f</italic>(∑<sub><italic>j</italic></sub> <italic>v</italic><sub><italic>ji</italic></sub><italic>s</italic><sub><italic>j</italic></sub> + <italic>v</italic><sub>0</sub>). (Note that this is a simple generalisation of the subtractive model where responses were strictly linear). For our simulations we used a threshold non-linearity, while linear weights (<italic>v</italic><sub><italic>ji</italic></sub>) and offset (<italic>v</italic><sub>0</sub>), were learned so as to best fit the responses obtained with the input-targetted divisive model. Using a different non-linearity (e.g. exponential) had no qualitative effect on the predicted contextual tuning curve changes. In addition, we also considered a ‘global divisive-inhibition’ model (Section 5 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>).</p>
</sec>
<sec id="sec021">
<title>Suppression by a contextual stimulus</title>
<p>For the simulation shown in <xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2b</xref> there were 30 sensory receptors and 30 neurons. We used a generative model in which each feature activates two neighbouring receptors (i.e. <italic>w</italic><sub><italic>ii</italic></sub> = <italic>w</italic><sub>(<italic>i</italic>+1)<italic>i</italic></sub> = 40). Thus, each neuron received equal strength feed-forward inputs from two neighbouring receptors (<xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2a</xref>). We computed the steady-state response of the <italic>k</italic><sup><italic>th</italic></sup> neuron with both the subtractive or divisive algorithms, in three different stimulus conditions. In the ‘no-context’ condition, only one of the inputs to the recorded neuron was active, with firing rate drawn from a Poisson distribution with mean 50 (i.e. 〈<italic>s</italic><sub><italic>k</italic>+1</sub>〉 = 50). For the ‘adjoint context’ condition, a neighbouring input that did not drive the recorded neuron was also active (with amplitude 〈<italic>s</italic><sub><italic>k</italic>+2</sub>〉 = 20). Finally, for the ‘disjoint context’ condition, an input on the opposite side of the recorded neuron’s receptive field was active (i.e. 〈<italic>s</italic><sub><italic>k</italic>−1</sub>〉 = 20). In each condition, we averaged the neuron’s steady state response over 200 trials.</p>
</sec>
<sec id="sec022">
<title>Contextual shifts in tuning curves</title>
<p>For the simulation shown in <xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2c</xref> there were 30 sensory receptors and 30 neurons. We assumed a generative model in which a stimulus moving in a given direction (indexed by ‘<italic>i</italic>’) activates multiple neighbouring receptors, described mathematically via the circular basis functions: <inline-formula id="pcbi.1005582.e039"><alternatives><graphic id="pcbi.1005582.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:mrow><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:msub> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mn>4</mml:mn> <mml:mo>[</mml:mo> <mml:mo form="prefix">cos</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow> <mml:mn>30</mml:mn></mml:mfrac> <mml:mo>(</mml:mo> <mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> (with <italic>w</italic><sub><italic>max</italic></sub> = 40). As before, this implies that each neuron receives feed-forward inputs from multiple neighbouring inputs. We first looked at the steady state response of a single neuron to a varying stimulus direction, <italic>i</italic>. The activation of the <italic>j</italic><sup><italic>th</italic></sup> sensory input was drawn from a Poisson distribution, with mean 〈<italic>s</italic><sub><italic>j</italic></sub> (<italic>i</italic>)〉 = <italic>w</italic><sub><italic>ji</italic></sub> + <italic>w</italic><sub>0</sub>. We next looked at the response of the same neuron in the presence of a ‘mask’, which activated a single receptor, shifted 3 receptors to the left or right of the neuron’s preferred input. The activation of this receptor was held constant at 200. The input to all other receptors was the same as in the previous control condition. The mask was chosen specifically so that it did not elicit any response in the recorded neuron when presented alone.</p>
</sec>
<sec id="sec023">
<title>Measurement of receptive fields</title>
<p>For the simulation shown in <xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2d and 2e</xref> there were 400 neurons, and 900 sensory inputs (arranged on a 30×30 grid in visual space). Each neuron encoded a circular ‘blob-like’ stimulus feature. Specifically, columns of the matrix <italic>W</italic> specified the feature encoded by each neuron, with elements given by: <inline-formula id="pcbi.1005582.e040"><alternatives><graphic id="pcbi.1005582.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:mrow><mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>w</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:msub> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>2</mml:mn> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>w</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>[</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>x</mml:mi> <mml:msub><mml:mn>0</mml:mn> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi>y</mml:mi> <mml:msub><mml:mn>0</mml:mn> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>]</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. <italic>x</italic>0<sub><italic>i</italic></sub> and <italic>y</italic>0<sub><italic>i</italic></sub> specify the preferred region of visual space for the <italic>i</italic><sup><italic>th</italic></sup> neuron, distributed uniformly along the axis spanned by <italic>x</italic> and <italic>y</italic> (0 → 1). <italic>w</italic><sub><italic>max</italic></sub>, and <italic>σ</italic><sub><italic>w</italic></sub> determine the amplitude and width of the encoded features, and were set to 40 and 0.1 respectively. We first performed a simulation with ‘random sparse’ stimuli. Sensory inputs, <italic>s</italic><sub><italic>j</italic></sub>, were either equal to 0 (with probability 0.95) or 100 (with probability 0.05). Next, a vertical grating stimulus (in which each bar spanned 8 pixels), of magnitude 20, was added to the random sparse stimulus (<xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2d and 2e</xref>, bottom left). The phase (but not the orientation) of the grating varied randomly on each trial. Thus, on the <italic>n</italic><sup><italic>th</italic></sup> trial, the sensory input was equal to, <inline-formula id="pcbi.1005582.e041"><alternatives><graphic id="pcbi.1005582.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow> <mml:mi>n</mml:mi></mml:msup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow> <mml:mrow><mml:mi>g</mml:mi> <mml:mi>r</mml:mi> <mml:mi>a</mml:mi> <mml:mi>t</mml:mi> <mml:mi>i</mml:mi> <mml:mi>n</mml:mi> <mml:mi>g</mml:mi></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">s</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow> <mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. In each case, neural receptive fields (RFs) were quantified using reverse correlation: <inline-formula id="pcbi.1005582.e042"><alternatives><graphic id="pcbi.1005582.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>Q</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>s</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">q</mml:mi></mml:mrow> <mml:mrow><mml:mi>r</mml:mi> <mml:mi>s</mml:mi></mml:mrow> <mml:mi>j</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, where (<italic>Q</italic><sub><italic>ss</italic></sub>)<sub><italic>ij</italic></sub> = 〈<italic>s</italic><sub><italic>i</italic></sub><italic>s</italic><sub><italic>j</italic></sub>〉 and <inline-formula id="pcbi.1005582.e043"><alternatives><graphic id="pcbi.1005582.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mo>〈</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>〉</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, and 〈⋅〉 denotes an average over 10<sup>4</sup> stimulus presentations.</p>
<p>In Figs <xref ref-type="fig" rid="pcbi.1005582.g003">3a</xref> and <xref ref-type="fig" rid="pcbi.1005582.g005">5</xref> we considered an ‘olfactory network’, with neurons were assumed to have a distributed selectivity, spanning multiple receptor inputs. Mathematically, the network was similar to the network described above. However, for the olfactory simulations, the feature encoded by each neuron consisted of a sum of four ‘blobs’, distributed randomly across the input space (see examples shown in upper panels of <xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3a</xref>).</p>
<p>Neural receptive fields were estimated as before, in response to a random sparse stimulus plus a contextual stimulus. For the plots shown in <xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3a</xref>, the contextual stimulus consisted of a single ‘blob’ (of magnitude 100, and width <italic>σ</italic><sub><italic>cntxt</italic></sub> = 0.1), that activated a set of nearby receptors (see black and white panels in <xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3a</xref>).</p>
<p>Finally, we illustrated the principles underlying reshaping of neural receptive field using a simple network of only three neurons, each of which encoded a different letter of the alphabet (‘A’, ‘I’, and ‘V’). Encoded features (comprised of 600 sensory inputs, arranged in a 20×30 grid), are shown in <xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3b</xref>. As before, neural RFs were estimated using random sparse stimuli, in addition to a contextual mask (shown in the left panels of <xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3c</xref>).</p>
</sec>
<sec id="sec024">
<title>Invariance of neural code</title>
<p>We next investigated how divisive inhibition enables the network to maintain an invariant representation of encoded stimulus features.</p>
<p>The network used for these simulations was the same as the model with bell-shaped tuning curves, shown in <xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2c</xref>. We measured tuning curves in the same way as before, measuring the mean firing rate of each neuron versus the stimulus orientation. However, in this case we measured tuning curves in the presence of three constant ‘masks’, constructed from different combinations of encoded features (<xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4b</xref>), added to the varying stimulus.</p>
<p>In each stimulus condition, we estimated the linear filters required to reconstruct the stimulus from the neural responses, using linear regression. Thus, readout filters were given by <inline-formula id="pcbi.1005582.e044"><alternatives><graphic id="pcbi.1005582.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mrow><mml:mi>U</mml:mi> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>〈</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:msup><mml:mover accent="true"><mml:mi>r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>T</mml:mi></mml:msup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mspace width="1pt"/> <mml:msup><mml:mrow><mml:mo>〈</mml:mo> <mml:mover accent="true"><mml:mi>r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:msup><mml:mover accent="true"><mml:mi>r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>T</mml:mi></mml:msup> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1005582.e045"><alternatives><graphic id="pcbi.1005582.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mo>〈</mml:mo> <mml:mi>s</mml:mi> <mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005582.e046"><alternatives><graphic id="pcbi.1005582.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mo>〈</mml:mo> <mml:mi>r</mml:mi> <mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>
<xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4d</xref> was constructed in the same way using the LN model (<xref ref-type="fig" rid="pcbi.1005582.g004">Fig 4e</xref>). The parameters of the LN model were fitted to minimize the mean squared difference between the responses predicted by the LN model and the input-targeted inhibition model, across all three stimulus conditions.</p>
<p>In <xref ref-type="fig" rid="pcbi.1005582.g005">Fig 5</xref> we demonstrate how a model with input-targeted inhibition is able to discriminate between similar overlapping stimulus features. To illustrate this, we returned to the ‘olfactory network’ used to generate <xref ref-type="fig" rid="pcbi.1005582.g003">Fig 3a</xref>. We compared this input-targeted divisive inhibition model to the output-targeted divisive inhibition model, described previously. Parameters of this model were fitted to minimize the mean squared difference between the responses of the global inhibition model and the input-targeted inhibition models. Stimuli used to fit the model parameters consisted of random linear combinations of the features encoded by the network, corrupted by Poisson noise.</p>
</sec>
<sec id="sec025">
<title>Neural network implementation</title>
<p>We proposed a neurally plausible implementation of the the estimation algorithm described in <xref ref-type="disp-formula" rid="pcbi.1005582.e012">Eq 3</xref> (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6b</xref>). This network consists of two populations of neurons: excitatory neurons with dynamics described by <xref ref-type="disp-formula" rid="pcbi.1005582.e025">Eq 5</xref>, and inhibitory neurons with dynamics described by <xref ref-type="disp-formula" rid="pcbi.1005582.e027">Eq 6</xref>. Figs <xref ref-type="fig" rid="pcbi.1005582.g007">7</xref> and <xref ref-type="fig" rid="pcbi.1005582.g008">8</xref> were generated using discretized version of these equations. For these simulations, the background input was set to <italic>w</italic><sub>0</sub> = 1. Parameters, <italic>a</italic> and <italic>b</italic>, determining the timescale of excitation and inhibition were set to 0.08 and 40 respectively (see section 6 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref> for the effect of varying the excitatory and inhibitory timescales). Input spikes were always counted over a time-window of <italic>T</italic> = 1s, so that the number of spikes fired by each input is equal to its firing rate.</p>
<p>The network connectivity was entirely constrained by the generative model describing how presented stimulus features activate the inputs to the network. That is, the parameter ‘<italic>w</italic><sub><italic>ji</italic></sub>’, that describes how strongly the <italic>i</italic><sup><italic>th</italic></sup> stimulus feature activates the <italic>j</italic><sup><italic>th</italic></sup> receptor, also determined the strength of the lateral connection between the <italic>j</italic><sup><italic>th</italic></sup> excitatory neuron and the <italic>i</italic><sup><italic>th</italic></sup> inhibitory neuron.</p>
</sec>
<sec id="sec026">
<title>Gain modulation</title>
<p>For the plots shown in <xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6d and 6e</xref> we considered a minimal model with 1 encoded feature and 2 sensory inputs. Within our framework, this corresponds to a network with 1 inhibitory and 2 excitatory neurons (<xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6d</xref>, left panel). The inhibitory neuron received equal strength inputs from both excitatory neurons (<italic>w</italic><sub>11</sub> = <italic>w</italic><sub>21</sub> = 40). Steady-state excitatory responses could be obtained directly from <xref ref-type="disp-formula" rid="pcbi.1005582.e030">Eq 7</xref>. In <xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6d</xref>, the input to each excitatory neuron was drawn from a Poisson distribution with mean: 〈<italic>s</italic><sub>1</sub>〉 = <italic>I</italic><sub><italic>test</italic></sub> and 〈<italic>s</italic><sub>2</sub>〉 = <italic>I</italic><sub><italic>mask</italic></sub> respectively. in <xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6e</xref>, the ‘test’ and ‘mask’ stimulus activated both sensory inputs, so that: 〈<italic>s</italic><sub>1</sub>〉 = <italic>I</italic><sub><italic>test</italic></sub> + 0.1<italic>I</italic><sub><italic>mask</italic></sub> and 〈<italic>s</italic><sub>2</sub>〉 = <italic>I</italic><sub><italic>mask</italic></sub> + 0.1<italic>I</italic><sub><italic>test</italic></sub>.</p>
</sec>
<sec id="sec027">
<title>Temporal response dynamics</title>
<p>For the plots shown in <xref ref-type="fig" rid="pcbi.1005582.g007">Fig 7</xref> we again considered the minimal network with 1 excitatory and 2 inhibitory neurons (connection strengths were same as for <xref ref-type="fig" rid="pcbi.1005582.g006">Fig 6</xref>). On each trial, the input to the recorded excitatory neuron was drawn from a Poisson distribution, with mean varying between 0 &amp; 200Hz. The other neuron received zero input.</p>
<p>For the plots shown in <xref ref-type="fig" rid="pcbi.1005582.g008">Fig 8</xref>, we considered a ‘topographic’ network of 30 excitatory and 30 inhibitory neurons. Each inhibitory neuron connected with equal strength to 2 neighbouring excitatory neurons (<italic>w</italic><sub><italic>ii</italic></sub> = <italic>w</italic><sub><italic>i</italic>(<italic>i</italic>+1)</sub> = 40). The input to the <italic>j</italic><sup><italic>th</italic></sup> excitatory neuron was drawn from a Poisson distribution with mean, <inline-formula id="pcbi.1005582.e047"><alternatives><graphic id="pcbi.1005582.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005582.e047" xlink:type="simple"/><mml:math display="inline" id="M47"><mml:mrow><mml:mrow><mml:mo>〈</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>〉</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>150</mml:mn> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mo>|</mml:mo> <mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mi>k</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>k</italic> denotes the neuron that receives maximal input.</p>
</sec>
</sec>
<sec id="sec028">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005582.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Supplementary appendix.</title>
<p>Includes derivation of optimal estimation algorithm, generalisation to non-poisson noise statistics, correlated input noise, and implementation of in a multi-layer neural network.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005582.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.s002" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Comparison between simulation and analytic results.</title>
<p>The network consists of 30 inhibitory and 30 excitatory neurons. Connection strengths between inhibitory and excitatory neurons are chosen from a uniform distribution between 0 and 40. In the ‘no mask’ condition one of the sensory inputs varies between 10<sup>−1</sup>Hz and 10<sup>4</sup>Hz, while all the other inputs are set to the background input of <italic>w</italic><sub>0</sub> = 1Hz. In the ‘mask condition’ all sensory inputs are activated at 10Hz. Solid lines plot the steady-state response of the maximally driven excitatory neuron, in the ‘no mask’ and ‘mask’ conditions. Dashed curves show the response of the neuron, approximated using eq 31 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005582.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.s003" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Predictions of global divisive inhibition.</title>
<p>The figure is the same as <xref ref-type="fig" rid="pcbi.1005582.g002">Fig 2c and 2d</xref> and in the main text, but with a global divisive inhibition (with responses described by eq 34 in <xref ref-type="supplementary-material" rid="pcbi.1005582.s001">S1 Text</xref>).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005582.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005582.s004" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Effect of varying exicitatory/inhibitory timescales.</title>
<p>The figure is the same to <xref ref-type="fig" rid="pcbi.1005582.g007">Fig 7a and 7b</xref> in the main text, with the exception that the timescale of inhibition has been increased by a factor of 40, relative to excitation.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1005582.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rao</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Ballard</surname> <given-names>KH</given-names></name>. <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title>. <source>Nature Neuroscience</source>. <year>1999</year>; <volume>2</volume>:<fpage>79</fpage>–<lpage>87</lpage> <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/4580" xlink:type="simple">10.1038/4580</ext-link></comment> <object-id pub-id-type="pmid">10195184</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name>. <article-title>Linearity and normalization in simple cells of the macaque primary visual cortex</article-title>. <source>Journal of Neuroscience</source>. <year>1997</year>; <volume>17</volume>:<fpage>8621</fpage>–<lpage>8644</lpage>. <object-id pub-id-type="pmid">9334433</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Faisal</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Selen</surname> <given-names>PJL</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>. <article-title>Noise in the nervous system</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2008</year>; <volume>169</volume>:<fpage>292</fpage>–<lpage>303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2258" xlink:type="simple">10.1038/nrn2258</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nawrot</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Boucsein</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Molina</surname> <given-names>VR</given-names></name>, <name name-style="western"><surname>Riehle</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>. <article-title>Measurement of variability dynamics in cortical spike trains</article-title>. <source>Journal of Neuroscience Methods</source>. <year>2008</year>; <volume>169</volume>:<fpage>374</fpage>–<lpage>390</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jneumeth.2007.10.013" xlink:type="simple">10.1016/j.jneumeth.2007.10.013</ext-link></comment> <object-id pub-id-type="pmid">18155774</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>. <article-title>The variable discharge of cortical neurons: implications for connectivity, computation, and information coding</article-title>. <source>Journal of Neuroscience</source>. <year>1998</year>, <volume>18</volume>:<fpage>3870</fpage>–<lpage>3896</lpage>. <object-id pub-id-type="pmid">9570816</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kabara</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Bonds</surname> <given-names>AB</given-names></name>, <article-title>Modification of response functions of cat visual cortical cells by spatially congruent perturbing stimuli</article-title>. <source>Journal of Neurophysiology</source>, <year>2001</year>; <volume>86</volume>:<fpage>2703</fpage>–<lpage>2714</lpage>. <object-id pub-id-type="pmid">11731530</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yehn</surname> <given-names>C-I</given-names></name>., <name name-style="western"><surname>Xing</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Williams</surname> <given-names>P.E</given-names></name>, <name name-style="western"><surname>Shapley</surname> <given-names>RM</given-names></name>. <article-title>Adaptation of the simple or complex nature of V1 receptive fields to visual statistics</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <year>2009</year>; <volume>106</volume>:<fpage>14652</fpage>–<lpage>14657</lpage></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fournier</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Monier</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Pananceau</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Fregnac</surname> <given-names>Y</given-names></name>. <article-title>Adaptation of the simple or complex nature of V1 receptive fields to visual statistics</article-title>. <source>Nature Neuroscience</source>, <year>2011</year>; <volume>14</volume>:<fpage>1053</fpage>–<lpage>1060</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2861" xlink:type="simple">10.1038/nn.2861</ext-link></comment> <object-id pub-id-type="pmid">21765424</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Trott</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Born</surname> <given-names>RT</given-names></name> <article-title>Input-Gain Control Produces Feature-Specific Surround Suppression</article-title>. <source>Journal of Neuroscience</source>, <year>2015</year>; <volume>35</volume>:<fpage>4973</fpage>–<lpage>4982</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4000-14.2015" xlink:type="simple">10.1523/JNEUROSCI.4000-14.2015</ext-link></comment> <object-id pub-id-type="pmid">25810527</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>, <article-title>Normalization of cell responses in cat striate cortex</article-title>. <source>Visual Neuroscience</source>, <year>1992</year>; <volume>9</volume>:<fpage>181</fpage>–<lpage>197</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S0952523800009640" xlink:type="simple">10.1017/S0952523800009640</ext-link></comment> <object-id pub-id-type="pmid">1504027</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name>. <article-title>Computational models of cortical visual processing</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <year>1996</year>; <volume>93</volume>:<fpage>623</fpage>–<lpage>627</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.93.2.623" xlink:type="simple">10.1073/pnas.93.2.623</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cavanaugh</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>James</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bair</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name>, <article-title>Nature and interaction of signals from the receptive field center and surround in macaque V1 neurons</article-title>. <source>Journal of Neurophysiology</source>, <year>2002</year>; <volume>88</volume>:<fpage>2530</fpage>–<lpage>2546</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005582.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rust</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Mante</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>, <article-title>How MT cells analyze the motion of visual patterns</article-title>. <source>Nature Neuroscience</source>, <year>2006</year>; <volume>9</volume>:<fpage>1421</fpage>–<lpage>1431</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1786" xlink:type="simple">10.1038/nn1786</ext-link></comment> <object-id pub-id-type="pmid">17041595</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Busse</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wade</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <article-title>Representation of Concurrent Stimuli by Population Activity in Visual Cortex</article-title>. <source>Neuron</source>, <year>2009</year>; <volume>88</volume>:<fpage>64931</fpage>–<lpage>942</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005582.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Deneve</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <article-title>Efficient computation and cue integration with noisy population codes</article-title>. <source>Nature Neuroscience</source>, <year>2001</year>; <volume>4</volume>:<fpage>826</fpage>–<lpage>831</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/90541" xlink:type="simple">10.1038/90541</ext-link></comment> <object-id pub-id-type="pmid">11477429</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref016">
<label>16</label>
<mixed-citation publication-type="other" xlink:type="simple">Pillow J. Likelihood-Based Approaches to Modeling the Neural Code. in Bayesian Brain: Probabilistic approaches to neural coding, (MIT press, 2007), 53–70.</mixed-citation>
</ref>
<ref id="pcbi.1005582.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hosoya</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Baccus</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Meister</surname> <given-names>M</given-names></name>. <article-title>Dynamic predictive coding by the retina</article-title>. <source>Nature</source>, <year>2005</year>; <volume>436</volume>:<fpage>71</fpage>–<lpage>77</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature03689" xlink:type="simple">10.1038/nature03689</ext-link></comment> <object-id pub-id-type="pmid">16001064</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lochmann</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ernst</surname> <given-names>UA</given-names></name>, <name name-style="western"><surname>Deneve</surname> <given-names>S</given-names></name>, <article-title>Perceptual Inference Predicts Contextual Modulations of Sensory Responses</article-title>. <source>Journal of neuroscience</source>, <year>2012</year>; <volume>32</volume>:<fpage>4179</fpage>–<lpage>4195</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0817-11.2012" xlink:type="simple">10.1523/JNEUROSCI.0817-11.2012</ext-link></comment> <object-id pub-id-type="pmid">22442081</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Laurent</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Stopfer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Friedrich</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Rabinovich</surname> <given-names>RI</given-names></name>, <name name-style="western"><surname>Volkovskii</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Abarbanel</surname> <given-names>H.DI</given-names></name>. <article-title>Odor encoding as an active, dynamical process: experiments, computation and theory</article-title>. <source>Annual Rev. Neurosci</source>, <year>2001</year>; <volume>24</volume>:<fpage>263</fpage>–<lpage>297</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.24.1.263" xlink:type="simple">10.1146/annurev.neuro.24.1.263</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fritz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Elhilali</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>K</given-names></name>. <article-title>Rapid task–related plasticity of spetrotemporal receptive fields in primary auditory cortex</article-title>. <source>Nature Neuroscience</source>, <year>2003</year>; <volume>6</volume>:<fpage>1216</fpage>–<lpage>1223</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1141" xlink:type="simple">10.1038/nn1141</ext-link></comment> <object-id pub-id-type="pmid">14583754</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Marre</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Botella-Soler</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Simoons</surname> <given-names>KD</given-names></name>, <name name-style="western"><surname>Morra</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tkacik</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>M</given-names></name>. <article-title>High Accuracy Decoding of Dynamical Motion from a Large Retinal Population</article-title>. <source>PloS. Comp. Bio</source>., <year>2015</year>; <volume>11</volume>:<fpage>e1004304</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1004304" xlink:type="simple">10.1371/journal.pcbi.1004304</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>. <article-title>Normalization as a canonical computation</article-title>, <source>Nature Neuroscience</source>, <year>2012</year>; <volume>13</volume>:<fpage>51</fpage>–<lpage>62</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005582.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Reynaud</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Masson</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Chavane</surname> <given-names>F</given-names></name>. <article-title>Dynamics of Local Input Normalization Result from Balanced Short- and Long-Range Intracortical Interactions in Area V1</article-title>. <source>Journal of neuroscience</source>, <year>2012</year>; <volume>32</volume>:<fpage>12558</fpage>–<lpage>69</lpage>, <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1618-12.2012" xlink:type="simple">10.1523/JNEUROSCI.1618-12.2012</ext-link></comment> <object-id pub-id-type="pmid">22956845</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Albrecht</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Geisler</surname> <given-names>WS</given-names></name>, <name name-style="western"><surname>Frazer</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Crane</surname> <given-names>AM</given-names></name>. <article-title>Visual cortex neurons of monkeys and cats: temporal dynamics of the contrast response function</article-title>, <source>Journal of Neurophysiology</source>, <year>2002</year>; <volume>88</volume>:<fpage>888</fpage>–<lpage>913</lpage>. <object-id pub-id-type="pmid">12163540</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tatsuo</surname> <given-names>SK</given-names></name>, <name name-style="western"><surname>Nauhaus</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>. <article-title>Traveling Waves in Visual Cortex</article-title>. <source>Neuron</source>, <year>2012</year>; <volume>75</volume>:<fpage>218</fpage>–<lpage>229</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.06.029" xlink:type="simple">10.1016/j.neuron.2012.06.029</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sit</surname> <given-names>YF</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Geisler</surname> <given-names>WS</given-names></name>, <name name-style="western"><surname>Miikkulainen</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Seidemann</surname> <given-names>E</given-names></name>. <article-title>Complex Dynamics of V1 Population Responses Explained by a Simple Gain-Control Model</article-title>. <source>Neuron</source>, <year>2009</year>; <volume>64</volume>:<fpage>943</fpage>–<lpage>956</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2009.08.041" xlink:type="simple">10.1016/j.neuron.2009.08.041</ext-link></comment> <object-id pub-id-type="pmid">20064399</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nelson</surname> <given-names>ME</given-names></name>. <article-title>A mechanism for neuronal gain control by descending pathways</article-title>. <source>Neural Computation</source>, <year>1994</year>; <volume>6</volume>:<fpage>242</fpage>–<lpage>254</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.1994.6.2.242" xlink:type="simple">10.1162/neco.1994.6.2.242</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rabinwitz</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BDB</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Contrast gain control in auditory cortex</article-title>. <source>Neuron</source>, <year>2011</year>; <volume>70</volume>;<fpage>1178</fpage>–<lpage>1191</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.04.030" xlink:type="simple">10.1016/j.neuron.2011.04.030</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Bayesian inference with probabilistic population codes</article-title>. <source>Nature Neuroscience</source>, <year>2006</year>; <volume>9</volume>(<issue>11</issue>):<fpage>1432</fpage>–<lpage>1438</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1790" xlink:type="simple">10.1038/nn1790</ext-link></comment> <object-id pub-id-type="pmid">17057707</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>, <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title>. <source>Nature</source>, <year>2002</year>; <volume>415</volume>:<fpage>429</fpage>–<lpage>433</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/415429a" xlink:type="simple">10.1038/415429a</ext-link></comment> <object-id pub-id-type="pmid">11807554</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sober</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Sabes</surname> <given-names>PN</given-names></name>. <article-title>Flexible strategies for sensory integration during motor planning</article-title>. <source>Nature Neuroscience</source>, <year>2005</year>; <volume>25</volume>:<fpage>126</fpage>–<lpage>1288</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005582.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Knill</surname> <given-names>D</given-names></name>. <article-title>Learning bayesian priors for depth perception</article-title> <source>Journal of vision</source>, <year>2007</year>; <volume>7</volume>(<issue>8</issue>):<fpage>1</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/7.8.13" xlink:type="simple">10.1167/7.8.13</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Churchland</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Sugrue</surname> <given-names>LP</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Corrado</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Clark</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Hosseini</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Scott</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Bradley</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Kohn</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Armstrong</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Chang</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>Snyder</surname> <given-names>LH</given-names></name>, <name name-style="western"><surname>Lisberger</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Priebe</surname> <given-names>NJ</given-names></name>, <name name-style="western"><surname>Finn</surname> <given-names>IM</given-names></name>, <name name-style="western"><surname>Ferster</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Ryu</surname> <given-names>SI</given-names></name>, <name name-style="western"><surname>Santhanam</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Shenoy</surname> <given-names>KV</given-names></name>. <article-title>Stimulus onset quenches neural variability: a widespread cortical phenomenon</article-title>. <source>Nature Neuroscience</source>, <year>2010</year>; <volume>13</volume>(<issue>3</issue>):<fpage>369</fpage>–<lpage>378</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2501" xlink:type="simple">10.1038/nn.2501</ext-link></comment> <object-id pub-id-type="pmid">20173745</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ponce–Alvarez</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Thiele</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Albright</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Stoner</surname> <given-names>GR</given-names></name>, <name name-style="western"><surname>Deco</surname> <given-names>G</given-names></name>, <article-title>Stimulus-dependent variability and noise correlations in cortical MT neurons</article-title>. <source>PNAS</source>, <year>2013</year>; <volume>110</volume>(<issue>32</issue>):<fpage>13161</fpage>–<lpage>67</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005582.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schwartz</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>. <article-title>Natural signal statistics and sensory gain control</article-title>. <source>Nature Neuroscience</source>, <year>2001</year>; <volume>4</volume>:<fpage>819</fpage>–<lpage>825</lpage> <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/90526" xlink:type="simple">10.1038/90526</ext-link></comment> <object-id pub-id-type="pmid">11477428</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schwartz</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Soft mixer assignment in a hierarchical generative model of natural scene statistics</article-title>. <source>Neural Computation</source>, <year>2006</year>; <volume>18</volume>:<fpage>2680</fpage>–<lpage>2718</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2006.18.11.2680" xlink:type="simple">10.1162/neco.2006.18.11.2680</ext-link></comment> <object-id pub-id-type="pmid">16999575</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Marginalization in neural circuits with divisive normalization</article-title>. <source>Journal of Neuroscience</source>, <year>2011</year>; <volume>31</volume>:<fpage>15310</fpage>–<lpage>15319</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1706-11.2011" xlink:type="simple">10.1523/JNEUROSCI.1706-11.2011</ext-link></comment> <object-id pub-id-type="pmid">22031877</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref038">
<label>38</label>
<mixed-citation publication-type="other" xlink:type="simple">Beck JM, Pouget A, Heller KA. Complex Inference in Neural Circuits with Probabilistic Population Codes and Topic Models. Advances in Neural Information Processing Systems 2012; 3068–3076.</mixed-citation>
</ref>
<ref id="pcbi.1005582.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mesgarani</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Fritz</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Mechanisms of noise robust representations of speech in primary auditory cortex</article-title>. <source>PNAS</source> <year>2014</year>; <volume>111</volume>:<fpage>6792</fpage>–<lpage>6797</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1318017111" xlink:type="simple">10.1073/pnas.1318017111</ext-link></comment> <object-id pub-id-type="pmid">24753585</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rabinowitz</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BEB</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>. <article-title>Constructing noise-invariant representations of sound in the auditory pathway</article-title>. <source>Plos Biology</source>, <year>2013</year>; <volume>11</volume>:<fpage>e1001710</fpage> <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1001710" xlink:type="simple">10.1371/journal.pbio.1001710</ext-link></comment> <object-id pub-id-type="pmid">24265596</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Spratling</surname> <given-names>MW</given-names></name>. <article-title>Predictive coding as a model of response properties in cortical area V1</article-title>. <source>Journal of neuroscience</source> <year>2010</year>; <volume>30</volume>:<fpage>3531</fpage>–<lpage>3543</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4911-09.2010" xlink:type="simple">10.1523/JNEUROSCI.4911-09.2010</ext-link></comment> <object-id pub-id-type="pmid">20203213</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Koulakov</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Rinberg</surname> <given-names>D</given-names></name>. <article-title>Sparse Incomplete Representations: A Potential Role of Olfactory Granule Cells</article-title>. <source>Neuron</source>, <year>2011</year>; <volume>72</volume>:<fpage>124</fpage>–<lpage>136</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.07.031" xlink:type="simple">10.1016/j.neuron.2011.07.031</ext-link></comment> <object-id pub-id-type="pmid">21982374</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Boerlin</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Machens</surname> <given-names>CK</given-names></name>, <name name-style="western"><surname>Deneve</surname> <given-names>S</given-names></name>. <article-title>Predictive Coding of Dynamical Variables in Balanced Spiking Networks</article-title>. <source>PloS Computational Biology</source>, <year>2013</year>; <volume>9</volume>:<fpage>e1003258</fpage> <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003258" xlink:type="simple">10.1371/journal.pcbi.1003258</ext-link></comment> <object-id pub-id-type="pmid">24244113</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Olsen</surname> <given-names>SR</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>RI</given-names></name>. <article-title>Lateral presynaptic inhibition mediates gain control in an olfactory circuit</article-title>. <source>Nature</source>, <year>2008</year>; <volume>452</volume>:<fpage>956</fpage>–<lpage>960</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature06864" xlink:type="simple">10.1038/nature06864</ext-link></comment> <object-id pub-id-type="pmid">18344978</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Olsen</surname> <given-names>SR</given-names></name>, <name name-style="western"><surname>Bhandawat</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>RI</given-names></name>. <article-title>Divisive normalization in olfactory population codes</article-title>. <source>Neuron</source>, <year>2010</year>; <volume>66</volume>:<fpage>287</fpage>–<lpage>299</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2010.04.009" xlink:type="simple">10.1016/j.neuron.2010.04.009</ext-link></comment> <object-id pub-id-type="pmid">20435004</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lee</surname> <given-names>S-H</given-names></name>, <name name-style="western"><surname>Kwan</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Dan</surname> <given-names>Y</given-names></name>. <article-title>Interneuron subtypes and orientation tuning</article-title>. <source>Nature</source>, <year>2014</year>, <volume>73</volume>:<fpage>159</fpage>–<lpage>170</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005582.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lee</surname> <given-names>SH</given-names></name>, <name name-style="western"><surname>Kwan</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Phoumthipphavong</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Flannery</surname> <given-names>JG</given-names></name>, <name name-style="western"><surname>Masmanidis</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Taniguchi</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Huang</surname> <given-names>ZJ</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Boyden</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Deisseroth</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dan</surname> <given-names>Y</given-names></name>. <article-title>Activation of specific interneurons improves V1 feature selectivity and visual perception</article-title>. <source>Nature</source>, <year>2011</year>; <volume>488</volume>:<fpage>379</fpage>–<lpage>383</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature11312" xlink:type="simple">10.1038/nature11312</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Atallah</surname> <given-names>BV</given-names></name>, <name name-style="western"><surname>Bruns</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Scanziani</surname> <given-names>M</given-names></name>. <article-title>Parvalbumin-expressing interneurons linearly transform cortical responses to visual stimuli</article-title>. <source>Neuron</source>, <year>2012</year>; <volume>73</volume>:<fpage>159</fpage>–<lpage>170</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.12.013" xlink:type="simple">10.1016/j.neuron.2011.12.013</ext-link></comment> <object-id pub-id-type="pmid">22243754</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wilson</surname> <given-names>NR</given-names></name>, <name name-style="western"><surname>Runyan</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>FL</given-names></name>, <name name-style="western"><surname>Sur</surname> <given-names>M</given-names></name>. <article-title>Division and subtraction by distinct cortical inhibitory networks in vivo</article-title>. <source>Nature</source>, <year>2012</year>; <volume>488</volume>:<fpage>343</fpage>–<lpage>348</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature11347" xlink:type="simple">10.1038/nature11347</ext-link></comment> <object-id pub-id-type="pmid">22878717</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Holt</surname> <given-names>GR</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <article-title>Shunting inhibition does not have a divisive effect on firing rates</article-title>. <source>Neural Computation</source>, <year>1997</year>, <volume>9</volume>:<fpage>1001</fpage>–<lpage>1013</lpage> <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.1997.9.5.1001" xlink:type="simple">10.1162/neco.1997.9.5.1001</ext-link></comment> <object-id pub-id-type="pmid">9188191</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chance</surname> <given-names>FS</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>, <name name-style="western"><surname>Reyes</surname> <given-names>AD</given-names></name>. <article-title>Gain modulation from background synaptic input</article-title>. <source>Neuron</source>, <year>2002</year>; <volume>35</volume>:<fpage>773</fpage>–<lpage>782</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0896-6273(02)00820-6" xlink:type="simple">10.1016/S0896-6273(02)00820-6</ext-link></comment> <object-id pub-id-type="pmid">12194875</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mitchell</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Silver</surname> <given-names>RA</given-names></name>. <article-title>Shunting inhibition modulates neuronal gain during synaptic excitation</article-title>. <source>Neuron</source>, <year>2003</year>; <volume>38</volume>:<fpage>433</fpage>–<lpage>446</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0896-6273(03)00200-9" xlink:type="simple">10.1016/S0896-6273(03)00200-9</ext-link></comment> <object-id pub-id-type="pmid">12741990</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Senn</surname> <given-names>W</given-names></name>. <article-title>A synaptic explanation of suppression in visual cortex</article-title>. <source>Journal of Neuroscience</source>, <year>2002</year>; <volume>22</volume>:<fpage>10053</fpage>–<lpage>10065</lpage>. <object-id pub-id-type="pmid">12427863</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Finn</surname> <given-names>IM</given-names></name>, <name name-style="western"><surname>Priebe</surname> <given-names>NJ</given-names></name>, <name name-style="western"><surname>Furster</surname> <given-names>D</given-names></name>. <article-title>The emergence of contrast-invariant tuning in simple cells of cat visual cortex</article-title>. <source>Neuron</source>, <year>2007</year>, <volume>54</volume>:<fpage>137</fpage>–<lpage>152</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2007.02.029" xlink:type="simple">10.1016/j.neuron.2007.02.029</ext-link></comment> <object-id pub-id-type="pmid">17408583</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roberts</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Zinke</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Guo</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Robertson</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>McDonald</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Thiele</surname> <given-names>A</given-names></name>. <article-title>Acetylcholine dynamically controls spatial integration in marmoset primary visual cortex</article-title>. <source>J. Neurophysiology</source>, <year>2005</year>; <volume>93</volume>:<fpage>2062</fpage>–<lpage>2072</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00911.2004" xlink:type="simple">10.1152/jn.00911.2004</ext-link></comment> <object-id pub-id-type="pmid">15548624</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Haider</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Hausser</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>. <article-title>Inhibition dominates sensory responses in awake cortex</article-title>. <source>Nature</source>, <year>2013</year>; <volume>493</volume>:<fpage>97</fpage>–<lpage>102</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature11665" xlink:type="simple">10.1038/nature11665</ext-link></comment> <object-id pub-id-type="pmid">23172139</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kato</surname> <given-names>HK</given-names></name>, <name name-style="western"><surname>Chu</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Isaacson</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Komiyama</surname> <given-names>T</given-names></name>. <article-title>Dynamic Sensory Representations in the Olfactory Bulb: Modulation by Wakefulness and Experience</article-title>. <source>Neuron</source>, <year>2012</year>; <volume>76</volume>:<fpage>962</fpage>–<lpage>975</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.09.037" xlink:type="simple">10.1016/j.neuron.2012.09.037</ext-link></comment> <object-id pub-id-type="pmid">23217744</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005582.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Womelsdorf</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Anton-Erxleben</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Pieper</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Treue</surname> <given-names>S</given-names></name>. <article-title>Dynamic shifts of visual receptive fields in cortical area MT by spatial attention</article-title>. <source>Nature Neuroscience</source>, <year>2006</year>; <volume>9</volume>:<fpage>1156</fpage>–<lpage>1160</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1748" xlink:type="simple">10.1038/nn1748</ext-link></comment> <object-id pub-id-type="pmid">16906153</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
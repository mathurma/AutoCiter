<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004515</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-00349</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>At the Edge of Chaos: How Cerebellar Granular Layer Network Dynamics Can Provide the Basis for Temporal Filters</article-title>
<alt-title alt-title-type="running-head">Basis for Temporal Filters in the Cerebellar Granular Layer</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Rössert</surname>
<given-names>Christian</given-names>
</name>
<xref rid="currentaff001" ref-type="fn"><sup>¤</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
<xref rid="aff001" ref-type="aff"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Dean</surname>
<given-names>Paul</given-names>
</name>
<xref rid="aff001" ref-type="aff"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Porrill</surname>
<given-names>John</given-names>
</name>
<xref rid="aff001" ref-type="aff"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Department of Psychology, The University of Sheffield, Sheffield, United Kingdom</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Graham</surname> <given-names>Lyle J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Université Paris Descartes, Centre National de la Recherche Scientifique, FRANCE</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: CR PD JP. Performed the experiments: CR. Analyzed the data: CR PD JP. Contributed reagents/materials/analysis tools: CR PD JP. Wrote the paper: CR PD JP.</p>
</fn>
<fn fn-type="current-aff" id="currentaff001">
<label>¤</label><p>Current address: Blue Brain Project, EPFL, Geneva, Switzerland</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">christian.a@roessert.de</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>20</day>
<month>10</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="collection">
<month>10</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>10</issue>
<elocation-id>e1004515</elocation-id>
<history>
<date date-type="received">
<day>3</day>
<month>3</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>24</day>
<month>8</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Rössert et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004515" xlink:type="simple"/>
<abstract>
<p>Models of the cerebellar microcircuit often assume that input signals from the mossy-fibers are expanded and recoded to provide a foundation from which the Purkinje cells can synthesize output filters to implement specific input-signal transformations. Details of this process are however unclear. While previous work has shown that recurrent granule cell inhibition could in principle generate a wide variety of random outputs suitable for coding signal onsets, the more general application for temporally varying signals has yet to be demonstrated. Here we show for the first time that using a mechanism very similar to reservoir computing enables random neuronal networks in the granule cell layer to provide the necessary signal separation and extension from which Purkinje cells could construct basis filters of various time-constants. The main requirement for this is that the network operates in a state of criticality close to the edge of random chaotic behavior. We further show that the lack of recurrent excitation in the granular layer as commonly required in traditional reservoir networks can be circumvented by considering other inherent granular layer features such as inverted input signals or mGluR2 inhibition of Golgi cells. Other properties that facilitate filter construction are direct mossy fiber excitation of Golgi cells, variability of synaptic weights or input signals and output-feedback via the nucleocortical pathway. Our findings are well supported by previous experimental and theoretical work and will help to bridge the gap between system-level models and detailed models of the granular layer network.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>The cerebellum plays an important role in the learning of precise movements, and in humans holds 80% of all the neurons in the brain, due to numerous small cells called “granule cells” embedded in the granular layer. It is widely thought that the granular layer receives, transforms and delays input signals coming from many different senses like touch, vision and balance, and that these transformed signals then serve as a basis to generate responses that help to control the muscles of the body. But how the granular layer carries out this important transformation is still obscure. While current models can explain how the granular layer network could produce specific outputs for particular reflexes, there is at present no general understanding of how it could generate outputs that were computationally adequate for general movement control. With the help of a simulated granular layer network we show here that a random recurrent network can in principle generate the necessary signal transformation as long as it operates in a state close to chaotic behavior, also termed the “edge-of-chaos”.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by a grant from the European Union 2012 (REALNET, 270434 FP7) and partially supported by EPSRC grant no. EP/IO32533/1. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="9"/>
<table-count count="0"/>
<page-count count="28"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>All models, methods and simulation results are available from the github repository <ext-link ext-link-type="uri" xlink:href="https://github.com/croessert/ClosedLoopRoessertEtAl" xlink:type="simple">https://github.com/croessert/ClosedLoopRoessertEtAl</ext-link>. A snapshot of the model code can also be found on ModelDB: <ext-link ext-link-type="uri" xlink:href="https://senselab.med.yale.edu/modeldb/ShowModel.asp?model=168950" xlink:type="simple">https://senselab.med.yale.edu/modeldb/ShowModel.asp?model=168950</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Many models of the cerebellum assume that the granular layer recodes its mossy-fiber inputs into a more diverse set of granule-cell outputs [<xref rid="pcbi.1004515.ref001" ref-type="bibr">1</xref>–<xref rid="pcbi.1004515.ref004" ref-type="bibr">4</xref>]. It is further assumed that the recoded signals, which travel via granule-cell ascending axons and parallel fibers to Purkinje cells and molecular layer interneurons, are appropriately weighted using plastic synapses and then combined to produce the particular Purkinje cell outputs that are required for any given learning task. Recoding in these models thus enables a given set of mossy-fiber inputs to generate one of a very wide variety of Purkinje cell outputs, giving the model demonstrable computational power (e.g. [<xref rid="pcbi.1004515.ref005" ref-type="bibr">5</xref>]).</p>
<p>Although this framework is seen as plausible in broad outline (e.g. [<xref rid="pcbi.1004515.ref006" ref-type="bibr">6</xref>,<xref rid="pcbi.1004515.ref007" ref-type="bibr">7</xref>]), the details of its workings are far from established [<xref rid="pcbi.1004515.ref008" ref-type="bibr">8</xref>]. Relatively simple top-down models have shown that theoretically well-understood recoding schemes such as tapped delay lines, spectral timing, Gaussians, sinusoids, and exponentials can be effective, but do not establish how they could be implemented biologically (references in [<xref rid="pcbi.1004515.ref008" ref-type="bibr">8</xref>–<xref rid="pcbi.1004515.ref010" ref-type="bibr">10</xref>]). In contrast, more complex bottom-up models of recurrent inhibitory networks representing the connectivity between granule and Golgi cells are closer to biological plausibility, but have been used for very specific tasks such as eye-blink conditioning so that their general computational adequacy is unknown [<xref rid="pcbi.1004515.ref011" ref-type="bibr">11</xref>–<xref rid="pcbi.1004515.ref020" ref-type="bibr">20</xref>].</p>
<p>In part this is because eyeblink conditioning requires a response only at the time the unconditioned stimulus arrives. Eyelid (or nictitating membrane) position is not specified either for the period between the conditioned and unconditioned stimulus, or for the period (possibly some hundreds of milliseconds) after the unconditioned stimulus has been delivered. In contrast, for a task such as the vestibulo-ocular reflex eye-position is very precisely specified for as long as the head is moving, and afterwards for as long as gaze has to be held constant. Thus, cerebellar output—and hence granular-layer output—is more tightly constrained in motor-control tasks resembling the vestibulo-ocular reflex than in eyeblink conditioning [<xref rid="pcbi.1004515.ref003" ref-type="bibr">3</xref>].</p>
<p>Here we combine elements of top-down and bottom-up approaches, by investigating whether the outputs of neural networks that incorporate the recurrent inhibition observed in the granular layer can be linearly combined to generate continuous filter functions which are computationally useful for example in vestibulo-ocular reflex adaptation [<xref rid="pcbi.1004515.ref009" ref-type="bibr">9</xref>]. The split between a complex representation layer (granular layer) and a linear reconstruction layer (perhaps corresponding to the plastic synapses between granule cells and Purkinje cells or molecular-layer interneurons) is similar to the structure employed in reservoir computing [<xref rid="pcbi.1004515.ref021" ref-type="bibr">21</xref>], and it is convenient to use terminology and methods from that field in analyzing these networks (see <xref rid="sec002" ref-type="sec">Methods</xref>).</p>
<p>We begin by analyzing the case of a one-layer network with recurrent inhibition [<xref rid="pcbi.1004515.ref015" ref-type="bibr">15</xref>]. This is simpler than the real granular layer in which feedback is provided via a second layer of Golgi cell interneurons, but is worth analyzing separately because it allows us to test the hypothesis, suggested by the reservoir computing metaphor, that the crucial parameter in determining the time extension of responses is the mean amount of feedback in the network, and how closely this parameter is tuned to the edge-of-chaos [<xref rid="pcbi.1004515.ref022" ref-type="bibr">22</xref>]. This degree of tuning can be measured by the Lyapunov exponent. Generally speaking, if there is very little recurrent feedback in a network, then responses will be highly stable and die away very quickly over time, while for large amounts of feedback the responses can be chaotic or even unstable. The Lyapunov exponent (see <xref rid="sec002" ref-type="sec">Methods</xref>) is a quantitative measure of stability because it captures the rate of growth or decay of small perturbations. In linear systems negative values imply stability, while positive values imply instability. In non-linear systems, small, negative values of Lyapunov exponents can be especially interesting, since they can signal the ‘edge-of-chaos’, where there are long-lasting and possibly complex responses to transient inputs. We show that this is the interesting region for our reconstruction problem.</p>
<p>One novel feature of this contribution is its use of generic colored noise inputs, rather than the stereotyped pulse or step inputs that are usually considered. These colored-noise inputs are essential for motor control applications such as the VOR, where they are needed to demonstrate that the filter can process generic vestibular signals. A second novel feature is the use of statistical techniques that allow us to evaluate the ability of the network to approximate the range of linear filters required for these applications.</p>
<p>While previous work on reservoir networks focused on generic inhibitory and excitatory networks [<xref rid="pcbi.1004515.ref022" ref-type="bibr">22</xref>–<xref rid="pcbi.1004515.ref030" ref-type="bibr">30</xref>] this is the first work to systematically examine stability and reservoir performance in networks dominated by recurrent inhibition like the granular layer while also taking into account the effects of cerebellar network properties on filter approximations. To achieve this we extend the model to two populations in order to represent inhibition via Golgi cells. We also test the effect of other non-generic features of the cerebellum such as the newly discovered functional feature of Golgi cell inhibition by mGluR2 receptor activated GIRK channels [<xref rid="pcbi.1004515.ref031" ref-type="bibr">31</xref>,<xref rid="pcbi.1004515.ref032" ref-type="bibr">32</xref>] and Golgi cell afferent excitation often neglected in cerebellar simulations. Furthermore we also evaluate the effect of output-feedback to the granular layer through the nucleocortical pathway.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec003">
<title>One population model</title>
<p>The one-population model used in this study (<xref rid="pcbi.1004515.g001" ref-type="fig">Fig 1A</xref>) was based on that of Yamazaki and Tanaka [<xref rid="pcbi.1004515.ref015" ref-type="bibr">15</xref>]. It consisted of <italic>N</italic><sub><italic>z</italic></sub> = 1000 granule cells, each receiving excitatory afferent inputs <italic>I</italic><sub><italic>i</italic></sub>(<italic>t</italic>) derived from the external signal <italic>x</italic>(<italic>t</italic>), and recurrent inhibitory inputs from other cells. The model neurons were firing-rate (i.e. non-spiking), and the output <italic>z</italic><sub><italic>i</italic></sub>(<italic>t</italic>) of the i-th neuron at time t was given by
<disp-formula id="pcbi.1004515.e001">
<alternatives>
<graphic id="pcbi.1004515.e001g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e001" xlink:type="simple"/>
<mml:math display="block" id="M1" overflow="scroll">
<mml:mrow><mml:msub><mml:mtext>z</mml:mtext><mml:mtext>i</mml:mtext></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mtext>t</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:munderover><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mi>Nz</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>ij</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ij</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:munderover><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>nN</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
(here the bracket notation []<sup>+</sup>is used to set negative values to zero, preventing the firing-rate of a neuron from becoming negative). This equation describes (see <xref rid="pcbi.1004515.g001" ref-type="fig">Fig 1A</xref>) memory-less rate-neurons connected by single-exponential synaptic process with time constant <italic>τ</italic><sub><italic>w</italic></sub> so that neuron <italic>i</italic> sums past inputs <italic>z</italic><sub><italic>j</italic></sub>(<italic>s</italic> − 1),1≤ s ≤ t from other neurons, exponentially weighted by distance <italic>s</italic> − <italic>t</italic> into the past. Neuron <italic>j</italic> has synaptic weight <italic>A</italic><sub><italic>ij</italic></sub> <italic>w</italic><sub><italic>ij</italic></sub> on neuron <italic>i</italic> where <italic>A</italic><sub><italic>ij</italic></sub> was set to 1 with probability <italic>a</italic> and 0 otherwise, hence the parameter <italic>a</italic> controls the sparsity of the connectivity. The connectivity strengths <italic>w</italic><sub><italic>ij</italic></sub> were drawn from a normal distribution with mean <italic>w</italic> and standard deviation <italic>v</italic><sub><italic>w</italic></sub><italic>w</italic>, normalized by population size Nz, and constrained to be positive, so that <inline-formula id="pcbi.1004515.e002"><alternatives><graphic id="pcbi.1004515.e002g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e002" xlink:type="simple"/><mml:math display="inline" id="M2" overflow="scroll"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>±</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>. Each neuron received an excitatory input <italic>I</italic><sub><italic>i</italic></sub>(<italic>t</italic>) with additive noise <italic>nN</italic><sub><italic>i</italic></sub>(<italic>t</italic>) (here <italic>N</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is a discrete white noise process with <italic>std</italic>(<italic>N</italic>) = 1/2 so that the added noise is smaller in magnitude than the noise amplitude <italic>n</italic> 95% of the time).</p>
<fig id="pcbi.1004515.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004515.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Granular layer models and filter construction procedure.</title>
<p><bold>A:</bold> Diagram of one-population granular layer model based on Yamazaki and Tanaka [<xref rid="pcbi.1004515.ref015" ref-type="bibr">15</xref>] consisting of mutually inhibiting granule cells and input signals coded by push-pull input. <bold>B</bold>: Diagram of two-population granular layer model consisting of granule cells (GC) and Golgi cells (GO). GC innervate GO using glutamatergic excitation (u) and inhibition by mGluR2 activated GIRK channels (m). GO inhibit GC by GABAergic inhibition (w). All synaptic connection simulated using single exponential processes (see <xref rid="sec002" ref-type="sec">Methods</xref>). <bold>C</bold>: Input signal <italic>x</italic>(<italic>t</italic>) consisting of colored noise input for training, test and impulse response input. <bold>D</bold>: Diagram of filter construction test procedure. The output signals <italic>z</italic><sub><italic>i</italic></sub>(<italic>t</italic>) of all granule cells during the training sequence were used to construct exponential (leaky integrator) filters of increasing time constants <italic>τ</italic><sub><italic>j</italic></sub> = 10ms (blue line), 100ms (green line) and 500ms (red line) using LASSO regression (see <xref rid="sec002" ref-type="sec">Methods</xref>). The goodness-of-fit (<italic>R</italic><sup>2</sup>) of this filter construction was evaluated during the noise test sequence.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.g001" position="float" xlink:type="simple"/>
</fig>
<p>In the simulations, unless otherwise specified, we used the following default values for the parameters above. The population size was <italic>Nz</italic> = 1000. The probability of connectivity was <italic>a</italic> = 0.4 (close to the value 0.5 in Yamazaki and Tanaka [<xref rid="pcbi.1004515.ref015" ref-type="bibr">15</xref>]), and synaptic variability was set to zero (<italic>v</italic><sub><italic>w</italic></sub> = 0). The default input noise level was <italic>n</italic> = 0.</p>
<p>This model had a single time constant which Yamazaki and Tanaka [<xref rid="pcbi.1004515.ref015" ref-type="bibr">15</xref>] took to be equal to the membrane time constant of Golgi cells in their simulations of granular layer dynamics. However it is not clear that this is the relevant time constant for a firing-rate model since the dynamics of the sub-threshold domain cannot be easily carried over into the supra-threshold (spiking) domain and are often counter intuitive. While a still prevailing misconception is that long membrane time-constants are equal to a slow spike response, the exact opposite is the case: integrate-and-fire with an infinite time constant (perfect integrators) have the fastest response time to a current step and can respond almost instantaneously [<xref rid="pcbi.1004515.ref033" ref-type="bibr">33</xref>]. Since temporal dynamics of neurons in a network are primarily determined by the time course of the synaptic currents [<xref rid="pcbi.1004515.ref033" ref-type="bibr">33</xref>–<xref rid="pcbi.1004515.ref036" ref-type="bibr">36</xref>] we have ignored membrane time constants in this and following models and instead related <italic>τ</italic><sub><italic>w</italic></sub> to the synaptic time constant of recurrent inhibition in the network.</p>
<p>We further want to note that the values for the synaptic time constants were not directly adjusted to replicate results for individual electrophysiological studies but rather kept at general values to study the effect on network output of interaction between different magnitudes of time constants. This issue is considered further in the Discussion.</p>
</sec>
<sec id="sec004">
<title>Two population model</title>
<p>To allow for more realistic modeling of the dynamics of the granular layer we extended the one-population network of granule cells above to include inhibition via a population of interneurons corresponding to Golgi cells (see <xref rid="pcbi.1004515.g001" ref-type="fig">Fig 1B</xref>). In this model the firing-rates <italic>z</italic><sub><italic>i</italic></sub>(<italic>t</italic>) of granule cells and <italic>q</italic><sub><italic>i</italic></sub>(<italic>t</italic>) of Golgi cells were given by
<disp-formula id="pcbi.1004515.e003">
<alternatives>
<graphic id="pcbi.1004515.e003g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e003" xlink:type="simple"/>
<mml:math display="block" id="M3" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:munderover><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:munderover><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
<disp-formula id="pcbi.1004515.e004">
<alternatives>
<graphic id="pcbi.1004515.e004g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e004" xlink:type="simple"/>
<mml:math display="block" id="M4" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mi>j</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:munderover><mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:munderover><mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>The default sizes for the two populations were <italic>Nz</italic> = 1000 and <italic>Nq</italic> = 100. As before, the excitatory afferent input into a granule cell <italic>i</italic> was given by <italic>I</italic><sub><italic>i</italic></sub>(<italic>t</italic>), however the two-population model also had direct afferent excitation <italic>gI</italic><sub><italic>i</italic></sub>(<italic>t</italic>) of Golgi cells. The factor <italic>g</italic> setting the level of excitation was set to 0 in the initial simulations, resulting in no afferent excitation for Golgi cells. The output-feedback <italic>L</italic>(<italic>t</italic>) was 0 until later simulations (see below). The connectivity between the two populations was given by the random binary connection matrices <italic>W</italic> and <italic>U</italic>, however in this model the connectivity was not defined by a probability but by the convergence ratios <italic>c</italic><sub><italic>w</italic></sub> = 4 between Golgi and granule cells and <italic>c</italic><sub><italic>u</italic></sub> = 100 vice versa. Thus exactly 4 randomly selected Golgi cells inhibited each granule cell and 100 randomly chosen granule cells were connected to each Golgi cell. The weight of GABAergic inhibition between Golgi and granule cells was drawn from a normal distribution and normalized with <inline-formula id="pcbi.1004515.e005"><alternatives><graphic id="pcbi.1004515.e005g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e005" xlink:type="simple"/><mml:math display="inline" id="M5" overflow="scroll"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>±</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>(default <italic>v</italic><sub><italic>w</italic></sub> = 0) and the time constant of inhibition was given by <italic>τ</italic><sub><italic>w</italic></sub>. Besides the glutamatergic excitatory connections between granule and Golgi cells with weight <inline-formula id="pcbi.1004515.e006"><alternatives><graphic id="pcbi.1004515.e006g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e006" xlink:type="simple"/><mml:math display="inline" id="M6" overflow="scroll"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>±</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> (default <italic>v</italic><sub><italic>u</italic></sub> = 0) and time constant <italic>τ</italic><sub><italic>u</italic></sub> the model was extended to emulate the inhibitory effect of mGluR2 activated GIRK channels [<xref rid="pcbi.1004515.ref031" ref-type="bibr">31</xref>] with <inline-formula id="pcbi.1004515.e007"><alternatives><graphic id="pcbi.1004515.e007g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e007" xlink:type="simple"/><mml:math display="inline" id="M7" overflow="scroll"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>±</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> (default <italic>m</italic> = 0, <italic>v</italic><sub><italic>m</italic></sub> = 0) and time constant <italic>τ</italic><sub><italic>m</italic></sub> = 50ms. Note that mGluR2 inhibition was not used until later simulations with <italic>m</italic> = 0.003. Additional simulations were conducted with only half of the Golgi cells receiving mGluR2 inhibition i.e. <italic>Pr</italic>(<italic>m</italic> = 0) = 0.5.</p>
<p>In all simulations <italic>u</italic> was set to 0.1 and normalized by the excitatory time constant resulting in <italic>u</italic> = 0.1/<italic>τ</italic><sub><italic>u</italic></sub>.</p>
<p>All network simulations were written in C and were integrated into Python by transforming them into dynamically linked extensions with the package <italic>distutils</italic>. The stepsize in all simulations was <italic>dt</italic> = 1<italic>ms</italic>. All results were analyzed using Python. All models, methods and simulation results are available from the github repository <ext-link ext-link-type="uri" xlink:href="https://github.com/croessert/ClosedLoopRoessertEtAl" xlink:type="simple">https://github.com/croessert/ClosedLoopRoessertEtAl</ext-link>. A snapshot of the model code can also be found on ModelDB: <ext-link ext-link-type="uri" xlink:href="https://senselab.med.yale.edu/modeldb/ShowModel.asp?model=168950" xlink:type="simple">https://senselab.med.yale.edu/modeldb/ShowModel.asp?model=168950</ext-link>. Computational resources for the simulations were partially provided by the ICEBERG cluster (University of Sheffield; access granted by the INSIGNEO Institute for in silico Medicine).</p>
</sec>
<sec id="sec005">
<title>Input</title>
<p>The modulated input to each cell was given by the excitatory input <italic>I</italic><sub><italic>i</italic></sub>(<italic>t</italic>) = [<italic>I</italic><sub>0i</sub> + <italic>f</italic> ∙ 0.1 ∙ <italic>I</italic><sub>0i</sub> ∙ <italic>x</italic>(<italic>t</italic>)]<sup>+</sup>. Unless noted otherwise the input <italic>I</italic><sub>0i</sub> was chosen from a normal distribution with mean 1 and default standard deviation <italic>v</italic><sub><italic>I</italic></sub> = 0.1. To test increased input variability, standard deviation was increased to <italic>v</italic><sub><italic>I</italic></sub> = 2 in a later experiment. The factor <italic>f</italic>, randomly picked as either 1 or -1 defined whether the input was inverted or not. This type of input coding, here termed “push-pull” coding can be routinely found for example in the vestibulo-cerebellum where half of the cells are ipsilateral preferring (<italic>f</italic> = 1, type I) or contralateral preferring (<italic>f</italic> = −1, type II) [<xref rid="pcbi.1004515.ref037" ref-type="bibr">37</xref>].</p>
<p>In order to test the ability of the network to construct a linear filter with a given impulse response it is not sufficient to use impulse inputs alone, since this does not test linearity (for example the response to two successive impulse inputs may not be the sum of the individual responses). For this reason we also used random process inputs that mimic behavioral inputs.</p>
<p>The input signal <italic>x</italic>(<italic>t</italic>) consisted of 3 parts (see <xref rid="pcbi.1004515.g001" ref-type="fig">Fig 1C</xref>). The first part was a training sequence of a 5 second band-passed white noise signal (low-passed with a maximum frequency of 20 Hz) [<xref rid="pcbi.1004515.ref038" ref-type="bibr">38</xref>] chosen to mimic head velocity in the behaviorally relevant frequency range of 0–20 Hz [<xref rid="pcbi.1004515.ref039" ref-type="bibr">39</xref>]. Additionally a 5 second silent signal (<italic>x</italic>(<italic>t</italic>) = 0) was added to the training sequence to train a stable response. Training with a segment of null data finds weights which not only give the appropriate impulse response but also produce zero output for zero input data, so that they reject spontaneous modulatory activity in the network. Consecutively the previous signals were repeated with a different realization of the noise signal to test the quality of the filter construction. The third part was an impulse test signal where <italic>x</italic>(<italic>t</italic>) = 0 apart from a brief pulse of 50 ms where <italic>x</italic>(<italic>t</italic>) = 1. The colored noise signal was normalized to <italic>std</italic>(<italic>x</italic>) = 1/2 which ensured that the amplitude 0.1 ∙ <italic>I</italic><sub>0i</sub> included the input 95% of the time.</p>
</sec>
<sec id="sec006">
<title>Filter construction and quality measure</title>
<p>To assess the ability of the network to implement linear filters that depend on the past history of the inputs, the output signals <italic>z</italic><sub><italic>i</italic></sub>(<italic>t</italic>) of all granule cells during the training sequence were used to construct exponential (leaky integrator) filters <italic>y</italic>(<italic>t</italic>) = <italic>F</italic> * <italic>x</italic>(<italic>t</italic>) of increasing time constants as linear sums <italic>y</italic>(<italic>t</italic>) = ∑<italic>β</italic><sub><italic>i</italic></sub><italic>z</italic><sub><italic>i</italic></sub>(<italic>t</italic>) of granule cell outputs. This can be regarded as the output of an artificial Purkinje cell that acts as a linear neuron. In matrix terms (writing time series in columns) this expression can be written <italic>y</italic> −<italic>Zβ</italic> where the undetermined coefficients <italic>β</italic> are usually fitted by the method of least squares to minimize root sum square fitting error
<disp-formula id="pcbi.1004515.e008">
<alternatives>
<graphic id="pcbi.1004515.e008g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e008" xlink:type="simple"/>
<mml:math display="block" id="M8" overflow="scroll">
<mml:mrow><mml:mo stretchy="false">∥</mml:mo><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:mi>Z</mml:mi><mml:mi>β</mml:mi><mml:msub><mml:mo stretchy="false">∥</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:msup><mml:mstyle displaystyle="true"><mml:mo>Σ</mml:mo></mml:mstyle><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mo>​</mml:mo></mml:msup><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow><mml:mo>​</mml:mo></mml:msup></mml:mrow><mml:mrow/></mml:munder></mml:mrow></mml:msqrt></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula></p>
<p>However over-fitting of the data, due to the large output population, can make this method misleading and give excessively high estimates of reconstruction accuracy. To avoid this problem we used the method of LASSO regression taken from the reservoir computing literature. This is a robust fitting procedure that includes a regularization term to keep the reconstruction weights small [<xref rid="pcbi.1004515.ref040" ref-type="bibr">40</xref>,<xref rid="pcbi.1004515.ref041" ref-type="bibr">41</xref>]. Here, the estimates are defined by <inline-formula id="pcbi.1004515.e009"><alternatives><graphic id="pcbi.1004515.e009g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e009" xlink:type="simple"/><mml:math display="inline" id="M9" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mtext>argmin</mml:mtext></mml:mrow><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mfenced open="‖" close="‖" separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mi>Z</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mfenced open="‖" close="‖" separators="|"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mi> </mml:mi></mml:math></alternatives></inline-formula> which is the least-squares minimization above with the additional constraint that the <italic>L</italic><sup>1</sup>-norm ||<italic>β</italic>||<sub>1</sub> = ∑<italic>β</italic><sub><italic>i</italic></sub> of the parameter vector is also kept small. In practice we find that up to about 90% of weights are effectively zero using this method. In contrast to ridge regression that employs a <italic>L</italic><sup>2</sup> -norm penalty and is commonly used to prevent over-fitting in reservoir computing [<xref rid="pcbi.1004515.ref027" ref-type="bibr">27</xref>] LASSO regression produces very sparse weight distributions. This corresponds well to the actual learning properties of the Purkinje cell, approximated as a linear neuron, in which optimality properties of the learning rule with respect to input noise force the majority of synapses to silence [<xref rid="pcbi.1004515.ref042" ref-type="bibr">42</xref>–<xref rid="pcbi.1004515.ref045" ref-type="bibr">45</xref>].</p>
<p>We fitted three responses <italic>y</italic><sub><italic>j</italic></sub>(<italic>t</italic>) = <italic>x</italic>(<italic>t</italic>)* <italic>F</italic><sub><italic>j</italic></sub>(<italic>t</italic>) with <italic>j</italic> = 1,2,3 and with <italic>F</italic><sub><italic>j</italic></sub>(<italic>t</italic>) = exp(−<italic>t</italic>/<italic>τ</italic><sub><italic>j</italic></sub>) being one of three exponential filters <italic>τ</italic><sub><italic>1</italic></sub> = 10<italic>ms</italic>, <italic>τ</italic><sub><italic>2</italic></sub> = 100<italic>ms</italic> or <italic>τ</italic><sub><italic>3</italic></sub> = 500<italic>ms</italic> (see <xref rid="pcbi.1004515.g001" ref-type="fig">Fig 1D</xref>). The regularization coefficient was set to <italic>α</italic> = 1<italic>e</italic><sup>−4</sup> which gave best maximum mean goodness-of-fit results for the one-population model with <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic> (not shown). LASSO regression was implemented using the function <italic>sklearn</italic>.<italic>linear_model</italic>.<italic>Lasso()</italic> from the python package <italic>scikit-learn</italic> [<xref rid="pcbi.1004515.ref046" ref-type="bibr">46</xref>].</p>
<p>In general the estimated weights <italic>β</italic><sub><italic>i</italic></sub> take both positive and negative values, which is not compatible with the interpretation of equation (4) above as parallel fiber synthesis by Purkinje cells. The use of negative weights is usually justified by assuming a relay through inhibitory molecular interneurons [<xref rid="pcbi.1004515.ref042" ref-type="bibr">42</xref>,<xref rid="pcbi.1004515.ref044" ref-type="bibr">44</xref>]. To test whether learning at parallel fibers alone is sufficient for the construction of filters from reservoir signals we additionally employed LASSO regression with only positive coefficients (positive-LASSO) as a comparison.</p>
<p>As a measure of the quality of filter construction, the weights estimated from the training sequence were used to construct the filtered responses in the test sequence and the goodness-of-fit between expected output and constructed output was computed for each filter using the squared Pearson correlation coefficient (<italic>R</italic><sup>2</sup>) [<xref rid="pcbi.1004515.ref047" ref-type="bibr">47</xref>] (see <xref rid="pcbi.1004515.g001" ref-type="fig">Fig 1D</xref>). For the final goodness-of-fit measure the mean of 10 networks with identical properties but with different random connections was computed.</p>
</sec>
<sec id="sec007">
<title>Lyapunov exponent estimation</title>
<p>A convenient way to analyze the stability or chaoticity of a dynamic system is the Lyapunov exponent <italic>λ</italic>. It is a measure for the exponential deviation of a system resulting from a small disturbance [<xref rid="pcbi.1004515.ref025" ref-type="bibr">25</xref>] and a value larger than 0 indicates a chaotic system. The Lyapunov exponent was measured empirically, similar to Legenstein and Maass [<xref rid="pcbi.1004515.ref022" ref-type="bibr">22</xref>] by calculating the average Euclidian distance <inline-formula id="pcbi.1004515.e010"><alternatives><graphic id="pcbi.1004515.e010g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e010" xlink:type="simple"/><mml:math display="inline" id="M10" overflow="scroll"><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msqrt><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>'</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msqrt></mml:math></alternatives></inline-formula> between all granule cell rates <italic>z</italic><sub><italic>i</italic></sub>(<italic>t</italic>) from a simulation where <italic>x</italic>(<italic>t</italic>) = 0 and the rates <inline-formula id="pcbi.1004515.e011"><alternatives><graphic id="pcbi.1004515.e011g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e011" xlink:type="simple"/><mml:math display="inline" id="M11" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>'</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> from a second simulation where the input was disturbed by a small amount at one time step, i.e. <italic>x</italic>(0) = 10<sup>−14</sup>. This state separation simulation was repeated for 10 randomly connected networks but otherwise identical parameters and <italic>λ</italic> was estimated from the mean average Euclidian distance <inline-formula id="pcbi.1004515.e012"><alternatives><graphic id="pcbi.1004515.e012g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e012" xlink:type="simple"/><mml:math display="inline" id="M12" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></alternatives></inline-formula> with <inline-formula id="pcbi.1004515.e013"><alternatives><graphic id="pcbi.1004515.e013g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e013" xlink:type="simple"/><mml:math display="inline" id="M13" overflow="scroll"><mml:mi>λ</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:mrow><mml:mtext>mean</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mn>2.01</mml:mn><mml:mi>s</mml:mi><mml:mo>:</mml:mo><mml:mn>2.11</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo><mml:mo>/</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>mean</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mn>0.01</mml:mn><mml:mi>s</mml:mi><mml:mo>:</mml:mo><mml:mn>0.11</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfenced><mml:mo>/</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>. To estimate the transition between stability and chaos we were mainly interested in the sign of the Lyapunov exponent. Although taking the mean of a 100 ms period and using a relatively large Δ<italic>t</italic> of 2s [<xref rid="pcbi.1004515.ref024" ref-type="bibr">24</xref>] decreases the accuracy of the Lyapunov estimation, it was used here to prevent errors in the estimation of the sign. The edge-of-chaos was defined as the point where <italic>λ</italic> crosses 0 for the first time when traversing in the direction of strong inhibition <italic>w</italic> to weak and therefore from high <italic>λ</italic> to low.</p>
</sec>
<sec id="sec008">
<title>Output feedback</title>
<p>To model putative output-feedback to the reservoir via the nucleocortical pathway the signal <italic>L</italic>(<italic>t</italic>) = <italic>f</italic> ∙ <italic>o</italic><sub><italic>i</italic></sub> ∙ −∑<italic>β</italic><sub><italic>i</italic></sub><italic>z</italic><sub><italic>i</italic></sub>(<italic>t</italic>) was injected into 20% of all granule and Golgi cells in the last simulations. The factor <italic>f</italic> was randomly picked as either 1 or -1 to model 50% excitation and inhibition and the weight was drawn from a normal distribution with <italic>o</italic><sub><italic>i</italic></sub> = [1<italic>e</italic><sup>−4</sup>±1<italic>e</italic><sup>−5</sup>]<sup>+</sup>. In these simulations only the case for output-feedback of the slowest filter signal is shown. Thus <italic>β</italic><sub><italic>i</italic></sub> are the weights needed to construct the filter with <italic>τ</italic><sub>3</sub> = 500<italic>ms</italic>.</p>
<p>As noted in the reservoir computing literature [<xref rid="pcbi.1004515.ref027" ref-type="bibr">27</xref>,<xref rid="pcbi.1004515.ref048" ref-type="bibr">48</xref>,<xref rid="pcbi.1004515.ref049" ref-type="bibr">49</xref>] output-feedback in general is a very difficult task since it leads to instability. Therefore the weights <italic>β</italic><sub><italic>i</italic></sub> were not learned online but a method called teacher forcing with noise was applied [<xref rid="pcbi.1004515.ref027" ref-type="bibr">27</xref>]. The weights <italic>β</italic><sub><italic>i</italic></sub> were learned in a prior step by using the teacher signal <italic>L</italic>′(<italic>t</italic>) = <italic>f</italic> ∙ <italic>o</italic><sub><italic>i</italic></sub> ∙ −<italic>y</italic><sub>3</sub>(<italic>t</italic>) ∙ <italic>N</italic>(<italic>t</italic>) instead of the feedback signal <italic>L</italic>(<italic>t</italic>) to uncouple the instable learning. Here <italic>y</italic><sub>3</sub>(<italic>t</italic>) is the target response for the slowest filter (<xref rid="pcbi.1004515.g001" ref-type="fig">Fig 1D</xref>) and <italic>N</italic>(<italic>t</italic>) is a discrete white noise process that helps to increase the dynamical stability [<xref rid="pcbi.1004515.ref027" ref-type="bibr">27</xref>]. The quality of filter construction and the Lyapunov exponent were estimated in a second simulation using the previously learned weights <italic>β</italic><sub><italic>i</italic></sub> for filter construction and the feedback signal <italic>L</italic>(<italic>t</italic>).</p>
</sec>
</sec>
<sec id="sec009" sec-type="results">
<title>Results</title>
<p>This section describes how filters with different time constants can be constructed from the activity of granular-layer-like networks of randomly connected neurons with recurrent inhibition, first for the one-population model consisting solely of simulated granule cells, then for the two-population model with both granule and Golgi cells.</p>
<sec id="sec010">
<title>One-population model</title>
<p>In the first part of this study we focused on the one-population rate-neuron model previously published by Yamazaki and Tanaka [<xref rid="pcbi.1004515.ref015" ref-type="bibr">15</xref>]. While in this previous study the model was used to represent the passage of time, i.e. an internal clock, we now show that it is also possible to use its output to construct exponential filters with various time-constants.</p>
<p>To illustrate the dependence of network stability regime on the amount of feedback we begin by presenting sample impulse responses (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2</xref>, second row) for a network (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2</xref>, top) with intermediate time constant <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic> and with three values of the recurrent inhibition: <italic>w</italic> = 0.01, lying in the highly stable region, <italic>w</italic> = 1.4, close to the edge-of-chaos, and <italic>w</italic> = 3, in the chaotic region. When the weight <italic>w</italic> was low, (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2A</xref>, <italic>w</italic> = 0.01) the network was highly stable to perturbations and showed no long lasting responses. Close to the edge-of-chaos (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2B</xref>, <italic>w</italic> = 1.4) complex, long lasting responses were present. For larger weights (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2C</xref>, <italic>w</italic> = 3) the network entered a chaotic state in which cells showed random activity without further input modulation.</p>
<fig id="pcbi.1004515.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004515.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Responses of constructed filters and individual granule cell rates.</title>
<p><bold>A,B,C</bold>: Individual responses of randomly selected granule cells with weights <italic>w</italic> = 0.01 (<bold>A</bold>), <italic>w</italic> = 1.4 (<bold>B</bold>), <italic>w</italic> = 3 (<bold>C</bold>). Black bars indicate duration of pulse input. <bold>D</bold>,<bold>E</bold>: Responses of filters (<italic>τ</italic><sub>1</sub> = 10<italic>ms</italic> (<bold>D1</bold>,<bold>E1</bold>), <italic>τ</italic><sub>2</sub> = 100<italic>ms</italic> (<bold>D2</bold>,<bold>E2</bold>) and <italic>τ</italic><sub>3</sub> = 500<italic>ms</italic> (<bold>D3</bold>,<bold>E3</bold>)) constructed from network with inhibitory time constant <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic> and inhibitory weight <italic>w</italic> = 1.4 (blue, green and red lines), <italic>w</italic> = 3 (light blue, light green and light red lines) or <italic>w</italic> = 0.01 (dotted light blue, light green and light red lines) to colored noise input (<bold>D</bold>) or pulse input (<bold>E</bold>). Responses of corresponding ideal filters shown as black lines. To construct the shown filters of 10/100/500ms the percentage of weights equal 0 and mean absolute weights &gt; 0 was 90/53/34% and 20.6/60.4/86.1 for <italic>w</italic> = 0.01, 76/70/65% and 4.2/13.6/26.5 for <italic>w</italic> = 3 and 91/86/75% and 5.5/11.7/52.6 for <italic>w</italic> = 1.4, respectively.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.g002" position="float" xlink:type="simple"/>
</fig>
<p>We further illustrate this dependence in the last two rows of <xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2</xref> which shows filter constructions (see <xref rid="sec002" ref-type="sec">Methods</xref>) for three target exponential filters with time constants <italic>τ</italic><sub><italic>i</italic></sub> of 10 ms (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2D1 and 2E1</xref>), 100 ms (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2D2 and 2E2</xref>) and 500 ms (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2D3 and 2E3</xref>) (chosen to cover the range of performance required for e.g. VOR plant compensation [<xref rid="pcbi.1004515.ref009" ref-type="bibr">9</xref>]; filter construction of intermediate time constants are not shown, but are generally of similar quality). It is clear that in the highly stable regime only fast and intermediate time constant responses could be reconstructed (dotted light lines). Near the edge-of-chaos acceptable reconstructions were possible at all three time constants (dark lines), and in the chaotic regime reconstruction was always inaccurate and showed oscillatory artifacts (solid light lines).</p>
<p>While Yamazaki and Tanaka [<xref rid="pcbi.1004515.ref015" ref-type="bibr">15</xref>] argued that this chaotic network state is the preferred network state to implement an internal clock (compare <xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2C</xref> with Fig 1 from [<xref rid="pcbi.1004515.ref015" ref-type="bibr">15</xref>]) these results show that it is disadvantageous when a filter of a continuous signal has to be implemented (see <xref rid="sec014" ref-type="sec">Discussion</xref>).</p>
<p>We have noted above (<xref rid="sec002" ref-type="sec">Methods</xref>) that accurate reconstruction of the impulse response of a linear filter does not imply that the output for other inputs is correct; this requires linearity of the reconstructed filter. Linearity of the reconstructed filters is investigated in the second row of <xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2</xref> by comparing their effects on a band-passed noise signal with that of the exact filter (plotted in black), again for time constants <italic>τ</italic><sub><italic>j</italic></sub> of 10 ms (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2D1</xref>), 100 ms (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2D2</xref>) and 500 ms (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2D3</xref>), It is clear that the reconstruction in the stable regime or the chaotic regime (light lines) were much less accurate than in the edge-of-chaos-regime (dark lines). Note these plots show the response to a test input (rather than the training input, see <xref rid="sec002" ref-type="sec">Methods</xref>).</p>
<p>The regularized fitting method used (LASSO regression, see <xref rid="sec002" ref-type="sec">Methods</xref>) tends to use weights that are as small as possible. This property is clear in our example, to construct filters from granule cell signals at the edge-of-chaos only a small subset of granule cell responses were necessary. For the filters with 10, 100 and 500 ms (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2D and 2E</xref>; <italic>w</italic> = 1.4), the percentage of weights being equal to zero was 90%, 86% and 75%, respectively, and the mean of non-zero weights was 5.5 and 11.7 and 52.6, respectively. The high proportion of silent synapses is consistent with experimental findings (see <xref rid="sec014" ref-type="sec">Discussion</xref>)</p>
<p>As discussed previously, the value of <italic>w</italic> corresponding to the edge-of-chaos can be identified using the Lyapunov exponent (see <xref rid="sec002" ref-type="sec">Methods</xref>). We illustrate this property by investigating the dependence of filter reconstruction accuracy on the Lyapunov exponent (<xref rid="pcbi.1004515.g003" ref-type="fig">Fig 3</xref>). Results are shown for three networks with different time constants for the recurrent inhibition: <italic>τ</italic><sub><italic>w</italic></sub> = 10<italic>ms</italic> (column 1), <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic> (column 2) <xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2B</xref> and <italic>τ</italic><sub><italic>w</italic></sub> = 100<italic>ms</italic> (column 3) approximately corresponding to the ranges of membrane and synaptic time constants present in the granular layer.</p>
<fig id="pcbi.1004515.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004515.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Construction of basis filters using a randomly connected network with feed-forward inhibition using LASSO regression.</title>
<p><bold>A1,B1,C1</bold>: Lyapunov exponent of randomly connected networks with increasing weight <italic>w</italic>. Networks with three different feed-forward inhibition time-constants are considered: <italic>τ</italic><sub><italic>w</italic></sub> = 10<italic>ms</italic> (<bold>A1</bold>), <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic> (<bold>A2</bold>) and <italic>τ</italic><sub><italic>w</italic></sub> = 100<italic>ms</italic> (A3). Vertical black lines visualize the “edge-of-chaos” as defined in Methods. <bold>A2,B2,C2</bold>: Goodness of fit (<italic>R</italic><sup>2</sup>) of three exponential filters (<italic>τ</italic><sub>1</sub> = 10<italic>ms</italic> (blue), <italic>τ</italic><sub>2</sub> = 100<italic>ms</italic> (green) and <italic>τ</italic><sub>3</sub> = 500<italic>ms</italic> (red)) constructed from responses of corresponding networks above.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.g003" position="float" xlink:type="simple"/>
</fig>
<p>The top row of <xref rid="pcbi.1004515.g003" ref-type="fig">Fig 3</xref> shows the Lyapunov exponent of each network plotted against the amount of recurrent inhibition <italic>w</italic>. In each case there was a point at which the exponent crossed the zero axis, corresponding to the edge-of-chaos value for that network time constant. It can be seen that the amount of recurrent inhibition needed decreased as the time constant increased.</p>
<p>The bottom row shows the effect of <italic>w</italic> on reconstruction accuracy (measured by <italic>R</italic><sup>2</sup> goodness-of-fit) for exponential filters with the three time constants considered previously: <italic>τ</italic><sub><italic>j</italic></sub> = 10ms (blue lines), 100<italic>ms</italic> (green lines) and 500<italic>ms</italic> (red lines) for each network. Performance strongly depended on the weight of the recurrent inhibition. The goodness-of-fit was best, especially for filters with time constants longer than the internal inhibitory time-constant, for networks close to the edge-of-chaos, just before the transition from stable to chaotic behavior.</p>
<p>Other observations were that while, as expected, the goodness-of-fit for slow filters, e.g. 500<italic>ms</italic>, increased with the (inhibitory) time constant, the performance for fast filters decreased slightly (<xref rid="pcbi.1004515.g003" ref-type="fig">Fig 3C2</xref>). Furthermore the performance was best if the inhibitory time constant was equal to the time-constant of the filter (<xref rid="pcbi.1004515.g003" ref-type="fig">Fig 3A2</xref>, <italic>τ</italic><sub>1</sub> = 10<italic>ms</italic> blue line; <xref rid="pcbi.1004515.g003" ref-type="fig">Fig 3C2</xref>, <italic>τ</italic><sub>2</sub> = 100<italic>ms</italic> green line).</p>
<p><xref rid="pcbi.1004515.g004" ref-type="fig">Fig 4</xref> investigates the robustness of the properties described above to moderate levels of additive noise and to variability in input signal levels and synaptic weights. While white noise with amplitude of <italic>a</italic> = 0.01 (noise amplitude equal to 10% of the input modulation amplitude) lead to a reduction in goodness-of-fit (<xref rid="pcbi.1004515.g004" ref-type="fig">Fig 4A1</xref>) the principal mechanism of filter construction was not disrupted and the edge-of-chaos was only shifted to larger weights <italic>w</italic> (<xref rid="pcbi.1004515.g004" ref-type="fig">Fig 4A2</xref>). Increasing the between-neuron variability of the mean input excitation to a high value of e.g. <italic>v</italic><sub><italic>I</italic></sub> = 2 (i.e. 95% of constant input increased to 0–5 from 0.8–1.2 for default value <italic>v</italic><sub><italic>I</italic></sub> = 0.1) (<xref rid="pcbi.1004515.g004" ref-type="fig">Fig 4B1</xref> solid dark lines) had almost no benefit for the goodness-of-fit while shifting the edge-of-chaos to larger weight values.</p>
<fig id="pcbi.1004515.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004515.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Filter construction is sensitive to various parameters.</title>
<p>As previously, filters used are <italic>τ</italic><sub>1</sub> = 10<italic>ms</italic> (blue), <italic>τ</italic><sub>2</sub> = 100<italic>ms</italic> (green) and <italic>τ</italic><sub>3</sub> = 500<italic>ms</italic> (red). Default inhibitory time constant: <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic>. Goodness of fit (<italic>R</italic><sup>2</sup>) (<bold>A1,B1,C1</bold>) and Lyapunov exponent (<bold>A2,B2,C2</bold>) are compared to a control shown as light solid lines in all subplots. <bold>A</bold>: Effect of additive white noise (n = 0.01) in the network (dark lines). <bold>B</bold>: Effect of increased input variability (v<sub><italic>in</italic></sub> = 2) (dark solid lines) and increased variability of the inhibitory weight (v<sub><italic>w</italic></sub> = 2) (dotted lines). <bold>C</bold>: Effect of increased sparseness by reducing probability of connectivity to <italic>a</italic> = 0.04 for network size <italic>N</italic> = 1<italic>k</italic> (dotted lines) and <italic>N</italic> = 10<italic>k</italic> (dark solid lines). For a better comparison x-axis was normalized with the probability of connectivity a.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.g004" position="float" xlink:type="simple"/>
</fig>
<p>In contrast, imposing larger variability in the inhibitory weight with <italic>v</italic><sub><italic>w</italic></sub> = 2 (i.e. 95% of weights between 0 and <italic>w+</italic>4<italic>w</italic>) shifted the edge-of-chaos in the opposite direction—towards lower weights (<xref rid="pcbi.1004515.g004" ref-type="fig">Fig 4B2</xref>, dotted lines), and the quality of filter construction was increased (<xref rid="pcbi.1004515.g004" ref-type="fig">Fig 4B1</xref>, dotted lines). This phenomena may be caused by a proportion of input signals or weights being driven to zero due to the positive cut-off which effectively leads to some cells receiving no input and a reduction of connectivity, respectively. To test the effect of reduced connectivity we examined the direct effect of increased sparseness on reservoir performance (<xref rid="pcbi.1004515.g004" ref-type="fig">Fig 4C</xref>).</p>
<p>Two methods were used to increase sparseness: the first was to decrease the convergence of inhibition to 40 cells (<xref rid="pcbi.1004515.g004" ref-type="fig">Fig 4C1</xref>, dotted lines) by decreasing the network connectivity from <italic>a</italic> = 0.4 to <italic>a</italic> = 0.04 while keeping the network size at <italic>Nz</italic> = 1<italic>k</italic>. The second way was to increase the network size to <italic>Nz</italic> = 10<italic>k</italic> while keeping convergence constant at 400 cells (<xref rid="pcbi.1004515.g004" ref-type="fig">Fig 4C2</xref>, solid dark lines) with <italic>a</italic> = 0.04. While both cases resulted in an improvement of filter quality, a smaller convergence slightly outperformed an increased network size suggesting that a sampling from less cells is more beneficial since it leads to a higher diversity and variability.</p>
<p>An important requirement for filter construction turned out to be push-pull coding, found for example in the vestibulo-cerebellum, where half of the input signals are inverted (see <xref rid="sec014" ref-type="sec">Discussion</xref>). When the input did not include inverted signals the responses from individual granule cells showed almost no variety in damped oscillations in response to pulse input (<xref rid="pcbi.1004515.g005" ref-type="fig">Fig 5A</xref>). This consequently lead to an impairment of filter construction performance especially for larger filter time-constants and a shift of the edge-of-chaos to lower weights <italic>w</italic> (<xref rid="pcbi.1004515.g005" ref-type="fig">Fig 5B1</xref>, dark lines) when compared to the control case (light lines). Although filter construction performance was only slightly reduced when using regression with positive coefficients only (see <xref rid="sec002" ref-type="sec">Methods</xref>) (<xref rid="pcbi.1004515.g005" ref-type="fig">Fig 5C</xref>, light lines) when push-pull input was present, without push-pull input filter construction quality was heavily reduced (<xref rid="pcbi.1004515.g005" ref-type="fig">Fig 5C</xref>, dark lines).</p>
<fig id="pcbi.1004515.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004515.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Push-pull coding is beneficial for filter construction.</title>
<p><bold>A</bold>: Individual responses of randomly chosen granule cells with <italic>w</italic> = 1.4 but without push-pull input coding. Black bars indicate duration of pulse input. <bold>B</bold>: As previously, filters used are <italic>τ</italic><sub>1</sub> = 10<italic>ms</italic> (blue), <italic>τ</italic><sub>2</sub> = 100<italic>ms</italic> (green) and <italic>τ</italic><sub>3</sub> = 500<italic>ms</italic> (red). Default network: <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic> and push-pull input coding. <bold>B1</bold>: Default goodness of fit (<italic>R</italic><sup>2</sup>) (light lines) is compared to network without push-pull input coding (dark lines). <bold>B2</bold>: Goodness of fit for default network (light lines) is compared to network without push-pull input (dark lines) using regression with positive coefficients only. <bold>B3</bold>: Corresponding Lyapunov exponent for network with (dark orange line) and without push-pull coding (light orange lines).</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.g005" position="float" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec011">
<title>Two population model</title>
<p>While the previous model was able to show the principles of filter construction from a simplified model of the granular layer with recurrent inhibition, it did not take into account the fact that inhibition in the granular layer is relayed via a second population of cells, i.e. Golgi cells. To investigate the effects of this arrangement we extended the one-population model to a two-population model.</p>
<p>The connectivity of the extended model was based on plausible convergence ratios of <italic>c</italic><sub><italic>w</italic></sub> = 4 between Golgi and granule cells and <italic>c</italic><sub><italic>u</italic></sub> = 100 vice versa [<xref rid="pcbi.1004515.ref050" ref-type="bibr">50</xref>]. Additional parameters were excitatory time constant <italic>τ</italic><sub><italic>u</italic></sub> and the weight of excitation <italic>u</italic> (<xref rid="pcbi.1004515.g006" ref-type="fig">Fig 6</xref>, top). Increasing <italic>τ</italic><sub><italic>u</italic></sub> while keeping the inhibitory time constant at <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic> showed that the performance of the two-population model was very similar to the one-population model if the excitation is fast (<xref rid="pcbi.1004515.g006" ref-type="fig">Fig 6A1</xref>). However, increasing the excitatory time constant improved the quality of the constructed slow filter (<italic>τ</italic> = 500<italic>ms</italic>) at the expense of the faster filters (<italic>τ</italic> = 10<italic>ms</italic> and <italic>τ</italic> = 100<italic>ms</italic>) (<xref rid="pcbi.1004515.g006" ref-type="fig">Fig 6B1 and 6C1</xref>). Additionally, this leads to a lowered gradient of the Lyapunov exponent (<xref rid="pcbi.1004515.g006" ref-type="fig">Fig 6B2 and 6C2</xref>). We therefore focus in the following on the best-case scenario of <italic>τ</italic><sub><italic>u</italic></sub> = 1<italic>ms</italic> and <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic>. As in the one-population model before (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2B</xref>), responses of single granule and Golgi cells in networks close to the edge-of-chaos featured complex but stable, long lasting damped oscillations (not shown).</p>
<fig id="pcbi.1004515.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004515.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Construction of basis filters using a randomly connected network with feed-forward inhibition via a second population mimicking Golgi cells.</title>
<p>As previously, filters used are <italic>τ</italic><sub>1</sub> = 10<italic>ms</italic> (blue), <italic>τ</italic><sub>2</sub> = 100<italic>ms</italic> (green) and <italic>τ</italic><sub>3</sub> = 500<italic>ms</italic> (red). <bold>A,B,C</bold>: Goodness of fit (<italic>R</italic><sup>2</sup>) (<bold>A1,B1,C1</bold>) and Lyapunov exponents (<bold>A2,B2,C2</bold>) for three networks with <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic>, <italic>τ</italic><sub><italic>u</italic></sub> = 1<italic>ms</italic> (<bold>A</bold>), <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic>, <italic>τ</italic><sub><italic>u</italic></sub> = 50<italic>ms</italic> (<bold>B</bold>) and <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic>, <italic>τ</italic><sub><italic>u</italic></sub> = 100<italic>ms</italic> (<bold>C</bold>). Results for previous one-population network with <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic> shown as light lines. <bold>D</bold>: Effect of increased sparseness in a two-population network with <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic>, <italic>τ</italic><sub><italic>u</italic></sub> = 1<italic>ms</italic>: 1. Increase of granule cell population size from <italic>Nz</italic> = 1<italic>k</italic> (dark solid lines) to <italic>N</italic> = 10<italic>k</italic> (dotted lines). 2. Decrease of convergence to <italic>c</italic><sub><italic>u</italic></sub> = 10 while keeping network size at <italic>Nz</italic> = 1<italic>k</italic> (light solid lines). <bold>E</bold>: Effect of increased weight variability in a two-population network with <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic>, <italic>τ</italic><sub><italic>u</italic></sub> = 1<italic>ms</italic>. Compared to control network without weight variability (dark solid lines). 1. Increase of variability for weight of inhibition w (<italic>v</italic><sub><italic>w</italic></sub> = 4) (dotted lines). 2. Increase of variability for weight of excitation u (<italic>v</italic><sub><italic>u</italic></sub> = 4) (light lines)</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.g006" position="float" xlink:type="simple"/>
</fig>
<p>In <xref rid="pcbi.1004515.g006" ref-type="fig">Fig 6D</xref> we show that increased sparseness, achieved by reducing the convergence onto Golgi cells from <italic>c</italic><sub><italic>u</italic></sub> = 100 to <italic>c</italic><sub><italic>u</italic></sub> = 10 (light lines) increased the quality of constructed filters as in the previous model. However, this time, increasing the granular cell population size to <italic>Nz</italic> = 10<italic>k</italic> (dotted lines) has almost no beneficial effect, which can be attributed to the bottleneck effect of the small Golgi cell population of <italic>Nq</italic> = 100 (compare to <xref rid="pcbi.1004515.g004" ref-type="fig">Fig 4C</xref>, dotted lines). Here, many granule cell responses converge onto a lower dimension of signals, which decreases the fidelity. On the contrary increasing the granule cell as well as the Golgi cell population size to <italic>Nq</italic> = <italic>Nz</italic> = 10<italic>k</italic> increased the filter construction performance similar to before (results not shown).</p>
<p>Equally, further reducing the Golgi cell population to <italic>Nq</italic> = 10 for the default case (<italic>Nz</italic> = 1<italic>k</italic>, <italic>c</italic><sub><italic>u</italic></sub> = 100) enforced the bottleneck effect and strongly decreased the construction quality of slow filters (results not shown).</p>
<p>The effects of synaptic-weight variability in the two-population model differed for excitatory and inhibitory weights (<xref rid="pcbi.1004515.g006" ref-type="fig">Fig 6E</xref>). Adding a large variability to excitatory weights <italic>v</italic><sub><italic>u</italic></sub> = 4 increased the goodness-of-fit (light lines) just as seen in the model before. However, adding variability to inhibitory weights <italic>v</italic><sub><italic>w</italic></sub> = 4 decreased the quality of constructed filters (dotted lines). This can be explained by the low number of connections between Golgi and granule cells of <italic>c</italic><sub><italic>w</italic></sub> = 4. Using equal convergence of <italic>c</italic><sub><italic>w</italic></sub> = <italic>c</italic><sub><italic>u</italic></sub> = 20 gave equal effects in increased filter quality with increased variability for excitatory and inhibitory weights (results not shown).</p>
<sec id="sec012">
<title>Putative biological features increase reservoir performance</title>
<p>Finally, we investigate modifications to the network configurations that significantly influence filter construction (Figs <xref rid="pcbi.1004515.g007" ref-type="fig">7</xref> and <xref rid="pcbi.1004515.g008" ref-type="fig">8</xref>). Default values for synaptic time constants were <italic>τ</italic><sub><italic>u</italic></sub> = 1<italic>ms</italic> and <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic> and results are compared to a control network without modifications (light lines).</p>
<fig id="pcbi.1004515.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004515.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Effects of Golgi cell afferent excitation on filter construction performance.</title>
<p>As previously, target filters used are <italic>τ</italic><sub>1</sub> = 10<italic>ms</italic> (blue), <italic>τ</italic><sub>2</sub> = 100<italic>ms</italic> (green) and <italic>τ</italic><sub>3</sub> = 500<italic>ms</italic> (red). Default synaptic time constants: <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic>, <italic>τ</italic><sub><italic>u</italic></sub> = 1<italic>ms</italic>. <bold>A,B</bold>: Goodness of fit (<italic>R</italic><sup>2</sup>) (<bold>A1,B1</bold>) and Lyapunov exponents (<bold>A2,B2</bold>) for default network (light lines) and network with external excitation of Golgi cells (dark lines) with either default excitation of <italic>u</italic> = 0.1 (<bold>A</bold>) or increased excitation <italic>u</italic> = 50 (<bold>B</bold>).</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.g007" position="float" xlink:type="simple"/>
</fig>
<fig id="pcbi.1004515.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004515.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Effect of mGluR2 receptor activated GIRK channel inhibition of Golgi cells on filter construction performance.</title>
<p>For clarity only most affected target filter <italic>τ</italic><sub>3</sub> = 500<italic>ms</italic> (red) is shown. Default synaptic time constants: <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic>, <italic>τ</italic><sub><italic>u</italic></sub> = 1<italic>ms</italic>. <bold>A,B</bold>: Goodness of fit (<italic>R</italic><sup>2</sup>) (<bold>A1</bold>) and Lyapunov exponents (<bold>A2</bold>) for default network (light red lines) and network with mGluR2 receptor activated GIRK channel inhibition of Golgi cells (<italic>m</italic> = 0.003) either without (<italic>v</italic><sub><italic>m</italic></sub> = 0) (dotted red lines) or small (<italic>v</italic><sub><italic>m</italic></sub> = 0.1) (dashed red lines) weight variability. Additionally results with mGluR2 dynamics in only 50% of the Golgi cells (solid red lines) (<italic>Pr</italic>(m = 0) = 0.5, <italic>v</italic><sub><italic>m</italic></sub> = 0.1). <bold>B</bold> shows results for networks without push-pull input coding.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.g008" position="float" xlink:type="simple"/>
</fig>
<p>The first influential configuration is excitatory input to Golgi cells. While this property is often omitted for simplicity in granular-layer networks [<xref rid="pcbi.1004515.ref020" ref-type="bibr">20</xref>] it had a substantial impact on filter construction (<xref rid="pcbi.1004515.g007" ref-type="fig">Fig 7</xref>). Simply adding excitation to the Golgi cell population (<italic>g</italic> = 1, see <xref rid="sec002" ref-type="sec">Methods</xref>, equation (3) and keeping all other parameters identical prevented the system from entering into the edge-of-chaos regime (<xref rid="pcbi.1004515.g007" ref-type="fig">Fig 7A2</xref>) by inhibiting any activity due to the strong direct activation of Golgi cells. The only possible filter construction, which was however very poor, could be achieved during low inhibition with <italic>w</italic> &lt; 0.015 (<xref rid="pcbi.1004515.g007" ref-type="fig">Fig 7A1</xref>, dark lines). There are several ways to increase filter construction performance during Golgi cells afferent excitation. The most obvious case being the increase of afferent Granule cell excitation, which counteracts Golgi cell inhibition and prevents Granule cells from being silenced (not shown). Another interesting possibility however is to increase recurrent Golgi cell excitation which shifts the edge-of-chaos to lower values of <italic>w</italic>. Increasing this weight of excitation to <italic>u</italic> = 50 resulted in an effective excitatory weight from granule cell to Golgi cell that was equal to the afferent Golgi cell excitation (<inline-formula id="pcbi.1004515.e014"><alternatives><graphic id="pcbi.1004515.e014g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.e014" xlink:type="simple"/><mml:math display="inline" id="M14" overflow="scroll"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>u</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mn>1</mml:mn></mml:math></alternatives></inline-formula>, see <xref rid="sec002" ref-type="sec">Methods</xref>) and lead to an interesting effect on filter construction performance (<xref rid="pcbi.1004515.g007" ref-type="fig">Fig 7B</xref>, dark lines). While the same performance as without afferent excitation (light lines) was achieved, the decline in goodness-of-fit was postponed until larger values of <italic>w</italic>. The afferent excitation that effectively counteracted the generation of chaotic behavior kept the state of the network closer to the edge-of-chaos for a wider range of <italic>w</italic>. This can be seen in the disrupted rise in the Lyapunov exponent (<xref rid="pcbi.1004515.g007" ref-type="fig">Fig 7B2</xref>, dark orange lines).</p>
<p>A second property that also had a large influence on the filter construction was the inhibition of Golgi cells by granule cell input via mGluR2 receptor activated GIRK channels [<xref rid="pcbi.1004515.ref031" ref-type="bibr">31</xref>,<xref rid="pcbi.1004515.ref032" ref-type="bibr">32</xref>]. This property was modeled by a slow inhibitory process with <italic>τ</italic><sub><italic>m</italic></sub> = 50<italic>ms</italic> in addition to the short excitatory process (<italic>τ</italic><sub><italic>u</italic></sub> = 1<italic>ms</italic>) at the connection from granule to Golgi cell (<xref rid="pcbi.1004515.g008" ref-type="fig">Fig 8</xref>, top). For clarity only results for the most affected slow filter (<italic>τ</italic><sub>3</sub> = 500<italic>ms</italic>) will be shown. While initially this concurrent inhibition resulted in a strong reduction of filter construction performance (<xref rid="pcbi.1004515.g008" ref-type="fig">Fig 8A</xref>, dotted red lines) adding weight variability (<italic>v</italic><sub><italic>m</italic></sub> = 0.1) lead to a strong improvement of the overall goodness-of-fit (dashed red lines). Since some Golgi cells have been shown not to express mGluR2 [<xref rid="pcbi.1004515.ref031" ref-type="bibr">31</xref>,<xref rid="pcbi.1004515.ref051" ref-type="bibr">51</xref>] we further tested the effect of only 50% of the Golgi cells receiving mGluR2 inhibition (<xref rid="pcbi.1004515.g007" ref-type="fig">Fig 7A</xref>, solid red lines). While this did not massively improve filter quality compared to the baseline condition (compare to light lines) it delayed the development of chaotic behavior. The greatest beneficial effect of mGluR2 however was observed in the absence of push-pull coding (<xref rid="pcbi.1004515.g008" ref-type="fig">Fig 8B</xref>). Here, but only for the case of mGluR2 inhibition to half of the Golgi population, push-pull coding input is almost made redundant (solid red lines). However even with these improvements, as before, filter construction was strongly reduced with positive-LASSO regression (not shown). While the addition of variable mGluR2 inhibition did not change the qualitative behavior of single cell responses it increased the variability of damped oscillations for granule and Golgi cell responses (not shown).</p>
</sec>
<sec id="sec013">
<title>Effect of output feedback</title>
<p>For some reservoir computing applications, e.g. pattern generation, the learned output signal is fed back into the reservoir leading to a recurrence between the reservoir and the trained readout [<xref rid="pcbi.1004515.ref027" ref-type="bibr">27</xref>,<xref rid="pcbi.1004515.ref048" ref-type="bibr">48</xref>,<xref rid="pcbi.1004515.ref049" ref-type="bibr">49</xref>]. In the cerebellum a corresponding connection that would allow for a similar recurrence is the nucleocortical pathway that consists of inhibitory and excitatory connections from cerebellar nucleus to the granular layer [<xref rid="pcbi.1004515.ref052" ref-type="bibr">52</xref>–<xref rid="pcbi.1004515.ref054" ref-type="bibr">54</xref>]. This connection thus supports a putative recurrent loop that sends the trained signals from Purkinje cells via cerebellar nucleus neurons back to the granular layer reservoir.</p>
<p>While information on the exact distribution of source and target neuron properties for the nucleocortical pathway is sparse we tested the effect of output-feedback onto granule and Golgi cells using 50% excitatory and inhibitory connections (<xref rid="pcbi.1004515.g009" ref-type="fig">Fig 9</xref>). When using the output of the slowest filter (<italic>τ</italic> = 500<italic>ms</italic>) as feedback (<xref rid="pcbi.1004515.g009" ref-type="fig">Fig 9A</xref>, dark lines) the maximum performance increased for the slowest filter but slightly decreased for the two other filters (compared to case without feedback, light lines). This effect can be explained by the increase of delayed signals that are now being fed back through the slow filter output. Furthermore the maximum of filter construction quality is now well shifted away from the edge-of-chaos into more stable regimes. The preference for more stable networks with output-feedback becomes even more evident when push-pull input is removed (<xref rid="pcbi.1004515.g009" ref-type="fig">Fig 9B</xref>, dark lines). Here, even in the absence of any connections between Golgi and granule cells (<italic>w</italic> = 0) the slow filter (dark red line) can be well constructed due to the memory created by the recurrent loop between output and input, similar to a neural integrator [<xref rid="pcbi.1004515.ref055" ref-type="bibr">55</xref>]. The goodness of fit for the other two filters is however closer to the previous results (<xref rid="pcbi.1004515.g009" ref-type="fig">Fig 9B1</xref>, compare dark blue and green to light lines). In this regime (<italic>w</italic>&lt;0.01) the reservoir with output-feedback is very stable (<xref rid="pcbi.1004515.g009" ref-type="fig">Fig 9B2</xref>) resulting in Lyapunov exponents of negative infinity (i.e. the Euclidian distance between perturbed and unperturbed simulation decays to 0). Interestingly however the filter performance reaches goodness-of-fit values above 80% for all three filters (<xref rid="pcbi.1004515.g009" ref-type="fig">Fig 9B1</xref>, dark lines) only when the Lyapunov exponents have values closer to 0 and thus the reservoir is not completely stable (<xref rid="pcbi.1004515.g009" ref-type="fig">Fig 9B2</xref>, dark orange dots).</p>
<fig id="pcbi.1004515.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004515.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Effect of output-feedback on filter construction performance.</title>
<p>As previously, target filters used are <italic>τ</italic><sub>1</sub> = 10<italic>ms</italic> (blue), <italic>τ</italic><sub>2</sub> = 100<italic>ms</italic> (green) and <italic>τ</italic><sub>3</sub> = 500<italic>ms</italic> (red). Default synaptic time constants: <italic>τ</italic><sub><italic>w</italic></sub> = 50<italic>ms</italic>, <italic>τ</italic><sub><italic>u</italic></sub> = 1<italic>ms</italic>. <bold>A,B</bold>: Goodness of fit (<italic>R</italic><sup>2</sup>) (<bold>A1,B1</bold>) and Lyapunov exponents (<bold>A2,B2</bold>) for default network (light lines) and network having output-feedback of the slowest filter response (<italic>τ</italic><sub>3</sub> = 500<italic>ms</italic>) to granule and Golgi cells (dark lines) with either push-pull input (<bold>A</bold>) or without (<bold>B</bold>).</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004515.g009" position="float" xlink:type="simple"/>
</fig>
</sec>
</sec>
</sec>
<sec id="sec014" sec-type="conclusions">
<title>Discussion</title>
<p>Here we have investigated whether simplified models of the recurrent neural network (RNN) formed by the cerebellar granular layer are capable of generating signals that can be used to construct linear exponential filters with different time constants. We consider first the issues raised by our methods of simulation and analysis, then how the findings relate to previous theoretical and experimental studies, and finally the implications of the findings for future work.</p>
<sec id="sec015">
<title>Method of simulation and analysis</title>
<sec id="sec016">
<title>Intermediate modeling approach</title>
<p>The cerebellum has been modeled at very different levels of detail, ranging from linear systems (e.g. the adaptive-filter model [<xref rid="pcbi.1004515.ref009" ref-type="bibr">9</xref>]) to compartmental neurons (e.g. Masoli et al’s recent model of the Purkinje cell [<xref rid="pcbi.1004515.ref056" ref-type="bibr">56</xref>]). A recurring problem is that while abstract models can be shown to have particular computational competencies it is generally not clear how they could be implemented biologically, whereas detailed models are more biologically realistic but their computational properties are often obscure and in any case dependent in an unknown way on a huge number of parameters.</p>
<p>A possible way round this problem is to use intermediate level models, intended on the one hand to be simple enough for their properties to be systematically investigated, yet on the other to have properties closer to biological reality than the abstract original. The abstract models we want to improve are those that require the granular layer to recode mossy-fibre inputs (see below) in a manner that enables Purkinje cells to learn the response appropriate for a particular task (e.g. adaptive filter model). To address this issue we chose an intermediate level model using a recurrent Artificial Neural Network (RNN) representation that is accepted as a potentially useful tool for investigating signal processing not only in the granular layer [<xref rid="pcbi.1004515.ref015" ref-type="bibr">15</xref>,<xref rid="pcbi.1004515.ref017" ref-type="bibr">17</xref>,<xref rid="pcbi.1004515.ref026" ref-type="bibr">26</xref>] but also other parts of the brain like the visual cortex [<xref rid="pcbi.1004515.ref026" ref-type="bibr">26</xref>]. The argument would be that since the properties of these RNNs are at present poorly understood, it is appropriate to explore the computational properties of relatively simple networks first. The gain in understanding is more important than the lack of biological fidelity.</p>
<p>We think that by incorporating more and more realistic structural properties in future versions of this model we can highlight possible differences between random connectivity and structure, a valuable insight in itself.</p>
</sec>
<sec id="sec017">
<title>Network size</title>
<p>Although the largest population size of 10k neurons used here is probably rather smaller than the typical number of granule cells acting as a reservoir for a particular cerebellar microzone we have shown that it is nevertheless capable of implementing reservoirs from which the filters necessary to implement cerebellar functions can be constructed. This is compatible with the cerebellar ‘chip’ metaphor [<xref rid="pcbi.1004515.ref056" ref-type="bibr">56</xref>] where microzones are indicated to implement separate functions [<xref rid="pcbi.1004515.ref004" ref-type="bibr">4</xref>]. By exploring different network sizes and lower convergence ratios (Figs <xref rid="pcbi.1004515.g004" ref-type="fig">4C</xref> and <xref rid="pcbi.1004515.g006" ref-type="fig">6D</xref>) we further indicate that the described reservoir effect does not diminish but is rather improved by up-scaling. This extra capacity may give the reservoir capabilities for implementing a wider range of basis functions, such as non-linear or multimodal bases. However, one has to be cautious when comparing the number of simulated rate neurons and effective individual biological spiking neurons. While rate neurons are a simplification that offer perfect signal transmission, this is not the case with individual spiking neurons like granule cells where one rate neuron unit would have to be constituted by several biological neurons to achieve the same signal transmission fidelity [<xref rid="pcbi.1004515.ref038" ref-type="bibr">38</xref>].</p>
<p>Our 1k and 10k models do not differ much from the population size in spiking models of the cerebellum with 4k [<xref rid="pcbi.1004515.ref050" ref-type="bibr">50</xref>] and 10k [<xref rid="pcbi.1004515.ref011" ref-type="bibr">11</xref>,<xref rid="pcbi.1004515.ref013" ref-type="bibr">13</xref>,<xref rid="pcbi.1004515.ref014" ref-type="bibr">14</xref>]. Even scaling up by a factor of 100 from 10k to 1 Million cells, allowing for more realistic divergence ratios, only gave modest increase in performance for eye-blink conditioning [<xref rid="pcbi.1004515.ref057" ref-type="bibr">57</xref>], further suggesting that the basic principles of cerebellar computation can already be captured in rather small networks.</p>
</sec>
<sec id="sec018">
<title>Analysis with LASSO-regression</title>
<p>While actual synapses are constrained to be either excitatory or inhibitory, regression methods in general, and LASSO-regression in particular, use positive and negative weights to construct the desired output signal from the input signals. This assumption can however be justified if there is an appropriate inhibitory pathway between granule and Purkinje cells, now shown to be provided via molecular layer interneurons [<xref rid="pcbi.1004515.ref042" ref-type="bibr">42</xref>,<xref rid="pcbi.1004515.ref044" ref-type="bibr">44</xref>] which have been indicated to be essential for cerebellar motor learning [<xref rid="pcbi.1004515.ref058" ref-type="bibr">58</xref>]. Furthermore we showed that when using push-pull coding, filters could be constructed using LASSO-regression even with positive coefficients, i.e. excitatory synapses, only.</p>
<p>This study tries not to claim that LASSO-regression is a substitute function for learning at Purkinje cells and it doesn’t try to answer how plasticity at Purkinje cells is actually capable to construct the filters from the given reservoir. This is even more the case during the simulation with output-feedback where learning is very unstable and teacher forcing was applied. The given method is merely a powerful and descriptive way to analyze the performance of the granular layer RNN and shows whether it would be able to provide the necessary components of computation and memory.</p>
<p>In the adaptive filter the learning mechanism at Purkinje cell synapses is modeled using the covariance learning rule which is compatible with known properties of LTP and LTD at PF/PC and PF/MLI synapses. With this assumption it can be shown that the end state after learning is least squares optimal [<xref rid="pcbi.1004515.ref059" ref-type="bibr">59</xref>] and that the unavoidable presence of noise on parallel fiber inputs drives synaptic weights to the smallest values compatible with task accuracy [<xref rid="pcbi.1004515.ref060" ref-type="bibr">60</xref>]. For efficiency in dealing with large populations, and to avoid overfitting, this learning process has been modeled using LASSO regression. This is a least-squares minimization procedure with a regularization term to keep reconstruction weights small and hence has essentially the same end state as covariance learning in the presence of noise. Since regularization tends to reduce fitting accuracy we believe this is a conservative method for quantifying reservoir performance.</p>
</sec>
</sec>
<sec id="sec019">
<title>Difference between one- and two-population models</title>
<p>The one-population model demonstrated the properties of a homogeneous reservoir dominated by recurrent inhibition. However in the cerebellum recurrent inhibition is implemented as a relay via a second population of Golgi cells. To test the effect of this layered recurrence we considered a two-population model and found that reservoir behavior was generally preserved. We did observe three differences between the two types of networks: 1. A slow synaptic time constant for Golgi cell excitation decreases the quality of fast filter construction (<xref rid="pcbi.1004515.g006" ref-type="fig">Fig 6C</xref>). 2. The lower number of Golgi cells can create a bottleneck in filter fidelity when few Golgi cells sample input from a large number of granule cells (<xref rid="pcbi.1004515.g004" ref-type="fig">Fig 4C</xref>). 3. Direct afferent Golgi cell excitation can decrease chaotic behavior and is beneficial for filter construction by prolonging the edge-of-chaos regime. These issues are further discussed below.</p>
</sec>
<sec id="sec020">
<title>Theoretical findings</title>
<p>Early models of the cerebellar microcircuit focused on its ability to adaptively process static patterns. Subsequently Fujita [<xref rid="pcbi.1004515.ref003" ref-type="bibr">3</xref>] described a cerebellar model that could adaptively process time-varying analogue signals, based on the adaptive linear filter used in signal processing and control engineering [<xref rid="pcbi.1004515.ref061" ref-type="bibr">61</xref>]. In Fujita’s model the granular layer recurrent neuronal network (RNN) generated a set of parallel-fiber outputs for a given mossy-fiber input which by linear summation at the Purkinje cell allowed the microcircuit to adaptively transform time-varying inputs into the specific time-varying outputs required for any given signal-processing task.</p>
<p>Fujita’s adaptive-filter model required the granular layer to generate computationally adequate sets of parallel-fiber outputs in a biologically realistic way [<xref rid="pcbi.1004515.ref004" ref-type="bibr">4</xref>]. Subsequent extensions of his work initially focused on computational adequacy, suggesting suitable basis functions for transforming mossy-fiber inputs that included tapped delay lines, spectral timing, and sinusoids (references in [<xref rid="pcbi.1004515.ref008" ref-type="bibr">8</xref>–<xref rid="pcbi.1004515.ref010" ref-type="bibr">10</xref>]). However, it was not usually made clear how these functions could be generated by a plausible neuronal network, raising concerns that the approach was unrealistic [<xref rid="pcbi.1004515.ref011" ref-type="bibr">11</xref>] and excessively ‘top-down’ [<xref rid="pcbi.1004515.ref014" ref-type="bibr">14</xref>]. The preferred alternative was ‘bottom-up’ modeling in which temporal-processing properties emerged from biologically detailed models of the granular-layer RNN rather than being imposed by a priori theoretical considerations [<xref rid="pcbi.1004515.ref013" ref-type="bibr">13</xref>,<xref rid="pcbi.1004515.ref014" ref-type="bibr">14</xref>,<xref rid="pcbi.1004515.ref062" ref-type="bibr">62</xref>]. These models successfully learned an eyeblink-conditioning task by generating a suitably delayed output timed to coincide with the arrival of the unconditioned stimulus.</p>
<p>Yamazaki and Tanaka [<xref rid="pcbi.1004515.ref015" ref-type="bibr">15</xref>] investigated the generic time-coding properties of simplified RNNs, with (usually) 1000 rate-coding neurons receiving excitatory afferent inputs and recurrent inhibitory inputs from other neurons (cf. first model here). These RNNs could generate a sequence of activity patterns that never recurred, a sequence that could be triggered reliably by a strong transient input signal. Such networks could therefore be used to encode the passage of time for any task that required it. Related results were found for RNNs of integrate-and-fire model neurons [<xref rid="pcbi.1004515.ref016" ref-type="bibr">16</xref>], and for a more realistic two-layer RNN embedded in a spiking model of the entire cerebellar microcircuit [<xref rid="pcbi.1004515.ref063" ref-type="bibr">63</xref>].</p>
<sec id="sec021">
<title>Reservoir computing</title>
<p>Yamazaki and Tanaka [<xref rid="pcbi.1004515.ref017" ref-type="bibr">17</xref>] noted the resemblance between their approach and that of reservoir computing [<xref rid="pcbi.1004515.ref028" ref-type="bibr">28</xref>,<xref rid="pcbi.1004515.ref064" ref-type="bibr">64</xref>–<xref rid="pcbi.1004515.ref066" ref-type="bibr">66</xref>], where artificial RNNs consisting of either non-spiking nodes (echo state networks) or spiking model neurons (liquid state machines) are used to generate a rich high dimensional “reservoir” of dynamic responses to a temporally varying input. These responses are weighted and linearly summed by a plastic readout unit, and the weights adjusted so that the system’s output is as close as possible to a desired output. Suitable RNNs exhibit temporal memory, in that short-duration inputs can generate long-duration outputs, and can be used to model nonlinear functions and thus act as a non-linear adaptive filter [<xref rid="pcbi.1004515.ref025" ref-type="bibr">25</xref>,<xref rid="pcbi.1004515.ref049" ref-type="bibr">49</xref>,<xref rid="pcbi.1004515.ref066" ref-type="bibr">66</xref>,<xref rid="pcbi.1004515.ref067" ref-type="bibr">67</xref>]. These capabilities have been applied to a range of problems such as robot motor control that are thought to involve the cerebellum in their biological equivalents [<xref rid="pcbi.1004515.ref021" ref-type="bibr">21</xref>]. Yamazaki and Tanaka [<xref rid="pcbi.1004515.ref017" ref-type="bibr">17</xref>] applied the generic reservoir-computing framework specifically to the cerebellum, and showed that a cerebellar-inspired RNN was capable to learn and represent Boolean functions.</p>
<p>However, neither this study nor its predecessors addressed the generic issue of temporal processing (see <xref rid="sec001" ref-type="sec">Introduction</xref>). In the present study we therefore showed that cerebellar-inspired RNNs could in fact generate a range of temporally-varying outputs, in this case exponentials with different time constants. Exponentials are suitable basis functions for linear transformations and have been shown to be effective in a linear model of the cerebellum for adaptation of the vestibulo-ocular reflex [<xref rid="pcbi.1004515.ref009" ref-type="bibr">9</xref>]. Here we show how these ‘top-down’ functions can be generated by RNNs resembling previous ‘bottom-up’ models, thus starting to bridge the gap between the two approaches outlined above.</p>
<p>We also found that the ability to generate exponential functions depended on the mean amount of feedback in the network. Theoretical investigations of RNNs, both from within the reservoir-computing framework [<xref rid="pcbi.1004515.ref023" ref-type="bibr">23</xref>–<xref rid="pcbi.1004515.ref025" ref-type="bibr">25</xref>] and outside it [<xref rid="pcbi.1004515.ref026" ref-type="bibr">26</xref>,<xref rid="pcbi.1004515.ref029" ref-type="bibr">29</xref>,<xref rid="pcbi.1004515.ref030" ref-type="bibr">30</xref>,<xref rid="pcbi.1004515.ref068" ref-type="bibr">68</xref>,<xref rid="pcbi.1004515.ref069" ref-type="bibr">69</xref>] suggest that, in very broad terms, the outputs of networks with weak recurrent connections tend to reproduce the temporal structure of their input, whereas when the recurrent connections are strong the outputs are determined primarily by the network’s internal structure. Between these two extremes, a suitably connected RNN may be able to reproducibly deliver a rich variety of temporal responses to an input stimulus. In the present study we found that it was RNNs with small, negative values of Lyapunov exponents, representing this intermediate ‘edge-of-chaos’ region that generated long-lasting and complex responses to transient inputs. In contrast, Yamazaki and Tanaka’s ‘passage-of-time’ RNNs appear to operate where the network’s internal state dominates, conveying little information about the temporal structure of its inputs. Yamazaki and Tanaka [<xref rid="pcbi.1004515.ref015" ref-type="bibr">15</xref>] have in fact argued that this chaotic network state is the preferred network state to implement an internal clock, but our results show that it is disadvantageous when a filter applied to a continuous signal has to be implemented.</p>
<p>Previous work has already highlighted the advantages of reservoir networks for various computational tasks [<xref rid="pcbi.1004515.ref023" ref-type="bibr">23</xref>–<xref rid="pcbi.1004515.ref028" ref-type="bibr">28</xref>] and established the usefulness of different stable, critical or chaotic regimes [<xref rid="pcbi.1004515.ref022" ref-type="bibr">22</xref>,<xref rid="pcbi.1004515.ref029" ref-type="bibr">29</xref>,<xref rid="pcbi.1004515.ref030" ref-type="bibr">30</xref>] generated by changing the weights inside the reservoir. This however was almost exclusively done for generic networks where neurons are always connected by negative and positive weights [<xref rid="pcbi.1004515.ref027" ref-type="bibr">27</xref>] or include both mutual exciting and inhibiting neurons in the randomly connected reservoir networks [<xref rid="pcbi.1004515.ref028" ref-type="bibr">28</xref>]. Our work is the first to thoroughly examine the performance in network regimes while accounting for the restrictions of basic cerebellar connectivity where reservoir granule cells do only inhibit through feedback of interneurons (Golgi cells), but do not excite each other. This effectively leads to a reservoir network of inhibitory interneurons (Figs <xref rid="pcbi.1004515.g002" ref-type="fig">2</xref>, <xref rid="pcbi.1004515.g003" ref-type="fig">3</xref>, <xref rid="pcbi.1004515.g004" ref-type="fig">4</xref> and <xref rid="pcbi.1004515.g005" ref-type="fig">5</xref>). By incorporating Golgi cells in the model (Figs <xref rid="pcbi.1004515.g006" ref-type="fig">6</xref>, <xref rid="pcbi.1004515.g007" ref-type="fig">7</xref>, <xref rid="pcbi.1004515.g008" ref-type="fig">8</xref> and <xref rid="pcbi.1004515.g009" ref-type="fig">9</xref>) we further showed the influence of inhibitory neuron properties like population size, direct excitation, synaptic time constant and mGluR2 inhibition on reservoir performance and stability.</p>
</sec>
</sec>
<sec id="sec022">
<title>Experimental findings</title>
<p>The main theoretical conclusion is that with appropriate network parameters the granular-layer RNN can in principle generate the outputs needed for an adaptive filter. It also indicates what those outputs might look like. We now consider experimental evidence bearing on these two points. For convenience, evidence from detailed models of the granular-layer that are concerned primarily with its electrophysiology (as opposed to the functional models discussed above) is also included in this experimental section.</p>
<sec id="sec023">
<title>Direct evidence: Recordings from granular layer</title>
<p>In contrast to previous ‘top-down’ models where individual granule cells code specific basis functions [<xref rid="pcbi.1004515.ref008" ref-type="bibr">8</xref>], here basis functions are carried by populations of granule cells and the firing patterns of individual cells (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2B</xref>) are hard to interpret. But a prediction for experimental testing can still be made, which is that the same mossy fiber input should produce a variety of granule-cell responses, some of which outlast the input.</p>
<p>The responses to forelimb stimulation of granule cells in the C3 zone of decerebrate cats are very homogeneous, apparently reflecting only a slight transformation of their mossy-fiber inputs [<xref rid="pcbi.1004515.ref070" ref-type="bibr">70</xref>–<xref rid="pcbi.1004515.ref072" ref-type="bibr">72</xref>]. Similar high-fidelity transmission has also been observed for granule cells in crus I and IIa of anaesthetized rats that respond to perioral or vibrissal stimulation [<xref rid="pcbi.1004515.ref073" ref-type="bibr">73</xref>]. In contrast, Holtzman et al. [<xref rid="pcbi.1004515.ref032" ref-type="bibr">32</xref>] found heterogeneous responses of granule cells in crus Ic/IIa/b of anesthetized rats to brief hindlimb stimulation. In particular, they show various combinations of short-, long lasting and early-, late excitation and depression, which is very compatible with our results for simulations with feedback inhibition (<xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2B</xref>). Moreover, it appeared that long-lasting granule-cell responses were related to long-lasting depression of Golgi-cell firing, which in turn was produced by glutamate released from granule cells acting via mGluR2 receptors. Heterogeneous firing patterns have also been described for granule cells in the flocculus of awake rabbits in response to changes in head velocity [<xref rid="pcbi.1004515.ref074" ref-type="bibr">74</xref>]. However, it is not yet clear how much of this heterogeneity comes from diversity of mossy-fiber input or the action of unipolar brush cells rather than feedback from Golgi cells (further discussion below and [<xref rid="pcbi.1004515.ref038" ref-type="bibr">38</xref>]).</p>
</sec>
<sec id="sec024">
<title>Indirect evidence: General connectivity</title>
<p>In contrast to common reservoir-computing networks, in the cerebellar granular layer only recurrent inhibition onto granule cells is available, posing an additional constraint for successful filter synthesis. One way of compensating for the lack of mutual excitation is employing “push-pull” input coding, in which half of the cells receive signals in phase with the input, and the other half signals that are out of phase, i.e. multiplied by –1. Direct evidence that push-pull coding is available at least in the vestibular system comes from recordings where approximately half of the mossy fibers increase firing when the head is moved ipsilateral to the recording site (type 1) and half for contralateral movement (type 2). This has been shown in recordings from the cells of origin of floccular mossy fibers in awake primate [<xref rid="pcbi.1004515.ref075" ref-type="bibr">75</xref>] and cat [<xref rid="pcbi.1004515.ref076" ref-type="bibr">76</xref>]. Furthermore also most granule cells can be separated into type 1 and type 2 activity as shown by extracellular [<xref rid="pcbi.1004515.ref077" ref-type="bibr">77</xref>] and internal EPSP recordings in anesthetized mice [<xref rid="pcbi.1004515.ref078" ref-type="bibr">78</xref>].</p>
<p>A recent experiment showed that rerouting of climbing fibers can switch the simple spike activity of Purkinje cells from ipsi- to contralateral [<xref rid="pcbi.1004515.ref079" ref-type="bibr">79</xref>] while maintaining reciprocal complex spike activity [<xref rid="pcbi.1004515.ref080" ref-type="bibr">80</xref>]. This change occurs without any modification of mossy fiber input, further supporting the idea that the granular layer exhibits a diverse signal reservoir that in addition can be actively shaped with plasticity controlled by climbing fiber activity.</p>
<p>Two other of our results on optimal Golgi cell excitation are directly supported by recent findings. First of all, optimal filter construction requires sparse connectivity arguing for local connectivity, i.e. small world connectivity and against a congregation of global activity. In support of this is the finding that Golgi cells do not only receive distal excitatory inputs from other modules via the parallel fiber pathway but more than half of its excitatory inputs are local inputs from neurons within the module via ascending axons with a connection probability of 10% [<xref rid="pcbi.1004515.ref081" ref-type="bibr">81</xref>].</p>
<p>Finally, the filters in our study can be constructed only using a fraction of the provided granule cell signals which is compatible with the high proportion of silent synapses found between parallel fibers and Purkinje cells [<xref rid="pcbi.1004515.ref042" ref-type="bibr">42</xref>–<xref rid="pcbi.1004515.ref045" ref-type="bibr">45</xref>].</p>
</sec>
<sec id="sec025">
<title>Indirect evidence: Synaptic properties</title>
<p>A necessity for our proposed model is the presence of a strong excitatory—inhibitory loop between granule and Golgi cells. Direct evidence for this comes from recent experiments [<xref rid="pcbi.1004515.ref081" ref-type="bibr">81</xref>] showing that during sustained mossy fiber activity half of the excitatory charge input to Golgi cells comes from granule cell synapses. Furthermore, more than half of the these local connections are from local ascending axon connections on basolateral Golgi cells dendrites with decay time constants faster than 1.2 ms supporting our assumption of fast excitation.</p>
<p>One property that naturally increases the range of expansion recoding i.e. the ability to construct long filters is to increase the time constant of the synaptic inhibition. GABAergic inhibition of granule cells is usually reported to be strong enough to dynamically regulate output of granule cells [<xref rid="pcbi.1004515.ref082" ref-type="bibr">82</xref>] and to have a large slow component that is manly governed by the spillover activation of <italic>α</italic><sub>6</sub>GABA<sub><italic>A</italic></sub> receptors [<xref rid="pcbi.1004515.ref083" ref-type="bibr">83</xref>].</p>
<p>We show that compensation for the lack of mutual excitation can also be achieved by paradoxical inhibition of Golgi cells due to mGluR2 receptor activated GIRK channels [<xref rid="pcbi.1004515.ref031" ref-type="bibr">31</xref>,<xref rid="pcbi.1004515.ref032" ref-type="bibr">32</xref>]. In the presence of push-pull input mGluR2 activation can improve filter construction, but only when the density of mGluR2 and/or GIRK channels is variable across Golgi cells. Further increasing the variability of mGluR2 to the point where only 50% of Golgi cells receive inhibitory input can even compensate for the absence of push-pull coding by bringing the connectivity closer to that of traditional reservoir models where connections are either excitatory or inhibitory. This strong variability across cells can be justified by the finding that not all Golgi cells express mGluR2 [<xref rid="pcbi.1004515.ref031" ref-type="bibr">31</xref>,<xref rid="pcbi.1004515.ref051" ref-type="bibr">51</xref>].</p>
<p>Very compatible with our results are the findings of long-lasting alternating excitation and inhibition to brief sensory stimulation due to mutual inhibition of Golgi cells by mGluR2 and granule cells by GABA [<xref rid="pcbi.1004515.ref032" ref-type="bibr">32</xref>]. However since the latter study based their identification of Golgi cells on the occurrence of long lasting depression due to putative mGluR2 inhibition, recordings of Golgi cells without mGluR2 expression, which we find to be very important for filter construction, are not available.</p>
</sec>
<sec id="sec026">
<title>Indirect evidence: Output feedback</title>
<p>A further property that can greatly improve filter construction is output-feedback via the nucleocortical pathway sending trained signals from Purkinje cells via cerebellar nucleus neurons back to the granular layer reservoir [<xref rid="pcbi.1004515.ref052" ref-type="bibr">52</xref>–<xref rid="pcbi.1004515.ref054" ref-type="bibr">54</xref>]. We report that this recurrent loop could increase reservoir memory especially in the absence of push-pull input where it does require a more stable network with lower inhibitory gain. However, learning under this condition is difficult. While teacher forcing, a strategy used in reservoir computing is able to tackle unstable learning tasks [<xref rid="pcbi.1004515.ref027" ref-type="bibr">27</xref>] by providing the target output signals before the weights are even learned, it remains to be shown if learning at Purkinje synapses itself can be stable during output feedback.</p>
</sec>
</sec>
<sec id="sec027">
<title>Implications of findings</title>
<p>In all networks and configurations considered the single cell activity of granule and Golgi cells at the edge-of-chaos showed complex but stable, long lasting damped oscillations that were the effect of inhibition and dis-inhibition (only shown for the one-population model, <xref rid="pcbi.1004515.g002" ref-type="fig">Fig 2B</xref>). The similarity between Golgi and granule cell responses is easily graspable when one considers that for the default two-population network Golgi cells merely relay signals from granule cells und thus have to show similar activity. On the other hand for Golgi cells with added mGluR2 dynamics they themselves become prone to inhibition and dis-inhibition. This study thus suggests that one indicator for the presence of reservoir computation in a certain area of the cerebellum would be the similarity in heterogeneity and timing of the responses for granule and Golgi cells.</p>
<p>This comparison however must not be made based on the spike activity but on the modulated signals. One explanation for the often-reported bursting responses in granule cells compared to Golgi cells could be the lower baseline/background activity of the former cells [<xref rid="pcbi.1004515.ref077" ref-type="bibr">77</xref>]. While the signal is carried and hidden by the higher spike rate in Golgi cells, granule cells would ultimately only spike during phases of strong dis-inhibition, which would effectively resemble bursting behavior. This would be even further increased if the operation point of the network is not close to the edge-of-chaos but in the chaotic regime. A further evaluation of these properties will however require the inclusion of spiking neurons in future studies.</p>
<p>While the present study only focuses on the interaction between granule and Golgi cells the inclusion of other identified neurons might improve filter construction properties. Glycinergic Lugaro cells which have been found to increase the long-lasting depression of Golgi cells [<xref rid="pcbi.1004515.ref032" ref-type="bibr">32</xref>] and various other non-traditional interneurons like globular [<xref rid="pcbi.1004515.ref084" ref-type="bibr">84</xref>] or perivascular neurons [<xref rid="pcbi.1004515.ref085" ref-type="bibr">85</xref>] might further improve the reservoir performance by contributing to the inhibitory circuit. Furthermore, in some areas of cerebellar cortex, particularly in the vestibulo-cerebellum (e.g. [<xref rid="pcbi.1004515.ref086" ref-type="bibr">86</xref>]), a substantial proportion of mossy-fiber input is processed and relayed by unipolar brush cells (UBC) which are thought to prolong and diversify the input signals [<xref rid="pcbi.1004515.ref087" ref-type="bibr">87</xref>]. In addition a recently discovered timing mechanism intrinsic to Purkinje cells [<xref rid="pcbi.1004515.ref088" ref-type="bibr">88</xref>] would potentially further increase the heterogeneity of the granular layer reservoir signals.</p>
<p>Although the edge-of-chaos criterion is not a universal predictor of maximal computational performance [<xref rid="pcbi.1004515.ref022" ref-type="bibr">22</xref>] we find that it applies for most of the configurations considered here. With this requirement however the question arises how the granular layer network can be adjusted to operate in this computationally powerful regime. While the easiest way to achieve this is to change properties inside the loop like weights at Golgi cell—granule cell synapses or the convergence ratio of Golgi cell excitation we show that also external mechanisms like noise, input variability and especially mossy fiber—Golgi cell exaction can shift the network state. The question however remains how and if the cerebellar granule layer network can be automatically tuned to operate close to the edge-of-chaos. Possible mechanism that could help achieve this are synaptic long or short-term plasticity.</p>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1004515.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marr</surname> <given-names>D</given-names></name>. <article-title>A theory of cerebellar cortex</article-title>. <source>J Physiol</source>. <year>1969</year>;<volume>202</volume>: <fpage>437</fpage>–<lpage>470</lpage>. <object-id pub-id-type="pmid">5784296</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Albus</surname> <given-names>JS</given-names></name>. <article-title>A theory of cerebellar function</article-title>. <source>Math Biosci</source>. <year>1971</year>;<volume>10</volume>: <fpage>25</fpage>–<lpage>61</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fujita</surname> <given-names>M</given-names></name>. <article-title>Adaptive filter model of the cerebellum</article-title>. <source>Biol Cybern</source>. <year>1982</year>;<volume>45</volume>: <fpage>195</fpage>–<lpage>206</lpage>. <object-id pub-id-type="pmid">7171642</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dean</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Porrill</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ekerot</surname> <given-names>C-F</given-names></name>, <name name-style="western"><surname>Jörntell</surname> <given-names>H</given-names></name>. <article-title>The cerebellar microcircuit as an adaptive filter: experimental and computational evidence</article-title>. <source>Nat Rev Neurosci</source>. <year>2010</year>;<volume>11</volume>: <fpage>30</fpage>–<lpage>43</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2756" xlink:type="simple">10.1038/nrn2756</ext-link></comment> <object-id pub-id-type="pmid">19997115</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref005"><label>5</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Dean</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Jörntell</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Porrill</surname> <given-names>DJ</given-names></name>. <chapter-title>Adaptive Filter Models</chapter-title>. In: <name name-style="western"><surname>Manto</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schmahmann</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Rossi</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Gruol</surname> <given-names>DL</given-names></name>, <name name-style="western"><surname>Koibuchi</surname> <given-names>N</given-names></name>, editors. <source>Handbook of the Cerebellum and Cerebellar Disorders</source>. <publisher-name>Springer</publisher-name> <publisher-loc>Netherlands</publisher-loc>; <year>2013</year>. pp. <fpage>1315</fpage>–<lpage>1335</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://link.springer.com/referenceworkentry/10.1007/978-94-007-1333-8_58" xlink:type="simple">http://link.springer.com/referenceworkentry/10.1007/978-94-007-1333-8_58</ext-link></mixed-citation></ref>
<ref id="pcbi.1004515.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gao</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Beugen van</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Zeeuw</surname> <given-names>CID</given-names></name>. <article-title>Distributed synergistic plasticity and cerebellar learning</article-title>. <source>Nat Rev Neurosci</source>. <year>2012</year>;<volume>13</volume>: <fpage>619</fpage>–<lpage>635</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn3312" xlink:type="simple">10.1038/nrn3312</ext-link></comment> <object-id pub-id-type="pmid">22895474</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref007"><label>7</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Ito</surname> <given-names>M</given-names></name>. <source>Cerebellum: The Brain for an Implicit Self</source>. <publisher-name>FT press</publisher-name>; <year>2012</year>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yamazaki</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>S</given-names></name>. <article-title>Computational Models of Timing Mechanisms in the Cerebellar Granular Layer</article-title>. <source>The Cerebellum</source>. <year>2009</year>;<volume>8</volume>: <fpage>423</fpage>–<lpage>432</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s12311-009-0115-7" xlink:type="simple">10.1007/s12311-009-0115-7</ext-link></comment> <object-id pub-id-type="pmid">19495900</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dean</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Porrill</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Stone</surname> <given-names>JV</given-names></name>. <article-title>Decorrelation control by the cerebellum achieves oculomotor plant compensation in simulated vestibulo-ocular reflex</article-title>. <source>Proc R Soc B Biol Sci</source>. <year>2002</year>;<volume>269</volume>: <fpage>1895</fpage>–<lpage>1904</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lepora</surname> <given-names>NF</given-names></name>, <name name-style="western"><surname>Porrill</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Yeo</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Dean</surname> <given-names>P</given-names></name>. <article-title>Sensory prediction or motor control? Application of Marr–Albus type models of cerebellar function to classical conditioning</article-title>. <source>Front Comput Neurosci</source>. <year>2010</year>;<volume>4</volume>: <fpage>140</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2010.00140" xlink:type="simple">10.3389/fncom.2010.00140</ext-link></comment> <object-id pub-id-type="pmid">21031161</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buonomano</surname> <given-names>DV</given-names></name>, <name name-style="western"><surname>Mauk</surname> <given-names>MD</given-names></name>. <article-title>Neural Network Model of the Cerebellum: Temporal Discrimination and the Timing of Motor Responses</article-title>. <source>Neural Comput</source>. <year>1994</year>;<volume>6</volume>: <fpage>38</fpage>–<lpage>55</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mauk</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Donegan</surname> <given-names>NH</given-names></name>. <article-title>A model of Pavlovian eyelid conditioning based on the synaptic organization of the cerebellum</article-title>. <source>Learn Mem</source>. <year>1997</year>;<volume>4</volume>: <fpage>130</fpage>–<lpage>158</lpage>. <object-id pub-id-type="pmid">10456059</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Medina</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Garcia</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Nores</surname> <given-names>WL</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>NM</given-names></name>, <name name-style="western"><surname>Mauk</surname> <given-names>MD</given-names></name>. <article-title>Timing Mechanisms in the Cerebellum: Testing Predictions of a Large-Scale Computer Simulation</article-title>. <source>J Neurosci</source>. <year>2000</year>;<volume>20</volume>: <fpage>5516</fpage>–<lpage>5525</lpage>. <object-id pub-id-type="pmid">10884335</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Medina</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Mauk</surname> <given-names>MD</given-names></name>. <article-title>Computer simulation of cerebellar information processing</article-title>. <source>Nat Neurosci</source>. <year>2000</year>;<volume>3</volume>: <fpage>1205</fpage>–<lpage>1211</lpage>. <object-id pub-id-type="pmid">11127839</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yamazaki</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>S</given-names></name>. <article-title>Neural Modeling of an Internal Clock</article-title>. <source>Neural Comput</source>. <year>2005</year>;<volume>17</volume>: <fpage>1032</fpage>–<lpage>1058</lpage>. <object-id pub-id-type="pmid">15829099</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref016"><label>16</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Yamazaki</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>S</given-names></name>. <chapter-title>Building the Cerebellum in a Computer</chapter-title>. In: <name name-style="western"><surname>Duch</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Kacprzyk</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Oja</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Zadrożny</surname> <given-names>S</given-names></name>, editors. <source>Artificial Neural Networks: Biological Inspirations–ICANN</source> <year>2005</year>. <publisher-name>Springer</publisher-name> <publisher-loc>Berlin Heidelberg</publisher-loc>; 2005. pp. <fpage>71</fpage>–<lpage>77</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://link.springer.com/chapter/10.1007/11550822_12" xlink:type="simple">http://link.springer.com/chapter/10.1007/11550822_12</ext-link></mixed-citation></ref>
<ref id="pcbi.1004515.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yamazaki</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>S</given-names></name>. <article-title>The cerebellum as a liquid state machine</article-title>. <source>Neural Netw</source>. <year>2007</year>;<volume>20</volume>: <fpage>290</fpage>–<lpage>297</lpage>. <object-id pub-id-type="pmid">17517494</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref018"><label>18</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Honda</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Yamazaki</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Nishino</surname> <given-names>T</given-names></name>. <chapter-title>A Possible Mechanism for Controlling Timing Representation in the Cerebellar Cortex</chapter-title>. In: <name name-style="western"><surname>Zhang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Lu</surname> <given-names>B-L</given-names></name>, <name name-style="western"><surname>Kwok</surname> <given-names>J</given-names></name>, editors. <source>Advances in Neural Networks—ISNN 2010</source>. <publisher-name>Springer</publisher-name> <publisher-loc>Berlin Heidelberg</publisher-loc>; <year>2010</year>. pp. <fpage>67</fpage>–<lpage>76</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://link.springer.com/chapter/10.1007/978-3-642-13278-0_10" xlink:type="simple">http://link.springer.com/chapter/10.1007/978-3-642-13278-0_10</ext-link></mixed-citation></ref>
<ref id="pcbi.1004515.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Honda</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Yamazaki</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Nagao</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Nishino</surname> <given-names>T</given-names></name>. <article-title>Stimulus-Dependent State Transition between Synchronized Oscillation and Randomly Repetitive Burst in a Model Cerebellar Granular Layer</article-title>. <source>PLoS Comput Biol</source>. <year>2011</year>;<volume>7</volume>: <fpage>e1002087</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002087" xlink:type="simple">10.1371/journal.pcbi.1002087</ext-link></comment> <object-id pub-id-type="pmid">21779155</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yamazaki</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Nagao</surname> <given-names>S</given-names></name>. <article-title>A Computational Mechanism for Unified Gain and Timing Control in the Cerebellum</article-title>. <source>PLoS ONE</source>. <year>2012</year>;<volume>7</volume>: <fpage>e33319</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0033319" xlink:type="simple">10.1371/journal.pone.0033319</ext-link></comment> <object-id pub-id-type="pmid">22438912</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lukoševičius</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Jaeger</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Schrauwen</surname> <given-names>B</given-names></name>. <article-title>Reservoir Computing Trends</article-title>. <source>KI—Künstl Intell</source>. <year>2012</year>;<volume>26</volume>: <fpage>365</fpage>–<lpage>371</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Legenstein</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>. <article-title>Edge of chaos and prediction of computational performance for neural circuit models</article-title>. <source>Neural Netw</source>. <year>2007</year>;<volume>20</volume>: <fpage>323</fpage>–<lpage>334</lpage>. <object-id pub-id-type="pmid">17517489</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Büsing</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Schrauwen</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Legenstein</surname> <given-names>R</given-names></name>. <article-title>Connectivity, Dynamics, and Memory in Reservoir Computing with Binary and Analog Neurons</article-title>. <source>Neural Comput</source>. <year>2009</year>;<volume>22</volume>: <fpage>1272</fpage>–<lpage>1311</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Legenstein</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>. <article-title>What makes a dynamical system computationally powerful</article-title>. <source>New Dir Stat Signal Process Syst Brain</source>. <year>2007</year>; <fpage>127</fpage>–<lpage>154</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Verstraeten</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Schrauwen</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>D’Haene</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Stroobandt</surname> <given-names>D</given-names></name>. <article-title>An experimental unification of reservoir computing methods</article-title>. <source>Neural Netw</source>. <year>2007</year>;<volume>20</volume>: <fpage>391</fpage>–<lpage>403</lpage>. <object-id pub-id-type="pmid">17517492</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buonomano</surname> <given-names>DV</given-names></name>, <name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>. <article-title>State-dependent computations: spatiotemporal processing in cortical networks</article-title>. <source>Nat Rev Neurosci</source>. <year>2009</year>;<volume>10</volume>: <fpage>113</fpage>–<lpage>125</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2558" xlink:type="simple">10.1038/nrn2558</ext-link></comment> <object-id pub-id-type="pmid">19145235</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref027"><label>27</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Lukoševičius</surname> <given-names>M</given-names></name>. <chapter-title>A Practical Guide to Applying Echo State Networks</chapter-title>. In: <name name-style="western"><surname>Montavon</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Orr</surname> <given-names>GB</given-names></name>, <name name-style="western"><surname>Müller</surname> <given-names>K-R</given-names></name>, editors. <source>Neural Networks: Tricks of the Trade</source>. <publisher-name>Springer</publisher-name> <publisher-loc>Berlin Heidelberg</publisher-loc>; <year>2012</year>. pp. <fpage>659</fpage>–<lpage>686</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://link.springer.com/chapter/10.1007/978-3-642-35289-8_36" xlink:type="simple">http://link.springer.com/chapter/10.1007/978-3-642-35289-8_36</ext-link></mixed-citation></ref>
<ref id="pcbi.1004515.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Natschläger</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Markram</surname> <given-names>H</given-names></name>. <article-title>Real-Time Computing Without Stable States: A New Framework for Neural Computation Based on Perturbations</article-title>. <source>Neural Comput</source>. <year>2002</year>;<volume>14</volume>: <fpage>2531</fpage>–<lpage>2560</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976602760407955" xlink:type="simple">10.1162/089976602760407955</ext-link></comment> <object-id pub-id-type="pmid">12433288</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ostojic</surname> <given-names>S</given-names></name>. <article-title>Two types of asynchronous activity in networks of excitatory and inhibitory spiking neurons</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>: <fpage>594</fpage>–<lpage>600</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3658" xlink:type="simple">10.1038/nn.3658</ext-link></comment> <object-id pub-id-type="pmid">24561997</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laje</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Buonomano</surname> <given-names>DV</given-names></name>. <article-title>Robust timing and motor patterns by taming chaos in recurrent neural networks</article-title>. <source>Nat Neurosci</source>. <year>2013</year>;<volume>16</volume>: <fpage>925</fpage>–<lpage>933</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3405" xlink:type="simple">10.1038/nn.3405</ext-link></comment> <object-id pub-id-type="pmid">23708144</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Watanabe</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Nakanishi</surname> <given-names>S</given-names></name>. <article-title>mGluR2 Postsynaptically Senses Granule Cell Inputs at Golgi Cell Synapses</article-title>. <source>Neuron</source>. <year>2003</year>;<volume>39</volume>: <fpage>821</fpage>–<lpage>829</lpage>. <object-id pub-id-type="pmid">12948448</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holtzman</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sivam</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Zhao</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Frey</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Wal van der</surname> <given-names>PD</given-names></name>, <name name-style="western"><surname>Rooij de</surname> <given-names>NF</given-names></name>, <etal>et al</etal>. <article-title>Multiple extra-synaptic spillover mechanisms regulate prolonged activity in cerebellar Golgi cell–granule cell loops</article-title>. <source>J Physiol</source>. <year>2011</year>;<volume>589</volume>: <fpage>3837</fpage>–<lpage>3854</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.2011.207167" xlink:type="simple">10.1113/jphysiol.2011.207167</ext-link></comment> <object-id pub-id-type="pmid">21669981</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref033"><label>33</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>. <source>Biophysics of computation: information processing in single neurons</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>; <year>1999</year>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Rapp</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Segev</surname> <given-names>I</given-names></name>. <article-title>A brief history of time (constants)</article-title>. <source>Cereb Cortex N Y N 1991</source>. <year>1996</year>;<volume>6</volume>: <fpage>93</fpage>–<lpage>101</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Suarez</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Douglas</surname> <given-names>R</given-names></name>. <article-title>Modeling direction selectivity of simple cells in striate visual cortex within the framework of the canonical microcircuit</article-title>. <source>J Neurosci</source>. <year>1995</year>;<volume>15</volume>: <fpage>6700</fpage>–<lpage>6719</lpage>. <object-id pub-id-type="pmid">7472430</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref036"><label>36</label><mixed-citation publication-type="other" xlink:type="simple">Holt GR. A critical reexamination of some assumptions and implications of cable theory in neurobiology [Internet]. phd, California Institute of Technology. 1998. Available: <ext-link ext-link-type="uri" xlink:href="http://resolver.caltech.edu/CaltechETD:etd-09122006-135415" xlink:type="simple">http://resolver.caltech.edu/CaltechETD:etd-09122006-135415</ext-link></mixed-citation></ref>
<ref id="pcbi.1004515.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lisberger</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Fuchs</surname> <given-names>AF</given-names></name>. <article-title>Role of primate flocculus during rapid behavioral modification of vestibuloocular reflex. II. Mossy fiber firing patterns during horizontal head rotation and eye movement</article-title>. <source>J Neurophysiol</source>. <year>1978</year>;<volume>41</volume>: <fpage>764</fpage>–<lpage>777</lpage>. <object-id pub-id-type="pmid">96226</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rössert</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Solinas</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>D’Angelo</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Dean</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Porrill</surname> <given-names>J</given-names></name>. <article-title>Model cerebellar granule cells can faithfully transmit modulated firing rate signals</article-title>. <source>Front Cell Neurosci</source>. <year>2014</year>;<volume>8</volume>: <fpage>304</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncel.2014.00304" xlink:type="simple">10.3389/fncel.2014.00304</ext-link></comment> <object-id pub-id-type="pmid">25352777</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sadeghi</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Chacron</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>Cullen</surname> <given-names>KE</given-names></name>. <article-title>Neural Variability, Detection Thresholds, and Information Transmission in the Vestibular System</article-title>. <source>J Neurosci</source>. <year>2007</year>;<volume>27</volume>: <fpage>771</fpage>–<lpage>781</lpage>. <object-id pub-id-type="pmid">17251416</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>. <article-title>Regression Shrinkage and Selection via the Lasso</article-title>. <source>J R Stat Soc Ser B Methodol</source>. <year>1996</year>;<volume>58</volume>: <fpage>267</fpage>–<lpage>288</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>. <article-title>Regression shrinkage and selection via the lasso: a retrospective</article-title>. <source>J R Stat Soc Ser B Stat Methodol</source>. <year>2011</year>;<volume>73</volume>: <fpage>273</fpage>–<lpage>282</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ekerot</surname> <given-names>C-F</given-names></name>, <name name-style="western"><surname>Jömtell</surname> <given-names>H</given-names></name>. <article-title>Parallel fiber receptive fields: a key to understanding cerebellar operation and learning</article-title>. <source>The Cerebellum</source>. <year>2003</year>;<volume>2</volume>: <fpage>101</fpage>–<lpage>109</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/14734220309411" xlink:type="simple">10.1080/14734220309411</ext-link></comment> <object-id pub-id-type="pmid">12880177</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Isope</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Barbour</surname> <given-names>B</given-names></name>. <article-title>Properties of Unitary Granule Cell→Purkinje Cell Synapses in Adult Rat Cerebellar Slices</article-title>. <source>J Neurosci</source>. <year>2002</year>;<volume>22</volume>: <fpage>9668</fpage>–<lpage>9678</lpage>. <object-id pub-id-type="pmid">12427822</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jörntell</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Ekerot</surname> <given-names>C-F</given-names></name>. <article-title>Reciprocal Bidirectional Plasticity of Parallel Fiber Receptive Fields in Cerebellar Purkinje Cells and Their Afferent Interneurons</article-title>. <source>Neuron</source>. <year>2002</year>;<volume>34</volume>: <fpage>797</fpage>–<lpage>806</lpage>. <object-id pub-id-type="pmid">12062025</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Porrill</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dean</surname> <given-names>P</given-names></name>. <article-title>Silent Synapses, LTP, and the Indirect Parallel-Fibre Pathway: Computational Consequences of Optimal Cerebellar Noise-Processing</article-title>. <source>PLoS Comput Biol</source>. <year>2008</year>;<volume>4</volume>: <fpage>e1000085</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000085" xlink:type="simple">10.1371/journal.pcbi.1000085</ext-link></comment> <object-id pub-id-type="pmid">18497864</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pedregosa</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Varoquaux</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Gramfort</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Michel</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Thirion</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Grisel</surname> <given-names>O</given-names></name>, <etal>et al</etal>. <article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>J Mach Learn Res</source>. <year>2011</year>;<volume>12</volume>: <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref047"><label>47</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Hill</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Lewicki</surname> <given-names>P</given-names></name>. <source>Statistics: Methods and Applications</source>. <edition>1 edition</edition>. <publisher-loc>Tulsa, OK</publisher-loc>: <publisher-name>StatSoft, Inc</publisher-name>.; <year>2005</year>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reinhart</surname> <given-names>RF</given-names></name>, <name name-style="western"><surname>Jakob Steil</surname> <given-names>J</given-names></name>. <article-title>Regularization and stability in reservoir networks with output feedback</article-title>. <source>Neurocomputing</source>. <year>2012</year>;<volume>90</volume>: <fpage>96</fpage>–<lpage>105</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref049"><label>49</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Wyffels</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Schrauwen</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Stroobandt</surname> <given-names>D</given-names></name>. <chapter-title>Stable Output Feedback in Reservoir Computing Using Ridge Regression</chapter-title>. In: <name name-style="western"><surname>Kůrková</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Neruda</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Koutník</surname> <given-names>J</given-names></name>, editors. <source>Artificial Neural Networks—ICANN 2008</source>. <publisher-name>Springer</publisher-name> <publisher-loc>Berlin Heidelberg</publisher-loc>; <year>2008</year>. pp. <fpage>808</fpage>–<lpage>817</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://link.springer.com/chapter/10.1007/978-3-540-87536-9_83" xlink:type="simple">http://link.springer.com/chapter/10.1007/978-3-540-87536-9_83</ext-link></mixed-citation></ref>
<ref id="pcbi.1004515.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Solinas</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Nieus</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>DëAngelo</surname> <given-names>E</given-names></name>. <article-title>A realistic large-scale model of the cerebellum granular layer predicts circuit spatio-temporal filtering properties</article-title>. <source>Front Cell Neurosci</source>. <year>2010</year>;<volume>4</volume>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Neki</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ohishi</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Kaneko</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Shigemoto</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Nakanishi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Mizuno</surname> <given-names>N</given-names></name>. <article-title>Metabotropic glutamate receptors mGluR2 and mGluR5 are expressed in two non-overlapping populations of Golgi cells in the rat cerebellum</article-title>. <source>Neuroscience</source>. <year>1996</year>;<volume>75</volume>: <fpage>815</fpage>–<lpage>826</lpage>. <object-id pub-id-type="pmid">8951875</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Houck</surname> <given-names>BD</given-names></name>, <name name-style="western"><surname>Person</surname> <given-names>AL</given-names></name>. <article-title>Cerebellar loops: a review of the nucleocortical pathway</article-title>. <source>Cerebellum Lond Engl</source>. <year>2014</year>;<volume>13</volume>: <fpage>378</fpage>–<lpage>385</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McCrea</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Bishop</surname> <given-names>GA</given-names></name>, <name name-style="western"><surname>Kitai</surname> <given-names>ST</given-names></name>. <article-title>Morphological and electrophysiological characteristics of projection neurons in the nucleus interpositus of the cat cerebellum</article-title>. <source>J Comp Neurol</source>. <year>1978</year>;<volume>181</volume>: <fpage>397</fpage>–<lpage>419</lpage>. <object-id pub-id-type="pmid">690271</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tolbert</surname> <given-names>DL</given-names></name>, <name name-style="western"><surname>Bantli</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Bloedel</surname> <given-names>JR</given-names></name>. <article-title>Organizational features of the cat and monkey cerebellar nucleocortical projection</article-title>. <source>J Comp Neurol</source>. <year>1978</year>;<volume>182</volume>: <fpage>39</fpage>–<lpage>56</lpage>. <object-id pub-id-type="pmid">100532</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Robinson</surname> <given-names>DA</given-names></name>. <article-title>Integrating with Neurons</article-title>. <source>Annu Rev Neurosci</source>. <year>1989</year>;<volume>12</volume>: <fpage>33</fpage>–<lpage>45</lpage>. <object-id pub-id-type="pmid">2648952</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Masoli</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Solinas</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>D’Angelo</surname> <given-names>E</given-names></name>. <article-title>Action potential processing in a detailed Purkinje cell model reveals a critical role for axonal compartmentalization</article-title>. <source>Front Cell Neurosci</source>. <year>2015</year>;<volume>9</volume>: <fpage>47</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncel.2015.00047" xlink:type="simple">10.3389/fncel.2015.00047</ext-link></comment> <object-id pub-id-type="pmid">25759640</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>W-K</given-names></name>, <name name-style="western"><surname>Hausknecht</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Stone</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Mauk</surname> <given-names>MD</given-names></name>. <article-title>Using a million cell simulation of the cerebellum: Network scaling and task generality</article-title>. <source>Neural Netw</source>. <year>2013</year>;<volume>47</volume>: <fpage>95</fpage>–<lpage>102</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neunet.2012.11.005" xlink:type="simple">10.1016/j.neunet.2012.11.005</ext-link></comment> <object-id pub-id-type="pmid">23200194</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wulff</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Schonewille</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Renzi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Viltono</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sassoè-Pognetto</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Badura</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Synaptic inhibition of Purkinje cells mediates consolidation of vestibulo-cerebellar motor learning</article-title>. <source>Nat Neurosci</source>. <year>2009</year>;<volume>12</volume>: <fpage>1042</fpage>–<lpage>1049</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2348" xlink:type="simple">10.1038/nn.2348</ext-link></comment> <object-id pub-id-type="pmid">19578381</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dean</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Porrill</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Jörntell</surname> <given-names>H</given-names></name>. <article-title>An adaptive filter model of cerebellar zone C3 as a basis for safe limb control?</article-title> <source>J Physiol</source>. <year>2013</year>;<volume>591</volume>: <fpage>5459</fpage>–<lpage>5474</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.2013.261545" xlink:type="simple">10.1113/jphysiol.2013.261545</ext-link></comment> <object-id pub-id-type="pmid">23836690</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nakano</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Otsuka</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Yoshimoto</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Doya</surname> <given-names>K</given-names></name>. <article-title>A Spiking Neural Network Model of Model-Free Reinforcement Learning with High-Dimensional Sensory Input and Perceptual Ambiguity</article-title>. <source>PLoS ONE</source>. <year>2015</year>;<volume>10</volume>: <fpage>e0115620</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0115620" xlink:type="simple">10.1371/journal.pone.0115620</ext-link></comment> <object-id pub-id-type="pmid">25734662</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Widrow</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Glover</surname> <given-names>J</given-names> <suffix>J.R.</suffix></name>, <name name-style="western"><surname>McCool</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Kaunitz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Williams</surname> <given-names>CS</given-names></name>, <name name-style="western"><surname>Hearn</surname> <given-names>RH</given-names></name>, <etal>et al</etal>. <article-title>Adaptive noise cancelling: Principles and applications</article-title>. <source>Proc IEEE</source>. <year>1975</year>;<volume>63</volume>: <fpage>1692</fpage>–<lpage>1716</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Medina</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Mauk</surname> <given-names>MD</given-names></name>. <article-title>Simulations of Cerebellar Motor Learning: Computational Analysis of Plasticity at the Mossy Fiber to Deep Nucleus Synapse</article-title>. <source>J Neurosci</source>. <year>1999</year>;<volume>19</volume>: <fpage>7140</fpage>–<lpage>7151</lpage>. <object-id pub-id-type="pmid">10436067</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yamazaki</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>S</given-names></name>. <article-title>A spiking network model for passage-of-time representation in the cerebellum</article-title>. <source>Eur J Neurosci</source>. <year>2007</year>;<volume>26</volume>: <fpage>2279</fpage>–<lpage>2292</lpage>. <object-id pub-id-type="pmid">17953620</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dominey</surname> <given-names>PF</given-names></name>. <article-title>Complex sensory-motor sequence learning based on recurrent state representation and reinforcement learning</article-title>. <source>Biol Cybern</source>. <year>1995</year>;<volume>73</volume>: <fpage>265</fpage>–<lpage>274</lpage>. <object-id pub-id-type="pmid">7548314</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref065"><label>65</label><mixed-citation publication-type="other" xlink:type="simple">Steil JJ. Backpropagation-decorrelation: online recurrent learning with O(N) complexity. 2004 IEEE International Joint Conference on Neural Networks, 2004 Proceedings. 2004. pp. 843–848 vol.2.</mixed-citation></ref>
<ref id="pcbi.1004515.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jaeger</surname> <given-names>H</given-names></name>. <article-title>The “echo state” approach to analysing and training recurrent neural networks-with an erratum note</article-title>. <source>Bonn Ger Ger Natl Res Cent Inf Technol GMD Tech Rep</source>. <year>2001</year>;<volume>148</volume>: <fpage>34</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jaeger</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Haas</surname> <given-names>H</given-names></name>. <article-title>Harnessing nonlinearity: predicting chaotic systems and saving energy in wireless communication</article-title>. <source>Science</source>. <year>2004</year>;<volume>304</volume>: <fpage>78</fpage>–<lpage>80</lpage>. <object-id pub-id-type="pmid">15064413</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sussillo</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>. <article-title>Generating Coherent Patterns of Activity from Chaotic Neural Networks</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>63</volume>: <fpage>544</fpage>–<lpage>557</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2009.07.018" xlink:type="simple">10.1016/j.neuron.2009.07.018</ext-link></comment> <object-id pub-id-type="pmid">19709635</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wallace</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Maei</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>. <article-title>Randomly Connected Networks Have Short Temporal Memory</article-title>. <source>Neural Comput</source>. <year>2013</year>;<volume>25</volume>: <fpage>1408</fpage>–<lpage>1439</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/NECO_a_00449" xlink:type="simple">10.1162/NECO_a_00449</ext-link></comment> <object-id pub-id-type="pmid">23517097</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bengtsson</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Jörntell</surname> <given-names>H</given-names></name>. <article-title>Sensory transmission in cerebellar granule cells relies on similarly coded mossy fiber inputs</article-title>. <source>Proc Natl Acad Sci</source>. <year>2009</year>;<volume>106</volume>: <fpage>2389</fpage>–<lpage>2394</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0808428106" xlink:type="simple">10.1073/pnas.0808428106</ext-link></comment> <object-id pub-id-type="pmid">19164536</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ekerot</surname> <given-names>C-F</given-names></name>, <name name-style="western"><surname>Jörntell</surname> <given-names>H</given-names></name>. <article-title>Synaptic Integration in Cerebellar Granule Cells</article-title>. <source>The Cerebellum</source>. <year>2008</year>;<volume>7</volume>: <fpage>539</fpage>–<lpage>541</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s12311-008-0064-6" xlink:type="simple">10.1007/s12311-008-0064-6</ext-link></comment> <object-id pub-id-type="pmid">19009328</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jörntell</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Ekerot</surname> <given-names>C-F</given-names></name>. <article-title>Properties of Somatosensory Synaptic Integration in Cerebellar Granule Cells In Vivo</article-title>. <source>J Neurosci</source>. <year>2006</year>;<volume>26</volume>: <fpage>11786</fpage>–<lpage>11797</lpage>. <object-id pub-id-type="pmid">17093099</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rancz</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Ishikawa</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Duguid</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Chadderton</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Mahon</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Hausser</surname> <given-names>M</given-names></name>. <article-title>High-fidelity transmission of sensory information by single cerebellar mossy fibre boutons</article-title>. <source>Nature</source>. <year>2007</year>;<volume>450</volume>: <fpage>1245</fpage>–<lpage>1248</lpage>. <object-id pub-id-type="pmid">18097412</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref074"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hensbroek</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Van Beugen</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Ruigrok</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Simpson</surname> <given-names>JI</given-names></name>. <article-title>Spike modulation of unipolar brush cells and granule cells in the cerebellum of the awake rabbit</article-title>. <source>Soc Neurosci Abstr</source>. <year>2006</year>;<volume>32</volume>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref075"><label>75</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Partsalis</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Highstein</surname> <given-names>SM</given-names></name>. <article-title>Properties of superior vestibular nucleus neurons projecting to the cerebellar flocculus in the squirrel monkey</article-title>. <source>J Neurophysiol</source>. <year>1993</year>;<volume>69</volume>: <fpage>642</fpage>–<lpage>645</lpage>. <object-id pub-id-type="pmid">8459292</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref076"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cheron</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Escudero</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Godaux</surname> <given-names>E</given-names></name>. <article-title>Discharge properties of brain stem neurons projecting to the flocculus in the alert cat. I. Medical vestibular nucleus</article-title>. <source>J Neurophysiol</source>. <year>1996</year>;<volume>76</volume>: <fpage>1759</fpage>–<lpage>1774</lpage>. <object-id pub-id-type="pmid">8890290</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref077"><label>77</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barmack</surname> <given-names>NH</given-names></name>, <name name-style="western"><surname>Yakhnitsa</surname> <given-names>V</given-names></name>. <article-title>Functions of Interneurons in Mouse Cerebellum</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>: <fpage>1140</fpage>–<lpage>1152</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3942-07.2008" xlink:type="simple">10.1523/JNEUROSCI.3942-07.2008</ext-link></comment> <object-id pub-id-type="pmid">18234892</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref078"><label>78</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Arenz</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Silver</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Schaefer</surname> <given-names>AT</given-names></name>, <name name-style="western"><surname>Margrie</surname> <given-names>TW</given-names></name>. <article-title>The Contribution of Single Synapses to Sensory Representation in Vivo</article-title>. <source>Science</source>. <year>2008</year>;<volume>321</volume>: <fpage>977</fpage>–<lpage>980</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1158391" xlink:type="simple">10.1126/science.1158391</ext-link></comment> <object-id pub-id-type="pmid">18703744</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref079"><label>79</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Badura</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schonewille</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Voges</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Galliano</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Renier</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Gao</surname> <given-names>Z</given-names></name>, <etal>et al</etal>. <article-title>Climbing Fiber Input Shapes Reciprocity of Purkinje Cell Firing</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>78</volume>: <fpage>700</fpage>–<lpage>713</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2013.03.018" xlink:type="simple">10.1016/j.neuron.2013.03.018</ext-link></comment> <object-id pub-id-type="pmid">23643935</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref080"><label>80</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zeeuw</surname> <given-names>CID</given-names></name>, <name name-style="western"><surname>Wylie</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Stahl</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Simpson</surname> <given-names>JI</given-names></name>. <article-title>Phase relations of Purkinje cells in the rabbit flocculus during compensatory eye movements</article-title>. <source>J Neurophysiol</source>. <year>1995</year>;<volume>74</volume>: <fpage>2051</fpage>–<lpage>2064</lpage>. <object-id pub-id-type="pmid">8592196</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref081"><label>81</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cesana</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Pietrajtis</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Bidoret</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Isope</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>D’Angelo</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Dieudonné</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Granule Cell Ascending Axon Excitatory Synapses onto Golgi Cells Implement a Potent Feedback Circuit in the Cerebellar Granular Layer</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>: <fpage>12430</fpage>–<lpage>12446</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4897-11.2013" xlink:type="simple">10.1523/JNEUROSCI.4897-11.2013</ext-link></comment> <object-id pub-id-type="pmid">23884948</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref082"><label>82</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nieus</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Mapelli</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>D’Angelo</surname> <given-names>E</given-names></name>. <article-title>Regulation of output spike patterns by phasic inhibition in cerebellar granule cells</article-title>. <source>Front Cell Neurosci</source>. <year>2014</year>;<volume>8</volume>: <fpage>246</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncel.2014.00246" xlink:type="simple">10.3389/fncel.2014.00246</ext-link></comment> <object-id pub-id-type="pmid">25202237</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref083"><label>83</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mapelli</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Rossi</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Nieus</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>D’Angelo</surname> <given-names>E</given-names></name>. <article-title>Tonic Activation of GABAB Receptors Reduces Release Probability at Inhibitory Connections in the Cerebellar Glomerulus</article-title>. <source>J Neurophysiol</source>. <year>2009</year>;<volume>101</volume>: <fpage>3089</fpage>–<lpage>3099</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.91190.2008" xlink:type="simple">10.1152/jn.91190.2008</ext-link></comment> <object-id pub-id-type="pmid">19339456</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref084"><label>84</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lainé</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Axelrad</surname> <given-names>H</given-names></name>. <article-title>Extending the cerebellar Lugaro cell class</article-title>. <source>Neuroscience</source>. <year>2002</year>;<volume>115</volume>: <fpage>363</fpage>–<lpage>374</lpage>. <object-id pub-id-type="pmid">12421603</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref085"><label>85</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Flace</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Benagiano</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Lorusso</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Girolamo</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Rizzi</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Virgintino</surname> <given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Glutamic acid decarboxylase immunoreactive large neuron types in the granular layer of the human cerebellar cortex</article-title>. <source>Anat Embryol (Berl)</source>. <year>2004</year>;<volume>208</volume>: <fpage>55</fpage>–<lpage>64</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004515.ref086"><label>86</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mugnaini</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Sekerková</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Martina</surname> <given-names>M</given-names></name>. <article-title>The unipolar brush cell: A remarkable neuron finally receiving deserved attention</article-title>. <source>Brain Res Rev</source>. <year>2011</year>;<volume>66</volume>: <fpage>220</fpage>–<lpage>245</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.brainresrev.2010.10.001" xlink:type="simple">10.1016/j.brainresrev.2010.10.001</ext-link></comment> <object-id pub-id-type="pmid">20937306</object-id></mixed-citation></ref>
<ref id="pcbi.1004515.ref087"><label>87</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dorp van</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Zeeuw</surname> <given-names>CID</given-names></name>. <article-title>Variable timing of synaptic transmission in cerebellar unipolar brush cells</article-title>. <source>Proc Natl Acad Sci</source>. <year>2014</year>; 201314219.</mixed-citation></ref>
<ref id="pcbi.1004515.ref088"><label>88</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johansson</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Jirenhed</surname> <given-names>D-A</given-names></name>, <name name-style="western"><surname>Rasmussen</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zucca</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Hesslow</surname> <given-names>G</given-names></name>. <article-title>Memory trace and timing mechanism localized to cerebellar Purkinje cells</article-title>. <source>Proc Natl Acad Sci</source>. <year>2014</year>;<volume>111</volume>: <fpage>14930</fpage>–<lpage>14934</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1415371111" xlink:type="simple">10.1073/pnas.1415371111</ext-link></comment> <object-id pub-id-type="pmid">25267641</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
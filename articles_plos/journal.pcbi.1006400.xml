<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006400</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-00583</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject><subj-group><subject>Recurrent neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject><subj-group><subject>Recurrent neural networks</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular structures and organelles</subject><subj-group><subject>Cell signaling structures</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Ecology</subject><subj-group><subject>Community ecology</subject><subj-group><subject>Community structure</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Ecology and environmental sciences</subject><subj-group><subject>Ecology</subject><subj-group><subject>Community ecology</subject><subj-group><subject>Community structure</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Network analysis</subject><subj-group><subject>Signaling networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>People and places</subject><subj-group><subject>Population groupings</subject><subj-group><subject>Professions</subject><subj-group><subject>Teachers</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Interactive reservoir computing for chunking information streams</article-title>
<alt-title alt-title-type="running-head">Reservoir computing for chunking</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Asabuki</surname>
<given-names>Toshitake</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Hiratani</surname>
<given-names>Naoki</given-names>
</name>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6977-5638</contrib-id>
<name name-style="western">
<surname>Fukai</surname>
<given-names>Tomoki</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Department of Complexity Science and Engineering, Univ. of Tokyo, Kashiwa, Chiba, Japan</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Gatsby Computational Neuroscience Unit, Univ. College London, London, United Kingdom</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>RIKEN Center for Brain Science, Wako, Saitama, Japan</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Graham</surname>
<given-names>Lyle J.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Université Paris Descartes, Centre National de la Recherche Scientifique, FRANCE</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">tfukai@riken.jp</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>8</day>
<month>10</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="collection">
<month>10</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>10</issue>
<elocation-id>e1006400</elocation-id>
<history>
<date date-type="received">
<day>16</day>
<month>4</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>25</day>
<month>7</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Asabuki et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006400"/>
<abstract>
<p>Chunking is the process by which frequently repeated segments of temporal inputs are concatenated into single units that are easy to process. Such a process is fundamental to time-series analysis in biological and artificial information processing systems. The brain efficiently acquires chunks from various information streams in an unsupervised manner; however, the underlying mechanisms of this process remain elusive. A widely-adopted statistical method for chunking consists of predicting frequently repeated contiguous elements in an input sequence based on unequal transition probabilities over sequence elements. However, recent experimental findings suggest that the brain is unlikely to adopt this method, as human subjects can chunk sequences with uniform transition probabilities. In this study, we propose a novel conceptual framework to overcome this limitation. In this process, neural networks learn to predict dynamical response patterns to sequence input rather than to directly learn transition patterns. Using a mutually supervising pair of reservoir computing modules, we demonstrate how this mechanism works in chunking sequences of letters or visual images with variable regularity and complexity. In addition, we demonstrate that background noise plays a crucial role in correctly learning chunks in this model. In particular, the model can successfully chunk sequences that conventional statistical approaches fail to chunk due to uniform transition probabilities. In addition, the neural responses of the model exhibit an interesting similarity to those of the basal ganglia observed after motor habit formation.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Varieties of information processing require chunking, but chunking arbitrary complex sequences as flexibly as the brain does remains a challenge. In this study, we solved this important but difficult problem of chunking by "reservoir computing" inferred from brain computation. In the method, chunking occurs automatically when a pair of such modules supervising one another agree on the recurring response patterns to remember. Our model revealed a unique dynamical mechanism for embedding the temporal community structure of inputs into low-dimensional neural trajectories. From a biological viewpoint, our model based on pairwise computing suggests the computational implications of brain's bi-hemispheric information streams. Owing to recent technological advances, the implementation of this model by electronic devices should be straightforward.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001700</institution-id>
<institution>Ministry of Education, Culture, Sports, Science and Technology</institution>
</institution-wrap>
</funding-source>
<award-id>16H01289</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6977-5638</contrib-id>
<name name-style="western">
<surname>Fukai</surname>
<given-names>Tomoki</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001700</institution-id>
<institution>Ministry of Education, Culture, Sports, Science and Technology</institution>
</institution-wrap>
</funding-source>
<award-id>17H06036</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6977-5638</contrib-id>
<name name-style="western">
<surname>Fukai</surname>
<given-names>Tomoki</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was partly supported by KAKENHI (nos. 16H01289 and 17H06036: <ext-link ext-link-type="uri" xlink:href="https://www.jsps.go.jp/english/index.html" xlink:type="simple">https://www.jsps.go.jp/english/index.html</ext-link>) to TF, and TA was supported by Junior Research Associate program of RIKEN. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="0"/>
<page-count count="21"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-10-18</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All codes for computer simulations were written in Python 3 and are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/ToshitakeAsabuki/dualRC_codes" xlink:type="simple">https://github.com/ToshitakeAsabuki/dualRC_codes</ext-link>. All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>When a sequence of stimuli is repeated, they may be segmented into “chunks,” which are then processed and stored as discrete units. This process, called “chunking” or "bracketing" [<xref ref-type="bibr" rid="pcbi.1006400.ref001">1</xref>], takes place during various cognitive behaviors that require hierarchical sequence processing [<xref ref-type="bibr" rid="pcbi.1006400.ref002">2</xref>–<xref ref-type="bibr" rid="pcbi.1006400.ref005">5</xref>]. For instance, in motor learning, a sequence of smaller movements may be executed as one compound movement after repetitive practice [<xref ref-type="bibr" rid="pcbi.1006400.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006400.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1006400.ref009">9</xref>]. During language acquisition, continuous vocal sounds are segmented into familiar groups of contiguous sounds that are processed as words [<xref ref-type="bibr" rid="pcbi.1006400.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref011">11</xref>]. Chunking is believed to reduce the complexity of sequence processing and hence the associated computational cost [<xref ref-type="bibr" rid="pcbi.1006400.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref012">12</xref>–<xref ref-type="bibr" rid="pcbi.1006400.ref013">13</xref>]. In this regard, chunking constitutes a crucial step in representing the hierarchical structure of sequential knowledge in neural circuits [<xref ref-type="bibr" rid="pcbi.1006400.ref014">14</xref>].</p>
<p>Chunking is believed to occur through two consecutive processes. Long and complex sequences are first segmented into shorter and simple sequences, while frequently repeated segments are concatenated into a single unit [<xref ref-type="bibr" rid="pcbi.1006400.ref015">15</xref>]. Various mechanisms of chunking have been proposed based on Bayesian computation [<xref ref-type="bibr" rid="pcbi.1006400.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref016">16</xref>], statistical learning guided by prediction errors [<xref ref-type="bibr" rid="pcbi.1006400.ref017">17</xref>], and a bifurcation structure (stable heteroclinic orbits) in nonlinear dynamical systems [<xref ref-type="bibr" rid="pcbi.1006400.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref019">19</xref>]. In addition, a neuromorphic hardware has been proposed [<xref ref-type="bibr" rid="pcbi.1006400.ref020">20</xref>]. However, none of these mechanisms have been shown to chunk with the level of flexibility that the brain offers. It also remains unclear whether a bifurcation theoretic mechanism exists that enables the chunking of arbitrary complex sequences. Many studies evaluating event segmentation in biological and artificial systems have focused on mechanisms to detect boundaries between events by transient increases in surprise signals, which are thought to form based on unequal transition probabilities among sequence elements [<xref ref-type="bibr" rid="pcbi.1006400.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref021">21</xref>–<xref ref-type="bibr" rid="pcbi.1006400.ref022">22</xref>]. However, human subjects can segment sequences of visual stimuli that have uniform transition probabilities and hence cannot be chunked by any variation of such mechanisms [<xref ref-type="bibr" rid="pcbi.1006400.ref023">23</xref>]. These findings suggest that biological neural networks favor a mechanism of chunking that is based on temporal community detection, in which stimuli that frequently go together are grouped into a chunk. A similar mechanism may also account for the brain’s ability to detect repetitions of patterned stimuli in random sequences [<xref ref-type="bibr" rid="pcbi.1006400.ref024">24</xref>–<xref ref-type="bibr" rid="pcbi.1006400.ref026">26</xref>].</p>
<p>However, the logic and neural mechanism of flexible and automatic chunking by the brain remain unknown. In this study, we propose a novel mechanism of unsupervised chunk learning based on a unique computational framework that differs from any of the previous proposals. In this mechanism, neural networks learn the low-dimensional dynamical trajectories embedding stereotyped responses to recurring segments (chunks) of a temporal input. We achieve this mechanism in a framework of cortical computation [<xref ref-type="bibr" rid="pcbi.1006400.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref028">28</xref>] by extending reservoir computing (RC) to unsupervised learning. RC is a high-dimensional dynamical system consisting of a recurrent neural network, readout units, with feedforward and feedback projections between them, and supervised learning in its original form [<xref ref-type="bibr" rid="pcbi.1006400.ref029">29</xref>]. We were able to attain unsupervised learning in a pair of independent RC modules supervising each other without any external instructive signal. As a consequence, they learned to mimic, or predict, the preferential responses of partner modules to chunks in a given temporal input.</p>
<p>The primary interest of this study was determining the novel computational mechanism to segment information streams. However, an unexpected finding included a surprising similarity between the temporal response patterns of readout units in our model and a functional subtype of basal ganglia neurons, called stop cells, which are observed after habituation [<xref ref-type="bibr" rid="pcbi.1006400.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1006400.ref009">9</xref>]. This finding suggests that the proposed paradigm of sequence processing has a biological relevance.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Reservoir computing modules with mutual supervision</title>
<p>To demonstrate the basic framework of our model, we first consider the case where the input sequence alternates a single chunk (i.e., a-b-c-d) and random sequences of discrete items, which are chosen from the remaining 22 letters of the English alphabet (e to z) (<xref ref-type="fig" rid="pcbi.1006400.g001">Fig 1A</xref>). In reality, each letter may correspond to a brief stimulus in any sensory modality, such as a brief tone signal, and is given to the model through phasic activation of a specific input neuron (<italic>I</italic><sub><italic>μ</italic></sub>(<italic>t</italic>) in <xref ref-type="disp-formula" rid="pcbi.1006400.e005">Eq 4</xref> in the Methods) with slow rise and decay constants (<xref ref-type="fig" rid="pcbi.1006400.g001">Fig 1B</xref>). Thus, the number of input neurons coincides with that of letters. The random sequence components are introduced to unambiguously define the initial and end points of a chunk, and their lengths vary with every repetition cycle within the length range of 5 to 8.</p>
<fig id="pcbi.1006400.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006400.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Learning of a single chunk repeated in random sequence.</title>
<p><bold>(a)</bold> Input sequence repeating a single chunk. In this example, the chunk is composed of four alphabets (a, b, c, d). The components and lengths of random sequences varied during the repetition of chunks. <bold>(b)</bold> Example responses are shown for input neurons. <bold>(c)</bold> In the dual RC model, two non-identical reservoirs are activated by the same set of input neurons. Readout weights of each RC system undergo supervised learning with a teaching signal given by the output of the partner network. <bold>(d)</bold> and <bold>(e)</bold> Pre- and post-learning trial averaged activities of a readout unit are shown, respectively. Shaded intervals designate the presentation periods of the chunk. The other readout unit exhibited a similar activity pattern. (<bold>f</bold>) Readout activity was trained with many-to-one input projections. The fraction of input neurons projecting to a reservoir neuron was 10% (red), 40% (green) and 70% (black).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006400.g001" xlink:type="simple"/>
</fig>
<p>Our network model comprises two mutually non-interacting RC modules, each of which consists of a recurrent network (reservoir) of rate-based neurons and a readout unit. Each RC module receives an identical input sequence (<xref ref-type="fig" rid="pcbi.1006400.g001">Fig 1C</xref>). Each reservoir neuron receives a selective input from one of the input neurons and hence has a preferred stimulus. As shown later, however, this constraint is not essential for chunking and can be relaxed. Within each reservoir, all neurons are mutually connected and project to a readout unit, which projects back to all neurons belonging to the same reservoir. Note that the two reservoirs have different recurrent wiring patterns and hence are not identical. The activity of each readout unit <italic>z</italic>(<italic>t</italic>) is given as a weighted sum of the activities <bold><italic>r</italic></bold>(<italic>t</italic>) of the reservoir neurons projecting to the readout: <italic>z</italic>(<italic>t</italic>) = <bold><italic>w</italic></bold><sup>T</sup><bold><italic>r</italic></bold>(<italic>t</italic>). Note that one readout unit per reservoir is sufficient for learning a single chunk. We will consider more complex cases later. The weight vector <bold><italic>w</italic></bold> is modifiable through the FORCE learning algorithm [<xref ref-type="bibr" rid="pcbi.1006400.ref029">29</xref>], whereas the recurrent and feedback connections are non-plastic because the model can solve the present task without modifying these connections. The initial states of the reservoirs are weakly chaotic as in the previous model [<xref ref-type="bibr" rid="pcbi.1006400.ref029">29</xref>]. See the <xref ref-type="sec" rid="sec012">Methods</xref> for details of the model and values of the relevant parameters.</p>
<p>A unique feature of the present model is that the output of each readout unit is used as a teacher signal to train the readout weights of the other reservoir module, implying that the two RC modules supervise each other. As a consequence, although the FORCE learning per se is a supervised learning rule, the entire network, which we call the "dual RC system," is subject to unsupervised leaning because teaching signals originate from the system itself. The details of the teaching signals will be shown later.</p>
</sec>
<sec id="sec004">
<title>Chunk learning from a random sequence</title>
<p>The design of the teaching signals is the key for successful chunk learning in the present model. The teaching signals should be symmetric with respect to the interchange of the two readout units, and should be determined such that the two systems stop learning when the two readout units output similar response patterns. In other words, the teaching signals eventually become identical between the two RC modules during learning. The following teaching signals <italic>f</italic><sub><italic>i</italic></sub> enable chunk learning in the proposed dual RC system:
<disp-formula id="pcbi.1006400.e001">
<alternatives>
<graphic id="pcbi.1006400.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mi mathvariant="normal">β</mml:mi><mml:mo>)</mml:mo><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where <inline-formula id="pcbi.1006400.e002"><alternatives><graphic id="pcbi.1006400.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is the normalized output of the <italic>i</italic>-th readout unit (Methods), the threshold linear function [<italic>x</italic>]<sub>+</sub> returns 0 if <italic>x</italic>≦0, and [<italic>x</italic>]<sub>+</sub> = <italic>x</italic> if <italic>x</italic>&gt;0, and the constant was set as <italic>β</italic> = 3. Defining error signals as <italic>e</italic><sub><italic>i</italic></sub>(<italic>t</italic>) = <italic>z</italic><sub><italic>i</italic></sub>(<italic>t</italic>) – <italic>f</italic><sub><italic>i</italic></sub>(<italic>t</italic>), we trained the pair of RC modules through the FORCE learning algorithm until the error signals become sufficiently small (typically, about 0.01) and the readout weights converge to equilibrium values (within small fluctuations). The sigmoidal function allows the system to learn nontrivial solutions <italic>z</italic><sub><italic>j</italic></sub>(<italic>t</italic>) ≠ 0, while maintaining the outputs (and hence the teaching signals) to be finite during learning. Furthermore, the saturation part of sigmoidal function prevents the model from responding too strongly to a specific chunk and makes it easier to detect all the chunks embedded in the input sequence. This activity regulation is particularly important in the learning of multiple chunks studied later. The threshold linear function makes the outputs positive; these nonlinear transformations greatly improved the performance of learning. Importantly, the teaching signals do not explicitly contain information about the structure and timing of chunks in the input sequence. This dual RC system converged to a state of stable operations when the two RC systems produced similar teaching signals (hence similar outputs) that were consistent with the temporal structure of the input sequence (<xref ref-type="supplementary-material" rid="pcbi.1006400.s001">S1 Fig</xref>). The readout units did not respond to the chunk before learning (<xref ref-type="fig" rid="pcbi.1006400.g001">Fig 1D</xref>). After learning, the responses of the readout units were tested for the input sequences that had not been used for the training. The test sequences contained the same chunk “a-b-c-d,” but the random sequence part was different. Given these inputs, the readout units exhibited steady phasic responses time-locked to the chunk (<xref ref-type="fig" rid="pcbi.1006400.g001">Fig 1E</xref>). The readout activity piled up gradually in the beginning of the chunk, rapidly increased at its end, and then returned to a baseline level. The selective responses to the chunk were also successfully learned when each reservoir neuron was innervated by multiple input neurons. As shown in <xref ref-type="fig" rid="pcbi.1006400.g001">Fig 1F</xref>, the system succeeded in learning when randomly-chosen 10% or 40% of input neurons projected to each reservoir neuron, but failed when the fraction was 70%. Thus, responses of the individual reservoir neurons should be sufficiently independent of each other to robustly capture the recurrence of chunks.</p>
</sec>
<sec id="sec005">
<title>Learning of multiple chunks</title>
<p>We can extend the previous learning rule for learning multiple chunks without difficulty. To show this, we embedded three chunks into a random input sequence (<xref ref-type="fig" rid="pcbi.1006400.g002">Fig 2A</xref>, top). The three chunks had the same occurrence probability of 1/3. To process this complex input sequence, we made two modifications to the previous model. First, each reservoir was connected to three readout units (<italic>z</italic><sub>1</sub>, <italic>z</italic><sub>2</sub>, <italic>z</italic><sub>3</sub> for the 1st reservoir and <italic>z</italic><sub>4</sub>, <italic>z</italic><sub>5</sub>, <italic>z</italic><sub>6</sub> for the 2nd reservoir), each responsible for the learning of one of the three chunks (<xref ref-type="fig" rid="pcbi.1006400.g002">Fig 2B</xref>). Second, we modified the teaching signals as follows:
<disp-formula id="pcbi.1006400.e003">
<alternatives>
<graphic id="pcbi.1006400.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi mathvariant="normal">tanh</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mstyle displaystyle="false"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi mathvariant="normal">β</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mspace width="0.50em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
<disp-formula id="pcbi.1006400.e004">
<alternatives>
<graphic id="pcbi.1006400.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1,2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mi mathvariant="normal">β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mspace width="0.50em"/><mml:mo>(</mml:mo><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>4,5</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula>
where <italic>a</italic>’ and <italic>b</italic>’ refer to the corresponding readout units of the partner RC modules (i.e., <italic>a</italic>’ = <italic>a</italic>+3 and <italic>b</italic>’ = <italic>b</italic>-3), and dashes in the second term indicate that the corresponding readout unit should be excluded from the summation. The constant <italic>γ</italic> was set as 0.5. Thus, teaching signals were exchanged between the RC modules as in the previous case. Each readout unit receives a triplet of teaching signals from the partner network, in which one is cooperative and the other two are competitive (<xref ref-type="supplementary-material" rid="pcbi.1006400.s002">S2A Fig</xref>). These signals allow each readout unit to adopt to a specific chunk, but the chunk to be learned by a readout unit is not a priori specified because the teaching signals are symmetric with respect to the permutation of indices per reservoir. A further extension of the learning rule to an arbitrary number of chunks is straightforward.</p>
<fig id="pcbi.1006400.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006400.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Readout activity after learning detects multiple chunks.</title>
<p><bold>(a)</bold> Top, Three chunks a-b-c-d (red), e-f-g-h (green), and i-j-k-l (blue) separated by random sequences are recurred at equal frequencies in input. Bottom, The three chunks are repeated without the intervals of random sequences. <bold>(b)</bold> Each reservoir was connected to three readout units. <bold>(c)</bold> Selective readout responses to the individual chunks (colored intervals) were self-organized. Input contained random sequences. The responses are colored according to their selectivity to the chunks. <bold>(d)</bold> The same chunks were repeated without breaks by random sequences. Previous models of chunking typically processed such input sequences. <bold>(e)</bold> Readout activities formed with (left) and without (right) random sequence intervals were averaged over the recurrence of chunk “a-b-c-d”. <bold>(f)</bold> Time evolution of average readout weights is shown at every step of learning with (gray) and without (black) random sequence intervals.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006400.g002" xlink:type="simple"/>
</fig>
<p>As in the case with a single chunk, each readout unit displayed a ramping activity selective to a specific chunk, signaling successful chunk learning (<xref ref-type="fig" rid="pcbi.1006400.g002">Fig 2C</xref>). During this learning, teaching signals also self-organized such that each pair of the readout units eventually exhibited a selective response to a specific chunk, indicating that the teaching signals work adequately (<xref ref-type="supplementary-material" rid="pcbi.1006400.s002">S2B Fig</xref>). The complex form of teacher signals looks somewhat biologically unrealistic, but they can easily be implemented by inhibitory neurons (<xref ref-type="supplementary-material" rid="pcbi.1006400.s002">S2C Fig</xref>: see <xref ref-type="sec" rid="sec012">Methods</xref>) to generate chunk-selective phasic readout responses (<xref ref-type="supplementary-material" rid="pcbi.1006400.s002">S2D Fig</xref>). Below, inhibitory neurons are not explicitly modeled.</p>
<p>The question then arises whether the RC system could also learn multiple chunks when they occur continuously without temporal separations by random sequences. To study this, we trained the model by using input sequences in which three chunks appear randomly and consecutively with equal probabilities, without any interval of random sequences (<xref ref-type="fig" rid="pcbi.1006400.g002">Fig 2A</xref>, bottom). Thus, the same RC system as before could easily learn multiple chunks (<xref ref-type="fig" rid="pcbi.1006400.g002">Fig 2D</xref>). A notable difference was that, outside of the chunks, the readout activity decayed faster for undisturbed sequences than for temporally separated ones (<xref ref-type="fig" rid="pcbi.1006400.g002">Fig 2E</xref>). In fact, learning proceeded faster for the former sequences (<xref ref-type="fig" rid="pcbi.1006400.g002">Fig 2F</xref>), suggesting that learning is more effective when chunks are not disrupted by random sequences. Throughout this study, one learning step corresponds to 15 sec.</p>
</sec>
<sec id="sec006">
<title>Selective recruitment of reservoir neurons for chunk learning</title>
<p>Next, we investigated how the activities of reservoir neurons encode chunks. Here, the network was trained on sequences containing three chunks and random sequences. In each reservoir, a subset of neurons selectively responded to each chunk after learning (<xref ref-type="supplementary-material" rid="pcbi.1006400.s003">S3A Fig</xref>). Therefore, we classified reservoir neurons into three ensembles according to the selectivity of their responses to each chunk (Methods). Some reservoir neurons responded to more than one chunk, but they were excluded from the following analysis for the sake of simplicity. Each neural ensemble received slightly stronger inputs from the specific chunk it encoded, which then determines the selectivity of the encoding ensemble (<xref ref-type="supplementary-material" rid="pcbi.1006400.s003">S3B Fig</xref>). Through learning, the neural ensemble encoding a particular chunk developed stronger projections to the corresponding readout unit compared with other neural ensembles (<xref ref-type="supplementary-material" rid="pcbi.1006400.s003">S3C Fig</xref>). Consistent with this, the distribution of readout weights was more positively skewed in encoding ensembles than in non-encoding ensembles (<xref ref-type="supplementary-material" rid="pcbi.1006400.s003">S3D Fig</xref>). Moreover, the readout unit projected back to the corresponding encoding neuron ensemble more strongly than to the other ensembles (<xref ref-type="supplementary-material" rid="pcbi.1006400.s003">S3E Fig</xref>). Because feedback connections were not modifiable, these results imply that readout connections were strengthened between readout units and reservoir neurons that happened to receive relatively strong feedback from the readout unit.</p>
</sec>
<sec id="sec007">
<title>The role of low-dimensional network dynamics in chunk learning</title>
<p>To gain further insight into the mechanism of chunking, we explored the low-dimensional characteristics of the dynamics of reservoir networks. In our model, the two RC modules, termed R1 and R2, are thought to mimic others. This would be possible when the two recurrent networks receiving the same input sequence predict the responses of other modules well. To see how this prediction is formed, we calculated the principal components (PCs) of the post-learning activity of trained recurrent networks in the example shown in <xref ref-type="fig" rid="pcbi.1006400.g001">Fig 1</xref>. After learning, the lowest principal component (PC1) but not the other PCs, of each reservoir resembled the phasic response of the corresponding readout unit during the presentation of chunks (<xref ref-type="fig" rid="pcbi.1006400.g003">Fig 3A</xref>, left). The learned trajectories wandered in the low-dimensional PC space outside the chunks where teacher signals vanished, while, inside the chunks, non-vanishing teacher signals rapidly constrained both trajectories in narrower regions showing similar PC1 values (<xref ref-type="fig" rid="pcbi.1006400.g003">Fig 3A</xref>, right). This behavior is understandable because the eigenvalues of PCs decay rapidly (<xref ref-type="fig" rid="pcbi.1006400.g003">Fig 3B</xref>). Interestingly, the correlation coefficient between each PC and the readout activity decayed more dramatically (<xref ref-type="fig" rid="pcbi.1006400.g003">Fig 3C</xref>). Accordingly, the direction of readout weight vector was more strongly correlated with that of PC1 compared to other PCs (<xref ref-type="fig" rid="pcbi.1006400.g003">Fig 3D</xref>). These results suggest that the low-dimensional characteristics of neural dynamics play a pivotal role in encoding the chunks.</p>
<fig id="pcbi.1006400.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006400.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Principal component analysis of recurrent networks.</title>
<p>Each recurrent network consists of 300 neurons. <bold>(a)</bold> Left, Activities of two reservoir networks are projected onto the top five eigenvectors of the correlation matrix. Shaded areas indicate the intervals of the presentation of chunks. Numerals on the right side show the variances explained. Right, The low-dimensional trajectories of the two reservoir modules are shown in the space spanned by PC1 to PC3. Red/blue or magenta/cyan portions show trajectories during the epoch of non-vanishing or vanishing teacher signals, respectively. <bold>(b)</bold> The eigenvalues of PCs are shown in a logarithmic scale. <bold>(c)</bold> The correlation coefficient between each PC and the readout activity is shown. <bold>(d)</bold> The length of readout weights projected onto each eigenvector is shown for first 100 eigenstates. <bold>(e)</bold> “Within-self” difference between the R1-output and the projected R1-output (green) and “between-partner” difference between the R2-output and the projected R1-output (blue) are shown for all the eigenstates before (dashed) and after (solid) learning. Insets display magnified versions for major eigenstates.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006400.g003" xlink:type="simple"/>
</fig>
<p>We then determined to what extent the responses of R1 and R2 are represented by the low-dimensional dynamical characteristics of R1. We calculated the PCs of recurrent network dynamics in R1, and expanded its population rate vector and readout weight vector up to the <italic>M</italic>-th order of these PCs (<italic>M</italic> ≦ <italic>N</italic><sub>G</sub>). Then, we reconstructed the output of R1 by using the <italic>M</italic>-th order rate vector and the <italic>M</italic>-th order weight vector on the low-dimensional subspace spanned by the first <italic>M</italic> PCs (Methods). In <xref ref-type="fig" rid="pcbi.1006400.g003">Fig 3E</xref>, we calculated the differences between the reconstructed R1-output and the full outputs of R1 (within-self difference) and R2 (between-partner difference). Before learning, both differences remained large as <italic>M</italic> was increased. After learning, the “within-self” difference rapidly decreased for <italic>M</italic> &lt; 30–40 and then gradually approached zero. The “between-partner” difference also rapidly dropped for relatively small values of <italic>M</italic>, but it stopped decreasing for <italic>M</italic> &gt; 50, remaining at relatively large values. These results suggest that R1’s reservoir, as well as R2’s reservoir, learns to mimic the partner's response by using the low-dimensional characteristics of its recurrent neural dynamics.</p>
<p>The role of low-dimensional neural dynamics in a broad range of computation was recently explored in a class of recurrent network models with a minimal connectivity structure [<xref ref-type="bibr" rid="pcbi.1006400.ref030">30</xref>], which is a combination of a low-rank structured matrix and a random unstructured matrix. The low-rank matrix may be trained to give task-related low-dimensional dynamics whereas the random matrix may generate chaotic fluctuations useful for learning. The RC system can be approximately viewed as such a network, where the product of readout weight vector and feedback weight vector (<bold><italic>J</italic></bold><sup><italic>GZ</italic></sup>)<sup>T</sup><bold><italic>w</italic></bold> defines a rank-one matrix and recurrent connections in the reservoir gives a random matrix. It will be intriguing to study the present chunk learning in the theoretical framework.</p>
</sec>
<sec id="sec008">
<title>Network- and chunk-size dependences of learning</title>
<p>Chunk learning may be easier and more accurate if chunks were shorter or network size is larger. However, we did not find a sharp drop of performance when the size of chunks was increased. To observe this, we first measured learning performance for two chunks with the sizes 4 and 7 by varying the network size. Instantaneous correlations were calculated between the activity of a readout unit and a reference response pattern, which takes the value 1 during the presentation of a chunk and is 0 otherwise, every 15 s during learning and were averaged over 20 independent simulations. Note that the maximum value of the correlation was 0.5 if the readout activity grows linearly from 0 to 1 during the chunk presentation. <xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4A Fig</xref> shows the correlations for input sequences containing the short or long chunk in networks of sizes <italic>N</italic><sub><italic>G</italic></sub> = 30, 300, and 500. Correlations were nearly zero before learning, but reached similar maximum values approximately within ten steps of learning. The average value of the correlations was generally larger for chunk size 4 than for chunk size 7, but the differences were not significant (<xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4B Fig</xref>).</p>
<p>Second, we measured learning performance by varying the size of chunks with the network size fixed (<italic>N</italic><sub>G</sub> = 300). In this simulation, we alternately presented a single chunk with the size <italic>s</italic> and random sequences of the sizes <italic>s</italic> + 2 to <italic>s</italic> + 5, where each element of the random sequences was chosen from a set of 4<italic>s</italic> elements. Thus, the dual RC system had 5<italic>s</italic> input neurons. When the chunk size exceeded 10 (<xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4C Fig</xref>), the value of correlation rapidly dropped, suggesting the existence of a critical chunk size beyond which learning performance is degraded. For <italic>s</italic> = 4, learning performance showed unexpectedly large fluctuations due to some unknown reason. The explicit evaluation of the critical chunk size requires an analytic approach, which is beyond the scope of this study.</p>
<p>In addition, a larger network did not necessarily show better performance. The magnitude of the post-learning instantaneous correlation was not significantly increased when the network size was 200 or greater (<xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4B Fig</xref>). Thus, the performance of chunk learning does not scale with the network size. This is not so surprising because increasing the size of the reservoirs does not necessarily increase the variety of neural responses useful for learning if the size is already sufficiently large. This seems to be particularly the case in the proposed mechanism because it heavily relies on the low-dimensional characteristics of neural dynamics (<xref ref-type="supplementary-material" rid="pcbi.1006400.s003">S3A Fig</xref>).</p>
</sec>
<sec id="sec009">
<title>Crucial role of noise in chunk learning</title>
<p>We found that external noise plays an active role in successful chunking. We demonstrated this in the case where the input only contained a single chunk (<xref ref-type="fig" rid="pcbi.1006400.g004">Fig 4A</xref>). In the absence of noise readout units, phasic responses were still observed, but these responses were not necessarily time-locked to chunks (<xref ref-type="fig" rid="pcbi.1006400.g004">Fig 4A</xref>, vertical arrow). As shown later, the two RC modules in principle may agree on an arbitrary feature of the input sequence, which implies the RC system may converge to a local minimum of learning. Noise may help the system to escape from the local minima. On the other hand, too strong of noise completely deteriorated the phasic responses to chunks. Thus, the RC system could learn chunks only when a modest amount of external noise existed (<xref ref-type="fig" rid="pcbi.1006400.g004">Fig 4B</xref>). In the presence of adequate noise (<italic>σ</italic> = 0.25), the average weight of the readout connections rapidly decreased to a small equilibrium value during learning (<xref ref-type="fig" rid="pcbi.1006400.g004">Fig 4C</xref>), leaving some readout weights much stronger than the majority (<xref ref-type="fig" rid="pcbi.1006400.g004">Fig 4D</xref>). This reduction was expected because external noise gives a regularization effect on synaptic weights in error-minimization learning [<xref ref-type="bibr" rid="pcbi.1006400.ref031">31</xref>]. The strong weights were obtained for readout connections from the reservoir neurons responding to the chunk, hence they were crucial for chunk detection. However, this was not the case in the absence of noise (<italic>σ</italic> = 0). We counted the fraction of strong readout connections that emerged from chunk-encoding reservoir neurons, where strong connections included those that were greater than the standard deviation of the weight distribution. Such a fraction was significantly larger in the presence of adequate noise than in the absence of noise. Under strong noise (σ = 1), although the weight distribution becomes more bimodal, the noise disrupted learning and the system failed to capture the chunks (<xref ref-type="fig" rid="pcbi.1006400.g004">Fig 4E</xref>).</p>
<fig id="pcbi.1006400.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006400.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Effects of noise on successful chunk learning.</title>
<p><bold>(a)</bold> Activity of a readout unit after learning a chunk at different noise levels: <italic>σ</italic> = 0 (black), 0.25 (red) and 1 (green). Without noise, the readout unit still learned to respond to a portion of input, but this portion did not necessarily belong to a chunk (vertical arrow). <bold>(b)</bold> Learning performance is a non-monotonic function of the noise level. The optimal performance was obtained at <italic>σ</italic> = 0.4–0.6 when the scaling factor in <xref ref-type="disp-formula" rid="pcbi.1006400.e005">Equation 4</xref> was set as <italic>g</italic><sub>G</sub> = 1.5 (cyan). The effect of noise on the learning performance was not significantly changed when the scaling factor was simultaneously reduced with the noise level (gray). <bold>(c)</bold> Evolution of the norm of readout weights during learning is shown for <italic>σ</italic> = 0 (black), 0.25 (red) and 1 (green). <bold>(d)</bold> The distributions of readout weights from chunk-encoding (red) and non-encoding (blue) reservoir neurons are shown after learning at different noise levels. Arrows indicate the maximum weight values from the chunk-encoding neurons. <bold>(e)</bold> The fraction of strong readout weights (see the main text) from the encoding neurons is shown for different noise levels. The fraction is significantly larger for <italic>σ</italic> = 0.25 compared with <italic>σ</italic> = 0 and 1 (p&lt;0.01, Mann–Whitney U test).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006400.g004" xlink:type="simple"/>
</fig>
<p>Another possible mechanism in which the external noise would improve the learning performance is that the dynamics of RC modules with weak noise are too far in the chaotic regime and the external noise suppresses chaos to enable proper chunk learning [<xref ref-type="bibr" rid="pcbi.1006400.ref032">32</xref>]. To test this possibility, we compensated a decrease of <italic>σ</italic> by decreasing the strength of recurrent conections <italic>g</italic><sub><italic>G</italic></sub>, which weakens the influences of chaos, and investigated whether the deterioration of performance is suppressed. The noise intensity was decreased from a modest level (<italic>σ</italic> = 0.5), and the values of <italic>σ</italic> and <italic>g</italic><sub><italic>G</italic></sub> were decreased at the same rate. Although the improvement was not significant, the dual RC system better resisted the performance deterioration (<xref ref-type="fig" rid="pcbi.1006400.g004">Fig 4B</xref>), suggesting that proper chunk learning requires a certain balance between external noise and chaotic dynamics.</p>
<p>Though our results so far suggest that mutual supervision enables the RC system to learn recurring groups of items in a sequence, these results do not indicate how the system chooses particular groups for learning. The question then arises whether our model detects a “chunk” if a sequence merely repeats each letter randomly without temporal grouping. To study this, we constructed a set of input sequences of ten letters, where all the letters appeared equally often in each sequence. We then exposed the RC system with a readout unit to these sequences. We found that the system learned to respond to one of the letters with approximately equal probabilities (<xref ref-type="supplementary-material" rid="pcbi.1006400.s005">S5A Fig</xref>). We then made the occurrence probability of letter “a” twice as large as the occurrence probabilities of the others and found that the system detected “a” about twice as frequent as the others (<xref ref-type="supplementary-material" rid="pcbi.1006400.s005">S5B Fig</xref>). These results indicate that the learning performance of the dual RC system relies on the occurrence frequency of repeated features if there are no other characteristic temporal features in the input sequence.</p>
<p>The frequency dependence of our model partially accounts for the features of sequences that are grouped into chunks. As demonstrated in <xref ref-type="fig" rid="pcbi.1006400.g003">Fig 3</xref>, a pair of RC modules engage in the mutual prediction of the partners' response. This prediction would be easier for the items in the input that repeatedly occur in a fixed temporal order. However, the explicit role of temporal grouping in chunking remains to be further clarified.</p>
<p>We then demonstrate that the RC system can simultaneously chunk multiple sequences with overlaps, where input sequences share some letters as common items. In some sequences, common subsequences appeared in the beginning or the end of chunks (<xref ref-type="fig" rid="pcbi.1006400.g005">Fig 5A</xref>), whereas other sequences involved common subsequences in the middle of chunks (<xref ref-type="fig" rid="pcbi.1006400.g005">Fig 5D</xref>). In both cases, the RC system (with two readout units) successfully chunked these input sequences without difficulty (<xref ref-type="fig" rid="pcbi.1006400.g005">Fig 5B and 5E</xref>). Interestingly, the activity of the readout units averaged over repetitive presentations ceased to increase during the presentation of the overlapping part of the chunks (<xref ref-type="fig" rid="pcbi.1006400.g005">Fig 5C and 5F</xref>). This seems reasonable as overlapping in part does not contribute to the prediction of the following items in the chunks and hence needs not be learned.</p>
<fig id="pcbi.1006400.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006400.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Learning chunks with mutual overlaps.</title>
<p><bold>(a)</bold> Two chunks shared the last component “d” in a random input sequence. <bold>(b)</bold> Activities of two readout units were selective to different chunks after learning. <bold>(c)</bold> The average response profiles are shown for the two readout units. <bold>(d)</bold> Two chunks shared the middle components “d-e” in a random input sequence. <bold>(e)</bold> and <bold>(f),</bold> Activities of two readout units and the average response profiles are shown, respectively.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006400.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec010">
<title>Chunking sequences of realistic inputs</title>
<p>So far, we have only studied discrete sequences of letters with varying complexity. However, the applicability of the proposed mechanism is not restricted to this relatively simple class of temporal inputs. We first showed the potential advantage of this mechanism over the conventional statistical methods, considering a system with three readout units (per RC module) for processing sequence inputs generated by a random walk through a graph (<xref ref-type="fig" rid="pcbi.1006400.g006">Fig 6A</xref>). This was previously used in examining the learning ability of event recognition by human subjects [<xref ref-type="bibr" rid="pcbi.1006400.ref023">23</xref>]. Each node of this graph has exactly four neighbors, and hence is visited by random walk with uniform transition probabilities over all neighbors. Despite this uniformity, the graph has three clusters of densely connected nodes, which define the communities in the graph [<xref ref-type="bibr" rid="pcbi.1006400.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref034">34</xref>]. Human subjects and our model (<xref ref-type="fig" rid="pcbi.1006400.g006">Fig 6A</xref>) can easily chunk these clusters according to community structure, but machine-learning algorithms based on surprise signals (e.g., [<xref ref-type="bibr" rid="pcbi.1006400.ref021">21</xref>]) cannot [<xref ref-type="bibr" rid="pcbi.1006400.ref023">23</xref>].</p>
<fig id="pcbi.1006400.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006400.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Chunking complex temporal inputs.</title>
<p>(a) Sequence inputs were generated by a graph with uniform transition probabilities and community structure. The graph was modified from [<xref ref-type="bibr" rid="pcbi.1006400.ref023">23</xref>]. (b) Sequence of high -resolution (97x97x3) visual stimuli, where the factor 3 represents the three RGB channels, was chunked. White intervals show periods of Gaussian noise. (c) Sequence of high-resolution (97x97x3) visual stimuli was chunked. (d) Learning curves are compared for the images shown in (c) between high (black) and low (gray) resolution versions. The images were repeatedly presented without noise intervals.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006400.g006" xlink:type="simple"/>
</fig>
<p>We further demonstrated that the proposed system can learn to detect two images recurring in visual input streams with (<xref ref-type="fig" rid="pcbi.1006400.g006">Fig 6B</xref>) and without (<xref ref-type="fig" rid="pcbi.1006400.g006">Fig 6C</xref>) random intervals of Gaussian noise stimuli. We examined whether learning speed depends on the resolution of images and found that such a dependence was weak if the network size was unchanged (<xref ref-type="fig" rid="pcbi.1006400.g006">Fig 6D</xref>). Our results show the potential ability of the proposed mechanism in analyzing the community structure of a broad class of temporal inputs.</p>
</sec>
</sec>
<sec id="sec011" sec-type="conclusions">
<title>Discussion</title>
<p>Conventional statistical methods of chunking use unequal transition probabilities between sequence elements as cues for sequence segmentation. In contrast, we propose a conceptually novel framework in which the neural system self-organizes its internal dynamics to respond preferentially to chunks (i.e., frequently recurring segments) with a temporal input, rather than attempts to predict the temporal patterns of input sequences. We achieved this unsupervised learning in a network of paired RC modules mutually learning the responses of the partners. Sequence leaning with RC has been studied in motor control [<xref ref-type="bibr" rid="pcbi.1006400.ref035">35</xref>–<xref ref-type="bibr" rid="pcbi.1006400.ref037">37</xref>] and decision making [<xref ref-type="bibr" rid="pcbi.1006400.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref039">39</xref>]. Theoretical extensions to spiking neuron networks [<xref ref-type="bibr" rid="pcbi.1006400.ref040">40</xref>] and/or reward-based learning [<xref ref-type="bibr" rid="pcbi.1006400.ref041">41</xref>] have thus been proposed. In this study, we showed that RC can be used for the unsupervised learning of hidden structure of continuous information streams.</p>
<p>Chunking has often been accounted for by predictive uncertainty or surprise [<xref ref-type="bibr" rid="pcbi.1006400.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref042">42</xref>–<xref ref-type="bibr" rid="pcbi.1006400.ref044">44</xref>]. However, recent evidence suggests the existence of an alternative mechanism of chunking in which events are segmented based on the temporal community structure of sequential stimuli [<xref ref-type="bibr" rid="pcbi.1006400.ref023">23</xref>]. Indeed, it has been shown that individual items in a sequence are concatenated into an event when they frequently go together in the sequence. This dual RC system automatically chunks a continuous flow of stimuli based on temporal clustering structure and the occurrence probabilities of the stimuli without relying on predictive uncertainty or surprise. In addition, the model can chunk clusters of sequence elements that cannot be chunked by conventional statistical methods based on unequal transition probabilities (<xref ref-type="fig" rid="pcbi.1006400.g006">Fig 6A</xref>). Unsupervised chunk learning was previously modeled by using heteroclinic orbits in a dynamical neural system [<xref ref-type="bibr" rid="pcbi.1006400.ref019">19</xref>]. Though this mechanism enables the learning of prescribed chunks, whether it also offers flexible learning of arbitrary chunks remains unclear.</p>
<p>Our model has some advantages over the previous models of chunking. Our model can detect multiple chunks embedded into random background sequences. To our knowledge, the detection of multiple chunks has not been seriously attempted in the presence of various types of input noise on chunking. Further, as shown in <xref ref-type="fig" rid="pcbi.1006400.g005">Fig 5</xref> our model can learn multiple partially overlapping chunks without additional mechanisms, which was also previously difficult. On the other hand, a weak point is that our model requires specially designed teaching signals, which depend on the structure of chunks. Related to this, mutually inhibitory teaching signals were introduced in an ad-hoc manner to prevent multiple readout units from learning the same chunk. A more flexible mechanism of learning should be further explored.</p>
<p>The dual RC system described here shows good performance in the presence of external noise. Without noise, the system also learns to respond to certain segments of a sequence, but these segments may not coincide with any of the frequently repeated chunks. An adequate amount of external noise eliminates such spurious responses and enables the system to respond to the most prominent features of a sequence, namely repeated chunks. This finding is interesting because the initial state of the dual RC system is chosen on the so-called “edge of chaos,” on which weakly chaotic neural dynamics provide an adequate amount of flexibility for supervised learning [<xref ref-type="bibr" rid="pcbi.1006400.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref045">45</xref>–<xref ref-type="bibr" rid="pcbi.1006400.ref046">46</xref>]. Moreover, the present system assumes a similar initial state, but additionally requires the regularization of synaptic weight dynamics by noise (<xref ref-type="fig" rid="pcbi.1006400.g004">Fig 4C</xref>). Training a recurrent neural network with an explicit regularization term is known to eliminate the strange neuronal responses that are not observed in the motor cortex [<xref ref-type="bibr" rid="pcbi.1006400.ref037">37</xref>].</p>
<p>The dual RC system learns sequence in an unsupervised fashion by using two neural networks and, in this sense, is similar to Generative Adversarial Network (GAN) in deep learning [<xref ref-type="bibr" rid="pcbi.1006400.ref047">47</xref>]. A critical difference, however, exists between the two models. In GANs, a generative network learns to mimic the structure of training data and a discriminative network learns to distinguish between samples from the training data and those generated by the generative network. Because the generative model learns to deceive the discriminative model, GANs learn the structure of data distribution under a conflicting cost function. By contrast, in the dual RC system, two neural networks learn to help each other for the formation of a consensus about the structure of temporal inputs. Therefore, our model is conceptually different from GANs.</p>
<p>The structure of our model has an interesting similarity to cortico-basal ganglia loops, where two reservoirs may represent bi-hemispheric cortical networks and readout units may correspond to striatal neurons. The responses of readout units and those of striatal neurons in the formation of motor habits also look similar. Sequential motor behavior becomes more rigid and automatic over the course of learning and practice, and the basal ganglia is thought to play a pivotal role in habit formation [<xref ref-type="bibr" rid="pcbi.1006400.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref048">48</xref>]. For instance, in rats running in a T maze, the majority of dorsolateral striatal neurons exhibit burst firing when the run is initiated or completed, or both [<xref ref-type="bibr" rid="pcbi.1006400.ref049">49</xref>]. Similarly, in mice an increased population of striatal neurons selectively responds to the initial (Start cells), the last (Stop cells), or both actions in the trained behavioral sequence [<xref ref-type="bibr" rid="pcbi.1006400.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref008">8</xref>]. In our model, readout units respond strongly to the last component of each chunk, similar to the Stop cells. Our model predicts that the Stop-cell’s response may decrease when two motor chunks have overlapping portions (<xref ref-type="fig" rid="pcbi.1006400.g005">Fig 5</xref>). On the other hand, our model does not show Start cell-like responses. Whether and how Start cells are formed is an intriguing open question.</p>
<p>The proposed learning scheme works most efficiently when two RC modules are not interconnected, but rather work independently. In fact, the performance of chunk learning drops below 50% of the initial level when the connection probability between the two reservoirs exceeds about 10% (<xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4D Fig</xref>, see the <xref ref-type="sec" rid="sec012">Methods</xref>). This suggests that each RC module can obtain maximum information about temporal input when it receives the teaching signal completely from its outside. The existence of inter-reservoir connections implies that some portion of the teaching signal originates from its inside. Where can such independent networks be located in the brain? One possibility is that they are represented by mutually disconnected recurrent neuronal networks in a local cortical area. Because they are functionally equivalent, it is unlikely that they are implemented in functionally distinct areas. Another intriguing possibility is that they are distributed to functionally equivalent cortical areas in different hemispheres. Indeed, the inferior frontal gyrus and the anterior insula are bilaterally activated when human subjects chunk visual information streams [<xref ref-type="bibr" rid="pcbi.1006400.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1006400.ref050">50</xref>]. Whether subnetworks of pyramidal cells perform chunking in these or other cortical areas [<xref ref-type="bibr" rid="pcbi.1006400.ref051">51</xref>] remains an intriguing open question.</p>
<p>In summary, we propose an unsupervised learning system by combining two independent reservoir computing modules. During learning, the two systems supervise each other to generate coincident outputs, which in turn allows the entire system to consistently learn chunks hidden in irregular input sequences. As chunking is a fundamental step in the analysis of sequence information, our results have significant implications for understanding how the brain models the external world.</p>
</sec>
<sec id="sec012" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec013">
<title>Details of the neural network models</title>
<p>In this study, the proposed model is composed of two recurrent networks (reservoirs). Each recurrent network is composed of <italic>N</italic><sub><italic>G</italic></sub> neurons. Each neuron follows the following dynamics as <italic>i</italic> = 1,2,… <italic>N</italic><sub><italic>G</italic></sub>,
<disp-formula id="pcbi.1006400.e005">
<alternatives>
<graphic id="pcbi.1006400.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mi>τ</mml:mi><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>˙</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mi>G</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mi>Z</mml:mi></mml:mrow></mml:msubsup><mml:mi>z</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">μ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="normal">σ</mml:mi><mml:msub><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
<disp-formula id="pcbi.1006400.e006">
<alternatives>
<graphic id="pcbi.1006400.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">tanh</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula>
where <italic>I</italic><sub><italic>μ</italic></sub>(<italic>t</italic>) is the activity of input neurons, <italic>ξ</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is a random (Wiener) process and <italic>σ</italic> is the standard deviation. <italic>N</italic><sub><italic>I</italic></sub> is the number of input neurons. The parameter <italic>g</italic><sub><italic>G</italic></sub> determines the complexity of the behavior of the reservoir, and shows chaotic spontaneous activity if <italic>g</italic><sub><italic>G</italic></sub> &gt; 1. The instantaneous output is given by <italic>z</italic>(<italic>t</italic>) = <bold><italic>w</italic></bold><sup>T</sup><bold><italic>r</italic></bold>(<italic>t</italic>), where <bold><italic>w</italic></bold> is the readout weight vector. The readout unit is connected with <italic>n</italic> reservoir neurons by the readout weights <bold><italic>w</italic></bold>. The readout weights are modified according to the FORCE learning rule in which the error between the actual output and the teaching signal is minimized [<xref ref-type="bibr" rid="pcbi.1006400.ref029">29</xref>]. The activity of the readout unit is transmitted to the reservoir via the feedback.</p>
<p>The initial values of the readout weights <bold><italic>w</italic></bold> are generated by a Gaussian distribution with the mean 0 and variance 1/<italic>n</italic>. Each element of the feedback coupling <italic>J</italic><sup><italic>Gz</italic></sup> is randomly sampled from a uniform distribution [-1, +1]. In the connection matrix <italic>J</italic><sup><italic>GG</italic></sup> of the reservoir, each element is taken from a Gaussian distribution with mean 0 and variance 1/(<italic>pN</italic><sub><italic>G</italic></sub>), where <italic>p</italic> is the connection probability of the reservoir neurons. In the connection matrix <italic>J</italic><sup><italic>GI</italic></sup> between input neurons and the reservoir, each row has only one non-zero element drawn from a normal distribution of mean 0 and variance 1. We simulated the model with time steps of 1 [ms].</p>
<p>The values of parameters used in simulations are as follows: in Figs <xref ref-type="fig" rid="pcbi.1006400.g001">1</xref>, <xref ref-type="fig" rid="pcbi.1006400.g003">3</xref> and <xref ref-type="fig" rid="pcbi.1006400.g004">4</xref> and <xref ref-type="supplementary-material" rid="pcbi.1006400.s001">S1 Fig</xref>, <xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4C Fig</xref>, <xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4D Fig</xref>, and <xref ref-type="supplementary-material" rid="pcbi.1006400.s005">S5 Fig</xref>, <italic>N</italic><sub>G</sub> = 300,<italic>p</italic> = 1,<italic>n</italic> = 300 and <italic>σ</italic> = 0.3; in Figs <xref ref-type="fig" rid="pcbi.1006400.g002">2</xref> and <xref ref-type="fig" rid="pcbi.1006400.g006">6</xref>, <xref ref-type="supplementary-material" rid="pcbi.1006400.s002">S2 Fig</xref>, and <xref ref-type="supplementary-material" rid="pcbi.1006400.s003">S3 Fig</xref>, <italic>N</italic><sub>G</sub> = 600,<italic>p</italic> = 0.5,<italic>n</italic> = 300 and <italic>σ</italic> = 0.1; in <xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4A Fig</xref> and <xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4B Fig</xref>, <italic>p</italic> = 1,<italic>σ</italic> = 0.3 and <italic>n</italic> = <italic>N</italic><sub>G</sub> while the values of <italic>N</italic><sub>G</sub> were varied; in <xref ref-type="fig" rid="pcbi.1006400.g005">Fig 5</xref>, <italic>p</italic> = 1,<italic>n</italic> = 300, and <italic>N</italic><sub>G</sub> = 800,<italic>σ</italic> = 0.15 (b) or <italic>N</italic><sub>G</sub> = 500,<italic>σ</italic> = 0.1 (e). The number of input neurons was <italic>N</italic><sub>I</sub> = 26 in all simulations except <xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4C Fig</xref>, in which <italic>N</italic><sub>I</sub> was 5<italic>s</italic> with <italic>s</italic> being the size of the chunk. In all simulations, <italic>τ</italic> = 10 [ms] and <italic>g</italic><sub>G</sub> = 1.5. The learning rate was set as <italic>α</italic> = 100 because larger values could cause instability in the learning process. The network was trained typically for several hundreds of seconds except in Figs <xref ref-type="fig" rid="pcbi.1006400.g002">2</xref>, <xref ref-type="fig" rid="pcbi.1006400.g005">5B and 5E</xref> where the simulation time was 5000, 2500 and 25,000 [s], respectively.</p>
</sec>
<sec id="sec014">
<title>Teaching signals mediated by interneurons</title>
<p>In <xref ref-type="supplementary-material" rid="pcbi.1006400.s002">S2D Fig</xref>, the teaching signals were generated as
<disp-formula id="pcbi.1006400.e007">
<alternatives>
<graphic id="pcbi.1006400.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>4,5</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mi mathvariant="normal">β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mspace width="0.50em"/><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>1,2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula>
where the activities of interneurons were calculated as
<disp-formula id="pcbi.1006400.e008">
<alternatives>
<graphic id="pcbi.1006400.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mi>τ</mml:mi><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>˙</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula>
A similar formula applied to the partner network. Note that a dash in the second term of <xref ref-type="disp-formula" rid="pcbi.1006400.e007">Eq 6</xref> indicates that the corresponding readout unit should be excluded from the summation (<xref ref-type="supplementary-material" rid="pcbi.1006400.s002">S2C Fig</xref>).</p>
</sec>
<sec id="sec015">
<title>Connections between the reservoirs</title>
<p>In <xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4D Fig</xref>, the weights of recurrent connections in each reservoir module and those of connections between the modules were sampled from an identical Gaussian distribution with mean 0 and variance 1/{(1 + <italic>q</italic>)<italic>N</italic><sub><italic>G</italic></sub>}, where <italic>q</italic> is the connection probability of inter-module connections. The recurrent connections were all-to-all. The value 1 in the denominator was introduced such that the limit <italic>q</italic> → 0 gives the disconnected RC modules studied in other panels in <xref ref-type="supplementary-material" rid="pcbi.1006400.s004">S4 Fig</xref>.</p>
</sec>
<sec id="sec016">
<title>Normalized output for teaching signals</title>
<p>In our learning rule, we changed the outputs of readout units such that the mean outputs coincide with zero and the standard deviation becomes unity:
<disp-formula id="pcbi.1006400.e009">
<alternatives>
<graphic id="pcbi.1006400.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mi>z</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>⟶</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>z</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula>
where <italic>μ</italic>(<italic>t</italic>) and <italic>σ</italic>(<italic>t</italic>) were calculated as
<disp-formula id="pcbi.1006400.e010">
<alternatives>
<graphic id="pcbi.1006400.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mi>μ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mfrac><mml:mspace width="0.25em"/><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mi>z</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
<label>(9)</label>
</disp-formula>
<disp-formula id="pcbi.1006400.e011">
<alternatives>
<graphic id="pcbi.1006400.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>μ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
<label>(10)</label>
</disp-formula>
with a sufficiently long period <italic>T</italic> (= 15 [s]). The modified output <inline-formula id="pcbi.1006400.e012"><alternatives><graphic id="pcbi.1006400.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> was then transformed by two nonlinear functions to generate the teaching signal shown in the Results.</p>
</sec>
<sec id="sec017">
<title>Selectivity of reservoir neurons</title>
<p>In <xref ref-type="supplementary-material" rid="pcbi.1006400.s003">S3A Fig</xref>, the activities of all reservoir neurons were first averaged and then normalized. To define the response selectivity of neurons, we sorted all of the neurons by their mean activation phases defined as,
<disp-formula id="pcbi.1006400.e013">
<alternatives>
<graphic id="pcbi.1006400.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">arg</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mspace width="0.50em"/><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>]</mml:mo><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
<label>(11)</label>
</disp-formula>
where <inline-formula id="pcbi.1006400.e014"><alternatives><graphic id="pcbi.1006400.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> is the normalized average response of each cell and <italic>T</italic> = 2400 [ms]. Each reservoir neuron generally showed a significantly large and prolonged phasic response to a particular chunk, which determined the selectivity of the reservoir neuron. We defined a phasic response as such transient activity that exceeded the threshold value μ + 3σ for more than 100 [ms], where μ and σ stand for the average and standard deviation of its activity during the presentation of input sequence. Neurons that were not related to any chunks or responded to multiple chunks were discarded in the analysis.</p>
</sec>
<sec id="sec018">
<title>Analysis of the low-dimensional dynamics of reservoirs</title>
<p>In <xref ref-type="fig" rid="pcbi.1006400.g003">Fig 3</xref>, we projected the neural responses <bold><italic>r</italic></bold><sub>R1</sub>(<italic>t</italic>) of recurrent network in R1 onto the <italic>M</italic> (≦<italic>N</italic><sub><italic>G</italic></sub>) dimensional subspace:
<disp-formula id="pcbi.1006400.e015">
<alternatives>
<graphic id="pcbi.1006400.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e015" xlink:type="simple"/>
<mml:math display="block" id="M15">
<mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
<label>(12)</label>
</disp-formula>
Here, the (<italic>N</italic><sub><italic>G</italic></sub>×<italic>M</italic>)-dimensional matrix <bold><italic>V</italic></bold><sub><italic>M</italic></sub> is defined as <bold><italic>V</italic></bold><sub><italic>M</italic></sub> = (<bold><italic>φ</italic></bold><sub><italic>1</italic></sub><sup>(R1)</sup> <bold><italic>φ</italic></bold><sub><italic>2</italic></sub><sup>(R1)</sup> …<bold><italic>φ</italic></bold><sub><italic>M</italic></sub><sup>(R1)</sup>) in terms of the <italic>λ-</italic>th eigenvector of R1 reservoir <bold><italic>φ</italic></bold><sub><italic>λ</italic></sub><sup>(R1)</sup>. Similarly, we projected the readout weight vectors from R1 onto the same subspace as
<disp-formula id="pcbi.1006400.e016">
<alternatives>
<graphic id="pcbi.1006400.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e016" xlink:type="simple"/>
<mml:math display="block" id="M16">
<mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
<label>(13)</label>
</disp-formula>
We then calculated the difference between the actual output of R1 and the output reconstructed on the subspace as
<disp-formula id="pcbi.1006400.e017">
<alternatives>
<graphic id="pcbi.1006400.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006400.e017" xlink:type="simple"/>
<mml:math display="block" id="M17">
<mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msqrt><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
<label>(14)</label>
</disp-formula>
The difference between the actual output of R2 and the projected R1-output was calculated in a similar fashion.</p>
</sec>
<sec id="sec019">
<title>Simulations of visual information streams</title>
<p>In <xref ref-type="fig" rid="pcbi.1006400.g006">Fig 6B and 6C</xref>, we constructed a pair of RC modules each having two readout units. A stream of two images with high (97x97 pixels x 3 RGB channels) or low (32x32 pixels x 3 RGB channels) resolutions was used as input, in which the presentations of two images (and Gaussian noise images in <xref ref-type="fig" rid="pcbi.1006400.g006">Fig 6B</xref>) were randomly switched at every 250 ms. Each reservoir neuron received input from randomly chosen 10% of pixels. In <xref ref-type="fig" rid="pcbi.1006400.g006">Fig 6D</xref>, the low-resolution versions of the images used in <xref ref-type="fig" rid="pcbi.1006400.g006">Fig 6C</xref> were created at the reduced size of 32 x32 pixels (x 3 RGB channels).</p>
<p>All codes for computer simulations were written in Python 3 and are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/ToshitakeAsabuki/dualRC_codes" xlink:type="simple">https://github.com/ToshitakeAsabuki/dualRC_codes</ext-link>.</p>
</sec>
</sec>
<sec id="sec020">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006400.s001" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006400.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Responses of readout neurons during learning procedure.</title>
<p>Below, numerical results are shown for the model simulated in <xref ref-type="fig" rid="pcbi.1006400.g001">Fig 1</xref>. The responses of two readout neurons were initially incoherent (top). They gradually developed strong coherent responses to the repetition of a chunk as learning proceeded (middle and bottom).</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006400.s002" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006400.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Structure of teaching signals for multiple chunk learning.</title>
<p><bold>(a)</bold> A schematic illustration for the structure of teaching signals for <italic>z</italic><sub>1</sub>. Since the partner node of <italic>z</italic><sub>1</sub> is <italic>z</italic><sub>4,</sub> the sign of the corresponding term in the teaching signal is positive whereas the other terms are negative. <bold>(b)</bold> Teaching signals show incoherent activities (top) before learning, while the learning procedure makes these activities much coherent (middle and bottom). Thick and thin lines represent teaching signals from the pair of the readouts. <bold>(c)</bold> Lateral inhibitions by interneurons are modeled. <bold>(d)</bold> The activities of readouts after learning with interneurons.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006400.s003" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006400.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Cell assemblies selected in the reservoirs.</title>
<p><bold>(a)</bold> The activity of each reservoir neuron was averaged over repeated trials and normalized by its maximum activity. Neurons were sorted according to the onset times of their activations to reveal the cell assemblies encoding the three chunks (Methods). <bold>(b)</bold> The distributions of input weights onto each cell assembly are shown for input neurons belonging to the corresponding chunk (solid) and the others (dashed). The solid and dashed distributions summed over all cell assemblies were significantly different (p = 0.011, t-test). <bold>(c)</bold> Temporal evolution is shown for average weights from encoding cell assemblies to the corresponding readout units. <bold>(d)</bold> Normalized distributions are shown for readout weights from each cell assembly. <bold>(e)</bold> The distribution of feedback weights from readout units to each cell assembly is shown.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006400.s004" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006400.s004" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Learning with different sizes of reservoirs and chunks.</title>
<p><bold>(a)</bold> The time course and performance of learning are shown for an input sequence involving a single chunk of the length 4 (blue) or 7 (red). Three networks with different sizes (<italic>N</italic><sub>G</sub> = 30, 300, 500) were tested. <bold>(b)</bold> The values of the correlation after learning are plotted as a function of the network size. <bold>(c)</bold> The dependence of the correlation on the chunk size is shown. <bold>(d)</bold> The dependence of the correlation on the connection probability between the two reservoirs is presented.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006400.s005" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006400.s005" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Learning random sequences of single characters.</title>
<p>The model shown in <xref ref-type="fig" rid="pcbi.1006400.g001">Fig 1</xref> was exposed to random sequences consisting of 10 characters (a, b, …, j). Input sequences had no apparent temporally grouped subsequences. (a) The counts of simulation trials in which each character was learned. All characters appeared equally often in input sequences. In total, 300 trials were performed. (b) Similar trial counts were taken when character “a” appeared twice as often as others.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Vladimir Klinshov, Tomoki Kurikawa, Keita Watanabe and Takashi Takekawa for illuminating discussions about analysis methods for population neural dynamics.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006400.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graybiel</surname> <given-names>AM</given-names></name>. <article-title>The basal ganglia and chunking of action repertoires</article-title>. <source>Neurobiol Learn Mem</source>. <year>1998</year>; <volume>70</volume>(<issue>1–2</issue>): <fpage>119</fpage>–<lpage>136</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/nlme.1998.3843" xlink:type="simple">10.1006/nlme.1998.3843</ext-link></comment> <object-id pub-id-type="pmid">9753592</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>GA</given-names></name>. <article-title>The magical number seven, plus or minus two: Some limits on our capacity for processing information</article-title>. <source>Psychological Review</source>. <year>1956</year>; <volume>63</volume>(<issue>2</issue>): <fpage>81</fpage>–<lpage>97</lpage>. <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/h0043158" xlink:type="simple">http://dx.doi.org/10.1037/h0043158</ext-link>. <object-id pub-id-type="pmid">13310704</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ericcson</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Chase</surname> <given-names>WG</given-names></name>, <name name-style="western"><surname>Faloon</surname> <given-names>S</given-names></name>. <article-title>Acquisition of a memory skill</article-title>. <source>Science</source>. <year>1980</year>; <volume>208</volume>(<issue>4448</issue>): <fpage>1181</fpage>–<lpage>1182</lpage>. <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.7375930" xlink:type="simple">http://dx.doi.org/10.1126/science.7375930</ext-link>. <object-id pub-id-type="pmid">7375930</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Orban</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Fiser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Aslin</surname> <given-names>RN</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Bayesian learning of visual chunks by human observers</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2007</year>; <volume>105</volume>(<issue>7</issue>): <fpage>2745</fpage>–<lpage>2750</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0708424105" xlink:type="simple">10.1073/pnas.0708424105</ext-link></comment> <object-id pub-id-type="pmid">18268353</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Christiansen</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>. <article-title>The Now-or-Never bottleneck: A fundamental constraint on language</article-title>. <source>Behavioral &amp; Brain Sciences</source>. <year>2016</year>; <volume>39</volume>, <fpage>e62</fpage>: <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1017/S0140525X1500031X" xlink:type="simple">10.1017/S0140525X1500031X</ext-link></comment> <object-id pub-id-type="pmid">25869618</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fujii</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Graybiel</surname> <given-names>AM</given-names></name>. <article-title>Representation of action sequence boundaries by macaque prefrontal cortical neurons</article-title>. <source>Science</source>. <year>2003</year>; <volume>301</volume>(<issue>5637</issue>): <fpage>1246</fpage>–<lpage>1249</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1086872" xlink:type="simple">10.1126/science.1086872</ext-link></comment> <object-id pub-id-type="pmid">12947203</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jin</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Costa</surname> <given-names>RM</given-names></name>. <article-title>Start/stop signals emerge in nigrostriatal circuits during sequence learning</article-title>. <source>Nature</source>. <year>2010</year>; <volume>466</volume>(<issue>7305</issue>): <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature09263" xlink:type="simple">10.1038/nature09263</ext-link></comment> <object-id pub-id-type="pmid">20651684</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jin</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Tecuapetla</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Costa</surname> <given-names>RM</given-names></name>. <article-title>Basal ganglia subcircuits distinctively encode the parsing and concatenation of action sequences</article-title>. <source>Nat Neurosci</source>. <year>2014</year>; <volume>17</volume>(<issue>3</issue>): <fpage>423</fpage>–<lpage>430</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3632" xlink:type="simple">10.1038/nn.3632</ext-link></comment> <object-id pub-id-type="pmid">24464039</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Graybiel</surname> <given-names>AM</given-names></name>. <article-title>A dual operator view of habitual behavior reflecting cortical and striatal dynamics</article-title>. <source>Neuron</source>. <year>2013</year>; <volume>79</volume>(<issue>3</issue>): <fpage>361</fpage>–<lpage>374</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.05.038" xlink:type="simple">10.1016/j.neuron.2013.05.038</ext-link></comment> <object-id pub-id-type="pmid">23810540</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buiatti</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Peña</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dehaene-Lambertz</surname> <given-names>G</given-names></name>. <article-title>Investigating the neural correlates of continuous speech computation with frequency-tagged neuroelectric responses</article-title>. <source>Neuroimage</source>. <year>2009</year>; <volume>44</volume>(<issue>2</issue>): <fpage>509</fpage>–<lpage>519</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2008.09.015" xlink:type="simple">10.1016/j.neuroimage.2008.09.015</ext-link></comment> <object-id pub-id-type="pmid">18929668</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gentner</surname> <given-names>TQ</given-names></name>, <name name-style="western"><surname>Fenn</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Margoliash</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Nusbaum</surname> <given-names>HC</given-names></name>. <article-title>Recursive syntactic pattern learning by songbirds</article-title>. <source>Nature</source>. <year>2006</year>; <volume>440</volume>(<issue>7088</issue>): <fpage>1204</fpage>–<lpage>1207</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature04675" xlink:type="simple">10.1038/nature04675</ext-link></comment> <object-id pub-id-type="pmid">16641998</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ramkumar</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Acuna</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Berniker</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Grafton</surname> <given-names>ST</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Kording</surname> <given-names>KP</given-names></name>. <article-title>Chunking as the result of an efficiency computation trade-off</article-title>. <source>Nat Commun</source>. <year>2016</year>; <volume>7</volume>: <fpage>12176</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ncomms12176" xlink:type="simple">10.1038/ncomms12176</ext-link></comment> <object-id pub-id-type="pmid">27397420</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Verwey</surname> <given-names>WB</given-names></name>, <name name-style="western"><surname>Abrahamse</surname> <given-names>EL</given-names></name>. <article-title>Distinct modes of executing movement sequences: reacting, associating, and chunking</article-title>. <source>Acta Psychol</source>. <year>2012</year>; <volume>140</volume>(<issue>3</issue>): <fpage>274</fpage>–<lpage>282</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.actpsy.2012.05.007" xlink:type="simple">https://doi.org/10.1016/j.actpsy.2012.05.007</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Meyniel</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Wacongne</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Pallier</surname> <given-names>C</given-names></name>. <article-title>The Neural Representation of Sequences: From Transition Probabilities to Algebraic Patterns and Linguistic Trees</article-title>. <source>Neuron</source>. <year>2015</year>; <volume>88</volume>(<issue>1</issue>): <fpage>2</fpage>–<lpage>19</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.09.019" xlink:type="simple">10.1016/j.neuron.2015.09.019</ext-link></comment> <object-id pub-id-type="pmid">26447569</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wymbs</surname> <given-names>NF</given-names></name>, <name name-style="western"><surname>Bassett</surname> <given-names>DS</given-names></name>, <name name-style="western"><surname>Mucha</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Porter</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Grafton</surname> <given-names>ST</given-names></name>. <article-title>Differential recruitment of the sensorimotor putamen and frontoparietal cortex during motor chunking in humans</article-title>. <source>Neuron</source>. <year>2012</year>; <volume>74</volume>(<issue>5</issue>): <fpage>936</fpage>–<lpage>946</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2012.03.038" xlink:type="simple">10.1016/j.neuron.2012.03.038</ext-link></comment> <object-id pub-id-type="pmid">22681696</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kiebel</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Von Kriegstein</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Recognizing Sequences of Sequences</article-title>. <source>PLoS computational biology</source>. <year>2009</year>; <volume>5</volume>(<issue>8</issue>): <fpage>e1000464</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1000464" xlink:type="simple">10.1371/journal.pcbi.1000464</ext-link></comment> <object-id pub-id-type="pmid">19680429</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reynolds</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Zacks</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Braver</surname> <given-names>TS</given-names></name>. <article-title>A computational model of event segmentation from perceptual prediction</article-title>. <source>Cogn Sci</source>. <year>2007</year>; <volume>31</volume>(<issue>4</issue>): <fpage>613</fpage>–<lpage>643</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/15326900701399913" xlink:type="simple">10.1080/15326900701399913</ext-link></comment> <object-id pub-id-type="pmid">21635310</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rabinovich</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Varona</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Tristan</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Afraimovich</surname> <given-names>V</given-names></name>. <article-title>Chunking dynamics: heteroclinics in mind</article-title>. <source>Frontiers Comput. Neurosci</source>. <year>2014</year>; <volume>8</volume>(<issue>22</issue>): <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncom.2014.00022" xlink:type="simple">10.3389/fncom.2014.00022</ext-link></comment> <object-id pub-id-type="pmid">24672469</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fonollosa</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Neftci</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Rabinovich</surname> <given-names>M</given-names></name>. <article-title>Learning of chunking sequences in cognition and behavior</article-title>. <source>PLoS computational biology</source>. <year>2015</year>; <volume>11</volume>(<issue>11</issue>): <fpage>e1004592</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004592" xlink:type="simple">10.1371/journal.pcbi.1004592</ext-link></comment> <object-id pub-id-type="pmid">26584306</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Deng</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Zeng</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Song</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Pei</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shi</surname> <given-names>L</given-names></name>. <article-title>Hierarchical Chunking of Sequential Memory on Neuromorphic Architecture with Reduced Synaptic Plasticity</article-title>. <source>Frontiers Comput. Neurosci</source>. <year>2016</year>; <volume>10</volume>(<issue>136</issue>): <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncom.2016.00136" xlink:type="simple">https://doi.org/10.3389/fncom.2016.00136</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perruchet</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Vinter</surname> <given-names>A</given-names></name>. <article-title>Parser: a model for word segmentation</article-title>. <source>J. Mem. Lang</source>. <year>1998</year>; <volume>39</volume>(<issue>2</issue>): <fpage>246</fpage>–<lpage>263</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/jmla.1998.2576" xlink:type="simple">https://doi.org/10.1006/jmla.1998.2576</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Remillard</surname> <given-names>G</given-names></name>. <article-title>Implicit learning of fifth- and sixth-order sequential probabilities</article-title>. <source>Mem. Cognit</source>. <year>2010</year>; <volume>38</volume>(<issue>7</issue>): <fpage>905</fpage>–<lpage>915</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/MC.38.7.905" xlink:type="simple">10.3758/MC.38.7.905</ext-link></comment> <object-id pub-id-type="pmid">20921103</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schapiro</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Rogers</surname> <given-names>TT</given-names></name>, <name name-style="western"><surname>Cordova</surname> <given-names>NI</given-names></name>, <name name-style="western"><surname>Turk-Browne</surname> <given-names>NB</given-names></name>, <name name-style="western"><surname>Botvinick</surname> <given-names>MM</given-names></name>. <article-title>Neural representations of events arise from temporal community structure</article-title>. <source>Nat Neurosci</source>. <year>2013</year>; <volume>16</volume>(<issue>4</issue>): <fpage>486</fpage>–<lpage>492</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3331" xlink:type="simple">10.1038/nn.3331</ext-link></comment> <object-id pub-id-type="pmid">23416451</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huettel</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Mack</surname> <given-names>PB</given-names></name>, <name name-style="western"><surname>McCarthy</surname> <given-names>G</given-names></name>. <article-title>Perceiving patterns in random series: dynamic processing of sequence in prefrontal cortex</article-title>. <source>Nat Neurosci</source>. <year>2002</year>; <volume>5</volume>(<issue>5</issue>): <fpage>485</fpage>–<lpage>490</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn841" xlink:type="simple">10.1038/nn841</ext-link></comment> <object-id pub-id-type="pmid">11941373</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Agus</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Thorpe</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Pressnitzer</surname> <given-names>D</given-names></name>. <article-title>Rapid formation of robust auditory memories: insights from noise</article-title>. <source>Neuron</source>. <year>2010</year>; <volume>66</volume>(<issue>4</issue>): <fpage>610</fpage>–<lpage>618</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2010.04.014" xlink:type="simple">10.1016/j.neuron.2010.04.014</ext-link></comment> <object-id pub-id-type="pmid">20510864</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Romberg</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Saffran</surname> <given-names>JR</given-names></name>. <article-title>Expectancy learning from probabilistic input by infants</article-title>. <source>Front Psychol</source>. <year>2013</year>; <volume>3</volume>: <fpage>610</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2012.00610" xlink:type="simple">10.3389/fpsyg.2012.00610</ext-link></comment> <object-id pub-id-type="pmid">23439947</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Natschlger</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Markram</surname> <given-names>H</given-names></name>. <article-title>Real-Time Computing Without Stable States: A New Framework for Neural Computation Based on Perturbations</article-title>. <source>Neural Comput</source>. <year>2002</year>; <volume>14</volume>(<issue>11</issue>): <fpage>2531</fpage>–<lpage>2560</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089976602760407955" xlink:type="simple">10.1162/089976602760407955</ext-link></comment> <object-id pub-id-type="pmid">12433288</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jaeger</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Haas</surname> <given-names>H</given-names></name>. <article-title>Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in Wireless Communication</article-title>. <source>Science</source>. <year>2004</year>; <volume>304</volume>(<issue>5667</issue>): <fpage>78</fpage>–<lpage>80</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1091277" xlink:type="simple">10.1126/science.1091277</ext-link></comment> <object-id pub-id-type="pmid">15064413</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sussillo</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>. <article-title>Generating coherent patterns of activity from chaotic neural networks</article-title>. <source>Neuron</source>. <year>2009</year>; <volume>63</volume>(<issue>4</issue>): <fpage>544</fpage>–<lpage>557</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2009.07.018" xlink:type="simple">10.1016/j.neuron.2009.07.018</ext-link></comment> <object-id pub-id-type="pmid">19709635</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref030"><label>30</label><mixed-citation publication-type="other" xlink:type="simple">Mastrogiuseppe F, Ostojic S. Linking connectivity, dynamics and computation in recurrent neural networks. arXiv:1711.09672 [q-bio.NC]. 2017.</mixed-citation></ref>
<ref id="pcbi.1006400.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bishop</surname> <given-names>CM</given-names></name>. <article-title>Training with noise is equivalent to Tikhonov regularization</article-title>. <source>Neural Comput</source>. <year>1995</year>; <volume>7</volume>(<issue>1</issue>): <fpage>108</fpage>–<lpage>116</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/neco.1995.7.1.108" xlink:type="simple">https://doi.org/10.1162/neco.1995.7.1.108</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref032"><label>32</label><mixed-citation publication-type="other" xlink:type="simple">Schuecker J, Goedeke S, Helias M. Optimal sequence memory in driven random networks. arXiv:1603.01880 [q-bio.NC]. 2016.</mixed-citation></ref>
<ref id="pcbi.1006400.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fortunato</surname> <given-names>S</given-names></name>. <article-title>Community detection in graphs</article-title>. <source>Phys. Rep</source>. <year>2010</year>; <volume>486</volume>(<issue>3–5</issue>): <fpage>175</fpage>–<lpage>174</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.physrep.2009.11.002" xlink:type="simple">https://doi.org/10.1016/j.physrep.2009.11.002</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Newman</surname> <given-names>MEJ</given-names></name>. <article-title>The structure and function of complex networks</article-title>. <source>SIAM Rev</source>. <year>2003</year>; <volume>45</volume>(<issue>2</issue>): <fpage>167</fpage>–<lpage>256</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1137/S003614450342480" xlink:type="simple">https://doi.org/10.1137/S003614450342480</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laje</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Buonomano</surname> <given-names>DV</given-names></name>. <article-title>Robust timing and motor patterns by taming chaos in recurrent neural networks</article-title>. <source>Nat Neurosci</source>. <year>2013</year>; <volume>16</volume>(<issue>7</issue>): <fpage>925</fpage>–<lpage>933</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3405" xlink:type="simple">10.1038/nn.3405</ext-link></comment> <object-id pub-id-type="pmid">23708144</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shenoy</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Kaufman</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Churchland</surname> <given-names>MM</given-names></name>. <article-title>A dynamical systems view of motor preparation: implications for neural prosthetic system design</article-title>. <source>Prog Brain Res</source>. <year>2011</year>; <volume>192</volume>: <fpage>33</fpage>–<lpage>58</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/B978-0-444-53355-5.00003-8" xlink:type="simple">10.1016/B978-0-444-53355-5.00003-8</ext-link></comment> <object-id pub-id-type="pmid">21763517</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sussillo</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Churchland</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Kaufman</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Shenoy</surname> <given-names>KV</given-names></name>. <article-title>A neural network that finds a naturalistic solution for the production of muscle activity</article-title>. <source>Nat Neurosci</source>. <year>2015</year>; <volume>18</volume>(<issue>7</issue>): <fpage>1025</fpage>–<lpage>1033</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4042" xlink:type="simple">10.1038/nn.4042</ext-link></comment> <object-id pub-id-type="pmid">26075643</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mante</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Sussillo</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Shenoy</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>. <article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title>. <source>Nature</source>. <year>2013</year>; <volume>503</volume>(<issue>7474</issue>): <fpage>78</fpage>–<lpage>84</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature12742" xlink:type="simple">10.1038/nature12742</ext-link></comment> <object-id pub-id-type="pmid">24201281</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carnevale</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>de Lafuente</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Barak</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Parga</surname> <given-names>N</given-names></name>. <article-title>Dynamic Control of Response Criterion in Premotor Cortex during Perceptual Detection under Temporal Uncertainty</article-title>. <source>Neuron</source>. <year>2015</year>; <volume>86</volume>(<issue>4</issue>): <fpage>1067</fpage>–<lpage>1077</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.04.014" xlink:type="simple">10.1016/j.neuron.2015.04.014</ext-link></comment> <object-id pub-id-type="pmid">25959731</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>, <name name-style="western"><surname>DePasquale</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Memmesheimer</surname> <given-names>RM</given-names></name>. <article-title>Building functional networks of spiking model neurons</article-title>. <source>Nat Neurosci</source>. <year>2016</year>; <volume>19</volume>(<issue>3</issue>): <fpage>350</fpage>–<lpage>355</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4241" xlink:type="simple">10.1038/nn.4241</ext-link></comment> <object-id pub-id-type="pmid">26906501</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hoerzer</surname> <given-names>GM</given-names></name>, <name name-style="western"><surname>Legenstein</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>. <article-title>Emergence of complex computational structures from chaotic neural networks through reward-modulated Hebbian learning</article-title>. <source>Cereb Cortex</source>. <year>2014</year>; <volume>24</volume>(<issue>3</issue>): <fpage>677</fpage>–<lpage>690</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhs348" xlink:type="simple">10.1093/cercor/bhs348</ext-link></comment> <object-id pub-id-type="pmid">23146969</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baldwin</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Andersson</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Saffran</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Meyer</surname> <given-names>M</given-names></name>. <article-title>Segmenting dynamic human action via statistical structure</article-title>. <source>Cognition</source>. <year>2008</year>; <volume>106</volume>(<issue>3</issue>): <fpage>1382</fpage>–<lpage>1407</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cognition.2007.07.005" xlink:type="simple">10.1016/j.cognition.2007.07.005</ext-link></comment> <object-id pub-id-type="pmid">18035346</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zacks</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Kurby</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Eisenberg</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Haroutunian</surname> <given-names>N</given-names></name>. <article-title>Prediction error associated with the perceptual segmentation of naturalistic events</article-title>. <source>J Cogn Neurosci</source>. <year>2011</year>; <volume>23</volume>(<issue>12</issue>): <fpage>4057</fpage>–<lpage>4066</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn_a_00078" xlink:type="simple">10.1162/jocn_a_00078</ext-link></comment> <object-id pub-id-type="pmid">21671745</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saffran</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Aslin</surname> <given-names>RN</given-names></name>, <name name-style="western"><surname>Newport</surname> <given-names>EL</given-names></name>. <article-title>Statistical learning by 8-month-old infants</article-title>. <source>Science</source>. <year>1996</year>; <volume>274</volume>(<issue>5294</issue>): <fpage>1926</fpage>–<lpage>1928</lpage>. <object-id pub-id-type="pmid">8943209</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Toyoizumi</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>. <article-title>Beyond the edge of chaos: amplification and temporal integration by recurrent networks in the chaotic regime</article-title>. <source>Phys Rev E</source>. <year>2011</year>; <volume>84</volume>(<issue>5 Pt 1</issue>): <fpage>051908</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevE.84.051908" xlink:type="simple">10.1103/PhysRevE.84.051908</ext-link></comment> <object-id pub-id-type="pmid">22181445</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rivkind</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Barak</surname> <given-names>O</given-names></name>. <article-title>Local dynamics in trained recurrent neural networks</article-title>. <source>Phys Rev Lett</source>. <year>2017</year>; <volume>118</volume>: <fpage>258101</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevLett.118.258101" xlink:type="simple">10.1103/PhysRevLett.118.258101</ext-link></comment> <object-id pub-id-type="pmid">28696758</object-id></mixed-citation></ref>
<ref id="pcbi.1006400.ref047"><label>47</label><mixed-citation publication-type="other" xlink:type="simple">Goodfellow IJ, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courville A, Bengio Y. Generative Adversarial Networks. arXiv:1406.2661v1 [stat.ML]. 2014.</mixed-citation></ref>
<ref id="pcbi.1006400.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graybiel</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Grafton</surname> <given-names>ST</given-names></name>. <article-title>The striatum: where skills and habits meet</article-title>. <source>Cold Spring Harb Perspect Biol</source>. <year>2015</year>; <volume>7</volume>(<issue>8</issue>): <fpage>a021691</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/cshperspect.a021691" xlink:type="simple">10.1101/cshperspect.a021691</ext-link></comment> <object-id pub-id-type="pmid">26238359</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barnes</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Kubota</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Jin</surname> <given-names>DZ</given-names></name>, <name name-style="western"><surname>Graybiel</surname> <given-names>AM</given-names></name>. <article-title>Activity of striatal neurons reflects dynamic encoding and recoding of procedural memories</article-title>. <source>Nature</source>. <year>2005</year>; <volume>437</volume>(<issue>7062</issue>): <fpage>1158</fpage>–<lpage>1161</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature04053" xlink:type="simple">10.1038/nature04053</ext-link></comment> <object-id pub-id-type="pmid">16237445</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bor</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Duncan</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wiseman</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Owen</surname> <given-names>AM</given-names></name>. <article-title>Encoding strategies dissociate prefrontal activity from working memory demand</article-title>. <source>Neuron</source>. <year>2003</year>; <volume>37</volume>(<issue>2</issue>): <fpage>361</fpage>–<lpage>367</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0896-6273(02)01171-6" xlink:type="simple">https://doi.org/10.1016/S0896-6273(02)01171-6</ext-link>. <object-id pub-id-type="pmid">12546829</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006400.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zacks</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Braver</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Sheridan</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Donaldson</surname> <given-names>DI</given-names></name>, <name name-style="western"><surname>Snyder</surname> <given-names>AZ</given-names></name>, <name name-style="western"><surname>Ollinger</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Buckner</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Raichle</surname> <given-names>ME</given-names></name>. <article-title>Human brain activity time-locked to perceptual event boundaries</article-title>. <source>Nat Neurosci</source>. <year>2001</year>; <volume>18</volume>(<issue>5</issue>): <fpage>449</fpage>–<lpage>455</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1467-9280.2007.01920.x" xlink:type="simple">10.1111/j.1467-9280.2007.01920.x</ext-link></comment> <object-id pub-id-type="pmid">17576286</object-id>.</mixed-citation></ref>
</ref-list>
</back>
</article>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006843</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-01179</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Information technology</subject><subj-group><subject>Data processing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Database and informatics methods</subject><subj-group><subject>Bioinformatics</subject><subj-group><subject>Sequence analysis</subject><subj-group><subject>Sequence alignment</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Mechanical engineering</subject><subj-group><subject>Engines</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Grammar</subject><subj-group><subject>Syntax</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Genome analysis</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Genetics</subject><subj-group><subject>Genomics</subject><subj-group><subject>Genome analysis</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Genetics</subject><subj-group><subject>Gene expression</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Data visualization</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>Script of Scripts: A pragmatic workflow system for daily computational research</article-title>
<alt-title alt-title-type="running-head">Script of Scripts workflow system</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9336-402X</contrib-id>
<name name-style="western">
<surname>Wang</surname>
<given-names>Gao</given-names>
</name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8225-2284</contrib-id>
<name name-style="western">
<surname>Peng</surname>
<given-names>Bo</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Department of Human Genetics, The University of Chicago, Chicago, IL, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Department of Bioinformatics and Computational Biology, The University of Texas MD Anderson Cancer Center, Houston, TX, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Schneidman-Duhovny</surname>
<given-names>Dina</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Hebrew University of Jerusalem, ISRAEL</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">bpeng@mdanderson.org</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>27</day>
<month>2</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<month>2</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>2</issue>
<elocation-id>e1006843</elocation-id>
<history>
<date date-type="received">
<day>6</day>
<month>7</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>29</day>
<month>1</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Wang, Peng</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006843"/>
<abstract>
<p>Computationally intensive disciplines such as computational biology often require use of a variety of tools implemented in different scripting languages and analysis of large data sets using high-performance computing systems. Although scientific workflow systems can powerfully organize and execute large-scale data-analysis processes, creating and maintaining such workflows usually comes with nontrivial learning curves and engineering overhead, making them cumbersome to use for everyday data exploration and prototyping. To bridge the gap between interactive analysis and workflow systems, we developed Script of Scripts (SoS), an interactive data-analysis platform and workflow system with a strong emphasis on readability, practicality, and reproducibility in daily computational research. For exploratory analysis, SoS has a multilanguage scripting format that centralizes otherwise-scattered scripts and creates dynamic reports for publication and sharing. As a workflow engine, SoS provides an intuitive syntax for creating workflows in process-oriented, outcome-oriented, and mixed styles, as well as a unified interface for executing and managing tasks on a variety of computing platforms with automatic synchronization of files among isolated file systems. As illustrated herein by real-world examples, SoS is both an interactive analysis tool and pipeline platform suitable for different stages of method development and data-analysis projects. In particular, SoS can be easily adopted in existing data analysis routines to substantially improve organization, readability, and cross-platform computation management of research projects.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000051</institution-id>
<institution>National Human Genome Research Institute</institution>
</institution-wrap>
</funding-source>
<award-id>R01HG008972</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8225-2284</contrib-id>
<name name-style="western">
<surname>Peng</surname>
<given-names>Bo</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000051</institution-id>
<institution>National Human Genome Research Institute</institution>
</institution-wrap>
</funding-source>
<award-id>1R01HG005859</award-id>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000054</institution-id>
<institution>National Cancer Institute</institution>
</institution-wrap>
</funding-source>
<award-id>CA143883</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9336-402X</contrib-id>
<name name-style="western">
<surname>Wang</surname>
<given-names>Gao</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution>Cancer Prevention and Research Institute of Texas (US)</institution>
</funding-source>
<award-id>RP130397</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9336-402X</contrib-id>
<name name-style="western">
<surname>Wang</surname>
<given-names>Gao</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award005">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000936</institution-id>
<institution>Gordon and Betty Moore Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>4559</award-id>
</award-group>
<award-group id="award006">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000983</institution-id>
<institution>Mary Kay Foundation</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9336-402X</contrib-id>
<name name-style="western">
<surname>Wang</surname>
<given-names>Gao</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award007">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000880</institution-id>
<institution>Michael and Susan Dell Foundation</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9336-402X</contrib-id>
<name name-style="western">
<surname>Wang</surname>
<given-names>Gao</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award008">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000054</institution-id>
<institution>National Cancer Institute</institution>
</institution-wrap>
</funding-source>
<award-id>P30CA016672</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9336-402X</contrib-id>
<name name-style="western">
<surname>Wang</surname>
<given-names>Gao</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported in part by National Human Genome Research Institute grants R01HG008972 and 1R01HG005859, NCI grant CA143883 (to The Cancer Genome Atlas Genome Data Analysis Center at The University of Texas MD Anderson Cancer Center), Cancer Prevention and Research Institute of Texas grant RP130397, the Gordon and Betty Moore Foundation GBMF #4559, the Mary K. Chapman Foundation, the Michael &amp; Susan Dell Foundation (honoring Lorraine Dell), and the NIH/NCI under award number P30CA016672 and used the Bioinformatics Shared Resource. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="3"/>
<table-count count="0"/>
<page-count count="14"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-03-11</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>SoS is hosted at <ext-link ext-link-type="uri" xlink:href="https://github.com/vatlab/SoS" xlink:type="simple">https://github.com/vatlab/SoS</ext-link> and is distributed under a 3-clause BSD license. It can be installed alone as a command line tool or as part of the SoS suite, in which an IDE and notebook interface are provided by SoS Notebook. Both classic Jupyter and JupyterLab are supported although the JupyterLab extension jupyterlab-sos is still evolving with development of JupyterLab. The SoS website (<ext-link ext-link-type="uri" xlink:href="https://vatlab.github.io/sos-docs/" xlink:type="simple">https://vatlab.github.io/sos-docs/</ext-link>) contains documentation, tutorials, examples of SoS, and a video library demonstrating the design and syntaxes of SoS. Although we frequently release new versions of SoS following a “release early, release often” development philosophy, we created and deposited version 0.18.1 of SoS to the Zenodo research data depository (doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.1291523" xlink:type="simple">10.5281/zenodo.1291523</ext-link>) for evaluation with this report. Examples described herein are available in the Publication section of the SoS documentation, as well as at Zenodo (doi:<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2537428" xlink:type="simple">10.5281/zenodo.2537428</ext-link>).</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<p>This is a <italic>PLOS Computational Biology</italic> Software paper.</p>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Computational biologists typically spend a significant portion of their time developing and using scripts written in general purpose scripting languages, such as shell, Python, R, and Ruby [<xref ref-type="bibr" rid="pcbi.1006843.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1006843.ref004">4</xref>]. For reasons such as researchers’ inadequacy of software development skills, limited time and resources, and difficulties in and lack of need for writing portable and reusable scripts for individual projects, scripts written for daily computational research are often inadequately engineered, tested, and documented [<xref ref-type="bibr" rid="pcbi.1006843.ref004">4</xref>]. This makes it difficult for third parties, sometimes even the scripts authors, to understand and reuse scripts to reproduce prior analysis, port to different platforms, or apply to new projects.</p>
<p>To make scripts better suited for reproducible research, theories and implementations of scientific workflow systems [<xref ref-type="bibr" rid="pcbi.1006843.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1006843.ref005">5</xref>] have been introduced for script management and execution, creating what are referred to as “pipeline languages” or “pipeline tools.” Numerous pipeline tools have been developed to date [<xref ref-type="bibr" rid="pcbi.1006843.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1006843.ref007">7</xref>]. Most of them have rigorous interfaces and syntaxes for specification of computational tasks. They may require users to work with graphical interfaces [<xref ref-type="bibr" rid="pcbi.1006843.ref008">8</xref>], describe details of workflow steps and logics using a configuration system [<xref ref-type="bibr" rid="pcbi.1006843.ref009">9</xref>], define workflow steps as functions or classes in other scripting languages [<xref ref-type="bibr" rid="pcbi.1006843.ref010">10</xref>], or learn a new language [<xref ref-type="bibr" rid="pcbi.1006843.ref011">11</xref>–<xref ref-type="bibr" rid="pcbi.1006843.ref013">13</xref>]. Inevitably, re-factoring codes for these pipeline platforms results in notably different implementations of their non-pipeline counterparts. At an early stage of a project that involves switching between interactive analysis environments, maintenance, and synchronization of variations of the same code require a great deal of effort. Even at a late research stage, when scripts are ready to be “pipelined,” researchers may have difficulty adapting data analysis logics to comply with those of the workflow system (e.g., enforce filename patterns to connect steps of workflows) [<xref ref-type="bibr" rid="pcbi.1006843.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006843.ref015">15</xref>]. Therefore, some authors argue that “pipelineitis is a nasty disease” [<xref ref-type="bibr" rid="pcbi.1006843.ref016">16</xref>]. In their view, overuse of pipelines, particularly in the early stages of projects, decreases productivity, as researchers are forced to redirect their focus from scientific problems to engineering details.</p>
<p>Several authors have envisioned workflow systems suitable for daily computational research. Spjuth <italic>et</italic>. <italic>al</italic>. [<xref ref-type="bibr" rid="pcbi.1006843.ref017">17</xref>] categorized workflow systems into those designed for routine processing versus those for <italic>ad hoc</italic> data exploration. Whereas the former should be made easy to workflow end users to use, at the cost of careful design and engineering on the developers’ end, the latter should be made easy to developers themselves, working under a framework that is “simple, lightweight, easy to install and integrate with bash and scripting languages.” Atkinson <italic>et</italic>. <italic>al</italic>. [<xref ref-type="bibr" rid="pcbi.1006843.ref018">18</xref>] argued that workflow system designs should consider researchers who have less experience in software engineering and be tailored for domain experts. In both reports, the authors called for the paramount importance to bridge the gap between interactive and batch data analysis [<xref ref-type="bibr" rid="pcbi.1006843.ref002">2</xref>], an aspect explored by only a few systems, such as YesWorkflow and NoWorkflow [<xref ref-type="bibr" rid="pcbi.1006843.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1006843.ref020">20</xref>], which capture workflow structure and provenance of existing scripts, but have yet to offer workflow execution features.</p>
<p>Motivated by the limitations of current systems for <italic>ad hoc</italic> data exploration, we developed Script of Scripts (SoS), a cross-platform, multilanguage scripting and workflow system designed for daily computational research. SoS features a plain-text file format for multilanguage scripting and workflow execution. It also has an optional Jupyter-based Integrated Development Environment (IDE) [<xref ref-type="bibr" rid="pcbi.1006843.ref021">21</xref>] that provides a notebook format that allows for the inclusion of scientific narratives, workflow descriptions, sample input and output, along with the embedded workflows. SoS empowers daily research applications, ranging from neatly consolidating fragments of scripts into a single executable source file for executing sophisticated workflows that harness the power of multiple remote computing environments, while keeping the entire process of script development, interactive data analysis, batch data processing, and reporting and sharing of results in a local environment familiar to users. In contrast with other workflow tools, SoS enhances existing scripts with workflow functionalities, while requiring little to no modification of the scripts themselves.</p>
<p>Herein we introduce SoS syntax and design, with an emphasis on exploratory analysis and prototyping features. We then describe SoS functionalities as a conventional workflow system, focusing on benefits of multiple workflow specification styles. Next, we describe the cross-platform execution and task management mechanism. Finally, we apply SoS to several well-established problems in machine learning and genomics to demonstrate how daily research tasks can be streamlined, integrated, and documented in SoS.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Design and implementation</title>
<sec id="sec003">
<title>SoS as a script organization tool</title>
<p>Suppose data analysis can be or has been performed with a number of scripts, the scripts can be organized into one SoS script and executed by SoS. The simplest SoS scripts are merely verbatim copies of existing scripts, each with an extra word indicating the language of the script (<xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1A</xref>). The scripts form a single-step workflow that can be executed in the order in which they are included. Optionally, “headers” can be added to code sections to separate them into steps of one or more workflows. Numerically ordered sections in SoS scripts can be executed sequentially as steps of a single workflow (<xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1B</xref>), whereas sections with different names can be executed separately as individual workflows (<xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1C</xref>).</p>
<fig id="pcbi.1006843.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006843.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Incremental SoS scripting.</title>
<p>(A) An SoS script integrating a Python script that converts a Microsoft Excel file to a CSV file, and an R script that plots data from the CSV file. (B) An SoS script with headers for executing two scripts as separate steps of a workflow. The section headers are numbered with optional descriptions. (C) An SoS script with headers for executing two scripts as separate workflows. (D) An SoS script that uses a global parameter and string interpolation to unify filenames. (E) An SoS script that accepts a parameter from the command line and defines input and output targets for each step. (F) An SoS script with input and output targets derived from a global parameter. SoS provides a list of format options to aid in the formatting of filenames (e.g., ‘:n’ in this example removes extensions from filenames).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006843.g001" xlink:type="simple"/>
</fig>
<p>If a workflow must be rerun with different options or applied to different sets of data, the scripts can be generalized to use templates, which are expanded with workflow variables using Python-formatted string literals (<xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1D–1F</xref>). Workflow variables can be defined as parameters that accept values from the command line (<xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1E and 1F</xref>). With the input and output of steps defined at the step level, input and output files can be accessed in the scripts as the variables “_input” and “_output” (<xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1E and 1F</xref>). The use of SoS variables to share and pass on information, as well as the use of SoS parameters as universal lightweight argument parsers for scripts in any language, represent an easy method of consolidating scripts in different languages, while abstracting common information at the workflow level. To facilitate sharing of filenames across scripting languages, SoS implements a series of format options to render filenames in different formats (e.g., file paths, basenames, extensions, quotes for special characters) (<xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1F</xref>).</p>
<p>With the option of adding comments before sections and parameter definitions, SoS enables researchers to consolidate analytic steps scattered in multiple scripts into a single, well-documented SoS script. The script can be executed using a command console. It has a proper help message (comments in the script accessed by typing command option “-h”) that summarizes available subcommands (workflow names) and parameters; it can be used to reproduce the entire data analysis or selected workflows, or it can be applied to new batches of data with different parameter settings. Even without any advanced workflow features, the ability to organize multiple scripts into a single, executable SoS script simplifies the execution of multistep, multilanguage data analysis, improving documentation, version control, and project sharing.</p>
</sec>
<sec id="sec004">
<title>Basic syntaxes of SoS workflows</title>
<p>With increasing data size and/or analysis complexity, “pipelinizing” a workflow for more efficient and robust executions becomes more relevant. As with many pipeline tools, rigorous workflows in SoS are characterized by steps connected with static or dynamic <bold>input</bold> and <bold>output</bold> or by target dependencies in which one step <bold>provides</bold> some targets that another step <bold>depends</bold> on. All words above in bold font are SoS keywords or options that are necessary to define complex workflows, e.g., <xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1E and 1F</xref>.</p>
<p>More formally, SoS extends from Python 3.6 and allows for the use of arbitrary Python statements and modules inside an SoS workflow. An SoS script is just a Python script separated into multiple sections and interpreted by SoS. The script blocks with headers shown in <xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1</xref> are Python function calls written in a special script format so that the first parameter (the multiline script) can be easily specified, with or without string interpolation (option expand). Indentation of included scripts is optional, but recommended for clarity. An SoS section has a header and a body consisting of SoS directives to specify step input, output, dependent targets (if applicable), and arbitrary Python statements. The section header specifies names of and options for SoS steps and, together with the input, output, and dependent targets, determines how a workflow should be created from the sections.</p>
<p>The script format of function calls, section header, parameter, input, output, depends, and task (to be discussed later) statements constitute all the syntaxes that SoS adds to Python 3.6+. These statements accept options in Python syntax and control how SoS workflows and steps are executed. For example, an SoS step is usually executed once with variable _input representing all input files of the step (<xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1</xref>). However, with input option group_by = 1, SoS divides the input files into groups of size 1 and executes the step statements (called substeps) multiple times with _input presenting each of these input groups. SoS provides multiple ways to specify input sources (e.g. from outputs of upstream steps) and to group input files, and by default executes substeps in parallel.</p>
</sec>
<sec id="sec005">
<title>Multistyle workflow system</title>
<p>An SoS workflow is defined as a collection of SoS steps that are connected to form a Directed Acyclic Graph (DAG). Distinct from other pipeline tools, SoS has a multistyle design to provide more than one way to construct a workflow.</p>
<p>The most intuitive SoS workflow style is the process-oriented style, as used with some other pipeline tools [<xref ref-type="bibr" rid="pcbi.1006843.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006843.ref022">22</xref>]. In its simplest form, this style sequentially executes a series of numerically ordered steps (<xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1</xref>, with two single-step workflows defined in <xref ref-type="fig" rid="pcbi.1006843.g001">Fig 1C</xref>). The step numbers do not have to be consecutive, allowing steps to be added later, if needed. Although such a workflow, by default, has a DAG with a single linear execution path, users can break the default dependencies and introduce new dependencies (edges of DAGs) by defining input, output, and dependent targets in each step. These dependent targets can be files, other SoS steps (function sos_step), outputs from upstream steps (functions output_from and named_output), software libraries, or available system resources. SoS creates a DAG from the steps and their dependencies and execute steps with met dependencies in parallel, regardless of the logical orders in which steps are specified. This process-oriented style is most naturally applied to pipelines with dynamic or multiple known outcomes. Furthermore, it is logically intuitive and thus friendly to novice users.</p>
<p>Another workflow style that SoS supports is the outcome-oriented or Makefile style, which relies on implicit wild-card idioms introduced with the Make utility, and adopted by some pipeline tools [<xref ref-type="bibr" rid="pcbi.1006843.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1006843.ref023">23</xref>]. Harnessing the power of wild-card pattern matching, the outcome-oriented style implicitly determines dependencies, and automatically builds and executes DAGs. Triggered by the specification of one or more output files through option -t of the sos run command, outcome-oriented style specification enables the flexibility of generating specific outputs by executing only the required steps and there is not necessarily a complete workflow with a final outcome. By design, it fully parallelizes the workflow engine to schedule and execute jobs. However, the logic in the outcome-oriented style is backward, which is counter-intuitive to some bioinformaticists; the conventional pattern-matched dependency specification can be tricky for steps with no obvious or dynamic outcomes. Therefore, this style is often more challenging to use and extend than process-oriented style [<xref ref-type="bibr" rid="pcbi.1006843.ref014">14</xref>].</p>
<p>The multistyle design of SoS alleviates the dilemma of choosing between process- and outcome-oriented styles. With SoS, researchers have the freedom to build intuitive pipelines in the process-oriented style and, as the workflow grows, convert it to the outcome-oriented style with minimal syntax changes, even though the underlying logics of the two styles are very different. In fact, many SoS users may prefer to work with the third SoS coding style: the mixed style. In this style the trunk of the workflow can be process-oriented, with dependencies in both process-oriented (depends on other steps by step names or named or unnamed outputs) and outcome-oriented (depends on pattern-matched outputs) styles. Alternatively, the trunk of the workflow can be outcome-oriented, with dependencies generated by subworkflows consisting of multiple process-oriented steps (a step depends on another workflow). The proportions of process-oriented versus outcome-oriented steps depend on the needs of specific problems. When properly applied, the mixed style usually resolves logic and syntax dilemmas encountered with the other two styles.</p>
<p><xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2</xref> illustrates applications of the three SoS workflow styles to the same real-world problem, a simulation study elaborated on in the Results section. In this three-step numerical comparison (apart from the “default” section, which serves as a default entry point if multiple workflows are defined in the script), step 2 depends on step 1, and step 3 depends on both step 1 and step 2. As shown in <xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2A</xref>, SoS sequentially executes one step after another, with each step analyzing all data sets in parallel. In <xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2B</xref>, the logic is backward, as indicated by wild-card patterns, and the steps are triggered separately for each data set. In <xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2C</xref>, the first step is “auxiliary” in the sense that it provides data to other steps only as needed; thus, users can focus on developing and expanding the core part of the simulation study (i.e., when the regression methods are executed and evaluated).</p>
<fig id="pcbi.1006843.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006843.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Multistyle SoS workflows.</title>
<p>Shown are abstracted versions of implementations of high-dimensional regression workflows in SoS demonstrating the (A) process-oriented, (B) outcome-oriented, and (C) mixed workflow styles. These workflow style definitions are inspired by Leipzig [<xref ref-type="bibr" rid="pcbi.1006843.ref037">37</xref>], who classified workflow systems as either “explicit convention” (process-oriented) or “implicit convention” (outcome-oriented) frameworks. The workflow logics are primarily reflected by the SoS section names and step statements “input,” “output,” and “depends.” Full versions of these workflows are available online [<xref ref-type="bibr" rid="pcbi.1006843.ref028">28</xref>].</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006843.g002" xlink:type="simple"/>
</fig>
<p>In addition to the workflows with DAGs built before execution, as described above, SoS allows for construction and execution of nested workflows within another workflow step (function sos_run in <xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2</xref>). Combined with the ability to execute any Python statement in an SoS step, and thus execute nested workflows conditionally or repeatedly for each substep applied to subsets of input files or with different parameters (<xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2C</xref>), SoS facilitates the creation of complex, dynamic workflows in styles suitable for the complexity of a project. Another improvement of SoS over conventional outcome-oriented workflow styles is that it extends dependency targets beyond files to prerequisites for execution of steps, such as executable commands, installed libraries, and, particularly, another SoS step or workflow. For example, dependencies can be defined by step names, in addition to step output (see the <xref ref-type="sec" rid="sec009">Results</xref> section for an example). From an engineering point of view, this feature addresses the known issue of file-based DAGs being impractical for large applications [<xref ref-type="bibr" rid="pcbi.1006843.ref014">14</xref>]. In practice, it further improves pipeline readability and provides support for dynamic file targets.</p>
<p>SoS builds a DAG from explicit and implicit step dependencies to either execute a specified workflow (process-oriented) or obtain specified targets (outcome-oriented). The DAG can be specified and resolved fully before parallel execution, or with unknown dependencies that can only be verified, created, and resolved during execution. The DAG also can be expanded dynamically with the execution of nested workflows (<xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2C</xref>). SoS uses runtime signatures to track workflow execution (via the content of steps, environments, input, output, and dependent targets) so that successfully completed steps are ignored during the re-execution of the workflow. It also protects output files using process locks during the execution of workflows, and removes partial outputs from failed steps so that output files will only be written by one SoS instance and are saved only after successful completion of the steps. Unlike time stamps [<xref ref-type="bibr" rid="pcbi.1006843.ref015">15</xref>], step signatures in SoS are generated using checksums and are workflow-independent. Therefore, completed steps can be ignored by revised or completely different workflows, as long as the signatures stay the same. Finally, SoS allows for replacement of large intermediate files with their signatures via an operation called zap. In SoS, a “zapped” step is considered complete, unless the actual intermediate files are required in later steps in the workflow.</p>
</sec>
<sec id="sec006">
<title>Cross-platform workflow execution and job management</title>
<p>As research projects advance to stages involving large-scale data analysis consisting of numerous computationally intensive tasks, SoS remains particularly relevant owing to its unique cross-platform task model (<xref ref-type="fig" rid="pcbi.1006843.g003">Fig 3</xref>). Using a YAML-based configuration system that defines properties of all remote computing environments (hosts), SoS can submit tasks in the same workflow to one or multiple isolated hosts, such as high-performance computing clusters running various task queue systems (PBS/MOAB/LFS/Slurm), standalone workstations owned in a laboratory, and virtual machine instances hosted by cloud services. When a task is executed by different remote hosts, SoS translates paths of the task into paths on remote hosts, and optionally synchronizes input as output files as tasks are executed (<xref ref-type="fig" rid="pcbi.1006843.g003">Fig 3</xref>). With proper configuration of all available hosts, which can be done in advance by a system administrator for all users, running cross-platform computations involves simply sending tasks to hosts with appropriate hardware and software resources. SoS provides a series of command utilities to monitor and manage tasks. For example, sos status -q server lists the status of all tasks running on the specified server, and sos kill task_id terminates the execution of a task. These utilities unify job management on different platforms using the same interface on a local machine.</p>
<fig id="pcbi.1006843.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006843.g003</object-id>
<label>Fig 3</label>
<caption>
<title>SoS task model.</title>
<p>This diagram illustrates SoS remote task execution managed on a local machine whose file system is not shared with the remote host. 1) SoS translates the local task to a remote task via file-path mapping. 2) At the same time, SoS transfers files necessary for the computation to the remote host. 3) SoS then uses preconfigured templates to send commands to the remote job-management system to submit jobs, if applicable, or to directly execute jobs on the remote host. 4) Output files are generated at the end of computation on the remote host. 5) Results are automatically transferred back to the local host, thus completing the computational task on the local machine without direct interaction with remote hosts. Of note, different tasks can be sent to multiple remote hosts simultaneously. The local machine only provides the computational resources necessary to manage and monitor these tasks.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006843.g003" xlink:type="simple"/>
</fig>
<p>In cases when data are large and reside on remote hosts, SoS allows the execution of tasks or complete workflows on the remote host without file synchronization. For example, the input of a step can be marked as remote, so that SoS can process files that reside on a remote host, while still copying results to the local host for downstream analysis. Similarly, output files marked as remote will stay on the remote host. When both input and output files are on the remote host, it can be easier to write workflows with respect to remote paths and use option -r host to send the entire workflow to the remote host for execution. This is equivalent to, but much more convenient than copying the workflow to the remote host, logging in to that host, and executing the workflow there. The ability to analyze data remotely using local workflows simplifies the management of projects, especially when the project consists of both local and remote data analysis steps and are recorded in the same notebook.</p>
</sec>
<sec id="sec007">
<title>Container support</title>
<p>Whereas SoS tasks can be executed locally or distributed to multiple remote hosts, the host environment must be properly configured with required software applications. SoS addresses this problem with built-in support for docker and singularity container engines, which isolate applications and their supporting libraries and tools such that the entire tool chain and related resources are encapsulated as a bundle and can be readily executed on different platforms. By simply specifying the image and engine to use as a parameter for the script to be executed, SoS downloads the specified image, mounts appropriate directories, and executes the script inside the container. By substituting local commands and libraries with docker- or singularity-based tools [<xref ref-type="bibr" rid="pcbi.1006843.ref024">24</xref>], an SoS workflow becomes less dependent on the local runtime environment, and therefore enhances reproducibility.</p>
</sec>
</sec>
<sec id="sec008">
<title>Comparison with other workflow systems</title>
<p>Despite vast differences in design goals, SoS remains competitive as a traditional workflow system. A unique feature of SoS is its multistyle design based on a unified dependency building scheme, which allows more flexible workflow specification and execution than uni-style workflow systems. For example, mimicking workflow systems (e.g. Galaxy [<xref ref-type="bibr" rid="pcbi.1006843.ref008">8</xref>]) that connect inputs and outputs of well-defined steps, an SoS workflow can be written as separate steps with named inputs and outputs. Because steps defined in this way can serve as both process- and outcome-oriented steps, such workflows can be used to execute any steps or generate any defined targets, and in both cases DAGs will be built dynamically from relevant steps according to the flow of data. Although such workflows lack the pattern-matching capacity of typical Makefile style workflows, they are easier to design and are especially suitable for composing data flow based workflows.</p>
<p>To evaluate SoS in terms of workflow features with leading bioinformatics workflow systems, we created an online table [<xref ref-type="bibr" rid="pcbi.1006843.ref025">25</xref>] that compares SoS with Snakemake [<xref ref-type="bibr" rid="pcbi.1006843.ref015">15</xref>], Nextflow [<xref ref-type="bibr" rid="pcbi.1006843.ref014">14</xref>], Galaxy [<xref ref-type="bibr" rid="pcbi.1006843.ref008">8</xref>], CWL [<xref ref-type="bibr" rid="pcbi.1006843.ref009">9</xref>] and Bpipe [<xref ref-type="bibr" rid="pcbi.1006843.ref022">22</xref>]. We acknowledge SoS’ lack of support for features such as cloud storage and distributed systems (e.g., Kubernetes), and plan to address this in future releases of SoS. The table provides details for each comparison (e.g., links to documentation), and is updated to reflect new features of workflow systems in comparison, as needed. A snapshot of the table is included with this article as <xref ref-type="supplementary-material" rid="pcbi.1006843.s001">S1 Table</xref>.</p>
<p>Among these workflow systems, comparisons between SoS and CWL are particularly interesting, because CWL was designed to be a common workflow language that SoS can potentially adopt or support. However, in contrast to CWL workflows, which requires rigorous workflow dependency instructions [<xref ref-type="bibr" rid="pcbi.1006843.ref026">26</xref>], SoS workflows are designed to be easy to read, write, and update, with a minimal amount of workflow instructions and a smooth learning curve. The workflow execution engine of SoS is designed for succinctness and flexibility, sometimes at a cost of performance (e.g. steps with unspecified input and output have to be executed sequentially). It is therefore unlikely for the SoS engine to become a favorable executor for CWL workflows compared to existing solutions.</p>
</sec>
<sec id="sec009" sec-type="results">
<title>Results</title>
<sec id="sec010">
<title>Multistyle workflow demonstration</title>
<p>We previously demonstrated the multistyle SoS workflow design with a published computational experiment of high-dimensional regression [<xref ref-type="bibr" rid="pcbi.1006843.ref027">27</xref>]. The experiment simulates labeled data sets, builds regression models, and evaluates prediction errors for Lasso and ridge regression, as outlined in <xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2</xref> and detailed online with links to full scripts and commands [<xref ref-type="bibr" rid="pcbi.1006843.ref028">28</xref>].</p>
<p><xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2A</xref> illustrates the process-oriented style. The default order of execution is set by the numeric order of step indices (“_1”, “_2”, “_3”). The first section, as its name “lasso_1, ridge_1” suggests, is shared step of both Lasso and ridge regression pipelines. The core algorithms “lasso_2” (and “ridge_2,” [<xref ref-type="bibr" rid="pcbi.1006843.ref028">28</xref>]), coded in different sections, use output of the first section in groups of two for training and testing data, and produce two files for parameter estimation and prediction. Outputs from first two steps both flow into “lasso_3, ridge_3,” another shared step, for performance evaluation. Dependency on both its upstream steps is explicitly configured by named inputs and outputs (function output_from), overriding the default dependency on its immediate upstream step when evaluated by the ordering of step indices. Of note, simultaneous execution of “lasso” and “ridge” have to be explicitly specified (by using one sos_run call) because dependency between the two subworkflows is ambiguous otherwise. <xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2B</xref> illustrates the outcome-oriented style. Expected results are specified at the beginning of the script. The “default” step requires these results, which, through wild-card pattern matching, leads to the “evaluation” step, which depends on Lasso and ridge regression [<xref ref-type="bibr" rid="pcbi.1006843.ref028">28</xref>], and finally leads to execution of the “simulation” step to generate the required data set. Unlike that for process-oriented workflow style, the backward logic herein fully specifies dependencies implicitly, and is by default parallelized to execute both regression methods.</p>
<p><xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2C</xref> illustrates the mixed workflow style. It balances clarity of logic and simplicity of implementation of the computational experiment. Given the “simulation” step, or any step capable of providing training and testing data sets, this workflow is simplified to “model fitting” and “evaluation” of Lasso and ridge regression [<xref ref-type="bibr" rid="pcbi.1006843.ref028">28</xref>]. These steps are implemented in a process-oriented style, whose data dependency, similar to the outcome-oriented style, is specified by the wild-card pattern matching the “simulate” step. This style is likely more suited for this study than the other two styles, because it encourages researchers to separate data and methods in a way that the core analysis can be applied to a number of data inputs of interest.</p>
<p>Additionally, we demonstrate online an example “Outcome Oriented Step Targets,” a revision of <xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2B</xref> that uses step dependencies; and an example “Mixed Style Data Flow”, a revision of <xref ref-type="fig" rid="pcbi.1006843.g002">Fig 2C</xref> that uses named outputs dependencies [<xref ref-type="bibr" rid="pcbi.1006843.ref028">28</xref>]. Although the execution logic remains unchanged, these alternative implementations are possibly more intuitive compared to using wild-card idiom for the problem. We also provide online a modular version of this application, which keeps regression methods implementation in separate files and execute them from both process- and outcome-oriented workflows.</p>
</sec>
<sec id="sec011">
<title>Migrating to SoS</title>
<p>To demonstrate migration of existing projects to SoS, we reimplemented three published bioinformatics workflows. The first workflow combines interactive analysis of differential expression, originally published as a Bioconductor tutorial but without the RNA-seq alignment workflow that we included here. The second workflow adapts a normalization and expression residual analysis pipeline for the Genotype-Tissue Expression project [<xref ref-type="bibr" rid="pcbi.1006843.ref029">29</xref>], originally written in the WDL workflow description language at the Broad institute [<xref ref-type="bibr" rid="pcbi.1006843.ref030">30</xref>]. The third workflow implements a published samtools whole genome sequencing variant calling pipeline using container tools. We demonstrate with these examples that migration to SoS requires minimal extra coding and that the codes are better organized and documented, once they are ported to SoS.</p>
</sec>
<sec id="sec012">
<title>RNA-seq alignment and differential expression analysis</title>
<p>The Bioconductor software project provides R libraries capable of handling aligned sequence data when performing differential expression analysis, as shown in the Bioconductor tutorial. However, external software packages and data must be used to perform the alignment to generate BAM files from FASTQ files [<xref ref-type="bibr" rid="pcbi.1006843.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1006843.ref032">32</xref>]. Instead of using separate fragmented scripts, our SoS implementation of the alignment pipeline is coded inside the interactive analysis notebook for differential expression analysis, which downloads all required data in SRA format from the Gene Expression Omnibus, decrypts them in FASTQ format, performs read alignment, and outputs BAM files. This alignment pipeline uses dockerized tools to guarantee reproducibility. It further benefits from the use of the Jupyter IDE to embed multipage Portable Document Format figures in interactive analysis (which precludes rendering of low-quality bitmap images for tutorial presentation in addition to high-quality vector graphics for publication), and to automatically provide an HTML-based report focusing on narratives and analysis results.</p>
</sec>
<sec id="sec013">
<title>RNA-seq normalization and expression residual analysis</title>
<p>This is an example of a data-preprocessing pipeline for the Genotype-Tissue Expression project, developed by the project’s analysis group [<xref ref-type="bibr" rid="pcbi.1006843.ref033">33</xref>]. Several pipelines available from this group generate gene expression count data and perform various types of preprocessing of expression and genotype data, followed by expression quantitative trait loci association mapping. Because raw RNA-seq data and genotypes are not publicly available, we focus on migrating the preprocessing pipeline to demonstrate cross-platform analysis of large data sets [<xref ref-type="bibr" rid="pcbi.1006843.ref034">34</xref>]. The original pipeline is written in WDL, which executes Python, R, and shell scripts, accompanied by separate text file documentation. We port this pipeline to SoS with few changes to the workhorse scripts, creating a single file containing all of the codes, documentation, and configurations for execution on remote machines with the following computational requirements: the normalization step requires more than 60 GB of memory, and the expression residual analysis [<xref ref-type="bibr" rid="pcbi.1006843.ref035">35</xref>] requires submitting 53 CPU-intensive batch jobs. In the SoS implementation, we use dedicated Markdown sections to emphasize computational challenges. Furthermore, with two lines of configuration (as options for the task statement), memory- and CPU-intensive jobs are sent to separate remote computers, with output automatically synchronized. The workflow is written in Jupyter IDE, which can be executed interactively or by using a command console, with an HTML report exported for circulation.</p>
</sec>
<sec id="sec014">
<title>Whole-genome sequencing mapping and variant calling pipeline</title>
<p>We migrated the samtools variant calling tutorial [<xref ref-type="bibr" rid="pcbi.1006843.ref036">36</xref>] to SoS workflow. All workflow steps are executed by containers we have prepared and made publicly available. Additionally, this notebook contains information on software setup instructions, steps to prepare reference genome and variants data, and examples to review intermediate output files and visualize diagnostic plots, demonstrating seamless integration of workflow steps and possible interactive exploration of step output under a unified framework.</p>
</sec>
</sec>
<sec id="sec015" sec-type="conclusions">
<title>Discussion</title>
<p>Development of SoS was driven by the need for a workflow system that can be easily used for daily computational research. It is designed to 1) have a smooth learning curve, so that users with little experience with workflow systems can immediately use and benefit from it; 2) be readable, for ease of understanding and revising embedded scripts by researchers who are not familiar with SoS; 3) fit more naturally into how users already structure their analysis; and 4) allow easy access to all available computing resources with minimal extra work. Perhaps most importantly, with the assistance of the SoS Notebook and related utilities, SoS provides an integrated Jupyter-based data analysis environment that encompasses the entire spectrum of data analysis from script development, interactive data analysis, and visualization, to batch data processing and report generation. This effectively narrows the gap between interactive data analysis and batch data processing, and has the potential to become an indispensable tool for daily computational research.</p>
<p>We recommend and develop SoS to facilitate the verbatim inclusion of short scripts in different languages in an SoS workflow. This makes the workflow easy to read, modify, share, and reproduce. Longer scripts, especially those that are designed to be reused by multiple projects, can be saved outside of the workflow and executed by appropriate shell commands (e.g.,. use sh(‘Rscript preprocess.R’) instead of applying action R on the content of the script in SoS). However, the development of such external scripts can easily break the reproducibility of completed projects, so extra attention should be paid to version control the scripts. For scripts that are also useful to others, it is highly recommended that they be properly implemented, tested, documented, and be used in SoS as modules or libraries with stable programming interfaces. These scripts should also be versioned and made publicly available (e.g., deposited to pypi for Python modules, CRAN for R libraries, and npm for JavaScript modules) to make it easy to reproduce the workflows that depend on them.</p>
<p>SoS facilitates the reproducibility of bioinformatic data analysis in many ways. For the organization of data analysis, SoS helps consolidate multiple scripts into fewer SoS scripts, each with clear interfaces, and with a unified version control history for its components. For documentation, SoS generates a command-line interface with narratives of workflows and steps from the script, which facilitates keeping documentation consistent with source code. For report generation, SoS provides related functions, such as report, Rmarkdown, and pandoc to create dynamic documents that intermingle codes directly within scientific narratives in a multilanguage scripting environment. For encapsulation of the runtime environment, SoS allows for the use of containers for all scripts in the workflow. Although not the focus of this report, SoS workflows can be embedded into SoS notebooks, which can contain dynamic tables and figures, previews of output of data analysis, and Jupyter magics, such as %revisions and %sessioninfo to keep track of revisions of notebooks, session information for interpreters, and versions of libraries loaded in interactive sessions.</p>
<p>In conclusion, SoS is a unique workflow tool suitable for interactive data analysis and batch execution of workflows in a unified environment. With a smooth learning curve, SoS can be easily integrated into and used for all stages of computational methodology research and data-analysis projects. We believe that use of SoS in daily computational research can substantially improve the organization, readability, and cross-platform computation management, and thus reproducibility of the research.</p>
</sec>
<sec id="sec016">
<title>Availability and future directions</title>
<p>SoS is hosted at <ext-link ext-link-type="uri" xlink:href="https://github.com/vatlab/SoS" xlink:type="simple">https://github.com/vatlab/SoS</ext-link> and is distributed under a 3-clause BSD license. It can be installed alone as a command line tool or as part of the SoS suite, in which an IDE and notebook interface are provided by SoS Notebook. Both classic Jupyter and JupyterLab are supported although the JupyterLab extension jupyterlab-sos is still evolving with development of JupyterLab. The SoS website (<ext-link ext-link-type="uri" xlink:href="https://vatlab.github.io/sos-docs/" xlink:type="simple">https://vatlab.github.io/sos-docs/</ext-link>) contains documentation, tutorials, examples of SoS, and a video library demonstrating the design and syntaxes of SoS. Although we frequently release new versions of SoS following a “release early, release often” development philosophy, we created and deposited version 0.18.1 of SoS to the Zenodo research data depository (doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.1291523" xlink:type="simple">10.5281/zenodo.1291523</ext-link>) for evaluation with this report. Examples described herein are available in the Publication section of the SoS documentation, as well as at Zenodo (doi:<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2537428" xlink:type="simple">10.5281/zenodo.2537428</ext-link>).</p>
</sec>
<sec id="sec017">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006843.s001" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006843.s001" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Comparison of SoS with other workflow management systems.</title>
<p>The table compare SoS with several popular bioinformatics workflow systems including Nextflow, Snakemake, Bpipe, CWL, and Galaxy, in three broad aspects: 1) basic features (syntax, file format, user interface, etc), 2) workflow features (workflow specification, dependency handling, execution and monitoring, etc), and built-in support for external tools and services (container support, HPC systems, distributed systems and cloud support). It is a snapshot of an interactive table online at <ext-link ext-link-type="uri" xlink:href="https://vatlab.github.io/blog/post/comparison" xlink:type="simple">https://vatlab.github.io/blog/post/comparison</ext-link> where comments and potential contributions from the community can be continuously incorporated through github issues or pull requests.</p>
<p>(XLSX)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We appreciate feedback and support from members of the Department of Bioinformatics and Computational Biology at MD Anderson, especially Chris Wakefield and James Melott from the programming team. We thank Dr. Matthew Stephens at The University of Chicago for helpful discussions and support. Some tests of SoS were performed using high-performance computing clusters at MD Anderson and The University of Chicago Research Computing Center.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006843.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ekmekci</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>McAnany</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Mura</surname> <given-names>C</given-names></name>. <article-title>An Introduction to Programming for Bioscientists: A Python-Based Primer</article-title>. <source>PLoS Comput Biol</source>. <year>2016</year>;<volume>12</volume>(<issue>6</issue>):<fpage>e1004867</fpage>. Epub 2016/06/09. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004867" xlink:type="simple">10.1371/journal.pcbi.1004867</ext-link></comment> <object-id pub-id-type="pmid">27271528</object-id>; PubMed Central PMCID: PMCPMC4896647.</mixed-citation></ref>
<ref id="pcbi.1006843.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen-Boulakia</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Belhajjame</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Collin</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Chopard</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Froidevaux</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Gaignard</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Scientific workflows for computational reproducibility in the life sciences: Status, challenges and opportunities</article-title>. <source>Future Gener Comp Sy</source>. <year>2017</year>;<volume>75</volume>:<fpage>284</fpage>–<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.future.2017.01.012" xlink:type="simple">10.1016/j.future.2017.01.012</ext-link></comment> PubMed PMID: WOS:000404704400023.</mixed-citation></ref>
<ref id="pcbi.1006843.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilson</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Aruliah</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>CT</given-names></name>, <name name-style="western"><surname>Chue Hong</surname> <given-names>NP</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Guy</surname> <given-names>RT</given-names></name>, <etal>et al</etal>. <article-title>Best practices for scientific computing</article-title>. <source>PLoS Biol</source>. <year>2014</year>;<volume>12</volume>(<issue>1</issue>):<fpage>e1001745</fpage>. Epub 2014/01/15. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1001745" xlink:type="simple">10.1371/journal.pbio.1001745</ext-link></comment> <object-id pub-id-type="pmid">24415924</object-id>; PubMed Central PMCID: PMCPMC3886731 computing with PLOS Computational Biology.</mixed-citation></ref>
<ref id="pcbi.1006843.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hannay</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Langtangen</surname> <given-names>HP</given-names></name>, <name name-style="western"><surname>MacLeod</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Pfahl</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>G</given-names></name>. <article-title>How Do Scientists Develop and Use Scientific Software?</article-title> <source>2009 Icse Workshop on Software Engineering for Computational Science and Engineering</source>. <year>2009</year>:<fpage>1</fpage>–+. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/Secse.2009.5069155" xlink:type="simple">10.1109/Secse.2009.5069155</ext-link></comment> PubMed PMID: WOS:000271851900001.</mixed-citation></ref>
<ref id="pcbi.1006843.ref005"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Zhao Y, Raicu I, Foster I. Scientific Workflow Systems for 21st Century, New Bottle or New Wine? 2008 IEEE Congress on Services—Part I; 20082008.</mixed-citation></ref>
<ref id="pcbi.1006843.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leipzig</surname> <given-names>J</given-names></name>. <article-title>A review of bioinformatic pipeline frameworks</article-title>. <source>Brief Bioinform</source>. <year>2017</year>;<volume>18</volume>(<issue>3</issue>):<fpage>530</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bib/bbw020" xlink:type="simple">10.1093/bib/bbw020</ext-link></comment> <object-id pub-id-type="pmid">27013646</object-id></mixed-citation></ref>
<ref id="pcbi.1006843.ref007"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Crusoe MR. Existing Workflow systems. Available from: <ext-link ext-link-type="uri" xlink:href="https://s.apache.org/existing-workflow-systems" xlink:type="simple">https://s.apache.org/existing-workflow-systems</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006843.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Afgan</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Baker</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>van den Beek</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Blankenberg</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Bouvier</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Čech</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>The Galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2016 update</article-title>. <source>Nucleic Acids Res</source>. <year>2016</year>;<volume>44</volume>(<issue>W1</issue>):<fpage>W3</fpage>–<lpage>W10</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkw343" xlink:type="simple">10.1093/nar/gkw343</ext-link></comment> <object-id pub-id-type="pmid">27137889</object-id></mixed-citation></ref>
<ref id="pcbi.1006843.ref009"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Amstutz P, Crusoe MR, Tijanić N, Chapman B, Chilton J, Heuer M, et al. Common Workflow Language, v1.0. Specification, Common Workflow Language working group. 2016.</mixed-citation></ref>
<ref id="pcbi.1006843.ref010"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">spotify. Luigi. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/spotify/luigi" xlink:type="simple">https://github.com/spotify/luigi</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006843.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cingolani</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Sladek</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Blanchette</surname> <given-names>M</given-names></name>. <article-title>BigDataScript: a scripting language for data pipelines</article-title>. <source>Bioinformatics</source>. <year>2015</year>;<volume>31</volume>(<issue>1</issue>):<fpage>10</fpage>–<lpage>6</lpage>. Epub 2014/09/06. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btu595" xlink:type="simple">10.1093/bioinformatics/btu595</ext-link></comment> <object-id pub-id-type="pmid">25189778</object-id>; PubMed Central PMCID: PMCPMC4271142.</mixed-citation></ref>
<ref id="pcbi.1006843.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brandt</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Reisig</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Leser</surname> <given-names>U</given-names></name>. <article-title>Computation semantics of the functional scientific workflow language Cuneiform</article-title>. <source>J Funct Program</source>. <year>2017</year>;<volume>27</volume>. doi: ARTN e22 <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1017/S0956796817000119" xlink:type="simple">10.1017/S0956796817000119</ext-link></comment> PubMed PMID: WOS:000413544000001.</mixed-citation></ref>
<ref id="pcbi.1006843.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goodstadt</surname> <given-names>L</given-names></name>. <article-title>Ruffus: a lightweight Python library for computational pipelines</article-title>. <source>Bioinformatics</source>. <year>2010</year>;<volume>26</volume>(<issue>21</issue>):<fpage>2778</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btq524" xlink:type="simple">10.1093/bioinformatics/btq524</ext-link></comment> <object-id pub-id-type="pmid">20847218</object-id></mixed-citation></ref>
<ref id="pcbi.1006843.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Di Tommaso</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Chatzou</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Floden</surname> <given-names>EW</given-names></name>, <name name-style="western"><surname>Barja</surname> <given-names>PP</given-names></name>, <name name-style="western"><surname>Palumbo</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Notredame</surname> <given-names>C</given-names></name>. <article-title>Nextflow enables reproducible computational workflows</article-title>. <source>Nat Biotechnol</source>. <year>2017</year>;<volume>35</volume>(<issue>4</issue>):<fpage>316</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nbt.3820" xlink:type="simple">10.1038/nbt.3820</ext-link></comment> PubMed PMID: WOS:000398780600017. <object-id pub-id-type="pmid">28398311</object-id></mixed-citation></ref>
<ref id="pcbi.1006843.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koster</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rahmann</surname> <given-names>S</given-names></name>. <article-title>Snakemake—a scalable bioinformatics workflow engine</article-title>. <source>Bioinformatics</source>. <year>2012</year>;<volume>28</volume>(<issue>19</issue>):<fpage>2520</fpage>–<lpage>2</lpage>. Epub 2012/08/22. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/bts480" xlink:type="simple">10.1093/bioinformatics/bts480</ext-link></comment> <object-id pub-id-type="pmid">22908215</object-id>.</mixed-citation></ref>
<ref id="pcbi.1006843.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Loman</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Watson</surname> <given-names>M</given-names></name>. <article-title>So you want to be a computational biologist?</article-title> <source>Nat Biotechnol</source>. <year>2013</year>;<volume>31</volume>(<issue>11</issue>):<fpage>996</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nbt.2740" xlink:type="simple">10.1038/nbt.2740</ext-link></comment> <object-id pub-id-type="pmid">24213777</object-id></mixed-citation></ref>
<ref id="pcbi.1006843.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Spjuth</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Bongcam-Rudloff</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Hernandez</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Forer</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Giovacchini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Guimera</surname> <given-names>RV</given-names></name>, <etal>et al</etal>. <article-title>Experiences with workflows for automating data-intensive bioinformatics</article-title>. <source>Biol Direct</source>. <year>2015</year>;<volume>10</volume>. doi: ARTN 43 <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s13062-015-0071-8" xlink:type="simple">10.1186/s13062-015-0071-8</ext-link></comment> PubMed PMID: WOS:000359518000001. <object-id pub-id-type="pmid">26282399</object-id></mixed-citation></ref>
<ref id="pcbi.1006843.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atkinson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gesing</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Montagnat</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>I</given-names></name>. <article-title>Scientific workflows: Past, present and future</article-title>. <source>Future Gener Comp Sy</source>. <year>2017</year>;<volume>75</volume>:<fpage>216</fpage>–<lpage>27</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.future.2017.05.041" xlink:type="simple">10.1016/j.future.2017.05.041</ext-link></comment> PubMed PMID: WOS:000404704400018.</mixed-citation></ref>
<ref id="pcbi.1006843.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pimentel</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Murta</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Braganholo</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Freire</surname> <given-names>J</given-names></name>. <article-title>noWorkflow: a Tool for Collecting, Analyzing, and Managing Provenance from Python Scripts</article-title>. <source>Proc Vldb Endow</source>. <year>2017</year>;<volume>10</volume>(<issue>12</issue>):<fpage>1841</fpage>–<lpage>4</lpage>. PubMed PMID: WOS:000416494000022.</mixed-citation></ref>
<ref id="pcbi.1006843.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pimentel</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Dey</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>McPhillips</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Belhajjame</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Koop</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Murta</surname> <given-names>L</given-names></name>, <etal>et al</etal>. <article-title>Yin &amp; Yang: Demonstrating Complementary Provenance from noWorkflow &amp; YesWorkflow</article-title>. <source>Lect Notes Comput Sc</source>. <year>2016</year>;<volume>9672</volume>:<fpage>161</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-3-319-40593-3_13" xlink:type="simple">10.1007/978-3-319-40593-3_13</ext-link></comment> PubMed PMID: WOS:000389496000013.</mixed-citation></ref>
<ref id="pcbi.1006843.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peng</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Leong</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>Wakefield</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Melott</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>SoS Notebook: An Interactive Multi-Language Data Analysis Environment</article-title>. <source>bioRxiv</source>. <year>2018</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/274001" xlink:type="simple">10.1101/274001</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006843.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sadedin</surname> <given-names>SP</given-names></name>, <name name-style="western"><surname>Pope</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Oshlack</surname> <given-names>A</given-names></name>. <article-title>Bpipe: a tool for running and managing bioinformatics pipelines</article-title>. <source>Bioinformatics</source>. <year>2012</year>;<volume>28</volume>(<issue>11</issue>):<fpage>1525</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/bts167" xlink:type="simple">10.1093/bioinformatics/bts167</ext-link></comment> <object-id pub-id-type="pmid">22500002</object-id></mixed-citation></ref>
<ref id="pcbi.1006843.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holmes</surname> <given-names>IH</given-names></name>, <name name-style="western"><surname>Mungall</surname> <given-names>CJ</given-names></name>. <article-title>BioMake: a GNU make-compatible utility for declarative workflow management</article-title>. <source>Bioinformatics</source>. <year>2017</year>;<volume>33</volume>(<issue>21</issue>):<fpage>3502</fpage>–<lpage>4</lpage>. Epub 2017/05/10. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btx306" xlink:type="simple">10.1093/bioinformatics/btx306</ext-link></comment> <object-id pub-id-type="pmid">28486579</object-id>; PubMed Central PMCID: PMCPMC5860158.</mixed-citation></ref>
<ref id="pcbi.1006843.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Folarin</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Dobson</surname> <given-names>RJB</given-names></name>, <name name-style="western"><surname>Newhouse</surname> <given-names>SJ</given-names></name>. <article-title>NGSeasy: a next generation sequencing pipeline in Docker containers</article-title>. <source>F1000Res</source>. <year>2015</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.12688/f1000research.7104.1" xlink:type="simple">10.12688/f1000research.7104.1</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006843.ref025"><label>25</label><mixed-citation publication-type="other" xlink:type="simple">Peng B, Wang G. How does SoS compare with other workflow engines 2018. Available from: <ext-link ext-link-type="uri" xlink:href="https://vatlab.github.io/blog/post/comparison/" xlink:type="simple">https://vatlab.github.io/blog/post/comparison/</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006843.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kanwal</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Khan</surname> <given-names>FZ</given-names></name>, <name name-style="western"><surname>Lonie</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sinnott</surname> <given-names>RO</given-names></name>. <article-title>Investigating reproducibility and tracking provenance—A genomic workflow case study</article-title>. <source>BMC Bioinformatics</source>. <year>2017</year>;<volume>18</volume>(<issue>1</issue>):<fpage>337</fpage>. Epub 2017/07/14. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s12859-017-1747-0" xlink:type="simple">10.1186/s12859-017-1747-0</ext-link></comment> <object-id pub-id-type="pmid">28701218</object-id>; PubMed Central PMCID: PMCPMC5508699.</mixed-citation></ref>
<ref id="pcbi.1006843.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zou</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Hastie</surname> <given-names>T</given-names></name>. <article-title>Regularization and variable selection via the elastic net</article-title>. <source>J Roy Stat Soc B</source>. <year>2005</year>;<volume>67</volume>:<fpage>301</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1467-9868.2005.00503.x" xlink:type="simple">10.1111/j.1467-9868.2005.00503.x</ext-link></comment> PubMed PMID: WOS:000227498200007.</mixed-citation></ref>
<ref id="pcbi.1006843.ref028"><label>28</label><mixed-citation publication-type="other" xlink:type="simple">Peng B, Wang G. SoS Documentation. Available from: <ext-link ext-link-type="uri" xlink:href="https://vatlab.github.io/sos-docs/#documentation" xlink:type="simple">https://vatlab.github.io/sos-docs/#documentation</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006843.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Keen</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>HM</given-names></name>. <article-title>The Genotype-Tissue Expression (GTEx) Project: Linking Clinical Data with Molecular Analysis to Advance Personalized Medicine</article-title>. <source>J Pers Med</source>. <year>2015</year>;<volume>5</volume>(<issue>1</issue>):<fpage>22</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3390/jpm5010022" xlink:type="simple">10.3390/jpm5010022</ext-link></comment> <object-id pub-id-type="pmid">25809799</object-id>; PubMed Central PMCID: PMCPMC4384056.</mixed-citation></ref>
<ref id="pcbi.1006843.ref030"><label>30</label><mixed-citation publication-type="other" xlink:type="simple">Voss K, Gentry J, Van dAG. Full-stack genomics pipelining with GATK4 + WDL + Cromwell 2017. Available from: <ext-link ext-link-type="uri" xlink:href="https://f1000research.com/posters/6-1379" xlink:type="simple">https://f1000research.com/posters/6-1379</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006843.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Handsaker</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Wysoker</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Fennell</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ruan</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Homer</surname> <given-names>N</given-names></name>, <etal>et al</etal>. <article-title>The Sequence Alignment/Map format and SAMtools</article-title>. <source>Bioinformatics</source>. <year>2009</year>;<volume>25</volume>(<issue>16</issue>):<fpage>2078</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btp352" xlink:type="simple">10.1093/bioinformatics/btp352</ext-link></comment> <object-id pub-id-type="pmid">19505943</object-id></mixed-citation></ref>
<ref id="pcbi.1006843.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dobin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Schlesinger</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Drenkow</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zaleski</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Jha</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>STAR: ultrafast universal RNA-seq aligner</article-title>. <source>Bioinformatics</source>. <year>2013</year>;<volume>29</volume>(<issue>1</issue>):<fpage>15</fpage>–<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/bts635" xlink:type="simple">10.1093/bioinformatics/bts635</ext-link></comment> <object-id pub-id-type="pmid">23104886</object-id></mixed-citation></ref>
<ref id="pcbi.1006843.ref033"><label>33</label><mixed-citation publication-type="other" xlink:type="simple">Broad Institute. GTEx Consortium data production and analysis pipelines 2017 [cited 2018 Feb 28]. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/broadinstitute/gtex-pipeline" xlink:type="simple">https://github.com/broadinstitute/gtex-pipeline</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006843.ref034"><label>34</label><mixed-citation publication-type="other" xlink:type="simple">GTEx Project Team, GTEx expression and eQTL association data (version 6), Available from: <ext-link ext-link-type="uri" xlink:href="https://gtexportal.org" xlink:type="simple">https://gtexportal.org</ext-link></mixed-citation></ref>
<ref id="pcbi.1006843.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stegle</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Parts</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Piipari</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Winn</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Durbin</surname> <given-names>R</given-names></name>. <article-title>Using probabilistic estimation of expression residuals (PEER) to obtain increased power and interpretability of gene expression analyses</article-title>. <source>Nat Protoc</source>. <year>2012</year>;<volume>7</volume>(<issue>3</issue>):<fpage>500</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nprot.2011.457" xlink:type="simple">10.1038/nprot.2011.457</ext-link></comment> <object-id pub-id-type="pmid">22343431</object-id></mixed-citation></ref>
<ref id="pcbi.1006843.ref036"><label>36</label><mixed-citation publication-type="other" xlink:type="simple">Genome Research Limited. WGS/WES Mapping to Variant Calls—Version 1.0. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.htslib.org/workflow/" xlink:type="simple">http://www.htslib.org/workflow/</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006843.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leipzig</surname> <given-names>J</given-names></name>. <article-title>A review of bioinformatic pipeline frameworks</article-title>. <source>Brief Bioinform</source>. <year>2017</year>;<volume>18</volume>(<issue>3</issue>):<fpage>530</fpage>–<lpage>6</lpage>. Epub 2016/03/26. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bib/bbw020" xlink:type="simple">10.1093/bib/bbw020</ext-link></comment> <object-id pub-id-type="pmid">27013646</object-id>; PubMed Central PMCID: PMCPMC5429012.</mixed-citation></ref>
</ref-list>
</back>
</article>
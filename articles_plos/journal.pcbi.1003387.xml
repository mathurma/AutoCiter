<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-13-00553</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003387</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories>
<title-group>
<article-title>Cortical and Hippocampal Correlates of Deliberation during Model-Based Decisions for Rewards in Humans</article-title>
<alt-title alt-title-type="running-head">Cortico-Hippocampal Correlates of Model-Based RL</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Bornstein</surname><given-names>Aaron M.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref><xref ref-type="fn" rid="fn1"><sup>¤</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Daw</surname><given-names>Nathaniel D.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Department of Psychology, Program in Cognition and Perception, New York University, New York, New York, United States of America</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Center for Neural Science, New York University, New York, New York, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Behrens</surname><given-names>Tim</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Oxford, United Kingdom</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">aaronmb@princeton.edu</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: AMB NDD. Performed the experiments: AMB. Analyzed the data: AMB. Contributed reagents/materials/analysis tools: AMB NDD. Wrote the paper: AMB NDD.</p></fn>
<fn id="fn1" fn-type="current-aff"><label>¤</label><p>Current address: Princeton Neuroscience Institute, Princeton, New Jersey, United States of America.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>12</month><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>5</day><month>12</month><year>2013</year></pub-date>
<volume>9</volume>
<issue>12</issue>
<elocation-id>e1003387</elocation-id>
<history>
<date date-type="received"><day>2</day><month>4</month><year>2013</year></date>
<date date-type="accepted"><day>10</day><month>10</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Bornstein, Daw</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/3.0/" xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/3.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>How do we use our memories of the past to guide decisions we've never had to make before? Although extensive work describes how the brain learns to repeat rewarded actions, decisions can also be influenced by associations between stimuli or events not directly involving reward — such as when planning routes using a cognitive map or chess moves using predicted countermoves — and these sorts of associations are critical when deciding among novel options. This process is known as model-based decision making. While the learning of environmental relations that might support model-based decisions is well studied, and separately this sort of information has been inferred to impact decisions, there is little evidence concerning the full cycle by which such associations are acquired and drive choices. Of particular interest is whether decisions are directly supported by the same mnemonic systems characterized for relational learning more generally, or instead rely on other, specialized representations. Here, building on our previous work, which isolated dual representations underlying sequential predictive learning, we directly demonstrate that one such representation, encoded by the hippocampal memory system and adjacent cortical structures, supports goal-directed decisions. Using interleaved learning and decision tasks, we monitor predictive learning directly and also trace its influence on decisions for reward. We quantitatively compare the learning processes underlying multiple behavioral and fMRI observables using computational model fits. Across both tasks, a quantitatively consistent learning process explains reaction times, choices, and both expectation- and surprise-related neural activity. The same hippocampal and ventral stream regions engaged in anticipating stimuli during learning are also engaged in proportion to the difficulty of decisions. These results support a role for predictive associations learned by the hippocampal memory system to be recalled during choice formation.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>We are always learning regularities in the world around us: where things are, and in what order we might find them. Our knowledge of these contingencies can be relied upon if we later want to use them to make decisions. However, there is little agreement about the neurobiological mechanism by which learned contingencies are deployed for decision making. These are different kinds of decisions than simple habits, in which we take actions that have in the past given us reward. Neural mechanisms of habitual decisions are well-described by computational reinforcement learning approaches, but have not often been applied to ‘model-based’ decisions that depend on learned contingencies. In this article, we apply reinforcement learning to investigate model-based decisions. We tested participants on a serial reaction time task with changing sequential contingencies, and choice probes that depend on these contingencies. Fitting computational models to reaction times, we show that two sets of predictions drive simple response behavior, only one of which is used to make choices. Using fMRI, we observed learning and decision-related activity in hippocampal and ventral cortical areas that is computationally linked to the learned contingencies used to make choices. These results suggest a critical role for a hippocampal-cortical network in model-based decisions for reward.</p>
</abstract>
<funding-group><funding-statement>AMB was supported by National Institute of Mental Health Predoctoral Research Fellowship 1F31MH095501. NDD was supported by a Scholar Award from the McKnight Foundation, an Award in Understanding Human Cognition from the McDonnell Foundation, and National Institute of Neurological Disorders and Stroke R01NS078784. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="19"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Every day, we learn new information that is not immediately relevant to our current goals. We might learn the layout of a new neighborhood, or, while traveling a familiar street, happen upon a restaurant that is about to open. Though we might not receive any rewards — e.g., a friendly neighbor or a great meal — during our initial experience, we still learn our way around. If, later, we decide to seek a particular reward, we are usually quite capable of using the knowledge we gained from such exploration to achieve our goal. This is known as goal-directed or model-based decision making: the construction of plans to achieve rewards, incorporating knowledge about contingencies in the world <xref ref-type="bibr" rid="pcbi.1003387-Dickinson1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Daw1">[3]</xref>. The neural systems that support these forms of decisions are a focus of much ongoing research.</p>
<p>In this study, we provide evidence that the hippocampus and related cortical regions support the contingencies necessary to perform model-based decisions. We show that ongoing learning of the required contingencies can be measured in two kinds of behavior: simple responses and deliberative choices. Further, we show that BOLD signal in the regions of interest scales with multiple computational variables that describe the use of these contingencies to perform action selection.</p>
<sec id="s1a">
<title>Representations in model-based decisions</title>
<p>Model-based decisions stand in contrast to a simpler sort of learned decision making whose neural instantiation is better understood: simply learning to repeat rewarded behaviors <xref ref-type="bibr" rid="pcbi.1003387-Thorndike1">[4]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Schultz1">[6]</xref>. To explain the former, more knowledge-driven path to decisions, researchers have long argued that the brain maintains internal representations of the contingency structure of a task — a “world model” or, in spatial tasks, a “cognitive map” — that can be adaptively applied to drive behavior. Like a map of space, these representations describe the relationships between situations and actions, separate from any ties to reward. The reliance on these representations is a defining characteristic of goal-directed decisions <xref ref-type="bibr" rid="pcbi.1003387-Dickinson1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Dickinson2">[2]</xref>. Therefore, to identify the neural mechanisms of these decisions, researchers must first identify the representations that guide them.</p>
</sec><sec id="s1b">
<title>From learning to action</title>
<p>Here, to examine in detail the process by which contingency representations are learned and inform action choice, we combined a sequential learning task <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref> with an interleaved decision task in which rewards depended on contingencies learned in the first task. In the learning task, participants were presented with one of four photograph images at a time, and asked simply to press the key corresponding to that image. Which of the four images appeared next depended, probabilistically, on the image currently being viewed. The sequential learning task allowed us to measure the gradual, trial-by-trial, acquisition of these probabilistic contingencies linking the four image stimuli. Participants' responses provided two observable measurements of learning: reaction time to identify each image, and image-specific BOLD activity in the ventral stream visual cortex.</p>
<p>Reaction times to identify an image indicated the degree to which subjects expected it, given the previous one — a classic and relatively direct measure of the learned predictive association <xref ref-type="bibr" rid="pcbi.1003387-Bahrick1">[8]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-TurkBrowne1">[12]</xref> — and category-specific BOLD also reflected engagement of the neural representation of each image in anticipation of its presentation <xref ref-type="bibr" rid="pcbi.1003387-TurkBrowne2">[13]</xref>. By fitting computational models to this progression of subject expectations, we extracted a computational signature of the learning process, the <italic>learning rate</italic>, and used it to generate timeseries of decision variables based on these learned contingencies.</p>
<p>This enabled us to quantitatively characterize the influence of these associations when participants were asked, in the interleaved decision probes, to draw on them to make decisions. Specifically, participants were told that one of the four images was, for a short period of time, to be associated with a reward. They were then asked which of two other images would lead to that rewarded image as quickly as possible. This manipulation has a form similar to a latent learning paradigm <xref ref-type="bibr" rid="pcbi.1003387-Tolman1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Glscher1">[15]</xref>, in which contingencies are learned separately from their link to reward. By requiring subjects to use knowledge of the contingencies to guide their decisions, this design allows us to probe how and whether the contingencies are used to seek trial-specific goals — contingencies that are exclusively the realm of model-based decision processes.</p>
<p>Comparing the learning rates fit to behavior and BOLD responses we observed a striking match between hippocampal correlates of sequential learning and the learning underlying the reaction times, choices, prediction errors, and ventral visual stream activity, during both simple identification responses and deliberative decisions for reward. These results suggest that regions involved in sequential learning, including hippocampus and ventral cortical areas, indeed provide the necessary contingency representations to support model-based choice — and, critically, demonstrate the use of particular associations learned by these regions during model-based decision making.</p>
</sec></sec><sec id="s2">
<title>Results</title>
<p>Our task trains participants on probabilistic sequential contingencies linking image stimuli (<xref ref-type="fig" rid="pcbi-1003387-g001">Figure 1</xref>). Then, on probe trials interspersed with the learning, the task offers participants the opportunity to make decisions for rewards, using their estimates of those sequential contingencies to inform their choices (<xref ref-type="fig" rid="pcbi-1003387-g002">Figure 2</xref>). Previously, we showed that two neural processes — associated with the hippocampus and striatum, respectively — develop separate estimates of the contingencies in the learning portion of this task <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>. As the hippocampal system has long been a candidate for learning the relations (e.g., maps or models) supporting flexible choice, our hypothesis is that goal-directed decisions will depend on the contingency estimates learned by the hippocampal system.</p>
<fig id="pcbi-1003387-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003387.g001</object-id><label>Figure 1</label><caption>
<title>Serial reaction time task.</title>
<p>Images were presented one at a time for a fixed 3000-order Markov transition process (i.e., a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e001" xlink:type="simple"/></inline-formula> matrix of conditional probabilties). The conditional probabilities were changed abruptly at three points during the task, unaligned to rest periods and with no visual or other notification. (Images shown here are not those used in the study, but public domain stand-ins from clker.com that reflect the category of the photographs used during the experiment.)</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003387.g001" position="float" xlink:type="simple"/></fig><fig id="pcbi-1003387-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003387.g002</object-id><label>Figure 2</label><caption>
<title>Choice task.</title>
<p>Participants were asked to use their knowledge of the sequential transition structure to make decisions for reward. Choice rounds consisted of three steps. First, participants observed the reward amount and target image for one second. Next, they were given five seconds to choose one of two images to start the sequence from again. This choice was of varying difficulty, depending on how likely it was for each choice image to be followed by the reward image. For the next several presentations after choice, each observation of the valued image was accompanied by reward. (Images shown here are not those used in the study, but public domain stand-ins from clker.com that reflect the category of the photographs used during the experiment.)</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003387.g002" position="float" xlink:type="simple"/></fig>
<p>To test this hypothesis, we fit computational learning models to explain behavioral and neural observables (such as reaction times, decisions, and BOLD activity) in terms of recent experience with image transitions. Following the approach developed previously <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, for each observable we estimate a learning rate parameter, which measures how far into the past its behavior is affected by previous events. Since the learning rate measures which particular events the observable is sensitive to, we use it as signature of the underlying associative learning process. We then compare these estimates across different observables to investigate whether they might be driven by common learned associations.</p>
<p>We first examine reaction times for behavioral evidence of prediction learning during the sequential image presentations, verifying that the key results from the earlier study are replicated in the present design. Next, we examine how this learning is used to guide goal-directed choices for reward.</p>
<p>We then carry these analyses over to neuroimaging data, observing neural correlates of learned predictions across both task phases. One source of such correlates is image category-specific BOLD signals in visual ventral stream regions during the sequential learning task. During choice probes, we identify analogous content-specific activations that reflect deliberative computations supporting model-based decisions.</p>
<sec id="s2a">
<title>Behavior</title>
<sec id="s2a1">
<title>Two processes learn serial order relationships</title>
<p>Participants performed a sequential response task in which they were asked to press a key corresponding to one of four exemplar images, each displayed one at a time (<xref ref-type="fig" rid="pcbi-1003387-g001">Figure 1</xref>). The sequence was generated according to a first-order Markov process: at each step, an image's successor was chosen from a probability distribution over the four images. The distributions over next images were different for each current image. Participants were instructed as to the existence, but not the content, of this transition structure. They were told that these contingencies would change periodically, and without notice, throughout the experiment.</p>
<p>As has often been observed in such tasks <xref ref-type="bibr" rid="pcbi.1003387-Bahrick1">[8]</xref>, reaction times (RTs) were facilitated for images that were conditionally more probable given their predecessor (<xref ref-type="fig" rid="pcbi-1003387-g003">Figure 3</xref>). The impression that RTs are faster for conditionally more probable images is confirmed by performing a multiple linear regression with the ground-truth (programmed) conditional probability as the explanatory variable of interest. Across participants, the regression weight for this quantity was indeed significantly negative (one-sample t-test, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e002" xlink:type="simple"/></inline-formula>; mean effect size 0.44 ms RT per percentage conditional probability) and, at an individual level, reached significance (at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e003" xlink:type="simple"/></inline-formula>) for all 17 participants.</p>
<fig id="pcbi-1003387-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003387.g003</object-id><label>Figure 3</label><caption>
<title>Behavioral analyses.</title>
<p><italic>a</italic>. Reaction time on the image identification task decreases as the ‘ground-truth’ probability – the probabilities generated by the task program, and uninstructed to the participant – of that image appearing, conditional on the previous image increases. Here, for each participant, RTs were first corrected for their mean and a number of nuisance effects, estimated using a linear regression containing only these effects as explanatory variables. <italic>b</italic>. Across subjects, the fitted learning rate values that best explain behavior. For reaction times, the best-fitting model contained two learning rates (one ‘slow’, the other ‘fast’), whose estimates were combined linearly according to a fitted weighting parameter. For choice behavior, the best-fitting model contained one learning rate, statistically indistinguishable from the slow rate fit to reaction times, but significantly different from the fast.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003387.g003" position="float" xlink:type="simple"/></fig>
<p>This speeding allowed us to use RT as a behavioral index of participants' image expectation, and to leverage this to study how subjects updated their expectations trial-by-trial, by fitting computational learning models to the RT timeseries. As in our previous study <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, RTs were well explained by combining two incremental learning processes <xref ref-type="bibr" rid="pcbi.1003387-Bush1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Rescorla1">[17]</xref>. The processes each separately learn a table of conditional image succession probabilities, updating it incrementally in response to the prediction error at each observation, but with the size of this update in each of the independent processes controlled by a different learning rate parameter (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e004" xlink:type="simple"/></inline-formula>). To explain reaction times, the two conditional probability predictions are combined in a weighted average with some proportion <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e005" xlink:type="simple"/></inline-formula>. This two-process learning model provided a better fit to RTs than a one-process model for all 17 subjects individually (average log Bayes Factor 12.53, with no individual Bayes Factor in favor of the one-process model), and for the population as a whole (summed log Bayes Factor 213.08). The means, over the population, of the model's best fitting parameters were <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e006" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e007" xlink:type="simple"/></inline-formula>, with a weight of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e008" xlink:type="simple"/></inline-formula> to the slower rate. To generate regressors for fMRI we refit the group's behavior, taking all parameters as fixed effects across the population. (This regularizes the parameter estimates and allows us to examine variations in neurally implied learning rate estimates relative to a common baseline.) The fixed-effect parameter estimates were <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e009" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e010" xlink:type="simple"/></inline-formula>, weighted at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e011" xlink:type="simple"/></inline-formula>, which did not significantly differ from the ensemble of individual estimates (all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e012" xlink:type="simple"/></inline-formula>).</p>
<p>These data are consistent with our hypothesis that sequential learning arises from two distinct learning processes, which are superimposed to produce reaction time behavior.</p>
</sec><sec id="s2a2">
<title>Only slow-process associations drive choice</title>
<p>Our next aim was to examine how these predictions were used to make decisions for reward, and in particular to what extent decisions draw on either or both of the learning processes that drive reaction times.</p>
<p>At pseudorandom intervals throughout the task, participants encountered a choice probe (<xref ref-type="fig" rid="pcbi-1003387-g002">Figure 2</xref>) in which they were asked to use their current estimates of image contingencies to make decisions for reward.</p>
<p>Participants were informed that one of the four images was now worth money ($1 to $5) each time it occurred during the next several trials. They were next asked to choose from which of two other images to restart the sequence, so as to maximize their chance of winning money.</p>
<p>To examine how learned sequential transition probabilities influence choice behavior, we fit choices with a model in which participants chose between the two starting images on the basis of the estimated probability of each image leading to the rewarded image in one step. (We did not find evidence that participants took into account the possibility that choosing an image would lead to the rewarded image on timesteps following the first.) In particular, the model assumes that the chance of choosing an option depends on a decision variable defined as the difference between the conditional probability that the rewarded image would follow each of the two options. In this model, choice preferences depend on the transition probabilities learned in the preceding sequential response trials, and therefore they also depend on the learning rate. Because each learning rate implies a different series of transition probabilities, they also imply a different timeseries of choice preferences.</p>
<p>We fit learning models to the choices to answer the question: Which learning rate (or rates) for transition probabilities provided the best explanation for choice behavior? Considering the possibility that, like RTs, choices were due to some weighted combination of probabilities learned at two rates, we compared one- and two-process models. However, in this case a model with a single free learning rate provided a better fit for all 17 subjects individually (mean log Bayes Factor 2.31), and across the population (summed log Bayes Factor 39.26 versus the two rate model).</p>
<p>This single free learning rate, fit to choices, matched the slow learning rate fit to reaction times. Across subjects, the mean best-fit learning rate was 0.10+/−0.05, which was smaller than the fast learning rate obtained for RTs (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e013" xlink:type="simple"/></inline-formula>) but not significantly different from the slow learning rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e014" xlink:type="simple"/></inline-formula>) (<xref ref-type="fig" rid="pcbi-1003387-g003">Figure 3</xref>). These results suggest that choices, unlike reaction times, exclusively result from associations learned at a single timescale, consistent with the slow process observed in RTs.</p>
<p>How are these learned transition probabilities used to compute action values? The standard model is that expected values are computed by multiplying the probability of each option image leading to the goal image by the reward value of that goal image. These expected values are then transformed into choice probabilities using a softmax function, with a free parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e015" xlink:type="simple"/></inline-formula>.</p>
<p>Another approach, inspired by race models <xref ref-type="bibr" rid="pcbi.1003387-Ratcliff1">[18]</xref>, is based on the idea that the outcome predictions driving choice might involve discrete retrievals of next-step images, proportional to the estimated transition probabilities <xref ref-type="bibr" rid="pcbi.1003387-Lengyel1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Erev1">[20]</xref>. In this model, choice probabilities result from a thresholded comparison process after some number of draws from the binomial distribution (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e016" xlink:type="simple"/></inline-formula>) defined by the transition probabilities. This approach is similar to the sort of sequential sampling processes used to model perceptual decisions <xref ref-type="bibr" rid="pcbi.1003387-Gold1">[21]</xref>. Fitting this model to the set of choices by each participant gives an additional parameter, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e017" xlink:type="simple"/></inline-formula>, the average number of draws. Here, binomial sampling noise introduces stochasticity in the choices similar to the softmax logistic distribution often used in decision models <xref ref-type="bibr" rid="pcbi.1003387-Daw2">[22]</xref>, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e018" xlink:type="simple"/></inline-formula> playing a role analogous to softmax's inverse temperature. (See <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref>, section <italic>Choice models</italic>, for more details.) In fact, choices are also similarly fit by the softmax, and the foregoing results concerning learning rate are robust to either choice rule. We adopt the sampling model because the process-level description of decision noise motivates analyses of neuroimaging data during choice formation, presented below.</p>
<p>At the fixed, slow learning rate, the best-fit value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e019" xlink:type="simple"/></inline-formula> was 4.675+/−1.25 samples, across subjects. As in our learning rate analysis, we estimated this as a fixed effect (4.177), for generating our fMRI regressors (see <italic>Choice difficulty</italic> in <italic>Neuroimaging results</italic>).</p>
</sec></sec><sec id="s2b">
<title>Neuroimaging</title>
<p>We next identified neural correlates of each learning process.</p>
<sec id="s2b1">
<title>Stimulus anticipation in each process has distinct neural substrates</title>
<p>We began by looking for correlates of participants' anticipation of the next image to appear. Specifically, we sought activity that reflected how difficult it might be to predict this next image. Previous work <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Strange1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Harrison1">[10]</xref> has shown that BOLD activity in hippocampus and elsewhere covaries with the participants' modeled uncertainty about future events. This may reflect a process of spreading activation, by which an image triggers activations of likely successor images, which are more numerous in situations of uncertainty. Also consistent with this idea, the anterior portion of the hippocampus was recently shown more directly to reflect such anticipation in sequential relationships among abstract stimuli <xref ref-type="bibr" rid="pcbi.1003387-Schapiro1">[23]</xref>.</p>
<p>Here, uncertainty is formally defined as the “forward entropy,” or entropy of the model's prediction about the identity of the next image, conditional on the current one. This is a trial-by-trial function of the model's learned transition probabilities, which in turn depend on the learning rate fit to behavior. These regressors are specified as parametric modulators on delta functions placed at the onset of the currently presented image.</p>
<p>The two-process model as fit to reaction times therefore gives rise to two entropy timeseries, one each from predictions generated at the fast and slow learning rates. Based on our previous results <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, we expected to find different correlates corresponding to the entropy timeseries from each process: in hippocampus for the slower learning rate and in striatum for the faster learning rate. We defined, using the AAL template library, anatomical masks of the structures in which we observed above-threshold activations in our previous study: left hippocampus for slow learning rate entropy and bilateral caudate for fast learning rate entropy <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>. Accordingly, when forward entropy was computed according to the slow learning rate process, a cluster of significantly correlated activity was observed in the region identified in our previous study, left anterior hippocampus (peak −26, −10, −18; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e020" xlink:type="simple"/></inline-formula> corrected for family-wise error due to multiple comparisons over an anatomically-defined mask of left hippocampus; <xref ref-type="fig" rid="pcbi-1003387-g004">Figure 4</xref>).</p>
<fig id="pcbi-1003387-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003387.g004</object-id><label>Figure 4</label><caption>
<title>BOLD signal reflecting anticipation of the next stimulus.</title>
<p><italic>a</italic>. BOLD signal correlated with forward entropy in the fast process. Activity in the dorsal caudate was significant after correction over an anatomically-defined mask of bilateral caudate. <italic>b</italic>. BOLD signal correlated with forward entropy in the slow process. Activity in the anterior hippocampus was significant after correction over an anatomically-defined mask of left hippocampus. Both <italic>a</italic> and <italic>b</italic> displayed at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e021" xlink:type="simple"/></inline-formula>, uncorrected.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003387.g004" position="float" xlink:type="simple"/></fig>
<p>We ran a separate regression containing an identical GLM except for the entropy regressor, which was now computed according to the fast learning rate. In this GLM, we observed activation on the tail of right caudate (peak 24, −14, 26) that was significant when corrected for multiple comparisons over an anatomically-defined mask of bilateral caudate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e022" xlink:type="simple"/></inline-formula>). (A symmetric cluster in left caudate was observed at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e023" xlink:type="simple"/></inline-formula> uncorrected, but did not survive correction for multiple comparisons.)</p>
<p>The foregoing results suggest two prediction processes that each learn at a rate corresponding to one of those observed in the RT behavior, with anatomically separate substrates. As in our previous study <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, we more directly tested the correspondence of learning rate to neural structure within a single GLM by independently estimating the learning rate that best explained entropy-related BOLD signals in each area. We located voxels of interest in an unbiased manner and fit the learning rate using a Taylor approximation to the entropy regressor's dependence on the parameter <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Josephs1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Daw3">[25]</xref>. Neural learning rate estimates are visualized, superimposed over the behaviorally-obtained learning rates, in <xref ref-type="fig" rid="pcbi-1003387-g005">Figure 5</xref>.</p>
<fig id="pcbi-1003387-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003387.g005</object-id><label>Figure 5</label><caption>
<title>Learning rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e024" xlink:type="simple"/></inline-formula> computed from BOLD signal.</title>
<p>Learning rates computed from each of our regions of interest, overlaid on the learning rates fit to reaction time behavior. The best-fitting learning rates are displayed for each type of trial: sequential image-identification trials, decision trials, and choice outcome trials. For learning trials in hippocampus and caudate, learning rates are computed using the forward entropy regressor. For learning trials in face- and house-selective cortex, learning rates are computed using the estimated probability of the image appearing on the next trial. For decision trials in hippocampus, learning rate is computed using the choice difficulty regressor. For decision trials in face- and house-selective cortex, learning rates are computed using the portion of the choice difficulty regressor specific to that image. For outcome trials in nucleus accumbens, learning rate is computed using the reward prediction error regressor. Error bars: 1 SEM.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003387.g005" position="float" xlink:type="simple"/></fig>
<p>Matching our previous results <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, the fast learning rate from RTs matched the one computed from BOLD signal in the striatum. In the mean over participants, the learning rate implied by BOLD in caudate was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e025" xlink:type="simple"/></inline-formula>. This rate was significantly larger than the slow learning rate fit to RTs (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e026" xlink:type="simple"/></inline-formula>), but not significantly different from the fast learning rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e027" xlink:type="simple"/></inline-formula>).</p>
<p>In our prior study <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, the slow learning rate from RTs matched the one computed from BOLD signal in the anterior hippocampus; here, though the hippocampal BOLD learning rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e028" xlink:type="simple"/></inline-formula>) was numerically closer to the slow rate fit to RTs, it was statistically different from both that rate as well as the fast (both <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e029" xlink:type="simple"/></inline-formula>). Importantly, however, it was not statistically distinguishable from the learning rate fit to choices (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e030" xlink:type="simple"/></inline-formula>) — thus supporting the critical link, from learning to choices — and also significantly smaller than the striatal learning rates computed from BOLD (paired samples; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e031" xlink:type="simple"/></inline-formula>).</p>
<p>Taken together with the behavioral model fits, these neuroimaging results and learning rate computations support the suggestion that two distinct processes learn to estimate the sequential contingencies embedded in our image identification task. Further, neural activity in two structures reflects anticipation (indexed by forward entropy) according to the estimates of each processes, with learning rates that differ from one another and approximate those identified in reaction time behavior.</p>
</sec><sec id="s2b2">
<title>Neural decision computations are uniquely explained by the slow process</title>
<p>We next sought correlates of decision computations driven by the learned transition probabilities. Our analysis of choice behavior indicated that decisions were informed by the sequential contingencies learned at a rate consistent with the slow learning rate fit to RTs. Therefore we hypothesized that activity related to decision computations would also be identified with a similar learning rate. If this indeed reflected a common underlying learning process, it would engage the anterior hippocampus, which was shown to support slow learning in the sequential learning task.</p>
<p>We first analyzed activity during the deliberation period leading up to the choice. Similar to our analysis of anticipatory activity during sequential response trials, we probed the neural correlates of deliberation by asking: how difficult was it for the participant to make this decision? We used as our measurement of choice difficulty the uncertainty (variance) in the decision variable (the value difference between options) that led to the current choice, computed using the choice model parameters fit to behavior (for details, see <italic>Choice models</italic> in <xref ref-type="sec" rid="s4"><italic>Materials and Methods</italic></xref>). This quantity, which was motivated by the process-level model of decision noise, is similar to the entropy measure used to define uncertainty during the learning task. The key difference is that the distribution being analyzed lumps images into two categories (rewarded vs nonrewarded) rather than predicting all four separately.</p>
<p>This regressor was specified at the time of onset of the choice screen.</p>
<p>In our region of prior interest, an area of left anterior hippocampus was activated, though only marginally significant after multiple comparison correction over our anatomical mask (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e032" xlink:type="simple"/></inline-formula>; <xref ref-type="fig" rid="pcbi-1003387-g006">Figure 6b</xref>). This activation is similar to that seen to entropy during the stimulus prediction task.</p>
<fig id="pcbi-1003387-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003387.g006</object-id><label>Figure 6</label><caption>
<title>BOLD signal during choices and outcomes.</title>
<p>During deliberation periods after choice options were presented, we observed activity in <italic>a</italic>. posterior cingulate (−2, −18, 32), anterior mPFC (4, 64, −2) and <italic>b</italic>. left hippocampus (peak −24, −10, −18), all significantly correlated with choice difficulty in the slow process. <italic>c</italic>. BOLD signal at outcome. A cluster in the nucleus accumbens (peak 10, 12, −2) correlated with reward prediction error as computed using the expectations derived from the slow process. All activations displayed at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e033" xlink:type="simple"/></inline-formula>, uncorrected.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003387.g006" position="float" xlink:type="simple"/></fig>
<p>Does this activity reflect learning similar to one of the processes observed in RT behavior? We again estimated the learning rate implied by these BOLD correlates. The learning rate computed from anterior hippocampal BOLD during choices matched the slow learning rate fit to RT. The mean learning rate that best explained this activity was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e034" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003387-g005">Figure 5</xref>). This was different from the fast learning rate from RT behavior (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e035" xlink:type="simple"/></inline-formula>), but did not differ from the slow RT learning rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e036" xlink:type="simple"/></inline-formula>). The involvement of the hippocampal region in both phases of the task, showing the same type of learned associations, supports the idea that a common learning process supports both behaviors.</p>
</sec><sec id="s2b3">
<title>Choice difficulty engages a fronto-temporal memory network</title>
<p>Additionally, at the whole brain level, the choice difficulty measure revealed correlates in a broad fronto-temporal network that appears to correspond to a component of the ‘default network’, a set of brain regions that has been associated with constructive memory and mindwandering <xref ref-type="bibr" rid="pcbi.1003387-Buckner1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Buckner2">[27]</xref>.</p>
<p>In particular, two clusters survived correction for multiple comparisons over the entire brain: a region of anterior medial PFC (peak 4, 64, −2; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e037" xlink:type="simple"/></inline-formula>), and a region of posterior cingulate cortex (peak −2, −18, 32; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e038" xlink:type="simple"/></inline-formula>; <xref ref-type="fig" rid="pcbi-1003387-g006">Figure 6a</xref>). Also, activation in a third component of the default network, the dorsomedial PFC (peak 14, 40, 40) survived whole-brain multiple comparison correction for cluster extent (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e039" xlink:type="simple"/></inline-formula>), but not peak (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e040" xlink:type="simple"/></inline-formula>). Together with the above-reported anterior hippocampal cluster, the overall pattern of activation is consistent with previous observations of the fronto-temporal memory component of the default network <xref ref-type="bibr" rid="pcbi.1003387-Kahn1">[28]</xref>.</p>
<p>We ruled out alternative explanations for activity in these regions, or other variables that might correspond to the notion of ‘choice difficulty’. The choice difficulty regressor was not significantly correlated with reaction time (across subjects, mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e041" xlink:type="simple"/></inline-formula>), nor the expected value of the choice (mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e042" xlink:type="simple"/></inline-formula>).</p>
</sec><sec id="s2b4">
<title>Prediction error activity in striatum</title>
<p>This same hippocampally-linked, slow process learning also matched the neural reward prediction error (RPE) in nucleus accumbens <xref ref-type="bibr" rid="pcbi.1003387-Delgado1">[29]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-McClure1">[31]</xref>. We analyzed the RPE at the time of the onset of the first image following the choice, since that was the timepoint that primarily influenced the decision in our behavioral analysis. Here, the RPE is defined as the difference between the obtained reward (or $0, if an image other than the rewarded one occurs) and the expected value of the option chosen. Since the expected value depends on the learned image transition probabilities, this signal again should depend on the learning rate.</p>
<p><xref ref-type="fig" rid="pcbi-1003387-g006">Figure 6</xref> illustrates activity in nucleus accumbens correlated with the RPE regressor computed from the slow learning rate (peak 10, 12, −2 ; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e043" xlink:type="simple"/></inline-formula> after correction for family-wise error due to multiple comparisons over an anatomical mask of the nucleus accumbens). Again, the learning rate in the NAcc was best matched to the slow learning rate fit to RT. The mean learning rate implied by NAcc activity was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e044" xlink:type="simple"/></inline-formula>. Across the population, this rate was smaller than the fast learning rate obtained from RT behavior (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e045" xlink:type="simple"/></inline-formula>) but was not different from the slow learning rate computed from RT behavior (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e046" xlink:type="simple"/></inline-formula>). Thus, these results are again consistent with the idea that the choice phase of the task is driven by the slow, hippocampally-linked process.</p>
<p>To verify that these results are indiciative of a reward prediction error signal, and not simply driven by the receipt of reward, we extracted the coefficients for reward value and expectation separately. A signal reflecting the computation of reward prediction error should positively covary with the former, and negatively with the latter. This was in fact the case: across the population, the correlation coefficient at the peak voxel was significantly positive for reward value (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e047" xlink:type="simple"/></inline-formula>, by two-tailed, one-sample t-test) and significantly negative for expected value (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e048" xlink:type="simple"/></inline-formula>).</p>
</sec><sec id="s2b5">
<title>Content-preferring visual regions are selectively driven by anticipation for stimulus category</title>
<p>One interpretation of activity related to forward entropy during the sequential image identification trials (<xref ref-type="fig" rid="pcbi-1003387-g004">Figure 4</xref> above) is that it might result in the aggregate from the retrieval of likely targets in anticipation of the upcoming image. To seek more direct evidence for such retrieval at the item level, we leveraged the fact that our design used four category-specific exemplars as stimuli. Each of these exemplars was chosen because it represents a category that has been shown to preferentially engage a particular region of higher-order visual cortex: bodies <xref ref-type="bibr" rid="pcbi.1003387-Downing1">[32]</xref>, faces <xref ref-type="bibr" rid="pcbi.1003387-Kanwisher1">[33]</xref>, houses <xref ref-type="bibr" rid="pcbi.1003387-Epstein1">[34]</xref>, and household objects <xref ref-type="bibr" rid="pcbi.1003387-Malach1">[35]</xref>. We examined whether activity in these regions was related to the estimated probability (from the model fit to participant behavior) that the corresponding image would appear on the <italic>next</italic> trial. This probability timeseries is a parametric measure of the strength of the estimate for a given image, specified at the time of onset of the preceding image. We tested these effects only for houses and faces, because these categories were the most consistently identified with regions in our initial localizer analysis.</p>
<p>First, we identified face- and house-sensitive regions using the relevant (in-task) localizer contrast: regions that responded more for trials on which the face was presented than they did on trials on which the house was presented, and vice-versa. We selected the voxels that survived correction over a combined anatomical mask of the right ventral stream regions: fusiform gyrus, parahippocampal gyrus, and inferior occipital lobe, chosen to encompass previously observed content-sensitive regions <xref ref-type="bibr" rid="pcbi.1003387-Downing1">[32]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Malach1">[35]</xref>, and reflecting the fact that these activations tend to be right-lateralized in our areas of interest. The face and house selective regions are depicted in <xref ref-type="fig" rid="pcbi-1003387-g007">Figure 7</xref> (face peak 42, −48, −20, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e049" xlink:type="simple"/></inline-formula> ; house peak 28, −82, −2, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e050" xlink:type="simple"/></inline-formula>).</p>
<fig id="pcbi-1003387-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003387.g007</object-id><label>Figure 7</label><caption>
<title>Image-selective regions.</title>
<p>The regions defined by the in-task localizer contrasts house <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e051" xlink:type="simple"/></inline-formula> face and face <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e052" xlink:type="simple"/></inline-formula> house, are colored yellow (left: face, right: house). The face localizer yielded the largest cluster of activation in a region of right fusiform gyrus. The house localizer yielded the largest cluster of activation in a region stretching from posterior parahippocampal gyrus to the occipital lobe. Regions selectively sensitive to the estimated probability of an image appearing next (on sequential response trials) are colored blue. Regions selectively sensitive to the difficulty of deciding whether a particular image would lead to reward are colored red. Displayed at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e053" xlink:type="simple"/></inline-formula>, uncorrected.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003387.g007" position="float" xlink:type="simple"/></fig>
<p>These face- and house-selective regions were then used to seek activity sensitive in a graded fashion to <italic>anticipation</italic> of the face or the house, respectively. Within these regions, we tested for activity preferentially related to the probability of the face (as opposed to the house) appearing <italic>next</italic>, and vice versa. (Note that any such activity cannot be explained by a confounding tendency of the house actually to appear after it is expected, since the GLM also models the actual presentation of the faces and houses, and the test of the parametric effect of probability therefore turns only on the portion of activity orthogonal to this.) Indeed, activations within the face- and house-selective regions were significantly (though <italic>negatively</italic>) correlated with the probability of the corresponding image appearing next (face: peak 42, −66, −14, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e054" xlink:type="simple"/></inline-formula>; house: peak 26, −70, −8, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e055" xlink:type="simple"/></inline-formula>). The face and house-selective regions and the corresponding contrasts selective for anticipation of each image are displayed in <xref ref-type="fig" rid="pcbi-1003387-g007">Figure 7</xref>.</p>
<p>Like entropy, the anticipatory probability regressor depends, in the model, on the learning rate that produces the probability estimates. We again estimated the learning rate, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e056" xlink:type="simple"/></inline-formula>, that best explained anticipatory activity in each of these category-selective regions (<xref ref-type="fig" rid="pcbi-1003387-g007">Figure 7</xref>). In both regions, the learning rate was best matched to the slow, hippocampal learning process. In the face region, the mean learning rate was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e057" xlink:type="simple"/></inline-formula>. This rate was smaller than the fast learning rate fit to RTs (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e058" xlink:type="simple"/></inline-formula>), but not significantly different from the slow learning rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e059" xlink:type="simple"/></inline-formula>). In the house region, the mean learning rate was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e060" xlink:type="simple"/></inline-formula>. Across the population, this rate was numerically closer to the slow rate, but significantly different from both the fast and the slow However it did not significantly differ from other slow learning rates we estimated: that fit to choice behavior (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e061" xlink:type="simple"/></inline-formula>), or the hippocampal learning rate computed from BOLD (paired samples; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e062" xlink:type="simple"/></inline-formula>). Finally, this rate <italic>was</italic> significantly smaller than the learning rate computed from striatal BOLD (paired samples; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e063" xlink:type="simple"/></inline-formula>).</p>
<p>Together, these results confirm that anticipatory activity in the image-sensitive regions corresponds with the estimated probability of each image appearing next. Further, they concord with the notion that learning implied by these signals most closely conforms to a slow learning process identified in reaction time, choice, and hippocampal BOLD.</p>
</sec><sec id="s2b6">
<title>Content-selective regions are selectively driven by difficulty of deliberating about a stimulus category</title>
<p>Activity in content-preferring regions was linked to the slow, hippocampal process during choice trials as well. Our choice model, fit to behavior, involved drawing samples of associations that would lead to the rewarded image. Here, we looked for activity in content-selective regions consistent with the reinstatement predicted by this process. For this analysis, we split our measure of choice difficulty into separate components, associated with each of the four different image categories (though limiting our analysis again to faces and houses). In particular, we considered the uncertainty about the probability that each image, separately, would lead to the rewarded image. We hypothesized that if the decision process involved retrieving each image's associates in attempting to compute its chance of leading to reward, then activity in the category-sensitive regions might be modulated by the difficulty of making this determination. Indeed, at the slow learning rate, the BOLD signal was positively correlated with the category-specific choice difficulty in the content-sensitive regions previously identified (face: peak 40, −62, −16, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e064" xlink:type="simple"/></inline-formula>; house: peak 30, −76, −6, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e065" xlink:type="simple"/></inline-formula> ; all p-values corrected for multiple comparisons over the respective regions identified in our visual localizer).</p>
<p>Again, the activity in both face and house-selective regions was best matched to the slow learning process. The mean learning rate implied by activity in the face-selective region was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e066" xlink:type="simple"/></inline-formula>. This rate was slower than the fast rate identified in RT behavior (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e067" xlink:type="simple"/></inline-formula>), and did not differ significantly from the slow learning rate fit to RTs (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e068" xlink:type="simple"/></inline-formula>). The mean learning rate implied by activity in the house-selective region was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e069" xlink:type="simple"/></inline-formula>. This rate was also smaller than the fast RT learning rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e070" xlink:type="simple"/></inline-formula>). Consistent with our hypothesis, it did not differ significantly from the slow RT learning rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e071" xlink:type="simple"/></inline-formula>).</p>
<p>For a full accounting of the comparisons between each of the learning rates identified in choices, reaction times, and BOLD, see <xref ref-type="table" rid="pcbi-1003387-t001">Table 1</xref>.</p>
<table-wrap id="pcbi-1003387-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003387.t001</object-id><label>Table 1</label><caption>
<title>Learning rates implied by BOLD in each region of interest.</title>
</caption><alternatives><graphic id="pcbi-1003387-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003387.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Region-Regressor</td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e072" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Not fast?</td>
<td align="left" rowspan="1" colspan="1">Not slow?</td>
<td align="left" rowspan="1" colspan="1">Not choice LR?</td>
<td align="left" rowspan="1" colspan="1">Not HC?</td>
<td align="left" rowspan="1" colspan="1">Not caudate?</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">HC-Entropy</td>
<td align="left" rowspan="1" colspan="1">0.099</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref><xref ref-type="table-fn" rid="nt103">!</xref></td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">-</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">HC-Difficulty</td>
<td align="left" rowspan="1" colspan="1">0.018</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Caudate-Entropy</td>
<td align="left" rowspan="1" colspan="1">0.507</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt102">**</xref></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt102">**</xref></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
<td align="left" rowspan="1" colspan="1">-</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">NAcc-RPE</td>
<td align="left" rowspan="1" colspan="1">0.0193</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Face-Probability</td>
<td align="left" rowspan="1" colspan="1">0.04</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Face-Difficulty</td>
<td align="left" rowspan="1" colspan="1">0.063</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">House-Probability</td>
<td align="left" rowspan="1" colspan="1">0.12</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref><xref ref-type="table-fn" rid="nt103">!</xref></td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt101">*</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">House-Difficulty</td>
<td align="left" rowspan="1" colspan="1">0.085</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt102">**</xref></td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1">n.s.</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="table-fn" rid="nt102">**</xref></td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt101"><label>*</label><p>- <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e073" xlink:type="simple"/></inline-formula>.</p></fn><fn id="nt102"><label>**</label><p>- <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e074" xlink:type="simple"/></inline-formula>.</p></fn><fn id="nt103"><label>!</label><p>- test ran counter to our hypothesis about the learning rate of that region.</p></fn></table-wrap-foot></table-wrap>
<p>Taken together, these results tie activity in the ventral visual stream during decisions to an associative learning process consistent both anatomically and in terms of learning rate with that examined during sequential responding. Thus, altogether, these results suggest that the associative learning processes whose correlates were observed in hippocampus and the ventral visual stream during the sequential response trials also support deliberative, goal-directed planning in decisions for reward.</p>
</sec></sec></sec><sec id="s3">
<title>Discussion</title>
<p>It is well established that decisions can be influenced by knowledge of contingencies embedded in the environment. The current study examined the neural computations underlying the learning of these contingencies, and linked them to computations underlying the decisions themselves. We present evidence that model-based decisions are supported by a contingency learning process involving hippocampus and ventral visual cortex, whose activity changed with this learning and was observed in concert with multiple kinds of instrumental behavior.</p>
<p>These results go beyond previous research that indirectly inferred the contribution of contingency learning to decisions, by using characteristics of the decisions and neural activity related to decision variables (action values or prediction errors; <xref ref-type="bibr" rid="pcbi.1003387-Hampton1">[36]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Daw4">[38]</xref>), or conversely by examining activity related to contingency learning <xref ref-type="bibr" rid="pcbi.1003387-Glscher1">[15]</xref> without directly comparing it to choices. Here, we used additional observables — reaction times and fMRI signatures of reactivation of past experiences — to examine the learning of contingencies more directly, and to demonstrate that a component of this learning was quantitatively well matched to that implied by decisions.</p>
<sec id="s3a">
<title>Learning rate comparisons</title>
<p>We are able to compare learning across different task phases (learning and choice) and sorts of measurements (reaction times, choices, and BOLD correlates of different quantities) by treating them all as different windows on a computational learning process. We fit each sort of data with a standard computational model of how predictions are learned from recent experience, and compare the learning rate parameters that best explain these measurements. The pattern of data in <xref ref-type="fig" rid="pcbi-1003387-g003">Figures 3</xref> and <xref ref-type="fig" rid="pcbi-1003387-g005">5</xref> and <xref ref-type="table" rid="pcbi-1003387-t001">Table 1</xref> shows a striking consistency in these estimated learning rates between the different measurements.</p>
<p>However, there are a number of caveats to keep in mind about these analyses. First, it is in principle not possible to conclude that any two of these learning rate estimates are “the same” as one another — only that they are not statistically distingishable. But this pattern of negative findings is supported by positive ones, for instance that the differences between the various manifestations of “slow” and “fast” learning rates are significant (<xref ref-type="table" rid="pcbi-1003387-t001">Table 1</xref>). Also, our findings that apart from exhibiting similar learning rates, neural activity during choice and decisions implicate common neural structures support the interpretation that all this activity relates to a common underlying learning process. Ultimately, however, establishing a definitive link between activity during learning and choice will require additional work using methods that can probe causal relationships between brain function and behavior.</p>
<p>A related point is that the estimates of learning rates from BOLD in <xref ref-type="fig" rid="pcbi-1003387-g005">Figure 5</xref> consistently tend to be less extreme than their behavioral counterparts, i.e. slightly slower relative to the fast learning rate and faster relative to slow. In a couple of cases, this difference between BOLD and behavioral estimates is significant, seeming to contradict the interpretation that all these measurements reflect a common learning process. We believe this relates to another important set of caveats with this study, which is that it is methodologically challenging to estimate learning rates from BOLD data due to the nonlinear relationship between the learning rate and the decision variables that have BOLD correlates (entropy, etc.). To permit estimation, we approximate this relationship as linear using a first-order Taylor expansion <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Daw3">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Bchel1">[39]</xref>. This allows us to estimate the learning rate in the context of the same standard fMRI analysis (using a general linear model) as the rest of our results, and in turn means these analyses cope in the standard ways with the many methodological complications of fMRI (including for instance intersubject random effects, temporal and spatial autocorrelation, hemodynamics, and regressor colinearity). This method appears to perform robustly in this and our previous study <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref> and other closely related analyses of parametric brain-behavior relationships <xref ref-type="bibr" rid="pcbi.1003387-Daw4">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Wittmann1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Wimmer1">[41]</xref>, but there has not yet been a formal simulation study quantifying the error introduced by this approximation. One key sort of approximation error that we have examined <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref> arises from our choice of the midpoint between fast and slow learning rates as the point around which to linearize. We choose this point to minimize the distance between the linearization point and the hypothetically relevant learning rates, since the error from linear extrapolation is expected to accumulate with distance. However, this choice interacts with the way we identify voxels of interest for fitting the learning rate, by identifying peaks in activity assuming this midpoint learning rate. Intuitively, this selection biases the estimated learning rates toward this midpoint (see our previous study using this approach for a more thorough technical explanation <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>). Although this effect is innocuous with respect to the conclusions in this article, it may account for some of the observed difference between neural and behavioral estimates in <xref ref-type="fig" rid="pcbi-1003387-g005">Figure 5</xref>.</p>
</sec><sec id="s3b">
<title>Hippocampus and striatum</title>
<p>Our choice task has one of the key features of a latent learning task <xref ref-type="bibr" rid="pcbi.1003387-Glscher1">[15]</xref>: sequential contingency learning precedes the introduction of a new and unpracticed rewarding goal. In particular, given the sparse occurrence of the choice probes, and the different combinations of rewarded and starting images, these decisions implicate a model-based response strategy requiring participants to evaluate options' chances of reaching the new goal based on the predictive associations being continually learned in the sequential image presentation trials. Conversely, choices of this sort leave little room for model-free reinforcement learning based only on the success of particular choices at earning money in previous choice trials.</p>
<p>Consistent with this, a key neural player in both the learning and decision phases in our results is the hippocampus. The hippocampal system is associated with flexible memory for stimulus-stimulus relations <xref ref-type="bibr" rid="pcbi.1003387-Squire1">[42]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Rose1">[44]</xref> and is a longstanding candidate for maintaining contingency structure in the service of goal-directed decisions <xref ref-type="bibr" rid="pcbi.1003387-Dickinson2">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Lengyel1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Johnson1">[45]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Buckner3">[48]</xref>. In part, these suggestions are based on the analogy with spatial tasks, in which it has long been argued that the hippocampus implements a cognitive map <xref ref-type="bibr" rid="pcbi.1003387-OKeefe1">[49]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Redish1">[50]</xref>.</p>
<p>A suggestive connection of these ideas to nonspatial tasks is ubiquitous findings that the the hippocampal system is implicated in acquired equivalence, transitive inference, and sensory preconditioning effects <xref ref-type="bibr" rid="pcbi.1003387-Wimmer1">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Bunsey1">[51]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Shohamy1">[53]</xref>, as well as the flexible use of conceptual <xref ref-type="bibr" rid="pcbi.1003387-Kumaran1">[54]</xref> and structured <xref ref-type="bibr" rid="pcbi.1003387-Kumaran2">[55]</xref> knowledge. All of these effects demonstrate a bias in novel choice probes caused by previously learned stimulus-stimulus relations. Model-based decision making relies on a similar ability to flexibly chain together or recombine associations in novel ways, as exercised in latent learning tasks like our choice probes here.</p>
<p>Accordingly, we hypothesized that participants would draw on hippocampally-linked contingencies to make decisions. Indeed, the learning rates that best explained both choices and BOLD signals during the decision trials were not distinguishable from those seen in hippocampus and nearby ventral stream visual cortex during sequential responding, while differing significantly from those seen in BOLD activity in caudate and the fast process in reaction times. This quantitative convergence between learning processes examined during different tasks and through the lens of different observables substantiates the idea that model-based decisions and incidental stimulus-stimulus learning, like other sorts of relational learning and transfer <xref ref-type="bibr" rid="pcbi.1003387-Wimmer1">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Shohamy1">[53]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Kumaran2">[55]</xref> are supported by the same hippocampal memory system.</p>
<p>Interestingly, the literature concerning these tasks suggests what appear to be two distinct (but potentially complementary) mechanisms supporting the flexible transfer of relational knowledge to novel probes. Some studies have demonstrated that better performance on transfer probes is predicted by hippocampal BOLD activity at learning but not test time <xref ref-type="bibr" rid="pcbi.1003387-Shohamy1">[53]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Wimmer2">[56]</xref> suggesting that transfer is somehow supported by processes that occur already during encoding. One hypothesis is that such activity reflects the immediate transfer of learning, when information is first obtained, to other related associates by a process of spreading activation. In other studies <xref ref-type="bibr" rid="pcbi.1003387-Kumaran1">[54]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Kumaran2">[55]</xref>, neural activity at probe time also related to correct performance or with the relational information itself. This suggests the importance of processes occurring at the time of retrieval, and is consistent with theories (as in the standard account of model-based RL) that transfer is supported by some sort of active inference, planning or search at the time of the novel choice. Our result (discussed further below) that hippocampal activity tracked the difficulty of the decision probes speaks to the latter mechanism, providing relatively direct evidence that the hippocampal system engages in more computation for harder transfer problems (see also Simon &amp; Daw <xref ref-type="bibr" rid="pcbi.1003387-Simon1">[57]</xref>). Altogether, these two distinct but complementary mechanisms appear to be each well supported across the literature, and could plausibly both contribute in different circumstances.</p>
<p>The type of model-based decision making studied here contrasts with “model-free” habit learning, of the sort associated with dorsolateral striatum <xref ref-type="bibr" rid="pcbi.1003387-Yin1">[58]</xref>, predominant temporal-difference learning accounts of reward prediction error signal seen in dopamine neurons <xref ref-type="bibr" rid="pcbi.1003387-Schultz1">[6]</xref>, and the striatal BOLD response <xref ref-type="bibr" rid="pcbi.1003387-Delgado1">[29]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-McClure1">[31]</xref>. That said, parts of striatum are clearly necessary for model-based decision making in rodents as well <xref ref-type="bibr" rid="pcbi.1003387-Yin2">[59]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Yin3">[60]</xref>. Perhaps related, in human neuroimaging, even reward prediction errors observed in ventral striatum — though often characterized as reflecting the teaching signal for model-free stimulus-response learning — have recently been shown to report information about the state-state or relational structure of a task that would be known only to a model-based system <xref ref-type="bibr" rid="pcbi.1003387-Daw4">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Wimmer1">[41]</xref>. This may suggest some crosstalk between model-based and model-free learning in the brain. The reward prediction errors in the decision phase of the present task are consistent with these results, in that they reflect stimulus-stimulus predictions combined with trial-specific rewards to which a purely model-free reinforcement learner would be blind. The present results also extend these findings by showing that the stimulus-stimulus learning rate driving these prediction error effects matches that from the hippocampal system during the sequential response task, suggesting all these are indeed driven by a common learning process.</p>
<p>During the sequential response task, activity was <italic>not</italic> observed in the ventral striatal region commonly associated with reward prediction errors. This may reflect the lack of overt reinforcement in this more implicit association task. Instead, activity in a more dorsal/posterior region of striatum reflected a transient (high learning rate) adaptation process, which also had separate correlates in reaction times. We speculate that this activity (and the associated component of the reaction times) may reflect a second process of response learning, which did not carry over into the decision task. Indeed, the stimulus sequence in serial reaction time tasks of the sort we use is accompanied by an equivalent motor sequence (of button presses), leading previous authors to suggest <xref ref-type="bibr" rid="pcbi.1003387-Davis1">[61]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Willingham1">[63]</xref> that participants might learn either or both of two distinct types of sequential associations: stimulus-stimulus and response-response. That these processes then are uniquely tied to separate brain systems — hippocampus and striatum — suggests that they reflect learning of information specialized to each of those systems. Given the broader functional roles of both structures, it is tempting to hypothesize that hippocampus is associated with stimulus-stimulus associations and striatum with response-response <xref ref-type="bibr" rid="pcbi.1003387-Packard1">[64]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Knowlton1">[66]</xref>. While we did not explicitly dissociate response-response and stimulus-stimulus associations, the weight of the literature tying each of these types of information to each brain structure suggests this hypothesis and encourages us to carry it forward throughout the below <xref ref-type="sec" rid="s3">discussion</xref>. Importantly, by asking participants to seek a particular stimulus given another, our decision probes isolate only stimulus-stimulus associations and cannot be solved on the basis of response-response associations. Thus, the finding that the hippocampal activity (and its learning rate) contributed to these choices, but not the striatal one, is consisistent with these structures' hypothesized involvement in stimulus and response prediction. Further, the exclusive use of the slow-process associations in forward-looking, model-based choice suggest that these associations are of a type that may be flexibly recombined, a property long associated with hippocampal representations and not those of striatum <xref ref-type="bibr" rid="pcbi.1003387-Buckner3">[48]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Dusek1">[52]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Poldrack1">[67]</xref>.</p>
<p>That this learning was ‘slow’ in the hippocampus may at first seem to run counter to the notion that this structure supports flexible, rapidly bound learning, as in episodic memory. Model-based decisions are also characterized similarly, for instance because they tend to dominate behavior during initial learning but not following overtraining. However, it is important to emphasize that the theoretical ‘flexibility’ of the model-based system is in its ability to recombine the learned associations, applying them in novel contexts to novel goals: it is fundamentally about what is learned (e.g., a world model rather than a fixed policy) rather than how quickly. The question over what timescale any associations are learned is distinct from this issue – indeed, much previous work <xref ref-type="bibr" rid="pcbi.1003387-Simon1">[57]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Behrens1">[68]</xref> implies that the learning rate should normatively be controlled by factors such as the volatility of the environment and the reliability of observations. In this context, the learning rate measures the degree to which the model-based system can draw on experiences learned from the far past, in applying them to these novel contexts. A low learning rate indicates a long memory; a higher learning rate indicates a shorter memory.</p>
<p>The mechanisms which might give rise to these learning dynamics are an interesting topic for further research. Here, we have provided evidence that hippocampally-learned information is used in behavior via fetching memories of past transition events. That these candidate transition events might be drawn from memories stretching over tens of trials (spanning under a minute) into the past is well within understood capacity limitations of the hippocampal memory system. (For a further treatment of these issues, see the <xref ref-type="sec" rid="s3">discussion</xref> provided in our previous paper using this task <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>.)</p>
</sec><sec id="s3c">
<title>Anticipatory activation of stimulus representations</title>
<p>In category-selective regions of the ventral visual cortex, we observed reinstatement of stimulus-stimulus associations in a manner that was modulated by task demands, across our two different tasks. Over the sequential response trials, we observed that BOLD activity correlated with stimulus expectations in category-selective regions of the ventral visual stream. Specifically, activity in face- (or house-) selective regions of extrastriate visual cortex were also preferentially modulated by the expectation that the face (or house) image would appear next. The finding that activity parametrically fluctuates with stimulus predictions in both hippocampus and the ventral visual areas — and that the learning rates explaining these effects match one another — provides evidence that both areas are participating in a common associative learning process. At a more mechanistic level, it may be possible to interpret both entropy-related activity in hippocampus and probability-related activity in the ventral visual areas in terms of associative spreading that activates the representations of likely successors to the currently observed image.</p>
<p>On its face, the finding that anticipatory activity in the ventral areas <italic>decreases</italic> with conditional probability might seem to run counter to such a mechanism. That is, one might expect that, if probability is attributed largely to a single image, then the representation of that image should be more strongly activated. The contrary observation could be explained by a similar mechanism to the one that has been offered to explain ‘repetition suppression’ of BOLD (and spiking) responses <xref ref-type="bibr" rid="pcbi.1003387-Li1">[69]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Wiggs1">[70]</xref>. Here, a more narrowly tuned population could be recruited for more strongly expected stimuli. However, this explanation is insufficient to explain the parallel anticipatory activation we observe during choice trials, which are presumably the result of a common mechanism for anticipatory retrieval in the service of behavior.</p>
<p>A different interpretation of the effect is suggested by envisioning stimulus prediction as an active process of accessing memories. In particular, previously observed successors might be stochastically retrieved in a likelihood-weighted fashion to build up a statistical profile of the subsequent image, with this mnemonic evidence accumulated in a manner analogous to diffusion-to-bound models of perceptual discrimination <xref ref-type="bibr" rid="pcbi.1003387-Gold1">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-McClure2">[71]</xref>. This idea is consistent with suggestions that anticipatory activity in category regions is driven by evidence accumulation <xref ref-type="bibr" rid="pcbi.1003387-Summerfield1">[72]</xref>. If such a process terminates when evidence reaches some threshold, then spiking activity would be elevated only over a shorter interval of time and, thus, on trials with strong evidence observed signal would be lower when integrated over the length of the hemodynamic response <xref ref-type="bibr" rid="pcbi.1003387-Philiastides1">[73]</xref>.</p>
<p>The activity of these same category-selective regions during the decision trials could be understood in a similar manner, in terms of retrieving memories to evaluate candidate actions. Here, activity in the face (and house) areas of ventral visual cortex correlated with our measure of the <italic>difficulty</italic> of deciding whether the choice of that stimulus would lead to reward. This observation supports a model where evaluation of decision options occurs by bounded accumulation of evidence — memories stochastically sampled to evaluate the likely consequences of a choice (here, the successor image and its reward status).</p>
</sec><sec id="s3d">
<title>Episodic retrieval in forward search</title>
<p>Our aggregate (as opposed to stimulus-specific) choice difficulty measure was also positively correlated with activity in the anterior MPFC and posterior cingulate cortex. Activations under our reporting threshold were also observed in dorsal MPFC and anterior and posterior hippocampus. These regions together comprise the fronto-temporal memory component of the well-known “default network” <xref ref-type="bibr" rid="pcbi.1003387-Kahn1">[28]</xref>. Although originally characterized by its increased, coherent, activity during periods of rest, a role in deliberative evaluation is consistent with functional hypotheses for this network, in which activity is modulated by prospective or constructive memory. Tying together experimental data from multiple levels of observation and across task and rest modalities, Buckner &amp; Carroll <xref ref-type="bibr" rid="pcbi.1003387-Buckner1">[26]</xref> suggest the default network “enables mental exploration of alternative perspectives based on our past experiences”, a proposal they expanded on in later discussions <xref ref-type="bibr" rid="pcbi.1003387-Buckner2">[27]</xref>. Burgess <xref ref-type="bibr" rid="pcbi.1003387-Burgess1">[74]</xref> offers a complementary suggestion for one component of the network, proposing that BA10 in particular acts as a ‘gateway’ between a focus on internal (e.g., mnemonic) and external (e.g., sensory) representations. These proposals — along with observations of hippocampus and default network activity during look-ahead planning <xref ref-type="bibr" rid="pcbi.1003387-Schacter1">[75]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-GuitartMasip1">[77]</xref> — concord with our interpretation of the choice difficulty correlate as reflecting reinstatement of prior experiences.</p>
<p>Finally, by offering a closer look at how the brain employs associations in the service of model-based decision making, our study suggests a route toward addressing one key puzzle in this area. To wit, whereas simple reward learning has a straightforward neural implementation (embodied in model-free temporal difference theories and relatives <xref ref-type="bibr" rid="pcbi.1003387-Schultz1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Houk1">[78]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Frank1">[79]</xref>), and the inference that these be accompanied by model-based choice is well established <xref ref-type="bibr" rid="pcbi.1003387-Daw1">[3]</xref>, the mechanism by which the brain actually implements such computations remains opaque. The idea we have advanced above, that successor states are retrieved stochastically (see also <xref ref-type="bibr" rid="pcbi.1003387-Johnson1">[45]</xref>), and their values integrated, connects directly with known neural mechanisms. In particular, although the idea of model-based planning as a mnemonic version of evidence accumulation differs at least superficially from more abstract conceptualizations based on tree search <xref ref-type="bibr" rid="pcbi.1003387-Daw1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Keramati1">[80]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Wunderlich1">[81]</xref> or Bayesian inference <xref ref-type="bibr" rid="pcbi.1003387-Botvinick1">[82]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Solway1">[83]</xref>, sampling from successor states provides a more realizable process-level account of model-based evaluation in circumstances (such as chess) when the full set of future trajectories is too large to explore systematically. Moreover, it connects closely with evidence accumulation mechanisms that are well studied in the context of perceptual decision making, and comports with other suggestions that sampling or diffusion models apply to value-based decisions as well <xref ref-type="bibr" rid="pcbi.1003387-Kahn1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Rangel1">[84]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Bornstein2">[87]</xref>. It also joins those ideas with a literature suggesting that episodic memories can influence decisions <xref ref-type="bibr" rid="pcbi.1003387-Addis1">[46]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Wimmer2">[56]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Peters1">[88]</xref>.</p>
</sec></sec><sec id="s4" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Participants</title>
<p>Twenty-four right-handed individuals (twelve female; ages 18–40 years, mean 28) participated in the study. All had normal or corrected-to-normal vision. All participants received a fixed fee of $40 unrelated to performance, for their participation in the experiment, plus additional compensation of between $0 and $40 depending on their performance in one pseudorandomly-selected decision round. Participants were recruited from the New York University community as well as the surrounding area and gave informed consent in accordance with procedures approved by the New York University Committee on Activities Involving Human Subjects.</p>
<sec id="s4a1">
<title>Exclusion criteria</title>
<p>Data from seven participants were excluded from analysis due to their being unusable for various reasons, leaving seventeen participants analyzed here. For three participants, this was due to failure to behaviorally demonstrate learning of the sequential contingencies embedded in the task. As we did in our previous study <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, we excluded subjects for failure to learn when a regression model with only nuisance regressors (the ‘constant’ model) proved a statistically superior explanation of participant RTs than any of the other models considered here, which each include regressors of interest specifying the estimated conditional probability of images (see <italic>Analysis</italic>, below). Statistical superiority over the constant model was measured by the Bayesian Information Criterion (BIC; <xref ref-type="bibr" rid="pcbi.1003387-Schwarz1">[89]</xref>), used to correct likelihood scores when comparing models with different numbers of parameters. The rationale for excluding these subjects was that if they fail to learn the contingencies, it is not possible to ask the central question of the present study: how they use this learning to guide choices.</p>
<p>For the others, data were unusable due to operator error in operating the MRI unit (one participant), excessive head motion (two participants) and a failure to enter decisions on choice trials due to misunderstood instructions (one participant). Volumes during which instantaneous motion was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e075" xlink:type="simple"/></inline-formula> mm in any direction were excluded from analysis. Data from participants were excluded due to excessive motion when a large percentage (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e076" xlink:type="simple"/></inline-formula>) of volumes were excluded by this criterion.</p>
</sec></sec><sec id="s4b">
<title>Task design</title>
<p>Participants performed a serial reaction time (SRT) task in which they observed a sequence of image presentations and were instructed to respond using a pre-trained keypress assigned to that image. The experiment was controlled by a script written in Matlab (Mathworks, Natick, MA, USA), using the Psychophysics Toolbox <xref ref-type="bibr" rid="pcbi.1003387-Brainard1">[90]</xref>. The stimulus set consisted of four grayscale images that were matched for size, contrast, and luminance. The images were chosen because they represent categories known to preferentially engage different areas of the ventral visual stream — bodies <xref ref-type="bibr" rid="pcbi.1003387-Downing1">[32]</xref>, faces <xref ref-type="bibr" rid="pcbi.1003387-Kanwisher1">[33]</xref>, houses <xref ref-type="bibr" rid="pcbi.1003387-Epstein1">[34]</xref>, and household objects <xref ref-type="bibr" rid="pcbi.1003387-Malach1">[35]</xref>. Each participant viewed the same four images. During behavioral training, the keys corresponded to the innermost fingers on the home keys of a standard USA-layout keyboard (D, F, J, K). Participants were instructed to learn the responses as linking a finger and an image, rather than a key and an image (e.g. left index finger, rather than ‘F’). For the MRI sessions, the same fingers were used to respond on two MR-compatible button boxes. The mappings between the four images and four responses were one-to-one, pseudorandomly generated for each participant prior to their training session, trained to the criterion prior to the fMRI session, and fixed throughout the course of training and experiment sessions. Participants were informed that the key-to-image mapping was fixed, and that they were not being evaluated on the correctness of responses.</p>
<p>At each trial, one of the pictures was presented in the center of the screen, where it remained for three seconds, plus or minus uniformly distributed pseudorandom jitter, up to 474 ms in increments of 59 ms (the length of one slice in the MRI session). Participants were instructed to continue pressing keys until they responded correctly or ran out of time. Correct responses triggered a gray bounding box which appeared around the image for the lesser of 300 ms or the remaining trial time (<xref ref-type="fig" rid="pcbi-1003387-g001">Figure 1</xref>). Thus, each image presentation occurred for the programmed amount of time, regardless of participant response. The inter-trial interval consisted of 237 ms of blank screen.</p>
<p>The test phase of the scanning session proceeded with three blocks of 250 trials: 210 sequential response trials, 20 reward display screens (see <italic>Choice trials</italic>, below) and 20 choice trials. The first two blocks were followed by a rest period of participant-controlled length. During the rest period, participants were presented with a screen that was blank except for a fixation cross. Scan blocks after the first were initiated manually by the operator only after the participant pressed any of the relevant keys twice, to alert the operator that they were prepared to continue the task. Total experiment time — inclusive of training, practice and test periods — was approximately 1.5 hours, conducted continuously.</p>
<sec id="s4b1">
<title>Stimulus sequence</title>
<p>For training, the sequence of images was selected according to a uniform distribution. Participants were instructed to emphasize learning the mappings between image and finger, disregarding speed of response in favor of correctly identifying the on-screen image.</p>
<p>In the test phase, participants were instructed to respond as quickly as they could, disfavoring accuracy as they had already been trained to criterion. The sequence of images was generated pseudorandomly according to a first-order Markov process, meaning that the probability of viewing a particular image was solely dependent on the identity of the previous image, with the conditional relationship specified by a 4×4 transition matrix (<xref ref-type="fig" rid="pcbi-1003387-g001">Figure 1</xref>). To motivate the choice trials, unlike in our previous study <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, participants were informed that conditional probability structure existed in the task. Four transition matrices were generated pseudorandomly at the start of the experiment for each subject, in a manner designed to balance two priorities: (i) to equalize the overall presentation frequencies for each image over the long and medium term (formally: fast mixing to a uniform stationary distribution), while (ii) examining response properties across a wide sample of conditional image transition probabilities. The procedure used to generate matrices satisfying these constraints is described in detail in our previous study <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>.</p>
<p>Transition matrices were replaced at three evenly-spaced intervals — the second matrix was used starting on trial 188, the third matrix on trial 376, and the fourth on trial 563. Participants were informed that the structure would change, but they were not informed of when or how. The experiment display offered no indication of the shift to a different transition matrix, nor were matrix changes aligned with the onset of rest periods.</p>
<p>Time to first keypress was recorded as our primary behavioral dependent variable. Participants were not informed that RTs were being recorded, and no information was provided as to overall accuracy or speed either during or after the experiment. Trials on which the first keypress was incorrect were discarded from behavioral analysis.</p>
</sec><sec id="s4b2">
<title>Choice trials</title>
<p>Twenty choice rounds were interspersed throughout each of the three scanning sessions, for sixty choice rounds total per participant. Each choice round consisted of three parts (<xref ref-type="fig" rid="pcbi-1003387-g002">Figure 2</xref>). First, the reward display screen, visible for one second, notified the participant of which image was going to be rewarded and how much each occurrence of it would be worth. The rewarded image was chosen pseudorandomly from a uniform distribution over potential images. Reward values were whole dollar values between one and five, chosen pseudorandomly from a uniform distribution. Next, after a variable inter-stimulus interval of between two and eight seconds, chosen from a truncated exponential distribution with a mean of four, the participant was given five seconds to select between one of two <italic>different</italic> images. The two option images were chosen pseudorandomly from a uniform distribution, with the condition that they not be identical to the reward image. Participants were instructed to choose the image that was most likely to get them to the reward over the next few trials, and thereby earn the most money. Immediately after the choice was entered, the subsequent image was picked according to the conditional distribution implied by the image that the participant selected. The next image was then displayed after the standard ITI of 237 ms. Beginning with this first image after the choice — the ‘outcome’ image — text above each ensuing image indicated either a dollar amount (between $1 and $5), if it was the rewarded image, or $0 if it was not (<xref ref-type="fig" rid="pcbi-1003387-g002">Figure 2</xref>), for the extent of the choice round. The length of the choice round — that is, the number of images presented with dollar figures above them — was chosen from a truncated exponential distribution, with minimum of one, a maximum of eight and a mean of four, and adjusted to ensure a total of 80 trials across all of the choice rounds in a each session. To allow for equilibration of any transient effects, choice rounds did not occur within the first thirty trials of each scanning session.</p>
</sec></sec><sec id="s4c">
<title>Analysis</title>
<p>Our analysis proceeded in several steps meant to first characterize the associative learning process, and then use this characterization to test behavioral and neural predictions about choices. Each participant's trial-by-trial RTs for correct identifications were regressed on explanatory variables including the estimated conditional probability of the picture currently being viewed given its predecessor — defined, in separate models (described below), in a number of different ways representing different accounts of learning — together with several effects of no interest. Trials on which the first keypress was not correct were excluded from behavioral analysis. Effects of no interest included stimulus-self transitions, image identity effects and a linear effect of trial number. Stimulus-self transitions were included to account for variance due to motor response readiness for the same keypress appearing twice in a row, above and beyond the preparation implied by any effect of the variables of interest. Image identity effects were included to account for any differential response time by each finger. Trial number effects were included to account for any monotonic shift in response time over the course of the experiment. These nuisance effects were identical across all models considered; the models differed in how they specified the explanatory variable of interest, the conditional probability of each image. In our initial analysis, the conditional probabilities were specified as the ground-truth contingencies: the probabilities actually encoded in the transition matrix. Having established that RT reflected such learning by demonstrating a significant correlation with these idealized probabilities (<xref ref-type="fig" rid="pcbi-1003387-g002">Figure 2</xref>), subsequent analyses used computational models to generate a timeseries of probability estimates such as would be produced by different learning rules with the same experience history as the participant (see <italic>Learning models</italic> for details). Similarly, the learning rules for conditional probability were fit (separately) to choices in the decision trials, estimated so as to maximize the likelihood that the model would have selected the same options as did the participant, given the same series of experience (see <italic>Choice models</italic> for details).</p>
<p>The learning models involved additional free parameters controlling the learning and decision processes (e.g. learning rates), which were jointly estimated together with the regression weights by maximum likelihood. For behavioral analysis, models were fit and parameters were estimated separately for each participant. At the group level, regression weights were tested for significance using a t-test on the individual estimates across participants <xref ref-type="bibr" rid="pcbi.1003387-Holmes1">[91]</xref>. To generate regressors for fMRI analysis (below) we refitted the behavioral model to estimate a single set of the parameters that optimized the RT and choice likelihoods aggregated over all participants (i.e. treating the behavioral parameters as fixed effects). This approach allowed us to characterize baseline learning-related activity separate from individual variation in neurally implied learning rates relative to this common baseline. For the former, in our experience <xref ref-type="bibr" rid="pcbi.1003387-Daw2">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Daw3">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Daw4">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Simon2">[92]</xref>–<xref ref-type="bibr" rid="pcbi.1003387-Gershman1">[95]</xref>, enforcing common model parameters provides a simple regularization that improves the reliability of population-level neural results. Our neural model characterizes between-subjects variation in the learning rate parameter over this baseline, because it includes (as additional random effects across participants) the partial derivatives of each of the regressors of interest with respect to the learning rate.</p>
<sec id="s4c1">
<title>Learning models</title>
<p>Based on our previous results analyzing contingency learning in an SRT task <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, we considered learning rules of the form proposed by Rescorla and Wagner <xref ref-type="bibr" rid="pcbi.1003387-Rescorla1">[17]</xref> (see also <xref ref-type="bibr" rid="pcbi.1003387-Glscher1">[15]</xref>), which update entries in a 4×4 stimulus-stimulus transition matrix in light of each trial's experience. The appropriate estimate from this matrix at each step was then used as an explanatory variable for the RTs in place of the ground-truth probabilities.</p>
<p>Formally, at each trial the transition matrix was updated according to the following rule, for each image <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e077" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003387.e078"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003387.e078" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e079" xlink:type="simple"/></inline-formula> is the identity of the image observed at trial <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e080" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e081" xlink:type="simple"/></inline-formula> is a free learning-rate parameter. This rule preserves the normalization of the estimated conditional distribution.</p>
<p>Our primary model of interest for reaction times — again, drawn from our previous work <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref> — was a weighted combination of two Rescorla-Wagner processes, each with different values of the learning rate parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e082" xlink:type="simple"/></inline-formula>.</p>
<p>Each process updated its matrix as above, independently, but the behaviorally expressed estimate of conditional probability was computed by combining the output of each process according to a weighted average with weight (a free parameter) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e083" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003387.e084"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003387.e084" xlink:type="simple"/><label>(2)</label></disp-formula></p>
<p>As the models considered here differ in the number of free parameters, we compared their fit to the reaction time data using Bayes factors (<xref ref-type="bibr" rid="pcbi.1003387-Kass1">[96]</xref>; the ratio of posterior probabilities of the model given the data) to correct for the number of free parameters fit. We approximated the log Bayes factor using the difference between scores assigned to each model via the Laplace approximation to the model evidence <xref ref-type="bibr" rid="pcbi.1003387-Mackay1">[97]</xref>. This approximation was used because it provides a more fair comparison across models which use parameters of differing contributions to model complexity <xref ref-type="bibr" rid="pcbi.1003387-Boone1">[98]</xref>. The evidence calculations assumed a uniform prior distribution for the values of the learning rate and weight parameters. In participants for whom the Laplace approximation was not estimable for any model (due to a non-positive definite value of the Hessian of the likelihood function with respect to parameters) the Bayesian Information Criterion <xref ref-type="bibr" rid="pcbi.1003387-Schwarz1">[89]</xref> was instead used to estimate the posterior probabilities for all models. Model comparisons were computed both per individual, and on the log Bayes factors aggregated across the population.</p>
</sec><sec id="s4c2">
<title>Choice models</title>
<p>Each of the learning rates obtained from fitting reaction times also predicts a different series of option preferences on choice trials. We compared the relative fit to choice behavior of probability estimates at each learning rate or combination of learning rates. Each choice trial involves the choice between two options for the start image, which we index below as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e085" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e086" xlink:type="simple"/></inline-formula>, and a rewarded image, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e087" xlink:type="simple"/></inline-formula>.</p>
<p>We took as the decision variable the difference between the probability that each option would lead to the rewarded image in a single step: (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e088" xlink:type="simple"/></inline-formula>), where the probabilities are the conditional image transition probabilities estimated by the learning model at the current point in the task. Motivated by race and sampling models <xref ref-type="bibr" rid="pcbi.1003387-Ratcliff1">[18]</xref>, the model instantiates the decision variable on a particular trial by conducting some number <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e089" xlink:type="simple"/></inline-formula> of draws from a binomial distribution around each learned transition probability. The mean proportion of successes on the first option is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e090" xlink:type="simple"/></inline-formula>, with binomial variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e091" xlink:type="simple"/></inline-formula>, and similarly for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e092" xlink:type="simple"/></inline-formula>. We estimate the choice likelihood by adopting a Gaussian approximation to the binomials, so that the resulting decision variable (the difference in sample proportions) has a mean and variance given by the difference and sum, respectively, of the means and variances of the two sample proportions. We compute the likelihood that the subject chooses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e093" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e094" xlink:type="simple"/></inline-formula> using the CDF of this Gaussian, and aggregate the log probabilities for the options actually chosen across the experiment to compute the likelihood of the choices given different probability learning models and parameters.</p>
<p>As fMRI regressors, we also use this model to define the per-trial choice difficulty as the variance of the decision variable (the sum of the binomial variances), and the per-category choice difficulty as the binomial variance of that category's probability estimate.</p>
</sec></sec><sec id="s4d">
<title>fMRI methods</title>
<sec id="s4d1">
<title>Acquisition</title>
<p>Imaging was performed on the 3T Siemens Allegra head-only scanner at the NYU Center for Brain Imaging, using a Nova Medical (Wakefield, MA, USA) NM011 head coil. For functional imaging, 40 T2*-weighted axial slices of 3 mm thickness and 3 mm in-plane resolution were acquired using a gradient-echo EPI sequence (TR = 2.37 seconds). Three scans of 400 acquisitions each were collected, with the first four volumes (9.48 seconds) discarded to allow for T1 equilibration effects. We also obtained a T1-weighted high-resolution anatomical image (MPRAGE, 1×1×1 mm) for normalization and localizing functional activations.</p>
</sec><sec id="s4d2">
<title>Imaging analysis</title>
<p>Preprocessing and data analysis were performed using Statistical Parametric Mapping software version 8 (SPM8; Wellcome Department of Imaging Neuroscience, London, UK). EPI images were realigned to the first volume to compensate for participant motion, co-registered to the anatomical image, and, to facilitate group analysis, spatially normalized to atlas space using a transformation estimated by warping the subject's anatomical image to match a template (SPM8 segment and normalize). Following the default settings in SPM, to account for warping due to normalization to the template image, data images were resampled to 2 mm (rather than 3 mm) isotropic voxels, in the normalized space <xref ref-type="bibr" rid="pcbi.1003387-Josephs1">[24]</xref>. Finally, data were smoothed using a 6-mm full-width at half maximum Gaussian filter. For statistical analysis, data were scaled to their global mean intensity and high-pass filtered with a cutoff period of 128 seconds. Volumes during which instantaneous motion was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e095" xlink:type="simple"/></inline-formula> mm in any direction were excluded from analysis.</p>
</sec><sec id="s4d3">
<title>Statistical analysis</title>
<p>Statistical analyses of functional time-series were conducted using general linear models (GLM), and coefficient estimates from each individual were used to compute random-effects group statistics. Delta-function onsets were specified at the beginning of each stimulus presentation, and — to control for lateralization effects — nuisance onsets were specified for presentations on which right-handed responses were required. This had the effect of mean-correcting these trials separately. All further regressors were defined as parametric modulators over the initial, two-handed stimulus presentation or choice onsets. All regressors were convolved with SPM8's canonical hemodynamic response function. We used two separate GLMs for our main body of analyses: first, one analyzing sequential and response trials collectively, and a second breaking them down by image category.</p>
<p>In these GLMs we specify a number of parametric regressors derived from the model, often together with these regressors' partial dervatives with respect to the learning rate parameter. For the main analyses, all such regressors were evaluated using a (single) learning rate taken at the midpoint between the two identified in our best-fitting behavioral model, the two-learning rate model of <xref ref-type="disp-formula" rid="pcbi.1003387.e078">Eqns 1</xref> and <xref ref-type="disp-formula" rid="pcbi.1003387.e084">2</xref>. This enables us to detect activations related to these regressors without a bias toward one learning rate or the other, then use the partial derivatives to estimate the learning rate that best explains the signal (see <italic>Learning rate analysis</italic>).</p>
<p>We also performed ancillary GLM analyses to illustrate activations related to regressors computed using either learning rate identified in RT behavior. For these, the parametric regressors were substituted with the equivalent ones evaluated at one of those learning rates and the partial derivative regressors were omitted. Such analyses were carried out in separate GLMs due to correlation between regressors generated using different values of the learning rate parameter. However, it is important to note that these models were only used for generating figures to visualize the spatial extent of activity. Our formal results fitting learning rates to activity and comparing these estimates between areas are each conducted within a single GLM whose regressors (the main explanatory variable of interest and its partial derivative with respect to learning rate) in different weighted sums together approximately span the continuum of learning rates (see <italic>Learning rate analysis</italic>).. This allows the fit of different learning rates to an area to be formally assessed in a single model, while avoiding the problems of correlation between regressors and of specifying a discrete set of candidate learning rates a priori.</p>
<p>In all analyses, unless otherwise stated, activations are reported for areas where we had a prior anatomical hypothesis at a threshold of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e096" xlink:type="simple"/></inline-formula> after correction for family-wise error (FWE) in a small volume defined by constructing an anatomical mask, comprising the regions of a priori interest. Our anatomical regions of a priori interest were: left hippocampus for slow process associations and bilateral caudate for fast process associations, based on our previous results <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>; right ventral stream cortical regions for visual localizer responses and anticipatory recall of category representations: fusiform gyrus, parahippocampal gyrus, and inferior occipital lobe, based on previous reports of visual category-selective patches of cortex — bodies <xref ref-type="bibr" rid="pcbi.1003387-Downing1">[32]</xref>, faces <xref ref-type="bibr" rid="pcbi.1003387-Kanwisher1">[33]</xref>, houses <xref ref-type="bibr" rid="pcbi.1003387-Epstein1">[34]</xref>, and household objects <xref ref-type="bibr" rid="pcbi.1003387-Malach1">[35]</xref>; and nucleus accumbens, based on numerous previous reports of Reward Prediction Error (e.g. <xref ref-type="bibr" rid="pcbi.1003387-ODoherty1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-McClure1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Daw4">[38]</xref>). Anatomical regions were defined using the Automated Anatomical Labeling (AAL) atlas <xref ref-type="bibr" rid="pcbi.1003387-TzourioMazoyer1">[99]</xref>, except nucleus accumbens, which was taken from the mask produced in <xref ref-type="bibr" rid="pcbi.1003387-Daw4">[38]</xref>. Masks were dilated by 4 mm in all directions to allow for inconsistencies in alignment with the population mean structural image. Unless otherwise stated, activations outside regions of prior interest are reported if they exceed a threshold of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e097" xlink:type="simple"/></inline-formula>, whole-brain corrected for family-wise error. All voxel locations are reported in MNI coordinates, and results are displayed overlaid on the average over participants' normalized anatomical scans.</p>
</sec><sec id="s4d4">
<title>GLM1: Main effects</title>
<p>The first GLM was used to analyze main effects of sequential response and choice trials. It contained the following regressors. First, to control for non-specific effects of reaction time (which, as demonstrated by our behavioral results, was correlated with our primary regressor of interest, the conditional probability), the RT on each sequential response trial was entered into the design matrix as a parametric nuisance effect. As a result all subsequent regressors, including all regressors of interest, were orthogonalized against this variable, ensuring that it accounted for any shared variance. We next included the conditional probability of the current image, to control for effects of surprise on the current trial. Building on our previous work <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, this regressor was not treated as a regressor of interest in our current experiment. Our primary regressor of interest on sequential response trials was the entropy of the distribution over the subsequent stimulus, given the image <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e098" xlink:type="simple"/></inline-formula> currently viewed:<disp-formula id="pcbi.1003387.e099"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003387.e099" xlink:type="simple"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e100" xlink:type="simple"/></inline-formula> denotes the image displayed on trial t, but the sum is over all four possible image identities, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e101" xlink:type="simple"/></inline-formula>. Whereas the conditional probability measures how ‘surprising’ is the current stimulus, this quantity, which we refer to as the ‘forward entropy’, measures the ‘expected surprise’ for the next stimulus conditional on the current one, i.e. the uniformity of the conditional probability distribution.</p>
<p>The entropy regressor was followed by the partial derivative of this forward entropy, with respect to the learning rate (see <italic>Learning rate analysis</italic>). Finally, nuisance regressors, last in orthogonalization priority, were entered to model variance due to the effects of: missed trials (those in which the participant did not press any keys in the allotted time), error trials, and self-transition trials (house-house, etc.).</p>
<p>For decision analysis, we specified onsets at the time of the presentation of the two options, and also at the first trial of the reward round, referred to as the ‘outcome’ trial. At the time options were presented, we first specified nuisance regressors: the reaction time of the choice, and the value of the rewarded image (between $1 and $5). Last were our primary regressors of interest: the difficulty of the choice (see <italic>Choice models</italic>), and the partial derivative of this regressor with respect to learning rate.</p>
<p>On outcome trials, we specified as a nuisance regressor the reaction time of the response. Following was our primary regressor of interest, the Reward Prediction Error (RPE): the reward received minus the expected value of the image chosen (the probability of receiving the reward image times the round's reward value), and its partial derivative with respect to learning rate.</p>
</sec><sec id="s4d5">
<title>GLM2: Image-specific effects</title>
<p>We used a second GLM to analyze image-specific effects in sequential response and choice trials. Critically, nuisance onsets were specified for trials on which each image category was presented. Additional nuisance onsets were specified for right handed choices and sequential responses, to control for effects of lateralization.</p>
<p>Onsets of interest were specified for sequential response and choice trials. For these analyses, we specified a set of four parametric regressors, one for each image type, over the sequential response and choice onsets. As we did not want our analysis to implicitly prioritize one or another variable, we disabled SPM's serial orthogonalization. On sequential response trials, our regressors of interest were the anticipated probability of each image — body, face, house, object — occuring next. We specified reaction time as a regressor of no interest, along with regressors for missed trials, errors, and self-self trials.</p>
<p>For choice trial onsets, we specified as the primary regressors of interest the choice difficulty for each category separately (see <italic>Choice models</italic>). Separate timeseries for the difficulty of deciding whether each image led to reward were modeled at every decision period (irrespective of whether that image was part of the decision set), and entered as parametric modulators over these onsets. Subsequent nuisance regressors were entered for the identity of the images on the screen, the identity of the rewarded image, the image categories used as options, the reward value, and the expected value of the decision. Again, these regressors were not orthogonalized against one another.</p>
<p>We also considered the possibility that analyses testing probability effects (<xref ref-type="fig" rid="pcbi-1003387-g007">Figure 7</xref>) were biased by selecting face- and house-sensitive voxels, then testing the effect of interest in those voxels in the same trials <xref ref-type="bibr" rid="pcbi.1003387-Kriegeskorte1">[100]</xref>. Accordingly, we measured the correlation between the selecting and testing regressors in the final design matrix. After filtering and whitening, the selecting and testing contrasts were not strongly correlated, and the mean of the measured correlation is in the opposite direction of the effect we observed (mean correlation coefficient across subjects: 0.1399+/−0.0238 for the face regressors, 0.0765+/−0.0308 for the house regressors). That is, to whatever extent there is a bias due to voxel selection, it would tend to work <italic>against</italic> the result we obtained.</p>
</sec><sec id="s4d6">
<title>Learning rate analysis</title>
<p>In the best-fitting behavioral model, the learned transition matrix arises from two modeled learning processes, each with a free parameter for its learning rate. Thus, a naive attempt to seek fMRI activations related to either hypothesized process separate from the other would need two separate but correlated sets of our various model-derived regressors of interest, such as entropy in sequential response trials and RPE on outcome trials. An alternative specification allows us to evade the problem of mutual correlation while also reasoning statistically about the learning rate that best explains BOLD activity related to a particular variable in a particular area.</p>
<p>To do this, we specify each regressor of interest in our GLMs together with its partial derivative with respect to the learning rate parameter. The weighted sum of these two regressors approximates (linearly, using a first-order Taylor expansion) how the modeled signal would change under different values of the learning rate parameter. Conversely, the best fitting learning rate can be approximated from the betas obtained for the two regressors <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Daw3">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003387-Friston1">[101]</xref>. Each regressor and its partial derivative were evaluated at the learning rate midway between the two behaviorally-obtained rate. The regression weight estimated for the derivative measures how far from the midpoint, and in which direction, was the learning rate that best explained BOLD. This analysis allowed us to formally investigate the possibility that learning rates expressed across regions of the brain (and multiple distinct computational variables) differed from one another, identify the pattern by which these learning rates varied, and compare them to the learning rates obtained from behavior.</p>
<p>Specifically, we constructed the regressors of interest as estimated by a single process learning at the rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e102" xlink:type="simple"/></inline-formula> — which we set to the average of the two behaviorally identified rates — and included an additional regressor measuring how the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e103" xlink:type="simple"/></inline-formula> regressors would change if they had been generated from the model with a different learning rate. Technically, we defined these additional regressors as the partial derivatives of the original timeseries with respect to the learning rate parameter, evaluated at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e104" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003387-Friston1">[101]</xref>. This analysis allows us to estimate the change in learning rate, relative to the reference point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e105" xlink:type="simple"/></inline-formula>, that would best explain BOLD in an area, by using a regression to estimate coefficients for the first two terms in the Taylor expansion of the dependence of the regressor on the learning rate. This takes the following form:<disp-formula id="pcbi.1003387.e106"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003387.e106" xlink:type="simple"/><label>(4)</label></disp-formula></p>
<p>Here F(<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e107" xlink:type="simple"/></inline-formula>) is the regressor of interest (i.e., the RPE or entropy timeseries), viewed as a function of the learning rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e108" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e109" xlink:type="simple"/></inline-formula> is some other learning rate for which the regressor would best fit the BOLD signal. To encode learning rates in this analysis, we used a change in variables by which the original Rescorla-Wagner learning rate was transformed by an inverse sigmoid, so that it ranged through the real numbers and estimates of it could be treated with Gaussian statistics. Thus, the learning rates reported from the fMRI response to the partial derivative (which includes a derivative of the sigmoid transform, by the chain rule), are sigmoid-transformed means of the underlying variable, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e110" xlink:type="simple"/></inline-formula>. Similarly, the illustrated confidence bounds are the sigmoid-transformed S.E.M.s of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e111" xlink:type="simple"/></inline-formula>.</p>
<p>This linear approximation to the (nonlinear) relationship between the regressor and the learning rate parameter allows the use of a GLM to approximately estimate the learning rates that would best explain BOLD correlates to the regressor. In particular, the weight estimated for the partial derivative regressor corresponds to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e112" xlink:type="simple"/></inline-formula> (or, more particularly, k[<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e113" xlink:type="simple"/></inline-formula>], if the net effect of the regressor on BOLD is scaled by multiplying both sides of the approximation by some factor k). This is just the degree to which the best-fit (inverse-sigmoid transformed) learning rate for explaining the BOLD response differs from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e114" xlink:type="simple"/></inline-formula>, the value used to calculate our regressor of interest and its derivative.</p>
<p>We thus computed estimates of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e115" xlink:type="simple"/></inline-formula> for each regressor (entropy or probability) at a voxel by first extracting the regression weights for the partial derivative regressor for each subject. To normalize these coefficients to a common scale in units of transformed learning rate (even if they originated from different regions), we divided these weights by the average, across subjects, of the regression weights for the corresponding regressor F(<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e116" xlink:type="simple"/></inline-formula>) at the voxel, this corresponding to the overall scale factor k mentioned above. Lastly, we added the reference value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e117" xlink:type="simple"/></inline-formula>, converting the result into the range of our behaviorally-obtained rates. Our statistical analyses were all performed on the learning rate estimates in the transformed units, taken across the population. Specifically, we test whether the computed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e118" xlink:type="simple"/></inline-formula> is statistically distinguishable from learning rate values obtained by fitting behavior, via t-tests against each (transformed) fit rate. We also test whether <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e119" xlink:type="simple"/></inline-formula> differs between regions, by comparing the estimates in paired-sample t-tests. For our plots of BOLD learning rates, we mapped the mean estimates and their confidence intervals through the sigmoid to depict them in units of Rescorla-Wagner learning rate.</p>
<p>To maximize power, to examine learning-rate effects at areas where there was learning-related activity, and to identify areas to allow between-region comparisons, we performed these analyses of leraning rates at voxels that we selected as peaks of contrasts on the main effect of the conditional probability, entropy, or prediction error regressors (not their derivatives), again using the midpoint rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e120" xlink:type="simple"/></inline-formula>. This was one motivation for choosing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e121" xlink:type="simple"/></inline-formula> to be the midpoint of the fast and slow rates – i.e., that it is roughly equally suited to detect activity related to either rate. Additionally, the linear approximation to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e122" xlink:type="simple"/></inline-formula> is most accurate when the difference <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e123" xlink:type="simple"/></inline-formula> is small, suggesting a choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e124" xlink:type="simple"/></inline-formula> that is equally close to both relevant learning rates. We selected the voxels of peak group activation within each of our a priori regions of interest. Differences between parameters in the subsequent tests were considered reliable at a level of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e125" xlink:type="simple"/></inline-formula>.</p>
<p>Finally, note that selecting ROIs on the basis of correlation with a regressor of interest, then estimating the learning rate there, implies a bias that is innocuous with respect to our questions of interest, which generally concern to which of the extreme learning rates does the BOLD activity best correspond. It is intuitive — and can be shown <xref ref-type="bibr" rid="pcbi.1003387-Bornstein1">[7]</xref> — that the estimated learning rate is biased toward the midpoint used for selection, and therefore away from the extremes that our hypothesis tests concern.</p>
</sec></sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003387.s001" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003387.s001" position="float" xlink:type="simple"><label>Figure S1</label><caption>
<p>Multiple views of the main effects. Saggital, coronal, and axial views of each of the effects reported in the main text. Each row displays activation corresponding to one of the parametric regressors: First, the forward entropy regressor, generated using the slow process. Second, the forward entropy regressor, generated using the fast process. Third, the choice difficulty regressor (views on the hippocampal correlates). Fourth, the choice difficulty regressor (views of the mPFC and PCC correlates). Fifth, the reward prediction error regressor. All images are displayed at a threshold of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e126" xlink:type="simple"/></inline-formula>, uncorrected.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003387.s002" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003387.s002" position="float" xlink:type="simple"><label>Table S1</label><caption>
<p>Clusters greater than 10 contiguous voxels (at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e127" xlink:type="simple"/></inline-formula>) correlated with the forward entropy regressor computed at the slow learning rate.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003387.s003" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003387.s003" position="float" xlink:type="simple"><label>Table S2</label><caption>
<p>Clusters greater than 10 contiguous voxels (at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e128" xlink:type="simple"/></inline-formula>) correlated with the forward entropy regressor computed at the fast learning rate.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003387.s004" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003387.s004" position="float" xlink:type="simple"><label>Table S3</label><caption>
<p>Clusters greater than 10 contiguous voxels (at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e129" xlink:type="simple"/></inline-formula>) correlated with the choice difficulty regressor computed at the slow learning rate.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003387.s005" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003387.s005" position="float" xlink:type="simple"><label>Table S4</label><caption>
<p>Clusters greater than 10 contiguous voxels (at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003387.e130" xlink:type="simple"/></inline-formula>) correlated with the reward prediction error regressor computed at the slow learning rate.</p>
<p>(TIFF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>The authors wish to thank Thomas A. Geib for assistance with data collection, and Lila Davachi, Ernst Fehr, Paul Glimcher, Todd Gureckis, Daphna Shohamy, Arielle Tambini, Shannon Tubridy, Anthony Wagner, and Nathan Witthoft for helpful conversations.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003387-Dickinson1"><label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">Dickinson A, Balleine BW (2002) The role of learning in the operation of motivational systems. In: Gallistel CR, Pashler HV, editors. Stevens Handbook of Experimental Psychology. Vol. 3: Learning, Motivation and Emotion. New York, NY: John Wiley &amp; Sons Inc. pp. 497–533.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Dickinson2"><label>2</label>
<mixed-citation publication-type="book" xlink:type="simple">Dickinson A (1980) Contemporary Animal Learning Theory. Cambridge: Cambridge University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Daw1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>, <name name-style="western"><surname>Niv</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name> (<year>2005</year>) <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nature Neuroscience</source> <volume>8</volume>: <fpage>1704</fpage>–<lpage>1711</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Thorndike1"><label>4</label>
<mixed-citation publication-type="book" xlink:type="simple">Thorndike EL (1911) Animal Intelligence. New York: Macmillan.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Barto1"><label>5</label>
<mixed-citation publication-type="book" xlink:type="simple">Barto AC (1995) Adaptive Critics and the Basal Ganglia. In: Houk JC, Davis JL, Beiser DG, editors. Models of information processing in the basal ganglia, Cambridge, MA: MIT Press. pp. 215–232.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Schultz1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Montague</surname><given-names>PR</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name> (<year>1997</year>) <article-title>A Neural Substrate of Prediction and Reward</article-title>. <source>Science</source> <volume>275</volume>: <fpage>1593</fpage>–<lpage>1599</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Bornstein1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bornstein</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name> (<year>2012</year>) <article-title>Dissociating hippocampal and striatal contributions to sequential prediction learning</article-title>. <source>European Journal of Neuroscience</source> <volume>35</volume>: <fpage>1011</fpage>–<lpage>1023</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Bahrick1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bahrick</surname><given-names>H</given-names></name> (<year>1954</year>) <article-title>Incidental learning under two incentive conditions</article-title>. <source>Journal of Experimental Psychology</source> <volume>47</volume>: <fpage>170</fpage>–<lpage>172</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Strange1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Strange</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Duggins</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Penny</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name> (<year>2005</year>) <article-title>Information theory, novelty and hippocampal responses: unpredicted or unpredictable?</article-title> <source>Neural Networks</source> <volume>18</volume>: <fpage>225</fpage>–<lpage>230</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Harrison1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harrison</surname><given-names>LM</given-names></name>, <name name-style="western"><surname>Duggins</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name> (<year>2006</year>) <article-title>Encoding uncertainty in the hippocampus</article-title>. <source>Neural Networks</source> <volume>19</volume>: <fpage>535</fpage>–<lpage>546</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Bestmann1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bestmann</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Harrison</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Blankenburg</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Mars</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Haggard</surname><given-names>P</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Influence of contextual uncertainty and surprise on human corticospinal excitability during preparation for action</article-title>. <source>Current Biology</source> <volume>18</volume>: <fpage>775</fpage>–<lpage>80</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-TurkBrowne1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Turk-Browne</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Scholl</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Chun</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Neural evidence of statistical learning: efficient detection of visual regularities without awareness</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>21</volume>: <fpage>1934</fpage>–<lpage>45</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-TurkBrowne2"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Turk-Browne</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Scholl</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Chun</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>Implicit Perceptual Anticipation Triggered by Statistical Learning</article-title>. <source>Journal of Neuroscience</source> <volume>30</volume>: <fpage>11177</fpage>–<lpage>87</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Tolman1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tolman</surname><given-names>EC</given-names></name> (<year>1948</year>) <article-title>Cognitive Maps in Rats and Men</article-title>. <source>Psychological Review</source> <volume>55</volume>: <fpage>189</fpage>–<lpage>208</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Glscher1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gläscher</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name> (<year>2010</year>) <article-title>States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning</article-title>. <source>Neuron</source> <volume>66</volume>: <fpage>585</fpage>–<lpage>95</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Bush1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bush</surname><given-names>RR</given-names></name>, <name name-style="western"><surname>Mosteller</surname><given-names>F</given-names></name> (<year>1956</year>) <article-title>A Stochastic Model with Applications to Learning</article-title>. <source>The Annals of Mathematical Statistics</source> <volume>24</volume>: <fpage>559</fpage>–<lpage>585</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Rescorla1"><label>17</label>
<mixed-citation publication-type="book" xlink:type="simple">Rescorla RA, Wagner AR (1972) A Theory of Pavlovian Conditioning: Variations in the Effectiveness of Reinforcement and Nonreinforcement. In: Black AH, Prokasy WF, editors. Classical Conditioning II: Current research and theory. New York: Appleton-Century-Crofts. pp. 64–99.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Ratcliff1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ratcliff</surname><given-names>R</given-names></name> (<year>1978</year>) <article-title>A Theory of Memory Retrieval</article-title>. <source>Psychological Review</source> <volume>85</volume>: <fpage>59</fpage>–<lpage>108</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Lengyel1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lengyel</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name> (<year>2008</year>) <article-title>Hippocampal Contributions to Control: The Third Way</article-title>. <source>Advances in Neural Information Processing Systems</source> <volume>20</volume>: <fpage>889</fpage>–<lpage>896</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Erev1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Erev</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Glozman</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Hertwig</surname><given-names>R</given-names></name> (<year>2008</year>) <article-title>What impacts the impact of rare events</article-title>. <source>Journal of Risk and Uncertainty</source> <volume>36</volume>: <fpage>153</fpage>–<lpage>177</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Gold1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gold</surname><given-names>JI</given-names></name>, <name name-style="western"><surname>Shadlen</surname><given-names>MN</given-names></name> (<year>2002</year>) <article-title>Banburismus and the Brain: Decoding the Relationship between Sensory Stimuli, Decisions, and Reward</article-title>. <source>Neuron</source> <volume>36</volume>: <fpage>299</fpage>–<lpage>308</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Daw2"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Seymour</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name> (<year>2006</year>) <article-title>Cortical substrates for exploratory decisions in humans</article-title>. <source>Nature</source> <volume>441</volume>: <fpage>876</fpage>–<lpage>879</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Schapiro1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schapiro</surname><given-names>AC</given-names></name>, <name name-style="western"><surname>Kustner</surname><given-names>LV</given-names></name>, <name name-style="western"><surname>Turk-Browne</surname><given-names>NB</given-names></name> (<year>2012</year>) <article-title>Shaping of object representations in the human medial temporal lobe based on temporal regularities</article-title>. <source>Current Biology</source> <volume>22</volume>: <fpage>1622</fpage>–<lpage>7</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Josephs1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Josephs</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Turner</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>K</given-names></name> (<year>1997</year>) <article-title>Event-Related fMRI</article-title>. <source>Human Brain Mapping</source> <volume>5</volume>: <fpage>243</fpage>–<lpage>248</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Daw3"><label>25</label>
<mixed-citation publication-type="book" xlink:type="simple">Daw ND (2010) Trial-by-trial data analysis using computational models. In: Phelps E, Robbins T, Delgado M, editors. Affect, Learning and Decision Making, Attention and Performance. Xxiii edition. Oxford University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Buckner1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buckner</surname><given-names>RL</given-names></name>, <name name-style="western"><surname>Carroll</surname><given-names>DC</given-names></name> (<year>2006</year>) <article-title>Self-projection and the brain</article-title>. <source>Trends in Cognitive Sciences</source> <volume>11</volume>: <fpage>49</fpage>–<lpage>57</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Buckner2"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buckner</surname><given-names>RL</given-names></name>, <name name-style="western"><surname>Andrews-Hanna</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Schacter</surname><given-names>DL</given-names></name> (<year>2008</year>) <article-title>The brain's default network: anatomy, function, and relevance to disease</article-title>. <source>Annals of the New York Academy of Sciences</source> <volume>1124</volume>: <fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Kahn1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kahn</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Andrews-Hanna</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Vincent</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Snyder</surname><given-names>AZ</given-names></name>, <name name-style="western"><surname>Buckner</surname><given-names>RL</given-names></name> (<year>2008</year>) <article-title>Distinct Cortical Anatomy Linked to Subregions of the Medial Temporal Lobe Revealed by Intrinsic Functional Connectivity</article-title>. <source>Journal of Neurophysiology</source> <volume>100</volume>: <fpage>129</fpage>–<lpage>139</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Delgado1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Delgado</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Nystrom</surname><given-names>LE</given-names></name>, <name name-style="western"><surname>Fissell</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Noll</surname><given-names>DC</given-names></name>, <name name-style="western"><surname>Fiez</surname><given-names>JA</given-names></name> (<year>2000</year>) <article-title>Tracking the Hemodynamic Responses to Reward and Punishment in the Striatum</article-title>. <source>Journal of Neurophysiology</source> <volume>84</volume>: <fpage>3072</fpage>–<lpage>3077</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-ODoherty1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Critchley</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name> (<year>2003</year>) <article-title>Temporal Difference Models and Reward-Related Learning in the Human Brain</article-title>. <source>Neuron</source> <volume>38</volume>: <fpage>329</fpage>–<lpage>337</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-McClure1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McClure</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Berns</surname><given-names>GS</given-names></name>, <name name-style="western"><surname>Montague</surname><given-names>PR</given-names></name> (<year>2003</year>) <article-title>Temporal prediction errors in a passive learning task activate human striatum</article-title>. <source>Neuron</source> <volume>38</volume>: <fpage>339</fpage>–<lpage>46</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Downing1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Downing</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Jiang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Shuman</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name> (<year>2001</year>) <article-title>A Cortical Area Selective for Visual Processing of the Human Body</article-title>. <source>Science</source> <volume>293</volume>: <fpage>2470</fpage>–<lpage>2473</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Kanwisher1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Mcdermott</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Chun</surname><given-names>MM</given-names></name> (<year>1997</year>) <article-title>The Fusiform Face Area: A Module in Human Extrastriate Cortex Specialized for Face Perception</article-title>. <source>Journal of Neuroscience</source> <volume>17</volume>: <fpage>4302</fpage>–<lpage>4311</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Epstein1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Epstein</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name> (<year>1998</year>) <article-title>A cortical representation of the local visual environment</article-title>. <source>Nature</source> <volume>392</volume>: <fpage>598</fpage>–<lpage>601</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Malach1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Malach</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Reppas</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Benson</surname><given-names>RR</given-names></name>, <name name-style="western"><surname>Kwong</surname><given-names>KK</given-names></name>, <name name-style="western"><surname>Jlang</surname><given-names>H</given-names></name>, <etal>et al</etal>. (<year>1995</year>) <article-title>Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>92</volume>: <fpage>8135</fpage>–<lpage>8139</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Hampton1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hampton</surname><given-names>AN</given-names></name>, <name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name> (<year>2006</year>) <article-title>The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans</article-title>. <source>Journal of Neuroscience</source> <volume>26</volume>: <fpage>8360</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Hampton2"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hampton</surname><given-names>AN</given-names></name>, <name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name> (<year>2008</year>) <article-title>Neural correlates of mentalizing-related computations during strategic interactions in humans</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>105</volume>: <fpage>6741</fpage>–<lpage>6746</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Daw4"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>, <name name-style="western"><surname>Gershman</surname><given-names>SJ</given-names></name>, <name name-style="western"><surname>Seymour</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Raymond</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Model-based influences on humans choices and striatal prediction errors</article-title>. <source>Neuron</source> <volume>69</volume>: <fpage>1204</fpage>–<lpage>1215</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Bchel1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Büchel</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Wise</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Mummery</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Poline</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name> (<year>1996</year>) <article-title>Nonlinear regression in parametric activation studies</article-title>. <source>NeuroImage</source> <volume>4</volume>: <fpage>60</fpage>–<lpage>6</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Wittmann1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wittmann</surname><given-names>BC</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>, <name name-style="western"><surname>Seymour</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name> (<year>2008</year>) <article-title>Striatal activity underlies novelty-based choice in humans</article-title>. <source>Neuron</source> <volume>58</volume>: <fpage>967</fpage>–<lpage>73</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Wimmer1"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wimmer</surname><given-names>GE</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>, <name name-style="western"><surname>Shohamy</surname><given-names>D</given-names></name> (<year>2012</year>) <article-title>Generalization of value in reinforcement learning by humans</article-title>. <source>The European Journal of Neuroscience</source> <volume>35</volume>: <fpage>1092</fpage>–<lpage>104</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Squire1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Squire</surname><given-names>LR</given-names></name> (<year>1992</year>) <article-title>Memory and the hippocampus: a synthesis from findings with rats, monkeys, and humans</article-title>. <source>Psychological Review</source> <volume>99</volume>: <fpage>195</fpage>–<lpage>231</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Cohen1"><label>43</label>
<mixed-citation publication-type="book" xlink:type="simple">Cohen N, Eichenbaum H (1993) Amnesia, Memory and the Hippocampal System. Cambridge, MA: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Rose1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rose</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Haider</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Salari</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Buchel</surname><given-names>C</given-names></name> (<year>2011</year>) <article-title>Functional Dissociation of Hippocampal Mechanism during Implicit Learning Based on the Domain of Associations</article-title>. <source>Journal of Neuroscience</source> <volume>31</volume>: <fpage>13739</fpage>–<lpage>13745</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Johnson1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johnson</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name> (<year>2007</year>) <article-title>Neural ensembles in CA3 transiently encode paths forward of the animal at a decision point</article-title>. <source>Journal of Neuroscience</source> <volume>27</volume>: <fpage>12176</fpage>–<lpage>89</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Addis1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Addis</surname><given-names>DR</given-names></name>, <name name-style="western"><surname>Wong</surname><given-names>AT</given-names></name>, <name name-style="western"><surname>Schacter</surname><given-names>DL</given-names></name> (<year>2007</year>) <article-title>Remembering the past and imagining the future: common and distinct neural substrates during event construction and elaboration</article-title>. <source>Neuropsychologia</source> <volume>45</volume>: <fpage>1363</fpage>–<lpage>77</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Daw5"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>, <name name-style="western"><surname>Shohamy</surname><given-names>D</given-names></name> (<year>2008</year>) <article-title>The Cognitive Neuroscience of Motivation and Learning</article-title>. <source>Social Cognition</source> <volume>26</volume>: <fpage>593</fpage>–<lpage>620</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Buckner3"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buckner</surname><given-names>RL</given-names></name> (<year>2010</year>) <article-title>The role of the hippocampus in prediction and imagination</article-title>. <source>Annual Review of Psychology</source> <volume>61</volume>: <fpage>27</fpage>–<lpage>48, C1–8</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-OKeefe1"><label>49</label>
<mixed-citation publication-type="book" xlink:type="simple">O'Keefe J, Nadel L (1978) The hippocampus as cognitive map. Cambridge: Cambridge University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Redish1"><label>50</label>
<mixed-citation publication-type="book" xlink:type="simple">Redish AD (1999) Beyond the cognitive map: From place cells to episodic memory. Cambridge, MA: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Bunsey1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bunsey</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Eichenbaum</surname><given-names>H</given-names></name> (<year>1996</year>) <article-title>Conservation of hippocampal memory function in rats and humans</article-title>. <source>Nature</source> <volume>379</volume>: <fpage>255</fpage>–<lpage>257</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Dusek1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dusek</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Eichenbaum</surname><given-names>H</given-names></name> (<year>1997</year>) <article-title>The hippocampus and memory for orderly stimulus relations</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>94</volume>: <fpage>7109</fpage>–<lpage>7114</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Shohamy1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shohamy</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Wagner</surname><given-names>AD</given-names></name> (<year>2008</year>) <article-title>Integrating memories in the human brain: Hippocampal-midbrain encoding of overlapping event</article-title>. <source>Neuron</source> <volume>60</volume>: <fpage>378</fpage>–<lpage>89</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Kumaran1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kumaran</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Summerfield</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Hassabis</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Maguire</surname><given-names>EA</given-names></name> (<year>2009</year>) <article-title>Tracking the emergence of conceptual knowledge during human decision making</article-title>. <source>Neuron</source> <volume>63</volume>: <fpage>889</fpage>–<lpage>901</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Kumaran2"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kumaran</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Melo</surname><given-names>HL</given-names></name>, <name name-style="western"><surname>Duzel</surname><given-names>E</given-names></name> (<year>2012</year>) <article-title>The emergence and representation of knowledge about social and nonsocial hierarchies</article-title>. <source>Neuron</source> <volume>76</volume>: <fpage>653</fpage>–<lpage>66</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Wimmer2"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wimmer</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Shohamy</surname><given-names>D</given-names></name> (<year>2012</year>) <article-title>Preference by association: How memory mechanisms in the hippocampus bias decisions</article-title>. <source>Science</source> <volume>338</volume>: <fpage>270</fpage>–<lpage>3</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Simon1"><label>57</label>
<mixed-citation publication-type="book" xlink:type="simple">Simon DA, Daw ND (2011) Environmental statistics and the trade-off between model-based and TD learning in humans. In: Shawe-Taylor J, Zemel RS, Bartlett P, Pereira F, Weinberger K, editors. Advances in Neural Information Processing Systems 24. pp. 127–135.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Yin1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yin</surname><given-names>HH</given-names></name>, <name name-style="western"><surname>Knowlton</surname><given-names>BJ</given-names></name>, <name name-style="western"><surname>Balleine</surname><given-names>BW</given-names></name> (<year>2004</year>) <article-title>Lesions of dorsolateral striatum preserve outcome expectancy but disrupt habit formation in instrumental learning</article-title>. <source>European Journal of Neuroscience</source> <volume>19</volume>: <fpage>181</fpage>–<lpage>189</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Yin2"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yin</surname><given-names>HH</given-names></name>, <name name-style="western"><surname>Knowlton</surname><given-names>BJ</given-names></name> (<year>2006</year>) <article-title>The role of the basal ganglia in habit formation</article-title>. <source>Nature Reviews Neuroscience</source> <volume>7</volume>: <fpage>464</fpage>–<lpage>476</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Yin3"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yin</surname><given-names>HH</given-names></name>, <name name-style="western"><surname>Mulcare</surname><given-names>SP</given-names></name>, <name name-style="western"><surname>Hilário</surname><given-names>MRF</given-names></name>, <name name-style="western"><surname>Clouse</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Davis</surname><given-names>MI</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Dynamic reorganization of striatal circuits during the acquisition and consolidation of a skill</article-title>. <source>Nature Neuroscience</source> <volume>12</volume>: <fpage>333</fpage>–<lpage>341</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Davis1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Davis</surname><given-names>DGS</given-names></name>, <name name-style="western"><surname>Staddon</surname><given-names>JER</given-names></name> (<year>1990</year>) <article-title>Memory for reward in probabilistic choice: Markovian and non-Markovian properties</article-title>. <source>Behaviour</source> <volume>114</volume>: <fpage>37</fpage>–<lpage>64</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Mayr1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mayr</surname><given-names>U</given-names></name> (<year>1996</year>) <article-title>Spatial attention and implicit sequence learning: evidence for independent learning of spatial and nonspatial sequences</article-title>. <source>Journal of Experimental Psychology: Learning, Memory and Cognition</source> <volume>22</volume>: <fpage>350</fpage>–<lpage>364</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Willingham1"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Willingham</surname><given-names>DB</given-names></name> (<year>1999</year>) <article-title>Implicit motor sequence learning is not purely perceptual</article-title>. <source>Memory &amp; Cognition</source> <volume>27</volume>: <fpage>561</fpage>–<lpage>72</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Packard1"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Packard</surname><given-names>MG</given-names></name>, <name name-style="western"><surname>White</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Ha</surname><given-names>Q</given-names></name> (<year>1989</year>) <article-title>Differential Effects of Fornix and Caudate Radial Maze Tasks: Evidence for Multiple Nucleus Lesions on Two Memory Systems</article-title>. <source>Journal of Neuroscience</source> <volume>9</volume>: <fpage>1465</fpage>–<lpage>1472</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-McDonald1"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McDonald</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>White</surname><given-names>NM</given-names></name> (<year>1993</year>) <article-title>A triple dissociation of memory systems: hippocampus, amygdala, and dorsal striatum</article-title>. <source>Behavioral Neuroscience</source> <volume>107</volume>: <fpage>3</fpage>–<lpage>22</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Knowlton1"><label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knowlton</surname><given-names>BJ</given-names></name>, <name name-style="western"><surname>Mangels</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Squire</surname><given-names>LR</given-names></name> (<year>1996</year>) <article-title>A neostriatal habit learning system in humans</article-title>. <source>Science</source> <volume>273</volume>: <fpage>1399</fpage>–<lpage>402</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Poldrack1"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Poldrack</surname><given-names>RA</given-names></name>, <name name-style="western"><surname>Packard</surname><given-names>MG</given-names></name> (<year>2003</year>) <article-title>Competition among multiple memory systems: converging evidence from animal and human brain studies</article-title>. <source>Neuropsychologia</source> <volume>41</volume>: <fpage>245</fpage>–<lpage>51</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Behrens1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Behrens</surname><given-names>TEJ</given-names></name>, <name name-style="western"><surname>Woolrich</surname><given-names>MW</given-names></name>, <name name-style="western"><surname>Walton</surname><given-names>ME</given-names></name>, <name name-style="western"><surname>Rushworth</surname><given-names>MFS</given-names></name> (<year>2007</year>) <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nature Neuroscience</source> <volume>10</volume>: <fpage>1214</fpage>–<lpage>21</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Li1"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>EK</given-names></name> (<year>1993</year>) <article-title>The Representation of Stimulus Familiarity Temporal Cortex in Anterior Inferior</article-title>. <source>Journal of Neurophysiology</source> <volume>69</volume>: <fpage>1918</fpage>–<lpage>1929</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Wiggs1"><label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wiggs</surname><given-names>CL</given-names></name>, <name name-style="western"><surname>Martin</surname><given-names>A</given-names></name> (<year>1998</year>) <article-title>Properties and mechanisms of perceptual priming</article-title>. <source>Current Opinion in Neurobiology</source> <volume>8</volume>: <fpage>227</fpage>–<lpage>33</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-McClure2"><label>71</label>
<mixed-citation publication-type="book" xlink:type="simple">McClure SM, Gilzenrat MS, Cohen JD (2005) An exploration-exploitation model based on norepinephrine and dopamine activity. In: Advances in Neural Information Processing Systems. Cambridge, MA: MIT Press, pp. 867–874.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Summerfield1"><label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Summerfield</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Trittschuh</surname><given-names>EH</given-names></name>, <name name-style="western"><surname>Monti</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Mesulam</surname><given-names>Mm</given-names></name>, <name name-style="western"><surname>Egner</surname><given-names>T</given-names></name> (<year>2008</year>) <article-title>Neural repetition suppression reflects fulfilled perceptual expectations</article-title>. <source>Nature Neuroscience</source> <volume>11</volume>: <fpage>1004</fpage>–<lpage>1006</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Philiastides1"><label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Philiastides</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Biele</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Heekeren</surname><given-names>H</given-names></name> (<year>2010</year>) <article-title>A mechanistic account of value computation in the human brain</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>107</volume>: <fpage>9430</fpage>–<lpage>5</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Burgess1"><label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burgess</surname><given-names>PW</given-names></name>, <name name-style="western"><surname>Dumontheil</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Gilbert</surname><given-names>SJ</given-names></name> (<year>2007</year>) <article-title>The gateway hypothesis of rostral prefrontal cortex (area 10) function</article-title>. <source>Trends in Cognitive Sciences</source> <volume>11</volume>: <fpage>290</fpage>–<lpage>8</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Schacter1"><label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schacter</surname><given-names>DL</given-names></name>, <name name-style="western"><surname>Addis</surname><given-names>DR</given-names></name> (<year>2007</year>) <article-title>The cognitive neuroscience of constructive memory: remembering the past and imagining the future</article-title>. <source>Philosophical transactions of the Royal Society of London Series B, Biological sciences</source> <volume>362</volume>: <fpage>773</fpage>–<lpage>86</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Viard1"><label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Viard</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Doeller</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>Hartley</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Bird</surname><given-names>CM</given-names></name>, <name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name> (<year>2011</year>) <article-title>Anterior hippocampus and goaldirected spatial decision making</article-title>. <source>Journal of Neuroscience</source> <volume>31</volume>: <fpage>4613</fpage>–<lpage>21</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-GuitartMasip1"><label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guitart-Masip</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Barnes</surname><given-names>GR</given-names></name>, <name name-style="western"><surname>Horner</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Bauer</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Synchronization of medial temporal lobe and prefrontal rhythms in human decision making</article-title>. <source>The Journal of Neuroscience</source> <volume>33</volume>: <fpage>442</fpage>–<lpage>51</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Houk1"><label>78</label>
<mixed-citation publication-type="book" xlink:type="simple">Houk J, Adams J, Barto A (1995) A model of how the basal ganglia generate and use neural signals that predict reinforcement. In: Houk JC, Davis JL, Beiser DG, editors. Models of information processing in the Basal Ganglia. Cambridge, MA: MIT Press. pp. 249–270.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Frank1"><label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Frank</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Seeberger</surname><given-names>LC</given-names></name>, <name name-style="western"><surname>O'Reilly</surname><given-names>RC</given-names></name> (<year>2004</year>) <article-title>By carrot or by stick: cognitive reinforcement learning in Parkinsonism</article-title>. <source>Science</source> <volume>306</volume>: <fpage>1940</fpage>–<lpage>1943</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Keramati1"><label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Keramati</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Dezfouli</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Piray</surname><given-names>P</given-names></name> (<year>2011</year>) <article-title>Speed/Accuracy Trade-Off between the Habitual and the Goal-Directed Processes</article-title>. <source>PLoS Computational Biology</source> <volume>7</volume>: <fpage>e1002055</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Wunderlich1"><label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wunderlich</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name> (<year>2012</year>) <article-title>Mapping value based planning and extensively trained choice in the human brain</article-title>. <source>Nature Neuroscience</source> <volume>15</volume>: <fpage>786</fpage>–<lpage>91</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Botvinick1"><label>82</label>
<mixed-citation publication-type="book" xlink:type="simple">Botvinick M, An J (2008) Goal-directed decision making in prefrontal cortex: A computational framework. In: Koller D, Bengio, Y, Schuurmans D, Bouttou L, Culotta A, editors. Advances in Neural Information Processing Systems. Volume 21. pp. 169–176.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Solway1"><label>83</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Solway</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Botvinick</surname><given-names>MM</given-names></name> (<year>2012</year>) <article-title>Goal-directed decision making as probabilistic inference: A computational framework and potential neural correlates</article-title>. <source>Psychological Review</source> <volume>119</volume>: <fpage>120</fpage>–<lpage>54</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Rangel1"><label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rangel</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Camerer</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Montague</surname><given-names>PR</given-names></name> (<year>2008</year>) <article-title>A framework for studying the neurobiology of valuebased decision making</article-title>. <source>Nature Reviews Neuroscience</source> <volume>9</volume>: <fpage>545</fpage>–<lpage>56</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Krajbich1"><label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krajbich</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Rangel</surname><given-names>A</given-names></name> (<year>2011</year>) <article-title>Multialternative drift-diffusion model predicts the relationship between visual fixations and choice in value-based decisions</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>108</volume>: <fpage>13852</fpage>–<lpage>13857</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Stewart1"><label>86</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stewart</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Chater</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Brown</surname><given-names>GDA</given-names></name> (<year>2006</year>) <article-title>Decision by sampling</article-title>. <source>Cognitive Psychology</source> <volume>53</volume>: <fpage>1</fpage>–<lpage>26</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Bornstein2"><label>87</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bornstein</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name> (<year>2011</year>) <article-title>Multiplicity of control in the basal ganglia: computational roles of striatal subregions</article-title>. <source>Current Opinion in Neurobiology</source> <volume>21</volume>: <fpage>374</fpage>–<lpage>80</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Peters1"><label>88</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peters</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Büchel</surname><given-names>C</given-names></name> (<year>2010</year>) <article-title>Episodic future thinking reduces reward delay discounting through an enhancement of prefrontal-mediotemporal interactions</article-title>. <source>Neuron</source> <volume>66</volume>: <fpage>138</fpage>–<lpage>48</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Schwarz1"><label>89</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwarz</surname><given-names>G</given-names></name> (<year>1978</year>) <article-title>Estimating the Dimension of a Model</article-title>. <source>Annals of Statistics</source> <volume>6</volume>: <fpage>461</fpage>–<lpage>464</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Brainard1"><label>90</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brainard</surname><given-names>DH</given-names></name> (<year>1997</year>) <article-title>The Psychophysics Toolbox</article-title>. <source>Spatial Vision</source> <volume>10</volume>: <fpage>433</fpage>–<lpage>6</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Holmes1"><label>91</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holmes</surname><given-names>AP</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name> (<year>1998</year>) <article-title>Generalisability, Random Effects &amp; Population Inference</article-title>. <source>Neuroimage</source> <volume>7</volume>: <fpage>S754</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Simon2"><label>92</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simon</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name> (<year>2011</year>) <article-title>Neural Correlates of Forward Planning in a Spatial Decision Task in Humans</article-title>. <source>Journal of Neuroscience</source> <volume>31</volume>: <fpage>5526</fpage>–<lpage>5539</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Schnberg1"><label>93</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schönberg</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>, <name name-style="western"><surname>Joel</surname><given-names>D</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name> (<year>2007</year>) <article-title>Reinforcement learning signals in the human striatum distinguish learners from nonlearners during reward-based decision making</article-title>. <source>Journal of Neuroscience</source> <volume>27</volume>: <fpage>12860</fpage>–<lpage>7</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Schnberg2"><label>94</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schönberg</surname><given-names>T</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Joel</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Inzelberg</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Segev</surname><given-names>Y</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Selective impairment of prediction error signaling in human dorsolateral but not ventral striatum in Parkinson's disease patients: evidence from a model-based fMRI study</article-title>. <source>NeuroImage</source> <volume>49</volume>: <fpage>772</fpage>–<lpage>81</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Gershman1"><label>95</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gershman</surname><given-names>SJ</given-names></name>, <name name-style="western"><surname>Pesaran</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name> (<year>2009</year>) <article-title>Human reinforcement learning subdivides structured action spaces by learning effector-specific values</article-title>. <source>Journal of Neuroscience</source> <volume>29</volume>: <fpage>13524</fpage>–<lpage>31</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Kass1"><label>96</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kass</surname><given-names>RE</given-names></name>, <name name-style="western"><surname>Raftery</surname><given-names>AE</given-names></name> (<year>1995</year>) <article-title>Bayes Factors</article-title>. <source>Journal of the American Statistical Association</source> <volume>90</volume>: <fpage>773</fpage>–<lpage>795</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Mackay1"><label>97</label>
<mixed-citation publication-type="book" xlink:type="simple">Mackay DJC (2003) Information Theory, Inference, and Learning Algorithms. Cambridge, UK: Cambridge University Press. doi:10.2277/0521642981.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Boone1"><label>98</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boone</surname><given-names>EL</given-names></name>, <name name-style="western"><surname>Ye</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>EP</given-names></name> (<year>2005</year>) <article-title>Assessment of two approximation methods for computing posterior model probabilities</article-title>. <source>Computational Statistics &amp; Data Analysis</source> <volume>48</volume>: <fpage>221</fpage>–<lpage>234</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-TzourioMazoyer1"><label>99</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tzourio-Mazoyer</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Landeau</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Papathanassiou</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Crivello</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Etard</surname><given-names>O</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title>. <source>NeuroImage</source> <volume>15</volume>: <fpage>273</fpage>–<lpage>89</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Kriegeskorte1"><label>100</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Simmons</surname><given-names>WK</given-names></name>, <name name-style="western"><surname>Bellgowan</surname><given-names>PSF</given-names></name>, <name name-style="western"><surname>Baker</surname><given-names>CI</given-names></name> (<year>2009</year>) <article-title>Circular analysis in systems neuroscience: the dangers of double dipping</article-title>. <source>Nature Neuroscience</source> <volume>12</volume>: <fpage>535</fpage>–<lpage>40</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003387-Friston1"><label>101</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Josephs</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Rees</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Turner</surname><given-names>R</given-names></name> (<year>1997</year>) <article-title>Nonlinear Event-Related Responses in fMRI</article-title>. <source>Magnetic Resonance Methods</source> <volume>39</volume>: <fpage>41</fpage>–<lpage>52</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
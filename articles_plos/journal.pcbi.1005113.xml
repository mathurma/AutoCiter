<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005113</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-02079</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Infectious diseases</subject><subj-group><subject>Bacterial diseases</subject><subj-group><subject>Hemolytic-uremic syndrome</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuronal tuning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Network analysis</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Artificial intelligence</subject><subj-group><subject>Artificial neural networks</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Artificial intelligence</subject><subj-group><subject>Artificial neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Artificial neural networks</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Artificial neural networks</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Animals</subject><subj-group><subject>Vertebrates</subject><subj-group><subject>Amniotes</subject><subj-group><subject>Mammals</subject><subj-group><subject>Ferrets</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Network Receptive Field Modeling Reveals Extensive Integration and Multi-feature Selectivity in Auditory Cortical Neurons</article-title>
<alt-title alt-title-type="running-head">Network Receptive Field Modeling Reveals Non-linear Characteristics of Auditory Cortical Neurons</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Harper</surname>
<given-names>Nicol S.</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7182-2429</contrib-id>
<name name-style="western">
<surname>Schoppe</surname>
<given-names>Oliver</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Willmore</surname>
<given-names>Ben D. B.</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Cui</surname>
<given-names>Zhanfeng</given-names>
</name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Schnupp</surname>
<given-names>Jan W. H.</given-names>
</name>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>King</surname>
<given-names>Andrew J.</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Dept. of Physiology, Anatomy and Genetics (DPAG), Sherrington Building, University of Oxford, United Kingdom</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, United Kingdom</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Bio-Inspired Information Processing, Technische Universität München, Germany</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Department of Biomedical Science, City University of Hong Kong, Kowloon Tong, Hong Kong</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Nelken</surname>
<given-names>Israel</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Hebrew University of Jerusalem, ISRAEL</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con">
<p><list list-type="simple">
<list-item><p><bold>Conceptualization:</bold> NSH.</p></list-item>
<list-item><p><bold>Data curation:</bold> BDBW NSH.</p></list-item>
<list-item><p><bold>Formal analysis:</bold> OS NSH BDBW.</p></list-item>
<list-item><p><bold>Funding acquisition:</bold> AJK JWHS ZC.</p></list-item>
<list-item><p><bold>Investigation:</bold> BDBW NSH.</p></list-item>
<list-item><p><bold>Methodology:</bold> NSH OS BDBW.</p></list-item>
<list-item><p><bold>Project administration:</bold> AJK ZC JWHS.</p></list-item>
<list-item><p><bold>Resources:</bold> AJK ZC JWHS.</p></list-item>
<list-item><p><bold>Software:</bold> OS NSH BDBW.</p></list-item>
<list-item><p><bold>Supervision:</bold> NSH BDBW JWHS AJK ZC.</p></list-item>
<list-item><p><bold>Validation:</bold> OS NSH.</p></list-item>
<list-item><p><bold>Visualization:</bold> NSH OS.</p></list-item>
<list-item><p><bold>Writing – original draft:</bold> NSH OS.</p></list-item>
<list-item><p><bold>Writing – review &amp; editing:</bold> NSH JWHS BDBW AJK OS.</p></list-item></list></p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">nicol.harper@dpag.ox.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>11</day>
<month>11</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<month>11</month>
<year>2016</year>
</pub-date>
<volume>12</volume>
<issue>11</issue>
<elocation-id>e1005113</elocation-id>
<history>
<date date-type="received">
<day>12</day>
<month>12</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>22</day>
<month>8</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Harper et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005113"/>
<abstract>
<p>Cortical sensory neurons are commonly characterized using the receptive field, the linear dependence of their response on the stimulus. In primary auditory cortex neurons can be characterized by their spectrotemporal receptive fields, the spectral and temporal features of a sound that linearly drive a neuron. However, receptive fields do not capture the fact that the response of a cortical neuron results from the complex nonlinear network in which it is embedded. By fitting a nonlinear feedforward network model (a network receptive field) to cortical responses to natural sounds, we reveal that primary auditory cortical neurons are sensitive over a substantially larger spectrotemporal domain than is seen in their standard spectrotemporal receptive fields. Furthermore, the network receptive field, a parsimonious network consisting of 1–7 sub-receptive fields that interact nonlinearly, consistently better predicts neural responses to auditory stimuli than the standard receptive fields. The network receptive field reveals separate excitatory and inhibitory sub-fields with different nonlinear properties, and interaction of the sub-fields gives rise to important operations such as gain control and conjunctive feature detection. The conjunctive effects, where neurons respond only if several specific features are present together, enable increased selectivity for particular complex spectrotemporal structures, and may constitute an important stage in sound recognition. In conclusion, we demonstrate that fitting auditory cortical neural responses with feedforward network models expands on simple linear receptive field models in a manner that yields substantially improved predictive power and reveals key nonlinear aspects of cortical processing, while remaining easy to interpret in a physiological context.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Linear filter descriptions of sensory neurons have been with us since the 1970s, and have been enormously influential. But such models, and more recent nonlinear variants, are rather like modeling the entire network as a single neuron, failing to account for the neuron's response being a consequence of a network of many nonlinear units. Here we show how these limitations can be overcome by using recent advances in machine learning to fit “network receptive field models” to neural responses to natural sounds. Feedforward networks of 1–7 nonlinearly-interacting lower-order model neurons are required to model a cortical receptive field. Each lower order neuron is tuned to somewhat different stimulus features, arranged together in complex but interpretable structures, which cover a far wider range of sound frequencies and delays than current receptive field models indicate. The NRF models capture important nonlinear functional characteristics in auditory cortical neurons, including multiplicative gain control and conjunctive feature selectivity, where neurons respond when certain features are present together but not in isolation. This enables NRFs to predict the responses of auditory cortical neurons with considerably greater accuracy than conventional models.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>WT108369/Z/2015/Z</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000268</institution-id>
<institution>Biotechnology and Biological Sciences Research Council</institution>
</institution-wrap>
</funding-source>
<award-id>BB/H008608/1</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Cui</surname>
<given-names>Zhanfeng F</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>082692</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Harper</surname>
<given-names>Nicol S.</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>WT076508AIA</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award005">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100004350</institution-id>
<institution>Studienstiftung des Deutschen Volkes</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7182-2429</contrib-id>
<name name-style="western">
<surname>Schoppe</surname>
<given-names>Oliver</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award006">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000703</institution-id>
<institution>Action on Hearing Loss</institution>
</institution-wrap>
</funding-source>
<award-id>PA07</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Harper</surname>
<given-names>Nicol S.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>NSH was supported by a Sir Henry Wellcome Postdoctoral Fellowship (grant number WT082692) and other Wellcome Trust funding (grant numbers WT076508AIA and WT108369/Z/2015/Z), by the Department of Physiology, Anatomy and Genetics at the University of Oxford, by Action on Hearing Loss (grant number PA07), and by the Biotechnology and Biological Sciences Research Council (grant number BB/H008608/1). OS was supported by the German Academic Scholarship Foundation. ZC was supported by the Biotechnology and Biological Sciences Research Council (grant number BB/H008608/1). AJK and BDBW were supported by a Wellcome Trust Principal Research Fellowship to AJK (grant number WT076508AIA and WT108369/Z/2015/Z). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="5"/>
<table-count count="0"/>
<page-count count="30"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data can be found at <ext-link ext-link-type="uri" xlink:href="https://osf.io/ayw2p/" xlink:type="simple">https://osf.io/ayw2p/</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Developing models capable of quantitatively predicting neural responses to sensory stimuli is key to understanding the neural computations underlying perception. A widespread model of sensory neurons, including cortical sensory neurons, is the receptive field (RF), which describes the best-fitting linear transformation from the stimulus to the neural response [<xref ref-type="bibr" rid="pcbi.1005113.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1005113.ref016">16</xref>]. RF models, although simple and useful, are only moderately effective in capturing neural responses since processing by networks of neurons includes highly nonlinear operations. Consequently, they can fail to produce adequate descriptions of neural responses, particularly to natural stimuli [<xref ref-type="bibr" rid="pcbi.1005113.ref017">17</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref018">18</xref>].</p>
<p>While spectrotemporal receptive fields (STRF) of neurons in primary auditory cortex (A1) can be quite broad and complex, many of them are punctate, typically little more than a point in time and frequency, indicating little of the likely complexity of cortical processing [<xref ref-type="bibr" rid="pcbi.1005113.ref019">19</xref>] (although see [<xref ref-type="bibr" rid="pcbi.1005113.ref012">12</xref>]). Adding specific nonlinearities to STRF models [<xref ref-type="bibr" rid="pcbi.1005113.ref017">17</xref>], for example by applying output nonlinearities [<xref ref-type="bibr" rid="pcbi.1005113.ref019">19</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref020">20</xref>] to create linear-nonlinear (LN) models, improves prediction somewhat. However, basic LN models, consisting of just a single STRF and an output nonlinearity, still fail to capture the interactions of sensory filters that are bound to occur naturally in the neural networks of ascending sensory pathways. Recently, more complex and often nonlinear STRF models [<xref ref-type="bibr" rid="pcbi.1005113.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1005113.ref025">25</xref>] of A1 neurons have achieved improved predictions of experimental data, although sometimes at the expense of being very computationally intensive. These newer models have tended to concentrate on better modeling of features local to the neuron, such as synaptic depression [<xref ref-type="bibr" rid="pcbi.1005113.ref023">23</xref>] or refractoriness [<xref ref-type="bibr" rid="pcbi.1005113.ref022">22</xref>]. Other valuable approaches adopted to characterize the feature selectivity of A1 neurons are more phenomenological in nature [<xref ref-type="bibr" rid="pcbi.1005113.ref020">20</xref>].</p>
<p>Here we take a very different approach, one that embodies the fact that a neuron's response is the result of it being embedded in a network of many neurons, each of which is a nonlinear unit. We take advantage of recent advances in the training of artificial neural networks [<xref ref-type="bibr" rid="pcbi.1005113.ref026">26</xref>] to produce a new type of RF model, the network receptive field (NRF), which can be rapidly fitted to neural response data. The NRF model is composed of a hierarchical feedforward network of 20 LN units, embodying the fact that cortical neurons integrate the output of many lower order neurons. Although our choice of 20 possible feed-forward connections does not reflect the full range of converging inputs that cortical neurons receive, this approach stands in contrast to the above mentioned recent models of A1 responses [<xref ref-type="bibr" rid="pcbi.1005113.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1005113.ref024">24</xref>], which use only one, or in some cases two, STRF-like units. In fact, we show here that up to seven effective units are required to model a cortical receptive field.</p>
<p>Receptive field models tend to include large numbers of free parameters, which can lead to problems with “overfitting”: the many free parameters of the model may capture unimportant or coincidental details or noise in the training set. This can result in the model appearing to successfully capture the stimulus-response relationships in the training set, but subsequently performing poorly when the model is used to predict neural responses to novel stimuli that were not part of the training set. To prevent the risk of overfitting affecting our results we took the following steps: First, during model fitting, the NRF was regularized by the summed magnitudes of the network's weights (<italic>L</italic><sub>1</sub>-norm), which automatically prunes away superfluous weights and hidden units (from an initial 20 hidden units). This produces parsimonious and readily interpretable connection patterns that provide insights into the underlying circuitry. Second, we made extensive use of cross-validation during model training (see below) and assessed the performance of all models using a generalization test set which the models had not been exposed to during training.</p>
<p>Together, the regularization, cross-validation and generalization testing adopted here ensure that the improved performance exhibited by our NRF models is not a trivial consequence of the larger number of degrees of freedom that these models can bring to bear, but rather reflect the fact that the structure of these models renders them better able than conventional LN receptive field models to capture aspects of the sensory processing performed by the auditory pathway. Thus, using electrophysiological recordings from ferret auditory cortex, we find that NRF models consistently outperform LN models in predicting the responses of auditory cortical neurons to natural stimuli. The fitted NRF models of auditory cortical neurons reveal sensitivity over substantially wider time and frequency ranges than conventional LN and STRF models, and the NRFs also reveal distinct nonlinear properties, including gain control and conjunctive feature selectivity, features that may be critical to auditory cortex function. Conjunctive feature selectivity, where neurons respond when certain features are present together but not in isolation, allows neurons to show increased selectivity to specific complex spectrotemporal structures and may provide a valuable stage in the sound recognition process.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Network receptive field models of neural responses in auditory cortex</title>
<p>To investigate the ability of NRFs to account for cortical sensory responses, we fitted models to neural responses to clips of natural sounds. Seventy-six single-unit responses were recorded with multi-channel electrodes in the ferret primary auditory cortical areas, A1, and the anterior auditory field (AAF). The stimuli comprised 20 clips of natural acoustic scenes, each of 5 s duration, including ferret vocalizations, speech, and environmental sounds. The model fitting process is shown schematically in <xref ref-type="fig" rid="pcbi.1005113.g001">Fig 1</xref>. and described in detail in the Materials and Methods. The first step in the NRF model was to generate a first order approximation of auditory nerve response patterns to the stimuli, referred to here as the “cochleagram”, by measuring the log amplitude of the sound in each of 34 log-spaced frequency channels, spanning 0.5 to 22.6 kHz with ⅙ octave spectral resolution and 5 ms temporal resolution. The task of the model was then to predict the firing patterns recorded from the cortical neurons, also binned with 5 ms time resolution, from the previous 100 ms (20 time bins) of stimulus history.</p>
<fig id="pcbi.1005113.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005113.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Schematics of the models.</title>
<p>(A) The linear-nonlinear (LN) model. (B) The network receptive field (NRF) model, a feedforward neural network</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005113.g001" xlink:type="simple"/>
</fig>
<p>In accordance with principles of model selection and assessment [<xref ref-type="bibr" rid="pcbi.1005113.ref027">27</xref>], we divided the neural response data into a cross-validation set and a test set. The cross-validation set was then divided again into a training set that was used to fit the model parameters, and a validation set on with which the model's capacity to predict neural response was then assessed. By this means, the optimum value for general settings of the model (hyperparameters, such as the degree of regularization) could be determined. This fitting was repeated ten times for ten different ways of dividing the cross-validation set, to ensure a robust assessment of the optimum model hyperparameter values. Note that the model fits, for both the LN and NRF models, tended to differ little in their receptive field forms over these ten fits, despite having slightly different datasets and different randomly chosen weight initializations, indicating the robustness of the fitting procedure (for details and quantification see <xref ref-type="sec" rid="sec020">Materials and Methods</xref>). Once the optimum hyperparameters were obtained, the model was re-fitted using the full cross-validation dataset. Finally, the test dataset that was put aside was used to assess the fitted model's capacity to predict responses to sounds not encountered at any stage of the fitting (i.e. to “generalize”). All model performance data reported below refer to results obtained with the test set.</p>
<p>A conventional LN model and an NRF model were fitted for each cortical neuron in our dataset. The LN model comprised a linear STRF, used to calculate the activation of the model neuron, and a sigmoidal output nonlinearity (<xref ref-type="fig" rid="pcbi.1005113.g001">Fig 1A</xref>). The linear STRF on its own also provided a basic linear (L) model. The NRF model was a rate-based, feed-forward neural network (a multilayer perceptron), with units that integrate inputs linearly followed by a nonlinear transformation to produce their output [<xref ref-type="bibr" rid="pcbi.1005113.ref028">28</xref>]. The NRF effectively computes a weighted sum of several LN models, where each hidden unit (HU) instantiates one LN model, and their outputs are combined linearly as they converge on the output unit (OU). The resulting OU activation passes through a further sigmoidal nonlinear activation function (<xref ref-type="fig" rid="pcbi.1005113.g001">Fig 1B</xref>) to yield the NRF model’s prediction of the neural firing rate. The network units have no memory from time point to time point; the model does not use any recurrent or convolutional elements. All models (LN and NRF) were fitted by minimizing the squared error between the model’s estimate of the neural response and the actual neural firing rate (see <xref ref-type="sec" rid="sec020">Materials and Methods</xref> for details). Importantly, <italic>L</italic><sub>1</sub>-norm regularization of the connection weights was used to find a parsimonious representation. A recently developed algorithm [<xref ref-type="bibr" rid="pcbi.1005113.ref026">26</xref>] allowed for good NRF models to be fitted rapidly and efficiently for all 76 cortical neurons in our dataset.</p>
</sec>
<sec id="sec004">
<title>NRF models describe neural responses better than LN models</title>
<p>To assess the models’ predictive power, we measured how well they were able to predict responses to a “test set” of stimuli which were not part of the training set used during model fitting. The NRF tends to better predict the amplitude of sharp peaks in the observed neural response than the LN model (<xref ref-type="fig" rid="pcbi.1005113.g002">Fig 2A and 2B</xref>, seconds 3–4 are from the training set, seconds 4–5 are from the test set). We quantified the quality of the response prediction by calculating the normalized correlation coefficient (<italic>CC<sub>norm</sub></italic>) between predicted and observed neural responses [<xref ref-type="bibr" rid="pcbi.1005113.ref029">29</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref030">30</xref>]. A <italic>CC<sub>norm</sub></italic> of 0 would indicate that the model fails to predict the neural responses any better than chance, while <italic>CC<sub>norm</sub></italic> values of 1 indicate predictions that are at the highest achievable accuracy (see <xref ref-type="sec" rid="sec020">Materials and Methods</xref>). For the great majority of neurons (70/76), the NRF achieved higher <italic>CC<sub>norm</sub></italic> values than the LN model (p = 6.3×10<sup>−15</sup>, n = 76, sign test; <xref ref-type="fig" rid="pcbi.1005113.g002">Fig 2C</xref>), with the mean <italic>CC<sub>norm</sub></italic> for the NRFs being 0.73, compared to 0.67 for the LN model. The <italic>CC<sub>norm</sub></italic> for the L-model, the prediction using the STRF but without processing through the fitted sigmoidal output nonlinearity, was 0.60, significantly less than both the NRF (76/76, p = 2.6×10<sup>-23</sup>, n = 76, sign test) and the LN model (75/76, p = 2.0×10<sup>−21</sup>, n = 76, sign test). The <italic>CC<sub>norm</sub></italic> value for the NRF model may approach the maximum possible given the duration of the STRFs (100 ms) used by the NRF model [<xref ref-type="bibr" rid="pcbi.1005113.ref031">31</xref>] (See <xref ref-type="sec" rid="sec012">Discussion</xref>). We also report the raw mean correlation coefficient (<italic>CC</italic><sub><italic>raw</italic></sub>), which was 0.61 for the NRF model, and 0.56 for the LN model, to enable comparison with previous publications (but note, that differences in raw <italic>CC</italic><sub><italic>raw</italic></sub> values between different studies are difficult to interpret, as will be discussed further below). As expected, for this measure too, the great majority of neurons (70/76) were significantly better fit by the NRF than the LN model (p = 6.3×10<sup>−15</sup>, n = 76, sign test). The <italic>CC</italic><sub><italic>raw</italic></sub> for the linear model was 0.50, significantly less than both the NRF (76/76, p = 2.6×10<sup>−23</sup>, n = 76, sign test) and the LN model (75/76, p = 2.0×10<sup>−21</sup>, n = 76, sign test).</p>
<fig id="pcbi.1005113.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005113.g002</object-id>
<label>Fig 2</label>
<caption>
<title>A neural network receptive field model predicts the response of auditory cortical neurons better than the LN model.</title>
<p>(A) Cochleagram for a 2 s sound stimulus snippet. (B) The neural response firing rate to the stimulus snippet shown in A (black line) for one example neuron, shown alongside the predicted responses of the LN-model (dotted cyan line) and the NRF model (red line). The thin dotted black line indicates the 2<italic>σ</italic>-threshold, which was used to identify periods of large response peaks. (C) Prediction quality (normalized correlation coefficient) of the NRF model plotted against that of the LN-model for all 76 neurons in our dataset. (D) Mean squared error (MSE) of the prediction during peak response times of the NRF models plotted against error of the LN-models. (E) Average peak activity MSE (pMSE) over the whole dataset for the NRF and the LN models. (F) Average MSE of the predictions generated by NRF and LN models as in E, but calculated across the whole response to the test stimuli, not just the peak response period.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005113.g002" xlink:type="simple"/>
</fig>
<p>The capacity of the NRF model to predict better than the LN model is also robust to the exact choice of test set. This is evident from examining the prediction quality for the validation sets, which, in order to require the model to generalize across stimulus types, comprised 2 of the 20 sounds, chosen at random. The mean <italic>CC<sub>norm</sub></italic> for the validation set, averaged over all 10 folds, is greater for the NRF model (0.76) than the LN model (0.71), with significantly more neurons (69/76) showing a greater <italic>CC<sub>norm</sub></italic> for the NRF model than the LN model (p = 6.4x10<sup>-14</sup>, n = 76, sign test).</p>
<p>To investigate how well the models are able to predict peak responses in the test set, we also measured the “peak activity mean squared error”, which was defined as the MSE between the observed firing rates and those predicted by the models during periods where the observed firing rate exceeded two standard deviations above the mean firing rate (the “2σ-threshold”, dotted line in <xref ref-type="fig" rid="pcbi.1005113.g002">Fig 2B</xref>). It is readily apparent that the peak activity MSE of the NRF model is smaller than that of the LN model for the great majority of neurons (p = 5.2×10<sup>-16</sup>, n = 76, sign test; <xref ref-type="fig" rid="pcbi.1005113.g002">Fig 2D</xref>). The peak activity MSE, averaged over all neurons, was 27% smaller for the NRF model than for the LN model (<xref ref-type="fig" rid="pcbi.1005113.g002">Fig 2E</xref>). This reduction of prediction error during periods of peak excitation appears to drive the improved performance of the NRF model relative to the LN model. This is indicated by much smaller average improvement (8%) for the NRF over the LN model when the MSE was measured over the entire neural response (<xref ref-type="fig" rid="pcbi.1005113.g002">Fig 2F</xref>).</p>
<p>Note that all the model performance data in <xref ref-type="fig" rid="pcbi.1005113.g002">Fig 2</xref>. were calculated exclusively from test sets that the models were not exposed to during training. This is essential to ensure that appropriate model comparisons were made. NRF models have significantly more free parameters than conventional LN models, and, if tested on the training data, might trivially outperform the LN models by overfitting noise in the training data, but such overfitting would become disadvantageous when the models were used to make predictions for novel stimulus sets. The fact that NRF models outperform LN models on previously unseen data indicates that the NRF models mimic aspects of the behavior of the cortical neurons which the structure of LN models cannot account for.</p>
</sec>
<sec id="sec005">
<title>NRFs reveal that cortical neurons are better described by the interaction of multiple, diverse sub-receptive-fields</title>
<p>We first qualitatively examined the fitted characteristics of the two models (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3</xref>; each of the 10 numbered rows shows an example neuron; neuron 1 was used in Figs <xref ref-type="fig" rid="pcbi.1005113.g001">1</xref> and <xref ref-type="fig" rid="pcbi.1005113.g002">2B</xref>). In our dataset, as is quite commonly the case, the LN model STRFs are rather “punctate”, i.e. the model neuron is driven almost exclusively by stimulus elements clustered narrowly in frequency and recent stimulus history, often an excitatory point with some weak lagging inhibition (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3A</xref>, the top panel shows the STRF for each neuron). Moreover, the LN model tends to operate in the near-threshold region of the nonlinear activation function (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3A</xref>, lower panel for each neuron), with activations straddling the expansive part of the sigmoidal output function.</p>
<fig id="pcbi.1005113.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005113.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Example STRFs and nonlinearities for both models.</title>
<p>Each numbered row is an example neuron. (A) STRFs (top) and nonlinearities (bottom) for the LN model. Green bars mark 0–20 sp/s. The nonlinearities are superimposed over the distribution of activations. The green dot on the nonlinear activation function marks the mean output value. (B) Hidden unit (HU) 'STRFs' (top) and nonlinearities (bottom) for the NRF model. If the nonlinearity curve is red, it is an excitatory HU, if blue, it is inhibitory. Otherwise format as in A. Note that the STRFs of inhibitory units have been multiplied by -1 for display purposes, to indicate the direction of their influence on the final neural output (See <xref ref-type="sec" rid="sec020">Materials and Methods</xref>, The displayed STRFs). One would therefore not necessarily expect to observe extensive inhibitory areas such as those in some of these HU display STRFs in physiological recordings, as such inhibitory fields would most likely manifest in biological networks as excitatory fields that feed on to the next neuron via inhibitory synapses. (C) HU STRFs in B plotted together as contours. The contours are at 50% of an STRF's maximum (if an excitatory HU) or of its minimum (if an inhibitory HU). Each panel in column C only shows a sub-region of the full spectrotemporal range of the STRFs; it is an expansion of an area of interest, whose frequency range and temporal range are shown by the black bars on the edges of the first HU STRF of the neuron. (D) Top: the variance of weighted-output, the input to the output unit (OU), of each HU. The red line marks a variance of 5%, the threshold for distinguishing effective HUs from their “ineffective” counterparts. Bottom: OU nonlinearities for the NRF model for the same 10 cortical neurons. Format as bottom panel in A.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005113.g003" xlink:type="simple"/>
</fig>
<p>The NRF model reveals more complex tuning properties (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3B–3D</xref>, for the same 10 example neurons). Each NRF model had 20 HUs, but because the model training incorporated a regularization term that penalizes ineffectual and redundant synaptic weights (see <xref ref-type="sec" rid="sec020">Materials and Methods</xref>), HUs could develop substantive synaptic weights only if these were able to “explain” aspects of the firing of the biological neuron that were not already covered by the other HUs in the feedforward network. Any HUs that were redundant would have their input and output weights, and hence their overall contribution to the NRF, shrink to negligibly small values. We found that, of the 20 HUs in each NRF, most turned out to be redundant during the course of model fitting, and each NRF ended up with a relatively small number of “effective” HUs (between 1 and 7), which were the only ones to send strong signals to the output neuron (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3B</xref>; for each neuron, each column shows an 'effective' HU with an STRF, top panel, and a nonlinearity, bottom panel). The variance, calculated over the full stimulus set, of an HU's weighted-output (HU output × output weight) provides a measure of the HU's 'effectiveness' (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3D</xref>, top panel), with HUs with a variance ≥5% (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3D</xref>, red line) of the sum of the variances of all 20 HUs being considered effective. The weighted-output of an effective HU varies greatly as it rises and falls to signal the presence or absence of particular stimulus features. In contrast, the weighted-output variance of an “ineffective” HU is close to zero. Thus, an NRF with three effective HUs (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3B</xref>, neuron 1) has three weighted-output variances above the 5% threshold (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3D</xref>, top panel, neuron 1).</p>
<p>HUs can be classified into excitatory or inhibitory units according to whether their output weight is positive or negative, after adjusting the model to account for HUs where the input weights are predominantly negative and the output weight negative, which is effectively an excitatory HU, and also adjusting for HUs that show the converse (see <xref ref-type="sec" rid="sec020">Materials and Methods</xref>). If the plotted line of an HU's nonlinear activation function is red, it is excitatory, whereas if it is blue, the HU is inhibitory (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3B</xref>, bottom panel for each HU). The STRFs of HUs are more diverse in form than the STRFs of the LN model, and together appear to cover a wider range of frequencies and times (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3B</xref>, top panel for each HU). For display purposes only, the weights of the inhibitory HU STRFs in <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3</xref> have their signs inverted so as to show their influence on the OU (see <xref ref-type="sec" rid="sec020">Materials and Methods</xref>, “The displayed STRFs”).</p>
<p>We can examine how the HUs interact if we “zoom in” on a part of the STRF's frequency and temporal range marked by high levels of sensitivity (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>, 'zoomed' region identified by the black bars along the axes of the STRF for the first HU of each neuron in <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3B</xref>). Contours delineate the time-frequency regions of high sensitivity for each of the effective HUs, using shades of red for excitatory HUs and shades of blue for inhibitory HUs (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>). Here, for each excitatory HU, time-frequency regions of high sensitivity were defined as those for which the STRF's weights (as shown in <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>) exceeded half the maximum weight. For the inhibitory effective HUs, high-sensitivity regions were where the STRF weights fell below half the minimum weight. For many neurons, the high-sensitivity regions of the STRFs for different HUs align in close but distinct locations in spectrotemporal space to form apparent structures, suggesting the presence of conjunctive sensitivity to ordered features (see <xref ref-type="sec" rid="sec012">Discussion</xref>).</p>
<p>OUs tend to operate “near threshold” (where “threshold” is the lowest possible output value, see <xref ref-type="sec" rid="sec020">Materials and Methods</xref>), with activations (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3D</xref>, bottom panel per neuron, black histogram) mostly confined to the expansive part of their nonlinear activation function (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3D</xref>, bottom panel, red line), just like the LN model. However, the same is not always true for the effective HUs, many of which experience activations (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3B</xref>, bottom panels per neuron, black histogram) that sometimes fall in the linear range of their nonlinear activation function (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3B</xref>, bottom panels, red or blue line), or even operate over the compressive, upper range of their nonlinear activation function.</p>
</sec>
<sec id="sec006">
<title>NRF models have between 1 and 7 effective hidden units</title>
<p>For the NRF model, the most common number of effective HUs of a neuron was 2; this was the case for 42% (32/76) of neurons (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4A</xref>). Such 'bi-feature' neurons always have one excitatory and one inhibitory HU (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4B</xref>). A few 'uni-feature' neurons, with only an excitatory effective HU, made up 5% (4/76) of our sample (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4A</xref>). The remaining 53% (42/76) were 'multi-feature' neurons with between 3 and 7 (mode = 5) effective HUs (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4A</xref>), which tended to have more excitatory HUs than inhibitory HUs (p = 0.035, n = 76, sign test; <xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4B</xref>).</p>
<fig id="pcbi.1005113.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005113.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Properties of the feedforward neural network model.</title>
<p>(A) Histogram of the number of effective hidden units (HU) of the NRF model fits for each neuron. (B) Distribution of the number of effective excitatory and inhibitory HUs for each neuron. (C) Frequency tuning width of the NRF model versus that of the LN model. The red dot indicates the average frequency tuning width of both models. (D) Temporal tuning width of the power STRF of the NRF model versus that of the LN model. The red dot indicates the average temporal tuning width of both models. (E) A plot of the expansive/compressive (EC) score (which measures how the nonlinear activation function is used) against the excitatory/inhibitory (IE) score for all 246 effective HUs from the 76 neurons. Contour plot shows the density. (F) Distribution of the EC score for excitatory (red) and inhibitory (blue) HUs. (G) Distribution of the EC score for the output unit of the NRF model (red) and for the LN model (cyan). (H) Distribution of the EC score for excitatory (red) and inhibitory (blue) HUs for the bi-feature neurons. (I) Distribution of the EC score for excitatory (red) and inhibitory (blue) HUs for the multi-feature neurons.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005113.g004" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec007">
<title>NRF models reveal wider integration over time and frequency than LN models</title>
<p>To quantify the time and frequency tuning widths of LN model STRFs, we first calculated the “power STRF” for each neuron by squaring the weights in the STRF (see <xref ref-type="sec" rid="sec020">Materials and Methods</xref>). The temporal tuning width was then determined by summing the power STRF over the frequency bands and counting the number of time bins with power ≥25% of the maximum. Multiplying this count by the temporal bin size gave the temporal tuning width at quarter-height. The frequency tuning width at quarter-height was measured analogously by summing the power STRF over time and multiplying the number of bins exceeding a quarter of the maximal power by the width of each frequency channel.</p>
<p>To obtain comparable measurements of overall tuning widths for the NRF models, we calculated power STRFs for each of the NRF model’s HUs, then summed their power STRFs, weighted by the strength of the signals that they contribute to the OU, which was quantified as the variances of their weighted-outputs, as shown in the bar charts in <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3D</xref>. Quarter-height frequency and temporal tuning widths were then calculated from the weighted sum power STRF in the same way as for the LN model power STRFs.</p>
<p>The quarter-height frequency and the temporal tuning width for the NRF model was, for most neurons, significantly larger than for the LN model (n = 76, p = 1.6×10<sup>−3</sup> and p = 1.8×10<sup>−12</sup>, respectively, sign-test; <xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4C and 4D</xref> respectively). On average, the frequency tuning width for the NRF model was 0.83 octaves, which is 54% larger than the 0.54 octaves for the LN model. The average temporal tuning width for the NRF model was 28.2 ms, which is 99% larger than the 14.2 ms for the LN model. We also carried out analogous analyses for frequency and temporal tuning widths measured at half-height, which produced similar results, showing significantly larger tuning widths in the NRF model for both frequency and time (27% and 46% larger, respectively, n = 76, p = 0.033 and 1.7×10<sup>−7</sup>, respectively, sign-test).</p>
</sec>
<sec id="sec008">
<title>Inhibitory and excitatory receptive sub-fields have different nonlinear properties</title>
<p>We next examined whether excitatory or inhibitory HUs differ in the extent to which they operate over the expansive, linear or compressive part of their output nonlinear activation function. For each effective HU in our dataset, we computed an expansive/compressive measure (EC score) and inhibitory/excitatory measure (IE score; see <xref ref-type="sec" rid="sec020">Materials and Methods</xref> for details). Both EC and IE scores are bounded between -1 and 1. A unit with a negative EC score operates predominantly in a near-threshold, expansive region of its nonlinearity, while a positive score indicates that it operates in a compressive, saturating region, and a score close to zero indicates operation in a linear region. Negative IE scores mean that a unit is (predominantly) inhibitory and positive scores that it is excitatory. EC scores are plotted against IE scores for all 246 effective HUs from the 76 neurons in <xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4E</xref>. Superimposed on the scatter plot is a contour plot reflecting the density estimate of the scatter in the “EC/IE space”. The density estimation used a kernel with its bandwidth optimized to smooth away statistically spurious peaks [<xref ref-type="bibr" rid="pcbi.1005113.ref032">32</xref>]. The HUs fell into two broad clusters: the first, dense cluster is excitatory (IE ≥ 0) and expansive (EC &lt; 0), whereas the other, broader cluster is inhibitory (IE &lt; 0) and more linear (EC ≈ 0).</p>
<p>To confirm this observation, we divided the neurons into excitatory (IE ≥ 0) and inhibitory (IE &lt; 0), and separately plotted the distribution of the EC score for each, again using a kernel density estimator with optimally chosen kernel bandwidth (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4F</xref>). The EC scores of the 115 inhibitory HUs (blue) were more or less symmetrically distributed around 0, indicating that these HUs mostly operate in a linear region, whereas the great majority of the 131 excitatory HUs have EC scores &lt;0, indicating that they tend to operate in the near threshold, expansive region of their output nonlinear activation function. The difference in the median EC value of the two distributions was significant (p = 6.1<bold><italic>×</italic></bold>10<sup>−6</sup>, rank sum test), confirming the EC/IC space clustering observations (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4E</xref>). The distribution of EC scores for the OUs of the NRF model for all 76 neurons (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4G</xref>, red), shows that the OUs operate largely near threshold, in the expansive region (EC &lt; 0). This is similar to the case for the EC scores in the LN model (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4G</xref>, cyan), where all the neurons also operate in the expansive region (EC &lt; 0).</p>
<p>If we restrict the above analysis to only the HUs of uni-feature and bi-feature neurons (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4H</xref>, for density estimation the bandwidths from <xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4E</xref> were used), we observe that the median EC values of the 36 excitatory and 32 inhibitory HUs differ significantly (p = 4.8<bold><italic>×</italic></bold>10<sup>−5</sup>, rank sum test), as is the case for all HUs (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4F</xref>). If we restrict the EC distribution analysis to multi-feature neurons alone we again observe the same pattern (p = 2.4<bold><italic>×</italic></bold>10<sup>−3</sup>, rank sum test) as for all HUs (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4I</xref>, again the <xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4E</xref> bandwidths were used). However, the 36 excitatory HUs for the uni-feature and bi-feature neurons are significantly (p = 1.7<bold><italic>×</italic></bold>10<sup>−6</sup>, Levene's test) more tightly clustered than the 95 excitatory HUs of multi-feature neurons, indicating that the uni- and bi-feature neurons show less diversity in their use of the nonlinear activation function. The decrease in diversity for the 32 inhibitory HUs of uni- and bi-feature neurons relative to the 83 inhibitory HUs of the multi-feature neurons is also significant (p = 0.032, Levene’s test).</p>
</sec>
<sec id="sec009">
<title>Potential functional role of nonlinear characteristics</title>
<p>We have seen that NRF models capture more of the response properties of auditory cortical neurons than conventional LN models, and that they achieve this through the interplay of modest numbers of excitatory and inhibitory HUs. In this section, we consider which functional properties of cortical neurons might be captured by the NRF models. We identify two such properties: gain control and multi-feature sensitivity.</p>
<sec id="sec010">
<title>Gain control</title>
<p>We can use simulations derived from our modeling to show that the interplay of excitation and inhibition seen in the NRF models enables them to exhibit gain control. For an example bi-feature neuron (neuron 2 of <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3</xref>), we plotted the OU firing rate as a function of the activation of the excitatory HU (<xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5A</xref>). Using different hues from red to magenta, this dependence of OU firing rate on excitatory HU activation is shown for 7 different levels of inhibitory HU activation, which were also chosen to span the range of the inhibitory HU activation. Observe that increasing the inhibitory drive reduces the slope of the relationship between excitatory drive and OU firing rate. In other words, the inhibitory input reduces the gain of the excitatory drive on the OU: the effect of the inhibition is more “divisive” than “subtractive”. This form of gain control is not observed if we feed the inhibition into the excitatory HU instead of the OU; instead a threshold shift, i.e. a “subtractive inhibition”, is seen (<xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5B</xref>). Gain control is also not observed if the HU output functions are linear rather than sigmoidal. We measure the gain as the steepest slope of the OU-firing-rate vs. excitatory-HU-activation curves (<xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5A</xref>). For the bi-feature neurons the gain tends to decrease with increasing inhibitory HU activation (<xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5C</xref>), with the gain for 31/32 neurons being lower for the highest inhibitory HU activation than it is for the lowest inhibitory HU activation.</p>
<fig id="pcbi.1005113.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005113.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Functional implications of the neural network model fits.</title>
<p>(A) The effect of activation of the inhibitory hidden unit (HU) on the relationship between output unit (OU) firing rate and excitatory HU activation, for an example bi-feature neuron's NRF. The steepest slope of each curve is its gain. Activation in all plots is normalized to span 0–1, where 0 is the 1<sup>st</sup> centile and 1 the 99<sup>th</sup> centile of the distribution of activations over the stimulus set (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>). (B) The effect of inhibiting the excitatory HU (instead of the OU) on the same relationship for the same example NRF. (C) The gain as a function of inhibitory HU activation for all 32 bi-feature neurons (black lines). For each neuron the gain is normalized to be 1 when the normalized inhibitory HU activation is 0. Red/magenta line: the mean. Note that the full range of excitatory HU activations, from threshold to saturation of the HU, was examined to find the steepest slopes and hence the gain (i.e. beyond the 1<sup>st</sup> and 99<sup>th</sup> centiles). (D) The OU firing rate of an NRF model fit for an example multi-feature neuron (red line). The dotted line is the 2<italic>σ</italic>-threshold. (E) The weighted-output (the input to the OU, HU output × output weight) from the 3 effective excitatory HUs. (F) The weighted-output from the single effective inhibitory HU for this neuron. (G) The distribution of peak time ratio for all multi-feature neurons. The peak time ratio is the number of times the sum of the outputs of all reduced-NRF models exceeded the 2<italic>σ</italic>-threshold, relative to the number of times the output of the full NRF did so. The reduced-NRF models of a neuron each retain just one of the excitatory HUs.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005113.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec011">
<title>Multi-feature selectivity</title>
<p>We have seen that NRFs can reveal multiple excitatory fields of several HUs arranged closely together, but distinct, in time-frequency space (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>). This raises the question of what advantage parsing these excitatory regions out over several HUs rather than just combining them in a single STRF, as in an LN model, would bring. To address this, we have plotted the activity of the components of the NRF of one multi-feature neuron (neuron 5 in <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3</xref>) during 800 ms of test-set auditory stimulation. Plotted are the OU output (<xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5D</xref>) and effective HU weighted-outputs (excitatory HUs, <xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5E</xref>, inhibitory HUs, <xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5F</xref>). Note that the weighted-outputs of the excitatory HUs are often correlated, and that the OU tends to give a substantial response only when the weighted-output of more than one excitatory HU peaks at the same time. For example, at 4.2 s (<xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5E</xref>, left black box), one of the excitatory HUs is highly active, but the other two are not, and the OU gives little response, while at 4.75 s (<xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5E</xref>, right black box) two HUs are active and the OU response is ~6 times higher.</p>
<p>Given that the output and excitatory HUs tend to operate over the expansive, near-threshold range of the nonlinear activation function, one might expect a conjunctive effect to be common, whereby the OU “goes substantially above threshold” only when several features of the excitatory HUs occur together. To examine how single excitatory HUs on their own can drive the OU, we ran the natural sounds through the NRF model with all but one of its excitatory HUs disabled (set below 'threshold'). We did this for each excitatory HU in turn to obtain the response of the OU if it only had that one excitatory HU. Then, to provide a conservative comparison with the original model, we summed the OU response for all of those single excitatory HU reduced-NRF models (for example, a 3 excitatory HU NRF would produce 3 single excitatory HU reduced-NRF models, whose responses were summed). We then determined the number of time bins for which this summed response was above the 2<italic>σ</italic>-threshold (<xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5D</xref>, as in <xref ref-type="fig" rid="pcbi.1005113.g002">Fig 2B</xref>), and called this number the summed-reduced-NRF peak time. We compared this to the number of time bins during which the response of the original model exceeded the 2<italic>σ</italic>-threshold; we called this number the NRF peak time. We did this for all 36 neurons with more than one excitatory HU. Across the 36 neurons, the NRF peak time typically (for 78%, 28/36, of the neurons) exceeded the summed-reduced-NRF peak time (p = 1.2×10<sup>−3</sup>, sign test). <xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5G</xref> shows the distribution over the neurons of the peak time ratio, the neuron's summed-reduced-NRF peak time (the number of times the summed single excitatory HU response was above the 2<italic>σ</italic>-threshold) divided by its NRF peak time (the number of times the 2<italic>σ</italic>-threshold was surpassed by the unmodified model). Here we can see the strength of the conjunctive effect, the summed single excitatory HU response exceeded the 2<italic>σ</italic>-threshold less than half as often as the unmodified model alone (peak time ratio &lt; 0.5) for 67% (24/36) of the multi-feature neurons. This implies that, for many of the multi-feature neurons, spectrotemporal features often interact in a conjunctive, supra-additive manner. Such neurons require the simultaneous presence of multiple particular features to produce a substantial response, and respond very little to just one such feature alone. This need not have been the case, as it could have been that each feature alone could substantially drive the neuron, as is seen for 22% (8/36) of the neurons, which have a peak time ratio ≥1.</p>
</sec>
</sec>
</sec>
<sec id="sec012" sec-type="conclusions">
<title>Discussion</title>
<p>The network models we developed here represent a substantial improvement over conventional LN models in that they are able to produce more accurate predictions of the responses of cortical neurons to natural sounds, while remaining sufficiently parsimonious that they it can be quickly fitted using limited data and interpreted in a manner relevant to the known physiology of the auditory pathway. The NRF models are significantly more complex than LN models–in fact, their number of degrees of freedom is greater in proportion to the number of HUs in the network. Nevertheless, compared to the enormous complexity of the lemniscal auditory pathway, in which individual neurons receive potentially thousands of converging inputs, the model complexity remains very modest. Accordingly, and as with all models of cortical processing, we cannot expect the artificial neural network to replicate the biological network in any strict anatomical detail. Instead, given their capacity to predict the responses of auditory cortical neurons to natural sounds, we propose that the NRF models capture important aspects of the general signal processing performed by the neural circuitry driving the recorded neurons, and that this is likely to apply to other areas of the brain too.</p>
<sec id="sec013">
<title>Primary auditory cortical neurons are nonlinearly sensitive to a broad spectrotemporal domain</title>
<p>Our results indicate that auditory cortical neurons likely integrate more widely over time and frequency than linear STRF or LN models would suggest (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4C and 4D</xref>). That this integration is highly nonlinear may be the reason why linear STRFs do not effectively measure this broad tuning. Although they can be quite complex [<xref ref-type="bibr" rid="pcbi.1005113.ref012">12</xref>], LN model cortical STRFs tend to be relatively simple in structure [<xref ref-type="bibr" rid="pcbi.1005113.ref013">13</xref>]. Given the extensive network that constitutes the central auditory pathway, it seems likely that more sophisticated processing is being carried out than implied by linear STRFs. NRF models may help to shed light on the nature of this processing, as they reveal a diversity, complexity and breadth of spectrotemporal integration well beyond that which can be described by conventional LN models.</p>
<p>One consequence of this finding relates to models of sparse representation of natural sounds [<xref ref-type="bibr" rid="pcbi.1005113.ref033">33</xref>], a hypothesized method by which the brain may perform unsupervised learning of the statistical structure of the environment. These sparse models result in projective fields (for many parameter settings) that are often broad in frequency and particularly in time. Our results suggest that many neurons with punctate STRFs may be better described by NRF models with broader tuning, which is more consistent with these sparse representational models.</p>
</sec>
<sec id="sec014">
<title>The neurons are well characterized by 1–7 features that segregate into inhibitory and excitatory features</title>
<p>Although we found that many of our cortical neurons can be characterized as bi-feature (one inhibitory and one excitatory HU), we also found many multi-feature neurons, with 3–7 effective HUs, typically with slightly more excitatory HUs than inhibitory (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4A and 4B</xref>). It is interesting to speculate that the bi-feature neurons may mostly be located in granular cortical layers and the multi-feature neurons in the supra/infragranular layers, since the former receive most of the thalamic inputs and are known to show simpler tuning properties than neurons in the supra/infragranular layers [<xref ref-type="bibr" rid="pcbi.1005113.ref034">34</xref>].</p>
<p>The features (HU STRFs) naturally segregate into those that inhibit the neuron and those that excite it (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4E</xref>). The excitatory features tend to operate in the expansive part of the NRF model’s nonlinear activation function, ‘near threshold’, whereas the inhibitory features tend to operate in the more linear part of the nonlinear activation function (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4F</xref>). We speculate that the excitatory and inhibitory HUs may reflect the massed effects on the recorded neuron of directly connected excitatory neurons and inhibitory neurons, respectively. Should this be the case, the difference in nonlinear characteristics may reflect the observation that inhibitory neurons tend to have higher evoked and spontaneous firing rates than excitatory neurons [<xref ref-type="bibr" rid="pcbi.1005113.ref035">35</xref>], thus placing inhibitory inputs further above threshold than excitatory inputs and perhaps providing them with a more linear dependence on input.</p>
</sec>
<sec id="sec015">
<title>Bi-feature neurons</title>
<p>Many (42%) of the neurons showed NRF fits with just two effective HUs, one excitatory and one inhibitory. The excitatory HU operates near threshold (expansive), and the inhibitory HU is more linear. The OU is also expansive. Under this arrangement, the inhibition acts on the output in a manner that appears to decrease the gain (<xref ref-type="fig" rid="pcbi.1005113.g005">Fig 5A–5C</xref>). A number of possible mechanisms, which might work in isolation or together, have been proposed for gain control, including synaptic depression [<xref ref-type="bibr" rid="pcbi.1005113.ref036">36</xref>], shunting inhibition [<xref ref-type="bibr" rid="pcbi.1005113.ref037">37</xref>] and recurrent connectivity [<xref ref-type="bibr" rid="pcbi.1005113.ref038">38</xref>]. The NRF model illustrates another possible mechanism—feedforward expansive excitation and feedforward linear inhibition acting together on a neuron with an expansive nonlinearity. In vivo patching approaches may provide a method to explore this possibility, since it may be possible to measure the inhibition and excitation separately, as well as assess the output nonlinearity. The above discussion prompts two modifications to the model to be examined in future work. The first is to include some explicit gain control mechanism, for example, HUs with a divisive effect as a functional model of shunting inhibition. The second is to add an additional layer, which will allow for HUs to depend more directly on nonlinear measures like the standard deviation of the stimulus and perhaps capture the use of gain control to normalize for contrast, as has been observed for auditory neurons with artificial stimuli [<xref ref-type="bibr" rid="pcbi.1005113.ref019">19</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref039">39</xref>–<xref ref-type="bibr" rid="pcbi.1005113.ref041">41</xref>].</p>
</sec>
<sec id="sec016">
<title>Multi-feature neurons</title>
<p>The multi-feature neurons are quite a diverse group, and substantially larger population samples would therefore be needed to look for trends in their properties and investigate whether they form identifiable groups that may serve distinct purposes. However, we can make a number of observations. Although the HUs of multi-feature neurons show more diverse nonlinearity characteristics than bi-feature neurons, they still tend towards having expansive-range excitatory HUs and linear-range inhibitory HUs. The set of STRFs of multi-feature neurons can be quite complex and varied (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3B</xref>), and can show distinctly structured relationships between these STRFs (e.g. neurons 7 and 8, <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>). Often the spectrotemporal regions of high sensitivity (half-height tuning area) of HU STRFs do not substantially overlap (e.g. neurons 1, 4 and 9, <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>). However, some overlap of high sensitivity regions in the STRFs can occur, between excitatory HUs (e.g. neurons 5–8, <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>), between inhibitory HUs (neuron 7, <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>), and between excitatory and inhibitory HUs (neurons 6, 7, and 10, <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>).</p>
<p>Given that the model fitting process penalizes redundant STRF weights, the presence of spectrotemporal overlap in STRFs of different HUs may indicate that the NRF is using multiple HUs to alter the nonlinearity of the input-output mapping in order to achieve a better fit to the true output nonlinearity of the biological neuron. However, for the most part, the high sensitivity regions of HU STRFs are non-overlapping, suggesting that additional factors drive the diversity of multi-feature neuron STRFs. In a number of cases, excitatory fields of different HUs align consecutively along the time axis, sometimes with some overlap (e. g. neurons 4, 6, 7 and 10, <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>). This may to some extent capture the relationship between sound intensity and response latency found in both the auditory nerve and the cortex [<xref ref-type="bibr" rid="pcbi.1005113.ref042">42</xref>], as in some cases the shorter latency HU also has a higher ‘threshold’ (i.e. has a lower EC value, e.g. neuron 4, <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>). However, this is unlikely to be the whole story, because in other cases different excitatory HUs exhibit distinct well-separated regions of temporal tuning (e.g. neuron 10, <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>). In addition, STRF excitatory fields may also align over the frequency axis (e.g. neurons 1, 5 and 8, <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>) or align diagonally over time and frequency (e.g. neurons 6 and 9, <xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>).</p>
<p>For many multi-feature neurons (although far from all), the NRF requires that multiple excitatory HUs are activated simultaneously to produce a substantial response (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4D–4G</xref>). That the NRF model can capture such supra-additive sensitivity to particular conjunctions of multiple spectrotemporal features, while the LN model cannot, may explain why the NRF model is better able to predict the peak amplitudes of the responses of cortical neurons. This conjunctive feature selectivity allows for increased selectivity for particular complex spectrotemporal patterns consisting of a number of more basic features, a characteristic with an obvious potential role in sound recognition.</p>
</sec>
<sec id="sec017">
<title>Related work</title>
<p>A number of methods have been used previously to examine the spectrotemporal sensitivity of auditory cortical neurons. Previous studies have attempted to extend the application of the LN model to auditory cortical data, mostly using maximum-likelihood methods. Indeed, several studies have used approaches that have fundamental similarities to the one we explore here, in that they combine or cascade several linear filters in a nonlinear manner. One such body of work that improved predictions over the LN model is based on finding the maximally-informative dimensions (MID) [<xref ref-type="bibr" rid="pcbi.1005113.ref020">20</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref021">21</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref034">34</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref043">43</xref>–<xref ref-type="bibr" rid="pcbi.1005113.ref046">46</xref>] that drove the response of auditory cortical neurons. This method involves finding usually one or two maximally informative linear features that interact through a flexible 1D or 2D nonlinearity, and is equivalent to fitting a form of LN model under assumptions of a Poisson model of spiking variability [<xref ref-type="bibr" rid="pcbi.1005113.ref046">46</xref>–<xref ref-type="bibr" rid="pcbi.1005113.ref048">48</xref>]. When this method was applied to neurons in primary auditory cortex it was found that the neurons’ response properties are typically better described using two features rather than one [<xref ref-type="bibr" rid="pcbi.1005113.ref020">20</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref034">34</xref>], in contrast to midbrain neurons which are well fitted using a single feature [<xref ref-type="bibr" rid="pcbi.1005113.ref043">43</xref>]. That result thus seems consistent with ours, in that we found NRFs fitted to cortical responses most commonly evolved to have two effective HUs (or input features). Another approach, that has been found to improve predictions of auditory cortical responses, is to apply a multi-linear model over the dimensions of frequency, sound level, and time lag, and for the extended multi-linear model also over dimensions involved in multiplicative contextual effects [<xref ref-type="bibr" rid="pcbi.1005113.ref021">21</xref>]. However, the above studies in auditory cortex [<xref ref-type="bibr" rid="pcbi.1005113.ref020">20</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref034">34</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref043">43</xref>] did not use natural stimuli, and hence might not have been in the right stimulus space to observe some complexities, as STRFs measured with natural stimuli can be quite different than when measured with artificial stimuli [<xref ref-type="bibr" rid="pcbi.1005113.ref049">49</xref>]. An advantage of the NRF model is that its architecture is entirely that of traditional feedforward models of sensory pathways in which activations of lower level features simply converge onto model neurons with sigmoidal input-firing rate functions. NRFs can therefore be interpreted in a context that is perhaps simpler and more familiar than that of, for example, maximally informative dimension models [<xref ref-type="bibr" rid="pcbi.1005113.ref020">20</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref044">44</xref>].</p>
<p>Other developments on the standard LN model have included model components that can be interpreted as intraneuronal rather than network properties, such as including a post-spike filter [<xref ref-type="bibr" rid="pcbi.1005113.ref022">22</xref>] or synaptic depression [<xref ref-type="bibr" rid="pcbi.1005113.ref023">23</xref>], and have also been shown to improve predictions. Pillow and colleagues [<xref ref-type="bibr" rid="pcbi.1005113.ref050">50</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref051">51</xref>] applied a generalized linear model (GLM) to the problem of receptive field modelling. Their approach is similar to the basic LN model in that it involves a linear function of stimulus history combined with an output nonlinearity. However, unlike in LN models, the response of their GLM also depends on the spike history (using a post-spike filter). This post-spike filter may reflect intrinsic refractory characteristics of neurons, but could also represent network filter effects. A GLM model has been applied to avian forebrain neurons [<xref ref-type="bibr" rid="pcbi.1005113.ref022">22</xref>], where it has been shown to significantly improve predictions of neural responses over a linear model, but not over an LN model.</p>
<p>Although they haven’t yet been applied to auditory cortical responses, it is worth mentioning two extensions to GLMs. First, GLMs can be extended so that model responses depend on the history of many recorded neurons [<xref ref-type="bibr" rid="pcbi.1005113.ref050">50</xref>], representing interconnections between recorded neurons. While this approach is thus also aimed at modeling network properties, it is quite different from our NRF model, where we infer the characteristics of hidden units. Second, the extension of the GLM approach investigated by Park and colleagues [<xref ref-type="bibr" rid="pcbi.1005113.ref052">52</xref>] included sensitivity to more than one stimulus feature. Thus, like our NRF or the multi-feature MID approach, this “generalized quadratic model” (GQM) has an input stage comprising several filters which are nonlinearly combined, in this case using a quadratic function. One might argue that our choice for the HUs of a sigmoidal nonlinearity following a linear filter stage, and the same form for the OU, is perhaps more similar to what occurs in the brain, where dendritic currents might be thought of as combining linearly according to Kirchhoff’s laws as they converge on neurons that often have sigmoidal current-firing rate functions. However, we do not wish to overstate either the physiological realism of our model (which is very rudimentary compared to the known complexity of real neurons) or the conceptual difference with GQMs or multi-feature MIDs. A summation of sigmoidal unit outputs may perhaps be better motivated physiologically than a quadratic function, but given the diversity of nonlinearity in the brain this is a debatable point.</p>
<p>Another extension to GLMs, a generalized nonlinear model (GNM), does, however, employ input units with monotonically-increasing nonlinearities, and unlike multi-neuron GLMs or GQMs, GNMs have been applied to auditory neurons by Schinkel-Bielefeld and colleagues [<xref ref-type="bibr" rid="pcbi.1005113.ref024">24</xref>]. Their GNM comprises a very simple feedforward network based on the weighted sum of an excitatory and an inhibitory unit, along with a post-spike filter. The architecture of that model is thus not dissimilar from our NRFs, except that the number of HUs is fixed at two, and their inhibitory and excitatory influences are fixed in advance. It has been applied to mammalian (ferret) cortical neural responses, uncovering non-monotonic sound intensity tuning and onset/offset selectivity.</p>
<p>For neurons in the avian auditory forebrain, although not for mammalian auditory cortex, GNMs have also been extended by McFarland and colleagues to include the sum of more than two input units with monotonically-increasing nonlinearities [<xref ref-type="bibr" rid="pcbi.1005113.ref053">53</xref>]. Of the previously described models, this cascaded LN-LN ‘Nonlinear Input Model (NIM)’ model bears perhaps the greatest similarity with our NRF model. Just like our NRF, it comprises a collection of nonlinear units feeding into a nonlinear unit. The main differences between their model and ours thus pertain not to model architecture, but to the methods of fitting the models and the extent to which the models have been characterized. The NIM has been applied to a single zebra finch auditory forebrain neuron, separating out its excitatory and inhibitory receptive fields in a manner similar to what we observe in the bi-feature neurons described above.</p>
<p>One advantage of the NRF over the NIM is that the fitting algorithm automatically determines the number of features that parsimoniously explain each neuron's response, obviating the need to laboriously compare the cross-validated model performance for each possible number of hidden units. Another difference is that the NRF is simpler while still maintaining the capacity to capture complex nonlinear network properties of neural responses; for example, the NIM [<xref ref-type="bibr" rid="pcbi.1005113.ref053">53</xref>] had potentially large numbers of hyperparameters (four for each hidden unit or “feature”) that were manually turned, something that would be very difficult to do if the model needed to be fitted to datasets comprising large numbers of neurons. In contrast, the NRF has only one hyperparameter for the entire network, which can easily be tuned in an automated parameter search with cross-validation. Consequently, we have been able to use the NRF to characterize a sizeable population of recorded neurons, but so far no systematic examination of the capacity of the NIM to explain the responses of many neurons has been performed.</p>
<p>Another recent avian forebrain study [<xref ref-type="bibr" rid="pcbi.1005113.ref054">54</xref>] used a maximum noise entropy (MNE) approach to uncover multiple receptive fields sensitive to second-order aspects of the stimulus. Unlike the above two GNM [<xref ref-type="bibr" rid="pcbi.1005113.ref024">24</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref053">53</xref>] approaches, this model does not have hidden units with sigmoidal nonlinearities, but finds multiple quadratic features. The MNE predicted neural responses better than a linear model, although still poorly, with an average <italic>CC</italic><sub><italic>raw</italic></sub> of 0.24, and it was not determined whether it could out-predict an LN model. Note, however, that the <italic>CC</italic><sub><italic>raw</italic></sub> values reported in that study do not distinguish stimulus-driven response variability from neural “noise”. Consequently, it is unclear whether the relatively modest <italic>CC</italic><sub><italic>raw</italic></sub> values reported there might reflect shortcomings of the model or whether they are a consequence of differences in the species, brain regions and stimuli under study. Finally, perhaps the most relevant study in the avian forebrain used a time delay feedforward neural network to predict responses of zebra finch nucleus ovoidalis neurons to birdsong [<xref ref-type="bibr" rid="pcbi.1005113.ref055">55</xref>]. These authors reported that the network predicted neural responses better than a linear model, but performed no quantitative comparisons to support this.</p>
<p>Advances on the LN model have also been applied in other brain regions. Various advances on the LN model have also been made in studies of primary visual cortex, and of particular relevance are the few cases where neural networks have been used to predict neural responses. Visual cortical responses to certain artificial stimuli (randomly varying bar patterns and related stimuli) have been fitted using a single hidden layer neural network, resulting in improvements in prediction over linear models for complex but not simple cells in one study [<xref ref-type="bibr" rid="pcbi.1005113.ref056">56</xref>] and over LN-like models in another study [<xref ref-type="bibr" rid="pcbi.1005113.ref057">57</xref>]. However, the challenge we tackle here is to predict the responses to natural stimuli. In this respect we are aware of only one similar study by Prenger and colleagues [<xref ref-type="bibr" rid="pcbi.1005113.ref058">58</xref>] which used a single hidden layer neural network to predict responses to series of still images of natural scenes. The network model in this study gave better predictions than an LN model with a simple rectifying nonlinearity. However, the improvements had limited consistency, predicting significantly better in only 16/34 neurons, and it did worse than an LN model applied to the power spectra of the images. Additionally, the <italic>CC</italic><sub><italic>raw</italic></sub> of the model predictions with the neural data were somewhat small (0.24). This appears to contrast with the seemingly better performance we obtained with our NRF model.</p>
<p>These apparent differences in model performance may, however, not all be attributable to differences in model design or fitting. In addition to the fact we already noted that low <italic>CC</italic><sub><italic>raw</italic></sub> values might be diagnostic of very noisy neurons rather than shortcomings of the model, we also need to be cognizant of the differences in the types of data that are being modeled: we applied our model responses of auditory cortical neurons to natural auditory sound recordings, whereas Prenger and colleagues [<xref ref-type="bibr" rid="pcbi.1005113.ref058">58</xref>] applied theirs to visual cortical neuron responses to random sequences of photographs of natural scenes. Furthermore, the neural responses to our stimuli were averaged over several repeats, whereas the above study did not use repeated stimuli, which may limit how predictable their neural responses may be. However, there are also notable structural differences between their model and ours. For example, the activation function on the OU in the Prenger et al. study [<xref ref-type="bibr" rid="pcbi.1005113.ref058">58</xref>] was linear (as with [<xref ref-type="bibr" rid="pcbi.1005113.ref056">56</xref>] but not [<xref ref-type="bibr" rid="pcbi.1005113.ref057">57</xref>]), whereas the OU of our NRF has a nonlinear activation function, which enables our NRF to model observed neuronal thresholds explicitly. Furthermore, we used a notably powerful optimization algorithm, the sum-of-function optimizer [<xref ref-type="bibr" rid="pcbi.1005113.ref026">26</xref>], which has been shown to find substantially lower values of neural network cost function than the forms of gradient descent used in the above neural network studies. Finally, the <italic>L</italic><sub>1</sub>-norm regularization that we used has the advantage of finding a parsimonious network quickly and simply, as compared with the more laborious and often more complex methods of the above three studies: <italic>L</italic><sub>2</sub>-norm-based regularization methods and hidden unit pruning [<xref ref-type="bibr" rid="pcbi.1005113.ref058">58</xref>], early stopping and post-fit pruning [<xref ref-type="bibr" rid="pcbi.1005113.ref056">56</xref>] or no regularization and comparing different numbers of hidden units [<xref ref-type="bibr" rid="pcbi.1005113.ref057">57</xref>].</p>
</sec>
<sec id="sec018">
<title>Predictive capacity and possible model improvements</title>
<p>The predictions of the NRF models correlate with the observed neural responses with a <italic>CC</italic><sub><italic>norm</italic></sub> of 0.73 on average. Asari and Zador [<xref ref-type="bibr" rid="pcbi.1005113.ref031">31</xref>] estimated an upper limit on the performance that any model of A1 neurons might be able to achieve in predicting responses from a given duration of stimulus history. Our models predict responses from the last 100 ms of stimulus history, for which Asari and Zador [<xref ref-type="bibr" rid="pcbi.1005113.ref031">31</xref>] give an upper performance limit of 0.5–0.55 “signal power explained” (SPE). For SPE values in this range, SPE is approximately equal to the square of <italic>CC<sub>norm</sub></italic> [<xref ref-type="bibr" rid="pcbi.1005113.ref059">59</xref>], so that an upper limit SPE of 0.5–0.55 corresponds to an upper limit <italic>CC<sub>norm</sub></italic> of 0.71–0.74. This suggests that the NRF may possibly be capturing the majority of the neural response that is dependent on the stimulus, given the duration of stimulus history provided (100 ms).</p>
<p>The performance upper bound reaches its maximal plateau when about 3 s of stimulus history are provided [<xref ref-type="bibr" rid="pcbi.1005113.ref031">31</xref>]. This suggests that the most important way of advancing neural network models of auditory cortex might be to include a substantially longer stimulus history in the analysis. However, simply extending the number of time bins in the current model some 30 fold further into the past would likely lead to far too many free parameters. A better option might be to extend the approach presented here in the direction of convolutional or recurrent neural networks. Artificial recurrent neural networks have been applied successfully to sound recognition problems [<xref ref-type="bibr" rid="pcbi.1005113.ref060">60</xref>], and it is well known that feedback projections are common features of the auditory pathway. Developing recurrent versions of the NRFs introduced here is therefore likely to be important, particularly if we hope to develop successful models of higher order auditory cortical neurons.</p>
</sec>
<sec id="sec019">
<title>Conclusions</title>
<p>In summary, we have shown that fitting feedforward network models (with regularization of the weights to be sparse) to single neuron activity in primary cortical areas (A1/AAF) allows for better predictions of their responses to natural sounds, and has the potential to unmask some of the nonlinear signal processing strategies used by the auditory brain. This approach reveals more of the underlying richness and nonlinearity of cortical processing in an easily interpretable form. Neural responses to natural sounds in A1/AAF appear to be dependent on multiple features in the stimulus space that often interact in structured nonlinear ways, and depend upon a substantially larger spectrotemporal domain than is suggested by linear models with a simple output nonlinearity.</p>
</sec>
</sec>
<sec id="sec020" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="sec021">
<title>Electrophysiological recording</title>
<p>To assess the capacity of NRFs to account for cortical sensory responses, we fitted models to neural responses to clips of natural sounds. Single-unit responses were recorded with multi-channel electrodes in the ferret primary auditory cortex (A1) and the anterior auditory field (AAF), which are both considered to be primary cortical areas [<xref ref-type="bibr" rid="pcbi.1005113.ref061">61</xref>]. All animal procedures were performed under license from the United Kingdom Home Office and were approved by the local ethical review committee. For full details of the recording procedures see [<xref ref-type="bibr" rid="pcbi.1005113.ref062">62</xref>]. In brief, electrophysiological recordings were made from 6 adult pigmented ferrets under ketamine (5 mg/kg/h) and medetomidine (0.022 mg/kg/h) anesthesia. Bilateral extracellular recordings were made in A1/AAF using either 16 or 32 channel silicon probe electrodes (Neuronexus Technologies). Because these primary cortical fields share a common tonotopic gradient [<xref ref-type="bibr" rid="pcbi.1005113.ref061">61</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref063">63</xref>], we did not attempt to assign our sample of 76 units to one or other of these regions.</p>
</sec>
<sec id="sec022">
<title>Stimuli</title>
<p>In this study we modeled the responses of neurons to 20 clips of natural sound recordings. Each clip was 5 s long, and presented at a sampling rate of 48,828.125 Hz, using earphones as described by [<xref ref-type="bibr" rid="pcbi.1005113.ref019">19</xref>]. The clips were presented in random order, with a ~1 s silent interval between clips, and were repeated 20 times. The natural sound recordings included animal sounds (e.g. ferret vocalization and birdsong), environmental sounds (e.g. water and wind), and speech. The RMS intensity of clips ranged from 75 to 82 dB SPL. Data recorded during the first 250 ms after the onset of each stimulus were discarded, leaving an effective set of neural responses to 20 repeats of 20 sounds of 4.75 s duration each.</p>
</sec>
<sec id="sec023">
<title>Preprocessing of neural data and stimuli</title>
<p>NRF and LN models were fitted to the relationship between the neural data and the sound stimuli, after appropriate preprocessing as described below.</p>
<sec id="sec024">
<title>Neural data</title>
<p>Recorded spikes were sorted offline using Spikemonger, in-house software built around Klustakwik [<xref ref-type="bibr" rid="pcbi.1005113.ref064">64</xref>], to isolate single units. For each neuron, for each clip, peri-stimulus time histograms (PSTHs) were constructed, counting spikes in 5 ms bins, averaging over all 20 repeats, and subsequently smoothing with a 21 ms wide Hanning window [<xref ref-type="bibr" rid="pcbi.1005113.ref029">29</xref>] to estimate the spike count PSTH <italic>y</italic><sub><italic>n</italic></sub>(<italic>t</italic><sub><italic>n</italic></sub>) for each neuron at time <italic>t</italic><sub><italic>n</italic></sub>, where <italic>t</italic><sub><italic>n</italic></sub> is the time since the start of clip <italic>n</italic> (<italic>n</italic> goes from 1 to <italic>N</italic> = 20, <italic>t</italic><sub><italic>n</italic></sub> from 1 to <italic>T</italic><sub><italic>n</italic></sub> = 949). For fitting the NRF model the spike counts were also linearly rescaled to span the standard network nonlinear activation function (see below), so spike count 0 mapped to -σ<sub>1</sub> and spike count 1 to +σ<sub>1</sub>, where σ<sub>1</sub> = 1.7159. For model comparison, all spike counts were rescaled back, and for display all spike counts were rescaled to spike rates. To identify those neurons that were driven by the stimuli, we calculated a “noise ratio” (NR) statistic for each neuron [<xref ref-type="bibr" rid="pcbi.1005113.ref019">19</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref065">65</xref>] and excluded from further analysis any neurons with a NR&gt;40.</p>
</sec>
<sec id="sec025">
<title>Cochleagram</title>
<p>To transform the sound stimuli into a simple approximation of the activity pattern received by the auditory pathway, we processed the sound waveforms to calculate log-scaled spectrograms ('cochleagrams'). For each sound, the power spectrogram was taken using 10 ms Hamming windows, overlapping by 5 ms. The power across neighboring Fourier frequency components was then aggregated using overlapping triangular windows comprising 34 frequency channels with center frequencies ranging from 500 Hz to 22,627 Hz (⅙ octave spacing). Next, the log was taken of the power in each time-frequency bin, and finally any values below a low threshold were set to that threshold. These calculations were performed using code adapted from melbank.m (<ext-link ext-link-type="uri" xlink:href="http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.html" xlink:type="simple">http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.html</ext-link>). Both the LN and the NRF models were trained to predict the firing rate <italic>y</italic><sub><italic>n</italic></sub>(<italic>t</italic><sub><italic>n</italic></sub>) at time <italic>t</italic><sub><italic>n</italic></sub> from a snippet of the cochleagram extending 100 ms (20 time bins) back in time from <italic>t</italic><sub><italic>n</italic></sub>. The input to the models at time <italic>t</italic><sub><italic>n</italic></sub> is thus a 34×20 matrix (<italic>F =</italic> 34 frequency channels by <italic>H =</italic> 20 stimulus history time bins) of log sound power values preceding time <italic>t</italic><sub><italic>n</italic></sub>. We denote this as <italic>x</italic><sub><italic>nfτ</italic></sub>(<italic>t</italic><sub><italic>n</italic></sub>), where <italic>n</italic> is the index of the presented clip, <italic>f</italic> indexes the frequency bands, and <italic>τ</italic> indexes time history bins preceding time <italic>t</italic><sub><italic>n</italic></sub>. For fitting the NRF model, <italic>x</italic><sub><italic>nfτ</italic></sub>(<italic>t</italic><sub><italic>n</italic></sub>) was also normalized so the whole dataset had zero mean (&lt;<italic>x</italic><sub><italic>nfτ</italic></sub>(<italic>t</italic><sub><italic>n</italic></sub>)&gt;<sub><italic>nfτ</italic></sub> <italic>= 0)</italic> and unit variance. To simplify notation we define <italic>t</italic> as all the times <italic>t</italic><sub><italic>n</italic></sub> of all the sound clips <italic>n</italic>, where <italic>t</italic> goes from 1 to <italic>T</italic><sub><italic>n</italic></sub> × <italic>N</italic>. This gives <italic>y</italic>(<italic>t</italic>) and <italic>x</italic><sub><italic>fτ</italic></sub>(<italic>t</italic>).</p>
</sec>
</sec>
<sec id="sec026">
<title>LN model</title>
<sec id="sec027">
<title>Linear stage</title>
<p>The LN model (<xref ref-type="fig" rid="pcbi.1005113.g001">Fig 1A</xref>) consists of two stages: a linear STRF followed by a sigmoidal output nonlinearity. The linear part of the model is:
<disp-formula id="pcbi.1005113.e001">
<alternatives>
<graphic id="pcbi.1005113.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <inline-formula id="pcbi.1005113.e002"><alternatives><graphic id="pcbi.1005113.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the model neuron's “activation”, and <italic>w</italic><sub><italic>fτ</italic></sub> is the synaptic weight for frequency band <italic>f</italic> and history bin <italic>τ</italic> (all the weights compose the STRF). The bias <italic>b</italic> represents the neuron's background activity level. <italic>w</italic><sub><italic>fτ</italic></sub> and <italic>b</italic> are the free parameters of the model, and were estimated by regressing <italic>y</italic>(<italic>t</italic>) against <italic>xfτ</italic>(<italic>t</italic>) using 'glmnet' [<xref ref-type="bibr" rid="pcbi.1005113.ref066">66</xref>]. Thus <inline-formula id="pcbi.1005113.e003"><alternatives><graphic id="pcbi.1005113.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> can be seen as the best linear prediction from <italic>x</italic><sub><italic>fτ</italic></sub>(<italic>t</italic>) of <italic>y</italic>(<italic>t</italic>). To avoid overfitting and to find a parsimonious model, the regression was regularized by penalizing the <italic>L</italic><sub>1</sub>-norm of <italic>w</italic><sub><italic>fτ</italic></sub> (LASSO regression). The strength of the regularization was controlled with a hyperparameter <italic>λ</italic>. The optimum value of <italic>λ</italic> was found using k-fold cross-validation for a set of log-spaced values and for each neuron, and the <italic>λ</italic> that gave the best prediction was chosen (see <italic>Training</italic>, <italic>validation</italic>, <italic>and testing of models</italic> below). The resulting <inline-formula id="pcbi.1005113.e004"><alternatives><graphic id="pcbi.1005113.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> serves as the input to the nonlinear stage for our LN-model, and as the linear prediction (output) of the purely linear L-model used for the model comparisons which are described in Results.</p>
</sec>
<sec id="sec028">
<title>Nonlinear stage</title>
<p>The second stage involved fitting a logistic sigmoid nonlinear activation function,
<disp-formula id="pcbi.1005113.e005">
<alternatives>
<graphic id="pcbi.1005113.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
which mapped the linear activation <inline-formula id="pcbi.1005113.e006"><alternatives><graphic id="pcbi.1005113.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> to the predicted PSTH <inline-formula id="pcbi.1005113.e007"><alternatives><graphic id="pcbi.1005113.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> so as to minimize the error between the predicted PSTH and the observed PSTH <italic>y</italic>(<italic>t</italic>). Recent work [<xref ref-type="bibr" rid="pcbi.1005113.ref067">67</xref>] indicates that choosing different nonlinear output functions from a wide range of plausible candidates has only modest effects on the ability of LN models to capture neural response properties. We therefore did not attempt to systematically explore different types of output nonlinearity or to make the choice of nonlinearity as physiological as possible, but rather focused on an output nonlinearity that is simple, well characterized and widely used in the artificial network literature. The four parameters ρ<sub>i</sub> of the function were fitted by minimizing the squared error
<disp-formula id="pcbi.1005113.e008">
<alternatives>
<graphic id="pcbi.1005113.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
using a quasi-Newton iterative numerical method (<ext-link ext-link-type="uri" xlink:href="http://www.cs.ubc.ca/~schmidtm/Software/minFunc.html" xlink:type="simple">http://www.cs.ubc.ca/~schmidtm/Software/minFunc.html</ext-link>).</p>
</sec>
</sec>
<sec id="sec029">
<title>NRF model</title>
<sec id="sec030">
<title>Model description</title>
<p>NRFs (<xref ref-type="fig" rid="pcbi.1005113.g001">Fig 1B</xref>) model cortical responses using a rate based feedforward artificial neural network (multilayer perceptron) with one hidden layer of <italic>J</italic> = 20 hidden units (HU) converging onto a single output unit (OU). Each unit in the network operates in a fashion similar to an LN model—each unit integrates inputs through a set of linear weights, and this linear activation is passed through a nonlinear activation function to compute its output. The activation of the <italic>j</italic>-th HU <italic>a</italic><sub><italic>j</italic></sub>(<italic>t</italic>) is,
<disp-formula id="pcbi.1005113.e009">
<alternatives>
<graphic id="pcbi.1005113.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mrow><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>w</italic><sub><italic>jfτ</italic></sub> is the weight from frequency band <italic>f</italic> and time delay <italic>τ</italic> to HU <italic>j</italic>, and <italic>b</italic><sub><italic>j</italic></sub> is the bias on the HU. The output of the HU is <italic>z</italic><sub><italic>j</italic></sub>(<italic>t</italic>), given by,
<disp-formula id="pcbi.1005113.e010">
<alternatives>
<graphic id="pcbi.1005113.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mrow><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where g(<italic>ζ</italic>) is a nonlinear function. The OU then provides the prediction <inline-formula id="pcbi.1005113.e011"><alternatives><graphic id="pcbi.1005113.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, of the firing rate <italic>y</italic>(<italic>t</italic>), as a weighted sum of the HU outputs, also passed through the nonlinear activation function. The activation <italic>a</italic><sub><italic>o</italic></sub>(<italic>t</italic>) of the OU is,
<disp-formula id="pcbi.1005113.e012">
<alternatives>
<graphic id="pcbi.1005113.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e012" xlink:type="simple"/>
<mml:math display="block" id="M12">
<mml:mrow><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>w</italic><sub><italic>j</italic></sub> is the weight from HU <italic>j</italic> to the OU, and <italic>b</italic><sub><italic>o</italic></sub> is the bias on the OU. The output <inline-formula id="pcbi.1005113.e013"><alternatives><graphic id="pcbi.1005113.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> of the OU is;
<disp-formula id="pcbi.1005113.e014">
<alternatives>
<graphic id="pcbi.1005113.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e014" xlink:type="simple"/>
<mml:math display="block" id="M14">
<mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
which is the model’s prediction of the rescaled firing rate (see <italic><xref ref-type="sec" rid="sec023">Preprocessing of neural data and stimuli</xref></italic>). For both HUs and OUs, the nonlinear activation function g(<italic>ζ</italic>) was a hyperbolic tangent function:
<disp-formula id="pcbi.1005113.e015">
<alternatives>
<graphic id="pcbi.1005113.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e015" xlink:type="simple"/>
<mml:math display="block" id="M15">
<mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ζ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mtext>tanh</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ζ</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>In the LN model, the parameters σ<sub>i</sub> of the nonlinear activation function were optimized for each neuron, but in the NRF model these parameters were fixed to <italic>ρ</italic><sub>1</sub> = 1/tanh(2/3) ≈ 1.7159 and <italic>ρ</italic><sub>2</sub> = 3/2, which ensures that g(±<italic>1</italic>) = ±1. Using this particular form of nonlinear activation function [<xref ref-type="bibr" rid="pcbi.1005113.ref068">68</xref>] facilitates efficient learning with error backpropagation by maintaining statistical properties of the input distribution. Furthermore, for a given network with tanh activation functions, there is an equivalent network with logistic activation functions (for which units have non-negative outputs), which can be found with a simple linear rescaling of the weights and biases (see page 109 of [<xref ref-type="bibr" rid="pcbi.1005113.ref069">69</xref>]). This rescaling does not affect the structure of the STRFs. We use this equivalent network for display in the Results (for details see <italic>The adjusted network</italic> below). Note that the nonlinearities g(<italic>ζ</italic>) employed by the NRF and the LN models are equivalent except for a scaling and shifting.</p>
</sec>
<sec id="sec031">
<title>Learning</title>
<p>The free parameters of the NRF, <italic>w</italic><sub><italic>jfτ</italic>+</sub>, <italic>b</italic><sub><italic>j</italic></sub>, <italic>w</italic><sub><italic>j</italic></sub> and <italic>b</italic><sub><italic>o</italic></sub>, were optimized by minimizing the following objective function:
<disp-formula id="pcbi.1005113.e016">
<alternatives>
<graphic id="pcbi.1005113.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e016" xlink:type="simple"/>
<mml:math display="block" id="M16">
<mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow/></mml:munderover><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mi>j</mml:mi><mml:mrow/></mml:munderover><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>This objective function is the sum of two terms: The first term quantifies total square error between the observed PSTH <italic>y</italic>(<italic>t</italic>) and the PSTH <inline-formula id="pcbi.1005113.e017"><alternatives><graphic id="pcbi.1005113.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> predicted by the model. The second term, proportional to the sum of the absolute values of all the weights in the network (the <italic>L</italic><sub>1</sub>-norm of the weight vectors), serves to regularize the weights. That is, it puts a “cost” on non-zero synaptic weights and will tend to drive most weights to close to zero, except for a few, and thereby encourages parsimonious models and prevents overfitting. The regularization was therefore similar to the LASSO regression used to fit the LN model, which also incorporates an <italic>L</italic><sub>1</sub>-norm regularization term.</p>
<p>For both the NRF and the LN models, the constant <italic>λ</italic> is the hyperparameter that determines the strength of the regularization. Its optimum value was determined using k-fold cross-validation (k = 10) over a log-spaced range, and for each model and neuron the value of <italic>λ</italic> that gave the best prediction for each neuron was chosen (see <italic>Training</italic>, <italic>validation</italic>, <italic>and testing of models</italic>). The NRF was initialized with the weights and biases independently drawn from a uniform distribution between <inline-formula id="pcbi.1005113.e018"><alternatives><graphic id="pcbi.1005113.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:mrow><mml:mo>±</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msqrt><mml:mi>M</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> where <italic>M</italic> is the number of incoming connection weights and biases to a given unit of the network. The objective function of the NRF model was minimized using the Sum-of-Functions Optimizer, a recently developed algorithm which combines a Newton method with batch stochastic gradient descent, and which is substantially faster and finds lower minima than other optimization algorithms for multilayer feedforward networks [<xref ref-type="bibr" rid="pcbi.1005113.ref026">26</xref>]. The optimizer was run for 40 iterations, but usually settled within 20. On a desktop PC (Intel Xeon 8-core 3.1GHz CPU) it took on the order of hours to fit all 76 neurons, including the 10-fold cross validation.</p>
</sec>
</sec>
<sec id="sec032">
<title>Training, validation, and testing of the models</title>
<p>For both the LN models and the neural networks, the model parameters (weights <italic>w</italic> and biases <italic>b</italic>, and for the LN models also the parameters of the nonlinear activation function <italic>ρ</italic><sub><italic>i</italic></sub>) were found through the model fitting steps just described, but the models can only perform effectively if the model hyperparameters (regularization strength <italic>λ</italic> and, for the NRFs, also the number of HUs <italic>J</italic>) are appropriately chosen. We therefore conducted a parameter search which systematically explored the behavior of the models for a range of hyperparameters in a cross-validation test. To this end, the entire data set of 95 s duration (20 natural sound clips of 4.75 s duration each) was first split into a cross-validation set (80%) and a test set (20%). The test set was the last 20% (0.95 s) of each of the 20 sounds. The test set was put aside. The cross-validation set was then used to determine the hyperparameters by using k-fold cross-validation (k = 10). The cross-validation set was split into a training set (90% of the cross-validation set, that is the first 3.8s of 18 of the sounds) and a validation set (the remaining 10% of the cross-validation set, that is first 3.8s of 2 of the sounds).</p>
<p>The following steps were performed for each neuron and for each model. For a given <italic>λ</italic>, the model was first fitted on the training set, then the fitted model was used to predict the PSTH of the reserved validation set, and the prediction performance quantified by the normalized correlation coefficient (see <italic><xref ref-type="sec" rid="sec033">Performance measures</xref></italic>). This process was repeated <italic>k = 10</italic> times, each time using a different non-overlapping 10% of the data as a validation set. The above process was performed for a log spaced set of <italic>λ</italic> values. Then the <italic>λ</italic> was chosen that maximized the mean prediction performance of the 10 validation sets. Optimum <italic>λ</italic> differed across neurons (for both LN and NRF models), and over the two models, and was thus set separately for each model and neuron. A similar process was also performed over <italic>J</italic>, the number of HUs, for a number of reasonable <italic>λ</italic> values. However, as NRF prediction performance varied little as a function of <italic>J</italic>, this was simply set to 20 for all neurons.</p>
<p>Then for each neuron, both models were re-fitted to the full cross-validation set, using the optimum <italic>λ</italic> values, and each model was used to predict the PSTH of the test set. The prediction performance of two fitted models was compared using the performance measures described below. These model fits are the ones used throughout the results section.</p>
<p>To verify that the model fits (at the best <italic>λ</italic> for each neuron) were consistent across the ten different cross-validation fits, we quantitatively compared the STRF of the effective HUs obtained for each validation set. For a given neuron, the effective HU from a given fit that was most correlated with the effective HU from a different fit was found on average to share a correlation coefficient of 0.82, while the second most correlated pair of HUs across fits shared a correlation coefficient of 0.69. These high correlation coefficients are indicative of a high degree of consistency. We verified that, in the absence of repeatable fits, one would expect these correlation coefficients to be close to zero by randomly permuting the weights within every effective HU STRF matrix. This randomization caused the correlation coefficients to drop to 0.06 and 0.02 respectively.</p>
</sec>
<sec id="sec033">
<title>Performance measures</title>
<p>Model performance was quantified using three different performance measures: the normalized correlation coefficient <italic>CC</italic><sub><italic>norm</italic></sub>, the mean squared error <italic>MSE</italic>, and the peak activity mean square error <italic>pMSE</italic>. While the <italic>MSE</italic> is a well known quantifier of “goodness of fit”, the other two require further explanation.</p>
<sec id="sec034">
<title>Normalized correlation coefficient</title>
<p><italic>CC</italic><sub><italic>norm</italic></sub> quantifies model performance relative to a theoretically achievable maximum and independently of physiological noise. We use it as our standard performance measure in this paper, as it has a number of desirable properties [<xref ref-type="bibr" rid="pcbi.1005113.ref059">59</xref>], including the fact that it discounts the intrinsic noise of neural responses and quantifies the proportion of the stimulus driven response variability that is captured by the model. If the (Pearson's) correlation coefficient <italic>CC</italic><sub><italic>raw</italic></sub> between observed and predicted responses is low, then this could either indicate that the model is poor, or that the firing of the neuron under study is poorly stimulus driven and thus fundamentally quite unpredictable by a model that relies on stimulus history as the only explanatory variable. <italic>CC</italic><sub><italic>norm</italic></sub> does not have that shortcoming, and thus provides a more objective measure of model performance. We calculated the <italic>CC</italic><sub><italic>norm</italic></sub> [<xref ref-type="bibr" rid="pcbi.1005113.ref029">29</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref030">30</xref>] as the ratio of the <italic>CC</italic><sub><italic>raw</italic></sub> between the model’s predictions <inline-formula id="pcbi.1005113.e019"><alternatives><graphic id="pcbi.1005113.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and the real PSTH <italic>y</italic>(<italic>t</italic>), over the maximum correlation coefficient <italic>CC</italic><sub><italic>max</italic></sub> that is achievable by a perfect model, given the inherent variability of a particular set of neural responses:
<disp-formula id="pcbi.1005113.e020">
<alternatives>
<graphic id="pcbi.1005113.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e020" xlink:type="simple"/>
<mml:math display="block" id="M20">
<mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
<italic>CC</italic><sub><italic>max</italic></sub> is defined as the correlation coefficient between the PSTH of the recorded dataset constructed from the <italic>R</italic> repeats of the stimulus (here: <italic>R = 20</italic>) and the PSTH for an infinite number of repeats. <italic>CC</italic><sub><italic>max</italic></sub> cannot be measured directly, but, one can compute good estimates [<xref ref-type="bibr" rid="pcbi.1005113.ref029">29</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref030">30</xref>] of <italic>CC</italic><sub><italic>max</italic></sub> using the formula:
<disp-formula id="pcbi.1005113.e021">
<alternatives>
<graphic id="pcbi.1005113.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e021" xlink:type="simple"/>
<mml:math display="block" id="M21">
<mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Here <italic>CC</italic><sub><italic>half</italic></sub> is the correlation coefficient of the mean PSTH of <italic>R/2</italic> repeats with the mean PSTH of the remaining <italic>R</italic>/2 repeats. <italic>CC</italic><sub><italic>half</italic></sub> depends on the particular split of the <italic>R</italic> observations, and in order to minimize error the splitting is repeated many times and the values of <italic>CC</italic><sub><italic>half</italic></sub> are averaged. We took the average <italic>CC</italic><sub><italic>half</italic></sub> over a randomly chosen 126 combinations.</p>
</sec>
<sec id="sec035">
<title>Peak activity mean square error</title>
<p>The <italic>pMSE</italic> is the <italic>MSE</italic> between the predicted and observed PSTH for those parts of the signal where the observed firing rate is above the “2<italic>σ</italic>-threshold”, defined as two standard deviations above the mean firing rate to the sound. That is:
<disp-formula id="pcbi.1005113.e022">
<alternatives>
<graphic id="pcbi.1005113.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e022" xlink:type="simple"/>
<mml:math display="block" id="M22">
<mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mi>t</mml:mi><mml:mrow/></mml:munderover><mml:mi>p</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mi>p</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>p</italic>(<italic>t</italic>) is a binary window function consisting of all the binary window functions <italic>p</italic><sub><italic>n</italic></sub>(<italic>t</italic><sub><italic>n</italic></sub>) for each clip <italic>n</italic>. The binary window functions isolate the peaks of the signal:
<disp-formula id="pcbi.1005113.e023">
<alternatives>
<graphic id="pcbi.1005113.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e023" xlink:type="simple"/>
<mml:math display="block" id="M23">
<mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mspace width="0.35em"/><mml:mtext>if</mml:mtext><mml:mspace width="0.35em"/><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>σ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mspace width="0.35em"/><mml:mtext>if</mml:mtext><mml:mspace width="0.35em"/><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>σ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>μ</italic><sub><italic>n</italic></sub> is the average firing rate and <italic>σ</italic><sub><italic>n</italic></sub> its standard deviation for sound clip <italic>n</italic>. See <italic><xref ref-type="sec" rid="sec023">Preprocessing of neural data and stimuli</xref></italic> for how <italic>t</italic> relates to <italic>t</italic><sub><italic>n</italic></sub>, put briefly, we define <italic>t</italic> as all the times <italic>t</italic><sub><italic>n</italic></sub> of all the sound clips <italic>n</italic>.</p>
</sec>
</sec>
<sec id="sec036">
<title>Quantifying model properties</title>
<sec id="sec037">
<title>The adjusted network</title>
<p>While a biological neuron can only produce positive firing rate outputs and its 'synaptic output weights' are either only excitatory or only inhibitory, the nonlinear activation function of the NRF model allows both positive and negative outputs and is symmetric around zero. Likewise, with the NRF the same weight can be either positive or negative. While these aspects of the NRF model thus lack biological realism, they do offer distinct practical advantages. First, there is a considerable literature on how to train this type of multilayer perceptron model efficiently [<xref ref-type="bibr" rid="pcbi.1005113.ref028">28</xref>,<xref ref-type="bibr" rid="pcbi.1005113.ref068">68</xref>]. Second, it gives a network the freedom to discover during training how many excitatory or inhibitory neurons it requires, obviating the need to stipulate a fixed set of excitatory HUs and a fixed set of inhibitory HUs from the outset. However, the fact that the output and weights of a NRF unit can span both positive and negative values makes the distinction between excitatory and inhibitory neurons less categorical and somewhat ambiguous. Nevertheless, this can be resolved because an equivalent 'adjusted' network of excitatory and inhibitory units with logistic activation functions (and hence non-negative outputs) can be found, thus overcoming this problem [<xref ref-type="bibr" rid="pcbi.1005113.ref069">69</xref>]. Hence we can take advantage of the ease of training tanh networks while preserving the interpretability of logistic networks. This 'adjusted network' was used for all results.</p>
<p>In making the adjusted network, we first consider whether a HU is excitatory or inhibitory. The NRF unit output nonlinearities preserve the sign of the unit activation, so whether the <italic>j</italic>-th HU of an NRF has an overall inhibitory or excitatory effect on the OU will not only depend on the sign of the synaptic weight <italic>w</italic><sub><italic>j</italic></sub> that connects these two units, but also on the sign of the “expected activation” of the HU, which in turn depends on whether the HU’s STRF is composed mostly of negative or positive weights. To give an extreme example, a HU with all negative STRF weights and a negative <italic>w</italic><sub><italic>j</italic></sub> would have a positive, excitatory influence on the output neuron. Whether a HU should be considered excitatory or inhibitory thus depends on the product of <italic>w</italic><sub><italic>j</italic></sub> and the sum of the weights of its STRF <inline-formula id="pcbi.1005113.e024"><alternatives><graphic id="pcbi.1005113.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. If both are positive or both negative, the HU is excitatory, otherwise it is inhibitory. This is potentially confusing when readers are used to the idea that, whether a HU is inhibitory or not, can simply be determined from the sign of its output synaptic weight. Note, however, that the equation governing the NRF model unit’s nonlinearity is symmetric and odd, so that for HU <italic>j</italic>, multiplying <italic>w</italic><sub><italic>j</italic>,</sub> <italic>b</italic><sub><italic>j</italic>,</sub> and <italic>w</italic><sub><italic>jfτ</italic></sub> by -1 leaves the influence of that HU on the OU completely unchanged. Consequently, we can ensure that all our inhibitory HUs do indeed have negative values for <italic>w</italic><sub><italic>j</italic></sub> and all excitatory HUs have positive ones by switching the signs of <italic>w</italic><sub><italic>j</italic></sub>, <italic>b</italic><sub><italic>j</italic>,</sub> and <italic>w</italic><sub><italic>jfτ</italic></sub> in all those HUs for which <inline-formula id="pcbi.1005113.e025"><alternatives><graphic id="pcbi.1005113.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> was found to be negative after training. In the interest of easier interpretation, that is what we did, producing the 'partially adjusted' NRF model.</p>
<p>Next let us consider how to further adjust the network to have non-negative outputs. For the partially adjusted NRF model, threshold is simply the most negative output value -<italic>ρ</italic><sub><italic>1</italic></sub> (where weighted-output ranges from -<italic>ρ</italic><sub>1</sub><italic>w</italic><sub>j</sub> to +<italic>ρ</italic><sub>1</sub><italic>w</italic><sub>j</sub>). The explanation for this is as follows: An excitatory HU (positive <italic>w</italic><sub>j</sub>) can equivalently be seen as a neuron with a positive-only output, whose weighted-output goes from 0 to +2<italic>ρ</italic><sub>1</sub><italic>w</italic><sub>j</sub>, acting on an OU whose resting state is less by -<italic>ρ</italic><sub>1</sub><italic>w</italic><sub>j</sub>. An inhibitory HU (negative <italic>w</italic><sub>j</sub>) can equivalently be seen as a neuron with a positive-only output, whose weighted-output goes from 0 to -2 <italic>ρ</italic><sub>1</sub><italic>w</italic><sub>j</sub>, acting on an OU whose resting state is greater by +<italic>ρ</italic><sub>1</sub><italic>w</italic><sub>j</sub>. Making these adjustments thus produces the final 'adjusted' network, which was used for all the results.</p>
</sec>
<sec id="sec038">
<title>The inhibitory/excitatory score</title>
<p>As discussed, the HUs of the NRF model are not 'hard-wired' as excitatory or inhibitory, but each after fitting may nevertheless be “predominantly” excitatory or inhibitory in its influence on the OU. The sign of their output weight and the balance of positive and negative weights in the STRF will determine whether the HU is predominantly excitatory or inhibitory. To quantify the extent to which a HU is inhibitory or excitatory we calculated an inhibitory/excitatory (IE) score for each HU <italic>j</italic>:
<disp-formula id="pcbi.1005113.e026">
<alternatives>
<graphic id="pcbi.1005113.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e026" xlink:type="simple"/>
<mml:math display="block" id="M26">
<mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mtext>sign</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow/></mml:munderover><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow/></mml:munderover><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>This <italic>IE</italic> score is bounded between -1 and 1. For a positive <italic>w</italic><sub><italic>j</italic></sub>, if all elements <italic>w</italic><sub><italic>jfτ</italic></sub> are non-negative (and at least one is not 0), IE = 1, if all elements are non-positive (and at least one is not 0), <italic>IE</italic> = -1. For a negative <italic>w</italic><sub><italic>j</italic></sub>, the opposite is true. If the sum of the negative elements equals the sum of the positive elements, <italic>IE</italic> = 0. This measure was used to investigate whether excitatory or inhibitory HUs play different functional roles in the NRF (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4E</xref>).</p>
</sec>
<sec id="sec039">
<title>The expansive/compressive score</title>
<p>The distributions of HU activation in the nonlinearity plots (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3B</xref>) are calculated with the adjusted model. The expansive/compressive (EC) score measures where the unit tends to operate along the nonlinear activation function:
<disp-formula id="pcbi.1005113.e027">
<alternatives>
<graphic id="pcbi.1005113.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e027" xlink:type="simple"/>
<mml:math display="block" id="M27">
<mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>6</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>5</mml:mn></mml:msub></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>The EC score is the average output of the unit over all the stimuli, scaled to be between -1 at threshold and +1 at saturation. For the NRF model <italic>ρ</italic><sub>1</sub> = 1.7159, <italic>ρ</italic><sub><italic>4</italic></sub> = 0, <italic>ρ</italic><sub><italic>5</italic></sub> = 0, <italic>ρ</italic><sub><italic>6</italic></sub> = 1 and for the OU we replace <italic>z</italic><sub><italic>j</italic></sub>(<italic>t</italic>) with <inline-formula id="pcbi.1005113.e028"><alternatives><graphic id="pcbi.1005113.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. For the LN model, <inline-formula id="pcbi.1005113.e029"><alternatives><graphic id="pcbi.1005113.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005113.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> replaces <italic>z</italic><sub><italic>j</italic></sub>(<italic>t</italic>), <italic>ρ</italic><sub>1</sub> and <italic>ρ</italic><sub><italic>4</italic></sub> are the fitted values from the nonlinearity, and <italic>ρ</italic><sub><italic>5</italic></sub> = 1 and <italic>ρ</italic><sub><italic>6</italic></sub> = 2. The average output (unscaled EC) for each unit is shown as the green dot on its nonlinear activation function (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3A, 3B and 3D</xref>).</p>
</sec>
<sec id="sec040">
<title>The displayed STRFs</title>
<p>The HU SRTF weights (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3B</xref>, top panels of each HU) are shown with each element sign-reversed for the inhibitory HUs. Plotting HU STRFs in this manner thus ensures that the STRF plots always show the direction of effect of an STRF weight on the model output, rather than on the HU. This was done to facilitate the comparison between NRF HU STRFs and LN model STRFs.</p>
</sec>
<sec id="sec041">
<title>Measuring the contours, and temporal and spectral tuning width of the STRFs</title>
<p>To obtain smooth contours for high sensitivity regions of the HU STRFs (<xref ref-type="fig" rid="pcbi.1005113.g003">Fig 3C</xref>), we spline interpolated the HU’s display STRF onto an evenly spaced grid at 8 times the resolution, with 7 additional values between each frequency, and 7 between each time. For the excitatory HUs the contours at half the maximum value of this matrix were plotted. For the inhibitory HUs, the contours at half the minimum value of this matrix were plotted.</p>
<p>To get a measure of the tuning width (<xref ref-type="fig" rid="pcbi.1005113.g004">Fig 4C and 4D</xref>), we calculated the power STRF by taking the square of each element of the interpolated STRF. Next, to measure the frequency tuning width, we summed the power STRF over all the time bins and then determined the maximum value of the resulting vector. The half-height frequency tuning width was defined as the number of elements of this vector ≥50% of this maximum value, multiplied by the frequency range covered by each bin in the interpolated STRF (⅙ × ⅛ = 1/48 octaves). Quarter-height frequency tuning widths were defined analogously at ≥25%. The half- and quarter-height temporal tuning widths were calculated analogously.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<p>We thank Neil Rabinowitz, Kerry Walker, Astrid Klinge-Strahl and Fernando Nodal for help with some of the experiments, and Joseph Nour for implementing the nonlinearity fitting code for the LN model.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005113.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adelson</surname> <given-names>EH</given-names></name>, <name name-style="western"><surname>Bergen</surname> <given-names>JR</given-names></name>. <article-title>Spatiotemporal energy models for the perception of motion</article-title>. <source>J Opt Soc Am A</source>. <year>1985</year>;<volume>2</volume>: <fpage>284</fpage>–<lpage>299</lpage>. <object-id pub-id-type="pmid">3973762</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Johannesma</surname> <given-names>PIM</given-names></name>, <name name-style="western"><surname>Hermes</surname> <given-names>DJ</given-names></name>. <article-title>Spectro-temporal receptive fields of auditory neurons in the grassfrog</article-title>. <source>Biol Cybern</source>. <year>1980</year>;<volume>38</volume>: <fpage>235</fpage>–<lpage>248</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005113.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aertsen AMHJ</surname> <given-names>Johannesma PIM</given-names></name>. <article-title>A comparison of the Spectro-Temporal sensitivity of auditory neurons to tonal and natural stimuli</article-title>. <source>Biol Cybern</source>. <year>1981</year>;<volume>42</volume>: <fpage>145</fpage>–<lpage>156</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00336732" xlink:type="simple">10.1007/BF00336732</ext-link></comment> <object-id pub-id-type="pmid">6976799</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Christianson</surname> <given-names>GB</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>. <article-title>The Consequences of Response Nonlinearities for Interpretation of Spectrotemporal Receptive Fields</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>: <fpage>446</fpage>–<lpage>455</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1775-07.2007" xlink:type="simple">10.1523/JNEUROSCI.1775-07.2007</ext-link></comment> <object-id pub-id-type="pmid">18184787</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Mesgarani</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Fritz</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Rapid synaptic depression explains nonlinear modulation of spectro-temporal tuning in primary auditory cortex by natural stimuli</article-title>. <source>J Neurosci</source>. <year>2009</year>;<volume>29</volume>: <fpage>3374</fpage>–<lpage>3386</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5249-08.2009" xlink:type="simple">10.1523/JNEUROSCI.5249-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19295144</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>deCharms</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Blake</surname> <given-names>DT</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>. <article-title>Optimizing Sound Features for Cortical Neurons</article-title>. <source>Science</source>. <year>1998</year>;<volume>280</volume>: <fpage>1439</fpage>–<lpage>1444</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.280.5368.1439" xlink:type="simple">10.1126/science.280.5368.1439</ext-link></comment> <object-id pub-id-type="pmid">9603734</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Escabı</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Nonlinear spectrotemporal sound analysis by neurons in the auditory midbrain</article-title>. <source>J Neurosci</source>. <year>2002</year>;<volume>22</volume>: <fpage>4114</fpage>–<lpage>4131</lpage>. <object-id pub-id-type="pmid">12019330</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fritz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Elhilali</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>D</given-names></name>. <article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title>. <source>Nat Neurosci</source>. <year>2003</year>;<volume>6</volume>: <fpage>1216</fpage>–<lpage>1223</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1141" xlink:type="simple">10.1038/nn1141</ext-link></comment> <object-id pub-id-type="pmid">14583754</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gill</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Woolley</surname> <given-names>SMN</given-names></name>, <name name-style="western"><surname>Fremouw</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>. <article-title>Sound representation methods for spectro-temporal receptive field estimation</article-title>. <source>J Comput Neurosci</source>. <year>2006</year>;<volume>21</volume>: <fpage>5</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-006-7059-4" xlink:type="simple">10.1007/s10827-006-7059-4</ext-link></comment> <object-id pub-id-type="pmid">16633939</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gourévitch</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Noreña</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Shaw</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Eggermont</surname> <given-names>JJ</given-names></name>. <article-title>Spectrotemporal receptive fields in anesthetized cat primary auditory cortex are context dependent</article-title>. <source>Cereb Cortex N Y N 1991</source>. <year>2009</year>;<volume>19</volume>: <fpage>1448</fpage>–<lpage>1461</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhn184" xlink:type="simple">10.1093/cercor/bhn184</ext-link></comment> <object-id pub-id-type="pmid">18854580</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klein</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Depireux</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Simon</surname> <given-names>JZ</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Robust spectrotemporal reverse correlation for the auditory system: optimizing stimulus design</article-title>. <source>J Comput Neurosci</source>. <year>2000</year>;<volume>9</volume>: <fpage>85</fpage>–<lpage>111</lpage>. <object-id pub-id-type="pmid">10946994</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>. <article-title>Spectrotemporal structure of receptive fields in areas AI and AAF of mouse auditory cortex</article-title>. <source>J Neurophysiol</source>. <year>2003</year>;<volume>90</volume>: <fpage>2660</fpage>–<lpage>2675</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00751.2002" xlink:type="simple">10.1152/jn.00751.2002</ext-link></comment> <object-id pub-id-type="pmid">12815016</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Escabí</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Read</surname> <given-names>HL</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Spectrotemporal receptive fields in the lemniscal auditory thalamus and cortex</article-title>. <source>J Neurophysiol</source>. <year>2002</year>;<volume>87</volume>: <fpage>516</fpage>–<lpage>527</lpage>. <object-id pub-id-type="pmid">11784767</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reid</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Soodak</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>Shapley</surname> <given-names>RM</given-names></name>. <article-title>Linear mechanisms of directional selectivity in simple cells of cat striate cortex</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1987</year>;<volume>84</volume>: <fpage>8740</fpage>–<lpage>8744</lpage>. <object-id pub-id-type="pmid">3479811</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schnupp</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Linear processing of spatial cues in primary auditory cortex</article-title>. <source>Nature</source>. <year>2001</year>;<volume>414</volume>: <fpage>200</fpage>–<lpage>204</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/35102568" xlink:type="simple">10.1038/35102568</ext-link></comment> <object-id pub-id-type="pmid">11700557</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>, <name name-style="western"><surname>Sen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Doupe</surname> <given-names>AJ</given-names></name>. <article-title>Spectral-Temporal Receptive Fields of Nonlinear Auditory Neurons Obtained Using Natural Sounds</article-title>. <source>J Neurosci</source>. <year>2000</year>;<volume>20</volume>: <fpage>2315</fpage>–<lpage>2331</lpage>. <object-id pub-id-type="pmid">10704507</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Machens</surname> <given-names>CK</given-names></name>, <name name-style="western"><surname>Wehr</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Zador</surname> <given-names>AM</given-names></name>. <article-title>Linearity of cortical receptive fields measured with natural sounds</article-title>. <source>J Neurosci</source>. <year>2004</year>;<volume>24</volume>: <fpage>1089</fpage>–<lpage>1100</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4445-03.2004" xlink:type="simple">10.1523/JNEUROSCI.4445-03.2004</ext-link></comment> <object-id pub-id-type="pmid">14762127</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>DJ</given-names></name>. <article-title>How close are we to understanding v1?</article-title> <source>Neural Comput</source>. <year>2005</year>;<volume>17</volume>: <fpage>1665</fpage>–<lpage>1699</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/0899766054026639" xlink:type="simple">10.1162/0899766054026639</ext-link></comment> <object-id pub-id-type="pmid">15969914</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rabinowitz</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BDB</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Contrast Gain Control in Auditory Cortex</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>70</volume>: <fpage>1178</fpage>–<lpage>1191</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.04.030" xlink:type="simple">10.1016/j.neuron.2011.04.030</ext-link></comment> <object-id pub-id-type="pmid">21689603</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atencio</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Cooperative nonlinearities in auditory cortical neurons</article-title>. <source>Neuron</source>. <year>2008</year>;<volume>58</volume>: <fpage>956</fpage>–<lpage>966</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2008.04.026" xlink:type="simple">10.1016/j.neuron.2008.04.026</ext-link></comment> <object-id pub-id-type="pmid">18579084</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ahrens</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>. <article-title>Nonlinearities and contextual influences in auditory cortical responses modeled with multilinear spectrotemporal methods</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>: <fpage>1929</fpage>–<lpage>1942</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3377-07.2008" xlink:type="simple">10.1523/JNEUROSCI.3377-07.2008</ext-link></comment> <object-id pub-id-type="pmid">18287509</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calabrese</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schumacher</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Schneider</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Woolley</surname> <given-names>SMN</given-names></name>. <article-title>A Generalized Linear Model for Estimating Spectrotemporal Receptive Fields from Responses to Natural Sounds</article-title>. <source>PLoS ONE</source>. <year>2011</year>;<volume>6</volume>: <fpage>e16104</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0016104" xlink:type="simple">10.1371/journal.pone.0016104</ext-link></comment> <object-id pub-id-type="pmid">21264310</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Integration over multiple timescales in primary auditory cortex</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>: <fpage>19154</fpage>–<lpage>19166</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2270-13.2013" xlink:type="simple">10.1523/JNEUROSCI.2270-13.2013</ext-link></comment> <object-id pub-id-type="pmid">24305812</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schinkel-Bielefeld</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Butts</surname> <given-names>DA</given-names></name>. <article-title>Inferring the role of inhibition in auditory processing of complex natural stimuli</article-title>. <source>J Neurophysiol</source>. <year>2012</year>;<volume>107</volume>: <fpage>3296</fpage>–<lpage>3307</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.01173.2011" xlink:type="simple">10.1152/jn.01173.2011</ext-link></comment> <object-id pub-id-type="pmid">22457454</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Willmore</surname> <given-names>BD</given-names></name>, <name name-style="western"><surname>Schoppe</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>, <name name-style="western"><surname>Harper</surname> <given-names>NS</given-names></name>. <article-title>Incorporating midbrain adaptation to mean sound level improves models of auditory cortical processing</article-title>. <source>J Neurosci</source>. in press;</mixed-citation></ref>
<ref id="pcbi.1005113.ref026"><label>26</label><mixed-citation publication-type="other" xlink:type="simple">Sohl-Dickstein J, Poole B, Ganguli S. Fast large-scale optimization by unifying stochastic gradient and quasi-Newton methods. ArXiv13112115 Cs. 2013; Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1311.2115" xlink:type="simple">http://arxiv.org/abs/1311.2115</ext-link></mixed-citation></ref>
<ref id="pcbi.1005113.ref027"><label>27</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Hastie</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Friedman</surname> <given-names>J</given-names></name>. <chapter-title>The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition</chapter-title>. <edition>2nd ed.</edition> 2009. <source>Corr. 7th printing 2013 edition</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2011</year>.</mixed-citation></ref>
<ref id="pcbi.1005113.ref028"><label>28</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Bishop</surname> <given-names>CM</given-names></name>. <source>Pattern Recognition and Machine Learning (Information Science and Statistics)</source>. <publisher-loc>Secaucus, NJ, USA</publisher-loc>: <publisher-name>Springer-Verlag New York, Inc.</publisher-name>; <year>2006</year>.</mixed-citation></ref>
<ref id="pcbi.1005113.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hsu</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>. <article-title>Quantifying variability in neural responses and its application for the validation of model predictions</article-title>. <source>Netw Bristol Engl</source>. <year>2004</year>;<volume>15</volume>: <fpage>91</fpage>–<lpage>109</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005113.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Touryan</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Felsen</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Dan</surname> <given-names>Y</given-names></name>. <article-title>Spatial structure of complex cell receptive fields measured with natural images</article-title>. <source>Neuron</source>. <year>2005</year>;<volume>45</volume>: <fpage>781</fpage>–<lpage>791</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2005.01.029" xlink:type="simple">10.1016/j.neuron.2005.01.029</ext-link></comment> <object-id pub-id-type="pmid">15748852</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Asari</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Zador</surname> <given-names>AM</given-names></name>. <article-title>Long-lasting context dependence constrains neural encoding models in rodent auditory cortex</article-title>. <source>J Neurophysiol</source>. <year>2009</year>;<volume>102</volume>: <fpage>2638</fpage>–<lpage>2656</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00577.2009" xlink:type="simple">10.1152/jn.00577.2009</ext-link></comment> <object-id pub-id-type="pmid">19675288</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Botev</surname> <given-names>ZI</given-names></name>, <name name-style="western"><surname>Grotowski</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Kroese</surname> <given-names>DP</given-names></name>. <article-title>Kernel density estimation via diffusion</article-title>. <source>Ann Stat</source>. <year>2010</year>;<volume>38</volume>: <fpage>2916</fpage>–<lpage>2957</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1214/10-AOS799" xlink:type="simple">10.1214/10-AOS799</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1005113.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carlson</surname> <given-names>NL</given-names></name>, <name name-style="western"><surname>Ming</surname> <given-names>VL</given-names></name>, <name name-style="western"><surname>DeWeese</surname> <given-names>MR</given-names></name>. <article-title>Sparse Codes for Speech Predict Spectrotemporal Receptive Fields in the Inferior Colliculus</article-title>. <source>PLoS Comput Biol</source>. <year>2012</year>;<volume>8</volume>: <fpage>e1002594</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002594" xlink:type="simple">10.1371/journal.pcbi.1002594</ext-link></comment> <object-id pub-id-type="pmid">22807665</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atencio</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Hierarchical computation in the canonical auditory cortical circuit</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2009</year>;<volume>106</volume>: <fpage>21894</fpage>–<lpage>21899</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0908383106" xlink:type="simple">10.1073/pnas.0908383106</ext-link></comment> <object-id pub-id-type="pmid">19918079</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Moore</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Wehr</surname> <given-names>M</given-names></name>. <article-title>Parvalbumin-Expressing Inhibitory Interneurons in Auditory Cortex Are Well-Tuned for Frequency</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>: <fpage>13713</fpage>–<lpage>13723</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0663-13.2013" xlink:type="simple">10.1523/JNEUROSCI.0663-13.2013</ext-link></comment> <object-id pub-id-type="pmid">23966693</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Senn</surname> <given-names>W</given-names></name>. <article-title>A synaptic explanation of suppression in visual cortex</article-title>. <source>J Neurosci</source>. <year>2002</year>;<volume>22</volume>: <fpage>10053</fpage>–<lpage>10065</lpage>. <object-id pub-id-type="pmid">12427863</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name>. <article-title>Linearity and Normalization in Simple Cells of the Macaque Primary Visual Cortex</article-title>. <source>J Neurosci</source>. <year>1997</year>;<volume>17</volume>: <fpage>8621</fpage>–<lpage>8644</lpage>. <object-id pub-id-type="pmid">9334433</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>, <name name-style="western"><surname>Chance</surname> <given-names>FS</given-names></name>. <article-title>Drivers and modulators from push-pull and balanced synaptic input</article-title>. <source>Prog Brain Res</source>. <year>2005</year>;<volume>149</volume>: <fpage>147</fpage>–<lpage>155</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0079-6123(05)49011-1" xlink:type="simple">10.1016/S0079-6123(05)49011-1</ext-link></comment> <object-id pub-id-type="pmid">16226582</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dean</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Harper</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>McAlpine</surname> <given-names>D</given-names></name>. <article-title>Neural population coding of sound level adapts to stimulus statistics</article-title>. <source>Nat Neurosci</source>. <year>2005</year>;<volume>8</volume>: <fpage>1684</fpage>–<lpage>1689</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1541" xlink:type="simple">10.1038/nn1541</ext-link></comment> <object-id pub-id-type="pmid">16286934</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rabinowitz</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BDB</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>. <article-title>Constructing Noise-Invariant Representations of Sound in the Auditory Pathway</article-title>. <source>PLoS Biol</source>. <year>2013</year>;<volume>11</volume>: <fpage>e1001710</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1001710" xlink:type="simple">10.1371/journal.pbio.1001710</ext-link></comment> <object-id pub-id-type="pmid">24265596</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rabinowitz</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BDB</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Spectrotemporal Contrast Kernels for Neurons in Primary Auditory Cortex</article-title>. <source>J Neurosci</source>. <year>2012</year>;<volume>32</volume>: <fpage>11271</fpage>–<lpage>11284</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1715-12.2012" xlink:type="simple">10.1523/JNEUROSCI.1715-12.2012</ext-link></comment> <object-id pub-id-type="pmid">22895711</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heil</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Irvine</surname> <given-names>DR</given-names></name>. <article-title>First-spike timing of auditory-nerve fibers and comparison with auditory cortex</article-title>. <source>J Neurophysiol</source>. <year>1997</year>;<volume>78</volume>: <fpage>2438</fpage>–<lpage>2454</lpage>. <object-id pub-id-type="pmid">9356395</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atencio</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Receptive field dimensionality increases from the auditory midbrain to cortex</article-title>. <source>J Neurophysiol</source>. <year>2012</year>;<volume>107</volume>: <fpage>2594</fpage>–<lpage>2603</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.01025.2011" xlink:type="simple">10.1152/jn.01025.2011</ext-link></comment> <object-id pub-id-type="pmid">22323634</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sharpee</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Rust</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>Analyzing neural responses to natural signals: maximally informative dimensions</article-title>. <source>Neural Comput</source>. <year>2004</year>;<volume>16</volume>: <fpage>223</fpage>–<lpage>250</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976604322742010" xlink:type="simple">10.1162/089976604322742010</ext-link></comment> <object-id pub-id-type="pmid">15006095</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>, <name name-style="western"><surname>Atencio</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Hierarchical representations in the auditory cortex</article-title>. <source>Curr Opin Neurobiol</source>. <year>2011</year>;<volume>21</volume>: <fpage>761</fpage>–<lpage>767</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2011.05.027" xlink:type="simple">10.1016/j.conb.2011.05.027</ext-link></comment> <object-id pub-id-type="pmid">21704508</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>. <article-title>Computational Identification of Receptive Fields</article-title>. <source>Annu Rev Neurosci</source>. <year>2013</year>;<volume>36</volume>: <fpage>103</fpage>–<lpage>120</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev-neuro-062012-170253" xlink:type="simple">10.1146/annurev-neuro-062012-170253</ext-link></comment> <object-id pub-id-type="pmid">23841838</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kouh</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>. <article-title>Estimating linear-nonlinear models using Renyi divergences</article-title>. <source>Netw Bristol Engl</source>. <year>2009</year>;<volume>20</volume>: <fpage>49</fpage>–<lpage>68</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/09548980902950891" xlink:type="simple">10.1080/09548980902950891</ext-link></comment> <object-id pub-id-type="pmid">19568981</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Williamson</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>. <article-title>The Equivalence of Information-Theoretic and Likelihood-Based Methods for Neural Dimensionality Reduction</article-title>. <name name-style="western"><surname>Bethge</surname> <given-names>M</given-names></name>, editor. <source>PLOS Comput Biol</source>. <year>2015</year>;<volume>11</volume>: <fpage>e1004141</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1004141" xlink:type="simple">10.1371/journal.pcbi.1004141</ext-link></comment> <object-id pub-id-type="pmid">25831448</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laudanski</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Edeline</surname> <given-names>J-M</given-names></name>, <name name-style="western"><surname>Huetz</surname> <given-names>C</given-names></name>. <article-title>Differences between Spectro-Temporal Receptive Fields Derived from Artificial and Natural Stimuli in the Auditory Cortex</article-title>. <source>PLoS ONE</source>. <year>2012</year>;<volume>7</volume>: <fpage>e50539</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0050539" xlink:type="simple">10.1371/journal.pone.0050539</ext-link></comment> <object-id pub-id-type="pmid">23209771</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Shlens</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sher</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Litke</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Chichilnisky</surname> <given-names>EJ</given-names></name>, <etal>et al</etal>. <article-title>Spatio-temporal correlations and visual signalling in a complete neuronal population</article-title>. <source>Nature</source>. <year>2008</year>;<volume>454</volume>: <fpage>995</fpage>–<lpage>999</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07140" xlink:type="simple">10.1038/nature07140</ext-link></comment> <object-id pub-id-type="pmid">18650810</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>. <article-title>Maximum likelihood estimation of cascade point-process neural encoding models</article-title>. <source>Netw Comput Neural Syst</source>. <year>2004</year>;<volume>15</volume>: <fpage>243</fpage>–<lpage>262</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005113.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Park</surname> <given-names>IM</given-names></name>, <name name-style="western"><surname>Archer</surname> <given-names>EW</given-names></name>, <name name-style="western"><surname>Priebe</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>. <article-title>Spectral methods for neural characterization using generalized quadratic models</article-title>. <source>Advances in neural information processing systems</source>. <year>2013</year>. pp. <fpage>2454</fpage>–<lpage>2462</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/4993-spectra" xlink:type="simple">http://papers.nips.cc/paper/4993-spectra</ext-link></mixed-citation></ref>
<ref id="pcbi.1005113.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McFarland</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Cui</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Butts</surname> <given-names>DA</given-names></name>. <article-title>Inferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs</article-title>. <source>PLoS Comput Biol.</source> <year>2013</year>;<volume>9</volume>: <fpage>e1003143</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003143" xlink:type="simple">10.1371/journal.pcbi.1003143</ext-link></comment> <object-id pub-id-type="pmid">23874185</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kozlov</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Gentner</surname> <given-names>TQ</given-names></name>. <article-title>Central auditory neurons have composite receptive fields</article-title>. <source>Proc Natl Acad Sci</source>. <year>2016</year>;<volume>113</volume>: <fpage>1441</fpage>–<lpage>1446</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1506903113" xlink:type="simple">10.1073/pnas.1506903113</ext-link></comment> <object-id pub-id-type="pmid">26787894</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Margoliash</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Bankes</surname> <given-names>SC</given-names></name>. <article-title>Computations in the Ascending Auditory Pathway in Songbirds Related to Song Learning</article-title>. <source>Am Zool</source>. <year>1993</year>;<volume>33</volume>: <fpage>94</fpage>–<lpage>103</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005113.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lau</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Stanley</surname> <given-names>GB</given-names></name>, <name name-style="western"><surname>Dan</surname> <given-names>Y</given-names></name>. <article-title>Computational subunits of visual cortical neurons revealed by artificial neural networks</article-title>. <source>Proc Natl Acad Sci</source>. <year>2002</year>;<volume>99</volume>: <fpage>8974</fpage>–<lpage>8979</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.122173799" xlink:type="simple">10.1073/pnas.122173799</ext-link></comment> <object-id pub-id-type="pmid">12060706</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lehky</surname> <given-names>SR</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Desimone</surname> <given-names>R</given-names></name>. <article-title>Predicting responses of nonlinear neurons in monkey striate cortex to complex patterns</article-title>. <source>J Neurosci</source>. <year>1992</year>;<volume>12</volume>: <fpage>3568</fpage>–<lpage>3581</lpage>. <object-id pub-id-type="pmid">1527596</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Prenger</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Wu</surname> <given-names>MC-K</given-names></name>, <name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name>. <article-title>Nonlinear V1 responses to natural scenes revealed by neural network analysis</article-title>. <source>Neural Netw</source>. <year>2004</year>;<volume>17</volume>: <fpage>663</fpage>–<lpage>679</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neunet.2004.03.008" xlink:type="simple">10.1016/j.neunet.2004.03.008</ext-link></comment> <object-id pub-id-type="pmid">15288891</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schoppe</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Harper</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BDB</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>. <article-title>Measuring the Performance of Neural Models</article-title>. <source>Front Comput Neurosci</source>. <year>2016</year>; <volume>10</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2016.00010" xlink:type="simple">10.3389/fncom.2016.00010</ext-link></comment> <object-id pub-id-type="pmid">26903851</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Mulder</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Bethard</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Moens</surname> <given-names>M-F</given-names></name>. <article-title>A survey on the application of recurrent neural networks to statistical language modeling</article-title>. <source>Comput Speech Lang</source>. <year>2015</year>;<volume>30</volume>: <fpage>61</fpage>–<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.csl.2014.09.005" xlink:type="simple">10.1016/j.csl.2014.09.005</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1005113.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bizley</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Nodal</surname> <given-names>FR</given-names></name>, <name name-style="western"><surname>Nelken</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Functional organization of ferret auditory cortex</article-title>. <source>Cereb Cortex N Y N 1991</source>. <year>2005</year>;<volume>15</volume>: <fpage>1637</fpage>–<lpage>1653</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhi042" xlink:type="simple">10.1093/cercor/bhi042</ext-link></comment> <object-id pub-id-type="pmid">15703254</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bizley</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Walker</surname> <given-names>KMM</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>. <article-title>Neural Ensemble Codes for Stimulus Periodicity in Auditory Cortex</article-title>. <source>J Neurosci</source>. <year>2010</year>;<volume>30</volume>: <fpage>5078</fpage>–<lpage>5091</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5475-09.2010" xlink:type="simple">10.1523/JNEUROSCI.5475-09.2010</ext-link></comment> <object-id pub-id-type="pmid">20371828</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nelken</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Bizley</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Nodal</surname> <given-names>FR</given-names></name>, <name name-style="western"><surname>Ahmed</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Large-Scale Organization of Ferret Auditory Cortex Revealed Using Continuous Acquisition of Intrinsic Optical Signals</article-title>. <source>J Neurophysiol</source>. <year>2004</year>;<volume>92</volume>: <fpage>2574</fpage>–<lpage>2588</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00276.2004" xlink:type="simple">10.1152/jn.00276.2004</ext-link></comment> <object-id pub-id-type="pmid">15152018</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref064"><label>64</label><mixed-citation publication-type="other" xlink:type="simple">Kadir SN, Goodman DFM, Harris KD. High-dimensional cluster analysis with the Masked EM Algorithm. ArXiv13092848 Cs Q-Bio Stat. 2013; Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1309.2848" xlink:type="simple">http://arxiv.org/abs/1309.2848</ext-link></mixed-citation></ref>
<ref id="pcbi.1005113.ref065"><label>65</label><mixed-citation publication-type="other" xlink:type="simple">Sahani M, Linden JF. How linear are auditory cortical responses? In: Advances in Neural Information Processing Systems [Internet]. 2003 [cited 9 May 2015]. Available: <ext-link ext-link-type="uri" xlink:href="http://discovery.ucl.ac.uk/8281/" xlink:type="simple">http://discovery.ucl.ac.uk/8281/</ext-link></mixed-citation></ref>
<ref id="pcbi.1005113.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friedman</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hastie</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>. <article-title>Regularization Paths for Generalized Linear Models via Coordinate Descent</article-title>. <source>J Stat Softw</source>. <year>2010</year>;<volume>33</volume>: <fpage>1</fpage>–<lpage>22</lpage>. <object-id pub-id-type="pmid">20808728</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thorson</surname> <given-names>IL</given-names></name>, <name name-style="western"><surname>Liénard</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>David</surname> <given-names>SV</given-names></name>. <article-title>The Essential Complexity of Auditory Receptive Fields</article-title>. <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>, editor. <source>PLOS Comput Biol</source>. <year>2015</year>;<volume>11</volume>: <fpage>e1004628</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1004628" xlink:type="simple">10.1371/journal.pcbi.1004628</ext-link></comment> <object-id pub-id-type="pmid">26683490</object-id></mixed-citation></ref>
<ref id="pcbi.1005113.ref068"><label>68</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>LeCun</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Bottou</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Orr</surname> <given-names>GB</given-names></name>, <name name-style="western"><surname>Müller</surname> <given-names>K-R</given-names></name>. <chapter-title>Efficient BackProp</chapter-title>. In: <name name-style="western"><surname>Orr</surname> <given-names>GB</given-names></name>, <name name-style="western"><surname>Müller</surname> <given-names>K-R</given-names></name>, editors. <source>Neural Networks: Tricks of the Trade</source>. <publisher-name>Springer Berlin Heidelberg</publisher-name>; <year>1998</year>. pp. <fpage>9</fpage>–<lpage>50</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://link.springer.com/chapter/10.1007/3-540-49430-8_2" xlink:type="simple">http://link.springer.com/chapter/10.1007/3-540-49430-8_2</ext-link></mixed-citation></ref>
<ref id="pcbi.1005113.ref069"><label>69</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Príncipe</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Euliano</surname> <given-names>NR</given-names></name>, <name name-style="western"><surname>Lefebvre</surname> <given-names>WC</given-names></name>. <chapter-title>Neural and adaptive systems: fundamentals through simulations</chapter-title>. <publisher-name>Wiley</publisher-name>; <year>2000</year>.</mixed-citation></ref>
</ref-list>
</back>
</article>
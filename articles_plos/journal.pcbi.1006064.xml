<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-01761</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006064</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Computer architecture</subject><subj-group><subject>Pipelines (computing)</subject><subj-group><subject>Graphics pipelines</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Software engineering</subject><subj-group><subject>Preprocessing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Software engineering</subject><subj-group><subject>Preprocessing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Human factors engineering</subject><subj-group><subject>Man-computer interface</subject><subj-group><subject>Graphical user interface</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Computer architecture</subject><subj-group><subject>User interfaces</subject><subj-group><subject>Graphical user interface</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Software engineering</subject><subj-group><subject>Software tools</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Software engineering</subject><subj-group><subject>Software tools</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject><subj-group><subject>Reproducibility</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain mapping</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Diagnostic medicine</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Radiology and imaging</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Porcupine: A visual pipeline tool for neuroimaging analysis</article-title>
<alt-title alt-title-type="running-head">Porcupine: A visual pipeline tool for neuroimaging analysis</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8155-8641</contrib-id>
<name name-style="western">
<surname>van Mourik</surname> <given-names>Tim</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Snoek</surname> <given-names>Lukas</given-names></name>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Knapen</surname> <given-names>Tomas</given-names></name>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-3699-6917</contrib-id>
<name name-style="western">
<surname>Norris</surname> <given-names>David G.</given-names></name>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Radboud University Nijmegen, Donders Institute for Brain, Cognition and Behaviour, Kapittelweg, Nijmegen, The Netherlands</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>University of Amsterdam, Department of Brain &amp; Cognition, Nieuwe Achtergracht, Amsterdam, The Netherlands</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Cognitive Psychology &amp; Institute for Brain &amp; Behavior, Vd Boechorststraat, Amsterdam, The Netherlands</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>Spinoza Centre for Neuroimaging, Meibergdreef, Amsterdam, The Netherlands</addr-line>
</aff>
<aff id="aff005">
<label>5</label>
<addr-line>Erwin L. Hahn Institute for Magnetic Resonance Imaging, Arendahls Wiese, Essen, Germany</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Prlic</surname> <given-names>Andreas</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>UCSD, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">t.vanmourik@donders.ru.nl</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>5</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="epub">
<day>10</day>
<month>5</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>5</issue>
<elocation-id>e1006064</elocation-id>
<history>
<date date-type="received">
<day>23</day>
<month>10</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>27</day>
<month>2</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>van Mourik et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006064"/>
<abstract>
<p>The field of neuroimaging is rapidly adopting a more reproducible approach to data acquisition and analysis. Data structures and formats are being standardised and data analyses are getting more automated. However, as data analysis becomes more complicated, researchers often have to write longer analysis scripts, spanning different tools across multiple programming languages. This makes it more difficult to share or recreate code, reducing the reproducibility of the analysis. We present a tool, Porcupine, that constructs one’s analysis visually and automatically produces analysis code. The graphical representation improves understanding of the performed analysis, while retaining the flexibility of modifying the produced code manually to custom needs. Not only does Porcupine produce the analysis code, it also creates a shareable environment for running the code in the form of a Docker image. Together, this forms a reproducible way of constructing, visualising and sharing one’s analysis. Currently, Porcupine links to Nipype functionalities, which in turn accesses most standard neuroimaging analysis tools. Our goal is to release researchers from the constraints of specific implementation details, thereby freeing them to think about novel and creative ways to solve a given problem. Porcupine improves the overview researchers have of their processing pipelines, and facilitates both the development and communication of their work. This will reduce the threshold at which less expert users can generate reusable pipelines. With Porcupine, we bridge the gap between a conceptual and an implementational level of analysis and make it easier for researchers to create reproducible and shareable science. We provide a wide range of examples and documentation, as well as installer files for all platforms on our website: <ext-link ext-link-type="uri" xlink:href="https://timvanmourik.github.io/Porcupine" xlink:type="simple">https://timvanmourik.github.io/Porcupine</ext-link>. Porcupine is free, open source, and released under the GNU General Public License v3.0.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>Spinoza Research Grant</institution>
</funding-source>
<award-id>SPI 40-118</award-id>
</award-group>
<funding-statement>Tim van Mourik acknowledges support from the Royal Netherlands Academy of Arts and Sciences, from the Academy Professor Prize 2012, awarded to professor Peter Hagoort. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="3"/>
<table-count count="0"/>
<page-count count="10"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-05-22</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All software, documentation, and examples may be found on <ext-link ext-link-type="uri" xlink:href="https://timvanmourik.github.io/Porcupine" xlink:type="simple">https://timvanmourik.github.io/Porcupine</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<disp-quote><p>This is a <italic>PLOS Computational Biology</italic> Software paper.</p></disp-quote><sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The field of neuroimaging is rapidly adopting a more reproducible approach to data acquisition and analysis. Especially in recent years, a strong movement for conducting better documented and more reproducible science can be observed. Advances have been made in terms of openly sharing data (e.g. OpenFmri, [<xref ref-type="bibr" rid="pcbi.1006064.ref001">1</xref>]), standardizing data formats (BIDS format [<xref ref-type="bibr" rid="pcbi.1006064.ref002">2</xref>]), and facilitating more automated pipelines [<xref ref-type="bibr" rid="pcbi.1006064.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1006064.ref005">5</xref>]. These initiatives facilitate increasing global scientific communication and collaboration, that is paramount in the age of big data.</p>
<p>As a result of the increasing complexity of analyses and the wide variety of different tools, researchers often have to write custom scripts for combining different software packages, often in different programming languages. As an extra obstacle, many tools have external dependencies, intricate installation procedures, or different file formats for the same type of data. Furthermore, the sharing initiatives usually have a stronger focus on sharing <italic>data</italic> (Human Connectome Project [<xref ref-type="bibr" rid="pcbi.1006064.ref006">6</xref>], NeuroVault [<xref ref-type="bibr" rid="pcbi.1006064.ref007">7</xref>]) instead of <italic>code</italic>, such that analysis scripts still have to be recreated based on the method section of a paper. All these factors negatively affect the reproducibility, documentation, and in the worst case correctness of the analysis [<xref ref-type="bibr" rid="pcbi.1006064.ref008">8</xref>].</p>
<p>A considerable mastery of coding is required for analysing fMRI data. The conceptual side of understanding all preprocessing steps is not trivial, but converting this into a working pipeline can be an arduous journey. The necessary programming skills are not usually the prime focus of a brain researcher’s skills or interests, but they are a necessity for completing one’s analysis. Consequently, scripting a pipeline that covers all high-level and low-level aspects is daunting and error prone. As a result, there is a considerable risk of ‘hacking’ an analysis pipeline together, sacrificing a reproducible approach. So as a researcher, how do you start an analysis? It is easiest to start with visualising the steps of your analysis pipeline.</p>
<p>In an increasingly complicated analysis environment there is a strong need for tools that give a better oversight of these complex analyses, while retaining the flexibility of combining different tools. A notable effort to integrate different tools is Nipype [<xref ref-type="bibr" rid="pcbi.1006064.ref004">4</xref>], that has a Python interface to existing tools from all major MRI analysis packages. However, this still requires non-trivial Python scripting. Furthermore, Nipype is only able to visualise a workflow after it has been manually scripted [<xref ref-type="bibr" rid="pcbi.1006064.ref009">9</xref>].</p>
<p>Here we detail our solution to these problems, an open-source software program we call Porcupine: ‘PORcupine Creates Ur PipelINE. Porcupine allows the creation of neuroimaging pipelines by means of a graphical user interface (GUI). After graphical pipeline definition, Porcupine in turn creates the code that programmatically defines the pipeline. Additionally and without any additional overhead, we supply a Dockerfile (<ext-link ext-link-type="uri" xlink:href="https://www.docker.com" xlink:type="simple">https://www.docker.com</ext-link>) that automatically builds the run environment for the pipeline. This not only facilitates sharing the pipeline, but also ensures its reproducibility [<xref ref-type="bibr" rid="pcbi.1006064.ref010">10</xref>]. We provide an extensive list of examples and documentation on our <ext-link ext-link-type="uri" xlink:href="https://timvanmourik.github.io/Porcupine/examples" xlink:type="simple">website</ext-link>, as well as the possibility to upload one’s custom pipeline to create a community driven library of analyses.</p>
<p>By implementing an intermediate visual step in the generation of preprocessing workflows, Porcupine allows the user to focus on the logical flow of the preprocessing pipeline in a graphical representation without the need for coding at this conceptual stage of development. Because the GUI produces functional analysis code, the user can then immediately inspect, save, and run the generated code. Thus, Porcupine provides a stepping stone that eases the transition from concept to implementation. Because the entire pipeline and its parameters are defined <italic>in abstracto</italic> before it is run, systems such as Nipype allow for elaborate checks and optimisations of the pipeline’s execution. Furthermore, such systems can straightforwardly incorporate full logging of all analysis steps, creating a paper trail of the pipeline’s execution. This combination of a reproducible environment in which a predefined pipeline is run by means of a system that provides precise bookkeeping paves the way to new standard that will ensure steady and reproducible progress in the field of cognitive neuroimaging [<xref ref-type="bibr" rid="pcbi.1006064.ref011">11</xref>].</p>
<p>In our practical experience, the use of Porcupine allows one to very quickly prototype preprocessing pipelines. Novice users can create a pipeline <italic>de novo</italic> and quickly focus on the code for this pipeline, greatly speeding up the learning process and thereby facilitating the use of reproducible pipelines. We envisage Porcupine to play a role in both the education of novice neuroimaging students and the rapid prototyping of pipelines by expert users. Here, we first outline several Porcupine use-case scenarios of increasing complexity, after which we detail the architecture of Porcupine.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>What is Porcupine?</title>
<p>Porcupine is a graphical workflow editor that automatically produces analysis code from a graphically composed pipeline. By dropping ‘nodes’ (representing analysis steps) into the workflow editor and by connecting their data inputs and outputs, a pipeline is constructed. Analysis code is then automatically generated from the graphical representation of the pipeline. The code can readily be saved to a script (e.g. a Python, MATLAB, or Docker file) in order to perform the desired analysis. Additionally, the pipeline can be shared or inspected in visual form (PDF/SVG), or saved to a Porcupine specific (.pork) file to continue working on the pipeline at another time.</p>
<p>Apart from the visual representation of the pipeline, we provide more functionality to orderly structure one’s analysis, as outlined in <xref ref-type="fig" rid="pcbi.1006064.g001">Fig 1</xref>. All functions (the nodes in the graph) that are included in the pipeline are also listed in a separate panel, listing their input parameters, output data, as well as a link to the online documentation of the function. We also provide the option to iterate over any input variable in order to facilitate parallelisation over subjects, sessions, or other variables. All parameters may also be edited in a separate parameter panel of the user interface. This functions as a central storage for important parameters, for example the ones that should be reported in a methods section. Porcupine combines the graphical overview and the parameters to automatically create the analysis code shown in the code window.</p>
<fig id="pcbi.1006064.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006064.g001</object-id>
<label>Fig 1</label>
<caption>
<title>A screenshot of a Porcupine workflow.</title>
<p>The editor is divided into four panels, each of them targeted at facilitating a more understandable and reproducible analysis. The <italic>workflow editor</italic> (1) provides a visual overview of one’s analysis. The functions are all listed in the <italic>node editor</italic> (2), where the parameters for all functions can be orderly stored. This may include links to important parameters that are listed in the <italic>parameter editor</italic> (3), such that an overview of the main analysis settings can be easily viewed and modified. Readily executable analysis code is generated in the <italic>code window</italic> (4).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006064.g001" xlink:type="simple"/>
</fig>
<p>We here focus on code generation that strictly adheres to the Nipype API [<xref ref-type="bibr" rid="pcbi.1006064.ref004">4</xref>], a Python-based MRI analysis and pipelining package. Nipype is used for its strong focus on uniformity in accessing functions, its link to most major MRI analysis tools, and its emphasis on reproducible science. Porcupine’s architecture, however, is in principle agnostic with respect to the specific implementation of the underlying pipelining software. Any package with a consistent interface in the field of e.g. neuroimaging, bioengineering, or astronomy could benefit from using Porcupine’s architecture.</p>
<p>We first show that we can easily generate a standard fMRI analysis pipeline. After visually dragging and dropping modules, code is automatically created that is usually scripted manually instead. We then show how we facilitate loading data from an online repository, generate a readily executable fMRI pipeline, but also generate a shareable and reproducible analysis environment (using Docker), all with minimal additional effort. This allows for easily scalable analyses that can be performed locally, but also on computational clusters or with cloud computing, without manual installation of different software packages.</p>
</sec>
<sec id="sec004">
<title>Usage example</title>
<p>We here show a simple example that constructs a pipeline for a single operation. In three steps, data is loaded, (minimally) processed, and the output is written to disk, as shown in <xref ref-type="fig" rid="pcbi.1006064.g002">Fig 2</xref>. We here show an example that links to an OpenNeuro fMRI data set, but we could load any online data set that is set up according to the BIDS format [<xref ref-type="bibr" rid="pcbi.1006064.ref002">2</xref>]. OpenNeuro’s data sets are stored as Amazon repositories (‘S3 buckets’) and can be loaded by dragging the appropriate module into the workflow editor and typing the name of the bucket into the node editor. Its output can subsequently be connected to a Nipype function node, for example FSL’s Brain Extraction Tool. All parameters of the function are listed and can be set in two different ways: either by dragging a link from a previous node’s output port to an input port in the next node, or by typing in the parameter in the node editor. Subsequently, output can be written to disk by connecting the desired output to a Nipype DataSink node that collects and stores the data. By pressing the ‘Generate code’ button, the code for this pipeline is automatically generated and can immediately be saved and executed in a Python shell.</p>
<fig id="pcbi.1006064.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006064.g002</object-id>
<label>Fig 2</label>
<caption>
<title>An example of simple workflow.</title>
<p>In three steps, this pipeline loads data, processes it, and writes it to disk. This is achieved by connecting the input and output fields from subsequent nodes in the pipeline. The constructed workflow is then transformed in readily executable (Nipype) analysis code.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006064.g002" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec005">
<title>Pipeline sharing</title>
<p>From a simple example that reads and writes the data, a more complicated pipeline is readily set up. More functionality, i.e. nodes, can be dragged in and connected to quickly build a custom pipeline. As it is commonplace to repeat a single analysis or function for several subjects, sessions, or other variables, every field can be flagged as an ‘iterator’ field. This facilitates looping over variables. Once the pipeline is set up and the code is generated, Nipype offers functionality to construct a visual pipeline graph from custom python code. In Porcupine’s proposed use-case, this end point of a standard Nipype pipeline represents the starting point, as shown in <xref ref-type="fig" rid="pcbi.1006064.g003">Fig 3</xref>. This allows the user to focus on the desired pipeline graph first, and then progress to the manual editing of the generated code.</p>
<fig id="pcbi.1006064.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006064.g003</object-id>
<label>Fig 3</label>
<caption>
<title>An example of a more complicated and realistic fMRI preprocessing pipeline.</title>
<p>Once the code is generated, this can in turn be transformed into a Nipype graph visualisation. Whereas this is usually the end point for a pipeline in Nipype, we here propose to use a visualisation as a starting point of one’s analysis.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006064.g003" xlink:type="simple"/>
</fig>
<p>Not only does Porcupine provide a way of setting up a preprocessing or analysis pipeline, we also provide a means for executing these pipelines in a reproducible environment. In addition to the Python analysis file that is generated, we create a scaffold for a Docker file. Docker (<ext-link ext-link-type="uri" xlink:href="https://www.docker.com" xlink:type="simple">https://www.docker.com</ext-link>) is an open platform to easily build, run and share applications. The generated Docker file describes a minimal operating system that is required to run the analysis, based on the dependencies of the modules used in the workflow editor. With this Docker file, an image of the full analysis can be built, shared and executed. This provides a simple platform to reproduce results of one’s analysis, on the same data set, or on another with only a single change in the data source module. Alternatively, one can use it as a template environment for a new follow-up analysis. As with all generated code, the Docker code is fully customisable to a researcher’s need, but our suggested scaffold requires only a single manual edit to be built as a Docker image (see <xref ref-type="supplementary-material" rid="pcbi.1006064.s001">S1 File</xref>. Docker files). The Docker command will execute the pipeline: load the data from an online repository, process the data, and store only the output data to a local directory. The Docker image includes both the pipeline code and the run environment, and can be shared alongside a paper via DockerHub. The above examples (and many more) as well as extensive documentation and tutorials can be found <ext-link ext-link-type="uri" xlink:href="https://timvanmourik.github.io/Porcupine" xlink:type="simple">here</ext-link>.</p>
</sec>
<sec id="sec006">
<title>Limitations</title>
<p>Some features in Nipype have not been implemented. Notably, the JoinNode functionality is not yet accessible from the Porcupine user interface, in which the results from an upstream iterator are aggregated to a single output. Furthermore, custom extensions of Nipype functions are not automatically supported, but we do provide a script to add one’s own custom module to Porcupine that would make this functionality accessible. A GUI for this is still an intended point of improvement. In general, feature requests are maintained as <italic>issues</italic> and <italic>projects</italic> in the <ext-link ext-link-type="uri" xlink:href="https://github.com/TimVanMourik/Porcupine/projects" xlink:type="simple">GitHub repository</ext-link>. We encourage people to contribute new ideas or implementations for functionality in terms of modules, new toolboxes, and, most importantly, custom pipelines that can be added to the repository. Details on how to contribute can be found on the website.</p>
<p>While Porcupine in principle supports all workflow operations, a specific pipeline may well require modules that are not provided within Nipype. It is advised that the user either packages custom code for this into a new module, or manually adds it to the produced code. We furthermore stress that Porcupine is intended to function as a front-end encapsulation of NiPype, and does not implement the parsing of python files that contain pre-defined nipype pipelines. It also does not perform type-matching on the input and output of a connection, nor does it perform syntax checking of the manually edited parameters.</p>
</sec>
</sec>
<sec id="sec007" sec-type="materials|methods">
<title>Design and implementation</title>
<p>Porcupine’s graphical user interface was written first with a general visual programming application in mind. The initial interface to Nipype was developed at a three-day coding sprint at BrainHack 2017, Amsterdam. This kickstarted Porcupine in its current form. The source code, as well as the installer files for Windows, Mac, and Linux, are publicly available as a <ext-link ext-link-type="uri" xlink:href="https://github.com/TimVanMourik/Porcupine" xlink:type="simple">GitHub repository</ext-link>. Porcupine is free, open source, and released under the GNU General Public License v3.0. It has static digital object identifier (DOI) <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.1146653" xlink:type="simple">doi.org/10.5281/zenodo.1146653</ext-link>.</p>
<p>Visual programming is a generic way of programming to create a data flow or to perform an ordered task with a modular structure [<xref ref-type="bibr" rid="pcbi.1006064.ref012">12</xref>]. Customarily, it allows the user to construct a Directed Acyclic Graph (DAG) [<xref ref-type="bibr" rid="pcbi.1006064.ref013">13</xref>] of conceptualised operations that are subsequently interpreted or compiled as an application [<xref ref-type="bibr" rid="pcbi.1006064.ref014">14</xref>]. This format is particularly useful for workflows that fit modular structures, such as most neuroimaging data analyses [<xref ref-type="bibr" rid="pcbi.1006064.ref015">15</xref>].</p>
<sec id="sec008">
<title>Architecture</title>
<p>Not only do we intend researchers to make their analyses (re-)usable and robust, our software also adheres to all 20 simple rules that were laid out to this end [<xref ref-type="bibr" rid="pcbi.1006064.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1006064.ref017">17</xref>]. The updates as well as the releases of the source code are realised by means of a GitHub repository. Installer files are provided for all platforms and do not require administrator privilege. Users are aided in getting started quickly by extensive documentation and an example gallery.</p>
<p>Easy cross-platform installation or compilation was achieved by programming Porcupine as a stand-alone application in Qt Creator (<ext-link ext-link-type="uri" xlink:href="https://www.qt.io" xlink:type="simple">https://www.qt.io</ext-link>) for C++. Internal file formats were standardised to JSON dictionaries, a format native to Python, Qt, and web applications. This provides a simple means to add new modules to Porcupine, without the need to write additional code. Every dictionary specifies a software package (e.g. ‘Nipype’, ‘Docker’, etc.) that is interpreted by Porcupine and creates code that is native to the package. A package-specific interpreter needs to be written just once, after which new modules that are included in the dictionary will be automatically available in Porcupine.</p>
<p>Each JSON dictionary describes a list of functions (internally referred to as ‘nodes’). Each function has a name and (optionally) a category, a web url to its documentation, and a block of code. A code block specifies the software package for which the node is meant, the associated piece of code for that function and optionally an additional comment. Furthermore, a node contains any number of data/parameter ports, each of which can be input, output, or both. Optionally, additional flags can be set for ports to be visible in the editor, whether its value is editable, or whether the variable needs to be iterated over. Thus, JSON files for custom nodes can easily be created and added as a dictionary to the graphical interface. We also provide a Python script that converts a custom Python function(s) to a Nipype node dictionary.</p>
</sec>
<sec id="sec009">
<title>Extending Porcupine with new toolboxes</title>
<p>Currently, Porcupine features Nipype and Docker support, but this could easily be extended to other software packages. This requires no major changes to the Porcupine source code, merely the inclusion of a single C++ class that describes the relationship between the nodes, links, and the output code. Specifically, the ‘CodeGenerator’ class must be inherited and has access to the full workflow: the list of nodes, their parameters, and their connections. As long as all functions within an analysis toolbox can be accessed with a consistent interface, they can be represented as modules within Porcupine. Apart from Nipype, support for a laminar specific fMRI analysis toolbox in MATLAB is provided. The developers of the Fastr framework programmed initial support for their code base [<xref ref-type="bibr" rid="pcbi.1006064.ref018">18</xref>]. Unfortunately, only few neuroimaging packages abide by this uniformity of their functions and hence many cannot be included into Porcupine.</p>
</sec>
<sec id="sec010">
<title>Relation to existing pipeline managers</title>
<p>Porcupine aims to provide an extendable, transparent and flexible platform to build preprocessing and analysis pipelines. Other software packages have made similar attempts at providing visual aids to build or run pipelines. Within neuroimaging, the most notable ones are the JIST pipeline [<xref ref-type="bibr" rid="pcbi.1006064.ref019">19</xref>], extended with CBS Tools [<xref ref-type="bibr" rid="pcbi.1006064.ref020">20</xref>] and the LONI pipeline [<xref ref-type="bibr" rid="pcbi.1006064.ref015">15</xref>]. Porcupine distinguishes itself from these by not creating a run environment, but instead creating the analysis code for the researcher. This retains the possibility of immediately running the code through a Python interpreter, but also creates more flexibility, as researchers can modify and adjust the script according to their needs. Lastly, our open-source framework is set up to be extendable with new modules within existing frameworks, as well as with completely new frameworks. This provides a future-proof set-up for current and future analysis tools in neuroimaging and perhaps other disciplines.</p>
</sec>
</sec>
<sec id="sec011">
<title>Availability and future directions</title>
<p>We have presented a new tool to visually construct an analysis pipeline. Subsequently, Porcupine automatically generates the analysis code, and provides a way of running and sharing such analyses. We see this as an important tool and a stepping stone on the path to doing more reproducible and open science. Additionally, this gives researchers a better oversight of their analysis pipeline, allowing for greater ease of developing, understanding, and communicating complex analyses.</p>
<p>Porcupine provides two independent functionalities that dovetail to allow users to more easily take part in reproducible neuroimaging research. They are (1) a graphical user interface for the visual design of analysis pipelines and (2) a framework for the automated creation of docker images to execute and share the designed analysis.</p>
<p>We anticipate that the ability to design processing pipelines visually instead of programmatically will cut the novice user’s learning phase by a considerable amount of time by facilitating understanding and development. The ease of use of a Graphical User Interface (GUI) implementation extends and complements Nipype’s flexibility. Thus, it invites researchers to mix and match different tools, and adhere less stringently to the exclusive use of the tools of any given toolbox ecosystem. This flexibility enhances the possible sophistication of processing pipelines, and could for instance be helpful in cross-modal research or multi-site research. Additionally, it may nudge method developers to write new tools in a way that easily integrates with the Nipype and Porcupine structure.</p>
<p>The emphasis that Porcupine puts on visual development of analyses makes it easier to communicate a methods section visually rather than in writing. We foresee that researchers may prefer explicity sharing the created .pork files and the Nipype pipelines that are created from them, instead of solely relying on written descriptions of their methods. Yet another use case for Porcupine is the easy definition of proposed processing workflows for preregistered studies.</p>
<p>Importantly, Porcupine attempts to reduce the steepness of the learning curve that is inherent to the use of complex analysis, by providing a more structured and systematic approach to pipeline creation. It separates the skill of building a conceptual analysis pipeline from the skill of coding this in the appropriate programming language. This places Porcupine in a position to aid in the education of novice neuroimaging researchers, as it allows them to focus on the logic of their processing instead of the creation of the code for the processing—greatly improving and accelerating their understanding of the different steps involved in the preprocessing of neuroimaging data. At the same time, it allows more experienced researchers to spend more time on the conceptual side than on implementational side.</p>
<p>Having allowed for the visual design of a pipeline for the preprocessing or analysis of a neuroimaging dataset, the reproducible execution of this pipeline is another step that Porcupine facilitates. By flexibly creating a Docker image tailored to the different preprocessing steps defined visually in the GUI, Porcupine allows the user to share not only the definition of the pipeline but also its execution environment. This step removes the overhead of having to manually install the desired operating system with the matching distribution of MRI analysis software. This final step greatly facilitates the reproducibility of reported results, and is part of a general evolution of the field towards easily shareable and repeatable analyses.</p>
<p>The generated Docker image can be made High Performance Computing aware by means of dedicated tools such as <ext-link ext-link-type="uri" xlink:href="https://github.com/singularityware/docker2singularity" xlink:type="simple">docker2singularity</ext-link>. Alternatively, with only trivial additions to the Dockerfile, it can be transformed into a BIDS app [<xref ref-type="bibr" rid="pcbi.1006064.ref021">21</xref>]. A detailed explanation for doing this can be found on our <ext-link ext-link-type="uri" xlink:href="https://timvanmourik.github.io/Porcupine/documentation/advanced/make-a-bids-app" xlink:type="simple">website</ext-link>. An automatic and direct way of creating this has not yet been implemented. Additionally, integrating support for standardised workflow file formats, such as the Common Workflow Language [<xref ref-type="bibr" rid="pcbi.1006064.ref022">22</xref>] could further add to Porcupine’s aim of reproducibility. Another point of improvement is a functionality to embed pipelines within pipelines. Currently, a complicated pipeline does full justice to the term ‘spaghetti code’, and the number of nodes and links may easily compromise the visual aid in understanding; the very purpose for which Porcupine was created. This may easily be solved by compartmentalising pipelines into logical units by providing an embedded structure.</p>
<p>We intend Porcupine to be a strong aid for doing better, more reproducible and shareable science. By bridging the gap between a conceptual and implementational level of the analysis, we give scientists a better oversight of their pipeline and aid them in developing and communicating their work. We provide extensive and intuitive documentation and a wide range of examples to give users a frictionless start to use Porcupine. We look forward to adding more functionality and supporting more toolboxes in the near future.</p>
</sec>
<sec id="sec012">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006064.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006064.s001" xlink:type="simple">
<label>S1 File</label>
<caption>
<title>Docker files.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We would like to thank the organisation of BrainHack Global and BrainHack Amsterdam, specifically Pierre-Louis Bazin, for organising the platform that kickstarted Porcupine in its current form.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006064.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Poldrack</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Barch</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Mitchell</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wager</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Devlin</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Toward open sharing of task-based fMRI data: the OpenfMRI project</article-title>. <source>Frontiers in Neuroinformatics</source>. <year>2013</year>;<volume>7</volume>:<fpage>12</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fninf.2013.00012" xlink:type="simple">10.3389/fninf.2013.00012</ext-link></comment> <object-id pub-id-type="pmid">23847528</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gorgolewski</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Auer</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Calhoun</surname> <given-names>VD</given-names></name>, <name name-style="western"><surname>Craddock</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Das</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Duff</surname> <given-names>EP</given-names></name>, <etal>et al</etal>. <source>The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments</source>. <year>2016</year>;<volume>3</volume>:<fpage>160044</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006064.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fischl</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>van der Kouwe</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Destrieux</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Halgren</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Segonne</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Salat</surname> <given-names>DH</given-names></name>, <etal>et al</etal>. <article-title>Automatically parcellating the human cerebral cortex</article-title>. <source>Cereb Cortex</source>. <year>2004</year>;<volume>14</volume>(<issue>1</issue>):<fpage>11</fpage>–<lpage>22</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhg087" xlink:type="simple">10.1093/cercor/bhg087</ext-link></comment> <object-id pub-id-type="pmid">14654453</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gorgolewski</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Burns</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Madison</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Clark</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Halchenko</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Waskom</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Nipype: A Flexible, Lightweight and Extensible Neuroimaging Data Processing Framework in Python</article-title>. <source>Frontiers in Neuroinformatics</source>. <year>2011</year>;<volume>5</volume>:<fpage>13</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fninf.2011.00013" xlink:type="simple">10.3389/fninf.2011.00013</ext-link></comment> <object-id pub-id-type="pmid">21897815</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jenkinson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Beckmann</surname> <given-names>CF</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>SM</given-names></name>. <article-title>Fsl</article-title>. <source>Neuroimage</source>. <year>2012</year>;<volume>62</volume>(<issue>2</issue>):<fpage>782</fpage>–<lpage>790</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2011.09.015" xlink:type="simple">10.1016/j.neuroimage.2011.09.015</ext-link></comment> <object-id pub-id-type="pmid">21979382</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref006">
<label>6</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Elam</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Van Essen</surname> <given-names>D</given-names></name>. In: <name name-style="western"><surname>Jaeger</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Jung</surname> <given-names>R</given-names></name>, editors. <source>Human Connectome Project</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer New York</publisher-name>; <year>2015</year>. p. <fpage>1408</fpage>–<lpage>1411</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006064.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gorgolewski</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Varoquaux</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rivera</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Schwarz</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Ghosh</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Maumet</surname> <given-names>C</given-names></name>, <etal>et al</etal>. <article-title>NeuroVault.org: a web-based repository for collecting and sharing unthresholded statistical maps of the human brain</article-title>. <source>Frontiers in Neuroinformatics</source>. <year>2015</year>;<volume>9</volume>:<fpage>8</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fninf.2015.00008" xlink:type="simple">10.3389/fninf.2015.00008</ext-link></comment> <object-id pub-id-type="pmid">25914639</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brian</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Nosek</surname> <given-names>OSC</given-names></name>. <article-title>Estimating the reproducibility of psychological science</article-title>. <source>Science</source>. <year>2015</year>;<volume>349</volume> (<issue>6251</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.aac4716" xlink:type="simple">10.1126/science.aac4716</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref009">
<label>9</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Ellson</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gansner</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Koutsofios</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>North</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Woodhull</surname> <given-names>G</given-names></name>. In: <name name-style="western"><surname>Mutzel</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Jünger</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Leipert</surname> <given-names>S</given-names></name>, editors. <source>Graphviz— Open Source Graph Drawing Tools</source>. <publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer Berlin Heidelberg</publisher-name>; <year>2002</year>. p. <fpage>483</fpage>–<lpage>484</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006064.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Boettiger</surname> <given-names>C</given-names></name>. <article-title>An introduction to Docker for reproducible research</article-title>. <source>ACM SIGOPS Operating Systems Review</source>. <year>2015</year>;<volume>49</volume>(<issue>1</issue>):<fpage>71</fpage>–<lpage>79</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1145/2723872.2723882" xlink:type="simple">10.1145/2723872.2723882</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gorgolewski</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name>. <article-title>A Practical Guide for Improving Transparency and Reproducibility in Neuroimaging Research</article-title>. <source>PLoS Biology</source>. <year>2016</year>;<volume>14</volume>(<issue>7</issue>):<fpage>e1002506</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1002506" xlink:type="simple">10.1371/journal.pbio.1002506</ext-link></comment> <object-id pub-id-type="pmid">27389358</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Myers</surname> <given-names>BA</given-names></name>. <article-title>Visual Programming, Programming by Example, and Program Visualization: A Taxonomy</article-title>. <source>SIGCHI Bull</source>. <year>1986</year>;<volume>17</volume>(<issue>4</issue>):<fpage>59</fpage>–<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1145/22339.22349" xlink:type="simple">10.1145/22339.22349</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref013">
<label>13</label>
<mixed-citation publication-type="other" xlink:type="simple">Thulasiraman K, Swamy M. 5.7 Acyclic Directed Graphs. Graphs: Theory and Algorithms. 1992; p. 118.</mixed-citation>
</ref>
<ref id="pcbi.1006064.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Myers</surname> <given-names>BA</given-names></name>. <article-title>Taxonomies of visual programming and program visualization</article-title>. <source>Journal of Visual Languages &amp; Computing</source>. <year>1990</year>;<volume>1</volume>(<issue>1</issue>):<fpage>97</fpage>–<lpage>123</lpage>. <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S1045-926X(05)80036-9" xlink:type="simple">http://dx.doi.org/10.1016/S1045-926X(05)80036-9</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1006064.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rex</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>JQ</given-names></name>, <name name-style="western"><surname>Toga</surname> <given-names>AW</given-names></name>. <article-title>The LONI Pipeline Processing Environment</article-title>. <source>NeuroImage</source>. <year>2003</year>;<volume>19</volume>(<issue>3</issue>):<fpage>1033</fpage>–<lpage>1048</lpage>. <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S1053-8119(03)00185-X" xlink:type="simple">http://dx.doi.org/10.1016/S1053-8119(03)00185-X</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1006064.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>List</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ebert</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Albrecht</surname> <given-names>F</given-names></name>. <article-title>Ten Simple Rules for Developing Usable Software in Computational Biology</article-title>. <source>PLOS Computational Biology</source>. <year>2017</year>;<volume>13</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005265" xlink:type="simple">10.1371/journal.pcbi.1005265</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Taschuk</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>G</given-names></name>. <article-title>Ten simple rules for making research software more robust</article-title>. <source>PLOS Computational Biology</source>. <year>2017</year>;<volume>13</volume>(<issue>4</issue>):<fpage>1</fpage>–<lpage>10</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005412" xlink:type="simple">10.1371/journal.pcbi.1005412</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Achterberg</surname> <given-names>HC</given-names></name>, <name name-style="western"><surname>Koek</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Niessen</surname> <given-names>WJ</given-names></name>. <article-title>Fastr: A Workflow Engine for Advanced Data Flows in Medical Image Analysis</article-title>. <source>Frontiers in ICT</source>. <year>2016</year>;<volume>3</volume>:<fpage>15</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fict.2016.00015" xlink:type="simple">10.3389/fict.2016.00015</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lucas</surname> <given-names>BC</given-names></name>, <name name-style="western"><surname>Bogovic</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Carass</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bazin</surname> <given-names>PL</given-names></name>, <name name-style="western"><surname>Prince</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Pham</surname> <given-names>DL</given-names></name>, <etal>et al</etal>. <article-title>The Java Image Science Toolkit (JIST) for Rapid Prototyping and Publishing of Neuroimaging Software</article-title>. <source>Neuroinformatics</source>. <year>2010</year>;<volume>8</volume>(<issue>1</issue>):<fpage>5</fpage>–<lpage>17</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s12021-009-9061-2" xlink:type="simple">10.1007/s12021-009-9061-2</ext-link></comment> <object-id pub-id-type="pmid">20077162</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bazin</surname> <given-names>PL</given-names></name>, <name name-style="western"><surname>Weiss</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dinse</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Schäfer</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Trampel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>R</given-names></name>. <article-title>A computational framework for ultra-high resolution cortical segmentation at 7Tesla</article-title>. <source>Neuroimage</source>. <year>2014</year>;<volume>93</volume>:<fpage>201</fpage>–<lpage>209</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.03.077" xlink:type="simple">10.1016/j.neuroimage.2013.03.077</ext-link></comment> <object-id pub-id-type="pmid">23623972</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gorgolewski</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Alfaro-Almagro</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Auer</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Bellec</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Capotă</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Chakravarty</surname> <given-names>MM</given-names></name>, <etal>et al</etal>. <article-title>BIDS apps: Improving ease of use, accessibility, and reproducibility of neuroimaging data analysis methods</article-title>. <source>PLOS Computational Biology</source>. <year>2017</year>;<volume>13</volume>(<issue>3</issue>):<fpage>1</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005209" xlink:type="simple">10.1371/journal.pcbi.1005209</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006064.ref022">
<label>22</label>
<mixed-citation publication-type="other" xlink:type="simple">Amstutz P, Crusoe MR, Tijanić N, Chapman B, Chilton J, Heuer M, et al. Common Workflow Language, v1. 0. figshare. 2016;.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
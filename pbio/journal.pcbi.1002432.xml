<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PCOMPBIOL-D-11-01374</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002432</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Feedforward Inhibition and Synaptic Scaling – Two Sides of the Same Coin?</article-title><alt-title alt-title-type="running-head">Feedforward Inhibition and Synaptic Scaling</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
          <name name-style="western">
            <surname>Keck</surname>
            <given-names>Christian</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
          <name name-style="western">
            <surname>Savin</surname>
            <given-names>Cristina</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Lücke</surname>
            <given-names>Jörg</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Frankfurt Institute for Advanced Studies, Frankfurt am Main, Germany</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Computational and Biological Learning Lab, Department of Engineering, University of Cambridge, Cambridge, United Kingdom</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Department of Physics, Goethe-University, Frankfurt am Main, Germany</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Sporns</surname>
            <given-names>Olaf</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Indiana University, United States of America</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">luecke@fias.uni-frankfurt.de</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: JL CS. Performed the experiments: CK. Analyzed the data: CK. Wrote the paper: CS JL CK. Derivation of analytical results: JL and CK. Preliminary experiments: CS and JL.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>3</month>
        <year>2012</year>
      </pub-date><pub-date pub-type="epub">
        <day>22</day>
        <month>3</month>
        <year>2012</year>
      </pub-date><volume>8</volume><issue>3</issue><elocation-id>e1002432</elocation-id><history>
        <date date-type="received">
          <day>16</day>
          <month>9</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>1</day>
          <month>2</month>
          <year>2012</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2012</copyright-year><copyright-holder>Keck et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Feedforward inhibition and synaptic scaling are important adaptive processes that control the total input a neuron can receive from its afferents. While often studied in isolation, the two have been reported to co-occur in various brain regions. The functional implications of their interactions remain unclear, however. Based on a probabilistic modeling approach, we show here that fast feedforward inhibition and synaptic scaling interact synergistically during unsupervised learning. In technical terms, we model the input to a neural circuit using a normalized mixture model with Poisson noise. We demonstrate analytically and numerically that, in the presence of lateral inhibition introducing competition between different neurons, Hebbian plasticity and synaptic scaling approximate the optimal maximum likelihood solutions for this model. Our results suggest that, beyond its conventional use as a mechanism to remove undesired pattern variations, input normalization can make typical neural interaction and learning rules optimal on the stimulus subspace defined through feedforward inhibition. Furthermore, learning within this subspace is more efficient in practice, as it helps avoid locally optimal solutions. Our results suggest a close connection between feedforward inhibition and synaptic scaling which may have important functional implications for general cortical processing.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>The inputs a neuron receives from its presynaptic partners strongly fluctuate as a result of either varying sensory information or ongoing intrinsic activity. To represent this wide range of signals effectively, neurons use various mechanisms that regulate the total input they receive. On the one hand, feedforward inhibition adjusts the relative contribution of individual inputs inversely proportional to the total number of active afferents, implementing a form of input normalization. On the other hand, synaptic scaling uniformly rescales the efficacy of incoming synapses to stabilize the neuron's firing rate after learning-induced changes in drive. Given that these mechanisms often act on the same neurons, we ask here if there are any benefits in combining the two. We show that the interaction between the two has important computational consequences, beyond their traditional role in maintaining network homeostasis. When combined with lateral inhibition, synaptic scaling and fast feedforward inhibition allow the circuit to learn efficiently from noisy, ambiguous inputs. For inputs not normalized by feed-forward inhibition, learning is less efficient. Given that feed-forward inhibition and synaptic scaling have been reported in various systems, our results suggest that they could generally facilitate learning in neural circuits. More broadly, our work emphasizes the importance of studying the interaction between different plasticity mechanisms for understanding circuit function.</p>
      </abstract><funding-group><funding-statement>This work was supported by grants German Ministry of Research and Education (BMBF) under grant 01GQ0840, BFNT Frankfurt, (CK), the German Research Foundation (DFG) under grant LU∼1196/4-1 (JL) and the Wellcome Trust (CS). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="15"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>As part of an ever-changing world, brain activity changes continuously. The fraction of neurons active in a region at each given moment fluctuates significantly driven by changes in the environment and intrinsic dynamics. Ideally, regions receiving this activity as input should be able to represent incoming signals reliably across the full possible range of stimulation conditions. Indeed, this type of regulation seems to be ubiquitous in the cortex. In the early visual system, contrast gain control begins in the retina <xref ref-type="bibr" rid="pcbi.1002432-Baccus1">[1]</xref> and is strengthened at subsequent stages of the visual system, such that the way an image is represented in V1 simple cells is largely contrast invariant <xref ref-type="bibr" rid="pcbi.1002432-Sclar1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Mante1">[3]</xref>. Similarly, in the olfactory system, neuronal representations remain sparse and odor-specific over thousand-fold changes in odor concentration <xref ref-type="bibr" rid="pcbi.1002432-Stopfer1">[4]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Olsen1">[6]</xref>.</p>
      <p>To be able to achieve such invariance, neurons have evolved various mechanisms that adjust neuronal response properties as function of their total input. One instance of such normalization involves feedforward inhibition, in which afferent inputs induce both excitation and mono-synaptically delayed inhibition onto principal cells <xref ref-type="bibr" rid="pcbi.1002432-Swadlow1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Isaacson1">[12]</xref>, shaping the temporal activity pattern of the postsynaptic neurons <xref ref-type="bibr" rid="pcbi.1002432-Pouille1">[8]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Wehr1">[10]</xref>, and sparsifying population activity <xref ref-type="bibr" rid="pcbi.1002432-Assisi1">[5]</xref>. The degree of specificity of this inhibition can vary from stimulus specific to relatively unspecific <xref ref-type="bibr" rid="pcbi.1002432-Swadlow1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Isaacson1">[12]</xref>. Here, we focus on fast but unselective feedforward inhibition, which has been reported in a range of circuits including hippocampus and sensory areas <xref ref-type="bibr" rid="pcbi.1002432-Pouille2">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Chance1">[13]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Shu1">[15]</xref>. This mechanism adjusts, virtually instantaneously, the sensitivity of pyramidal cells to the overall strength of the afferent stimulus. As a result, the influence of an individual afferent on the firing of the postsynaptic neuron is continuously normalized by the total number of active afferents. Functionally, it has been hypothesized that such input normalization is needed to expand the range of inputs that can be represented in a neuron population <xref ref-type="bibr" rid="pcbi.1002432-Pouille2">[11]</xref>, however, its implications for learning in the circuit remain unclear.</p>
      <p>Another mechanism with similar effects, but acting on a slower time scale, is synaptic scaling <xref ref-type="bibr" rid="pcbi.1002432-Turrigiano1">[16]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Turrigiano2">[18]</xref>. Specifically, it is believed that neurons detect sustained changes in their firing rates through calcium-dependent sensors and increase or decrease the density of glutamate receptors at synaptic sites to compensate for these changes in drive <xref ref-type="bibr" rid="pcbi.1002432-Turrigiano3">[19]</xref>. This results in an uniform rescaling of the strength of excitatory synapses as a function of average postsynaptic activity. Synaptic scaling often takes a multiplicatively form <xref ref-type="bibr" rid="pcbi.1002432-Leslie1">[17]</xref>, which has the benefit of preserving the relative contribution of synapses and hence the information stored through Hebbian learning <xref ref-type="bibr" rid="pcbi.1002432-Abbott1">[20]</xref>. This type of weight normalization is believed to address a different kind of stability problem–the fact that synapses are plastic. As Hebbian learning alone would destabilize neural dynamics, due to a positive feedback loop, additional homeostatic mechanisms such as synaptic scaling are needed to ensure stable circuit function <xref ref-type="bibr" rid="pcbi.1002432-Turrigiano2">[18]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Abbott1">[20]</xref>.</p>
      <p>Fast feedforward inhibition and synaptic scaling have been reported for a range of circuits including hippocampal and neocortical pyramidal neurons <xref ref-type="bibr" rid="pcbi.1002432-Pouille2">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Turrigiano3">[19]</xref>. Given that both mechanisms effectively regulate the total incoming drive to neurons, it may be somewhat surprising that they co-occur in the same cell types. This suggests there may be some computational advantage in combining input normalization and synaptic scaling. However, based on the existing experimental evidence alone, it is unclear what possible benefits this interaction may have.</p>
      <p>We show here that the role of input normalization and synaptic scaling goes beyond simply maintaining circuit homeostasis, and that they play important computational roles during synaptic learning. In the presence of neuronal competition by global lateral inhibition, the two enable efficient unsupervised learning from noisy or ambiguous inputs. Specifically, we consider an elementary circuit that incorporates synaptic scaling and fast feedforward inhibition. We analyze the learning dynamics in this circuit and show that, for certain input statistics, standard neural dynamics and Hebbian synaptic plasticity implement approximately optimal learning for this data–an observation that we further confirm in numerical experiments. The studied circuit learns an efficient representation of its inputs which can be used for further processing by downstream networks (e.g., for classification). Importantly, in the absence of feedforward inhibition, learning in the same circuit results in much poorer representations, as the system has a stronger tendency to converge to locally optimal solutions–a problem that neural and non-neural systems for unsupervised learning commonly face. This provides evidence for synaptic plasticity requiring normalized inputs for efficient learning. Given that feedforward inhibition and synaptic scaling seem to co-occur in various neural circuits, our results suggest that the interplay between the two mechanisms may generally facilitate learning in the cortex.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <p>We construct a model of feedforward inhibition and synaptic scaling acting in a neural circuit in which excitatory synapses change by Hebbian learning. The analysis of their interaction proceeds in two steps. First, we study the dynamics of learning within the circuit, leaving details of the neural dynamics unspecified. This analysis reveals that the weights converge to final values that are fully determined by the input distribution and the neuronal transfer function. Second, when using a specific statistical model for the input distribution, we can identify biologically plausible neural dynamics that implement optimal learning for these stimuli. We show that a specific form of lateral inhibition implementing softmax competition between different neurons is sufficient for optimal learning in our setup, something which we then confirm by numerical simulations, using both artificially generated and natural data. Lastly, we show that learning performance is critically dependent on feedforward inhibition and, how the emerging representations can be used by higher processing layers, for instance, for efficient classification.</p>
      <sec id="s2a">
        <title>A neural circuit model</title>
        <p>As a starting point, consider the elementary neural circuit shown in <xref ref-type="fig" rid="pcbi-1002432-g001">Fig. 1A</xref>. The network consists of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e001" xlink:type="simple"/></inline-formula> neurons receiving excitatory inputs from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e002" xlink:type="simple"/></inline-formula> input neurons through a set of excitatory weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e003" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e004" xlink:type="simple"/></inline-formula>. We denote by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e005" xlink:type="simple"/></inline-formula> the activity of input neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e006" xlink:type="simple"/></inline-formula> and by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e007" xlink:type="simple"/></inline-formula> the activity of the downstream processing neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e008" xlink:type="simple"/></inline-formula>.</p>
        <fig id="pcbi-1002432-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002432.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>An overview of the model.</title>
            <p>(A) The neural circuit receives normalized inputs conveyed by excitatory synapses to a processing layer (large figure). The activity of the processing neurons is determined by the received inputs and internal dynamics mediated by lateral interactions. Inset: Two forms of weight scaling. The red curve shows conventional linear scaling, the green curve logarithmic scaling for values larger one. (B) Inputs to the circuit are modeled using a mixture model with normalized generative fields and Poisson noise. (C) Example normalized fields, with different values of the normalization constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e009" xlink:type="simple"/></inline-formula>. (D) Illustration how inputs with different contrast levels are normalized (background set to 1).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.g001" xlink:type="simple"/>
        </fig>
        <p>In the general case, the activity of neurons <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e010" xlink:type="simple"/></inline-formula> can be defined as a function of the activity of the input layer, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e011" xlink:type="simple"/></inline-formula>, and of the weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e012" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e013" xlink:type="simple"/><label>(1)</label></disp-formula>This transfer function is not necessarily local, as it does not restrict the dependency to the afferent weights of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e014" xlink:type="simple"/></inline-formula>; it allows us to also describe the interactions between neurons through lateral connections (marked by dotted lines in <xref ref-type="fig" rid="pcbi-1002432-g001">Fig. 1A</xref>). For the first part of the analysis, we assume the neural dynamics given by (1) to be arbitrary, though later we consider specific forms for the transfer function.</p>
        <p>We model feedforward inhibition by explicitly normalizing the input vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e015" xlink:type="simple"/></inline-formula> to satisfy the constraint:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e016" xlink:type="simple"/><label>(2)</label></disp-formula>Such input normalization can remove undesired patterned variations (e.g. contrast, see <xref ref-type="fig" rid="pcbi-1002432-g001">Fig. 1D</xref>), potentially facilitating learning in the circuit. If we denote the un-normalized input by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e017" xlink:type="simple"/></inline-formula>, the constraint can, for instance, be fulfilled by a simple division, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e018" xlink:type="simple"/></inline-formula>, though alternative implementations are possible. This formulation abstracts away the details of the biological implementation, focusing on its functional implications <xref ref-type="bibr" rid="pcbi.1002432-Pouille2">[11]</xref>. Importantly, the simple form allows us to derive theoretical results about the role of this form of feedforward inhibition during learning. At the level of the neural circuit, however, input normalization relies on the presence of a set of fast spiking interneurons (in the hippocampus – predominantly basket cells <xref ref-type="bibr" rid="pcbi.1002432-Pouille1">[8]</xref>) innervated by the same afferent inputs, with unspecific projections onto the subsequent layer. The implications of this neural implementation are considered in more detail in the <xref ref-type="sec" rid="s3">Discussion</xref>.</p>
        <p>We model incoming synapses to be plastic and to change by Hebbian learning, with synaptic scaling implemented by an additional weight dependent term <xref ref-type="bibr" rid="pcbi.1002432-Abbott1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Gerstner1">[21]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e019" xlink:type="simple"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e020" xlink:type="simple"/></inline-formula> is a small positive learning rate. This synaptic scaling model captures the important biological constraint that weight changes should rely only on information that is local to the synapse. It differs from global forms that use an explicit weight normalization in that the normalizing constant is not a separate parameter, but rather is implicitly determined by the circuit dynamics.</p>
      </sec>
      <sec id="s2b">
        <title>Evolution of weights during learning</title>
        <p>The circuit model above defines specific learning dynamics for the synaptic weights as function of the their initial values and of the incoming inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e021" xlink:type="simple"/></inline-formula>. To investigate the evolution of the weights analytically, it is informative to first study the time course of the weight sums <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e022" xlink:type="simple"/></inline-formula> for an arbitrary neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e023" xlink:type="simple"/></inline-formula>. Using the learning rule (Eq. 3) and the explicit input normalization constraint (Eq. 2), we obtain:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e024" xlink:type="simple"/><label>(4)</label></disp-formula>which shows that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e025" xlink:type="simple"/></inline-formula> is a stationary point for the dynamics of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e026" xlink:type="simple"/></inline-formula>. Furthermore, since neural activity and the learning rate are both positive, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e027" xlink:type="simple"/></inline-formula> is a stable stationary point, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e028" xlink:type="simple"/></inline-formula> increases when smaller than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e029" xlink:type="simple"/></inline-formula>, and decreases when larger, independent of the input statistics. Consequently, synaptic plasticity automatically adjusts the sum of the incoming weights to each neuron to the total incoming drive (since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e030" xlink:type="simple"/></inline-formula>). Hence, the synaptic weights of a processing neuron adapt during learning to match the scale of its inputs. Rather than being a separate parameter, the norm of the weights is inherited from the properties of the input stimuli. We show below that this match of the normalizing constants for inputs and weights, respectively, is critical for achieving efficient learning in the neural circuit.</p>
        <p>In contrast to the mean <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e031" xlink:type="simple"/></inline-formula>, which is independent of the inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e032" xlink:type="simple"/></inline-formula> provided that the inputs are normalized, the stationary points for individual weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e033" xlink:type="simple"/></inline-formula> depend on the statistics of the input patterns. Such a dependency is, of course, needed if the circuit is to memorize properties of the input after learning. We can derive an analytical solution for learning in this system, something that has often proved difficult for other models. Specifically, if we consider the input vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e034" xlink:type="simple"/></inline-formula> to be drawn independently and identically from a stationary but otherwise unspecified distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e035" xlink:type="simple"/></inline-formula>, we can show (see <xref ref-type="sec" rid="s4">Methods</xref>) that, at convergence, the weights associated with each neuron are uniquely determined by the statistics of input stimuli and the transfer function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e036" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e037" xlink:type="simple"/><label>(5)</label></disp-formula>where the brackets denote the average of the expression under the input distribution. This approximation is very accurate for small learning rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e038" xlink:type="simple"/></inline-formula> and large numbers of inputs.</p>
      </sec>
      <sec id="s2c">
        <title>A statistical model for normalized input stimuli</title>
        <p>Although Eq. 5 gives a formal description for the outcome of learning in the neural circuit as a function of the neuron dynamics <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e039" xlink:type="simple"/></inline-formula> and the input statistics <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e040" xlink:type="simple"/></inline-formula>, it tells us little about the quality of the learning result. For this, we need to specify the input distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e041" xlink:type="simple"/></inline-formula>. In particular, we use a generative model, which gives not only an explicit model for the input statistics <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e042" xlink:type="simple"/></inline-formula>, but also an expression for the theoretically optimal solution for inference and learning on such data, which we can use to evaluate the quality of learning in the neural circuit <xref ref-type="bibr" rid="pcbi.1002432-Marr1">[22]</xref>.</p>
        <p>The specific generative model we chose is a mixture model, which is naturally associated with classification tasks <xref ref-type="bibr" rid="pcbi.1002432-Duda1">[23]</xref>. Intuitively, a mixture model assumes each input stimulus to belong to one out of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e043" xlink:type="simple"/></inline-formula> classes. Each class is described by a representative input and its typical variations. Mixture models have been well-investigated theoretically and are used to model a variety of data <xref ref-type="bibr" rid="pcbi.1002432-Duda1">[23]</xref>. Moreover, although they may seem restrictive, mixtures are well-suited to model multi-modal data distributions also when the assumptions of the model are not satisfied exactly <xref ref-type="bibr" rid="pcbi.1002432-Duda1">[23]</xref>.</p>
        <p>In generative model terminology, mixture distributions assume an input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e044" xlink:type="simple"/></inline-formula> to be generated by one of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e045" xlink:type="simple"/></inline-formula> model classes (see <xref ref-type="fig" rid="pcbi-1002432-g001">Fig. 1B</xref>). Each class <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e046" xlink:type="simple"/></inline-formula> is described by a representative pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e047" xlink:type="simple"/></inline-formula>, which we will refer to as its generative field. The mixture distributions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e048" xlink:type="simple"/></inline-formula> define the variations of the patterns within each class, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e049" xlink:type="simple"/></inline-formula> is the matrix of all generative fields. The prior probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e050" xlink:type="simple"/></inline-formula> specifies how many inputs are generated by the different classes. Here, we assume all classes to be equally likely, and, since inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e051" xlink:type="simple"/></inline-formula> represent positive firing rates, we choose the Poisson distribution to model noise:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e052" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e053" xlink:type="simple"/></inline-formula> is the number of input dimensions.</p>
        <p>To capture the effects of feedforward inhibition, we assume the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e054" xlink:type="simple"/></inline-formula> to satisfy the constraint:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e055" xlink:type="simple"/><label>(7)</label></disp-formula>with parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e056" xlink:type="simple"/></inline-formula> effectively determining the contrast of the inputs, see <xref ref-type="fig" rid="pcbi-1002432-g001">Fig. 1C</xref>. Note that this model only approximates the effect of feedforward inhibition, since individual stimuli are not normalized (the constraint in Eq. 2 is only true on average). However, the approximation gets increasingly accurate with increasing size of the stimuli, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e057" xlink:type="simple"/></inline-formula>.</p>
        <p>Having a model for the input distribution, we can derive the optimal solution for inference and learning on this data. In particular, we use the expectation maximization (EM) framework <xref ref-type="bibr" rid="pcbi.1002432-Dempster1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Neal1">[25]</xref> which enables us to learn the maximum likelihood solutions for the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e058" xlink:type="simple"/></inline-formula> from input stimuli. Intuitively, this optimal learning procedure alternates between what we call the E-step, estimating how likely the data are under the current model, and the M-step, when we change the model parameters. Iterating E- and M-steps is guaranteed to never decrease the data likelihood and, in practice, it increases the likelihood to (possibly local) likelihood maxima. If a global maximum likelihood solution is found, the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e059" xlink:type="simple"/></inline-formula> represent the best possible learning result (in the limit of many data points). Similarly, the posterior distribution with optimal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e060" xlink:type="simple"/></inline-formula> represents the best possible inference given any specific input. For our model, we obtain the following update rules for optimal parameter learning:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e061" xlink:type="simple"/><label>(8)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e062" xlink:type="simple"/><label>(9)</label></disp-formula>where the posterior probability required for the E-step takes the form of the well-know softmax function <xref ref-type="bibr" rid="pcbi.1002432-Yuille1">[26]</xref> with arguments <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e063" xlink:type="simple"/></inline-formula>.</p>
      </sec>
      <sec id="s2d">
        <title>Optimal learning in the neural circuit</title>
        <p>With the concrete model of normalized input data, we can now ask how learning in our neural circuit is related to the theoretically optimal solutions for such data. First, recall that after learning in the neural circuit has converged, the synaptic weights are a solution of Eq. 5. Second, for the probabilistic model the (possibly local) optimum is obtained after the EM iterations have converged, which means that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e064" xlink:type="simple"/></inline-formula> satisfies Eq. 9 with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e065" xlink:type="simple"/></inline-formula>. Comparing the result of neural learning with the result of EM learning, we note that they have a very similar structure:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e066" xlink:type="simple"/><label>(10)</label></disp-formula>Indeed, synaptic weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e067" xlink:type="simple"/></inline-formula> can be easily mapped into the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e068" xlink:type="simple"/></inline-formula> of the generative model and if we choose the transfer function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e069" xlink:type="simple"/></inline-formula> in the circuit to be equal to the posterior probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e070" xlink:type="simple"/></inline-formula>, the two expressions are the same. Hence, if we interpret neural activity as representing posterior probabilities under our model (compare <xref ref-type="bibr" rid="pcbi.1002432-Dayan1">[27]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Lochmann1">[31]</xref>), any fixed point of EM optimization becomes an approximate fixed point of neural learning.</p>
        <p>The transfer function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e071" xlink:type="simple"/></inline-formula> makes learning in the neural circuit approximately optimal for normalized data, but what does this transfer function mean in neural terms? First, the optimal neural dynamics requires a specific form of lateral interactions, implementing the softmax function (Eq. 8, left-hand-side). Through these interactions, neurons compete for representing each input stimulus. Due to its importance for competitive learning, neural circuits giving rise to the softmax have extensively been investigated <xref ref-type="bibr" rid="pcbi.1002432-Yuille1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Yuille2">[32]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Kwok1">[34]</xref>. Typically they involve unspecific feedback inhibition which suppresses neurons with weak inputs while those with strong inputs can maintain high activity rates. Most of the variants of the implementation should work for the purposes of our model (also compare <xref ref-type="bibr" rid="pcbi.1002432-Fukai1">[35]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Mao1">[37]</xref>); hence we do not commit to one specific realization of this function.</p>
        <p>The arguments of the softmax have a particularly simple form: they represent local summations of input activities weighted by synaptic strengths, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e072" xlink:type="simple"/></inline-formula>. While the summation of inputs is biologically plausible, scaling by the logarithm of the weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e073" xlink:type="simple"/></inline-formula> may not be. It, for instance, implies that the contribution of an input to a neuron's activity may be negative or, unrealistically, change sign during learning. This problem can be addressed, however, while preserving the close correspondence between the circuit's fixed points and maximum likelihood solutions. To achieve this, we note that the only requirement for the input data <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e074" xlink:type="simple"/></inline-formula> is that the total input is preserved, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e075" xlink:type="simple"/></inline-formula>. We therefore have some freedom when modeling how feedforward inhibition enforces this constraint. In particular, if the un-normalized input is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e076" xlink:type="simple"/></inline-formula>, then feedforward inhibition could constrain the total inputs by:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e077" xlink:type="simple"/><label>(11)</label></disp-formula>which represents a slight alteration to the common choice <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e078" xlink:type="simple"/></inline-formula>. Practically, this form of normalization continues to scale the activity of an un-normalized input unit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e079" xlink:type="simple"/></inline-formula> by the total activity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e080" xlink:type="simple"/></inline-formula>, but it introduces an offset corresponding to having some spontaneous background activity in the input layer (which leads to a normalization constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e081" xlink:type="simple"/></inline-formula>).</p>
        <p>This model of feedforward inhibition guarantees that the weights will eventually converge to values larger or approximately equal to one. As a consequence, negative weight factors can be removed completely by linearizing the logarithm around one. We consider two forms of such a linearization: in the first, we use the linearization only for values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e082" xlink:type="simple"/></inline-formula>, in the second, we completely replace the logarithm by the linearized form (see inset of <xref ref-type="fig" rid="pcbi-1002432-g001">Fig. 1A</xref>):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e083" xlink:type="simple"/><label>(12)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e084" xlink:type="simple"/></inline-formula>. For the linearization we exploited that for normalized inputs the softmax becomes invariant with respect to weight offsets (see <xref ref-type="sec" rid="s4">Methods</xref>). The linear case recovers the conventional linear summation of synaptic inputs, while the logarithmic case is a closer approximation of the optimal dynamics (see <xref ref-type="sec" rid="s3">Discussion</xref>).</p>
        <p>The complete description of the final neural circuit is summarized in <xref ref-type="table" rid="pcbi-1002432-t001">Table 1</xref>. It consists of essentially three elements: input normalization, Hebbian plasticity with synaptic scaling, and softmax competition (see also <xref ref-type="fig" rid="pcbi-1002432-g001">Fig. 1</xref>). Our analysis shows that these elementary models of neural interactions can be approximately optimal for learning on normalized inputs from mixture distributions. Notably, the neural circuit can process any type of un-normalized data as feedforward inhibition projects any stimulus to a subspace on which learning is optimal.</p>
        <table-wrap id="pcbi-1002432-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1002432.t001</object-id><label>Table 1</label><caption>
            <title>Learning in neural circuits.</title>
          </caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1002432-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.t001" xlink:type="simple"/><table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td align="left" colspan="1" rowspan="1">lateral inhibition</td>
                <td align="left" colspan="1" rowspan="1">
                  <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e085" xlink:type="simple"/></inline-formula>
                </td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">input integration</td>
                <td align="left" colspan="1" rowspan="1">
                  <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e086" xlink:type="simple"/></inline-formula>
                </td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">synaptic plasticity</td>
                <td align="left" colspan="1" rowspan="1">
                  <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e087" xlink:type="simple"/></inline-formula>
                </td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">feedforward inhibition</td>
                <td align="left" colspan="1" rowspan="1">
                  <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e088" xlink:type="simple"/></inline-formula>
                </td>
              </tr>
            </tbody>
          </table></alternatives><table-wrap-foot>
            <fn id="nt101">
              <label/>
              <p>Summary of neural interactions for approximately optimal learning in our model. The function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e089" xlink:type="simple"/></inline-formula> is given by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e090" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e091" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e092" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e093" xlink:type="simple"/></inline-formula> (see <xref ref-type="fig" rid="pcbi-1002432-g001">Fig. 1A</xref>).</p>
            </fn>
          </table-wrap-foot></table-wrap>
        <p>It is important to remark that no explicit knowledge about <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e094" xlink:type="simple"/></inline-formula> is required at the level of processing neurons, which would be difficult to justify neurally. Instead, synaptic scaling automatically adjusts the weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e095" xlink:type="simple"/></inline-formula> such that the constraint in Eq. 2 is satisfied. This, furthermore, means that synaptic plasticity can follow slow changes of the normalization constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e096" xlink:type="simple"/></inline-formula>, which could be used to further facilitate learning. Formally, manipulating <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e097" xlink:type="simple"/></inline-formula> during learning provides a simple implementation for simulated annealing, which is often used to prevent optimization from converging to locally optimal solutions <xref ref-type="bibr" rid="pcbi.1002432-Ueda1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Sahani1">[39]</xref>. Alternatively, annealing can be achieved by changing the amount of spontaneous activity in the input layer (see <xref ref-type="sec" rid="s3">Discussion</xref> for neural mechanisms implementing such changes).</p>
        <p>Considering the details of the neural circuit and the generative model used here, some aspects of the analytical results presented may not seem very surprising. The similarity between the fixed points for the synaptic weights and the maximum likelihood solution is partly due to the fact that both models fulfill the same constraint, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e098" xlink:type="simple"/></inline-formula>, at least approximately. However, this constraint has different origins in the two models: in the neural circuit it is a reflection of synaptic scaling, whereas in the generative model it appears due to the fact that the modeled data is normalized. Along the same lines, the fact that the softmax function emerges as the optimal transfer function for the circuit is somewhat expected, given that the softmax is closely associated with mixture models. However, the arguments of the softmax, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e099" xlink:type="simple"/></inline-formula>, have a particularly compact form in our case, and they can be easily approximated through the integration of afferent inputs to the processing neurons. The compactness of the neural interactions is a direct consequence of the combination of Poisson mixture distributions, normalized inputs and synaptic scaling. Without any of these components, the interactions would be more complicated, or not optimal.</p>
      </sec>
      <sec id="s2e">
        <title>Optimal learning – numerical simulations</title>
        <p>Although we have shown that learning in the neural circuit approximates optimal learning for our data model, several details remain to be investigated. First, it is unclear how close is learning in the neural circuit to the optimum in practice. Second, since real data rarely follows the assumptions of the model exactly, we would like to know how robust learning is in such cases. These questions can only be answered through numerical simulations using either simple artificial data for which the optimal solutions are known, or realistic inputs from a standard database.</p>
        <sec id="s2e1">
          <title>Artificial data</title>
          <p>We consider an artificially generated data set, for which ground truth about the input distribution is available. In particular, input stimuli are generated by the normalized mixture model (Eqs. 6 and 7), using generative fields <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e100" xlink:type="simple"/></inline-formula> in the shape of partially overlapping filled rectangles, with background values set to one, see <xref ref-type="fig" rid="pcbi-1002432-g002">Fig. 2A</xref>. The degree of overlap of the rectangles and their relative sizes determine the difficulty of the task. Note that all data will be visualized two-dimensionally, i.e., we show inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e101" xlink:type="simple"/></inline-formula> and the synaptic weights of a neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e102" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e103" xlink:type="simple"/></inline-formula>, as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e104" xlink:type="simple"/></inline-formula> pixel images.</p>
          <fig id="pcbi-1002432-g002" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002432.g002</object-id>
            <label>Figure 2</label>
            <caption>
              <title>Learning on artificial data.</title>
              <p>(A) An example set of generative fields <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e105" xlink:type="simple"/></inline-formula>, for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e106" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e107" xlink:type="simple"/></inline-formula> pixels). Due to the normalization, different rectangles have different pixel intensities (displayed here for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e108" xlink:type="simple"/></inline-formula>). (B) Some examples of generated data for the same rectangles as in (A) with normalization constants <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e109" xlink:type="simple"/></inline-formula>. (C) Same examples with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e110" xlink:type="simple"/></inline-formula>. Very high intensity values were truncated to improve visibility. (D) The evolution of synaptic weights during learning in the neural circuit (linear case) if data as in (C) was used. (E) Evolution of the generative fields using EM algorithm for the same data. (F) Likelihood changes during learning for the neural circuit (both versions) and EM; learning used <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e111" xlink:type="simple"/></inline-formula> inputs from the classes shown in (A) with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e112" xlink:type="simple"/></inline-formula>. Different lines of the same color mark individual runs with different random initial conditions.</p>
            </caption>
            <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.g002" xlink:type="simple"/>
          </fig>
          <p>Some example data, generated with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e113" xlink:type="simple"/></inline-formula> classes, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e114" xlink:type="simple"/></inline-formula>, and different normalization constants are shown in <xref ref-type="fig" rid="pcbi-1002432-g002">Fig. 2B,C</xref>. High values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e115" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002432-g002">Fig. 2B</xref>) correspond to a high signal-to-noise ratios, while low values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e116" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002432-g002">Fig. 2C</xref>) result in very noisy data. In annealing terms, a low <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e117" xlink:type="simple"/></inline-formula> corresponds to a high temperature, which makes the system more flexible to explore the space of possible parameters and helps avoid local optima. Here, we keep <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e118" xlink:type="simple"/></inline-formula> fixed during learning and optimize its value for best performance (for this data <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e119" xlink:type="simple"/></inline-formula>, with performance deteriorating for values larger than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e120" xlink:type="simple"/></inline-formula>).</p>
          <p>We generated <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e121" xlink:type="simple"/></inline-formula> data points with generative fields as those in <xref ref-type="fig" rid="pcbi-1002432-g002">Fig. 2A</xref>, which we use to learn the weights in the neural circuit and for the EM parameter optimization (the detailed setup for these experiments is described in the <xref ref-type="sec" rid="s4">Methods</xref>). The evolution of the synaptic weights during learning for an example run in the linear neural circuit is shown in <xref ref-type="fig" rid="pcbi-1002432-g002">Fig. 2D</xref>. The corresponding evolution of the generative fields using EM optimization is shown in <xref ref-type="fig" rid="pcbi-1002432-g002">Fig. 2E</xref>. Both converge after about <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e122" xlink:type="simple"/></inline-formula> iterations over the whole data set (we repeat the input data in the neural circuit as well, for a closer match to EM). Also the neural circuit with log-saturation of inputs shows a behavior very similar to EM (not shown). For a more quantitative comparison of learning in the two systems, we use two measures: the likelihood of the input data under the model, given the learned model parameters, and the percentage of trials which converge to the global optimum.</p>
          <p>First, the evolution of the likelihood during learning is shown in <xref ref-type="fig" rid="pcbi-1002432-g002">Fig. 2F</xref> for the different versions of the model. During learning, the circuit parameters improve continuously to a value close to the likelihood of the ground-truth parameters and therefore close to the optimal value for the data. For comparison, the same plot also shows the likelihood values during EM optimization, which converges to the optimum with a small amount of overfitting (hardly visible in the figure), same as the neural model with log-saturating inputs. The great similarity between the obtained likelihoods confirms the high accuracy of the approximations used in the neural circuit with log-saturation. Likewise, the neural circuit with linear input summation converges to close to optimal likelihood values. The slightly lower final values are attributed to the stronger effect of the fully linear approximation. Second, regarding the recovery of global vs. locally optimal solutions, learning in the circuit converges to the approximately optimal solution for normalized data in most of the runs. Specifically, neural learning in the simple neural circuit recovers the global optimum in 86 of 100 runs, while the log-saturating version further improves this number to 97 of 100 runs; for comparison, EM learning converges to global optima in 96 of 100 runs.</p>
        </sec>
        <sec id="s2e2">
          <title>Realistic data</title>
          <p>We have seen that learning in the neural circuit shows close to optimal performance when the input data is generated according to the assumed mixture model. Real data, however, does not match the assumptions of our model exactly. If we take, for instance, the MNIST dataset of handwritten digits <xref ref-type="bibr" rid="pcbi.1002432-LeCun1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-LeCun2">[41]</xref>, a standard dataset for classification, differences between different items from the same class arise from different writing styles for the same digit. Although writing style variations are not modeled explicitly, we expect the stochasticity modeled by Poisson noise to capture these variations at least partially, allowing for robust learning in this setup. Hence, we use this dataset for learning in our model. We start by normalizing the data by feedforward inhibition (Eq. 11), after which learning proceeds as for the artificial data (see <xref ref-type="sec" rid="s4">Methods</xref> for details). The emerging weights in the neural circuit (linear case) and the corresponding generative fields for an example run using digits ‘0’ to ‘3’ are shown in <xref ref-type="fig" rid="pcbi-1002432-g003">Fig. 3A,B</xref>. As can be observed, both the neural circuit weights and the learned generative fields of EM converge to represent individual digits.</p>
          <fig id="pcbi-1002432-g003" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002432.g003</object-id>
            <label>Figure 3</label>
            <caption>
              <title>Learning on more realistic data.</title>
              <p>(A) Evolution of synaptic weights in the neural circuit on inputs from the MNIST database. (B) Evolution of generative fields using EM on the same data; for both input data consisted of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e123" xlink:type="simple"/></inline-formula> data points from the digit classes 0 to 3 with normalization <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e124" xlink:type="simple"/></inline-formula>. (C) Changes of the likelihood during learning for the neural circuit (both versions) and EM. (D) Synaptic weights learned by the circuit (linear version) on the same data but with five times more processing neurons.</p>
            </caption>
            <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.g003" xlink:type="simple"/>
          </fig>
          <p>A quantitative analysis of the learning outcomes is more difficult in the case of realistic inputs, as we no longer have access to ground-truth information. Nevertheless, we can still compare the likelihood values during learning. <xref ref-type="fig" rid="pcbi-1002432-g003">Fig. 3C</xref> shows the evolution of likelihoods for both circuit models and for EM. As can be observed, the likelihood values for both the neural circuit and EM again continuously increase. As before, the log-saturating circuit and EM converge to virtually identical likelihood values. For the linear circuit, there is again a gap, slightly more pronounced this time (but also note the finer y-axis scale). Still, the neural circuit is very similar to EM in representing individual digits (<xref ref-type="fig" rid="pcbi-1002432-g003">Fig. 3A,B</xref>).</p>
          <p>In general, unsupervised learning in the circuit and EM try to cluster the available data as well as possible, regardless of the ‘true’ class labels. In particular, because of similarities between different digits, the emerging generative fields do not necessarily reflect the digits' class distinction. If we use the full MNIST dataset and ten processing neurons, similar images from different classes, e.g. a ‘3’ and ‘8’ with similar slant, are often clustered together. As a consequence, the neural circuit and EM usually fail to represent all classes. A straight-forward solution for this problem is to increase the number of neurons in the processing layer, which allows for a finer grain representation of the inputs. In such an overcomplete setting, learning can successfully represents all classes. Furthermore, when several neurons learn the same digit, they represent different subclasses (e.g., different slants for ‘3’), as shown in <xref ref-type="fig" rid="pcbi-1002432-g003">Fig. 3D</xref>. In the following, we show that these emerging representations can be used by a higher neural processing layer for efficient classification.</p>
        </sec>
      </sec>
      <sec id="s2f">
        <title>Higher level processing – a classification task</title>
        <p>Until now, we have evaluated the effectiveness of learning by measuring how well the final weights can describe the data (formally, the data likelihood under the generative model). Alternatively, we could ask how useful the emerging input representation is for performing higher level tasks in downstream circuits. The performance for such tasks can give a measure of learning quality that is more independent of specific assumptions about the input statistics. Moreover, such alternative performance measures become a necessity when comparing learning on normalized versus un-normalized data, as done in the following section. Since likelihoods are well-suited measures of learning performance only when computed using the same data, no such comparison is possible when trying to asses the benefits of normalization.</p>
        <p>For the MNIST dataset, a natural task is classification, which has been extensively investigated in the literature, both in neural models and using purely functional approaches (e.g., <xref ref-type="bibr" rid="pcbi.1002432-Hinton1">[42]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Bruna1">[44]</xref>). Note, however, that the type of classification relevant for biological systems differs from the generic classification in several aspects. Perhaps most importantly, stimuli processed by neural circuits usually come without explicit labels. For instance, most visual stimuli we process are not accompanied by labels of the visual objects that caused them. However, during development we are provided (directly or indirectly) with the meaning of objects for some stimuli. In order to classify inputs accordingly, the model needs to have access to at least some stimuli <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e125" xlink:type="simple"/></inline-formula> for which the class membership (label) is known. These labels can then be used to associate the representations in the lower processing layer (obtained by unsupervised learning) with the corresponding class; for instance, all writing styles of a hand-written ‘2’ with digit class ‘2’. Having an overcomplete representation of the data becomes critical for the system to work in this setup. As we have seen in previous numerical experiments, learning with MNIST data yields representations of different classes of hand-written digits. Because of different writing styles, the variations of all patterns showing the same digit are too strong to allow for a representation of all digits with one class per digit. However, as already shown in <xref ref-type="fig" rid="pcbi-1002432-g003">Fig. 3D</xref>, with more neurons than classes, the emergent representation successfully captures all digit classes, with different neurons representing different writing styles (the more units, the more detailed the representation of different writing styles).</p>
        <p>For classification, we extend the neural circuit to include an additional processing stage that makes use of the previously learned representation for assigning class labels. As done for the first processing layer, we formulate the classification process probabilistically, using a generative model assuming that a digit type <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e126" xlink:type="simple"/></inline-formula> generates different writing styles (<xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4A</xref>). This allows us to derive a probabilistic procedure for classifying a given input stimulus (see <xref ref-type="sec" rid="s4">Methods</xref>). The focus here is assessing the utility of the first layer representation for higher level computations rather than the neural implementation of this later processing stage. Still, we can note that the dynamics of the second layer shares several features with the first layer model: the neural dynamics have a simple dependency on a weighted sum of incoming inputs (see <xref ref-type="sec" rid="s4">Methods</xref>), and the inputs themselves are normalized (because of the softmax), suggesting this type of computation could be implemented in a neurally plausible circuit.</p>
        <fig id="pcbi-1002432-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002432.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Classification of MNIST inputs.</title>
            <p>(A) A graphical model linking the representations in the first processing layer, learned in an unsupervised setting, to class labels <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e127" xlink:type="simple"/></inline-formula> in a second processing layer. (B) The assignment of the learned generative fields to digit classes obtained using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e128" xlink:type="simple"/></inline-formula> of the labels in the set of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e129" xlink:type="simple"/></inline-formula> training inputs (subset of MNIST with classes 0 to 3). (C) Classification rates after training for the neural circuit (both versions) and EM on the MNIST test set (classes 0 to 3). (D) Generative fields for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e130" xlink:type="simple"/></inline-formula> classes for EM trained on the full MNIST training set (10 digit types). (E) The classification rate based on the generative fields learned by EM for the full MNIST data set (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e131" xlink:type="simple"/></inline-formula>). Rates are plotted as function of the number of units in the first processing layer. For the results <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e132" xlink:type="simple"/></inline-formula> labels of the training set were used (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e133" xlink:type="simple"/></inline-formula>). Error bars (10 runs) were, in general, too small to be visible: for 100 units, different runs divert from the mean classification rate of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e134" xlink:type="simple"/></inline-formula> by less than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e135" xlink:type="simple"/></inline-formula>; for 300 units by results diverted by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e136" xlink:type="simple"/></inline-formula>; and for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e137" xlink:type="simple"/></inline-formula> units diversions were at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e138" xlink:type="simple"/></inline-formula>. (F) Classification performance as function of the amount of labeled data used for learning in the second processing layer, for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e139" xlink:type="simple"/></inline-formula> units. As in (E) error bars were, in general, too small to be visible.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.g004" xlink:type="simple"/>
        </fig>
        <p>To illustrate classification based on the representations learned unsupervised, we first consider stimuli representing digits of types ‘0’ to ‘3’. For this data, the representations learned by unsupervised learning in the first processing layer (with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e140" xlink:type="simple"/></inline-formula> units) is shown in <xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4B</xref> (bottom row). We label these representations using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e141" xlink:type="simple"/></inline-formula> of the data used for training (i.e., we use the labels of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e142" xlink:type="simple"/></inline-formula> of the training data). The probability distribution for the map between first layer representations and class labels is shown in <xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4B</xref> (computed using Eq. 34, see <xref ref-type="sec" rid="s4">Methods</xref>), demonstrating a close to perfect assignment of representations to digit classes. For a quantitative analysis of this match, we can measure the classification performance of the system for a test dataset (i.e., for data not used for training; see <xref ref-type="sec" rid="s4">Methods</xref> for details). For the four digit dataset, the classification performance as function of the number of neurons in the first processing layer is shown in <xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4C</xref>. For both the neural circuit and EM optimization classification performance increases with the number of units. As can be observed, the neural circuit with log-saturating synaptic efficacies shows virtually identical classification rates to EM learning. Likewise, the neural circuit with standard linear input summation shows a good classification performance, even slightly better for the complete case (four digit classes and four processing neurons). In an overcomplete setup, the rate of successful classifications is still high (e.g., around <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e143" xlink:type="simple"/></inline-formula> for the five times overcomplete setup), though a bit lower than for the log case and EM.</p>
        <p>So far, we have used classification performance as an additional measure for the quality of learning in the circuit. However, the setup is interesting from a functional perspective as well, since it allows for relatively high rates of correct classification using a very limited amount of labeled data. <xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4E</xref> shows classification performance for different degrees of overcompleteness in the processing layer if normalized EM is applied to the full MNIST data (we use EM here as it can be efficiently scaled-up to the size of the full MNIST dataset; see <xref ref-type="sec" rid="s4">Methods</xref>). As before, classification performance increases with an increasing number of units and with the number of labels used for classification (see <xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4E</xref> and <xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4F</xref>, respectively). Importantly, a small percentage of labels is already sufficient to obtain almost the same classification performance as when using all labels. For instance for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e144" xlink:type="simple"/></inline-formula> processing units we obtained a performance of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e145" xlink:type="simple"/></inline-formula> correctly classified stimuli using just <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e146" xlink:type="simple"/></inline-formula> of the MNIST labels. For rates above <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e147" xlink:type="simple"/></inline-formula> less than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e148" xlink:type="simple"/></inline-formula> of labels were sufficient. Moreover, performance in our model is comparable to that of state-of-the-art methods, such as deep belief networks (DBN; <xref ref-type="bibr" rid="pcbi.1002432-Hinton1">[42]</xref>). Using all the labels, the performance of DBN reaches <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e149" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002432-Hinton1">[42]</xref>, but with a much more complex circuit (two processing layers and an associative memory), several learning mechanisms, and after the tuning of many free parameters. In contrast, learning in our model is very straightforward, with very few free parameters (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e150" xlink:type="simple"/></inline-formula>), and requires just few labeled inputs. These properties seem particularly desirable in the biologically relevant setting.</p>
      </sec>
      <sec id="s2g">
        <title>Functional benefits of input normalization</title>
        <p>Even if we assume that synaptic scaling is unavoidable to guarantee stability during Hebbian learning, it is still unclear why the system would need feedforward inhibition, or, more in formal terms, what are the benefits of learning using normalized data. This question can be addressed at two levels. First, at an abstract level, we can ask how different are the outcomes of optimal probabilistic learning when using unconstrained versus normalized data. Second, in neural terms, we can ask how learning changes when blocking feedforward inhibition in the neural circuit.</p>
        <p>To answer the first question, we use our generative model approach to compare the optimal learning dynamics for data that is, or not, normalized (this difference will depend on the relative size of different stimuli; compare <xref ref-type="fig" rid="pcbi-1002432-g005">Fig. 5A and B</xref>). Formally, we construct an analog mixture model for un-normalized data, and derive optimal learning for this model. The analysis yields a similar set of update rules (see <xref ref-type="sec" rid="s4">Methods</xref>, Eqs. 26 and 27), which we can use for unsupervised learning with similar (but un-normalized) data. Because the two learning procedures use different data, comparing them is nontrivial. While for data generated according to the assumed probabilistic model we can still use the percentage of trials converging to the optimum as a performance measure, comparison becomes very difficult for the digits data. Since the likelihoods are no longer comparable (because they are estimated from different data), we can only rely on the classification rates for estimating the quality of the learned representations in this case.</p>
        <fig id="pcbi-1002432-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002432.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>The contribution of feedforward inhibition and synaptic scaling to learning.</title>
            <p>(A) An example set of generative fields for unconstrained (left column) and normalized (right column) data. The overall average intensity across all fields is constrained to facilitate the comparison of learning with different models. (B) Same as before, but with rectangles of similar sizes. (C) Rate of correct classification for optimal learning with constrained vs. unconstrained data. (D) Rate of convergence to global optima when learning from (un)constrained data with the linear network model, when weights are constrained either by local synaptic scaling, or through explicit normalization. All estimates are computed out of 100 trials. (E) Evolution of the synaptic weights when synaptic scaling is implemented either by synaptic scaling or (F) as instantaneous weights normalization, for an example run.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.g005" xlink:type="simple"/>
        </fig>
        <p>We compare the performance of the two learning procedures for the same two datasets described above. For the blocks dataset, learning performance is not significantly different in the two cases (not shown), probably because the task is too easy to be able to differentiate between the two learning procedures. The results for the digits are shown in <xref ref-type="fig" rid="pcbi-1002432-g005">Fig. 5C</xref>. The unconstrained learning procedure yields worse performance than the constrained case; the difference may seem small in absolute terms, but the classification rate for the unconstrained case is worse than the outcome of k-nearest-neighbour (k-NN) classification, which we may view as a lower bound for task difficulty. In itself, this result is not sufficient to prove that learning from normalized data is generally useful for unsupervised learning. Since we can only estimate learning performance indirectly, through the classification rates, it may be that data normalization improves classification in general, by removing task irrelevant variability, without having any specific benefit for learning per se. If this were the case, then we should observe a similar performance improvement for the normalized relative to the unnormalized data when using a standard classifier, such as k-NN. This is however not the case; on the contrary, for k-NN performance decreases to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e151" xlink:type="simple"/></inline-formula> (from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e152" xlink:type="simple"/></inline-formula>) after data normalization, suggesting that the benefits of normalization are restricted to learning procedures that explicitly exploit this property, as does learning in our model.</p>
        <p>For the neural circuit, the utility of the interaction between feedforward inhibition and synaptic scaling is further emphasized. When blocking feedforward inhibition (practically, this means using unnormalized stimuli as inputs to the circuit) the linear circuit converges to represent all classes very rarely, much less often than when feedforward inhibition is active in the circuit (<xref ref-type="fig" rid="pcbi-1002432-g005">Fig. 5D</xref>, compare grey and red bars). In principle, since the neural circuit approximatively implements optimal learning for normalized data, one could expect that performance should be similar to that obtained by constrained EM with un-normalized data, which is indistinguishable from that obtained when learning from normalized data. So why is there a the big difference in performance in the case of the neural circuit? The critical difference between EM and the network is that synaptic scaling only enforces the constraint of the weights through its (normalized) inputs. If the incoming stimuli are not normalized, the sum of the weights is not guaranteed to converge at all (Eq. 4 does not apply). This intuition is confirmed by the fact that when replacing synaptic scaling by an explicit weights normalization (see <xref ref-type="sec" rid="s4">Methods</xref>) learning evolves similarly to the case when feedforward inhibition is active. These results suggest that feedforward inhibition is critical for correctly learning the structure of the data when the weights are constrained by biologically plausible synaptic scaling.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>Our results reveal a close connection between feedforward inhibition and synaptic scaling, which could be important for cortical processing. We have shown that an elementary neural circuit with lateral inhibition, Hebbian plasticity and synaptic scaling can approximate optimal learning for normalized inputs. Furthermore, although our analysis demonstrates the approximate equivalence between learning in the neural circuit and the optimal theoretical solution only when inputs are generated by normalized mixture distributions with Poisson noise, numerical simulations using realistic data show that close to optimal learning is possible even when the inputs do not match these model assumptions exactly. Importantly, optimal learning is an outcome of a synergistic interaction between input and weight normalization, and learning is much less effective in absence of any of the two.</p>
      <p>The mechanisms required for optimal learning in our model circuit have close correspondents in biology. First, the type of input normalization used in our model has been observed in both hippocampus and the cortex <xref ref-type="bibr" rid="pcbi.1002432-Pouille2">[11]</xref>. It involves a population of fast-spiking inhibitory neurons that deliver relatively homogeneous inhibition to the pyramidal cells. For a more detailed map of our model onto this circuit, we assume, in first instance, that the normalized version of the stimulus is explicitly represented in one layer, which then projects onto the processing layer. Alternatively, it is imaginable that the normalized stimuli could only be available in implicit form, without the need for an additional input layer; this would, however, require some corrections to the Hebbian learning rule, since the presynaptic term would depend on the input scale in this case. Second, learning in the circuit takes a simple local form, which has natural biological correspondents. In particular, for the linear approximation for synaptic currents, learning involves simple Hebbian plasticity and multiplicative synaptic scaling. The map to biology is somewhat more difficult for the model with logarithmic saturation of synaptic efficacies. This would translate in an unconventional type of weight-dependent Hebbian learning, and more complex additive synaptic scaling. Although there is some data on weight-dependent correlation learning <xref ref-type="bibr" rid="pcbi.1002432-Watt1">[45]</xref> and additive synaptic scaling has been reported in some systems <xref ref-type="bibr" rid="pcbi.1002432-Echegoyen1">[46]</xref>, the experimental evidence clearly favors the linear approximation for synaptic currents. The logarithmic version is nonetheless important, as the closest approximation to the optimal solution with bounded excitatory input currents. Moreover, it enables us to quantify the effect of the approximations in the linear model and hence to explain the difference in performance of the neural circuit relative to the theoretical optimal solution. Lastly, optimal learning requires a lateral interactions between the processing neurons, mathematically described by the softmax function. Due to its importance for competitive learning, different circuit models giving rise to softmax or softmax-like competition have been investigated previously <xref ref-type="bibr" rid="pcbi.1002432-Yuille1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Yuille2">[32]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Kwok1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Liu1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Mao1">[37]</xref>, typically involving lateral inhibitory networks with uniform connectivity onto the excitatory population. Experimentally, evidence for such lateral inhibition has recently been reported, for instance, in primary sensory cortex, where feedback inhibition relies on broadly tuned interneurons, that integrate information from pyramidal cells with diverse stimulus preference <xref ref-type="bibr" rid="pcbi.1002432-Hofer1">[47]</xref>, confirming earlier anatomical observations (see <xref ref-type="bibr" rid="pcbi.1002432-Douglas1">[48]</xref> for an overview).</p>
      <p>We have seen that the normalization constant plays an important role during learning, as it controls the sharpness of the posterior distribution which in turn influences the frequency to converge to locally vs. globally optimal solutions. Learning outcomes can be improved by annealing this parameter throughout learning. Biologically, several neuromodulators are known to affect the response properties of inhibitory neurons <xref ref-type="bibr" rid="pcbi.1002432-Bacci1">[49]</xref> in a way that would effectively change the normalization constant. Alternatively, the modulation of background noise can affect neuronal gain in cortical neurons <xref ref-type="bibr" rid="pcbi.1002432-Chance1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Shu1">[15]</xref>, which, in the model, has similar effects (since both change input contrast). It is tempting to speculate that the effectiveness of learning can be manipulated by systematic changes in background current or in the concentration of neuromodulators, such as acetylcholine, dopamine or noradrenaline <xref ref-type="bibr" rid="pcbi.1002432-Bacci1">[49]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Kuo1">[50]</xref>. This would suggest that experimentally manipulating the concentration of these substances in the cortex should have predictable effects on learning efficiency, although these may be difficult to dissociate from other effects of such manipulations on arousal or attention <xref ref-type="bibr" rid="pcbi.1002432-Klinkenberg1">[51]</xref>.</p>
      <p>Activity normalization is ubiquitous in the cortex. In particular, divisive normalization – when a neuron's response is rescaled as function of that of its neighbors – has been reported for a variety of sensory systems, from visual <xref ref-type="bibr" rid="pcbi.1002432-Heeger1">[52]</xref>–<xref ref-type="bibr" rid="pcbi.1002432-Rust1">[54]</xref>, to auditory <xref ref-type="bibr" rid="pcbi.1002432-Schwartz1">[55]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Rabinowitz1">[56]</xref> or olfactory <xref ref-type="bibr" rid="pcbi.1002432-Olsen2">[57]</xref>. Correspondingly, a range of functions have been attributed to such normalization. It could optimize the representation of visual inputs in primary sensory areas <xref ref-type="bibr" rid="pcbi.1002432-Schwartz2">[58]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Ringach1">[59]</xref>, facilitate the decoding of information from probabilistic population codes <xref ref-type="bibr" rid="pcbi.1002432-Deneve1">[60]</xref>, explain attentional modulation of neural responses <xref ref-type="bibr" rid="pcbi.1002432-Reynolds1">[61]</xref>, or implement multi sensory cue integration <xref ref-type="bibr" rid="pcbi.1002432-Ohshiro1">[62]</xref>. While the form of normalization considered here is not equivalent to standard models of divisive normalization (which typically assume an L2 norm) and seems to have different neural substrates <xref ref-type="bibr" rid="pcbi.1002432-Finn1">[63]</xref>, several interesting parallels can be drawn with these models. In particular, we can view feedforward inhibition as a way to constrain the space of representations, similar to <xref ref-type="bibr" rid="pcbi.1002432-Ringach1">[59]</xref>. However, instead of asking how normalization affects the information that can be encoded in the population as a whole, we investigate how activity normalization constrains learning in neurons receiving it as inputs.</p>
      <p>The simple, biologically plausible neural circuit proposed here achieves robust, close to optimal unsupervised learning through the interaction between feedforward inhibition and synaptic scaling. Moreover, the two are mirror processes, which need to work together for Hebbian learning to yield efficient representations of the inputs to the network. Since the type of neural mechanisms involved in our model can be found throughout the cortex, it is tempting to suggest that the interaction between feedforward inhibition and synaptic scaling could be a general strategy for efficient learning in the brain.</p>
    </sec>
    <sec id="s4" sec-type="methods">
      <title>Methods</title>
      <sec id="s4a">
        <title>Evolution of weights – details</title>
        <p>Learning in the neural circuit consists of iterative applications of Eq. 1 and Eq. 3 to normalized input data <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e153" xlink:type="simple"/></inline-formula>, which is drawn identically and independently from a stationary distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e154" xlink:type="simple"/></inline-formula>. To facilitate numerical analysis, we assume that learning uses a finite dataset of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e155" xlink:type="simple"/></inline-formula> stimuli, presented repeatedly to the network in random order. In the limit of large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e156" xlink:type="simple"/></inline-formula>, this procedure becomes equal to drawing a new sample from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e157" xlink:type="simple"/></inline-formula> each time.</p>
        <p>For the learning dynamics Eqs. 1 to 3 we can show that the synaptic weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e158" xlink:type="simple"/></inline-formula> approximately satisfy Eq. 5 at convergence. The approximation holds for small learning rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e159" xlink:type="simple"/></inline-formula> and large numbers of inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e160" xlink:type="simple"/></inline-formula>. Large learning rates would bias learning towards recent inputs. A small dataset would introduce a large sample bias such that averages across the dataset would be significantly different from expectation values w.r.t. the distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e161" xlink:type="simple"/></inline-formula> in Eq. 5. For the derivation nested terms scaling with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e162" xlink:type="simple"/></inline-formula> and applied <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e163" xlink:type="simple"/></inline-formula> times have to be considered, which requires a series of rather technical approximations. We, therefore, present the essential steps here and provide the details as supplemental information (<xref ref-type="supplementary-material" rid="pcbi.1002432.s001">Text S1</xref>).</p>
        <p>For the derivation, we consider learning after convergence, i.e., after the changes of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e164" xlink:type="simple"/></inline-formula> have reduced to changes introduced by random fluctuations due to online updates. For small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e165" xlink:type="simple"/></inline-formula> these fluctuations are small. Let us denote by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e166" xlink:type="simple"/></inline-formula> an iteration step after which only such small fluctuations take place. After iteration <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e167" xlink:type="simple"/></inline-formula> we can assume the weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e168" xlink:type="simple"/></inline-formula> to have evolved to satisfy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e169" xlink:type="simple"/></inline-formula> for all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e170" xlink:type="simple"/></inline-formula> (which follows from Eq. 4). For small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e171" xlink:type="simple"/></inline-formula> the learning dynamics (1) to (3) is approximated by changing the weights according to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e172" xlink:type="simple"/></inline-formula> followed by an explicit normalization to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e173" xlink:type="simple"/></inline-formula>. More compactly, we can write:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e174" xlink:type="simple"/><label>(13)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e175" xlink:type="simple"/></inline-formula> denotes the weights at the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e176" xlink:type="simple"/></inline-formula>th iteration of learning, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e177" xlink:type="simple"/></inline-formula>.</p>
        <p>We now consider another <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e178" xlink:type="simple"/></inline-formula> learning steps after iteration <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e179" xlink:type="simple"/></inline-formula>, i.e., we iterate through the inputs once again after learning has converged. By applying the learning rule (13) iteratively <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e180" xlink:type="simple"/></inline-formula> times, the weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e181" xlink:type="simple"/></inline-formula> are given by (see <xref ref-type="supplementary-material" rid="pcbi.1002432.s001">Text S1</xref>):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e182" xlink:type="simple"/><label>(14)</label></disp-formula>The right-hand-side can now be simplified using a sequence of approximations, all of which are based on assuming a small but finite learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e183" xlink:type="simple"/></inline-formula> and a large number of inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e184" xlink:type="simple"/></inline-formula>. Below we present the main intermediate steps of the derivation and list the approximation used for each step:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e185" xlink:type="simple"/><label>(15)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e186" xlink:type="simple"/><label>(16)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e187" xlink:type="simple"/><label>(17)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e188" xlink:type="simple"/></inline-formula> (note that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e189" xlink:type="simple"/></inline-formula> is the mean of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e190" xlink:type="simple"/></inline-formula> over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e191" xlink:type="simple"/></inline-formula> iterations starting at iteration <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e192" xlink:type="simple"/></inline-formula>).</p>
        <p>For the first step (15) we rewrote the products in Eq. 14 and used a Taylor expansion (see <xref ref-type="supplementary-material" rid="pcbi.1002432.s001">Text S1</xref>):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e193" xlink:type="simple"/><label>(18)</label></disp-formula></p>
        <p>For the second step (16) we approximated the sum over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e194" xlink:type="simple"/></inline-formula> in (15) by observing that the terms with large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e195" xlink:type="simple"/></inline-formula> are negligible, and by approximating sums of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e196" xlink:type="simple"/></inline-formula> over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e197" xlink:type="simple"/></inline-formula> by the mean <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e198" xlink:type="simple"/></inline-formula> (see <xref ref-type="supplementary-material" rid="pcbi.1002432.s001">Text S1</xref>). For the last steps, Eq. 17, we used the geometric series and approximated for large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e199" xlink:type="simple"/></inline-formula> (see <xref ref-type="supplementary-material" rid="pcbi.1002432.s001">Text S1</xref>). Furthermore, we used the fact that for small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e200" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e201" xlink:type="simple"/></inline-formula> (which can be seen, e.g., by applying l'Hôpital's rule). Finally, we back-inserted the definition of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e202" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e203" xlink:type="simple"/></inline-formula>.</p>
        <p>By inserting the definition of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e204" xlink:type="simple"/></inline-formula> into (17) and by applying the assumption that the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e205" xlink:type="simple"/></inline-formula> are drawn from a stationary distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e206" xlink:type="simple"/></inline-formula>, it follows that:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e207" xlink:type="simple"/><label>(19)</label></disp-formula>yielding the final expression:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e208" xlink:type="simple"/><label>(20)</label></disp-formula>For Eq. 19 we used the initial assumption that the weights have converged, i.e., that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e209" xlink:type="simple"/></inline-formula> remains approximately unchanged after <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e210" xlink:type="simple"/></inline-formula>. If the same assumption is applied to Eq. 20, we obtain Eq. 5.</p>
        <p>Note that although we have applied a number of different approximations during this derivation (compare <xref ref-type="bibr" rid="pcbi.1002432-Lcke1">[64]</xref> for proof sketches of some of them), each approximation is individually very accurate for small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e211" xlink:type="simple"/></inline-formula> and large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e212" xlink:type="simple"/></inline-formula>. Eq. 5 can thus be expected to be satisfied with high accuracy in this case; subsequent numerical simulations for a specific choice of the transfer function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e213" xlink:type="simple"/></inline-formula> confirm such high accuracies.</p>
      </sec>
      <sec id="s4b">
        <title>Derivation of the EM update rules</title>
        <p>Given a set of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e214" xlink:type="simple"/></inline-formula> inputs drawn from an input distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e215" xlink:type="simple"/></inline-formula>, optimal generative model parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e216" xlink:type="simple"/></inline-formula> can be found by optimizing the likelihood: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e217" xlink:type="simple"/></inline-formula>. A frequently used approach to find optimal parameters is expectation maximization (EM) <xref ref-type="bibr" rid="pcbi.1002432-Dempster1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Neal1">[25]</xref>. Instead of maximizing the likelihood directly, EM maximizes a lower-bound of the log-likelihood, the free-energy:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e218" xlink:type="simple"/><label>(21)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e219" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e220" xlink:type="simple"/></inline-formula> are the newly computed and previous parameters of the generative model, respectively, and where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e221" xlink:type="simple"/></inline-formula> is an entropy term only depending on the previous parameters. To optimize the free-energy, EM alternates between two steps – the E-step and the M-step. First, in the E-step, the parameters are assumed fixed at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e222" xlink:type="simple"/></inline-formula> and the posterior <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e223" xlink:type="simple"/></inline-formula> is computed for all data points <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e224" xlink:type="simple"/></inline-formula>. Second, in the M-step, the model parameters are updated using these posterior values. Note that for more general models, computations of expectation values w.r.t. the posteriors are considered part of the E-step. For mixture models such expectations are tractable operations, and we, therefore, often use E-step and computation of the posterior synonymously.</p>
        <p>M-step solutions can be found by setting the derivative of the free-energy w.r.t. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e225" xlink:type="simple"/></inline-formula> to zero. Applied to the concrete model of normalized input given by the mixture model (Eq. 6), we have to optimize the free-energy under the constrained of normalized weights: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e226" xlink:type="simple"/></inline-formula>. We can satisfy the constraint by using Lagrange multipliers for the derivatives and obtain:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e227" xlink:type="simple"/></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e228" xlink:type="simple"/></disp-formula>Expanding the expression for the free energy and computing the partial derivatives gives (all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e229" xlink:type="simple"/></inline-formula> drop out):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e230" xlink:type="simple"/></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e231" xlink:type="simple"/></disp-formula>Taking the sum over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e232" xlink:type="simple"/></inline-formula> and applying the constraint <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e233" xlink:type="simple"/></inline-formula>, we can rewrite the above expression as:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e234" xlink:type="simple"/></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e235" xlink:type="simple"/></disp-formula></p>
        <p>Inserting the value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e236" xlink:type="simple"/></inline-formula> computed above and solving for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e237" xlink:type="simple"/></inline-formula> yields:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e238" xlink:type="simple"/><label>(22)</label></disp-formula>For the normalized mixture model (Eq. 6 and Eq. 7), the posterior probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e239" xlink:type="simple"/></inline-formula> can be computed directly. By inserting the Poisson noise model and constant priors, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e240" xlink:type="simple"/></inline-formula>, and by using the constraint on the weights, the posterior can be simplified as follows:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e241" xlink:type="simple"/><label>(23)</label></disp-formula>Note that the specific combination of normalization constraint and Poisson noise results in the final compact form of the posterior. The E-step consists of computing these posteriors for all inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e242" xlink:type="simple"/></inline-formula></p>
        <p>To summarize, putting together  22 and 23, E- and M-step for our model of normalized data are given by:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e243" xlink:type="simple"/><label>(24)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e244" xlink:type="simple"/><label>(25)</label></disp-formula></p>
        <sec id="s4b1">
          <title>Update rules for unconstrained learning</title>
          <p>In order to investigate the effects of feedfoward inhibition on learning, we need to derive the optimal learning rules for a mixture model that does not assume normalized generative fields. The derivation is very similar to the one above and more conventional because no Lagrange multipliers are required for enforcing the normalization constraint. The E- and M-step equations for the unconstrained case are given by:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e245" xlink:type="simple"/><label>(26)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e246" xlink:type="simple"/><label>(27)</label></disp-formula>Note that enforcing the weight normalization <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e247" xlink:type="simple"/></inline-formula> in the above expression recovers the expression for the constrained EM before.</p>
        </sec>
      </sec>
      <sec id="s4c">
        <title>Linearization of input integration - details</title>
        <p>To further simplify the computation of the posterior in Eq. 8, first note that due to normalized input, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e248" xlink:type="simple"/></inline-formula>, the posterior computations remain unchanged for any offset value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e249" xlink:type="simple"/></inline-formula> for the weights:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e250" xlink:type="simple"/><label>(28)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e251" xlink:type="simple"/><label>(29)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e252" xlink:type="simple"/><label>(30)</label></disp-formula>If we use an offset of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e253" xlink:type="simple"/></inline-formula> we can approximate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e254" xlink:type="simple"/></inline-formula> by applying a Taylor expansion around <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e255" xlink:type="simple"/></inline-formula>. If we use the linear approximation for values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e256" xlink:type="simple"/></inline-formula> only, we obtain the function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e257" xlink:type="simple"/></inline-formula> in Eq. 12. For data with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e258" xlink:type="simple"/></inline-formula> as enforced by Eq. 11, the weights will converge to values greater or approximately equal to one, which makes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e259" xlink:type="simple"/></inline-formula> to a very accurate approximation. If we use the linear approximation for all values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e260" xlink:type="simple"/></inline-formula>, we obtain the conventional linear summation in Eq. 12.</p>
      </sec>
      <sec id="s4d">
        <title>Higher level processing – details for classification</title>
        <p>In order to use the representation of pattern classes in the first processing layer for classification, we consider the hierarchical generative model in <xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4A</xref>. The model assumes the patterns to be generated by the following process: First, choose a pattern type <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e261" xlink:type="simple"/></inline-formula> (e.g., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e262" xlink:type="simple"/></inline-formula> for ten digit types), second, given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e263" xlink:type="simple"/></inline-formula> choose a pattern class <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e264" xlink:type="simple"/></inline-formula> (e.g., different writing styles), and, third, given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e265" xlink:type="simple"/></inline-formula> generate the actual pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e266" xlink:type="simple"/></inline-formula> (with added noise). For the generation of pattern types <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e267" xlink:type="simple"/></inline-formula> we assume flat priors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e268" xlink:type="simple"/></inline-formula>, i.e., we assume that each type is equally likely.</p>
        <p>Under the assumption that the data is generated by the model, optimal inference is given by computing the posterior <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e269" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e270" xlink:type="simple"/></inline-formula> are the parameters of the model. By using the form of the graphical model in <xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4A</xref>, we obtain:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e271" xlink:type="simple"/><label>(31)</label></disp-formula></p>
        <p>The probabilities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e272" xlink:type="simple"/></inline-formula> are given in Eq. 6 (right-hand-side). To estimate the probabilities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e273" xlink:type="simple"/></inline-formula> let us first define the sets <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e274" xlink:type="simple"/></inline-formula> and let us assume these sets to be disjoint (no overlap). In this case we obtain:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e275" xlink:type="simple"/><label>(32)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e276" xlink:type="simple"/><label>(33)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e277" xlink:type="simple"/><label>(34)</label></disp-formula>Together with Eq. 31, the estimate for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e278" xlink:type="simple"/></inline-formula> allows for a convenient way to approximate the posterior <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e279" xlink:type="simple"/></inline-formula> using input labels:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e280" xlink:type="simple"/><label>(35)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e281" xlink:type="simple"/><label>(36)</label></disp-formula></p>
        <p>That is, we can compute the values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e282" xlink:type="simple"/></inline-formula> using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e283" xlink:type="simple"/></inline-formula> labeled inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e284" xlink:type="simple"/></inline-formula> for each type <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e285" xlink:type="simple"/></inline-formula>. Having computed all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e286" xlink:type="simple"/></inline-formula>, the approximate posterior given an unlabeled input is given by Eq. 36. Few labeled inputs can be sufficient to get good estimates for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e287" xlink:type="simple"/></inline-formula> and thus for the posterior computation (compare <xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4B</xref>). Note that Eqs. 35 and 36 can only be regarded as approximations for optimal classification because of the assumptions made. However, they serve in providing good classification results (see Results), the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e288" xlink:type="simple"/></inline-formula> can conveniently be computed after unsupervised learning, and, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e289" xlink:type="simple"/></inline-formula> can be interpreted as weights in a neural processing context.</p>
        <p>After unsupervised learning and computation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e290" xlink:type="simple"/></inline-formula> using Eq. 35, an input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e291" xlink:type="simple"/></inline-formula> is assigned to the digit type <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e292" xlink:type="simple"/></inline-formula> with highest posterior using Eq. 36. If the assigned type matches the true label of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e293" xlink:type="simple"/></inline-formula>, the input is correctly classified. Note, in this context, that our approach would also allow for a quantification of the classifications' reliabilities by comparing the different values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e294" xlink:type="simple"/></inline-formula>.</p>
        <p>Finally, note that the setting of few labeled inputs among many unlabeled ones is typical for semi-supervised learning. Algorithms for semi-supervised learning usually take labeled and unlabeled data into account simultaneously. As we focus on unsupervised learning and use the labels for a second stage of classification, we avoided to refer to our approach as semi-supervised.</p>
      </sec>
      <sec id="s4e">
        <title>Simulation details</title>
        <p>For all simulations we initialize the weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e295" xlink:type="simple"/></inline-formula> with the mean pixel intensity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e296" xlink:type="simple"/></inline-formula> averaged over all data points, with some additive uniform noise:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e297" xlink:type="simple"/><label>(37)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e298" xlink:type="simple"/><label>(38)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e299" xlink:type="simple"/><label>(39)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e300" xlink:type="simple"/></inline-formula> is the uniform distribution in the range <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e301" xlink:type="simple"/></inline-formula>.</p>
        <sec id="s4e1">
          <title>Artificial data</title>
          <p>We generate a dataset of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e302" xlink:type="simple"/></inline-formula> images using our mixture model. The generating parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e303" xlink:type="simple"/></inline-formula> (Eqs. 6 and 7) used are of the type as shown in <xref ref-type="fig" rid="pcbi-1002432-g002">Fig. 2A</xref>, normalized with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e304" xlink:type="simple"/></inline-formula>. More specifically, the data generating process involves first choosing a class <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e305" xlink:type="simple"/></inline-formula> from the prior, and then applying Poisson noise to the corresponding generative field <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e306" xlink:type="simple"/></inline-formula>. We randomly create a new set of parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e307" xlink:type="simple"/></inline-formula> for each trial, each consisting of 4 fields with block sizes varying in the interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e308" xlink:type="simple"/></inline-formula> pixels, constrained such that the degree of overlap between any two blocks is in between 1 to 50%. The resulting dataset is repeatedly presented to the neural circuit, with the order of the data points permuted for each block. Learning in the neural circuit proceeds according to Eq. 3, with the learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e309" xlink:type="simple"/></inline-formula>. For the corresponding EM learning the same parameters and the same data is used.</p>
        </sec>
        <sec id="s4e2">
          <title>Realistic data</title>
          <p>For the numerical experiments shown in <xref ref-type="fig" rid="pcbi-1002432-g003">Fig. 3</xref>, we used <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e310" xlink:type="simple"/></inline-formula> data points of the digits ‘0’ to ‘3’. These data points are subsamples of the MNIST data set to guarantee equal representation of each digit (note that for the numerical experiments in the section ‘Higher level processing’ we do not use subsampling). We normalized the resulting dataset using Eq. 2. Note that this ensures that each input is normalized exactly while each of the artificial inputs used before was normalized approximately. Another distinction is that the new input images no longer have background noise. For the MNIST data we used with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e311" xlink:type="simple"/></inline-formula> a larger normalization constant than for the artificial data, which is needed due to the higher input dimensionality (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e312" xlink:type="simple"/></inline-formula>). Learning proceeds in the same way as for the artificial data before; the learning rate of both neural circuit models (the log case and the linear case) is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e313" xlink:type="simple"/></inline-formula>, chosen such that the number of iterations needed to converge is roughly the same as the number of EM iterations. For the overcomplete setting shown in <xref ref-type="fig" rid="pcbi-1002432-g003">Fig. 3D</xref>, we ran the experiment with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e314" xlink:type="simple"/></inline-formula> neurons in the processing layer; all other parameters were the same as before.</p>
        </sec>
        <sec id="s4e3">
          <title>Learning and higher processing on the full MNIST dataset</title>
          <p>Since we want to estimate the best possible result for MNIST digits classification, we apply annealing while learning the generative fields. For computational reasons, we can only use the EM algorithm for these results because EM can be executed on arrays of linear processors much more efficiently: the batch of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e315" xlink:type="simple"/></inline-formula> data points can be subdivided into smaller batches and distributed to the array of processors. The number of processors can be chosen such that each small batch can be stored in memory (we used up to 360 processing cores for the MNIST data). The E-step can then be executed in parallel, the results are collected, and the parameters are subsequently updated once per iteration across the batch. While neurally plausible, the online learning of the neural circuit requires an update of the parameters once per input. The parallelization approach for EM is therefore not applicable and learning with hundreds of processing neurons becomes impractically slow. Note, however, that with inherently parallel hardware such as VLSI or FPGA, neural learning could be made very efficient, but the application of such technologies would go beyond the scope of this paper. The neural circuit learning is thus only used with a limited number of neurons (<xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4B, C</xref>).</p>
          <p>For the results shown in <xref ref-type="fig" rid="pcbi-1002432-g004">Fig. 4D, E, F</xref> we started the EM algorithm with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e316" xlink:type="simple"/></inline-formula> and linearly increase it over 80 EM steps to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e317" xlink:type="simple"/></inline-formula>. When estimating the classification performance on the MNIST test set, training uses the full MNIST training set, in which the samples are not exactly distributed equally among the digits. In contrast to the numerical experiments with data points from digits ‘0’ to ‘3’ (<xref ref-type="fig" rid="pcbi-1002432-g003">Fig. 3</xref>), we do not subsample the MNIST learning set. Applying subsampling would mean to use indirectly the knowledge of the labels of the data points. Since we apply pure unsupervised learning, we did not want to use this knowledge. The actual performance estimate uses the MNIST test set <xref ref-type="bibr" rid="pcbi.1002432-LeCun1">[40]</xref>. Given an input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e318" xlink:type="simple"/></inline-formula> of the test set, we determine the digit type according to Eqs. 35 and 36.</p>
        </sec>
        <sec id="s4e4">
          <title>Comparison with other methods on MNIST classification</title>
          <p>More than a decade of research on MNIST data classification has generated a large body of literature. However, basically all reported approaches are fully supervised (see <xref ref-type="bibr" rid="pcbi.1002432-LeCun1">[40]</xref>), i.e., they are using all labels. Many approaches, furthermore, use a larger training set by extending the MNIST training set with adding transformed versions of its inputs. On the original MNIST data, and thus on the same data as used for our systems, deep belief networks (DBN; <xref ref-type="bibr" rid="pcbi.1002432-Hinton1">[42]</xref>) achieve <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e319" xlink:type="simple"/></inline-formula> by using all labels. For extended training sets or with systems using build-in transformation invariance <xref ref-type="bibr" rid="pcbi.1002432-Ranzato1">[43]</xref>, <xref ref-type="bibr" rid="pcbi.1002432-Bruna1">[44]</xref> still higher classification rates can be achieved (above <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e320" xlink:type="simple"/></inline-formula>). For a baseline comparison with our results, we ran a k-Nearest-Neighbor (k-NN) algorithm; we used the L3 norm for k-NN, since this is known to yields slightly better performance on MNIST compared to the more traditional L2 norm <xref ref-type="bibr" rid="pcbi.1002432-LeCun1">[40]</xref>. While such a classifier is very close to the state-of-the-art on extended MNIST training sets (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e321" xlink:type="simple"/></inline-formula>, see <xref ref-type="bibr" rid="pcbi.1002432-LeCun1">[40]</xref>) and on the original training set (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e322" xlink:type="simple"/></inline-formula>), our approach results in a better performance for few labeled inputs. E.g., if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e323" xlink:type="simple"/></inline-formula> of the labels are used, we obtained <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e324" xlink:type="simple"/></inline-formula> while the k-NN approaches achieved <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e325" xlink:type="simple"/></inline-formula>. For still fewer labels the performance difference gets still more pronounced. On <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e326" xlink:type="simple"/></inline-formula> of the labels, the k-NN algorithm achieved just <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e327" xlink:type="simple"/></inline-formula> while our approach resulted in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e328" xlink:type="simple"/></inline-formula> correct classifications. These results show a clear benefit of learning an unsupervised representation as provided by our approach, while fully supervised approaches such as k-NN algorithms can not make use of unlabeled data.</p>
        </sec>
        <sec id="s4e5">
          <title>Unconstrained learning and unconstrained inputs</title>
          <p>In the case of unconstrained EM, we use the original MNIST data (globally rescaled by a factor 1/255 to avoid numerical problems), with no input normalization. For the neural network results, artificial data is generated using the same blocks model as before, but without individually normalizing the generative fields. In the absence of input normalization, the contrast of the images remains unspecified; multiplying all inputs by an arbitrary constant does not affect the original model but can have serious consequences for learning on unconstrained data (intuitively, this scaling factor translates into an arbitrary change in learning rate, which is bound to affect learning). Hence, to facilitate the comparison between different models we globally rescale the generating fields to have the same mean intensity (averaged over all fields), while allowing different inputs to have different mean intensities (see <xref ref-type="fig" rid="pcbi-1002432-g005">Fig. 5A,B</xref>), using A = 200. Since the overall mean is preserved, any difference between the normalized and un-normalized data is not due to some overall scaling, but rather to constraining the space spanned by the data.</p>
          <p>Learning with either constrained or unconstrained EM or the (linear) neural network proceeds as before, the difference being that either the normalized or the unnormalized data is used as input (learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e329" xlink:type="simple"/></inline-formula> as before). Additionally, we use a variation of the linear neural circuit in which synapses change by simple Hebbian learning, followed by an explicit weight normalization, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e330" xlink:type="simple"/></inline-formula>. This version ensures that the synaptic weights are still normalized to the constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e331" xlink:type="simple"/></inline-formula> when the inputs are unconstrained. We use again <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002432.e332" xlink:type="simple"/></inline-formula> data points for training in all cases.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pcbi.1002432.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002432.s001" xlink:type="simple">
        <label>Text S1</label>
        <caption>
          <p>Evolution of weights – details of derivations and approximations.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>We would like to thank Sina Tootoonian, Abdul-Saboor Sheikh and Philip Sterne for feedback on earlier versions of the manuscript.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002432-Baccus1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Baccus</surname><given-names>SA</given-names></name><name name-style="western"><surname>Meister</surname><given-names>M</given-names></name></person-group>             <year>2002</year>             <article-title>Fast and slow contrast adaptation in retinal circuitry.</article-title>             <source>Neuron</source>             <volume>36</volume>             <fpage>909</fpage>             <lpage>919</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Sclar1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sclar</surname><given-names>G</given-names></name><name name-style="western"><surname>Maunsell</surname><given-names>JH</given-names></name><name name-style="western"><surname>Lennie</surname><given-names>P</given-names></name></person-group>             <year>1990</year>             <article-title>Coding of image contrast in central visual pathways of the macaque monkey.</article-title>             <source>Vision Res</source>             <volume>30</volume>             <fpage>1</fpage>             <lpage>10</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Mante1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mante</surname><given-names>V</given-names></name><name name-style="western"><surname>Frazor</surname><given-names>RA</given-names></name><name name-style="western"><surname>Bonin</surname><given-names>V</given-names></name><name name-style="western"><surname>Geisler</surname><given-names>WS</given-names></name><name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name></person-group>             <year>2005</year>             <article-title>Independence of luminance and contrast in natural scenes and in the early visual system.</article-title>             <source>Nat Neurosci</source>             <volume>8</volume>             <fpage>1690</fpage>             <lpage>1697</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Stopfer1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stopfer</surname><given-names>M</given-names></name><name name-style="western"><surname>Jayaraman</surname><given-names>V</given-names></name><name name-style="western"><surname>Laurent</surname><given-names>G</given-names></name></person-group>             <year>2003</year>             <article-title>Intensity versus identity coding in an olfactory system.</article-title>             <source>Neuron</source>             <volume>39</volume>             <fpage>991</fpage>             <lpage>1004</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Assisi1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Assisi</surname><given-names>C</given-names></name><name name-style="western"><surname>Stopfer</surname><given-names>M</given-names></name><name name-style="western"><surname>Laurent</surname><given-names>G</given-names></name><name name-style="western"><surname>Bazhenov</surname><given-names>M</given-names></name></person-group>             <year>2007</year>             <article-title>Adaptive regulation of sparseness by feedforward inhibition.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <fpage>1176</fpage>             <lpage>1184</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Olsen1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Olsen</surname><given-names>SR</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>RI</given-names></name></person-group>             <year>2008</year>             <article-title>Lateral presynaptic inhibition mediates gain control in an olfactory circuit.</article-title>             <source>Nature</source>             <volume>452</volume>             <fpage>956</fpage>             <lpage>960</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Swadlow1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Swadlow</surname><given-names>HA</given-names></name></person-group>             <year>2003</year>             <article-title>Fast-spike interneurons and feedforward inhibition in awake sensory neocortex.</article-title>             <source>Cereb Cortex</source>             <volume>13</volume>             <fpage>25</fpage>             <lpage>32</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Pouille1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pouille</surname><given-names>F</given-names></name><name name-style="western"><surname>Scanziani</surname><given-names>M</given-names></name></person-group>             <year>2001</year>             <article-title>Enforcement of temporal fidelity in pyramidal cells by somatic feed-forward inhibition.</article-title>             <source>Science</source>             <volume>293</volume>             <fpage>1159</fpage>             <lpage>1163</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Mittmann1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mittmann</surname><given-names>W</given-names></name></person-group>             <year>2004</year>             <article-title>Feed-forward inhibition shapes the spike output of cerebellar Purkinje cells.</article-title>             <source>J Physiol</source>             <volume>563</volume>             <fpage>369</fpage>             <lpage>378</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Wehr1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wehr</surname><given-names>M</given-names></name><name name-style="western"><surname>Zador</surname><given-names>AM</given-names></name></person-group>             <year>2005</year>             <article-title>Synaptic mechanisms of forward suppression in rat auditory cortex.</article-title>             <source>Neuron</source>             <volume>47</volume>             <fpage>437</fpage>             <lpage>445</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Pouille2">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pouille</surname><given-names>F</given-names></name><name name-style="western"><surname>Marin-Burgin</surname><given-names>A</given-names></name><name name-style="western"><surname>Adesnik</surname><given-names>H</given-names></name><name name-style="western"><surname>Atallah</surname><given-names>BV</given-names></name><name name-style="western"><surname>Scanziani</surname><given-names>M</given-names></name></person-group>             <year>2009</year>             <article-title>Input normalization by global feedforward inhibition expands cortical dynamic range.</article-title>             <source>Nat Neurosci</source>             <volume>12</volume>             <fpage>1577</fpage>             <lpage>1585</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Isaacson1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Isaacson</surname><given-names>JS</given-names></name><name name-style="western"><surname>Scanziani</surname><given-names>M</given-names></name></person-group>             <year>2011</year>             <article-title>How Inhibition Shapes Cortical Activity.</article-title>             <source>Neuron</source>             <volume>72</volume>             <fpage>231</fpage>             <lpage>243</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Chance1">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chance</surname><given-names>FS</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name><name name-style="western"><surname>Reyes</surname><given-names>AD</given-names></name></person-group>             <year>2002</year>             <article-title>Gain modulation from background synaptic input.</article-title>             <source>Neuron</source>             <volume>35</volume>             <fpage>773</fpage>             <lpage>782</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Fellous1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fellous</surname><given-names>J</given-names></name><name name-style="western"><surname>Rudolph</surname><given-names>M</given-names></name><name name-style="western"><surname>Destexhe</surname><given-names>A</given-names></name></person-group>             <year>2003</year>             <article-title>Synaptic background noise controls the input/output characteristics of single cells in an in vitro model of in vivo activity.</article-title>             <source>Neuroscience</source>             <volume>122</volume>             <fpage>811</fpage>             <lpage>829</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Shu1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shu</surname><given-names>Y</given-names></name><name name-style="western"><surname>Hasenstaub</surname><given-names>A</given-names></name><name name-style="western"><surname>Badoual</surname><given-names>M</given-names></name><name name-style="western"><surname>Bal</surname><given-names>T</given-names></name><name name-style="western"><surname>McCormick</surname><given-names>DA</given-names></name></person-group>             <year>2003</year>             <article-title>Barrages of synaptic activity control the gain and sensitivity of cortical neurons.</article-title>             <source>J Neurosci</source>             <volume>23</volume>             <fpage>10388</fpage>             <lpage>10401</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Turrigiano1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Turrigiano</surname><given-names>GG</given-names></name><name name-style="western"><surname>Leslie</surname><given-names>KR</given-names></name><name name-style="western"><surname>Desai</surname><given-names>NS</given-names></name><name name-style="western"><surname>Rutherford</surname><given-names>LC</given-names></name><name name-style="western"><surname>Nelson</surname><given-names>SB</given-names></name></person-group>             <year>1998</year>             <article-title>Activity-dependent scaling of quantal amplitude in neocortical neurons.</article-title>             <source>Nature</source>             <volume>391</volume>             <fpage>892</fpage>             <lpage>896</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Leslie1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Leslie</surname><given-names>KR</given-names></name><name name-style="western"><surname>Nelson</surname><given-names>SB</given-names></name><name name-style="western"><surname>Turrigiano</surname><given-names>GG</given-names></name></person-group>             <year>2001</year>             <article-title>Postsynaptic depolarization scales quantal amplitude in cortical pyramidal neurons.</article-title>             <source>J Neurosci</source>             <volume>21</volume>             <fpage>1</fpage>             <lpage>6</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Turrigiano2">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Turrigiano</surname><given-names>GG</given-names></name><name name-style="western"><surname>Nelson</surname><given-names>SB</given-names></name></person-group>             <year>2004</year>             <article-title>Homeostatic plasticity in the developing nervous system.</article-title>             <source>Nat Rev Neurosci</source>             <volume>5</volume>             <fpage>97</fpage>             <lpage>107</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Turrigiano3">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Turrigiano</surname><given-names>GG</given-names></name></person-group>             <year>2008</year>             <article-title>The self-tuning neuron: synaptic scaling of excitatory synapses.</article-title>             <source>Cell</source>             <volume>135</volume>             <fpage>422</fpage>             <lpage>435</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Abbott1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name><name name-style="western"><surname>Nelson</surname><given-names>SB</given-names></name></person-group>             <year>2000</year>             <article-title>Synaptic plasticity: taming the beast.</article-title>             <source>Nat Neurosci</source>             <volume>3</volume>             <fpage>1178</fpage>             <lpage>1183</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Gerstner1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name><name name-style="western"><surname>Kistler</surname><given-names>WM</given-names></name></person-group>             <year>2002</year>             <article-title>Mathematical formulations of Hebbian learning.</article-title>             <source>Biol Cybern</source>             <volume>87</volume>             <fpage>404</fpage>             <lpage>415</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Marr1">
        <label>22</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Marr</surname><given-names>D</given-names></name></person-group>             <year>1982</year>             <source>Vision: A Computational Investigation into the Human Representation and Processing of Visual Information</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Henry Holt and Co</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Duda1">
        <label>23</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Duda</surname><given-names>RO</given-names></name><name name-style="western"><surname>Hart</surname><given-names>PE</given-names></name><name name-style="western"><surname>Stork</surname><given-names>DG</given-names></name></person-group>             <year>2001</year>             <article-title>Pattern Classification.</article-title>             <comment>Wiley-Interscience (2nd Edition)</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Dempster1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dempster</surname><given-names>AP</given-names></name><name name-style="western"><surname>Laird</surname><given-names>NM</given-names></name><name name-style="western"><surname>Rubin</surname><given-names>DB</given-names></name></person-group>             <year>1977</year>             <article-title>Maximum likelihood from incomplete data via the EM algorithm (with discussion).</article-title>             <source>J R Stat Soc Series B Stat Methodol</source>             <volume>39</volume>             <fpage>1</fpage>             <lpage>38</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Neal1">
        <label>25</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Neal</surname><given-names>R</given-names></name><name name-style="western"><surname>Hinton</surname><given-names>G</given-names></name></person-group>             <year>1998</year>             <article-title>A view of the EM algorithm that justifies incremental, sparse, and other variants.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name></person-group>             <source>Learning in Graphical Models</source>             <publisher-name>Kluwer Academic Publishers</publisher-name>             <fpage>355</fpage>             <lpage>368</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Yuille1">
        <label>26</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yuille</surname><given-names>AL</given-names></name><name name-style="western"><surname>Geiger</surname><given-names>D</given-names></name></person-group>             <year>2003</year>             <article-title>Winner-take-all networks.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Arbib</surname><given-names>M</given-names></name></person-group>             <source>The handbook of brain theory and neural networks</source>             <publisher-name>MIT Press</publisher-name>             <fpage>1228</fpage>             <lpage>1231</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Dayan1">
        <label>27</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name></person-group>             <year>2001</year>             <source>Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Rao1">
        <label>28</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="editor"><name name-style="western"><surname>Rao</surname><given-names>RPN</given-names></name><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name><name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name></person-group>             <year>2002</year>             <source>Probabilistic Models of the Brain: Perception and Neural Function. Neural Information Processing</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>The MIT Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Fiser1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fiser</surname><given-names>J</given-names></name><name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name><name name-style="western"><surname>Orbán</surname><given-names>G</given-names></name><name name-style="western"><surname>Lengyel</surname><given-names>M</given-names></name></person-group>             <year>2010</year>             <article-title>Statistically optimal perception and learning: from behavior to neural representations.</article-title>             <source>Trends Cogn Sci</source>             <volume>14</volume>             <fpage>119</fpage>             <lpage>130</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Berkes1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name><name name-style="western"><surname>Orban</surname><given-names>G</given-names></name><name name-style="western"><surname>Lengyel</surname><given-names>M</given-names></name><name name-style="western"><surname>Fiser</surname><given-names>J</given-names></name></person-group>             <year>2011</year>             <article-title>Spontaneous Cortical Activity Reveals Hallmarks of an Optimal Internal Model of the Environment.</article-title>             <source>Science</source>             <volume>331</volume>             <fpage>83</fpage>             <lpage>87</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Lochmann1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lochmann</surname><given-names>T</given-names></name><name name-style="western"><surname>Deneve</surname><given-names>S</given-names></name></person-group>             <year>2011</year>             <article-title>Neural processing as causal inference.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>21</volume>             <fpage>774</fpage>             <lpage>781</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Yuille2">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yuille</surname><given-names>AL</given-names></name><name name-style="western"><surname>Grzywacz</surname><given-names>NM</given-names></name></person-group>             <year>1989</year>             <article-title>A Winner-Take-All mechanism based on presynaptic inhibition feedback.</article-title>             <source>Neural Comput</source>             <volume>1</volume>             <fpage>334</fpage>             <lpage>347</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Elfadel1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Elfadel</surname><given-names>IM</given-names></name><name name-style="western"><surname>Wyatt</surname><given-names>JLJ</given-names></name></person-group>             <year>1994</year>             <article-title>The ‘softmax’ nonlinearity: Derivation using statistical mechanics and useful properties as a multiterminal analog circuit element.</article-title>             <source>Adv Neural Inf Process Syst</source>             <volume>6</volume>             <fpage>882</fpage>             <lpage>887</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Kwok1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kwok</surname><given-names>T</given-names></name><name name-style="western"><surname>Smith</surname><given-names>K</given-names></name></person-group>             <year>2005</year>             <article-title>Optimization via intermittency with a self-organizing neural network.</article-title>             <source>Neural Comput</source>             <volume>17</volume>             <fpage>2454</fpage>             <lpage>2481</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Fukai1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fukai</surname><given-names>T</given-names></name><name name-style="western"><surname>Tanaka</surname><given-names>S</given-names></name></person-group>             <year>1997</year>             <article-title>A simple neural network exhibiting selective activation of neuronal ensembles: from winner-take-all to winners-share-all.</article-title>             <source>Neural Comput</source>             <volume>9</volume>             <fpage>77</fpage>             <lpage>97</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Liu1">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>SC</given-names></name></person-group>             <year>1999</year>             <article-title>A winner-take-all circuit with controllable soft max property.</article-title>             <source>Adv Neural Inf Process Syst</source>             <volume>12</volume>             <fpage>717</fpage>             <lpage>723</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Mao1">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mao</surname><given-names>ZH</given-names></name><name name-style="western"><surname>Massaquoi</surname><given-names>SG</given-names></name></person-group>             <year>2007</year>             <article-title>Dynamics of winner-take-all competition in recurrent neural networks with lateral inhibition.</article-title>             <source>IEEE Trans Neural Netw</source>             <volume>18</volume>             <fpage>55</fpage>             <lpage>69</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Ueda1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ueda</surname><given-names>N</given-names></name><name name-style="western"><surname>Nakano</surname><given-names>R</given-names></name></person-group>             <year>1998</year>             <article-title>Deterministic annealing EM algorithm.</article-title>             <source>Neural Netw</source>             <volume>11</volume>             <fpage>271</fpage>             <lpage>282</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Sahani1">
        <label>39</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name></person-group>             <year>1999</year>             <article-title>Latent variable models for neural data analysis [Ph.D. thesis]. Pasadena (California): California Institute of Technology.</article-title>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://citeseer.ist.psu.edu/sahani99latent.html" xlink:type="simple">citeseer.ist.psu.edu/sahani99latent.html</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-LeCun1">
        <label>40</label>
        <element-citation publication-type="other" xlink:type="simple">             <article-title>LeCun Y (NEC).</article-title>             <comment>MNIST database of handwritten digits. Available: <ext-link ext-link-type="uri" xlink:href="http://yann.lecun.com/exdb/mnist/" xlink:type="simple">http://yann.lecun.com/exdb/mnist/</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-LeCun2">
        <label>41</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>LeCun</surname><given-names>Y</given-names></name><name name-style="western"><surname>Bottou</surname><given-names>L</given-names></name><name name-style="western"><surname>Bengio</surname><given-names>Y</given-names></name><name name-style="western"><surname>Haffner</surname><given-names>P</given-names></name></person-group>             <year>1998</year>             <article-title>Gradient-based learning applied to document recognition.</article-title>             <source>Proceedings of the IEEE</source>             <fpage>2278</fpage>             <lpage>2324</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Hinton1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hinton</surname><given-names>G</given-names></name><name name-style="western"><surname>Osindero</surname><given-names>S</given-names></name><name name-style="western"><surname>Teh</surname><given-names>Y</given-names></name></person-group>             <year>2006</year>             <article-title>A fast learning algorithm for deep belief nets.</article-title>             <source>Neural Comput</source>             <volume>18</volume>             <fpage>1527</fpage>             <lpage>1554</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Ranzato1">
        <label>43</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ranzato</surname><given-names>M</given-names></name><name name-style="western"><surname>Huang</surname><given-names>F</given-names></name><name name-style="western"><surname>Boureau</surname><given-names>Y</given-names></name><name name-style="western"><surname>LeCun</surname><given-names>Y</given-names></name></person-group>             <year>2007</year>             <article-title>Unsupervised learning of invariant feature hierarchies with applications to object recognition.</article-title>             <comment>In: 2007 IEEE Conference on Computer Vision and Pattern Recognition; 17–22 June 2007</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Bruna1">
        <label>44</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bruna</surname><given-names>J</given-names></name><name name-style="western"><surname>Mallat</surname><given-names>S</given-names></name></person-group>             <year>2010</year>             <article-title>Classification with scattering operators.</article-title>             <comment>Computing Research Repository abs/1011.3023</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Watt1">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Watt</surname><given-names>AJ</given-names></name><name name-style="western"><surname>von Rossum</surname><given-names>MCW</given-names></name><name name-style="western"><surname>MacLeod</surname><given-names>KM</given-names></name><name name-style="western"><surname>Nelson</surname><given-names>SB</given-names></name><name name-style="western"><surname>Turrigiano</surname><given-names>GG</given-names></name></person-group>             <year>2000</year>             <article-title>Activity co-regulates quantal AMPA and NMDA current at neocortical synapses.</article-title>             <source>Neuron</source>             <volume>23</volume>             <fpage>659</fpage>             <lpage>670</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Echegoyen1">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Echegoyen</surname><given-names>J</given-names></name><name name-style="western"><surname>Neu</surname><given-names>A</given-names></name><name name-style="western"><surname>Graber</surname><given-names>KD</given-names></name><name name-style="western"><surname>Soltesz</surname><given-names>I</given-names></name></person-group>             <year>2007</year>             <article-title>Homeostatic plasticity studied using in vivo hippocampal activity-blockade: synaptic scaling, intrinsic plasticity and age-dependence.</article-title>             <source>PLoS One</source>             <volume>2</volume>             <fpage>e700</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Hofer1">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hofer</surname><given-names>SB</given-names></name><name name-style="western"><surname>Ko</surname><given-names>H</given-names></name><name name-style="western"><surname>Pichler</surname><given-names>B</given-names></name><name name-style="western"><surname>Vogelstein</surname><given-names>J</given-names></name><name name-style="western"><surname>Ros</surname><given-names>H</given-names></name><etal/></person-group>             <year>2011</year>             <article-title>Differential connectivity and response dynamics of excitatory and inhibitory neurons in visual cortex.</article-title>             <source>Nat Neurosci</source>             <volume>14</volume>             <fpage>1045</fpage>             <lpage>1052</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Douglas1">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Douglas</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Martin</surname><given-names>KAC</given-names></name></person-group>             <year>2004</year>             <article-title>Neuronal circuits of the neocortex.</article-title>             <source>Annu Rev Neurosci</source>             <volume>27</volume>             <fpage>419</fpage>             <lpage>451</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Bacci1">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bacci</surname><given-names>A</given-names></name><name name-style="western"><surname>Huguenard</surname><given-names>J</given-names></name></person-group>             <year>2005</year>             <article-title>Modulation of neocortical interneurons: extrinsic inuences and exercises in self-control.</article-title>             <source>Trends Neurosci</source>             <volume>28</volume>             <fpage>602</fpage>             <lpage>610</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Kuo1">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kuo</surname><given-names>SP</given-names></name><name name-style="western"><surname>Trussell</surname><given-names>LO</given-names></name></person-group>             <year>2011</year>             <article-title>Spontaneous Spiking and Synaptic Depression Underlie Noradrenergic Control of Feed-Forward Inhibition.</article-title>             <source>Neuron</source>             <volume>71</volume>             <fpage>306</fpage>             <lpage>318</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Klinkenberg1">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Klinkenberg</surname><given-names>I</given-names></name><name name-style="western"><surname>Sambeth</surname><given-names>A</given-names></name><name name-style="western"><surname>Blokland</surname><given-names>A</given-names></name></person-group>             <year>2011</year>             <article-title>Acetylcholine and attention.</article-title>             <source>Behav Brain Res</source>             <volume>221</volume>             <fpage>430</fpage>             <lpage>442</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Heeger1">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name></person-group>             <year>1992</year>             <article-title>Normalization of cell responses in cat striate cortex.</article-title>             <source>Vis Neurosci</source>             <volume>9</volume>             <fpage>181</fpage>             <lpage>197</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Carandini1">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name><name name-style="western"><surname>Heeger</surname><given-names>D</given-names></name></person-group>             <year>1997</year>             <article-title>Linearity and normalization in simple cells of the macaque primary visual cortex.</article-title>             <source>J Neurosci</source>             <volume>17</volume>             <fpage>8621</fpage>             <lpage>8644</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Rust1">
        <label>54</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rust</surname><given-names>NC</given-names></name><name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name><name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group>             <year>2005</year>             <article-title>Spatiotemporal elements of macaque V1 receptive fields.</article-title>             <source>Neuron</source>             <volume>46</volume>             <fpage>945</fpage>             <lpage>956</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Schwartz1">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group>             <year>2000</year>             <article-title>Natural sound statistics and divisive normalization in the auditory system.</article-title>             <source>Adv Neural Inf Process Syst</source>             <fpage>166</fpage>             <lpage>172</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Rabinowitz1">
        <label>56</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rabinowitz</surname><given-names>NC</given-names></name><name name-style="western"><surname>Willmore</surname><given-names>BDB</given-names></name><name name-style="western"><surname>Schnupp</surname><given-names>JWH</given-names></name><name name-style="western"><surname>King</surname><given-names>AJ</given-names></name></person-group>             <year>2011</year>             <article-title>Contrast gain control in auditory cortex.</article-title>             <source>Neuron</source>             <volume>70</volume>             <fpage>1178</fpage>             <lpage>1191</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Olsen2">
        <label>57</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Olsen</surname><given-names>SR</given-names></name><name name-style="western"><surname>Bhandawat</surname><given-names>V</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>RI</given-names></name></person-group>             <year>2010</year>             <article-title>Divisive normalization in olfactory population codes.</article-title>             <source>Neuron</source>             <volume>66</volume>             <fpage>287</fpage>             <lpage>299</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Schwartz2">
        <label>58</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group>             <year>2001</year>             <article-title>Natural signal statistics and sensory gain control.</article-title>             <source>Nat Neurosci</source>             <volume>4</volume>             <fpage>819</fpage>             <lpage>825</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Ringach1">
        <label>59</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ringach</surname><given-names>DL</given-names></name></person-group>             <year>2010</year>             <article-title>Population coding under normalization.</article-title>             <source>Vision Res</source>             <volume>50</volume>             <fpage>2223</fpage>             <lpage>2232</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Deneve1">
        <label>60</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Deneve</surname><given-names>S</given-names></name><name name-style="western"><surname>Latham</surname><given-names>PE</given-names></name><name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name></person-group>             <year>1999</year>             <article-title>Reading population codes: a neural implementation of ideal observers.</article-title>             <source>Nat Neurosci</source>             <volume>2</volume>             <fpage>740</fpage>             <lpage>745</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Reynolds1">
        <label>61</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Reynolds</surname><given-names>JH</given-names></name><name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name></person-group>             <year>2009</year>             <article-title>The normalization model of attention.</article-title>             <source>Neuron</source>             <volume>61</volume>             <fpage>168</fpage>             <lpage>185</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Ohshiro1">
        <label>62</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ohshiro</surname><given-names>T</given-names></name><name name-style="western"><surname>Angelaki</surname><given-names>DE</given-names></name><name name-style="western"><surname>Deangelis</surname><given-names>GC</given-names></name></person-group>             <year>2011</year>             <article-title>A normalization model of multisensory integration.</article-title>             <source>Nat Neurosci</source>             <volume>14</volume>             <fpage>775</fpage>             <lpage>782</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Finn1">
        <label>63</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Finn</surname><given-names>IM</given-names></name><name name-style="western"><surname>Priebe</surname><given-names>NJ</given-names></name><name name-style="western"><surname>Ferster</surname><given-names>D</given-names></name></person-group>             <year>2007</year>             <article-title>The emergence of contrast-invariant orientation tuning in simple cells of cat visual cortex.</article-title>             <source>Neuron</source>             <volume>54</volume>             <fpage>137</fpage>             <lpage>152</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002432-Lcke1">
        <label>64</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lücke</surname><given-names>J</given-names></name><name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name></person-group>             <year>2008</year>             <article-title>Maximal causes for non-linear component extraction.</article-title>             <source>J Mach Learn Res</source>             <volume>9</volume>             <fpage>1227</fpage>             <lpage>1267</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>
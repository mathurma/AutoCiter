<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-16-01609</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005861</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Algebra</subject><subj-group><subject>Linear algebra</subject><subj-group><subject>Eigenvalues</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical noise</subject><subj-group><subject>Gaussian noise</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Stabilizing patterns in time: Neural network approach</article-title>
<alt-title alt-title-type="running-head">Stabilizing patterns in time</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5437-445X</contrib-id>
<name name-style="western">
<surname>Ben-Shushan</surname> <given-names>Nadav</given-names></name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4762-3136</contrib-id>
<name name-style="western">
<surname>Tsodyks</surname> <given-names>Misha</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Department of Physics, The Weizmann Institute of science, Rehovot, Israel</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Neurobiology, The Weizmann Institute of science, Rehovot, Israel</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Ermentrout</surname> <given-names>Bard</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University of Pittsburgh, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">misha@weizmann.ac.il</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>12</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="epub">
<day>12</day>
<month>12</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>12</issue>
<elocation-id>e1005861</elocation-id>
<history>
<date date-type="received">
<day>19</day>
<month>2</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>31</day>
<month>10</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Ben-Shushan, Tsodyks</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005861"/>
<abstract>
<p>Recurrent and feedback networks are capable of holding dynamic memories. Nonetheless, training a network for that task is challenging. In order to do so, one should face non-linear propagation of errors in the system. Small deviations from the desired dynamics due to error or inherent noise might have a dramatic effect in the future. A method to cope with these difficulties is thus needed. In this work we focus on recurrent networks with linear activation functions and binary output unit. We characterize its ability to reproduce a temporal sequence of actions over its output unit. We suggest casting the temporal learning problem to a perceptron problem. In the discrete case a finite margin appears, providing the network, to some extent, robustness to noise, for which it performs perfectly (i.e. producing a desired sequence for an arbitrary number of cycles flawlessly). In the continuous case the margin approaches zero when the output unit changes its state, hence the network is only able to reproduce the sequence with slight jitters. Numerical simulation suggest that in the discrete time case, the longest sequence that can be learned scales, at best, as square root of the network size. A dramatic effect occurs when learning several short sequences in parallel, that is, their total length substantially exceeds the length of the longest single sequence the network can learn. This model easily generalizes to an arbitrary number of output units, which boost its performance. This effect is demonstrated by considering two practical examples for sequence learning. This work suggests a way to overcome stability problems for training recurrent networks and further quantifies the performance of a network under the specific learning scheme.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>The ability to learn and execute actions in fine temporal resolution is crucial, as many of our day to day actions require such temporal ordering (e.g. limb movement and speech). Indeed, generating stable time-varying outputs, using neural networks has attracted a lot of attention over the last years. One of the core problems, when facing such a task, is the solution stability, hence it was only possible to produce the sequence for a limited number of cycles. Here we propose a robust approach for the task of learning time-varying sequences.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>Foundation Adelis</institution>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4762-3136</contrib-id>
<name name-style="western">
<surname>Tsodyks</surname> <given-names>Misha</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100007601</institution-id>
<institution>Horizon 2020</institution>
</institution-wrap>
</funding-source>
<award-id>720270</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4762-3136</contrib-id>
<name name-style="western">
<surname>Tsodyks</surname> <given-names>Misha</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by the foundation Adelis. The funders had no role in study, design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="5"/>
<table-count count="2"/>
<page-count count="16"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The paper is a theoretical work and does not contain experimental data. All the parameters required to reproduce our results are specified in the Methods section.</meta-value>
</custom-meta>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2017-12-22</meta-value>
</custom-meta></custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>There are many human behaviors which unfold over time. Our limb movement, speech and even our internal train of thought appear to involve sequences of events that follow one another in time. We are capable of performing an enormous number of sequences, and we can perform the same action in a variety of different contexts. Hence the concept of generating temporal patterns or sequences by neural networks draw a lot of attention over the years. Early work relied on cyclic inhibition [<xref ref-type="bibr" rid="pcbi.1005861.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1005861.ref003">3</xref>] which formed the basis of networks that function as ring oscillators [<xref ref-type="bibr" rid="pcbi.1005861.ref004">4</xref>]. These models could only be applied to small number of neurons and are restricted in the complexity of the output they can generate. The complexity of a sequence is determined by the number of actions that must be remembered in order to know to correct successor. Later work [<xref ref-type="bibr" rid="pcbi.1005861.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1005861.ref006">6</xref>] produced temporal sequences in an arbitrary large network, using associative neural network with Hebb learning rule [<xref ref-type="bibr" rid="pcbi.1005861.ref007">7</xref>], encompassing the relation between output pattern and synaptic connections. The main idea in this model was to functionally separate the synaptic connection into two components, slow and fast, such that the slow component encoded transition between patterns and the fast component stabilized the current pattern. This model, in its basic form, only encodes transitions between neighboring states in a sequence. Hence it is also limited in the complexity of outputs it can produce. Specifically, in order to learn two partially overlapping sequences one should introduce another component in the synaptic connection, with time scale proportional to the amount of overlap between the sequences. Jordan first considered a clear distinction between the state of the network and the output [<xref ref-type="bibr" rid="pcbi.1005861.ref008">8</xref>]. Moreover, applying recurrent links within the network, provides it a dynamic memory by which “time” is implicitly encoded in the state of the network [<xref ref-type="bibr" rid="pcbi.1005861.ref009">9</xref>]. This kind of network architecture (i.e. recurrent and feedback connections) is common in cortical microcircuit [<xref ref-type="bibr" rid="pcbi.1005861.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1005861.ref011">11</xref>], hence various training schemes for such network architectures arose along the years. A generalization of this approach considered reading out target information from randomly connected network, was first suggested in [<xref ref-type="bibr" rid="pcbi.1005861.ref012">12</xref>] and later developed to the notion of echo state networks (ESN) [<xref ref-type="bibr" rid="pcbi.1005861.ref013">13</xref>] and liquid state machines (LSM) [<xref ref-type="bibr" rid="pcbi.1005861.ref014">14</xref>]. Typically these networks consists of non-linear activation function for units within the network “reservoir” which linearly combines the output signal. These models do not need an internal pacemaker for producing a temporal sequence, in addition, learning a complex sequence is deduced to effectively learning a simple sequence, as two highly overlapping sequences end up as distinct in the high dimensional phase space of the network. None the less, it has been found as a challenging task to establish a successful learning procedure for these networks, one in which the network is capable of reproducing a desired target sequence for an arbitrary number of cycles, yet exhibiting robustness to errors and noise which are assumed to be common in biological networks. The main difficulties in this context are: In order to achieve a stable solution one should use a long training period involving noise over the output unit. During training the network will sample various fluctuations which improves the final network stability [<xref ref-type="bibr" rid="pcbi.1005861.ref015">15</xref>]. The second difficulty is assigning credit to output errors, i.e. which neurons and synapses are most responsible for the output error. Previous work settled this issue by restricting modification to synapses which project directly to the output unit [<xref ref-type="bibr" rid="pcbi.1005861.ref016">16</xref>]. This assumption was supported by [<xref ref-type="bibr" rid="pcbi.1005861.ref017">17</xref>], in which they showed that even in the case that all synapses were subject to modification during training, the synapses to the output tended to change the most.</p>
<p>In our model we suggest a variation of the ESN, i.e. For a recurrent network with a feedback loop, we consider linear activation function for neurons within the network and a binary output unit. In such case, given a target sequence on the output unit, one may easily solve for the corresponding activity in the network. Following previous work [<xref ref-type="bibr" rid="pcbi.1005861.ref016">16</xref>] we restrict ourselves on modifying synapses which project directly to the output unit. Even though it causes the solution space to shrink, it makes the learning problem straight forward, as it can be reduced for solving a simple perceptron [<xref ref-type="bibr" rid="pcbi.1005861.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1005861.ref019">19</xref>] problem.</p>
<p>This approach settles the problem of feeding back erroneous output to the network. Robustness to errors and noise naturally emerges from the finite margin of the perceptron problem, thus reproduction of a target sequence for an arbitrary number of cycles is possible, even in the presence of noise. In addition, considering a binary output unit helps in better quantifying the network performance, hence providing a different view on the computational power of this class of networks.</p>
<p>In our model, quantifying the memory capacity (MC) of the network is mathematically equivalent to calculating the capacity of a perceptron with correlated patterns presented to it. Where correlation induced by the network dynamic, as such, this is a challenging task analytically. Similar problems had been tackled in [<xref ref-type="bibr" rid="pcbi.1005861.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1005861.ref021">21</xref>] for the simplified case in which each neuron maintained an activity trace consisting of a decaying sum over all previous inputs presented to it. In [<xref ref-type="bibr" rid="pcbi.1005861.ref022">22</xref>] they considered correlated input-output associations, where temporal correlations between binary input patterns were modeled as Markov chain. In this case analytic result could only be obtained for the case of no temporal correlation between input patterns. Both models form a simple feed-forward architecture, hence temporal correlation do not depend on the state of other neurons in the network. In our model temporal correlation are of higher complexity due to the recurrent connectivity, hence we use numeric simulations in order to quantify the memory capacity for both the discrete and continuous time cases. Specifically, we solved the soft margin perceptron problem (<xref ref-type="sec" rid="sec014">Methods</xref>) with <italic>matlab</italic> standard quadratic programming function. An analytic estimation is given to noise robustness of the system.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Discrete time case</title>
<sec id="sec004">
<title>Network model</title>
<p>We use a recurrent and feedback neural network architecture (<xref ref-type="fig" rid="pcbi.1005861.g001">Fig 1</xref>). We start by analyzing the simpler, discrete time case with the following dynamic equations:
<disp-formula id="pcbi.1005861.e001"><alternatives><graphic id="pcbi.1005861.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold">W</mml:mi> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">V</mml:mi> <mml:mi>z</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula> <disp-formula id="pcbi.1005861.e002"><alternatives><graphic id="pcbi.1005861.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>z</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>sign</mml:mtext> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">J</mml:mi> <mml:mo>·</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula></p>
<fig id="pcbi.1005861.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005861.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Network architecture.</title>
<p>The <italic>N</italic> generator neurons, <bold>x</bold>(<italic>t</italic>), displayed in the large circle, are connected within themselves randomly, connections are represented by matrix <bold>W</bold>. In the figure <italic>W</italic><sub><italic>ij</italic></sub> is the strength of connection from neuron <italic>i</italic> to <italic>j</italic>. The generator neurons are connected to the output unit <italic>z</italic>(<italic>t</italic>) via the weight vector <bold>J</bold>. The output unit is recurrently connected to the generator neurons with weight vector <bold>V</bold>. During simulation we will only modify the output weights, <bold>J</bold>, and leave <bold>W</bold> and <bold>V</bold> constant.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.g001" xlink:type="simple"/>
</fig>
<p>Where <bold>x</bold>(<italic>n</italic>) represent the activity pattern in the <italic>n</italic><sup><italic>th</italic></sup> time step over the pool of <italic>N</italic> generator neurons. These are randomly connected within themselves, the matrix <bold>W</bold>, represent these random connections. The vector <bold>J</bold> stand for the synaptic weights from the network to the binary output unit <italic>z</italic>(<italic>n</italic>), <bold>V</bold> stands for the synaptic weights of the feedback loop, i.e. from the output unit back to the network. We also included an uncorrelated random noise term, <bold><italic>η</italic></bold>(<italic>n</italic>), with the following statistics, 〈<italic>η</italic><sub><italic>i</italic></sub>(<italic>n</italic>)〉<sub><italic>n</italic></sub> = 0 and <inline-formula id="pcbi.1005861.e003"><alternatives><graphic id="pcbi.1005861.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>η</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>+</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow> <mml:mi>n</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, where 〈⋯〉<sub><italic>n</italic></sub> denotes a time average.</p>
<p>The random connections within the network are drawn from <inline-formula id="pcbi.1005861.e004"><alternatives><graphic id="pcbi.1005861.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mfrac><mml:msup><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:msup> <mml:mi>N</mml:mi></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, note that by choosing λ &lt; 1, we force the largest eigenvalue of <bold>W</bold> to be smaller than one (in absolute value) [<xref ref-type="bibr" rid="pcbi.1005861.ref023">23</xref>]. This choice ensures that the entire dynamic is restricted to stable manifolds. The synaptic weights in the feedback loop are random as well and drawn from a normal distribution, later we apply the normalization ‖<bold>V</bold>‖ = 1, to scale with our choice of <bold>W</bold>. Our goal is thus to find an appropriate set for the output weights, <bold>J</bold>, which are capable of holding a desired set of dynamic memories. Specifically we are interested in learning periodic sequences, motivated by the periodic nature of many motor actions (e.g. running, swimming or bouncing a ball). As such we would like the network to be capable of reproducing a desired sequence for an arbitrary number of cycles.</p>
<p>Given a specific target sequence <inline-formula id="pcbi.1005861.e005"><alternatives><graphic id="pcbi.1005861.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:mo>≡</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>.</mml:mo> <mml:mo>.</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>.</mml:mo> <mml:mo>.</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, one can use <xref ref-type="disp-formula" rid="pcbi.1005861.e001">Eq (1)</xref> to solve recursively for the activation pattern over <bold>x</bold> neurons in each time step:
<disp-formula id="pcbi.1005861.e006"><alternatives><graphic id="pcbi.1005861.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e006" xlink:type="simple"/><mml:math display="block" id="M6"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>n</mml:mi></mml:msup> <mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:munderover> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mi mathvariant="bold">V</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where we omitted the noise term while deriving <xref ref-type="disp-formula" rid="pcbi.1005861.e006">Eq (3)</xref>, since we are interested in the trajectory in phase space induced by a given target sequence, i.e. this is the exact trajectory we would like the network to follow. Demanding that the network will reproduce the sequence periodically we set <bold>x</bold>(<italic>T</italic>) = <bold>x</bold>(0), thus finding the appropriate initial condition, <bold>x</bold>(0) ≡ <bold>x</bold><sub>0</sub>:
<disp-formula id="pcbi.1005861.e007"><alternatives><graphic id="pcbi.1005861.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e007" xlink:type="simple"/><mml:math display="block" id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>I</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:munderover> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mi mathvariant="bold">V</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>-</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
Eqs (<xref ref-type="disp-formula" rid="pcbi.1005861.e006">3</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1005861.e007">4</xref>) uniquely defines the generator neurons activity, or target activity for a given target sequence at each time step. Hence we have a set of patterns and their labels <inline-formula id="pcbi.1005861.e008"><alternatives><graphic id="pcbi.1005861.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. We note that using the simple procedure described so far, we are able to cast the temporal learning problem to a simple perceptron problem. That is, we need to find an appropriate set of output weights, <bold>J</bold>, that classify correctly the training set, i.e. satisfies <xref ref-type="disp-formula" rid="pcbi.1005861.e009">Eq (5)</xref> at each time step:
<disp-formula id="pcbi.1005861.e009"><alternatives><graphic id="pcbi.1005861.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e009" xlink:type="simple"/><mml:math display="block" id="M9"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mtext>sign</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">J</mml:mi> <mml:mo>·</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
If there exists a solution for the perceptron problem, cuing the network with the appropriate initial condition, <bold>x</bold><sub>0</sub>, will cause the network to reproduce the desired target sequence over and over again, as by construction it is a periodic orbit.</p>
</sec>
<sec id="sec005">
<title>Network performance</title>
<p>In the following (<xref ref-type="fig" rid="pcbi.1005861.g002">Fig 2</xref>) we show a demonstration of our suggested learning procedure results. We used an <italic>N</italic> = 100 network with λ = 0.99 normalization in order to learn a desired target sequence of 40 time steps. After inferring the proper weights by our learning procedure we let the network naturally evolve with Eqs (<xref ref-type="disp-formula" rid="pcbi.1005861.e001">1</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1005861.e002">2</xref>) and <inline-formula id="pcbi.1005861.e010"><alternatives><graphic id="pcbi.1005861.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msup><mml:mn>10</mml:mn> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, where the network activity is <inline-formula id="pcbi.1005861.e011"><alternatives><graphic id="pcbi.1005861.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mrow><mml:mi mathvariant="script">O</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. For clarity we only show 2 cycles of the network dynamics, in which we notice the perfect performance of the network, despite the finite noise. We note that as expected the learned periodic orbit is stable, as small perturbations driven by noise, exponentially decay. Let us now turn on quantifying the performance of our system.</p>
<fig id="pcbi.1005861.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005861.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Learning a single sequence.</title>
<p>We used network of size <italic>N</italic> = 100, with λ = 0.99 normalization to learn a 40 time step target sequence. After the learning procedure we cued the network with the proper initial condition and let it naturally evolve by Eqs (<xref ref-type="disp-formula" rid="pcbi.1005861.e001">1</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1005861.e002">2</xref>) with <inline-formula id="pcbi.1005861.e012"><alternatives><graphic id="pcbi.1005861.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msup><mml:mn>10</mml:mn> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> (where the network activity is <inline-formula id="pcbi.1005861.e013"><alternatives><graphic id="pcbi.1005861.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:mi mathvariant="script">O</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>). In order to emphasize the model robustness, we show 2 cycles of the network dynamic. Dashed black line indicates the end of the first cycle. Generally Blue colors are used for the desired activity in the network and Red colors for the network activity after the learning procedure (A) The target sequence and the network output after learning, the network produces the exact target sequence with no errors (B) The projected error, <bold>R</bold> is the difference between the noiseless target activity to the noisy dynamics after learning. Note that noise driven deviations are kept small, indicating the solution is robust.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.g002" xlink:type="simple"/>
</fig>
<p><italic>The longest single sequence.</italic> As a first step in quantifying the network performance we ask <italic>what is the longest single sequence that the network is capable of learning?</italic>. The length of the longest sequence defines the memory capacity (MC) of the network. Since we are in a discrete time case we measure it in time steps. We examine how the MC varies with respect to the parameter λ—the largest eigenvalue of <bold>W</bold> in absolute value (See <xref ref-type="sec" rid="sec014">Methods</xref>). The target sequence, {<italic>z</italic><sub><italic>t</italic></sub>}, is binary such that <italic>z</italic><sub><italic>t</italic></sub>(<italic>n</italic>) = ±1 with probability ½. The memory capacity for a given network size, <italic>N</italic>, and specific normalization parameter λ, is the longest sequence the network can learn, such that on average (over many different target sequences) the network can reproduce a target sequence without a single erroneous bit. Simulations suggest (<xref ref-type="fig" rid="pcbi.1005861.g003">Fig 3</xref>), that for a given network size, <italic>N</italic>, The memory capacity increases as we increase λ. This is an intuitive result, as increasing λ also increases the effective decay time of the network. Indeed the ability to maintain ongoing activity in the network for longer time is intimately related to the memory capacity as simulations suggest. In addition, for a fixed sequence length, increasing λ, increases, on average, the solution margin κ (<xref ref-type="fig" rid="pcbi.1005861.g003">Fig 3D</xref>). The MC relation to the network size seems to be λ dependent, and generally behave as a power law, <italic>MC</italic> ∼ <italic>N</italic><sup><italic>b</italic>(λ)</sup> (<xref ref-type="fig" rid="pcbi.1005861.g003">Fig 3C</xref>). For λ → 1<sup>−</sup>, the MC scales roughly as <inline-formula id="pcbi.1005861.e014"><alternatives><graphic id="pcbi.1005861.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:math></alternatives></inline-formula>, and for small values of λ the MC seems to saturate.</p>
<fig id="pcbi.1005861.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005861.g003</object-id>
<label>Fig 3</label>
<caption>
<title>The memory capacity for a single sequence.</title>
<p>(A) The memory capacity normalized by the network size as function of λ—the largest eigenvalue of the connectivity matrix <bold>W</bold> in absolute value. The MC monotonically increase as we increase λ. Note that by increasing λ, we increase the number of eigenvectors with long decay times. On the other hand, the MC does not seem to scale with network size, <italic>N</italic>, but rather sub-linear with it. (B) probing the scaling of the MC with the network size. In the log log plot, the MC seems to linearly scale with the network size. But with different slope, <italic>b</italic>(λ), for every λ. Filled circles are simulations results, solid lines are least squares fit to these points (C) scaling of the exponent, <italic>b</italic>, as function of λ. For λ → 1<sup>−</sup>, <inline-formula id="pcbi.1005861.e015"><alternatives><graphic id="pcbi.1005861.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mrow><mml:mi>M</mml:mi> <mml:mi>C</mml:mi> <mml:mo>∼</mml:mo> <mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>. For small values of λ it seems that the MC saturates, <italic>b</italic> ≈ 0 (D) the solution margin, for a fixed sequence length, monotonically increase as we increase λ. On the other hand, the solution margin monotonically decreases as we increase the sequence length, for λ = 0.999.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.g003" xlink:type="simple"/>
</fig>
<p><italic>Learning several sequences in parallel.</italic> From a biological perspective, it seems common that a given network will be able to learn several sequences, for example several motor programs. Thus an important feature of the system is its ability to learn several sequences in parallel i.e. for a single set of learned weights, the system should be capable reproducing several different sequences. Distinct sequences will be generated upon cuing the network with appropriate initial conditions. We found that in our suggested learning scheme the network is capable in doing so. It is thus of interest to compare the network performance in this case, to the single sequence case. As an instructive example <xref ref-type="fig" rid="pcbi.1005861.g004">Fig 4A</xref> shows that a network with <italic>N = 100</italic> units is capable of learning 4 sequences in parallel (40 time steps each). After learning the network was cued, at each trial, with a different initial condition (each correspond to a different target sequence) and released to naturally evolve according to Eqs (<xref ref-type="disp-formula" rid="pcbi.1005861.e001">1</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1005861.e002">2</xref>). Indeed the network exhibit a stable reproduction of the target sequences, over the output unit. Deviations from the desired activity are obviously observed, but these perturbations decay exponentially, leaving a perfect reproduction of the target sequence over the readout unit, <italic>z</italic>.</p>
<fig id="pcbi.1005861.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005861.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Parallel learning.</title>
<p>(A) Learning 4 sequence (40 time step each) in parallel. Each panel corresponds to a different target sequence. Blue color represents the target sequence activity projected on the output weights <bold>J</bold>. Red color stands for the post learning noisy dynamic (<italic>σ</italic><sub><italic>noise</italic></sub> = 10<sup>−4</sup>) projection on the readout weights, <bold>J</bold>. Note that despite the noisy dynamics, the network is capable of reproducing perfectly the learned sequences. Noise causes small deviations from the desired activity in the network, which decays exponentially, leaving no trace on the output unit, <italic>z</italic>. (B) the memory capacity per neuron Vs. the number of sequences, <italic>s</italic>, one wishes to learn in parallel, such that each sequence is generated by cuing the network with an appropriate initial condition. For each number of sequences to learn in parallel, we looked for the maximal length of each sub-sequence, such that all <italic>s</italic> of them could be learned by a single output weight vector.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.g004" xlink:type="simple"/>
</fig>
<p>We now turn in quantifying the network performance in the case of learning, <italic>s</italic>, sequences in parallel. i.e. given an initial condition <inline-formula id="pcbi.1005861.e016"><alternatives><graphic id="pcbi.1005861.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:msup><mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mn mathvariant="bold">0</mml:mn></mml:msub> <mml:mi>μ</mml:mi></mml:msup></mml:math></alternatives></inline-formula>, the network will produce the sequence <inline-formula id="pcbi.1005861.e017"><alternatives><graphic id="pcbi.1005861.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:msup><mml:mi>T</mml:mi> <mml:mi>μ</mml:mi></mml:msup></mml:msubsup></mml:math></alternatives></inline-formula>. Where 1 ≤ <italic>μ</italic> ≤ <italic>s</italic> represent the <italic>μ</italic><sup><italic>th</italic></sup> sequence. Each sequence has its own training set <inline-formula id="pcbi.1005861.e018"><alternatives><graphic id="pcbi.1005861.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>μ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:msup><mml:mi>T</mml:mi> <mml:mi>μ</mml:mi></mml:msup></mml:msubsup></mml:math></alternatives></inline-formula>. The training set in the parallel case is: <inline-formula id="pcbi.1005861.e019"><alternatives><graphic id="pcbi.1005861.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:msubsup><mml:mo>∪</mml:mo> <mml:mrow><mml:mi>μ</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>s</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>μ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:msup><mml:mi>T</mml:mi> <mml:mi>μ</mml:mi></mml:msup> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, which is the union of all individual training sets together. Thus in order for the network to learn, <italic>s</italic>, sequences we should be able to solve the perceptron problem for this combined training set. In addition we will define the memory capacity as the maximal total length of all sequences together, i.e. <inline-formula id="pcbi.1005861.e020"><alternatives><graphic id="pcbi.1005861.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mi>μ</mml:mi></mml:msup></mml:mrow></mml:munder> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>μ</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>s</mml:mi></mml:msubsup> <mml:msup><mml:mi>T</mml:mi> <mml:mi>μ</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. For simplicity we will examine the case where all sequences are of equal length, <italic>T</italic><sup><italic>μ</italic></sup> = <italic>T</italic>, ∀<italic>μ</italic>. In simulations we look for the maximal sequence length, <italic>T</italic><sup><italic>max</italic></sup>, for every <italic>s</italic> (number of sequences to learn in parallel). Numeric results exhibit a dramatic effect (<xref ref-type="fig" rid="pcbi.1005861.g004">Fig 4B</xref>) relative to the single sequence case. For <italic>s</italic> ≲ 15, the maximal sub-sequence length slowly decreases to ∼40 time steps. From <italic>s</italic> &gt; 15, it seems that the network could be loaded with many sub-sequences (we checked up to 70), hence the MC roughly grows linear with the number of sub-sequences. It is an interesting result since a naive thinking would predict that given a single sequence, one can divide it in an arbitrary manner to a number of individual sequences and the network will be capable of learning them. Hence, a naive approach will predict that parallel learning will not affect the MC, which clearly is not the case.</p>
</sec>
</sec>
<sec id="sec006">
<title>Noise robustness</title>
<p>In the presence of noise the networks trajectory in phase space will have a probabilistic nature. Each point in phase space, obtained by <xref ref-type="disp-formula" rid="pcbi.1005861.e006">Eq (3)</xref> will be smeared to a <italic>N-1</italic> ball of possible states. Hence noise robustness in the system stems from the finite margin of the perceptron problem. The quantity
<disp-formula id="pcbi.1005861.e021"><alternatives><graphic id="pcbi.1005861.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e021" xlink:type="simple"/><mml:math display="block" id="M21"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>D</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">J</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mo>|</mml:mo> <mml:mi mathvariant="bold">J</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:mfrac> <mml:munder><mml:mo form="prefix" movablelimits="true">min</mml:mo> <mml:mi>n</mml:mi></mml:munder> <mml:mi mathvariant="bold">J</mml:mi> <mml:mo>·</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula></p>
<p>Defined in [<xref ref-type="bibr" rid="pcbi.1005861.ref024">24</xref>] quantifies the difficulty level of the classification problem at hand. It is the worst projection from the set <inline-formula id="pcbi.1005861.e022"><alternatives><graphic id="pcbi.1005861.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> on the hyperplane perpendicular to <bold>J</bold>. The best solution, i.e. with largest margin is obtained by maximizing the value of <italic>D</italic> over all possible weight vectors <bold>J</bold>:
<disp-formula id="pcbi.1005861.e023"><alternatives><graphic id="pcbi.1005861.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e023" xlink:type="simple"/><mml:math display="block" id="M23"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>D</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo> <mml:mi mathvariant="bold">J</mml:mi></mml:munder> <mml:mi>D</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">J</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula></p>
<p>This is the margin, κ, obtained by the learning algorithm we used. The robustness to noise will be the order of magnitude of noise <inline-formula id="pcbi.1005861.e024"><alternatives><graphic id="pcbi.1005861.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> we can apply on each neuron, such that a learned sequence is still stable i.e. the hyperplane <bold>J</bold> classifies correctly the the set <inline-formula id="pcbi.1005861.e025"><alternatives><graphic id="pcbi.1005861.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, for many cycles before an error occurs. In order to quantify this we use <xref ref-type="disp-formula" rid="pcbi.1005861.e001">Eq (1)</xref> to solve recursively for the activation pattern over the generator neurons, this time taking into account the noise term.
<disp-formula id="pcbi.1005861.e026"><alternatives><graphic id="pcbi.1005861.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e026" xlink:type="simple"/><mml:math display="block" id="M26"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>n</mml:mi></mml:msup> <mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:munderover> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mi mathvariant="bold">V</mml:mi> <mml:mi>z</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:munderover> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mi>η</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">R</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
where we denoted the noisy activity pattern by <bold>x</bold><sub><italic>noise</italic></sub>. As expected, <xref ref-type="disp-formula" rid="pcbi.1005861.e026">Eq (8)</xref> implies that the effect of noise is to drive the original activity pattern by <inline-formula id="pcbi.1005861.e027"><alternatives><graphic id="pcbi.1005861.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mrow><mml:mi mathvariant="bold">R</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, which represent the accumulation of noise at the <italic>n</italic><sup><italic>th</italic></sup> time step. Thus in order for the output weights, <bold>J</bold>, to classify correctly the noisy dynamics we need to find <italic>σ</italic><sub><italic>noise</italic></sub> for which ∀<italic>n</italic>, ‖<bold>x</bold>(<italic>n</italic>) − <bold>x</bold><sub><italic>noise</italic></sub>(<italic>n</italic>)‖ &lt; κ, i.e. by <xref ref-type="disp-formula" rid="pcbi.1005861.e026">Eq (8)</xref> we need to satisfy:
<disp-formula id="pcbi.1005861.e028"><alternatives><graphic id="pcbi.1005861.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e028" xlink:type="simple"/><mml:math display="block" id="M28"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>∥</mml:mo> <mml:mi mathvariant="bold">R</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo> <mml:mo>∥</mml:mo> <mml:mo>&lt;</mml:mo> <mml:mo>κ</mml:mo> <mml:mspace width="2.em"/><mml:mo>∀</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
Calculations show (<xref ref-type="supplementary-material" rid="pcbi.1005861.s001">S1 Text</xref>) that under the annealed approximation, the amount of noise that the network can tolerate is given by:
<disp-formula id="pcbi.1005861.e029"><alternatives><graphic id="pcbi.1005861.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>&lt;</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mfrac><mml:msup><mml:mo>κ</mml:mo> <mml:mn>2</mml:mn></mml:msup> <mml:mi>N</mml:mi></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow> <mml:mfrac><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>N</mml:mi> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>W</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>W</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula></p>
<p>Where <italic>σ</italic><sub><italic>W</italic></sub> denotes the variance of an element in the connectivity matrix <bold>W</bold>, <inline-formula id="pcbi.1005861.e030"><alternatives><graphic id="pcbi.1005861.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>W</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Note that in the large <italic>N</italic> limit <italic>σ</italic><sub><italic>W</italic></sub> is tightly related to |λ|–the maximal eigenvalue of <bold>W</bold>, through:
<disp-formula id="pcbi.1005861.e031"><alternatives><graphic id="pcbi.1005861.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>W</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mfrac><mml:msup><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:msup> <mml:mi>N</mml:mi></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula></p>
<p>Plugging this relation in <xref ref-type="disp-formula" rid="pcbi.1005861.e029">Eq (10)</xref> yields:
<disp-formula id="pcbi.1005861.e032"><alternatives><graphic id="pcbi.1005861.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e032" xlink:type="simple"/><mml:math display="block" id="M32"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>&lt;</mml:mo> <mml:mfrac><mml:msup><mml:mo>κ</mml:mo> <mml:mn>2</mml:mn></mml:msup> <mml:mi>N</mml:mi></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:mfrac><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula> <disp-formula id="pcbi.1005861.e033"><alternatives><graphic id="pcbi.1005861.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e033" xlink:type="simple"/><mml:math display="block" id="M33"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>→</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munder> <mml:mrow><mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:msup><mml:mo>κ</mml:mo> <mml:mn>2</mml:mn></mml:msup> <mml:mi>N</mml:mi></mml:mfrac> <mml:mrow><mml:mo>[</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:msup> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>λ</mml:mo> <mml:mo>&lt;</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>λ</mml:mo> <mml:mo>&gt;</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo/></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula></p>
<p>This result is confirmed by numerical simulations in which we calculated ‖<bold>R</bold>(<italic>n</italic>)‖ for <italic>σ</italic><sub><italic>noise</italic></sub> that saturates the bound predicted by <xref ref-type="disp-formula" rid="pcbi.1005861.e032">Eq (12)</xref>. The average value of ‖<bold>R</bold>(<italic>n</italic>)‖ over the noise is compared to our prediction in <xref ref-type="fig" rid="pcbi.1005861.g005">Fig 5</xref>. On average results coincide, supporting the prediction for the scale of noise the network can tolerate. From <xref ref-type="disp-formula" rid="pcbi.1005861.e033">Eq (13)</xref> we note that for λ &gt; 1, the noise in the system grows exponentially resulting in an unstable system to noise perturbations. It further suggests that the robustness to noise depends both on the normalization of <bold>W</bold> and on κ. We can explicitly determine λ, but κ is given per certain realization of <bold>W, V</bold> and a specific target sequence {<italic>z</italic><sub><italic>t</italic></sub>}. On the one hand, if we fix κ we get that increasing λ lowers the robustness to noise. But note that, as expected, simulations shows that κ is monotonically increasing function in λ (<xref ref-type="fig" rid="pcbi.1005861.g003">Fig 3D</xref>). This indicates that there exist an optimal λ, such that the robustness to noise of the system is ideal. This value will represent the counter balance between the ability to forget the errors and memorizing the desired sequence.</p>
<fig id="pcbi.1005861.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005861.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Noise robustness.</title>
<p>Validity check for the analytic approximation of noise robustness in the system. Results are given as an average over the noise with fixed target sequence and connectivity. In each realization we let a <italic>N</italic> = 300, λ = 0.9 network learn a 60 time step random sequence. We then simulated the network trajectory for 3 cycles according to Eqs (<xref ref-type="disp-formula" rid="pcbi.1005861.e001">1</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1005861.e002">2</xref>). Where <italic>σ</italic><sub><italic>noise</italic></sub> was chosen such it saturates the bound given by Eqs (<xref ref-type="disp-formula" rid="pcbi.1005861.e033">13</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1005861.e035">15</xref>). We calculated and present ‖<bold>R</bold>(<italic>n</italic>)‖, at each time step. The red dashed curve is the analytic approximation, the blue curve is the averaged result from the simulation. We see that the analytic approximation indeed fits well the simulations.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec007">
<title>Other weight matrices</title>
<p>So far our analysis focused on random connectivity, as we avoided from constraining the connectivity. In this section we will mention other classes of connectivity suggested for short term memory [<xref ref-type="bibr" rid="pcbi.1005861.ref025">25</xref>].</p>
<sec id="sec008">
<title>Shift-register networks</title>
<p>We will start by considering the simplest construction, the shift register. The simplest shift operator is given by <italic>W</italic><sub><italic>ij</italic></sub> = <italic>λδ</italic><sub><italic>i</italic>, <italic>j</italic>+1</sub>. A major drawback of this form is its extreme sensitivity to removal of a single neuron. A more robust, distributed architecture of the shift register operation is a fully connected network with
<disp-formula id="pcbi.1005861.e034"><alternatives><graphic id="pcbi.1005861.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e034" xlink:type="simple"/><mml:math display="block" id="M34"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>=</mml:mo> <mml:mo>λ</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:munderover> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula>
where {<bold>v</bold><sup><italic>k</italic></sup>} is an arbitrary set of <italic>N</italic> orthonormal vectors. Note that this architecture operates like the simple delay line since <bold>W</bold> <bold>v</bold><sup><italic>k</italic></sup> = λ <bold>v</bold><sup><italic>k</italic>+1</sup>. A clear advantage of these architectures is that they ensure the use of their <italic>N</italic> degrees of freedom for memory embedding. Indeed, simulation shows that for both the simple and distributed shift register, the memory capacity for λ = 0.999 roughly scales as <italic>1.5 N</italic> (<xref ref-type="supplementary-material" rid="pcbi.1005861.s003">S1 Fig</xref>). This is a surprising result considering that <bold>W</bold> is nilpotent matrix of order <italic>N</italic>. Hence feedback inputs from times earlier than <italic>N</italic> can’t interfere with current inputs. Nonetheless, given an initial condition, different feedback inputs leads to different, <bold>x</bold>, states of the network. Noise robustness calculations (<xref ref-type="supplementary-material" rid="pcbi.1005861.s001">S1 Text</xref>) suggest that in order for the solution to be stable, asymptotically the noise should satisfy
<disp-formula id="pcbi.1005861.e035"><alternatives><graphic id="pcbi.1005861.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e035" xlink:type="simple"/><mml:math display="block" id="M35"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>e</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>&lt;</mml:mo> <mml:mfrac><mml:msup><mml:mo>κ</mml:mo> <mml:mn>2</mml:mn></mml:msup> <mml:mi>N</mml:mi></mml:mfrac> <mml:mrow><mml:mo>[</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:msup> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula>
note that asymptotically the noise has similar effect as for the random Gaussian case. Differences in robustness between the cases depends on κ, which is reminiscent of the different dynamics.</p>
</sec>
<sec id="sec009">
<title>Random orthogonal network</title>
<p>A natural extension of the shift-register operation is to a network with <bold>W</bold> = λ <bold>O</bold>, where <bold>O</bold> is an <italic>N</italic> × <italic>N</italic> orthogonal matrix. In contrast to the shift-register, orthogonal <bold>W</bold> is full rank and inputs from times earlier than <italic>N</italic> can interfere with current inputs. Numerical simulations suggest that for matrices drawn from the Gaussian orthogonal ensemble the memory capacity per neuron for, λ = 0.999, pushes to Cover’s bound of <italic>2N</italic> (<xref ref-type="supplementary-material" rid="pcbi.1005861.s003">S1 Fig</xref>). Robustness to noise in this case is similar to the random generic case.</p>
</sec>
</sec>
<sec id="sec010">
<title>Model generalization - Concrete examples</title>
<p>In this section we consider two tasks that our model, in its generalized form, can easily accomplish, without the need for any parameters fine tuning.</p>
<sec id="sec011">
<title>Tapping experiment</title>
<p>Here we adopt a sequence learning task (SRT) from [<xref ref-type="bibr" rid="pcbi.1005861.ref026">26</xref>]. The SRT is a four-choice reaction time task in which visual cues are linked to spatial-specific motor responses [<xref ref-type="bibr" rid="pcbi.1005861.ref027">27</xref>]. In one of its forms visual cues appear in any one of four possible positions arranged horizontally on a touch tablet. the responses are made by rapidly touching the cued location with a single finger. The cues are presented in a fixed, structured series of spatial locations; thus, unbeknown to the subjects, the cues introduce a sequence of lateral movements to be learned [<xref ref-type="bibr" rid="pcbi.1005861.ref028">28</xref>].</p>
<p>In order to use our model for this task we need to consider slight generalization (<xref ref-type="sec" rid="sec014">Methods</xref>), i.e. two output units are required to account for any of the four possible positions on the touch tablet. We will account different feedback loop weights for every output unit, and normalize them such that the total feedback is <inline-formula id="pcbi.1005861.e036"><alternatives><graphic id="pcbi.1005861.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mrow><mml:mi mathvariant="script">O</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. In the learning phase we will have to solve the perceptron problem twice, once for every output unit.</p>
<p>In [<xref ref-type="bibr" rid="pcbi.1005861.ref026">26</xref>] part of the subjects had to learn two different, 12 steps sequences, namely S12 (1-2-1-4-3-2-4-1-3-4-2-3) and R12 (3-2-4-1-3-1-2-3-4-2-1-4), where 1- stands for the left most key on the touch tablet, and 4—to right most. In order to transform these sequences to valid target sequences for our model we used the map in <xref ref-type="table" rid="pcbi.1005861.t001">Table 1</xref>. Our model could easily learn this task, i.e. 20 neuron with wide scaling of λ managed to learn both sequences, in parallel, successfully.</p>
<table-wrap id="pcbi.1005861.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005861.t001</object-id>
<label>Table 1</label>
<caption>
<title>Map from output units state to key number on the touch-pad.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005861.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Output units state</th>
<th align="center">key number</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">{-1,-1}</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">{1,-1}</td>
<td align="center">2</td>
</tr>
<tr>
<td align="center">{-1,1}</td>
<td align="center">3</td>
</tr>
<tr>
<td align="center">{1,1}</td>
<td align="center">4</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec012">
<title>Learning to play a melody</title>
<p>Here we consider a task previously proposed in [<xref ref-type="bibr" rid="pcbi.1005861.ref013">13</xref>], where they used echo state architecture with 400 neurons to learn the melody of the “House of the rising sun”. This task forces us to use three binary output units, since the melody consists of eight different notes. We assign different states over the output units to different notes as shown in <xref ref-type="table" rid="pcbi.1005861.t002">Table 2</xref>. The target sequence, taken from [<xref ref-type="bibr" rid="pcbi.1005861.ref013">13</xref>], when written in terms of notes is
<disp-formula id="pcbi.1005861.e037"><alternatives><graphic id="pcbi.1005861.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e037" xlink:type="simple"/><mml:math display="block" id="M37"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>{</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>B</mml:mi> <mml:mo>,</mml:mo> <mml:mi>B</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>B</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>D</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>C</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>C</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>B</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>B</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mi>A</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>A</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>A</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>A</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>G</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:mi>D</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>C</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>D</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>D</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>D</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>D</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>D</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mi>A</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>A</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>A</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>A</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>G</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>G</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:mi>D</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>C</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>C</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>B</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>B</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>G</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>G</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>G</mml:mi> <mml:mo>♯</mml:mo> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>,</mml:mo> <mml:mi>A</mml:mi> <mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula></p>
<table-wrap id="pcbi.1005861.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005861.t002</object-id>
<label>Table 2</label>
<caption>
<title>Map from output units state to numerical values which represent notes, according to [<xref ref-type="bibr" rid="pcbi.1005861.ref013">13</xref>].</title>
</caption>
<alternatives>
<graphic id="pcbi.1005861.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.t002" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Output units state</th>
<th align="center">Numerical value</th>
<th align="center">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">{-1,-1,-1}</td>
<td align="center">-1</td>
<td align="center"><italic>G</italic>♯</td>
</tr>
<tr>
<td align="center">{1,-1,-1}</td>
<td align="center">0</td>
<td align="center"><italic>A</italic></td>
</tr>
<tr>
<td align="center">{1,1,-1}</td>
<td align="center">2</td>
<td align="center"><italic>B</italic></td>
</tr>
<tr>
<td align="center">{1,-1,1}</td>
<td align="center">3</td>
<td align="center"><italic>B</italic>♯</td>
</tr>
<tr>
<td align="center">{-1,-1,1}</td>
<td align="center">5</td>
<td align="center"><italic>C</italic>♯</td>
</tr>
<tr>
<td align="center">{-1,1,1}</td>
<td align="center">7</td>
<td align="center"><italic>D</italic>♯</td>
</tr>
<tr>
<td align="center">{-1,1,-1}</td>
<td align="center">12</td>
<td align="center"><italic>G</italic>′</td>
</tr>
<tr>
<td align="center">{1,1,1}</td>
<td align="center">14</td>
<td align="center"><italic>A</italic>′</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Learning has been done similarly as in the previous example, this time learning three different output weights. We found that our network easily learns this task, i.e. with completely random connectivity, and for a wide range of normalization factors, λ. For example the minimum number of neurons (λ = 0.75) required for that task is 21, with κ ∼ 10<sup>−3</sup>. With 400 neurons (λ = 0.999) the margin increased by two order of magnitude, κ ∼ 3 ⋅ 10<sup>−1</sup>. This is another example to the ability of our model to generalize easily, accounting for multiple output units. Note that it also boosts its performance, relative to the single unit case, as in this example the memory capacity per neuron &gt;2, which is impossible with single output unit.</p>
</sec>
</sec>
</sec>
<sec id="sec013" sec-type="conclusions">
<title>Discussion</title>
<p>We presented a simple solution to the stability problem in learning temporal sequences by recurrent networks. By considering a linear activation function for a recurrent neural network with feedback loop, we could cast the problem of learning a temporal sequence of actions over the output unit to a simple perceptron problem. Using our method we could get a perfect reproduction of a target sequence for many trials, even in the presence of noise. The robustness to noise was calculated in terms of the perceptron solution margin.</p>
<p><bold>Non-linear classification</bold> This work only considered linear classification for simplicity. Allowing for non-linear classification, e.g. by the kernel method [<xref ref-type="bibr" rid="pcbi.1005861.ref029">29</xref>], one can potentially improve the performance of the network. Indeed, we managed to improve the memory capacity by roughly tenfold, using a radial basis kernel (<xref ref-type="sec" rid="sec014">Methods</xref>). In order to best exploit this method one should systematically search for the best kernel and an optimal procedure to determine its parameters values, which was out of scope in this work.</p>
<p><bold>Parallel learning</bold> A dramatic effect has been observed when facing the task of learning several sequences in parallel. In our model it is possible to learn many sequences, such that the total number of actions the network can learn, substantially overcomes the length of the single sequence maximal length. While the core reason for this property remains mysterious for us, we would like to discuss a mathematical explanation and what it biologically infer. Mathematically the ability to learn sequence or sequences depends on the distribution in phase space of the training set. In our model, strong correlations are induced by the feedback loop, i.e. by the statistics of the target sequence. As mentioned in [<xref ref-type="bibr" rid="pcbi.1005861.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1005861.ref022">22</xref>] the memory capacity, of the perceptron, monotonically increase with increased correlations in both input and output. Even though they considered different model, we believe this finding stands in one with the effect observed in parallel learning. In our model different sequences are correlated in some manner through the dynamics (<bold>W</bold>, <bold>V</bold>) and the similar statistics of the target sequence.</p>
<p>In the biological aspect, our finding suggest that it is economical to use a neural microcircuit for learning several short sequences rather than a long single sequence, which is a desirable property from a memory circuit.</p>
<p><bold>Other weight matrices</bold> Our work focused on random connectivity, as we avoided from making assumptions on the internal structure. Nonetheless, major improvement in the network performance has been observed for other types of weight matrices. The special structure of these matrices better exploit the <italic>N</italic> degrees of freedom available to the network for memory embedding. This property also makes the memory capacity extensive. This finding should motivate future work that might consider learning procedures allowing for internal synapses modifications.</p>
<p><bold>Multiple output units</bold> In this work we considered two examples of generalizing our model for multiple output units (two and three). Generally, the model will generalize to an arbitrary number of output units. But, since the output states available for the network are exponential in the number of output units, only small number of these are sufficient to produce a fairly rich output sequence. The performance for multiple output units haven’t been studied systematically in this work. Nonetheless, we note that considering multiple output units is beneficial for the network performance. e.g 21 neuron are sufficient to study a 48 step periodic sequence (melody of the “House of the rising sun”), while with a single output unit, a network with 20 neuron could maximally learn a 30 step periodic sequence. Note that in the case of multiple units the network is driven, by its own feedback, in various directions. That compared to the case of a single output unit, which only feeds back on a single vector, <bold>V</bold>. Thus multiple output units encourage the dynamic of the network to span larger volume in phase space, making the perceptron problem easier.</p>
<p><bold>Continuous time case</bold> Extension of our model to a Continuous time representation is considered in <xref ref-type="supplementary-material" rid="pcbi.1005861.s002">S2 Text</xref>. Nonetheless, such an extension turned out yielding a major drawback. While in the discrete time case our method succeed in providing a robust solution, in the continuous time case it failed, as the margin approaches zero every time there is a jump in the target sequence. As a result, in the continuous case, the network was only able to reproduce the sequence with small jitters. It was numerically evident that the network is vulnerable to noise in the initial condition alone—hence it is vulnerable to noise in general. Changing the learning procedure, i.e. allowing modification in all synapses, internal and feedback connections, might help stabilizing the solution. Note that by taking this route the problem isn’t a simple perceptron problem any more, so a new learning rule should be obtained. One should note that modifying connections within the network, also changes the itinerary of the neural dynamic in phase space. This fact is what turns such an approach to a challenging one. Other works [<xref ref-type="bibr" rid="pcbi.1005861.ref015">15</xref>] used this approach, but as mentioned before, the network activity will eventually deviate from its target function outside the training window.</p>
<p>Timing is fundamental component for many of our day to day tasks. Yet, the neural mechanism underlying temporal processing remain unknown and controversial. It is not clear whether timing is dedicated to certain brain areas, or it is a general property, emerging from the neural activity. In our approach we used the dynamics of a recurrent neural network to implicitly represent time. That is, we encoded the timing of actions in the dynamics of the network.</p>
<p>From our results it is hard to be conclusive regarding this question. On the one hand, from the discrete time case it is evident, that indeed it is possible to encode time in a robust manner within the neural activity. On the other hand, in the continuous case we did face stability problem, which might only be a property of our mathematical solution.</p>
<p>In our mind, if it possible to robustly encode time in the discrete case, it should also be possible in the continuous case. As a consequence we do believe that this work support the claim in which timing is a general property of the brain, emerging from the neural activity.</p>
</sec>
<sec id="sec014" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec015">
<title>The perceptron learning algorithm</title>
<p>In simulations we solved both the primal and dual form of the soft margin perceptron problem, as defined in [<xref ref-type="bibr" rid="pcbi.1005861.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005861.ref030">30</xref>]. For learning multiple sequences in parallel we used the primal formulation, for the longest single sequence we used the dual formulation. The primal problem takes the following form
<disp-formula id="pcbi.1005861.e038"><alternatives><graphic id="pcbi.1005861.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e038" xlink:type="simple"/><mml:math display="block" id="M38"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>m</mml:mi> <mml:mi>i</mml:mi> <mml:mi>n</mml:mi> <mml:mi>i</mml:mi> <mml:mi>m</mml:mi> <mml:mi>i</mml:mi> <mml:mi>z</mml:mi> <mml:mi>e</mml:mi> <mml:mo>:</mml:mo> <mml:mspace width="1.em"/></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mi mathvariant="bold">J</mml:mi> <mml:mo>·</mml:mo> <mml:mi mathvariant="bold">J</mml:mi> <mml:mo>+</mml:mo> <mml:mo>λ</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>s</mml:mi> <mml:mi>u</mml:mi> <mml:mi>b</mml:mi> <mml:mi>j</mml:mi> <mml:mi>e</mml:mi> <mml:mi>c</mml:mi> <mml:mi>t</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>t</mml:mi> <mml:mi>o</mml:mi> <mml:mo>:</mml:mo> <mml:mspace width="1.em"/></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>ξ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>≥</mml:mo> <mml:mn>0</mml:mn> <mml:mspace width="1.em"/><mml:mo>∀</mml:mo> <mml:mi>i</mml:mi> <mml:mo>∈</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mo>.</mml:mo> <mml:mo>.</mml:mo> <mml:mo>,</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>z</mml:mi> <mml:mi>t</mml:mi> <mml:mi>i</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">J</mml:mi> <mml:mo>·</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi mathvariant="bold">i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>b</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≥</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Where <bold>J</bold> is the separating hyperplane and <italic>ξ</italic><sub><italic>i</italic></sub>’s are slack variables, yielding <italic>ξ</italic><sub><italic>i</italic></sub> = 0 for patterns on the correct side of the margin. 0 &lt; <italic>ξ</italic><sub><italic>i</italic></sub> &lt; 1 for patterns in the margin and <italic>ξ</italic><sub><italic>i</italic></sub> &gt; 1 for wrongly classified patterns. In this formulation choosing small values of λ will encourage a large margin, with possible not optimal performance on the training data, while large values of λ will encourage a solution that performs well on the training data. The advantage of solving the “soft” problem is that a solution that minimizes the objective function exists. We used λ = 10<sup>48</sup> which effectively serves as λ → ∞, to encourage correct classification over the training data. The dual problem takes the following form
<disp-formula id="pcbi.1005861.e039"><alternatives><graphic id="pcbi.1005861.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e039" xlink:type="simple"/><mml:math display="block" id="M39"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>m</mml:mi> <mml:mi>i</mml:mi> <mml:mi>n</mml:mi> <mml:mi>i</mml:mi> <mml:mi>m</mml:mi> <mml:mi>i</mml:mi> <mml:mi>z</mml:mi> <mml:mi>e</mml:mi> <mml:mo>:</mml:mo> <mml:mspace width="1.em"/></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:msub><mml:mi>α</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>α</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msubsup><mml:mi>z</mml:mi> <mml:mi>t</mml:mi> <mml:mi>i</mml:mi></mml:msubsup> <mml:msubsup><mml:mi>z</mml:mi> <mml:mi>t</mml:mi> <mml:mi>j</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi mathvariant="bold">i</mml:mi></mml:msub> <mml:mo>·</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi mathvariant="bold">j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:msub><mml:mi>α</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>s</mml:mi> <mml:mi>u</mml:mi> <mml:mi>b</mml:mi> <mml:mi>j</mml:mi> <mml:mi>e</mml:mi> <mml:mi>c</mml:mi> <mml:mi>t</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>t</mml:mi> <mml:mi>o</mml:mi> <mml:mo>:</mml:mo> <mml:mspace width="1.em"/></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn> <mml:mo>≤</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>≤</mml:mo> <mml:mo>λ</mml:mo> <mml:mspace width="1.em"/><mml:mo>∀</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>∑</mml:mo> <mml:mi>i</mml:mi></mml:munder> <mml:msub><mml:mi>α</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msubsup><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi></mml:mrow> <mml:mi>i</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
from the dual formulation the separating hypeplane is given by the support vectors
<disp-formula id="pcbi.1005861.e040"><alternatives><graphic id="pcbi.1005861.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e040" xlink:type="simple"/><mml:math display="block" id="M40"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">J</mml:mi> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:msub><mml:mover accent="true"><mml:mi>α</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:msubsup><mml:mi>z</mml:mi> <mml:mi>t</mml:mi> <mml:mi>i</mml:mi></mml:msubsup> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula>
the bias is calculated as a weighted average of the <inline-formula id="pcbi.1005861.e041"><alternatives><graphic id="pcbi.1005861.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:msubsup><mml:mi>α</mml:mi> <mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msubsup><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>, to deal with roundoff errors
<disp-formula id="pcbi.1005861.e042"><alternatives><graphic id="pcbi.1005861.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e042" xlink:type="simple"/><mml:math display="block" id="M42"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>b</mml:mi> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:msub><mml:mover accent="true"><mml:mi>α</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>z</mml:mi> <mml:mi>t</mml:mi> <mml:mi>i</mml:mi></mml:msubsup> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">J</mml:mi> <mml:mo>·</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>/</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>i</mml:mi></mml:munder> <mml:msub><mml:mover accent="true"><mml:mi>α</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(18)</label></disp-formula></p>
<p>Numerically we used the the matlab function <italic>quadprog</italic>, to solve both types of optimization problems. We set it with <italic>interior-point-convex</italic> algorithm and maximum number of iterations of 9000, to prevent it from terminating prematurely.</p>
<p><bold>Non-linear classification</bold> Solving the dual problem generalizes easily for solving a non-linear classification problem by choosing an appropriate kernel [<xref ref-type="bibr" rid="pcbi.1005861.ref029">29</xref>], i.e substituting <bold>x</bold><sub><italic>i</italic></sub> ⋅ <bold>x</bold><sub><italic>j</italic></sub> with a general kernel <italic>K</italic>(<bold>x</bold><sub><italic>i</italic></sub>, <bold>x</bold><sub><italic>j</italic></sub>). Individual simulations with radial basis kernel, <inline-formula id="pcbi.1005861.e043"><alternatives><graphic id="pcbi.1005861.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mrow><mml:mi>K</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo form="prefix">exp</mml:mo> <mml:mo>[</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mspace width="1pt"/> <mml:mo>−</mml:mo> <mml:mspace width="1pt"/> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, and <italic>σ</italic> set to typical distance between vectors, could increase the memory capacity by an order of magnitude (Not shown). This observation is based on single trials and not studied systematically.</p>
</sec>
<sec id="sec016">
<title>Simulations technique</title>
<p>The connectivity matrix, <bold>W</bold>, was constructed such that its largest eigenvalue is of particular value λ. To do so we first draw a random matrix with elements <inline-formula id="pcbi.1005861.e044"><alternatives><graphic id="pcbi.1005861.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mfrac><mml:msup><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:msup> <mml:mi>N</mml:mi></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, and applied normalization such that <inline-formula id="pcbi.1005861.e045"><alternatives><graphic id="pcbi.1005861.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:mrow><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mo>λ</mml:mo> <mml:msub><mml:mo>λ</mml:mo> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mfrac> <mml:mover accent="true"><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>. Where λ<sub><italic>max</italic></sub> is the largest eigenvalue, in absolute value of <inline-formula id="pcbi.1005861.e046"><alternatives><graphic id="pcbi.1005861.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:mover accent="true"><mml:mi mathvariant="bold">W</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. Every element in the feedback weight vector, <italic>V</italic><sub><italic>i</italic></sub>, was drawn from a standard normal distribution and normalized such that ‖<bold>V</bold>‖ = 1. In each trial of the simulation we where interested in learning a specific binary sequence {<italic>z</italic><sub><italic>t</italic></sub>} of length <italic>T</italic>, such that, <italic>z</italic><sub><italic>t</italic></sub>(<italic>t</italic>) = ±1 with probability <inline-formula id="pcbi.1005861.e047"><alternatives><graphic id="pcbi.1005861.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e047" xlink:type="simple"/><mml:math display="inline" id="M47"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula>. For each setup of random connections <bold>W</bold>, <bold>V</bold> we let the network learn various random sequences {<italic>z</italic><sub><italic>t</italic></sub>} of different length <italic>T</italic>. After learning the output weight vector <bold>J</bold>, we have simulated the network dynamic with Eqs (<xref ref-type="disp-formula" rid="pcbi.1005861.e001">1</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1005861.e002">2</xref>) for 5 cycles (e.g. for target sequence <italic>T</italic>, we have simulated the network dynamics for 5<italic>T</italic> time steps). Eventually we compared the simulated output versus the target sequence {<italic>z</italic><sub><italic>t</italic></sub>} counting for erroneous actions. For each sequence length we averaged the error over 300 repetitions of different random sequences. In addition we have done so for a given network setup over different normalization of <bold>W</bold>, i.e. different values of λ, note that that we have trained each specific random pattern over all different normalization of <bold>W</bold>. Following this procedure we have constructed the memory curve for a given network of size <italic>N</italic>, see <xref ref-type="supplementary-material" rid="pcbi.1005861.s003">S1 Fig</xref> for example. From such figure we extracted the memory capacity (MC) for each normalization of <bold>W</bold>, we have done so by taking the point on which the derivative of the curve is largest. Doing so for different realization of network setups we have plotted the memory capacity normalized by the network size (<italic>N</italic>) for different normalization of <bold>W</bold>, as can be seen in <xref ref-type="fig" rid="pcbi.1005861.g003">Fig 3</xref>.</p>
<p><bold>Several sequences in parallel</bold> In order to construct <xref ref-type="fig" rid="pcbi.1005861.g004">Fig 4</xref> we used Simulations of equal length sub-sequences. Given a number (denote by <italic>s</italic>) of sequences we wish to learn in parallel. We look for the maximal length, <inline-formula id="pcbi.1005861.e048"><alternatives><graphic id="pcbi.1005861.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e048" xlink:type="simple"/><mml:math display="inline" id="M48"><mml:msubsup><mml:mi>T</mml:mi> <mml:mrow><mml:mi>s</mml:mi></mml:mrow> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, for which we can learn this set of <italic>s</italic> sequences. Sequences are again binary with equal probability to be in each state. The memory capacity for a set of <italic>s</italic> sequences is just <inline-formula id="pcbi.1005861.e049"><alternatives><graphic id="pcbi.1005861.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e049" xlink:type="simple"/><mml:math display="inline" id="M49"><mml:mrow><mml:mi>s</mml:mi> <mml:msubsup><mml:mi>T</mml:mi> <mml:mrow><mml:mi>s</mml:mi></mml:mrow> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p><bold>Multiple output units</bold> A generalization of the model is to consider an arbitrary number, <italic>l</italic>, of output units, <italic>z</italic><sub><italic>i</italic></sub>, <italic>i</italic> = 1, 2, …, <italic>l</italic>, generally satisfying <italic>l</italic> ≪ <italic>N</italic>. Each output unit has its own feedback loop <bold>V</bold><sub><italic>i</italic></sub>, keeping the total feedback <inline-formula id="pcbi.1005861.e050"><alternatives><graphic id="pcbi.1005861.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e050" xlink:type="simple"/><mml:math display="inline" id="M50"><mml:mrow><mml:mi mathvariant="script">O</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, requires <inline-formula id="pcbi.1005861.e051"><alternatives><graphic id="pcbi.1005861.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">V</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mo>|</mml:mo></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:mo>½</mml:mo></mml:mrow> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mi>l</mml:mi></mml:msqrt></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. In the learning phase the perceptron problem is solved for each output unit separately, i.e. finding the best hyperplane, <bold>J</bold><sub><italic>i</italic></sub> for each unit. Note that the margin in this case is defined by <inline-formula id="pcbi.1005861.e052"><alternatives><graphic id="pcbi.1005861.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005861.e052" xlink:type="simple"/><mml:math display="inline" id="M52"><mml:munder><mml:mrow><mml:mo form="prefix" movablelimits="true">min</mml:mo> <mml:msub><mml:mo>κ</mml:mo> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mi>i</mml:mi></mml:munder></mml:math></alternatives></inline-formula>, i.e. the minimal margin from all of the <italic>l</italic> perceptron problem solved.</p>
</sec>
</sec>
<sec id="sec017">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005861.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>The discrete time case.</title>
<p>This section includes noise robustness calculations for several weight matrices.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005861.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.s002" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>The continuous time case.</title>
<p>In this section we generalize our model to continuous time.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005861.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.s003" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Memory curves for the Delay-line and random orthonormal connectivity.</title>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005861.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.s004" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Example for learning a continuous sequence.</title>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005861.s005" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.s005" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>The continuous solution dynamics.</title>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005861.s006" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.s006" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Memory capacity for the continuous case.</title>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005861.s007" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005861.s007" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Example of the continuous time learning algorithm.</title>
<p>(TIF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Elad Schneidman and Eitan Domany for helpful comments on the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005861.ref001">
<label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Reiss</surname> <given-names>R</given-names></name>. <chapter-title>A theory of resonance networks</chapter-title>. <source>Neural theory</source>. <year>1964</year>;.</mixed-citation>
</ref>
<ref id="pcbi.1005861.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Harmon</surname> <given-names>LD</given-names></name>. <article-title>Neuromimes: action of a reciprocally inhibitory pair</article-title>. <source>Science</source>. <year>1964</year>;<volume>146</volume>(<issue>3649</issue>):<fpage>1323</fpage>–<lpage>1325</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.146.3649.1323" xlink:type="simple">10.1126/science.146.3649.1323</ext-link></comment> <object-id pub-id-type="pmid">14207464</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wilson</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Waldron</surname> <given-names>I</given-names></name>. <article-title>Models for the generation of the motor output pattern in flying locusts</article-title>. <source>Proceedings of the IEEE</source>. <year>1968</year>;<volume>56</volume>(<issue>6</issue>):<fpage>1058</fpage>–<lpage>1064</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/PROC.1968.6457" xlink:type="simple">10.1109/PROC.1968.6457</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kling</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Székely</surname> <given-names>G</given-names></name>. <article-title>Simulation of rhythmic nervous activities</article-title>. <source>Kybernetik</source>. <year>1968</year>;<volume>5</volume>(<issue>3</issue>):<fpage>89</fpage>–<lpage>103</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00288899" xlink:type="simple">10.1007/BF00288899</ext-link></comment> <object-id pub-id-type="pmid">5728516</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kleinfeld</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>. <article-title>Associative neural network model for the generation of temporal patterns. Theory and application to central pattern generators</article-title>. <source>Biophysical Journal</source>. <year>1988</year>;<volume>54</volume>(<issue>6</issue>):<fpage>1039</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0006-3495(88)83041-8" xlink:type="simple">10.1016/S0006-3495(88)83041-8</ext-link></comment> <object-id pub-id-type="pmid">3233265</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kleinfeld</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>. <article-title>Associative network models for central pattern generators</article-title>. <source>Methods in neuronal modeling</source>. <year>1989</year>;p. <fpage>195</fpage>–<lpage>246</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005861.ref007">
<label>7</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Hebb</surname> <given-names>DO</given-names></name>. <source>The organization of behavior</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>1949</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005861.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>. <article-title>Serial order: A parallel distributed processing approach</article-title>. <source>Advances in psychology</source>. <year>1997</year>;<volume>121</volume>:<fpage>471</fpage>–<lpage>495</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0166-4115(97)80111-2" xlink:type="simple">10.1016/S0166-4115(97)80111-2</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Elman</surname> <given-names>JL</given-names></name>. <article-title>Finding structure in time</article-title>. <source>Cognitive science</source>. <year>1990</year>;<volume>14</volume>(<issue>2</issue>):<fpage>179</fpage>–<lpage>211</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1207/s15516709cog1402_1" xlink:type="simple">10.1207/s15516709cog1402_1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Horton</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>DL</given-names></name>. <article-title>The cortical column: a structure without a function</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>. <year>2005</year>;<volume>360</volume>(<issue>1456</issue>):<fpage>837</fpage>–<lpage>862</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rstb.2005.1623" xlink:type="simple">10.1098/rstb.2005.1623</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Joshi</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Sontag</surname> <given-names>ED</given-names></name>. <article-title>Computational aspects of feedback in neural circuits</article-title>. <source>PLoS Comput Biol</source>. <year>2007</year>;<volume>3</volume>(<issue>1</issue>):<fpage>e165</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.0020165" xlink:type="simple">10.1371/journal.pcbi.0020165</ext-link></comment> <object-id pub-id-type="pmid">17238280</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dominey</surname> <given-names>PF</given-names></name>. <article-title>Complex sensory-motor sequence learning based on recurrent state representation and reinforcement learning</article-title>. <source>Biological cybernetics</source>. <year>1995</year>;<volume>73</volume>(<issue>3</issue>):<fpage>265</fpage>–<lpage>274</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00201428" xlink:type="simple">10.1007/BF00201428</ext-link></comment> <object-id pub-id-type="pmid">7548314</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jaeger</surname> <given-names>H</given-names></name>. <article-title>The “echo state” approach to analysing and training recurrent neural networks-with an erratum note</article-title>. <source>Bonn, Germany: German National Research Center for Information Technology GMD Technical Report</source>. <year>2001</year>;<volume>148</volume>:<fpage>34</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005861.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Natschläger</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Markram</surname> <given-names>H</given-names></name>. <article-title>Real-time computing without stable states: A new framework for neural computation based on perturbations</article-title>. <source>Neural computation</source>. <year>2002</year>;<volume>14</volume>(<issue>11</issue>):<fpage>2531</fpage>–<lpage>2560</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089976602760407955" xlink:type="simple">10.1162/089976602760407955</ext-link></comment> <object-id pub-id-type="pmid">12433288</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sussillo</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>. <article-title>Generating coherent patterns of activity from chaotic neural networks</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>63</volume>(<issue>4</issue>):<fpage>544</fpage>–<lpage>557</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2009.07.018" xlink:type="simple">10.1016/j.neuron.2009.07.018</ext-link></comment> <object-id pub-id-type="pmid">19709635</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jaeger</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Haas</surname> <given-names>H</given-names></name>. <article-title>Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication</article-title>. <source>Science</source>. <year>2004</year>;<volume>304</volume>(<issue>5667</issue>):<fpage>78</fpage>–<lpage>80</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1091277" xlink:type="simple">10.1126/science.1091277</ext-link></comment> <object-id pub-id-type="pmid">15064413</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schiller</surname> <given-names>UD</given-names></name>, <name name-style="western"><surname>Steil</surname> <given-names>JJ</given-names></name>. <article-title>Analyzing the weight dynamics of recurrent learning algorithms</article-title>. <source>Neurocomputing</source>. <year>2005</year>;<volume>63</volume>:<fpage>5</fpage>–<lpage>23</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neucom.2004.04.006" xlink:type="simple">10.1016/j.neucom.2004.04.006</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rosenblatt</surname> <given-names>F</given-names></name>. <article-title>The perceptron: A probabilistic model for information storage and organization in the brain</article-title>. <source>Psychological review</source>. <year>1958</year>;<volume>65</volume>(<issue>6</issue>):<fpage>386</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0042519" xlink:type="simple">10.1037/h0042519</ext-link></comment> <object-id pub-id-type="pmid">13602029</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref019">
<label>19</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Rosenblatt</surname> <given-names>F</given-names></name>. <source>Principles of neurodynamics</source>. <year>1962</year>;.</mixed-citation>
</ref>
<ref id="pcbi.1005861.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bressloff</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>J</given-names></name>. <article-title>Temporal sequence storage capacity of time-summating neural networks</article-title>. <source>Journal of Physics A: Mathematical and General</source>. <year>1992</year>;<volume>25</volume>(<issue>4</issue>):<fpage>833</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1088/0305-4470/25/4/020" xlink:type="simple">10.1088/0305-4470/25/4/020</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bressloff</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>JG</given-names></name>. <article-title>Perceptron-like learning in time-summating neural networks</article-title>. <source>Journal of Physics A: Mathematical and General</source>. <year>1992</year>;<volume>25</volume>(<issue>16</issue>):<fpage>4373</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1088/0305-4470/25/16/014" xlink:type="simple">10.1088/0305-4470/25/16/014</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Clopath</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Nadal</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Brunel</surname> <given-names>N</given-names></name>. <article-title>Storage of correlated patterns in standard and bistable Purkinje cell models</article-title>. <source>PLoS Comput Biol</source>. <year>2012</year>;<volume>8</volume>(<issue>4</issue>):<fpage>e1002448</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002448" xlink:type="simple">10.1371/journal.pcbi.1002448</ext-link></comment> <object-id pub-id-type="pmid">22570592</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Girko</surname> <given-names>V</given-names></name>. <article-title>Circular law</article-title>. <source>Theory of Probability &amp; Its Applications</source>. <year>1985</year>;<volume>29</volume>(<issue>4</issue>):<fpage>694</fpage>–<lpage>706</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1137/1129095" xlink:type="simple">10.1137/1129095</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Krogh</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Palmer</surname> <given-names>RG</given-names></name>, <name name-style="western"><surname>Horner</surname> <given-names>H</given-names></name>. <article-title>Introduction to the Theory of Neural Computation</article-title>. <source>Physics Today</source>. <year>2008</year>;<volume>44</volume>(<issue>12</issue>):<fpage>70</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1063/1.2810360" xlink:type="simple">10.1063/1.2810360</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>White</surname> <given-names>OL</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>. <article-title>Short-term memory in orthogonal neural networks</article-title>. <source>Physical review letters</source>. <year>2004</year>;<volume>92</volume>(<issue>14</issue>):<fpage>148102</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevLett.92.148102" xlink:type="simple">10.1103/PhysRevLett.92.148102</ext-link></comment> <object-id pub-id-type="pmid">15089576</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Adini</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Bonneh</surname> <given-names>YS</given-names></name>, <name name-style="western"><surname>Komm</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Deutsch</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Israeli</surname> <given-names>D</given-names></name>. <article-title>The time course and characteristics of procedural learning in schizophrenia patients and healthy individuals</article-title>. <source>Frontiers in human neuroscience</source>. <year>2015</year>;<volume>9</volume>:<fpage>475</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2015.00475" xlink:type="simple">10.3389/fnhum.2015.00475</ext-link></comment> <object-id pub-id-type="pmid">26379536</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nissen</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Bullemer</surname> <given-names>P</given-names></name>. <article-title>Attentional requirements of learning: Evidence from performance measures</article-title>. <source>Cognitive psychology</source>. <year>1987</year>;<volume>19</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0010-0285(87)90002-8" xlink:type="simple">10.1016/0010-0285(87)90002-8</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Richard</surname> <given-names>MV</given-names></name>, <name name-style="western"><surname>Clegg</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Seger</surname> <given-names>CA</given-names></name>. <article-title>Implicit motor sequence learning is not represented purely in response locations</article-title>. <source>The Quarterly Journal of Experimental Psychology</source>. <year>2009</year>;<volume>62</volume>(<issue>8</issue>):<fpage>1516</fpage>–<lpage>1522</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/17470210902732130" xlink:type="simple">10.1080/17470210902732130</ext-link></comment> <object-id pub-id-type="pmid">19283555</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cortes</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Vapnik</surname> <given-names>V</given-names></name>. <article-title>Support-vector networks</article-title>. <source>Machine learning</source>. <year>1995</year>;<volume>20</volume>(<issue>3</issue>):<fpage>273</fpage>–<lpage>297</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00994018" xlink:type="simple">10.1007/BF00994018</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005861.ref030">
<label>30</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Press</surname> <given-names>WH</given-names></name>, <name name-style="western"><surname>Teukolsky</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Vetterling</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Flannery</surname> <given-names>BP</given-names></name>. <source>Numerical recipes in C</source>. vol. <volume>2</volume>. <publisher-name>Cambridge Univ Press</publisher-name>; <year>1982</year>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
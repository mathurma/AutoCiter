<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PCOMPBIOL-D-11-01072</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002346</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Social and behavioral sciences</subject>
          <subj-group>
            <subject>Psychology</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Learning and Generalization under Ambiguity: An fMRI Study</article-title><alt-title alt-title-type="running-head">Learning and Generalization under Ambiguity</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Chumbley</surname>
            <given-names>J. R.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Flandin</surname>
            <given-names>G.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Bach</surname>
            <given-names>D. R.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Daunizeau</surname>
            <given-names>J.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Fehr</surname>
            <given-names>E.</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Dolan</surname>
            <given-names>R. J.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Friston</surname>
            <given-names>K. J.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>The Wellcome Trust Centre for Neuroimaging, University College London, London, United Kingdom</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Laboratory for Social and Neural Systems Research, Institute of Empirical Research in Economics, University of Zurich, Zurich, Switzerland</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Behrens</surname>
            <given-names>Tim</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">University of Oxford, United Kingdom</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">j.chumbley@fil.ion.ucl.ac.uk</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: JRC KJF. Performed the experiments: JRC DRB. Analyzed the data: JRC. Contributed reagents/materials/analysis tools: JRC JD EF GF. Wrote the paper: JRC RJD KJF. Mathematical/computational modelling: JRC.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>1</month>
        <year>2012</year>
      </pub-date><pub-date pub-type="epub">
        <day>19</day>
        <month>1</month>
        <year>2012</year>
      </pub-date><volume>8</volume><issue>1</issue><elocation-id>e1002346</elocation-id><history>
        <date date-type="received">
          <day>21</day>
          <month>7</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>25</day>
          <month>11</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2012</copyright-year><copyright-holder>Chumbley et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Adaptive behavior often exploits generalizations from past experience by applying them judiciously in new situations. This requires a means of quantifying the relative importance of prior experience and current information, so they can be balanced optimally. In this study, we ask whether the brain generalizes in an optimal way. Specifically, we used Bayesian learning theory and fMRI to test whether neuronal responses reflect context-sensitive changes in ambiguity or uncertainty about experience-dependent beliefs. We found that the hippocampus expresses clear ambiguity-dependent responses that are associated with an augmented rate of learning. These findings suggest candidate neuronal systems that may be involved in aberrations of generalization, such as over-confidence.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>Intelligent behavior requires flexible responses to new situations, which exploit learned principles or abstractions. When no such principles exist, the imperative is to learn quickly from scratch. Behaviorally, we show that subjects learn action-reward relationships in a manner that enables them to generalize rules to new situations. Our fMRI results show that when subjects have no evidence that such a rule exists, medial temporal lobe responses (that reflect uncertainty) predict their augmented learning.</p>
      </abstract><funding-group><funding-statement>JC was funded by the SystemsX, CoMPLEX (UCL) and the Wellcome Trust. This work was supported by Wellcome Trust Program Grants to KJF and RJD. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="11"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Successful behavior in new situations often requires us to apply ‘rules-of-thumb’. However, acquiring and applying abstract rules from limited experience presents a fundamental computational problem <xref ref-type="bibr" rid="pcbi.1002346-Bishop1">[1]</xref>: in which both over- or under-generalization must be avoided <xref ref-type="bibr" rid="pcbi.1002346-Beck1">[2]</xref>, . Despite their importance, little is known about how neuronal systems learn these rules, and how the delicate balance between past and present information is maintained. Evolutionary arguments suggest that the use of previously learned rules when generalizing to new situations increases adaptive fitness by optimizing behavior <xref ref-type="bibr" rid="pcbi.1002346-Tenebaum1">[7]</xref>. This raises the key question of whether and how generalization is optimized <xref ref-type="bibr" rid="pcbi.1002346-Griffiths1">[8]</xref>. In this work, we examine whether human subjects combine previously learned rules and current information in an optimal way and identify the brain systems that underlie this combination. Using Bayesian learning theory to specify optimal generalization, we looked for its neural correlates. In particular, we drew on existing evidence that points to the hippocampus as a key structure that is implicated in learning the specifics of a new situation, when previously learned rules may not apply <xref ref-type="bibr" rid="pcbi.1002346-OReilly1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Wittmann1">[10]</xref>.</p>
      <p>Probabilistic inference in a natural environment is confounded by multiple sources of uncertainty <xref ref-type="bibr" rid="pcbi.1002346-Yu1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Chater1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Schultz1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-PayzanLeNestour1">[14]</xref>, including objective randomness and subjective ignorance <xref ref-type="bibr" rid="pcbi.1002346-PayzanLeNestour1">[14]</xref>. Uncertainty is a key concept here because the confidence about prior beliefs should be weighed against the confidence about new information, when deciding whether to generalize those beliefs to a new situation. Classical reinforcement learning models (e.g. <xref ref-type="bibr" rid="pcbi.1002346-Rescorla1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Schultz2">[16]</xref>) do not represent uncertainty or use generalization to guide learning and behavior: these schemes simply learn the expected value of action-states and only prosper in environments where the current state is sufficient to specify a successful action: see <xref ref-type="bibr" rid="pcbi.1002346-Zilli1">[17]</xref> for a critique and extension. Having said this, several other RL schemes are based on some form of non-probabilistic function approximation and therefore support generalization (see Chapter 8 in <xref ref-type="bibr" rid="pcbi.1002346-Sutton1">[18]</xref> for discussion and recent RL approaches in neuroscience that consider generalization in the spatial <xref ref-type="bibr" rid="pcbi.1002346-Gustafson1">[19]</xref> and temporal <xref ref-type="bibr" rid="pcbi.1002346-Ludvig1">[20]</xref> case). While recent RL developments in neuroscience incorporate some notion of uncertainty <xref ref-type="bibr" rid="pcbi.1002346-Preuschoff1">[21]</xref>, learning and generalization are typically non-probabilistic. In this work we ask if learnt generalizations are accompanied with due uncertainty <xref ref-type="bibr" rid="pcbi.1002346-Cox1">[22]</xref>, as prescribed by probability theory.</p>
      <p>At the behavioral level, human subjects readily abstract probabilistic rules and use them to generalize <xref ref-type="bibr" rid="pcbi.1002346-Griffiths1">[8]</xref>. Furthermore, they can distinguish different sources of uncertainty: the unavoidable or irreducible randomness of certain events versus subjective ignorance about the world <xref ref-type="bibr" rid="pcbi.1002346-Chater1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Schultz1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Strange1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Hsu1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Hsu2">[25]</xref>. The latter resembles the concept of subjective <italic>ambiguity</italic> in economics and represents uncertainty about objective risks. For example, the <italic>risk</italic> (or irreducible randomness) associated with a <italic>fair</italic> coin toss is high (50∶50); however, there may be subjective ambiguity as to whether the coin is itself fair. This paper examines the function and mechanisms of generalization in the face of ambiguity. While there are good reasons to restrict the term ambiguity to <italic>complete</italic> ignorance <xref ref-type="bibr" rid="pcbi.1002346-Bach1">[26]</xref>, we use the term more inclusively to denote the level of uncertainty about the outcome probabilities. This is akin to <italic>estimation</italic> <xref ref-type="bibr" rid="pcbi.1002346-PayzanLeNestour1">[14]</xref> or <italic>second-order</italic> <xref ref-type="bibr" rid="pcbi.1002346-Bach1">[26]</xref> uncertainty (i.e., uncertainty about uncertainty). Ambiguity is subjective and reference-dependent: it ranges from complete ignorance to near certainty and, crucially, can be reduced by generalization in a Bayes-optimal fashion <xref ref-type="bibr" rid="pcbi.1002346-Griffiths1">[8]</xref>. In other words, if subjects consider their current situation in the light of past experience, they can exploit similarities between the past and present to reduce their ambiguity <xref ref-type="bibr" rid="pcbi.1002346-Kemp1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Congdon1">[28]</xref>. In our example, ambiguity about a new coin will be reduced by observing the random behavior of similar coins. This ability to generalize over similar situations is seen readily in behavior and learning <xref ref-type="bibr" rid="pcbi.1002346-Griffiths1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-PayzanLeNestour1">[14]</xref>.</p>
      <p>In this study, we examined the neuronal correlates of generalization with a special focus on the hippocampus: The hippocampus is involved in generalization <xref ref-type="bibr" rid="pcbi.1002346-Greene1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Shohamy1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Zeithamova1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Heckers1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Preston1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Eichenbaum1">[34]</xref> and shows activations that are sensitive to objective uncertainty or risk <xref ref-type="bibr" rid="pcbi.1002346-Strange1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Harrison1">[35]</xref>. In this paper, we asked if hippocampal responses also report subjective uncertainty or ambiguity that changes with experience. Specifically, we tested for ambiguity-dependent hippocampal responses, when probabilistic nature of outcomes had to be learned. Furthermore, we hoped to show behaviorally that learning rates were greater in contexts that had more ambiguity. We addressed these questions using a model of our experimental task and, tested whether Bayesian updates or learning could explain behavioral and neurophysiological responses, as measured with fMRI.</p>
    </sec>
    <sec id="s2" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s2a">
        <title>Subjects and procedure</title>
        <p>Nineteen subjects (age 19–31, 11 female) were recruited from the UCL psychology Dept subject pool. All subjects gave informed consent, before reading a brief description of the task which was then performed under fMRI. The study protocol was approved by the local UCL ethics committee.</p>
      </sec>
      <sec id="s2b">
        <title>Image acquisition and analysis</title>
        <sec id="s2b1">
          <title>Image acquisition</title>
          <p>Images were acquired on a 3 T Allegra head scanner (Siemens Medical Systems) with a head coil for RF transmission and signal reception. We used BOLD signal sensitive T2*-weighted transverse single-shot gradient-echo echo-planar imaging (EPI; flip angle 90°; bandwidth BW, 3551 Hz/pixel; phase-encoding (PE) direction, anterior–posterior; bandwidth in PE direction BWPE, 47.3 Hz/pixel; TE, 30 ms; effective TR, 2600 ms). An automatic 3D-shim procedure was performed at the beginning of each experiment. Each volume contained 40 slices of 2-mm thickness (1-mm gap between slices; field of view, 192×192-mm<sup>2</sup>; matrix size, 64×64). Sensitivity losses due to susceptibility artifacts were minimized by applying a <italic>z</italic>-shim gradient moment of 0.4 mT/m, a slice tilt of 30°, and a positive PE gradient polarity <xref ref-type="bibr" rid="pcbi.1002346-Weiskopf1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Weiskopf2">[37]</xref>. Each subject underwent one scanning session, with three breaks. The task was self-timed, and therefore the duration of each session depended on the subject. The first five volumes of each session were discarded to ensure steady-state longitudinal magnetization.</p>
          <p>Whole-brain anatomical scans were acquired using a modified driven equilibrium Fourier transform (MDEFT) sequence with optimized parameters <xref ref-type="bibr" rid="pcbi.1002346-Deichmann1">[38]</xref>. One hundred seventy-six sagittal partitions were acquired with an image matrix of 256×224 (read×phase) and twofold oversampling in read direction (head/foot direction) to prevent aliasing (isotropic spatial resolution 1-mm;15°; TR/TE/TI, 7.92 ms/2.4 ms/910 ms; BW, 195 Hz/pixel). Spin tagging in the neck was performed to avoid flow artifacts in the vicinity of blood vessels. The flip angle of the tagging pulse was chosen to be 160° to account for B1 losses in the neck. Special RF excitation pulses were used to compensate for B1 inhomogeneity of the transmit coil in superior/inferior and anterior/posterior directions. Images were reconstructed using a standard 3D Fourier Transform, followed by modulus calculation.</p>
        </sec>
        <sec id="s2b2">
          <title>Image analysis</title>
          <p>Functional imaging data were analyzed with statistical parametric mapping (SPM8; Wellcome Trust Centre for Neuroimaging; <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm" xlink:type="simple">www.fil.ion.ucl.ac.uk/spm</ext-link>). EPI images were generated off-line using a generalized reconstruction method based on the measured EPI <italic>k</italic>-space trajectory to minimize ghosting. Motion-corrected images were co-registered to the individual's anatomical MDEFT image and spatially normalized to the Montreal Neurological Institute T1 reference brain template (re-sampled voxel size: 2×2×2-mm).</p>
        </sec>
      </sec>
      <sec id="s2c">
        <title>The experimental paradigm</title>
        <p>While our goal was to identify domain-general computational processes, the paradigm was framed as a social inference task: Subjects were told that two <italic>groups</italic> of thirty <italic>individuals</italic> had completed a marketing survey. Subjects were then asked to guess, over ten consecutive trials, whether each individual would choose a ‘blue’ or ‘purple’ product. Subjects were told they would be paid ‘in proportion to the number of correct guesses’ and that the two groups were ‘geographically and economically unlike one another’. Trial cues (individuals) were faces from the Sterling data-set, whose group membership was indicated by the symbol ‘*’ or ‘o’ (see <xref ref-type="fig" rid="pcbi-1002346-g001">Figure 1</xref>). Each trial comprised the following sequence: 1) an individual's face was presented along with the symbol indicating their group membership; 2) the response options (blue and purple squares) were then presented, after which 3) the subject responded and 4) received feedback about whether their guess was correct or incorrect. The timeline for a single trial is shown in <xref ref-type="fig" rid="pcbi-1002346-g001">Figure 1</xref>. If subjects did not guess within one second, they were shown the instruction ‘ACT FASTER!’. The subject's guess was highlighted until feedback was delivered. Correct guesses were signaled with an auditory beep (500 milliseconds of 500 Hz sine wave) and accumulated in a score bar at the bottom of the screen. Incorrect guesses were indicated by a 500 millisecond burst of white noise (with no increase in their score).</p>
        <fig id="pcbi-1002346-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002346.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>This schematic shows the structure of each trial.</title>
            <p>A face was presented for 600 ms before two choice options were displayed. The choice options cue the subjects' guess, which was then indicated by a yellow border around the selected option. Audio and visual feedback indicated whether the choice was rewarded (correct) or not (incorrect).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.g001" xlink:type="simple"/>
        </fig>
        <p>Unbeknown to subjects, individuals from one group had similar preferences, while the other group had more between-individual variability. This meant that subjects had to make guesses about choices in two distinct contexts established by the group an individual belonged to: in the <italic>generalization context</italic> (GC), all individuals chose ‘purple’ with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e001" xlink:type="simple"/></inline-formula>. In the <italic>ambiguous context</italic> (AC), ‘blue’ was probabilistically chosen (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e002" xlink:type="simple"/></inline-formula>) by half of the group members and ‘purple’ (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e003" xlink:type="simple"/></inline-formula>) by the other half. To reiterate, subjects were presented with the same face ten times and had to guess whether the individual preferred blue or purple. Each individual was identified as belonging to one group or the other. Every individual preferred one color that was chosen 80% of the time. In the generalization context, all group members preferred the same color, while in the ambiguous context, individual group members preferred blue or purple with equal probability. In both contexts, subjects could learn about any given individual over ten trials.</p>
        <p>The generalization context therefore contained a probabilistic rule prescribing the best guess, even in the absence of learning about an individual's preferences. Conversely, in the ambiguous context, subjects had to learn about individual preferences because their group membership provided no clues about what they would preferentially choose. Trials were arranged into blocks, in which the same individual was presented for ten consecutive trials. The blocks alternated between AC and GC, with a new individual (face) for each block. This resulted in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e004" xlink:type="simple"/></inline-formula> trials, for thirty individuals, presented ten times for two groups.</p>
        <p>The blue and purple options were presented with equal probability on the left and right of the screen on each trial. Individuals (faces) were randomly reassigned to either group, between subjects. All subjects experienced the same feedback contingencies (with randomly reassigned cues). Subjects had three short breaks during the task: for each they were first cued ‘PLEASE HAVE A SHORT REST AND RELAX’ before being prompted to restart thirty seconds later: ‘OK! PLEASE PRESS ANY KEY TO CONTINUE’.</p>
      </sec>
      <sec id="s2d">
        <title>Bayesian modeling versus conventional fMRI analyses</title>
        <p>Bayesian learning theory predicts that subjects should learn more quickly about a new individual from the ambiguous group, relative to an individual from the generalization group. This is based upon the assumption that subjects are making Bayes-optimal guesses using a notion of group or context. The increase in learning rate with higher levels of ambiguity is related to increases in learning rate in situations with a high degree of volatility <xref ref-type="bibr" rid="pcbi.1002346-Behrens1">[39]</xref> (see below). At the neuronal level, we predicted that increases in learning rate would selectively engage hippocampal processing in the ambiguous context. In other words, hippocampal activation should track changes in ambiguity about an individual's preference as it alternates between AC (high ambiguity) and GC (low ambiguity) blocks. To quantify ambiguity, we assumed subjects were ideal Bayesian observers who used a model of probabilistic outcomes. We focused on two alternative models to predict subject responses, M1 and M2. Under M1, Bayesian learning combines new information with existing generalizations based on group membership. Conversely, M2 accumulates information about every individual independently, without the benefit of generalization.</p>
        <p>To make optimal guesses about the choices of each group member, subjects have to infer their preferences i.e. the probability that this individual will choose a particular option, say ‘purple’. We denote this probability with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e005" xlink:type="simple"/></inline-formula>. The information following each trial is equivalent to observing the outcome of a biased coin. We use the random variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e006" xlink:type="simple"/></inline-formula> to denote whether the choice of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e007" xlink:type="simple"/></inline-formula> individual was ‘purple’ (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e008" xlink:type="simple"/></inline-formula>) or ‘blue’ (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e009" xlink:type="simple"/></inline-formula>): <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e010" xlink:type="simple"/></inline-formula> in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e011" xlink:type="simple"/></inline-formula> (subjects encountered <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e012" xlink:type="simple"/></inline-formula> individuals in each of the two groups).</p>
        <p>In what follows, we consider alternative models that subjects might have used to infer the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e013" xlink:type="simple"/></inline-formula>. We start with a model that permits generalization and then turn to a version that precludes generalization. We also consider a few alternative models that can be considered as special cases that are of interest from an RL perspective.</p>
      </sec>
      <sec id="s2e">
        <title>Models</title>
        <sec id="s2e1">
          <title>M1: Bayes-optimal generalization</title>
          <p>The critical feature of <italic>M1</italic> is that guesses about each individual are informed by knowledge about group membership. This model supposes that subjects <italic>jointly</italic> learn about all individuals in a given group. In the generalization context, subjects should be more confident about a new individual from the unambiguous group, relative to the ambiguous group that provides no contextual clues. This differential uncertainty (ambiguity) is our focus. For simplicity, we assumed that subjects generalize within, but not between, groups. In other words, learning in one context was independent of learning in the other. An additional hierarchical level would permit generalization across contexts (e.g., the relative size of each group) and could be modeled with an extension of the Bayesian framework described below <xref ref-type="bibr" rid="pcbi.1002346-Teh1">[40]</xref>.</p>
          <p>The form of our model appeals to behavioral evidence that human rule learning resembles non-parametric Bayesian inference <xref ref-type="bibr" rid="pcbi.1002346-Griffiths2">[41]</xref>. It is also related to a previous <xref ref-type="bibr" rid="pcbi.1002346-Gershman1">[42]</xref> Bayesian formulation of rule-learning. (While the latter model focuses on Pavlovian learning, it resembles M1 through inferring the hidden number of subgroups or ‘latent causes’ <xref ref-type="bibr" rid="pcbi.1002346-Gershman1">[42]</xref>). In our model, subjects represent the (preferences of) individuals, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e014" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e015" xlink:type="simple"/></inline-formula> is the total number of individuals encountered so far. Subjects represent individual preferences by assigning individuals to subgroups, according to their similarity. Note that while subjects observe group membership, subgroup membership is hidden: There are two hidden subgroups in the ambiguous context, preferring either blue or purple, but only one in the generalization context. By first finding the number and nature of subgroups, optimal Bayesian assignment avoids over-generalization (e.g. incorrectly labeling a new blue-preferring individual as belonging to a known purple-preferring subgroup) and under-generalizing (e.g. failing to recognize that a new purple-preferring individual belongs to a known purple-preferring subgroup). This type of learning has had considerable success in modeling category learning in humans <xref ref-type="bibr" rid="pcbi.1002346-Griffiths2">[41]</xref> and ‘rationalizes’ non-Bayesian models of generalization in reinforcement learning <xref ref-type="bibr" rid="pcbi.1002346-Redish1">[43]</xref> (see below).</p>
          <p>We assume that subjects store the number of times (out of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e016" xlink:type="simple"/></inline-formula>) the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e017" xlink:type="simple"/></inline-formula> individual chose ‘purple’. The cumulative counts up to the present trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e018" xlink:type="simple"/></inline-formula>, are denoted by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e019" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e020" xlink:type="simple"/></inline-formula>. Subjects model their cumulative observations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e021" xlink:type="simple"/></inline-formula> as drawn from a mixture of Binomial distributions of the form <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e022" xlink:type="simple"/></inline-formula>. Being ignorant of the mixing distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e023" xlink:type="simple"/></inline-formula>, we assume they use a Dirichlet process <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e024" xlink:type="simple"/></inline-formula> over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e025" xlink:type="simple"/></inline-formula>, with concentration parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e026" xlink:type="simple"/></inline-formula> and base distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e027" xlink:type="simple"/></inline-formula> [corresponding to the uninformative conjugate Beta distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e028" xlink:type="simple"/></inline-formula>]. These define the base measure <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e029" xlink:type="simple"/></inline-formula>. The resulting probabilistic model is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e030" xlink:type="simple"/><label>(1)</label></disp-formula>Here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e031" xlink:type="simple"/></inline-formula> means <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e032" xlink:type="simple"/></inline-formula> has the distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e033" xlink:type="simple"/></inline-formula>; so the right hand side specifies a distribution. The Dirichlet process, DP, is thus a distribution on distributions and models ambiguity. Because realizations of a DP are discrete with probability one, these models can be viewed as probability measures consisting of a weighted sum of point masses <xref ref-type="bibr" rid="pcbi.1002346-Sethuraman1">[44]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Teh2">[45]</xref>; i.e., countably infinite mixtures<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e034" xlink:type="simple"/><label>(2)</label></disp-formula>Here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e035" xlink:type="simple"/></inline-formula> is a point mass at a single point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e036" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e037" xlink:type="simple"/></inline-formula> is a stick-breaking process and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e038" xlink:type="simple"/></inline-formula> is distributed as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e039" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002346-Blackwell1">[46]</xref>.</p>
          <p>The implicit form of generalization is more transparent when we integrate over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e040" xlink:type="simple"/></inline-formula> to obtain a prior over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e041" xlink:type="simple"/></inline-formula> in terms of successive conditional distributions (see <xref ref-type="bibr" rid="pcbi.1002346-Blackwell1">[46]</xref> for a measure-theoretic proof of this integral)<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e042" xlink:type="simple"/><label>(3)</label></disp-formula>This means the prior belief about one individual <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e043" xlink:type="simple"/></inline-formula> depends on knowledge about others sampled from the population, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e044" xlink:type="simple"/></inline-formula>, as well as the initial distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e045" xlink:type="simple"/></inline-formula>. This completes our description of M1 in terms of a likelihood (in Eq. 1) and prior (in Eq. 2/3).</p>
          <p>To predict subject's responses we require M1's posterior belief about the behavioral contingencies. This quantifies the ambiguity as well as the value of their response options. For posterior inference, one can obtain a sample from the posterior of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e046" xlink:type="simple"/></inline-formula> by simulating a Markov chain whose equilibrium distribution is the desired posterior distribution <xref ref-type="bibr" rid="pcbi.1002346-Neal1">[47]</xref>. The simplest approach is to repeatedly sample <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e047" xlink:type="simple"/></inline-formula> from its conditional distribution, given both the data and all other <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e048" xlink:type="simple"/></inline-formula>, denoted by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e049" xlink:type="simple"/></inline-formula>. This distribution therefore combines the likelihood of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e050" xlink:type="simple"/></inline-formula> and the prior, conditional on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e051" xlink:type="simple"/></inline-formula>. This conditional prior for an individual based on previous individuals is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e052" xlink:type="simple"/><label>(4)</label></disp-formula>and derives from the previous equation by noting that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e053" xlink:type="simple"/></inline-formula> is the last of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e054" xlink:type="simple"/></inline-formula> observations (i.e. by assuming the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e055" xlink:type="simple"/></inline-formula> are exchangeable). Introducing the likelihood, this yields the following conditional posterior distribution: <disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e056" xlink:type="simple"/><label>(5)</label></disp-formula>Where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e057" xlink:type="simple"/></inline-formula> is the posterior over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e058" xlink:type="simple"/></inline-formula>, based on the prior <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e059" xlink:type="simple"/></inline-formula> and the single observation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e060" xlink:type="simple"/></inline-formula> with likelihood <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e061" xlink:type="simple"/></inline-formula>, <italic>i.e.</italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e062" xlink:type="simple"/></inline-formula>. Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e063" xlink:type="simple"/></inline-formula> is chosen to ensure that<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e064" xlink:type="simple"/></disp-formula>This Bayesian model is related to the non-Bayesian RL model of <xref ref-type="bibr" rid="pcbi.1002346-Redish1">[43]</xref> mentioned in the <xref ref-type="sec" rid="s1">introduction</xref>. In that RL model, each cue is first ‘classified’ before reinforcement learning. A cue is either assigned to a known class of cues based on similarity, or designated exceptional and given its own class. Both perceptual similarity and predictive similarity play a role: do two cues look the same? do they predict the same outcomes? Regarding the latter, <italic>negative prediction errors</italic> from RL reduce perceived similarity between cues in a separate <italic>recognition system</italic>, thereby promoting discrimination over generalization <xref ref-type="bibr" rid="pcbi.1002346-Redish1">[43]</xref>. Our focus is on this predictive similarity. To derive <italic>optimal</italic> generalization, we define predictive similarity as the likelihood of an outcome, given a cue (rather than the inverse magnitude of a negative prediction error). In particular, a cue's past associations determine if it will be assigned to a known class based on similarity, defined by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e065" xlink:type="simple"/></inline-formula>, or assigned to its own class with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e066" xlink:type="simple"/></inline-formula>. The hyperparameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e067" xlink:type="simple"/></inline-formula> controls this tradeoff between generalization and discrimination and can itself be learned <xref ref-type="bibr" rid="pcbi.1002346-Escobar1">[48]</xref>.</p>
          <p>Having assumed <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e068" xlink:type="simple"/></inline-formula> is an uninformative Beta distribution, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e069" xlink:type="simple"/></inline-formula>, which is conjugate to the likelihood, calculating the integral <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e070" xlink:type="simple"/></inline-formula> and sampling from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e071" xlink:type="simple"/></inline-formula> are straight-forward. The simplest algorithm <xref ref-type="bibr" rid="pcbi.1002346-Neal1">[47]</xref> for Gibbs sampling from the full posterior <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e072" xlink:type="simple"/></inline-formula> including <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e073" xlink:type="simple"/></inline-formula> is (see <xref ref-type="bibr" rid="pcbi.1002346-Neal1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Escobar1">[48]</xref> for further details):</p>
          <p><italic>For</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e074" xlink:type="simple"/></inline-formula></p>
          <p>→<italic>Draw a new value from</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e075" xlink:type="simple"/></inline-formula> <italic>as defined above.</italic></p>
          <p><italic>With probability</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e076" xlink:type="simple"/></inline-formula> <italic>draw</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e077" xlink:type="simple"/></inline-formula> <italic>from the base distribution</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e078" xlink:type="simple"/></inline-formula>.</p>
          <p>→<italic>Otherwise, uniformly draw one existing</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e079" xlink:type="simple"/></inline-formula> <italic>and assign its value to</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e080" xlink:type="simple"/></inline-formula>.</p>
          <p>This procedure approximates the trial-by-trial evolution of posterior belief about preferences, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e081" xlink:type="simple"/></inline-formula>. Once the Markov chain has reached equilibrium, we use a sample of size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e082" xlink:type="simple"/></inline-formula> from that distribution. Furthermore, any marginal posterior of interest <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e083" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e084" xlink:type="simple"/></inline-formula> is approximated simply as the univariate component of this joint sample <xref ref-type="bibr" rid="pcbi.1002346-Gelman1">[49]</xref>.</p>
          <p>We used two measures of this time-dependent posterior as explanatory variables to predict the behavioral and neurophysiological responses of each subject. Firstly, we operationalized the ambiguity about each new individual using the Shannon entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e085" xlink:type="simple"/></inline-formula>. To evaluate this entropy, univariate samples from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e086" xlink:type="simple"/></inline-formula> were first binned into <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e087" xlink:type="simple"/></inline-formula> bins to provide an approximate discrete probability mass function with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e088" xlink:type="simple"/></inline-formula>. In this case, we have <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e089" xlink:type="simple"/></inline-formula>. This uncertainty measure characterizes the ambiguity about a new individual, as generalized from experience with other individuals in the group. A differential entropy between AC/GC reflects both the number of subgroups (clusters) and uncertainty about the parameters describing those subgroups. To see this more clearly take an extreme case where all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e090" xlink:type="simple"/></inline-formula> individuals encountered so far have been attributed to one subgroup, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e091" xlink:type="simple"/></inline-formula>. This subgroup, characterized by a parameter setting of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e092" xlink:type="simple"/></inline-formula>, is therefore strongly favored as an <italic>a priori</italic> explanation for new individuals (i.e. strong generalization). Applying this condition to Eq. 3 gives<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e093" xlink:type="simple"/></disp-formula>Intuitively, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e094" xlink:type="simple"/></inline-formula> probability mass now rests on just one point mass (for small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e095" xlink:type="simple"/></inline-formula> this is all the mass). This predictive distribution is therefore less ‘dispersed’ than if there were two or more subgroups (i.e. it has lower entropy). For this reason, when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e096" xlink:type="simple"/></inline-formula> is small, learning is more strongly biased towards belief in one subgroup. In this sense, the entropy can be regarded as a proxy for ambiguity that dictates the ‘learning rate’ or the sensitivity to new information. We used this entropy measure to identify the neurophysiological correlates of ambiguity, using fMRI responses.</p>
          <p>We have emphasized that greater prior ambiguity (i.e. higher number of inferred subgroups/higher predictive entropy) is accompanied by a diminished <italic>a priori</italic> bias. This affords observations more influence over posterior belief. Another influential hypothesis is that uncertainty influences choice by promoting exploration itself <xref ref-type="bibr" rid="pcbi.1002346-Daw1">[50]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Kakade1">[51]</xref> i.e. what to learn about <italic>vs.</italic> how fast to learn in the current situation. To simplify things, we chose a task with no exploration-exploitation trade-off. Specifically, because every trial in our task provides feedback on the value of the chosen action <italic>and</italic> counterfactual information about the other unchosen action, there is no information to be gained from exploring the less valuable action.</p>
          <p>Subjects do not know the true expected reward, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e097" xlink:type="simple"/></inline-formula>, for choosing ‘purple’ when faced with the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e098" xlink:type="simple"/></inline-formula> individual (they do not know that individual's preference). Let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e099" xlink:type="simple"/></inline-formula> then denote their subjective, expected reward for guessing ‘purple’ on the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e100" xlink:type="simple"/></inline-formula> trial faced with the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e101" xlink:type="simple"/></inline-formula> individual, following a total of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e102" xlink:type="simple"/></inline-formula> trials under M1. This expectation is defined by weighting possible values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e103" xlink:type="simple"/></inline-formula> according to their current plausibility, giving <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e104" xlink:type="simple"/></inline-formula>. This is just the posterior expectation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e105" xlink:type="simple"/></inline-formula> and can be approximated by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e106" xlink:type="simple"/><label>(6)</label></disp-formula>Here, each <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e107" xlink:type="simple"/></inline-formula> is an MCMC sample from the posterior <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e108" xlink:type="simple"/></inline-formula> conditional on all observations to date. This replaces an analytic expectation with an empirical expectation (converging according to the law of large numbers). An exactly analogous approximation yields the predicted value for a new cue:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e109" xlink:type="simple"/><label>(7)</label></disp-formula>We now turn to some alternative models.</p>
        </sec>
        <sec id="s2e2">
          <title>M2: Rescorla-Wagner without generalization</title>
          <p>To assess the predictions of M1 in relation to a null model, we also considered the predictions under M2, where subjects learn about each individual without generalization. Under this assumption, the expected reward (correct choice) can be modeled with classical Rescorla-Wagner learning <xref ref-type="bibr" rid="pcbi.1002346-Rescorla1">[15]</xref>.<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e110" xlink:type="simple"/><label>(8)</label></disp-formula>Where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e111" xlink:type="simple"/></inline-formula> is still the binary outcome on trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e112" xlink:type="simple"/></inline-formula> with the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e113" xlink:type="simple"/></inline-formula> cue. One implementation of M2 - akin to habit learning – would be to separately initialize the value of guessing ‘purple’ or ‘blue’ (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e114" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e115" xlink:type="simple"/></inline-formula>) to zero and update each only when the corresponding action was taken <xref ref-type="bibr" rid="pcbi.1002346-Dayan2">[52]</xref>. Guesses could then be modeled according to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e116" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e117" xlink:type="simple"/></inline-formula> controls the stochastic precision of the guess. However, because subjects are told that exactly one option is correct, each outcome is informative about the counterfactual (unchosen) option. We therefore initialized <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e118" xlink:type="simple"/></inline-formula> (the value of the purple guess on trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e119" xlink:type="simple"/></inline-formula> in the presence of each cue <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e120" xlink:type="simple"/></inline-formula>) to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e121" xlink:type="simple"/></inline-formula>, and defined the value of the blue choice as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e122" xlink:type="simple"/></inline-formula>. Subsequent outcomes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e123" xlink:type="simple"/></inline-formula> push <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e124" xlink:type="simple"/></inline-formula> up or down as specified by M2. This agent therefore uses counterfactual data (from the unchosen option), but does not generalize between individuals. We fit the free ‘learning rate’ parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e125" xlink:type="simple"/></inline-formula> by minimizing the error function, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e126" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e127" xlink:type="simple"/></inline-formula> indicates which option the subject guessed on the corresponding trial (coded as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e128" xlink:type="simple"/></inline-formula>). <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e129" xlink:type="simple"/></inline-formula> was evaluated numerically for different values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e130" xlink:type="simple"/></inline-formula> with increments of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e131" xlink:type="simple"/></inline-formula> within parameter space.</p>
        </sec>
        <sec id="s2e3">
          <title>M3–M5: Additional models</title>
          <p>The resulting sequence of value for our two models <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e132" xlink:type="simple"/></inline-formula> are plotted as a function of trial number in the dashed and solid curves of <xref ref-type="fig" rid="pcbi-1002346-g002">Figure 2</xref>, for the sequence of face cues and outcomes presented to our subjects (i.e. the sequence of blue/purple choices made by each individual). These correspond to the value of guessing purple under a model with (M1) and without (M2) the facility for generalization. For ease of visualization, <xref ref-type="fig" rid="pcbi-1002346-g002">Figure 2</xref> and <xref ref-type="fig" rid="pcbi-1002346-g003">3</xref> interpolate discrete-time model predictions to form smooth curves. The vertical lines demarking the context (ambiguous or generalization) are centered on the first trial of each block.</p>
          <fig id="pcbi-1002346-g002" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002346.g002</object-id>
            <label>Figure 2</label>
            <caption>
              <title>Subject's predicted value (expected reward) for guessing ‘purple’, according to model-based (M1, red-dashed) and model-free (M2, black) schemes.</title>
              <p>M1 tracks current information when necessary (AC), and otherwise exploits generalization to limit the impact of spurious outcomes on action (GC). M2 is ignorant about each new individual and myopically chases reward. Red circles indicate the actual guesses of a typical subject.</p>
            </caption>
            <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.g002" xlink:type="simple"/>
          </fig>
          <fig id="pcbi-1002346-g003" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002346.g003</object-id>
            <label>Figure 3</label>
            <caption>
              <title>Degree of learning formalized as prior uncertainty about the reinforcement contingencies, in M1.</title>
              <p>Without evidence of a contextual norm (in the AC) subjects are uncertain about what to do with an unfamiliar person, and must learn quickly. This time-series, convolved with a hemodynamic response function predicted hippocampal fMRI responses (see main text).</p>
            </caption>
            <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.g003" xlink:type="simple"/>
          </fig>
          <p>To ensure we had not overlooked other explanations for the subjects' responses, we performed secondary analyses, to establish the explanatory power of M1 in the context of alternative models, M3–M5. M3 was a generalization of M2 <xref ref-type="bibr" rid="pcbi.1002346-Rescorla1">[15]</xref>, which represents and learns the value of contextual (group-membership) cues. This agent therefore represents 62 cues (60 faces, 2 contextual cues). On each trial, M3 calls and updates both the context (group) <italic>and</italic> individual (face) cues presented on that trial. Defining <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e133" xlink:type="simple"/></inline-formula> as the outcome on trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e134" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e135" xlink:type="simple"/></inline-formula> as the instrumental value of choosing purple, faced with the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e136" xlink:type="simple"/></inline-formula> cue, updates were implemented with<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e137" xlink:type="simple"/><label>(9)</label></disp-formula>where the indicator <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e138" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e139" xlink:type="simple"/></inline-formula> whenever the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e140" xlink:type="simple"/></inline-formula> cue is present and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e141" xlink:type="simple"/></inline-formula> otherwise. Only values for cues actually present in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e142" xlink:type="simple"/></inline-formula> are updated. Like M2, this agent uses counterfactual information (from the unchosen option). Specifically, the value of choosing ‘purple’ on trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e143" xlink:type="simple"/></inline-formula> was <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e144" xlink:type="simple"/></inline-formula> and the value of choosing ‘blue’ was <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e145" xlink:type="simple"/></inline-formula>. Each <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e146" xlink:type="simple"/></inline-formula> was initialized to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e147" xlink:type="simple"/></inline-formula> so that prior to learning ‘blue’ or ‘purple’ were equally valuable; i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e148" xlink:type="simple"/></inline-formula>. The free parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e149" xlink:type="simple"/></inline-formula> was fit to each subject's guesses using the same procedure as for M2. M4 modeled a Bayesian learner that <italic>over-generalizes</italic>. It has an identical mathematical form to M1 but unlike M1 does not distinguish between contexts. It treats all individuals from the two contexts/populations indiscriminately i.e. as part of one ‘meta-population’. M5 modeled a Bayesian learner that <italic>under-generalizes</italic>; In other words, it can represent uncertainty but cannot generalize. M5, like M1 and M4, models observations associated with any one individual as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e150" xlink:type="simple"/></inline-formula>, but differs in the prior. In particular, each individual is treated independently with no generalization within or between groups (the prior over individuals factorizes). Specifically, we use a Beta prior that resets the prior for the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e151" xlink:type="simple"/></inline-formula> cue to uniform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e152" xlink:type="simple"/></inline-formula>, irrespective of its experience with other cues. This agent shares a key feature of M2 - resetting the predictions for each new cue to <italic>0.5</italic> and learning without generalization. For subsequent trials, it calculates the expected value of choosing purple as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e153" xlink:type="simple"/><label>(10)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e154" xlink:type="simple"/></inline-formula> is still the count of correct purple choices with cue <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e155" xlink:type="simple"/></inline-formula> (see above and <xref ref-type="bibr" rid="pcbi.1002346-Gelman1">[49]</xref>). In practice this agent's predictions are similar to M2.</p>
        </sec>
      </sec>
      <sec id="s2f">
        <title>Relating model predictions to data</title>
        <sec id="s2f1">
          <title>Behavior</title>
          <p>We used logistic regression to predict trial-by-trial choices from the value (expected reward) based on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e156" xlink:type="simple"/></inline-formula>, while including the value derived from models <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e157" xlink:type="simple"/></inline-formula> as additional nuisance covariates. We calculated within-subject point estimates of the partial regression coefficients of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e158" xlink:type="simple"/></inline-formula> predictions, before testing for significant (nonzero) effects at the between-subject level using standard classical statistics.</p>
        </sec>
        <sec id="s2f2">
          <title>fMRI</title>
          <p>Our analyses of the fMRI data used a conventional approach in which the parametric effects of variables from our formal Bayesian model were used to predict the amplitude of fMRI responses, after convolution with a suitable hemodynamic response function <xref ref-type="bibr" rid="pcbi.1002346-ODoherty1">[53]</xref>. Because the majority of experimental variation in the model predictions is between conditions (AC vs. GC), we arranged these conditions in a block design to ensure high efficiency. We could therefore choose either a conventional analysis that simply tested for condition effects or a model-based analysis that used parametric variations within and between conditions. To exploit our formal model, we used the more comprehensive model-based analysis: The fMRI data were modeled using a general linear convolution model, whose explanatory variables comprised stimulus functions convolved with a canonical hemodynamic response function. These stimulus functions comprised delta functions modulated by the following:</p>
          <p>1) The prediction ‘risk’ under M1 (time-locked to the choice presentation): 2) The reward predictions under M1, conditioned on the subject's choice (time-locked to the choice): 3) The model-based (Shannon) surprise at the outcome under M1 (time-locked to the outcome): 4) The signed model-based prediction error under M1, conditional on subject's choice (time-locked to the outcome): 5) the trial outcome: correct/incorrect, coded at 1,0 respectively (time-locked to the outcome). In terms of our hypothesis, these regressors can be regarded as modeling nuisance effects. Our final regressor was the key effect of interest; namely, the trial specific ambiguity as measured by the Shannon entropy above. It is this measure that reflects an encoding of contextual uncertainty that weakens generalization. The entropy entered as parametrically modulated delta functions at the time of choice, but before feedback. Six columns describing scan-specific rigid body translations and rotations were included as confounds. The data was temporally filtered to remove low-frequency drifts below 1/128 Hz.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s3">
      <title>Results</title>
      <p><xref ref-type="fig" rid="pcbi-1002346-g002">Figure 2</xref> shows the value (expected reward) of each choice according to the two main learning models we considered, together with a typical subject's guesses. Model 1 (M1) generalizes, while Model 2 (M2) cannot. For each subject, we used logistic regression to explain their choices in terms of these predictions and a constant term. Using a between-subject summary-statistic approach, we applied a two-tailed Student's <italic>t</italic>-test to the subject-specific logistic regression coefficients associated with the predictions of M1 (red-dashed curve, <xref ref-type="fig" rid="pcbi-1002346-g002">Figure 2</xref>). We rejected the null hypothesis that this effect was equal to zero (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e159" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e160" xlink:type="simple"/></inline-formula>). Interestingly, the size of the M1 regression coefficient predicted the total number of rewards obtained by each subject (correlation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e161" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e162" xlink:type="simple"/></inline-formula><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e163" xlink:type="simple"/></inline-formula>). This illustrates that generalization is evident behaviorally and pays off.</p>
      <p>A secondary behavioral analysis assessed the specificity of M1 predictions by examining the explanatory power of M1 in the context of the alternative models, M2 to M5. For each subject, we used logistic regression to explain subject's choices as a mixture of predictions from five models (M1 to M5), plus a constant term. Having estimated the logistic regression model for each subject, we again considered the subject-specific estimates for the coefficient reporting on M1 predictions. A two-tailed Student's <italic>t</italic>-test on the M1 coefficients was highly significant, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e164" xlink:type="simple"/></inline-formula>. No other model coefficients reached significance.</p>
      <p>To summarize, we used standard regression techniques to ask if, having accounted for competing models, a component of choice behavior reflects Bayes-optimal generalization (M1). Specifically, we included several model predictions in one linear model and estimated the partial regression coefficient for the predictor of interest (action-values derived from M1). One can therefore <xref ref-type="bibr" rid="pcbi.1002346-Dobson1">[54]</xref> conclude that, over and above competing models, behavior can be predicted by M1. Because Models M2 and M3 have a free parameter this conclusion is conservative: having been pre-fit to subject's behavior, these models have an explanatory advantage that is unavailable to M1 (or M4 and M5). In contrast to M2 (Eq. 8), M1 attempts to explain behavior via abstract computational principles, not detailed mechanisms. Its predictions have no free parameters. Rather, its predictions are based only on the subject's observations under ideal Bayesian assumptions. We have demonstrated that this model predicts behavior, above and beyond that explained by the other models considered. In what follows, we now ask whether the brain encodes ambiguity [see e.g. <xref ref-type="bibr" rid="pcbi.1002346-Behrens1">[39]</xref> for a similar approach].</p>
      <p>While M1 differs from other models in many ways, the important aspect for the fMRI analysis is that M1 provides an ambiguity measure. We therefore tested the null hypothesis that the fMRI signal is sensitive to ambiguity, as quantified by the Shannon entropy of prior belief (see above). In our fMRI data, fourteen subjects satisfied the inclusion criteria for a second-level between subject analysis (no interruptions to the scanner session or rapid head movement, as estimated by co-registration). We conducted regional and whole-brain analyses. All fMRI results presented here are based on the same general linear model, including the confounding factors (i.e., with nine regressors). In view of our specific hypothesis, region of interest (ROI) analyses asked whether activity within bilateral hippocampi tracked ambiguity about the current contingencies. <xref ref-type="fig" rid="pcbi-1002346-g004">Figure 4a</xref> shows the anatomy of the ROI.</p>
      <fig id="pcbi-1002346-g004" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002346.g004</object-id>
        <label>Figure 4</label>
        <caption>
          <title>Structural MRI, mask and functional activation.</title>
          <p>(<bold>a</bold>) Structural region-of-interest (white) on the subjects' average anatomical image. For visualization, black blobs exceed the 0.05 level uncorrected threshold corresponding to a Student's <italic>t</italic> (13 df). See the main text for statistical inference at a corrected p&lt;0.05 level. (<bold>b,c</bold>) Whole brain analysis of the effect of ambiguity. (<bold>b</bold>) Shows a glass-brain view (maximum intensity projection) of significant activations. (<bold>c</bold>) Shows the anterior activation, which included right anterior hippocampus and amygdala as defined, superimposed on the subjects' average anatomical image. (<bold>d</bold>) The observed fMRI trial-by-trial time-series (blue) averaged over all subjects for the hippocampal activation identified in our whole brain analysis (see main text). The model-based ambiguity is shown in red. Note that the model only captures the slow changes in observed responses over blocks as the contingencies are learned.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002346.g004" xlink:type="simple"/>
      </fig>
      <p><xref ref-type="fig" rid="pcbi-1002346-g003">Figure 3</xref> depicts ambiguity about a new individual (alternating block-wise between GC and AC blocks). As discussed, this dictates the relative influence of the current observation on belief updates (higher when there is high ambiguity). The parameter estimates associated with the entropy regressor above were averaged over bilateral hippocampal voxels for each subject, using the AAL atlas <xref ref-type="bibr" rid="pcbi.1002346-TzourioMazoyer1">[55]</xref>. We applied a two-tailed Student's <italic>t</italic>-test to these subject-specific summaries, testing the null hypothesis that hippocampal responses do not covary with ambiguity. We were able to reject this null hypothesis with a correct <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e165" xlink:type="simple"/></inline-formula>. Repeating the analysis on unilateral right and left hippocampus separately provided similar results (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e166" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e167" xlink:type="simple"/></inline-formula>, respectively). (These latter two results examine the separate contribution of each hemisphere to our bi-lateral effect. These tests are not statistically independent of the bi-lateral test and were not subject to additional correction.) There was no significant difference between left and right hippocampi. Our results therefore suggest that neuronal activity encodes the same sorts of variables that arise in our Bayes-optimal computations and, consequently, may be performing some form of approximate Bayesian inference.</p>
      <p>As with the behavioral data, we next examined the between-subject correlation between the hippocampal ambiguity coefficients and the total number of rewards attained in the experiment (correlation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e168" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e169" xlink:type="simple"/></inline-formula><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e170" xlink:type="simple"/></inline-formula>). Testing for separate correlations in left and right hippocampal effects gave respectively: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e171" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e172" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e173" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e174" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e175" xlink:type="simple"/></inline-formula>).</p>
      <p>In an exploratory whole brain analysis, we then smoothed the data with a Gaussian Kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e176" xlink:type="simple"/></inline-formula> and re-estimated the general linear model above using a conventional SPM analysis with whole brain correction for multiple comparisons <xref ref-type="bibr" rid="pcbi.1002346-Friston1">[56]</xref>. Two right-hemisphere clusters survived correction for cluster-extent (using a height threshold of 3). The first region (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e177" xlink:type="simple"/></inline-formula> FWE corrected) subsumed a right hippocampal region, mostly hippocampus and amygdala, but also putamen, as defined with the AAL atlas <xref ref-type="bibr" rid="pcbi.1002346-TzourioMazoyer1">[55]</xref>. The second region (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002346.e178" xlink:type="simple"/></inline-formula> FWE corrected) encompassed the fusiform gyrus and precuneus, with a spill-over into a calcarine region. These regions are shown in maximum intensity projection format in <xref ref-type="fig" rid="pcbi-1002346-g004">Figure 4b</xref> (this display format shows voxels with maximum intensity that fall on parallel lines traced from the viewpoint to the plane of projection as in a standard X-Ray). Orthogonal views of the anterior activation at its local maximum are shown in <xref ref-type="fig" rid="pcbi-1002346-g004">Figure 4c</xref>. For illustration purposes, <xref ref-type="fig" rid="pcbi-1002346-g004">Figure 4d</xref> shows the mean times series in this anterior region, averaged over all subjects. All of the above fMRI analyses were based on the same model, which included the nuisance regressors listed in <bold>Relating model predictions to data: fMRI</bold>. None of these nuisance effects could explain the variation in hippocampal responses that was explained by our Bayes-optimal generalization model (M1).</p>
    </sec>
    <sec id="s4">
      <title>Discussion</title>
      <p>Behaviorally, we have shown that subjects learn action-reward relationships in a manner that enables them to generalize rules to new situations. Crucially, this enables subjects to adapt their learning rate to provide an optimal balance between pre-existing generalizations and new information. We established this by showing that the accuracy of subjects' guesses evolved over trials in a way that was predicted by Bayes-optimal generalization, using a statistical model equipped with prior beliefs that allowed for contextual ambiguity. Furthermore, we established that a significant component of hippocampal responses could be explained by fluctuations in ambiguity under this model. These regionally specific responses were also significant in a whole brain SPM analysis.</p>
      <p>We provide empirical support for a model that explains how experience moderates decision making. In this model, the bias towards rule-based choices is determined by low ambiguity. We show that both learning and hippocampal responses are attenuated when the underlying rule is learned and applied in an unambiguous context. Conventional ‘model-free’ reinforcement learning cannot easily explain such effects because these schemes do not include contextual ambiguity. As noted in the <xref ref-type="sec" rid="s1">introduction</xref>, one recent variant of reinforcement learning <xref ref-type="bibr" rid="pcbi.1002346-Redish1">[43]</xref> is relevant here: In this two-system learning theory, generalization between observable cues rests both on their perceptual similarity and their predictive similarity (do cues look the same? do they predict the same outcomes?). The authors of <xref ref-type="bibr" rid="pcbi.1002346-Redish1">[43]</xref> contrast normal learning with under/over-generalization or ‘under/over willingness to generate a new state’ p 97. We have used a single model that formalizes this optimality by drawing on principles of optimal probabilistic generalization (see <xref ref-type="bibr" rid="pcbi.1002346-Gershman1">[42]</xref> for a related model). As in <xref ref-type="bibr" rid="pcbi.1002346-Redish1">[43]</xref>, our model generalizes by classifying observable cues before acting. Unlike <xref ref-type="bibr" rid="pcbi.1002346-Redish1">[43]</xref>, it invokes an explicit representation of subjective ambiguity to mediate and optimize this generalization. There remains an interesting challenge to relate our formulation and results to classical RL schemes. Interestingly the authors of <xref ref-type="bibr" rid="pcbi.1002346-Redish1">[43]</xref> speculate that the neuronal systems mediating generalization depend on the hippocampus (and PFC); because these systems are flexible, the rules by which observable cues are classified can easily be changed to permit new discriminations. These speculations are entirely consistent with our findings.</p>
      <p>As in previous treatments <xref ref-type="bibr" rid="pcbi.1002346-PayzanLeNestour1">[14]</xref>, we distinguish uncertainty about objective, observable events (e.g., the risk of getting ‘tails’ in a fair coin flip) from subjective ambiguity about unobservable states or parameters (is the coin really fair?). While the hippocampus has been implicated in the former <xref ref-type="bibr" rid="pcbi.1002346-Strange1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Harrison1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-VanniMercier1">[57]</xref>, the latter is central to computational accounts of contextual learning and inference; e.g. <xref ref-type="bibr" rid="pcbi.1002346-Bishop1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Cox1">[22]</xref>. Using a Bayes-optimal model, our work provides the first evidence that the hippocampus tracks contextual ambiguity about hidden or latent variables.</p>
      <p>Previous work <xref ref-type="bibr" rid="pcbi.1002346-Yu1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-PayzanLeNestour1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Behrens1">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-denOuden1">[58]</xref> has addressed how ambiguity mediates the influence of uncued <italic>temporal</italic> variability (volatility) on learning. We asked if variability in response requirements to different cues influences creates ambiguity and influences learning. In the current study, we manipulated the uncertainty about the behavioral contingencies over contexts, rather than time, and showed that associative learning adapts accordingly. Further work could examine whether neuromodulatory manipulations influence this effect; e.g., by selectively facilitating synaptic gain as predicted by <xref ref-type="bibr" rid="pcbi.1002346-Yu1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Hasselmo1">[59]</xref>. The role of dopamine deserves special attention, given prior work with Pavlovian or simpler instrumental tasks <xref ref-type="bibr" rid="pcbi.1002346-Dayan3">[60]</xref>. Additionally, given that the amygdala is able to modulate memory storage in non-amygdala brain areas <xref ref-type="bibr" rid="pcbi.1002346-Cahill1">[61]</xref>, multi-region <italic>in vivo</italic> recordings could disclose interactions with the hippocampus in these tasks. Interestingly, the amygdala activation in our whole-brain analyses is consistent with previous work implicating the amygdala in the representation of ambiguity <xref ref-type="bibr" rid="pcbi.1002346-Hsu1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Prvost1">[62]</xref>. However, previous studies were unable to address whether ambiguity regulates learning, as predicted theoretically. In line with Bayesian learning theory, our results suggest that learning (updating beliefs) can be guided by optimal probabilistic constraints, generalized from previous experience.</p>
      <p>The learning rate in (model-free) reinforcement learning prescribes the sensitivity of belief updates to current information. When this information is under or over-weighted, inefficient learning ensues. While classical RL is non-probabilistic (i.e. has a degraded uncertainty representation <xref ref-type="bibr" rid="pcbi.1002346-Cox1">[22]</xref>), it may in principle address this challenge by incorporating something akin to an ‘ambiguity-dependent’ or ‘surprise-dependent’ learning rate. For example, attempts have been made to optimise learning rates <xref ref-type="bibr" rid="pcbi.1002346-Mackintosh1">[63]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Pearce1">[64]</xref> in both stationary and non-stationary settings <xref ref-type="bibr" rid="pcbi.1002346-Sutton2">[65]</xref>. Bayesian learners use the rules of probability to achieve this balance by weighing new information against pre-existing generalizations. The relative weight of the latter depends upon ambiguity (the relative confidence in prior beliefs about the current context). When pre-existing beliefs are held with a high degree of confidence, they generally accommodate new observations, by down-weighting their impact. Such abilities to balance different sources of information and constraints are at the heart of adaptive behavior <xref ref-type="bibr" rid="pcbi.1002346-Foraker1">[66]</xref>. For example, appropriate social behavior requires communal norms, while retaining sensitivity to individual inclinations and preferences. The (social) learning task in this paper is a first step in this direction. Conversely, aberrant generalization has widespread consequences <xref ref-type="bibr" rid="pcbi.1002346-Beck1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Dayan1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Carrell1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002346-Huys2">[67]</xref>. The framework used in this study may provide an experimental framework to quantify dysfunctional generalization in specific patients; e.g., over-generalized schemata which persist despite contradictory evidence, as seen in depressive and delusional states and its associated pathophysiology at the neuronal level.</p>
    </sec>
  </body>
  <back>
    <ack>
      <p>We would like to thank Peter Dayan, Jon Rosier, Read Montague, Antonio Rangel, John O'Doherty, Grit Hein and our anonymous reviewers for invaluable discussions and feedback.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002346-Bishop1">
        <label>1</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bishop</surname><given-names>C</given-names></name></person-group>             <year>2006</year>             <article-title>Pattern Recognition and Machine Learning.</article-title>             <comment>Springer</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Beck1">
        <label>2</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Beck</surname><given-names>A</given-names></name></person-group>             <year>1993</year>             <source>Cognitive Therapy and the Emotional Disorders</source>             <publisher-loc>NY</publisher-loc>             <publisher-name>Penguin</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Dayan1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Huys</surname><given-names>QJM</given-names></name></person-group>             <year>2008</year>             <article-title>Serotonin, inhibition, and negative mood.</article-title>             <source>PLoS Comp Biol</source>             <volume>4</volume>             <fpage>e4</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Huys1">
        <label>4</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Huys</surname><given-names>Q</given-names></name><name name-style="western"><surname>Vogelstein</surname><given-names>J</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name></person-group>             <year>2009</year>             <article-title>Psychiatry: insights into depression through normative decision-making models.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Koller</surname><given-names>D</given-names></name><name name-style="western"><surname>Schuurmans</surname><given-names>D</given-names></name><name name-style="western"><surname>Bengio</surname><given-names>Y</given-names></name><name name-style="western"><surname>Bottou</surname><given-names>L</given-names></name></person-group>             <source>Advances in Neural Information Processing Systems 21</source>             <publisher-loc>Cambrige (Massachusetts)</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>729</fpage>             <lpage>736</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Carrell1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Carrell</surname><given-names>PL</given-names></name><name name-style="western"><surname>Eisterhold</surname><given-names>JC</given-names></name></person-group>             <year>1983</year>             <article-title>Schema theory and ESL reading pedagogy.</article-title>             <source>TESOL Quarterly</source>             <volume>17</volume>             <fpage>553</fpage>             <lpage>573</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Hestenes1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hestenes</surname><given-names>D</given-names></name></person-group>             <year>1987</year>             <article-title>Toward a modeling theory of physics instruction.</article-title>             <source>Am J Phys</source>             <volume>55</volume>             <fpage>440</fpage>             <lpage>454</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Tenebaum1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tenebaum</surname><given-names>JB</given-names></name><name name-style="western"><surname>Griffiths</surname><given-names>TL</given-names></name></person-group>             <year>2001</year>             <article-title>Generalization, similarity, and Bayesian inference.</article-title>             <source>Behav Brain Sci</source>             <volume>24</volume>             <fpage>629</fpage>             <lpage>+</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Griffiths1">
        <label>8</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Griffiths</surname><given-names>TL</given-names></name><name name-style="western"><surname>Kemp</surname><given-names>C</given-names></name><name name-style="western"><surname>Tenenbaum</surname><given-names>JB</given-names></name></person-group>             <year>2008</year>             <article-title>Bayesian models of cognition.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Sun</surname><given-names>Ron</given-names></name></person-group>             <source>The Cambridge handbook of computational cognitive modeling</source>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-OReilly1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>O'Reilly</surname><given-names>RC</given-names></name><name name-style="western"><surname>Norman</surname><given-names>KA</given-names></name></person-group>             <year>2002</year>             <article-title>Hippocampal and neocortical contributions to memory: advances in the complementary learning systems framework.</article-title>             <source>Trends Cogn Sci</source>             <volume>6</volume>             <fpage>505</fpage>             <lpage>510</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Wittmann1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wittmann</surname><given-names>BC</given-names></name><name name-style="western"><surname>Bunzeck</surname><given-names>N</given-names></name><name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Duzel</surname><given-names>E</given-names></name></person-group>             <year>2007</year>             <article-title>Anticipation of novelty recruits reward system and hippocampus while promoting recollection.</article-title>             <source>Neuro Image</source>             <volume>38</volume>             <fpage>194</fpage>             <lpage>202</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Yu1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name></person-group>             <year>2005</year>             <article-title>Uncertainty, neuromodulation, and attention.</article-title>             <source>Neuron</source>             <volume>46</volume>             <fpage>681</fpage>             <lpage>692</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Chater1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chater</surname><given-names>N</given-names></name><name name-style="western"><surname>Tenenbaum</surname><given-names>J</given-names></name><name name-style="western"><surname>Yuille</surname><given-names>A</given-names></name></person-group>             <year>2006</year>             <article-title>Probabilistic models of cognition: Conceptual foundations.</article-title>             <source>Trends Cogn Sci</source>             <volume>10</volume>             <fpage>287</fpage>             <lpage>291</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Schultz1">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name><name name-style="western"><surname>Preuschoff</surname><given-names>K</given-names></name><name name-style="western"><surname>Camerer</surname><given-names>C</given-names></name><name name-style="western"><surname>Hsu</surname><given-names>M</given-names></name><name name-style="western"><surname>Fiorillo</surname><given-names>C</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Explicit neural signals reflecting reward uncertainty.</article-title>             <source>Philos Trans R Soc Lond, Ser B: Biol Sci</source>             <volume>363</volume>             <fpage>3801</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-PayzanLeNestour1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Payzan-LeNestour</surname><given-names>E</given-names></name><name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name></person-group>             <year>2011</year>             <article-title>Risk, Unexpected Uncertainty, and Estimation Uncertainty: Bayesian Learning in Unstable Settings.</article-title>             <source>PLoS Comp Biol</source>             <volume>7</volume>             <fpage>e1001048</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Rescorla1">
        <label>15</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rescorla</surname><given-names>R</given-names></name><name name-style="western"><surname>Wagner</surname><given-names>A</given-names></name></person-group>             <year>1972</year>             <article-title>Variations in the Effectiveness of Reinforcement and Nonreinforcement.</article-title>             <source>Classical Conditioning II: Current Research and Theory</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Appleton-Century-Crofts</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Schultz2">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Montague</surname><given-names>PR</given-names></name></person-group>             <year>1997</year>             <article-title>A neural substrate of prediction and reward.</article-title>             <source>Science</source>             <volume>275</volume>             <fpage>1593</fpage>             <lpage>1599</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Zilli1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zilli</surname><given-names>EA</given-names></name><name name-style="western"><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group>             <year>2008</year>             <article-title>Modeling the role of working memory and episodic memory in behavioral tasks.</article-title>             <source>Hippocampus</source>             <volume>18</volume>             <fpage>193</fpage>             <lpage>209</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Sutton1">
        <label>18</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sutton</surname><given-names>R</given-names></name><name name-style="western"><surname>Barto</surname><given-names>A</given-names></name></person-group>             <year>1998</year>             <source>Reinforcement learning: An introduction</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>The MIT Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Gustafson1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gustafson</surname><given-names>NJ</given-names></name><name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name></person-group>             <year>2011</year>             <article-title>Grid Cells, Place Cells, and Geodesic Generalization for Spatial Reinforcement Learning.</article-title>             <source>PLoS Comp Biol</source>             <volume>7</volume>             <fpage>e1002235</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Ludvig1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ludvig</surname><given-names>EA</given-names></name><name name-style="western"><surname>Sutton</surname><given-names>RS</given-names></name><name name-style="western"><surname>Kehoe</surname><given-names>EJ</given-names></name></person-group>             <year>2008</year>             <article-title>Stimulus representation and the timing of reward-prediction errors in models of the dopamine system.</article-title>             <source>Neural Comput</source>             <volume>20</volume>             <fpage>3034</fpage>             <lpage>3054</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Preuschoff1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Preuschoff</surname><given-names>K</given-names></name><name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name></person-group>             <year>2007</year>             <article-title>Adding prediction risk to the theory of reward learning.</article-title>             <source>Ann N Y Acad Sci</source>             <volume>1104</volume>             <fpage>135</fpage>             <lpage>146</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Cox1">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cox</surname><given-names>RT</given-names></name></person-group>             <year>1946</year>             <article-title>Probability, Frequency and reasonable expectation.</article-title>             <source>Am J Phys</source>             <volume>14</volume>             <fpage>1</fpage>             <lpage>13</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Strange1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Strange</surname><given-names>BA</given-names></name><name name-style="western"><surname>Duggins</surname><given-names>A</given-names></name><name name-style="western"><surname>Penny</surname><given-names>W</given-names></name><name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name></person-group>             <year>2005</year>             <article-title>Information theory, novelty and hippocampal responses: unpredicted or unpredictable?</article-title>             <source>Neural Netw</source>             <volume>18</volume>             <fpage>225</fpage>             <lpage>230</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Hsu1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hsu</surname><given-names>M</given-names></name><name name-style="western"><surname>Lin</surname><given-names>H</given-names></name><name name-style="western"><surname>McNamara</surname><given-names>P</given-names></name></person-group>             <year>2008</year>             <article-title>Neuroeconomics of decision-making in the aging brain: the example of long-term care.</article-title>             <source>Adv Health Econ Health Serv Res</source>             <volume>20</volume>             <fpage>203</fpage>             <lpage>225</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Hsu2">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hsu</surname><given-names>M</given-names></name><name name-style="western"><surname>Bhatt</surname><given-names>M</given-names></name><name name-style="western"><surname>Adolphs</surname><given-names>R</given-names></name><name name-style="western"><surname>Tranel</surname><given-names>D</given-names></name><name name-style="western"><surname>Camerer</surname><given-names>CF</given-names></name></person-group>             <year>2005</year>             <article-title>Neural systems responding to degrees of uncertainty in human decision-making.</article-title>             <source>Science</source>             <volume>310</volume>             <fpage>1680</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Bach1">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bach</surname><given-names>DR</given-names></name><name name-style="western"><surname>Hulme</surname><given-names>O</given-names></name><name name-style="western"><surname>Penny</surname><given-names>WD</given-names></name><name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name></person-group>             <year>2011</year>             <article-title>The Known Unknowns: Neural Representation of Second-Order Uncertainty, and Ambiguity.</article-title>             <source>J Neurosci</source>             <volume>31</volume>             <fpage>4811</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Kemp1">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kemp</surname><given-names>C</given-names></name><name name-style="western"><surname>Perfors</surname><given-names>A</given-names></name><name name-style="western"><surname>Tenenbaum</surname><given-names>JB</given-names></name></person-group>             <year>2007</year>             <article-title>Learning overhypotheses with hierarchical Bayesian models.</article-title>             <source>Dev Sci</source>             <volume>10</volume>             <fpage>307</fpage>             <lpage>321</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Congdon1">
        <label>28</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Congdon</surname><given-names>P</given-names></name></person-group>             <year>2003</year>             <source>Applied bayesian modelling</source>             <publisher-name>John Wiley &amp; Sons Inc</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Greene1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Greene</surname><given-names>A</given-names></name><name name-style="western"><surname>Gross</surname><given-names>W</given-names></name><name name-style="western"><surname>Elsinger</surname><given-names>C</given-names></name><name name-style="western"><surname>Rao</surname><given-names>S</given-names></name></person-group>             <year>2006</year>             <article-title>An FMRI analysis of the human hippocampus: inference, context, and task awareness.</article-title>             <source>J Cogn Neurosci</source>             <volume>18</volume>             <fpage>1156</fpage>             <lpage>1173</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Shohamy1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shohamy</surname><given-names>D</given-names></name><name name-style="western"><surname>Wagner</surname><given-names>A</given-names></name></person-group>             <year>2008</year>             <article-title>Integrating memories in the human brain: hippocampal-midbrain encoding of overlapping events.</article-title>             <source>Neuron</source>             <volume>60</volume>             <fpage>378</fpage>             <lpage>389</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Zeithamova1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zeithamova</surname><given-names>D</given-names></name><name name-style="western"><surname>Preston</surname><given-names>A</given-names></name></person-group>             <year>2010</year>             <article-title>Flexible Memories: Differential Roles for Medial Temporal Lobe and Prefrontal Cortex in Cross-Episode Binding.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>14676</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Heckers1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Heckers</surname><given-names>S</given-names></name><name name-style="western"><surname>Zalesak</surname><given-names>M</given-names></name><name name-style="western"><surname>Weiss</surname><given-names>A</given-names></name><name name-style="western"><surname>Ditman</surname><given-names>T</given-names></name><name name-style="western"><surname>Titone</surname><given-names>D</given-names></name></person-group>             <year>2004</year>             <article-title>Hippocampal activation during transitive inference in humans.</article-title>             <source>Hippocampus</source>             <volume>14</volume>             <fpage>153</fpage>             <lpage>162</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Preston1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Preston</surname><given-names>A</given-names></name><name name-style="western"><surname>Shrager</surname><given-names>Y</given-names></name><name name-style="western"><surname>Dudukovic</surname><given-names>N</given-names></name><name name-style="western"><surname>Gabrieli</surname><given-names>J</given-names></name></person-group>             <year>2004</year>             <article-title>Hippocampal contribution to the novel use of relational information in declarative memory.</article-title>             <source>Hippocampus</source>             <volume>14</volume>             <fpage>148</fpage>             <lpage>152</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Eichenbaum1">
        <label>34</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Eichenbaum</surname><given-names>H</given-names></name><name name-style="western"><surname>Cohen</surname><given-names>N</given-names></name></person-group>             <year>2004</year>             <article-title>From conditioning to conscious recollection: Memory systems of the brain.</article-title>             <comment>Oxford University Press, USA</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Harrison1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Harrison</surname><given-names>LM</given-names></name><name name-style="western"><surname>Duggins</surname><given-names>A</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name></person-group>             <year>2006</year>             <article-title>Encoding uncertainty in the hippocampus.</article-title>             <source>Neural Netw</source>             <volume>19</volume>             <fpage>535</fpage>             <lpage>546</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Weiskopf1">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Weiskopf</surname><given-names>N</given-names></name><name name-style="western"><surname>Hutton</surname><given-names>C</given-names></name><name name-style="western"><surname>Josephs</surname><given-names>O</given-names></name><name name-style="western"><surname>Deichmann</surname><given-names>R</given-names></name></person-group>             <year>2006</year>             <article-title>Optimal EPI parameters for reduction of susceptibility-induced BOLD sensitivity losses: A whole-brain analysis at 3 T and 1.5 T.</article-title>             <source>NeuroImage</source>             <volume>33</volume>             <fpage>493</fpage>             <lpage>504</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Weiskopf2">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Weiskopf</surname><given-names>N</given-names></name><name name-style="western"><surname>Hutton</surname><given-names>C</given-names></name><name name-style="western"><surname>Josephs</surname><given-names>O</given-names></name><name name-style="western"><surname>Turner</surname><given-names>R</given-names></name><name name-style="western"><surname>Deichmann</surname><given-names>R</given-names></name></person-group>             <year>2007</year>             <article-title>Optimized EPI for fMRI studies of the orbitofrontal cortex: compensation of susceptibility-induced gradients in the readout direction.</article-title>             <source>MAGMA</source>             <volume>20</volume>             <fpage>39</fpage>             <lpage>49</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Deichmann1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Deichmann</surname><given-names>R</given-names></name><name name-style="western"><surname>Schwarzbauer</surname><given-names>C</given-names></name><name name-style="western"><surname>Turner</surname><given-names>R</given-names></name></person-group>             <year>2004</year>             <article-title>Optimisation of the 3D MDEFT sequence for anatomical brain imaging: Technical implications at 1.5 and 3 T.</article-title>             <source>NeuroImage</source>             <volume>21</volume>             <fpage>757</fpage>             <lpage>767</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Behrens1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Behrens</surname><given-names>TEJ</given-names></name><name name-style="western"><surname>Woolrich</surname><given-names>MW</given-names></name><name name-style="western"><surname>Walton</surname><given-names>ME</given-names></name><name name-style="western"><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group>             <year>2007</year>             <article-title>Learning the value of information in an uncertain world.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <fpage>1214</fpage>             <lpage>1221</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Teh1">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Teh</surname><given-names>YW</given-names></name><name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name><name name-style="western"><surname>Beal</surname><given-names>MJ</given-names></name><name name-style="western"><surname>Blei</surname><given-names>DM</given-names></name></person-group>             <year>2006</year>             <article-title>Hierarchical dirichlet processes.</article-title>             <source>J Am Stat Assoc</source>             <volume>101</volume>             <fpage>1566</fpage>             <lpage>1581</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Griffiths2">
        <label>41</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Griffiths</surname><given-names>TL</given-names></name><name name-style="western"><surname>Canini</surname><given-names>KR</given-names></name><name name-style="western"><surname>Sanborn</surname><given-names>AN</given-names></name><name name-style="western"><surname>Navarro</surname><given-names>DJ</given-names></name></person-group>             <year>2007</year>             <article-title>Unifying rational models of categorization via the hierarchical Dirichlet process.</article-title>             <comment>Proceedings of the Twenty-Ninth Annual Conference of the Cognitive Science Society</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Gershman1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gershman</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Blei</surname><given-names>DM</given-names></name><name name-style="western"><surname>Niv</surname><given-names>Y</given-names></name></person-group>             <year>2010</year>             <article-title>Context, learning, and extinction.</article-title>             <source>Psychol Rev</source>             <volume>117</volume>             <fpage>197</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Redish1">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name><name name-style="western"><surname>Jensen</surname><given-names>S</given-names></name><name name-style="western"><surname>Johnson</surname><given-names>A</given-names></name><name name-style="western"><surname>Kurth-Nelson</surname><given-names>Z</given-names></name></person-group>             <year>2007</year>             <article-title>Reconciling reinforcement learning models with behavioral extinction and renewal: Implications for addiction, relapse, and problem gambling.</article-title>             <source>Psychol Rev</source>             <volume>114</volume>             <fpage>784</fpage>             <lpage>805</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Sethuraman1">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sethuraman</surname><given-names>J</given-names></name></person-group>             <year>1994</year>             <article-title>A constructive definition of Dirichlet priors.</article-title>             <source>Statistica Sinica</source>             <volume>4</volume>             <fpage>639</fpage>             <lpage>650</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Teh2">
        <label>45</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Teh</surname><given-names>Y</given-names></name></person-group>             <year>2010</year>             <article-title>Dirichlet Processes.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Sammut</surname><given-names>CW</given-names></name><name name-style="western"><surname>Geoffrey</surname><given-names>I</given-names></name></person-group>             <source>Encyclopedia of Machine Learning</source>             <publisher-name>Springer</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Blackwell1">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Blackwell</surname><given-names>D</given-names></name><name name-style="western"><surname>MacQueen</surname><given-names>JB</given-names></name></person-group>             <year>1973</year>             <article-title>Ferguson distributions via Polya urn schemes.</article-title>             <source>Ann Stat</source>             <volume>1</volume>             <fpage>353</fpage>             <lpage>355</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Neal1">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Neal</surname><given-names>RM</given-names></name></person-group>             <year>2000</year>             <article-title>Markov chain sampling methods for Dirichlet process mixture models.</article-title>             <source>J Comput Graph Stat</source>             <volume>9</volume>             <fpage>249</fpage>             <lpage>265</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Escobar1">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Escobar</surname><given-names>MD</given-names></name><name name-style="western"><surname>West</surname><given-names>M</given-names></name></person-group>             <year>1995</year>             <article-title>Bayesian density estimation and inference using mixtures.</article-title>             <source>J Am Stat Assoc</source>             <volume>90</volume>             <fpage>577</fpage>             <lpage>588</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Gelman1">
        <label>49</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gelman</surname><given-names>A</given-names></name></person-group>             <year>2004</year>             <article-title>Bayesian data analysis.</article-title>             <comment>Florida. CRC press</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Daw1">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name><name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Seymour</surname><given-names>B</given-names></name><name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name></person-group>             <year>2006</year>             <article-title>Cortical substrates for exploratory decisions in humans.</article-title>             <source>Nature</source>             <volume>441</volume>             <fpage>876</fpage>             <lpage>879</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Kakade1">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kakade</surname><given-names>S</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name></person-group>             <year>2002</year>             <article-title>Dopamine: generalization and bonuses.</article-title>             <source>Neural Netw</source>             <volume>15</volume>             <fpage>549</fpage>             <lpage>559</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Dayan2">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Niv</surname><given-names>Y</given-names></name><name name-style="western"><surname>Seymour</surname><given-names>B</given-names></name><name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name></person-group>             <year>2006</year>             <article-title>The misbehavior of value and the discipline of the will.</article-title>             <source>Neural Netw</source>             <volume>19</volume>             <fpage>1153</fpage>             <lpage>1160</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-ODoherty1">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name><name name-style="western"><surname>Hampton</surname><given-names>A</given-names></name><name name-style="western"><surname>Kim</surname><given-names>H</given-names></name></person-group>             <year>2007</year>             <article-title>Model-based fMRI and its application to reward learning and decision making.</article-title>             <source>Ann N Y Acad Sci</source>             <volume>1104</volume>             <fpage>35</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Dobson1">
        <label>54</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dobson</surname><given-names>AJ</given-names></name></person-group>             <year>2002</year>             <article-title>An introduction to generalized linear models.</article-title>             <comment>CRC Pr I Llc</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-TzourioMazoyer1">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tzourio-Mazoyer</surname><given-names>N</given-names></name><name name-style="western"><surname>Landeau</surname><given-names>B</given-names></name><name name-style="western"><surname>Papathanassiou</surname><given-names>D</given-names></name><name name-style="western"><surname>Crivello</surname><given-names>F</given-names></name><name name-style="western"><surname>Etard</surname><given-names>O</given-names></name><etal/></person-group>             <year>2002</year>             <article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain.</article-title>             <source>NeuroImage</source>             <volume>15</volume>             <fpage>273</fpage>             <lpage>289</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Friston1">
        <label>56</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Holmes</surname><given-names>A</given-names></name><name name-style="western"><surname>Poline</surname><given-names>JB</given-names></name><name name-style="western"><surname>Price</surname><given-names>CJ</given-names></name><name name-style="western"><surname>Frith</surname><given-names>CD</given-names></name></person-group>             <year>1996</year>             <article-title>Detecting activations in PET and fMRI: Levels of inference and power.</article-title>             <source>NeuroImage</source>             <volume>4</volume>             <fpage>223</fpage>             <lpage>235</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-VanniMercier1">
        <label>57</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Vanni-Mercier</surname><given-names>G</given-names></name><name name-style="western"><surname>Mauguiere</surname><given-names>F</given-names></name><name name-style="western"><surname>Isnard</surname><given-names>J</given-names></name><name name-style="western"><surname>Dreher</surname><given-names>JC</given-names></name></person-group>             <year>2009</year>             <article-title>The Hippocampus Codes the Uncertainty of Cue-Outcome Associations: An Intracranial Electrophysiological Study in Humans.</article-title>             <source>J Neurosci</source>             <volume>29</volume>             <fpage>5287</fpage>             <lpage>5294</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-denOuden1">
        <label>58</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>den Ouden</surname><given-names>HEM</given-names></name><name name-style="western"><surname>Daunizeau</surname><given-names>J</given-names></name><name name-style="western"><surname>Roiser</surname><given-names>J</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name></person-group>             <year>2010</year>             <article-title>Striatal prediction error modulates cortical coupling.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>3210</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Hasselmo1">
        <label>59</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group>             <year>1995</year>             <article-title>Neuromodulation and cortical function - modeling the physiological basis of behaviour.</article-title>             <source>Behav Brain Res</source>             <volume>67</volume>             <fpage>1</fpage>             <lpage>27</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Dayan3">
        <label>60</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Niv</surname><given-names>Y</given-names></name></person-group>             <year>2008</year>             <article-title>Reinforcement learning: The Good, The Bad and The Ugly.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>18</volume>             <fpage>185</fpage>             <lpage>196</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Cahill1">
        <label>61</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cahill</surname><given-names>L</given-names></name><name name-style="western"><surname>Weinberger</surname><given-names>NM</given-names></name><name name-style="western"><surname>Roozendaal</surname><given-names>B</given-names></name><name name-style="western"><surname>McGaugh</surname><given-names>JL</given-names></name></person-group>             <year>1999</year>             <article-title>Is the amygdala a locus of “conditioned fear”? Some questions and caveats.</article-title>             <source>Neuron</source>             <volume>23</volume>             <fpage>227</fpage>             <lpage>228</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Prvost1">
        <label>62</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Prévost</surname><given-names>C</given-names></name><name name-style="western"><surname>McCabe</surname><given-names>JA</given-names></name><name name-style="western"><surname>Jessup</surname><given-names>RK</given-names></name><name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name><name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name></person-group>             <year>2011</year>             <article-title>Differentiable contributions of human amygdalar subregions in the computations underlying reward and avoidance learning.</article-title>             <source>Eur J Neurosci</source>             <volume>34</volume>             <fpage>134</fpage>             <lpage>145</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Mackintosh1">
        <label>63</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mackintosh</surname><given-names>NJ</given-names></name></person-group>             <year>1983</year>             <source>Conditioning and associative learning</source>             <publisher-loc>Oxford</publisher-loc>             <publisher-name>Clarendon Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Pearce1">
        <label>64</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pearce</surname><given-names>JM</given-names></name><name name-style="western"><surname>Hall</surname><given-names>G</given-names></name></person-group>             <year>1980</year>             <article-title>A model for Pavlovian learning: Variations in the effectiveness of conditioned but not of unconditioned stimuli.</article-title>             <source>Psychol Rev</source>             <volume>87</volume>             <fpage>532</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Sutton2">
        <label>65</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sutton</surname><given-names>RS</given-names></name></person-group>             <year>1992</year>             <article-title>Gain adaptation beats least squares.</article-title>             <fpage>161</fpage>             <lpage>166</lpage>             <comment>Citeseer</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Foraker1">
        <label>66</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Foraker</surname><given-names>S</given-names></name><name name-style="western"><surname>Regier</surname><given-names>T</given-names></name><name name-style="western"><surname>Khetarpal</surname><given-names>N</given-names></name><name name-style="western"><surname>Perfors</surname><given-names>A</given-names></name><name name-style="western"><surname>Tenenbaum</surname><given-names>J</given-names></name></person-group>             <year>2009</year>             <article-title>Indirect Evidence and the Poverty of the Stimulus: The Case of Anaphoric One.</article-title>             <source>Cogn Sci</source>             <volume>33</volume>             <fpage>287</fpage>             <lpage>300</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002346-Huys2">
        <label>67</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Huys</surname><given-names>QJM</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name></person-group>             <year>2009</year>             <article-title>A Bayesian formulation of behavioral control.</article-title>             <source>Cognition</source>             <volume>113</volume>             <fpage>314</fpage>             <lpage>328</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>
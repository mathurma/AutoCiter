<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-12-01779</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003015</article-id>
    <article-categories><subj-group subj-group-type="heading"><subject>Perspective</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Neuroscience</subject><subj-group><subject>Behavioral neuroscience</subject>
        <subj-group><subject>Cognitive neurosciencee</subject> </subj-group> </subj-group> </subj-group></article-categories>
<title-group>
<article-title>A Healthy Fear of the Unknown: Perspectives on the Interpretation of Parameter Fits from Computational Models in Neuroscience</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Nassar</surname><given-names>Matthew R.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Gold</surname><given-names>Joshua I.</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><addr-line>Department of Neuroscience, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Indiana University, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">jigold@mail.med.upenn.edu</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>4</month><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>4</day><month>4</month><year>2013</year></pub-date>
<volume>9</volume>
<issue>4</issue>
<elocation-id>e1003015</elocation-id><permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Nassar, Gold</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Fitting models to behavior is commonly used to infer the latent computational factors responsible for generating behavior. However, the complexity of many behaviors can handicap the interpretation of such models. Here we provide perspectives on problems that can arise when interpreting parameter fits from models that provide incomplete descriptions of behavior. We illustrate these problems by fitting commonly used and neurophysiologically motivated reinforcement-learning models to simulated behavioral data sets from learning tasks. These model fits can pass a host of standard goodness-of-fit tests and other model-selection diagnostics even when the models do not provide a complete description of the behavioral data. We show that such incomplete models can be misleading by yielding biased estimates of the parameters explicitly included in the models. This problem is particularly pernicious when the neglected factors are unknown and therefore not easily identified by model comparisons and similar methods. An obvious conclusion is that a parsimonious description of behavioral data does not necessarily imply an accurate description of the underlying computations. Moreover, general goodness-of-fit measures are not a strong basis to support claims that a particular model can provide a generalized understanding of the computations that govern behavior. To help overcome these challenges, we advocate the design of tasks that provide direct reports of the computational variables of interest. Such direct reports complement model-fitting approaches by providing a more complete, albeit possibly more task-specific, representation of the factors that drive behavior. Computational models then provide a means to connect such task-specific results to a more general algorithmic understanding of the brain.</p>
</abstract>
<funding-group><funding-statement>This work was supported by NIH EY015260 and MH098899, the McKnight Endowment Fund for Neuroscience, the Burroughs-Wellcome Fund, the Sloan Foundation, and a Ruth L. Kirschstein National Research Service Award MH093099 (MN). The funders had no role in the preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="6"/></counts></article-meta>
</front>
<body>
<p>The use of models to infer the neural computations that underlie behavior is becoming increasingly common in neuroscience research, especially for cognitive and perceptual tasks involving decision making and learning. As their sophistication and usefulness expand, these models become increasingly central to the design, analysis, and interpretation of experiments. We consider this development to be generally positive but provide here some perspectives on the challenges inherent to this approach, particularly when behavior might be driven by unexpected factors that can complicate the interpretation of model fits. Our goal is to raise awareness of these issues and present complementary approaches that can help ensure that our understanding of the brain does not become overly conditioned to the quality of existing models fit to particular data sets.</p>
<p>We illustrate these challenges using a set of models that describe the ongoing process of learning values to guide actions and that are used extensively in the field of cognitive neuroscience <xref ref-type="bibr" rid="pcbi.1003015-Beeler1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1003015-Luksys1">[13]</xref>. These models adjust expectations about future outcomes according to the difference between actual and predicted outcomes, known as the prediction error. Originally developed in parallel in both animal- and machine-learning fields <xref ref-type="bibr" rid="pcbi.1003015-Rescorla1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1003015-Bertsekas1">[16]</xref>, this relatively simple form of reinforcement-learning algorithm (often referred to as a “delta rule” because the prediction error is typically represented by the Greek symbol delta (<italic>∂</italic>) in the equations) has: 1) provided efficient solutions to a broad array of biologically relevant problems <xref ref-type="bibr" rid="pcbi.1003015-Sutton1">[15]</xref>; 2) accounted for many, but not all, learning phenomena exhibited by both human and nonhuman subjects <xref ref-type="bibr" rid="pcbi.1003015-Dayan1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1003015-Shanks1">[18]</xref>; 3) provided a generative architecture that has been used to predict behavior across tasks, compare brain activity to learning variables within a single task, and explore the range of possible behaviors that one might expect to find in a variable population <xref ref-type="bibr" rid="pcbi.1003015-Miller1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003015-Dayan2">[20]</xref>; and 4) guided an understanding of the neural computations expressed by the brainstem dopaminergic system <xref ref-type="bibr" rid="pcbi.1003015-Schultz1">[21]</xref>. These successes have led to the proposal that the interpretation of delta-rule model parameters fit to behavioral data from human subjects performing simple learning tasks might serve as a more precise diagnostic tool for certain mental disorders than existing methods <xref ref-type="bibr" rid="pcbi.1003015-Huys1">[22]</xref>–<xref ref-type="bibr" rid="pcbi.1003015-Maia1">[24]</xref>. Thus reinforcement-learning models are becoming highly influential in guiding and filtering our understanding of normal and pathological brain function.</p>
<p>Here we focus on the interpretation of a term in most delta-rule models called the learning rate. The learning rate, α, determines the amount of influence that the prediction error, δ, associated with a given outcome has on the new expectation of future outcomes, E:<disp-formula id="pcbi.1003015.e001"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003015.e001" xlink:type="simple"/><label>(EQ 1)</label></disp-formula>As its name implies, the learning rate determines how quickly the model adapts to errors. A fixed value near zero implies that expectations are updated slowly, essentially averaging over a long history of past outcomes. In contrast, a fixed value near one implies that expectations are updated quickly to match the most recent outcomes. Thus, the learning rate can be interpreted as the amount of influence each unpredicted outcome exerts on the subsequent expectation. These updated expectations can, in turn, be used to select actions, often through a soft-max function with an inverse-temperature parameter. This parameter can be adjusted to optimize the trade-off between exploiting actions known to be valuable in the present (emphasized at higher inverse temperatures) and exploring actions that might be valuable in the future (emphasized at lower inverse temperatures) <xref ref-type="bibr" rid="pcbi.1003015-Daw1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1003015-Luksys1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1003015-Sutton1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003015-Ishii1">[25]</xref>.</p>
<p>Recent work has highlighted the advantages of using learning rates that, instead of remaining fixed, are adjusted adaptively according to environmental dynamics <xref ref-type="bibr" rid="pcbi.1003015-Nassar1">[9]</xref>–<xref ref-type="bibr" rid="pcbi.1003015-Krugel1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003015-Yu1">[26]</xref>–<xref ref-type="bibr" rid="pcbi.1003015-Preuschoff1">[28]</xref>. For example, adaptive learning rates can help ensure that expectations remain relatively stable in stationary environments but change rapidly in response to abrupt environmental changes. Consistent with this idea, human behavior in tasks containing abrupt changes conforms to models in which the influence of each outcome depends on the statistics of other recent outcomes. Such rational adjustments of learning rate are most prominent after changes in action-outcome contingencies that lead to surprisingly large prediction errors <xref ref-type="bibr" rid="pcbi.1003015-Nassar1">[9]</xref>–<xref ref-type="bibr" rid="pcbi.1003015-Krugel1">[11]</xref>.</p>
<p>Here we consider in detail two of these change-point tasks. The first, an estimation task, requires subjects to predict the next in a series of outcomes (randomly generated numbers) <xref ref-type="bibr" rid="pcbi.1003015-Nassar1">[9]</xref>. Each outcome is drawn from a normal distribution with a fixed mean and variance. However, the mean of this distribution is occasionally reset at random times, producing abrupt change-points in the series of outcomes. Learning rates can be measured directly on a trial-by-trial basis, using predictions and outcomes plugged into <xref ref-type="disp-formula" rid="pcbi.1003015.e001">Eq. 1</xref>. Previous work showed that subjects performing this task tended to use learning rates that were consistent with predictions from a reduced form of a Bayesian ideal-observer algorithm, including a positive relationship between error magnitude and learning rate. However, the details of this relationship varied considerably across individual subjects. Some subjects tended to use highly adaptive learning rates, including values near zero following small errors and values near one following surprisingly large prediction errors. In contrast, other subjects used a much narrower range of learning rates, choosing similar values over most conditions. This across-subject variability was described by a flexible model that could generate behaviors ranging from that of a fixed learning-rate delta rule to that of the reduced Bayesian algorithm, depending on the value of a learning rate “adaptiveness” parameter.</p>
<p>The second task is a four-alternative forced-choice task that includes occasional, unsignaled change-points in the probabilistic associations of monetary rewards for each choice target <xref ref-type="bibr" rid="pcbi.1003015-Krugel1">[11]</xref>. Learning rates are not measured directly, as in the estimation task, but rather inferred from model fits. The best-fitting models incorporate learning rates that increase transiently after unexpectedly large errors, although the magnitude of this increase differs across subjects. The existence of this kind of across-subject variability can have dramatic effects on the interpretation of best-fitting parameters from models that do not account for this variability explicitly. Here we illustrate this problem by fitting behavioral data corresponding to different forms of adaptive learning with delta-rule models that neglect adaptive learning entirely. However, we emphasize that this problem is not limited to adaptive learning but can also arise when neglecting other factors that can influence performance on learning tasks, such as a tendency to repeat choices <xref ref-type="bibr" rid="pcbi.1003015-Lau1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1003015-Schnberg1">[30]</xref>, and more generally whenever oversimplified models are fit to complex behavioral data.</p>
<p>We used simulations of the two tasks to illustrate how fitting models with fixed learning rates to behavior that is based on adaptive learning rates can lead to misleading conclusions. For each task, behavioral data were simulated using a delta-rule inference algorithm with different levels of learning-rate adaptiveness coupled with a soft-max function for action selection. These simulated data were then fit, using maximum-likelihood methods, with a simpler model that included two free parameters: a fixed learning rate and the inverse temperature of a soft-max action-selection process (see <xref ref-type="supplementary-material" rid="pcbi.1003015.s001">Text S1</xref>). In all cases, the simpler, fixed learning-rate model was preferred over a null model constituting random choice behavior, even after penalizing for additional complexity (e.g., using BIC or AIC; see <xref ref-type="supplementary-material" rid="pcbi.1003015.s001">Text S1</xref>). Despite passing these model-selection criteria, we highlight two misleading conclusions that might be drawn from these fits: biased estimates of adaptive learning and of exploratory behavior.</p>
<p>The problem of misestimating adaptive learning is depicted in <xref ref-type="fig" rid="pcbi-1003015-g001">Figure 1A &amp; B</xref>. Panel A shows simulations based on the estimation task. For this task, learning rate is measured directly as the proportion of the current prediction error used to update from the current prediction to the next prediction <xref ref-type="bibr" rid="pcbi.1003015-Nassar1">[9]</xref>. As expected, variability in measured learning rates tended to increase with learning-rate adaptiveness. The average value of measured learning rates also tended to decrease with learning-rate adaptiveness, because change-points that dictate high values of adaptive learning rates were relatively rare in our simulated tasks (black circles and error bars reflect median and interquartile range, respectively, across 800 simulated trials).</p>
<fig id="pcbi-1003015-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003015.g001</object-id><label>Figure 1</label><caption>
<title>Learning-rate adaptiveness can be misinterpreted as elevated fixed learning rates and decreased inverse temperatures for the estimation (A,C) or four-alternative (B,D) tasks (see text).</title>
<p>In all panels, the abscissa represents learning-rate adaptiveness (0 is equivalent to using a fixed learning rate; higher numbers indicate higher adaptiveness to unexpected errors). A &amp; B. Actual (black) and model-inferred (gray) learning rates used by agents with different levels of learning-rate adaptiveness. Points and error bars represent the median and interquartile range, respectively, of data from six simulated sessions. C &amp; D. Best-fitting values of the inverse-temperature parameter, intended to describe exploratory behavior, inferred using a fixed delta-rule (circles) or approximately Bayesian (squares) model. Shades of gray indicate the level of exploratory behavior of the simulated agent, as indicated. Arrows indicate the actual value of the inverse-temperature parameter used in the generative process. Points and error bars (obscured) represent the mean and standard error of the mean, respectively, of data from six simulated sessions.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003015.g001" position="float" xlink:type="simple"/></fig>
<p>The model fits, however, tell a different story. When behavior was simulated using a fixed learning rate (learning-rate adaptiveness = 0), the best-fitting models naturally captured the appropriate value. However, when behavior was simulated using increasingly adaptive learning rates, the fixed learning-rate models returned systematically larger estimates of learning rate than were actually used by the simulated subjects (<xref ref-type="fig" rid="pcbi-1003015-g001">Figure 1A</xref>, gray points).</p>
<p>Panel B shows simulations based on the four-choice task, for which we determined the learning rate on each trial based on its value in the internal, generative process used in the simulations. Data from this task tell a similar story. Simulated learning rates were lower but more variable for more adaptive models (black circles and error bars reflect median and interquartile range), yet fit learning rates were higher for these same models (<xref ref-type="fig" rid="pcbi-1003015-g001">Figure 1B</xref>, gray points). These data suggest that periods of rapid learning (i.e., following change-points) are more influential than periods of slow learning on maximum-likelihood fits of the fixed learning-rate parameter, which thus becomes biased upwards when the underlying learning rate is adaptive.</p>
<p>The problem of misestimating exploratory behavior is depicted in <xref ref-type="fig" rid="pcbi-1003015-g001">Figure 1C &amp; D</xref>. We first simulated behavior on both the estimation task and the four-choice task using a fixed learning rate and an action-selection process governed by an inverse-temperature parameter. In each case, fits from a model with a fixed learning rate and an inverse-temperature process returned appropriate estimates of the inverse temperature used in the generative process (left-most circles in <xref ref-type="fig" rid="pcbi-1003015-g001">Figure 1C &amp; D</xref>, corresponding to learning-rate adaptiveness = 0).</p>
<p>However, when the simulated subjects used increasingly adaptive learning rates, inverse-temperature fits from a fixed learning-rate model substantially overestimated the true variability in action selection (circles in <xref ref-type="fig" rid="pcbi-1003015-g001">Figure 1C &amp; D</xref>: inferred inverse temperature decreases as learning-rate adaptiveness increases). Such biased parameter estimates were not simply a problem with the fixed learning-rate model. Fitting an alternative model that used optimal (maximally adaptive) learning rates <xref ref-type="bibr" rid="pcbi.1003015-Nassar1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1003015-Wilson1">[31]</xref> to the behavior of the same simulated subjects yielded a complementary pattern of biases: the model accurately inferred the level of exploratory action selection for simulated subjects that choose learning rates adaptively but overestimated this quantity for subjects that used simpler strategies of less-adaptive, or even fixed, learning rates (squares in <xref ref-type="fig" rid="pcbi-1003015-g001">Figure 1C</xref>: inferred inverse temperature decreases as learning-rate adaptiveness decreases). For both models, these problems were not apparent from standard analyses of best-fitting parameter values, which had similar confidence intervals and covariance estimates for biased and unbiased fit conditions (see <xref ref-type="supplementary-material" rid="pcbi.1003015.s001">Text S1</xref>). These problems also did not simply reflect difficulties in estimating model parameters when the inverse temperature was low and behavior was more random, because the problem was also apparent when the inverse temperature was high. Thus, subtle differences in learning that were not accounted for by the inference model caused underestimation of the inverse-temperature parameter, which might be misinterpreted as increases in exploratory action selection.</p>
<p>Diagnosing these kinds of problems is difficult, especially when the subtle aspect of behavior that is missing from the model is unknown. Model-selection practices that compare likelihoods of various models (after either cross validation or penalization of parameter numbers) are useful for identifying the better of two or more models with respect to particular data sets. However, these practices require a priori knowledge of the models to be tested and cannot, by themselves, indicate what might be missing from the tested models. One might be tempted to interpret likelihoods directly and set a criterion for what might be considered a “good” model. However, these metrics cannot say whether or not a model is correct (or even sufficiently good, given that no fit model is truly correct). For example, consider a test of the suitability of a fixed learning-rate model for simulated subjects that can vary in terms of learning-rate adaptiveness and exploratory behavior. Similar values of AIC, BIC, and other likelihood-based quantities are obtained for fixed delta-rule models fit to two very different subjects: one who uses a fixed learning rate, which is consistent with the model, and relatively high exploration; and another who uses a highly adaptive learning rate, which is inconsistent with the model, and relatively low exploration. Interpretation of parameter fits from the latter case would be misleading, whereas parameter fits from the former would be asymptotically unbiased and thus more informative.</p>
<p>To overcome these limitations, it is sometimes effective to look for indications that a model is failing under specific sets of conditions for which behavior is heavily influenced by the assumptions of the model. For the case of adaptive learning, fixed learning-rate models fail to address adaptive responses to inferred change-points in the action-outcome contingency. Thus, it can be instructive to examine the likelihoods of these models computed for choice data collected shortly after change-points. For the case of the estimation task, a fixed learning-rate model shows an obvious inability to account for data from trials just after a change-point for all but the least adaptive simulated subjects (<xref ref-type="fig" rid="pcbi-1003015-g002">Figure 2A</xref>; dip in log-likelihood at trial 1). However, this approach is not effective for the four-choice task (<xref ref-type="fig" rid="pcbi-1003015-g002">Figure 2B</xref>).</p>
<fig id="pcbi-1003015-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003015.g002</object-id><label>Figure 2</label><caption>
<title>Poor fits from models that ignore learning-rate adaptiveness are easily identified in the estimation, but not the four-choice, task.</title>
<p>A &amp; B. Mean log-likelihood associated with a fixed learning-rate model, per simulated trial from the estimation (A) or four-choice (B) task, aligned to change-points in the generative process. Lighter shades of gray represent data from simulated agents with higher levels of learning-rate adaptiveness. C–F. Learning rates (C &amp; D) or inverse temperatures (E &amp; F) inferred from model fits that exclude log-likelihood information from trials occurring 0–10 trials after change-points (abscissa) for estimation (C &amp; E) and four-choice (D &amp; F) tasks. The transient changes in A, C, and E evident for all but the least adaptive simulated agents reflect the fixed learning-rate model's inability to account for behavior just following change-points on the estimation task; no comparable effects are evident for the four-choice task.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003015.g002" position="float" xlink:type="simple"/></fig>
<p>Another potentially useful approach for diagnosing misleading parameter fits is to compute these fits using subsets of data that might correspond to different best-fitting values of certain parameters. For the estimation task, eliminating data from trials immediately following change-points has dramatic effects on fits for both learning rate (<xref ref-type="fig" rid="pcbi-1003015-g002">Figure 2C</xref>) and inverse temperature (<xref ref-type="fig" rid="pcbi-1003015-g002">Figure 2E</xref>). However, this diagnostic approach is far less effective for the four-choice task, for which adjustments in learning rate occur with a longer and more variable time course following change-points (<xref ref-type="fig" rid="pcbi-1003015-g002">Figure 2D &amp; F</xref>). Thus, for tasks like the estimation task that provide explicit information about the subject's underlying expectations, the insufficiency of the fixed learning-rate model can be fairly simple to diagnose. However, for tasks like the four-choice task in which information about the subject's expectations is limited to inferences based on less-informative choice behavior, parameter biases are still large (<xref ref-type="fig" rid="pcbi-1003015-g001">Figure 1B &amp; D</xref>), but model insufficiency is far less apparent.</p>
<p>A sobering conclusion that can be drawn from these examples is that even when the parameter fits from a computational model are reasonably likely to produce a data set, and even when this likelihood is robust to perturbations in the specific trials that are fit or the settings of other parameters in the model, the model might still be missing specific features of the data. Missing even a fairly nuanced feature of the data (such as adaptive learning) can lead the parameters in the model to account for the feature in surprising ways. These unexpected influences can lead to parameter fits that, if interpreted naïvely, might suggest computational relationships that are unrelated to, or even opposite to, the true underlying relationships. Here we use an example from reinforcement learning, but the lessons apply to any model-fitting procedure that requires the interpretation of best-fitting parameter values. Certain parameters, like the inverse-temperature parameter in reinforcement-learning models, are particularly susceptible to this problem, because they are always sensitive to other sources of behavioral variability that are incompletely described by the rest of the model.</p>
<p>These challenges highlight the narrow wire on which the computational neuroscientist walks. On one hand, we seek to generalize a wide array of physiological and behavioral data from different tasks onto a tractable set of computational principles. On the other hand, the results that we obtain from each experiment are conditioned on assumptions from the particular model through which they are obtained. We believe that the goals of computational neuroscience are possible even in the face of this contradiction. Obtaining generalizable results depends on not only good modeling practices <xref ref-type="bibr" rid="pcbi.1003015-Daw2">[32]</xref> but also the extensive use of descriptive statistics to dissect and interpret data from both experiments and simulated model data. For example, the estimation task described above was designed to allow learning rates from individual trials to be computed directly and not inferred via model fits to resulting choice behaviors. This approach revealed clear task-dependent effects on adaptive learning <xref ref-type="bibr" rid="pcbi.1003015-Nassar1">[9]</xref>. In principle, congruence between these kinds of direct analyses of behavioral data and fit model parameters can help support interpretations of those parameters and has the advantage of testing modeling assumptions and predictions explicitly rather than via comparisons of different model sets <xref ref-type="bibr" rid="pcbi.1003015-Walton1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003015-Ding1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1003015-Frank2">[34]</xref>. In contrast, inconsistencies between direct analyses and fit model parameters can help guide how the model can be modified or expanded—keeping in mind, of course, that adding to a model's complexity can improve its overall fit to the data but often by overfitting to specious features of the data and making it more difficult to interpret the contributions of individual parameters <xref ref-type="bibr" rid="pcbi.1003015-Pitt1">[35]</xref>.</p>
<p>In summary, model fits to behavioral data can provide useful and important insights into the neurocomputational principles underlying such behavior but should not replace good experimental designs that explicitly isolate, manipulate, and/or measure the behavioral processes of interest. Combining such designs with both model fitting and other kinds of analyses can support steady progress in attaining a more general understanding of the neural basis for complex behaviors that is not overly tied to a particular model or behavioral test.</p>
<sec id="s2">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003015.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pcbi.1003015.s001" position="float" xlink:type="simple"><label>Text S1</label><caption>
<p>Provides methods for simulations and model fitting as well as Bayesian information criterion values for each set of models.</p>
<p>(DOCX)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We thank David Brainard, Peter Dayan, Long Ding, Yin Li, Mike Shadlen, Michael Todd, Takahiro Doi, and Robert Wilson for helpful comments.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003015-Beeler1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beeler</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Frazier</surname><given-names>CRM</given-names></name>, <name name-style="western"><surname>Zhuang</surname><given-names>X</given-names></name> (<year>2010</year>) <article-title>Tonic dopamine modulates exploitation of reward learning</article-title>. <source>Front Behav Neurosci</source> <volume>4</volume>: <fpage>170</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Doll1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doll</surname><given-names>BB</given-names></name>, <name name-style="western"><surname>Hutchison</surname><given-names>KE</given-names></name>, <name name-style="western"><surname>Frank</surname><given-names>MJ</given-names></name> (<year>2011</year>) <article-title>Dopaminergic genes predict individual differences in susceptibility to confirmation bias</article-title>. <source>J Neurosci</source> <volume>31</volume>: <fpage>6188</fpage>–<lpage>6198</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Frank1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Frank</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Doll</surname><given-names>BB</given-names></name>, <name name-style="western"><surname>Oas-Terpstra</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Moreno</surname><given-names>F</given-names></name> (<year>2009</year>) <article-title>Prefrontal and striatal dopaminergic genes predict individual differences in exploration and exploitation</article-title>. <source>Nat Neurosci</source> <volume>12</volume>: <fpage>1062</fpage>–<lpage>1068</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Jepma1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jepma</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Nieuwenhuis</surname><given-names>S</given-names></name> (<year>2011</year>) <article-title>Pupil diameter predicts changes in the exploration-exploitation trade-off: evidence for the adaptive gain theory</article-title>. <source>J Cogn Neurosci</source> <volume>23</volume>: <fpage>1587</fpage>–<lpage>1596</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Seo1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Seo</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>D</given-names></name> (<year>2008</year>) <article-title>Cortical mechanisms for reinforcement learning in competitive games</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>363</volume>: <fpage>3845</fpage>–<lpage>3857</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Strauss1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Strauss</surname><given-names>GP</given-names></name>, <name name-style="western"><surname>Frank</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Waltz</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Kasanova</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Herbener</surname><given-names>ES</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Deficits in positive reinforcement learning and uncertainty-driven exploration are associated with distinct aspects of negative symptoms in schizophrenia</article-title>. <source>Biol Psychiatry</source> <volume>69</volume>: <fpage>424</fpage>–<lpage>431</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Sul1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sul</surname><given-names>JH</given-names></name>, <name name-style="western"><surname>Jo</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Jung</surname><given-names>MW</given-names></name> (<year>2011</year>) <article-title>Role of rodent secondary motor cortex in value-based action selection</article-title>. <source>Nat Neurosci</source> <volume>14</volume>: <fpage>1202</fpage>–<lpage>1208</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Walton1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Walton</surname><given-names>ME</given-names></name>, <name name-style="western"><surname>Behrens</surname><given-names>TEJ</given-names></name>, <name name-style="western"><surname>Buckley</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Rudebeck</surname><given-names>PH</given-names></name>, <name name-style="western"><surname>Rushworth</surname><given-names>MFS</given-names></name> (<year>2010</year>) <article-title>Separable learning systems in the macaque brain and the role of orbitofrontal cortex in contingent learning</article-title>. <source>Neuron</source> <volume>65</volume>: <fpage>927</fpage>–<lpage>939</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Nassar1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nassar</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>RC</given-names></name>, <name name-style="western"><surname>Heasly</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Gold</surname><given-names>JI</given-names></name> (<year>2010</year>) <article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title>. <source>J Neurosci</source> <volume>30</volume>: <fpage>12366</fpage>–<lpage>12378</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Behrens1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Behrens</surname><given-names>TE</given-names></name>, <name name-style="western"><surname>Woolrich</surname><given-names>MW</given-names></name>, <name name-style="western"><surname>Walton</surname><given-names>ME</given-names></name>, <name name-style="western"><surname>Rushworth</surname><given-names>MF</given-names></name> (<year>2007</year>) <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source> <volume>10</volume>: <fpage>1214</fpage>–<lpage>1221</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Krugel1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krugel</surname><given-names>LK</given-names></name>, <name name-style="western"><surname>Biele</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Mohr</surname><given-names>PNC</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>S-C</given-names></name>, <name name-style="western"><surname>Heekeren</surname><given-names>HR</given-names></name> (<year>2009</year>) <article-title>Genetic variation in dopaminergic neuromodulation influences the ability to rapidly and flexibly adapt decisions</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>106</volume>: <fpage>17951</fpage>–<lpage>17956</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Daw1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Seymour</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name> (<year>2006</year>) <article-title>Cortical substrates for exploratory decisions in humans</article-title>. <source>Nature</source> <volume>441</volume>: <fpage>876</fpage>–<lpage>879</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Luksys1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Luksys</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Sandi</surname><given-names>C</given-names></name> (<year>2009</year>) <article-title>Stress, genotype and norepinephrine in the prediction of mouse behavior using reinforcement learning</article-title>. <source>Nat Neurosci</source> <volume>12</volume>: <fpage>1180</fpage>–<lpage>1186</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Rescorla1"><label>14</label>
<mixed-citation publication-type="book" xlink:type="simple">Rescorla RA, Wagner AR (1972) A theory of Pavlovian conditioning: variations in the effectiveness of reinforcement and nonreinforcement. In: Black AH, Prokasy WF, editors. Classical conditioning II: current research and theory. New York: Appleton-Century-Crofts. pp. 64–99.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Sutton1"><label>15</label>
<mixed-citation publication-type="book" xlink:type="simple">Sutton RS, Barto AG (1998) Reinforcement learning: an introduction. Cambridge (Massachusetts): MIT Press. 342 p.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Bertsekas1"><label>16</label>
<mixed-citation publication-type="book" xlink:type="simple">Bertsekas DP, Tsitsiklis JN (1996) Neuro-dynamic programming. Belmont (Massachusetts): Athena Scientific. 512 p.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Dayan1"><label>17</label>
<mixed-citation publication-type="book" xlink:type="simple">Dayan P, Abbott LF (2001) Theoretical neuroscience. Cambridge (Massachusetts): MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Shanks1"><label>18</label>
<mixed-citation publication-type="book" xlink:type="simple">Shanks DR (1995) The psychology of associative learning (problems in the behavioral sciences). Gray J, editor. Cambridge: Cambridge University Press. 194 p.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Miller1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname><given-names>RR</given-names></name>, <name name-style="western"><surname>Barnet</surname><given-names>RC</given-names></name>, <name name-style="western"><surname>Grahame</surname><given-names>NJ</given-names></name> (<year>1995</year>) <article-title>Assessment of the Rescorla-Wagner model</article-title>. <source>Psychol Bull</source> <volume>117</volume>: <fpage>363</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Dayan2"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>N</given-names></name> (<year>2008</year>) <article-title>Decision theory, reinforcement learning, and the brain</article-title>. <source>Cogn Affect Behav Neurosci</source> <volume>8</volume>: <fpage>429</fpage>–<lpage>453</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Schultz1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Montague</surname><given-names>PR</given-names></name> (<year>1997</year>) <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source> <volume>275</volume>: <fpage>1593</fpage>–<lpage>1599</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Huys1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huys</surname><given-names>QJM</given-names></name>, <name name-style="western"><surname>Moutoussis</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Williams</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Are computational models of any use to psychiatry</article-title>? <source>Neural Netw</source> <volume>24</volume>: <fpage>544</fpage>–<lpage>551</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Huys2"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huys</surname><given-names>Q</given-names></name>, <name name-style="western"><surname>Vogelstein</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name> (<year>2009</year>) <article-title>Psychiatry: insights into depression through normative decision-making models</article-title>. <source>Adv Neural Inf Process Syst</source> <volume>21</volume>: <fpage>729</fpage>–<lpage>736</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Maia1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maia</surname><given-names>TV</given-names></name>, <name name-style="western"><surname>Frank</surname><given-names>MJ</given-names></name> (<year>2011</year>) <article-title>From reinforcement learning models to psychiatric and neurological disorders</article-title>. <source>Nat Neurosci</source> <volume>14</volume>: <fpage>154</fpage>–<lpage>162</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Ishii1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ishii</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Yoshida</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Yoshimoto</surname><given-names>J</given-names></name> (<year>2002</year>) <article-title>Control of exploitation-exploration meta-parameter in reinforcement learning</article-title>. <source>Neural Netw</source> <volume>15</volume>: <fpage>665</fpage>–<lpage>687</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Yu1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yu</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name> (<year>2005</year>) <article-title>Uncertainty, neuromodulation, and attention</article-title>. <source>Neuron</source> <volume>46</volume>: <fpage>681</fpage>–<lpage>692</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Mathys1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mathys</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Daunizeau</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name> (<year>2011</year>) <article-title>A bayesian foundation for individual learning under uncertainty</article-title>. <source>Front Hum Neurosci</source> <volume>5</volume>: <fpage>39</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Preuschoff1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Preuschoff</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name> (<year>2007</year>) <article-title>Adding prediction risk to the theory of reward learning</article-title>. <source>Ann N Y Acad Sci</source> <volume>1104</volume>: <fpage>135</fpage>–<lpage>146</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Lau1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lau</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Glimcher</surname><given-names>PW</given-names></name> (<year>2005</year>) <article-title>Dynamic response-by-response models of matching behavior in rhesus monkeys</article-title>. <source>J Exp Anal Behav</source> <volume>84</volume>: <fpage>555</fpage>–<lpage>579</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Schnberg1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schönberg</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>, <name name-style="western"><surname>Joel</surname><given-names>D</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name> (<year>2007</year>) <article-title>Reinforcement learning signals in the human striatum distinguish learners from nonlearners during reward-based decision making</article-title>. <source>J Neurosci</source> <volume>27</volume>: <fpage>12860</fpage>–<lpage>12867</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Wilson1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilson</surname><given-names>RC</given-names></name>, <name name-style="western"><surname>Nassar</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Gold</surname><given-names>JI</given-names></name> (<year>2010</year>) <article-title>Bayesian online learning of the hazard rate in change-point problems</article-title>. <source>Neural Comput</source> <volume>22</volume>: <fpage>2452</fpage>–<lpage>2476</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Daw2"><label>32</label>
<mixed-citation publication-type="book" xlink:type="simple">Daw ND (2009) Trial-by-trial data analysis using computational models. In: Phelps E, Robbins T, Delgrado M, editors. Decision making, affect, and learning: attention and performance XXIII. Oxford: Oxford University Press. pp. 3–38.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Ding1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ding</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Gold</surname><given-names>JI</given-names></name> (<year>2012</year>) <article-title>Separate, causal roles of the caudate in saccadic choice and execution in a perceptual decision task</article-title>. <source>Neuron</source> <volume>75</volume>: <fpage>865</fpage>–<lpage>874</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Frank2"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Frank</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Seeberger</surname><given-names>LC</given-names></name>, <name name-style="western"><surname>O'Reilly</surname><given-names>RC</given-names></name> (<year>2004</year>) <article-title>By carrot or by stick: cognitive reinforcement learning in parkinsonism</article-title>. <source>Science</source> <volume>306</volume>: <fpage>1940</fpage>–<lpage>1943</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003015-Pitt1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pitt</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Myung</surname><given-names>IJ</given-names></name> (<year>2002</year>) <article-title>When a good fit can be bad</article-title>. <source>Trends Cogn Sci</source> <volume>6</volume>: <fpage>421</fpage>–<lpage>425</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
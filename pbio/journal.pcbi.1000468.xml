<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">09-PLCB-RA-0320R3</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000468</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology/Computational Neuroscience</subject><subject>Neuroscience/Behavioral Neuroscience</subject><subject>Neuroscience/Cognitive Neuroscience</subject><subject>Neuroscience/Motor Systems</subject></subj-group></article-categories><title-group><article-title>Nash Equilibria in Multi-Agent Motor Interactions</article-title><alt-title alt-title-type="running-head">Nash Equilibria in Motor Control</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Braun</surname><given-names>Daniel A.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Ortega</surname><given-names>Pedro A.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Wolpert</surname><given-names>Daniel M.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>Computational and Biological Learning Laboratory, Department of Engineering, University of Cambridge, Cambridge, United Kingdom</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Bernstein Center for Computational Neuroscience, Freiburg, Germany</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>Karl J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">dab54@cam.ac.uk</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: DAB PAO DMW. Performed the experiments: DAB. Analyzed the data: DAB PAO DMW. Wrote the paper: DAB DMW. Designed the figures: PAO.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>8</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>14</day><month>8</month><year>2009</year></pub-date><volume>5</volume><issue>8</issue><elocation-id>e1000468</elocation-id><history>
<date date-type="received"><day>27</day><month>3</month><year>2009</year></date>
<date date-type="accepted"><day>14</day><month>7</month><year>2009</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2009</copyright-year><copyright-holder>Braun et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>Social interactions in classic cognitive games like the ultimatum game or the prisoner's dilemma typically lead to Nash equilibria when multiple competitive decision makers with perfect knowledge select optimal strategies. However, in evolutionary game theory it has been shown that Nash equilibria can also arise as attractors in dynamical systems that can describe, for example, the population dynamics of microorganisms. Similar to such evolutionary dynamics, we find that Nash equilibria arise naturally in motor interactions in which players vie for control and try to minimize effort. When confronted with sensorimotor interaction tasks that correspond to the classical prisoner's dilemma and the rope-pulling game, two-player motor interactions led predominantly to Nash solutions. In contrast, when a single player took both roles, playing the sensorimotor game bimanually, cooperative solutions were found. Our methodology opens up a new avenue for the study of human motor interactions within a game theoretic framework, suggesting that the coupling of motor systems can lead to game theoretic solutions.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>Human motor interactions range from adversarial activities like judo and arm wrestling to more cooperative activities like tandem riding and tango dancing. In this study, we design a new methodology to study human sensorimotor interactions quantitatively based on game theory. We develop two motor tasks based on the prisoner's dilemma and the rope-pulling game in which we introduce an intrinsic cost related to effort rather than the typical monetary outcome used in cognitive game theory. We find that continuous motor interactions converged to game theoretic outcomes similar to the interaction dynamics reported for other dynamical systems in biology ranging in scale from microorganisms to population dynamics.</p>
</abstract><funding-group><funding-statement>This study was supported in parts by the Böhringer-Ingelheim-Fonds (BIF), the Wellcome Trust and the European grant SENSOPAC IST-2005-028056. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="8"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Riding a tandem, tango dancing, arm wrestling and judo are diverse but familiar examples of two-player motor interactions. The characteristic feature of such interactions is that the two players influence each others behavior through coupled sensorimotor control with continuous action spaces over repeated trials or continuously in time. In contrast, two-player interactions considered in classical game theory are typically thought to involve cognition in games with discrete actions and discrete time steps for decision-making such as tic-tac-toe, the ultimatum game or the prisoner's dilemma <xref ref-type="bibr" rid="pcbi.1000468-Fudenberg1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1000468-Shafir1">[8]</xref>. An important concept in such classical games is the <italic>Nash equilibrium solution</italic> <xref ref-type="bibr" rid="pcbi.1000468-Nash1">[9]</xref> in which each player chooses a strategy such that no player has anything to gain by changing only his or her strategy. Nash equilibria can also be defined for continuous games, i.e. games with continuous actions and payoffs <xref ref-type="bibr" rid="pcbi.1000468-Glicksberg1">[10]</xref>–<xref ref-type="bibr" rid="pcbi.1000468-Debreu1">[12]</xref>, and thus might provide a theoretical tool to understand multi-agent sensorimotor interactions. The theory of continuous games can also be used for sequential (dynamic) games where players are interacting continuously over a sequence of time steps <xref ref-type="bibr" rid="pcbi.1000468-Le1">[13]</xref>–<xref ref-type="bibr" rid="pcbi.1000468-Basar1">[15]</xref>. Nash equilibria in such continuous dynamic motor games correspond to (equilibrium) control policies, i.e. feedback rules that map past observations to actions.</p>
<p>Here, we develop continuous sensorimotor versions of the prisoner's dilemma and the rope-pulling game. In the classical prisoner's dilemma <xref ref-type="bibr" rid="pcbi.1000468-Poundstone1">[16]</xref>, two players (prisoners) have a choice (<xref ref-type="fig" rid="pcbi-1000468-g001">Fig. 1A</xref>) between cooperation (claiming the other player is innocent) and defection (claiming the other player is guilty). If both cooperate, they each receive a short sentence (3 years) whereas if both defect they each receive a moderate sentence (7 years). But if one cooperates while the other defects, the defector is freed and the cooperator receives a lengthy sentence (10 years). The globally optimal solution in which the players benefit the most is for both players to cooperate. However, if one of the players decides to defect, the defector reduces their sentence at the expense of the other player. In such a non-cooperative setting the stable Nash solution is for both players to defect. This Nash solution guarantees in this case that a player minimizes their maximum expected punishment (in this case 7 years) and the player does not have to rely on a particular action being chosen by the other player. The dilemma arises because the Nash solution is not identical to the globally optimal solution which is cooperative. The same dilemma occurs also in the rope-pulling game (given as a conceptual example in <xref ref-type="bibr" rid="pcbi.1000468-Basar1">[15]</xref>) where each of two players is attached by a rope to a mass that they have to pull together. One player is rewarded according to how far he pulls the mass along one direction and the other player is reward according to how far he pulls the mass in an orthogonal direction. Thus, the globally optimal solution is to cooperate and pull the mass along the diagonal. However, if one of the players defects and pulls into his own direction he gains even more payoff at the expense of the other player. Therefore, the stable Nash solution in this case is for each player to pull along his own direction. In the following we address the question whether human motor interactions in such motor games can be quantified using a game theoretic framework.</p>
<fig id="pcbi-1000468-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000468.g001</object-id><label>Figure 1</label><caption>
<title>The prisoner's dilemma motor game.</title>
<p>(A) Pay-off matrix for the classical prisoner's dilemma for two players (players denoted by red and blue). Depending on the choice of each player there are four different outcomes in terms of years that each player will serve in prison. (B) The motor version of the prisoner's dilemma. Each player controls a cursor and moves from a starting bar to a target bar and experiences a force that resists forward motion. The force arises from a virtual spring that attaches the handle to the starting bar (the springs are only shown on the schematic and are not visible to the players). The stiffness of the springs (K<sub>1</sub> &amp; K<sub>2</sub>) can vary online and each depends on the x-positions of both players' cursors (x<sub>1</sub> &amp; x<sub>2</sub>). (C) Continuous cost landscape for the motor prisoner's dilemma game. Each pair of x-positions (x<sub>1</sub>, x<sub>2</sub>) corresponds to a spring constant for each player. The corners of the plane correspond to the classical prisoner's dilemma matrix (A) and intermediate spring constants are obtained by linear interpolation. The current spring constants experienced by the players in B are shown by the points on the surface. The game was played by eight pairs of players and by eight individual players bimanually.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000468.g001" xlink:type="simple"/></fig></sec><sec id="s2">
<title>Results</title>
<p>In our continuous sensorimotor version of prisoner's dilemma (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>), two players sat next to each other and grasped the handles of separate robotic interfaces that were free to move in the horizontal plane (<xref ref-type="fig" rid="pcbi-1000468-g001">Fig. 1B</xref>, orange players). A virtual reality system was used to overlay visual feedback onto the plane of movement and players were prevented from seeing their own hand or that of the other player <xref ref-type="bibr" rid="pcbi.1000468-Howard1">[17]</xref>. Each player controlled the position of a cursor that represented the position of their hand. On each trial, the players were required to move their cursors to touch target bars which were directly ahead of them. However, participants were free to move the handle laterally to touch the target bar anywhere along its width. Therefore, participants could achieve the task with their final hand position anywhere between the left and right target bounds. One bound (e.g. left) represented cooperation while the other bound (e.g. right) represented defection. An implicit pay-off was placed on the movements by using each robot to generate a resistive force opposing the forward motion of the handle. The forces were generated by simulating springs that acted between each handle and its starting bar. The stiffness of each spring could vary continuously during the movement depending on the lateral positions of both handles. Directly analogous to the prisoner's dilemma, the spring constants depended on whether the two players cooperated or defected. That is we translate the sentence in years in the traditional cognitive game (<xref ref-type="fig" rid="pcbi-1000468-g001">Fig. 1A</xref>) into spring constants in N/m in our sensorimotor game. For positions of the handles between the bounds, that is between full cooperation and full defection, we linearly interpolated these spring constants (<xref ref-type="fig" rid="pcbi-1000468-g001">Fig. 1C</xref> shows spring constants landscape for each player). Therefore, the actions of each player directly affected both the forces they experienced, as well as the forces experienced by the other player. The game was either played by two players (<xref ref-type="fig" rid="pcbi-1000468-g001">Fig. 1B</xref>, orange) or by one player bimanually (<xref ref-type="fig" rid="pcbi-1000468-g001">Fig. 1B</xref>, green). We hypothesized that the bimanual condition could be conceived of as two cooperating players (instantiated by the two brain hemispheres) which should result in cooperative solutions as opposed to the competitive Nash solutions expected for the two-player setup. Each session consisted of 20 sets with each set consisting of 40 trials. At the start of each set the assignment of the defect/cooperation boundaries to the left/right side of each target was randomized.</p>
<p>Thus, our motor version of the prisoner's dilemma differs from the classic discrete version of the game in at least three different aspects. First, actions are continuous such that there is a continuous coupling between the two players. Second, reward in terms of money or years is replaced by an implicit cost, that is effort. Third, subjects have to learn their optimal strategy since they are unaware of the structure of the coupling, i.e. they have incomplete information about the payoffs. We found a clear distinction between the strategies used at the end of a set for the one-player and the two-player conditions. In <xref ref-type="fig" rid="pcbi-1000468-g002">Figure 2A</xref> and <xref ref-type="fig" rid="pcbi-1000468-g003">Figure 3A</xref> we show the endpoint distributions of the action choices for the two-player and the bimanual conditions. To analyze this result we categorized the final positions of the cursors in <xref ref-type="fig" rid="pcbi-1000468-g002">Figure 2B</xref> and <xref ref-type="fig" rid="pcbi-1000468-g003">Figure 3B</xref> into defect and cooperate responses, that is Nash responses (defect-defect), cooperative responses (cooperate-cooperate) and exploitative responses (defect-cooperate or cooperate-defect). In the one-player condition, the globally optimal cooperative solution was chosen in the majority of instances (<xref ref-type="fig" rid="pcbi-1000468-g003">Fig. 3B</xref>). In contrast, although in some of the two-player games there was a small fraction of exploitative trials, the two-player game led mostly to the Nash solution (<xref ref-type="fig" rid="pcbi-1000468-g002">Fig. 2B</xref>). The globally optimal cooperative solution was seen significantly more often for the one-player game compared to the two-player game (p&lt;0.01, Wilcoxon ranksum test on number of cooperative solutions in the two-player versus the bimanual condition) and conversely the Nash solution was seen significantly more often (p&lt;0.01) for the two-player game than for the one-player game.</p>
<fig id="pcbi-1000468-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000468.g002</object-id><label>Figure 2</label><caption>
<title>Results of the two-player version of the prisoner's dilemma.</title>
<p>(A) Endpoint distribution of handle positions in the four quadrants corresponding to the cooperate defect (lateral movement) plane with the cooperative solution (top left quadrant), the Nash solution (bottom right quadrant) and the two exploitative solutions (top right or bottom left quadrant). Each plot shows one of the eight games in the two-player version of the prisoner's dilemma. The data is shown for the last 20 trials in each set. (B) Histogram over the four quadrants. C corresponds to cooperation and D to defection. All eight participant-pairs show a strong tendency towards the Nash solution.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000468.g002" xlink:type="simple"/></fig><fig id="pcbi-1000468-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000468.g003</object-id><label>Figure 3</label><caption>
<title>Results of the one-player bimanual version of the prisoner's dilemma.</title>
<p>(A) Endpoint distribution of handle positions in the four quadrants corresponding to the cooperate defect (lateral movement) plane with the cooperative solution (top left quadrant), the Nash solution (bottom right quadrant) and the two exploitative solutions (top right or bottom left quadrant). Each plot shows one of the eight participants. The data is shown for the last 20 trials in each set. (B) Histogram over the four quadrants. C corresponds to cooperation and D to defection. All eight participants had a strong preference for the cooperative solution.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000468.g003" xlink:type="simple"/></fig>
<p>To investigate the temporal evolution of learning we analyzed the trial-by-trial behavior of the players averaged across all sets. Initially, in both the one-player and the two-player conditions, players acted at chance level in their strategy (<xref ref-type="fig" rid="pcbi-1000468-g004">Fig. 4</xref>). Later trials of the one-player game converged to the globally optimal cooperative solution, while their probability of choosing a Nash solution dropped to close to zero (<xref ref-type="fig" rid="pcbi-1000468-g004">Fig. 4A</xref>). In contrast, players in the two-player condition showed an increasing tendency to act according to the Nash solution over the course of a set, while their probability of choosing a cooperative solution dropped significantly below chance level (<xref ref-type="fig" rid="pcbi-1000468-g004">Fig. 4B</xref>). The frequency of the exploitative solutions decreased in the bimanual condition along with the frequency of the Nash solution (<xref ref-type="fig" rid="pcbi-1000468-g004">Fig. 4C</xref>). In the two-player game on the other hand, the frequency of exploitative solutions stayed around chance level (<xref ref-type="fig" rid="pcbi-1000468-g004">Fig. 4D</xref>). Therefore, players in both conditions showed significant exploration and learning over trials.</p>
<fig id="pcbi-1000468-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000468.g004</object-id><label>Figure 4</label><caption>
<title>Temporal evolution of game solutions.</title>
<p>(A,B) The evolution of the probability of cooperative (blue) and Nash (red) solutions across a 40 trial set for the one-player and two-player conditions. In the one-player condition the cooperative solution gains most probability, where as in the two-player condition the Nash solution is predominant. (C,D) The evolution of the probability of the exploitative solutions across the same set of trials for the one-player and two-player conditions. The shading is one standard error of the mean across the participants. As there are four possible behaviors chance level is shown at a probability of 0.25.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000468.g004" xlink:type="simple"/></fig>
<p>In our sensorimotor version of the prisoner's dilemma the cooperative and Nash solutions are two extremes of the one-dimensional control variable (lateral position at the target bar). Therefore, we designed a motor task based on another game, the ‘rope-pulling-game’, which has three additional features. First, the control variable is two-dimensional and the Nash and cooperative solutions are no longer at the boundaries of the control space. Second, unlike the prisoner's dilemma, where each player can achieve their task (reaching the bar) without paying attention to the strategy of the other player, in the new task, coordination is required between the players to jointly achieve the task. Third, the rope-pulling game can be translated into a linear dynamical system allowing for analytical solutions in terms of feedback policies (see <xref ref-type="supplementary-material" rid="pcbi.1000468.s001">Text S1</xref> for details). In the rope-pulling-game, two players each pull on a rope attached to a mass (<xref ref-type="fig" rid="pcbi-1000468-g005">Fig. 5A</xref>). Player 1 and player 2 are rewarded according to how far each manages to pull the mass along the y- and x-axis respectively. If the players cooperate they should both pull along the diagonal (<xref ref-type="fig" rid="pcbi-1000468-g005">Fig. 5A</xref>, right), because in this way no forces are wasted compensating for the other player's force. However, if one of the players decides to defect and pull only in his own direction while the other pulls along the diagonal, the defector increases his reward at the expense of the other player. In such a non-cooperative setting the stable Nash solution is for each player to pull only in his own direction (<xref ref-type="fig" rid="pcbi-1000468-g005">Fig. 5A</xref>, left).</p>
<fig id="pcbi-1000468-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000468.g005</object-id><label>Figure 5</label><caption>
<title>The rope-pulling game.</title>
<p>(A) The rope-pulling game in which a mass (circle) is pulled by two players. The arrows show the direction of force for two players for the Nash and cooperative solutions. Red and blue colors represent right and left handles throughout. (B) The motor version of the rope-pulling game. The position of a virtual mass is the sum of the displacements of the two handle positions from their origin (blue and red displacement vectors). However, the visual feedback is only a one-dimensional cursor location that is the y and x values of the mass position for players 1 and 2 respectively. Each player is required to reach a visual target with their cursor. Each robot was used to simulate the forces that would arise from a spring (with constant stiffness) attached between the handle and its origin. The arrow vectors and springs are only shown on the schematic and are not visible to the participants (grayed area not visible). For the one player game, a single participant controls both handles. The game was played by 4 pairs of participants and by 4 different participants individually. (C) Mean end points for each pair of left and right players for the last 40 trials in each set. The ellipses are centered at the average end points across all participants and indicate one standard error. (D) Smoothed frequency histograms (Gaussian kernel sd 20°) of pulling angles for the two-player condition (left: Nash equilibrium shown by vertical lines) and for the one player condition (right: cooperative solution shown by vertical line).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000468.g005" xlink:type="simple"/></fig>
<p>In our version of the rope-pulling game, player 1 and 2's task was to move a virtual mass to a fixed target that was equidistant to both players' origin. Again, each participant grasped the handle of the robotic interface and the location of the virtual mass was the sum of the (possibly rotated—see <xref ref-type="sec" rid="s4">Materials and Methods</xref>) positional displacements of the two handles from their origin (<xref ref-type="fig" rid="pcbi-1000468-g005">Fig. 5B</xref>, red and blue arrow vectors) – just like the positional vectors of two real agents would add up when pulling a real mass. Accordingly, there are infinitely many solutions to reach the target as there are infinitely many ways of how to add two vectors to become a certain target vector. However, each player only saw a one-dimensional projection of the two-dimensional position of the virtual mass, i.e. one player saw a projection along the virtual x-axis and the other player saw a projection along the virtual y-axis corresponding to the direction that they had to control (<xref ref-type="fig" rid="pcbi-1000468-g005">Fig. 5B</xref>). An implicit pay-off was placed on the movements by using the robots to simulate stiff springs between each handle and its origin. Therefore, the further a player had to move the robotic handle from the origin to achieve the task, the greater the resistive force and hence effort required. Limiting each participant's visual feedback to one-dimension, while preventing them from seeing the other participant's feedback, ensures that they could not form an explicit representation that could be used for cognitive solutions. In contrast to the prisoner's dilemma task the actions of each player did not directly affect the forces experienced by the other player but directly affected the position of the other player's cursor. Therefore, each cursor was affected by both players requiring coordination between the players to achieve the task, because subjects could not disregard the other player's action choice as both actions had to add up to a fixed target value. The game was either played by two players (<xref ref-type="fig" rid="pcbi-1000468-g005">Fig. 5B</xref>, orange) or by one player bimanually (<xref ref-type="fig" rid="pcbi-1000468-g005">Fig. 5B</xref>, green) as in the previous game.</p>
<p>We analyzed the distribution of pulling directions after learning (<xref ref-type="fig" rid="pcbi-1000468-g005">Fig. 5C</xref>, positions &amp; <xref ref-type="fig" rid="pcbi-1000468-g005">5D</xref> angles). We found that when a single participant played the game bimanually the movements tended to converge to the cooperative solution with pulling directions clustered around 45° for both arms. In contrast, in the two-player game the directions tended to converge to the Nash solution with pulling directions around 0° and 90° for the two participants. In individual games, both single players and pairs of players could deviate substantially from their respective solutions. Importantly, however, the densities of the solutions in the one-player and two-player conditions were different. Examining the average solution for each participant in the two player game and for each arm in the one-player game showed that the two-player game deviated significantly from 45° (p&lt;0.01, Wilcoxon signrank test), while the one-player game did not (p&gt;0.1). Thus, individual players tended towards a cooperative solution between the two arms, whereas two players tended towards a Nash equilibrium on average.</p>
</sec><sec id="s3">
<title>Discussion</title>
<p>In our study we have assessed human sensorimotor interactions based on game theoretic predictions with an implicit cost, that is effort. Effort, as a proxy for energy consumption, has been shown to be a fundamental determinant underlying how humans control their own movements <xref ref-type="bibr" rid="pcbi.1000468-Todorov1">[18]</xref>,<xref ref-type="bibr" rid="pcbi.1000468-Diedrichsen1">[19]</xref>. In line with the game theoretic predictions, we found in both motor games that the Nash equilibrium was the predominant solution in two-player motor interactions and the cooperative solution dominated in the one-player interactions. Previous studies have shown that natural patterns of coordination can arise between participants when provided with feedback of the other participant, such as the synchronization of gait patterns (for a review see <xref ref-type="bibr" rid="pcbi.1000468-Kelso1">[20]</xref>). In distinction, in our study we limited knowledge of the other participants' behavior to a pay-off in terms of energy and showed that different patterns of interaction develop in the one-player and two-player conditions that can be explained within the game theoretic framework. While this is a different explanatory framework, one should bear in mind that optimality theories and dynamic systems theory are in principle compatible with each other <xref ref-type="bibr" rid="pcbi.1000468-Schaal1">[21]</xref>. In previous studies in psychology, human group behavior in physical tasks such as tug-of-war has been examined and compared to individual performance. It was found that individuals tend to reduce their effort in group tasks and instead rely on others, for example in force production in tug-of-war <xref ref-type="bibr" rid="pcbi.1000468-Ringelmann1">[22]</xref>,<xref ref-type="bibr" rid="pcbi.1000468-Karau1">[23]</xref>. This has been dubbed “social loafing”, but has not been examined in a game theoretic context. Yet, game theoretic analysis has been applied to a wide range of biological systems from interacting microorganisms <xref ref-type="bibr" rid="pcbi.1000468-Reichenbach1">[24]</xref>,<xref ref-type="bibr" rid="pcbi.1000468-Kerr1">[25]</xref>, through animal behavior <xref ref-type="bibr" rid="pcbi.1000468-Bshary1">[26]</xref>,<xref ref-type="bibr" rid="pcbi.1000468-Stephens1">[27]</xref> to understanding population dynamics <xref ref-type="bibr" rid="pcbi.1000468-Smith1">[28]</xref>.</p>
<p>Our results contrast with those obtained in cognitive discrete games in interesting ways. For example, in the classical prisoner's dilemma, contrary to game-theoretic predictions, cooperation plays a significant role: players have been reported to cooperate almost half the time <xref ref-type="bibr" rid="pcbi.1000468-Colman1">[29]</xref>,<xref ref-type="bibr" rid="pcbi.1000468-Camerer1">[2]</xref>. Consequently, a large number of studies have investigated experimental and theoretical conditions that allow for such cooperation <xref ref-type="bibr" rid="pcbi.1000468-Acevedo1">[30]</xref>–<xref ref-type="bibr" rid="pcbi.1000468-Nowak1">[34]</xref>. Especially, in iterated versions of the prisoner's dilemma it was found that cooperative strategies such as tit-for-tat or “win-stay lose-shift” can be very successful <xref ref-type="bibr" rid="pcbi.1000468-Axelrod1">[35]</xref>–<xref ref-type="bibr" rid="pcbi.1000468-Nowak2">[37]</xref>. While cooperation can be optimal in case of indefinite repetitions <xref ref-type="bibr" rid="pcbi.1000468-Aumann1">[38]</xref>, for a fixed number of iterations it is still optimal to defect.</p>
<p>In our motor version of the prisoner's dilemma the participants showed very little inclination towards cooperative solutions. This could have several reasons. Our participants knew, for example, that the experiment was going to last for 800 trials, i.e. assuming the participants had full knowledge of the game structure their defection is optimal – however, knowing the number of trials does not stop players in discrete cognitive games from cooperating. In our study the action space is continuous. A recent theoretical study has found, for example, that cooperative solutions are less stable in continuous environments where agents can make gradual distinctions of cooperativeness ranging from full cooperation to total defection <xref ref-type="bibr" rid="pcbi.1000468-Le1">[13]</xref>. The intuition behind this finding is that the deadlock of a non-cooperative equilibrium is more difficult to break by agents that cooperate only slightly more than their non-cooperative counterparts, because two marginally cooperating agents have much less to gain from each others cooperation than two tit-for-tat agents, for example, that try full cooperation. To investigate the impact of action continuity on human cooperativeness in games one could compare the outcomes of continuous prisoner's dilemma experiments with monetary feedback to the outcomes of discrete versions of the game. Another important difference of both our motor games compared to classic game theoretic settings is that players had incomplete information about the payoff function and the structure of the game. Thus, players first had to gather information and learn the structural determinants of the game. Again one could compare our results to the outcome of classical prisoner's dilemma games where participants are not informed about payoff functions. Furthermore, due to the motor nature of the interactions, psychological effects such as ‘mentalizing’ might have been reduced <xref ref-type="bibr" rid="pcbi.1000468-Polezzi1">[39]</xref>. Participants in our motor games were not aware of the effects of their actions on the other player, since each player could not feel the force feedback given to the other player. To test whether such psychological effects would have an influence in our games that could lead towards more cooperation, one could give explicit feedback about the other player's payoff (e.g. force display in Newtons) and explain that their choice of action affects the other player's toil. Finally, it would also be interesting to investigate more complex games, since we have only examined a special class of games where the Nash solution corresponds to a minimax-solution – this is in general true for zero-sum games <xref ref-type="bibr" rid="pcbi.1000468-VonNeumann1">[40]</xref>, and also for the prisoner's dilemma. For this solution type, a player minimizes the maximum expected loss, thereby ignoring the actions of the other player (both in the classical and the motor prisoner's dilemma game). Thus, more complex games with more complex cost functions provide an interesting avenue for future research.</p>
<p>In our second motor game, the rope-pulling game, over all players we still observed that the Nash solution was the predominant solution for two-player interactions, but this time the inter-subject differences were quite considerable both in the two-player condition and in the bimanual case. One reason for this could be that the task was substantially more complex than the prisoner's dilemma task, especially in the bimanual case where two two-dimensional movements had to be performed simultaneously. Thus, incomplete learning might have played a crucial role. To model such states of incomplete information a special theory of Bayesian games has been devised dealing with so-called Bayes-Nash solutions <xref ref-type="bibr" rid="pcbi.1000468-Harsanyi1">[41]</xref> that need not to correspond to Nash equilibria in the same game under complete information. Furthermore, the dynamics of learning in two-player interactions are also studied in the reinforcement learning literature from a single-agent perspective <xref ref-type="bibr" rid="pcbi.1000468-Hu1">[42]</xref>–<xref ref-type="bibr" rid="pcbi.1000468-Stone1">[46]</xref>. Here we restricted ourselves to simpler classic game-theoretic models to analyze two-player motor interactions assuming complete information, i.e. complete learning of the true payoff structure – the same assumption is typically made in other optimal control models where learning itself is not modeled <xref ref-type="bibr" rid="pcbi.1000468-Diedrichsen1">[19]</xref>,<xref ref-type="bibr" rid="pcbi.1000468-Todorov1">[18]</xref>. Indeed, cooperation in our game can be modeled using optimal feedback control theory <xref ref-type="bibr" rid="pcbi.1000468-Todorov1">[18]</xref> – in <xref ref-type="supplementary-material" rid="pcbi.1000468.s001">Text S1</xref> we indicate how normative and methodical principles from optimal feedback control can be carried over to game theoretic settings. Although dynamic game theory is the most general formulation of motor games, it is not the only tool available to model sensorimotor interactions. For some games, such as those considered in our experiments, simple geometric considerations can be sufficient. In our games players also had imperfect information about the actions of the other player, i.e. they only felt the consequences of the other player's actions without feeling the force feedback given to the other player. This does not invalidate our model, however, since in our games players did not have to know the other players actions to play the Nash equilibrium policy, because, as already mentioned, Nash equilibria in our games corresponded to minimax-solutions. This is ultimately a consequence of the structure of the cost functions we employed, since each players payoff function did not take the actions of the other player into account explicitly. In the future it will be interesting, therefore, to investigate human motor interactions in games with more complex cost functions and to apply more advanced modelling tools.</p>
<p>In both our motor games we compared performance of two-players with the performance of a single player. The underlying hypothesis was that the single player condition could be regarded as an instance of a cooperative game where the two motor hemispheres interact to achieve the task. If the two hemispheres were unable to cooperate, for example as might be expected in patients who have undergone commisurectomy <xref ref-type="bibr" rid="pcbi.1000468-CriscimagnaHemminger1">[47]</xref>, then Nash equilibria might also arise in a single player. In summary, our results suggest that sensorimotor interactions can be understood by a game theoretic framework and that cooperative and Nash solutions in motor interactions can arise naturally by the dynamical coupling of two interacting sensorimotor processes. Moreover, the general design of our experiments provides a tool to translate classical games into continuous motor games and might provide a new avenue for studying human motor interactions.</p>
</sec><sec id="s4">
<title>Materials and Methods</title>
<p>Forty-eight naïve participants provided written informed consent and took part in one of two motor games. The experiments were conducted using two planar robotic interfaces (vBOTs). Participants held the handle of the vBOT that constrained hand movements to the horizontal plane. The vBOT allowed us to record the position of the handle and to generate forces on the hand with a 1 kHz update rate. Using a projection system we overlaid virtual visual feedback into the plane of the movement <xref ref-type="bibr" rid="pcbi.1000468-Howard1">[17]</xref>.</p>
<sec id="s4a">
<title/>
<sec id="s4a1">
<title>Ethics statement</title>
<p>All experimental procedures were approved by the Psychology Research Ethics Committee of the University of Cambridge.</p>
</sec><sec id="s4a2">
<title>Prisoner's dilemma motor game</title>
<p>Each of the robot handles controlled the position of a cursor in one half of the horizontal workspace (<xref ref-type="fig" rid="pcbi-1000468-g001">Fig. 1B</xref>). The cursor could be continuously controlled within a single trial. Each participant's task was to place their cursor within their respective target bar. A trial started after both participants had placed their cursor stationery within their respective starting bar. Both target bars then appeared at a distance randomly drawn each trial between 5 and 20 cm (the same distance for both players on each trial). Participants were required to make a forward movement (y-direction) to touch the target bar. They were free to touch it anywhere along its 15 cm width (the robot simulated walls which prevented participants moving further laterally than the width of the bar). For successful trial completion, the target bar had to be reached by both players within 1500 ms. The final <italic>x</italic>-position was taken as their choice in the game. During the movement, both players experienced a one-dimensional spring attached to the starting bar. The spring constants depended on the lateral positions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e001" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e002" xlink:type="simple"/></inline-formula> of both players, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e003" xlink:type="simple"/></inline-formula> corresponds to a normalized lateral deviation ranging between 0 and 1. For each target bar, one edge was defined as defect (e.g. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e004" xlink:type="simple"/></inline-formula>) and the other as cooperate (e.g. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e005" xlink:type="simple"/></inline-formula>). The assignment of the defect/cooperation boundaries to the left/right side of each target could be randomized. This gave four possible assignments (i.e. defect to left or right of target bar 1 and defect to left or right of target bar 2). Intermediate lateral deviations took on values between 0 and 1. The final <italic>x</italic>-position was categorized as cooperate or defect depending on whether <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e006" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e007" xlink:type="simple"/></inline-formula>. The spring constants were continuously updated as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e008" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e009" xlink:type="simple"/></inline-formula>, for players 1 and 2 respectively. The scaling parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e010" xlink:type="simple"/></inline-formula> was constant throughout the experiment at 0.19 N/cm. These spring constants are linear interpolations of the classical prisoner's dilemma matrix (<xref ref-type="fig" rid="pcbi-1000468-g001">Fig. 1A</xref>), with intermediate lateral deviations leading to intermediate spring constants (<xref ref-type="fig" rid="pcbi-1000468-g001">Fig. 1C</xref>). The participants experienced forces <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e011" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e012" xlink:type="simple"/></inline-formula> resisting their forward motion in which <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e013" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e014" xlink:type="simple"/></inline-formula> are the y-distances of player 1 and 2's hands from the starting bar respectively. Participants performed 20 sets of 40 trials. At the start of each set the allocation of the target edges to defect/cooperate was randomized. Thus, within a set of 40 trials the same force landscape was applied.</p>
</sec><sec id="s4a3">
<title>Rope-pulling game</title>
<p>The position of each robot handle was expressed as a two-dimensional vector position where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e015" xlink:type="simple"/></inline-formula> and<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e016" xlink:type="simple"/></inline-formula> are the position of right and left robot handle, respectively. The two robot handle positions together determined the position of a virtual mass at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e017" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e018" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e019" xlink:type="simple"/></inline-formula> are 2×2 rotation matrices. The scaling parameter was set to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e020" xlink:type="simple"/></inline-formula> throughout the experiments in order to confine arm movements to a smaller workspace so as to avoid collision of the robot handles. The rotation matrices were introduced to factor out any preference of movement direction and to allow repetitions of the game with different solutions. The rotations for each robot, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e021" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000468.e022" xlink:type="simple"/></inline-formula>, were drawn randomly from [−135°, −90°, −45°, 0°, +45°]. For successful trial completion, the virtual mass had to be placed on the virtual target at (13,13) cm for 200 ms within a time limit of 1500 ms. Therefore, participants had to move in two dimensions so as to place the one-dimensional cursor in the target. Accordingly, there are infinitely many solutions to reach the target as there are infinitely many ways of how to add the two position vectors to equal the target vector. However, neither the virtual mass point position nor the virtual target was displayed in 2-dimensional space. Participants could only see a one-dimensional projection of the virtual mass point such that player 1 saw the y-component of the position and player 2 saw the x-component of the virtual mass point position. This corresponded to the dimension that they had to control. Additionally, an isotropic spring (5 N/cm) was simulated attached from the handle of each robot to its origin. This increased the effort required for larger movements. Each game consisted of 10 sets of 80 trials with the same visuomotor rotations. Visual feedback was provided continuously throughout the movement. The final cursor position was taken as the players' choice in the game and used to compute the pulling angles. The feedback ensured that participants were never aware of playing a version of the rope-pulling game.</p>
<p>Each game was played by eight pairs of participants and by eight different participants individually. All participants were instructed to achieve the task as easily as possible. Participants were also told the number of trials in each set, and the sets were separated during the experiment by short breaks. For the two-player game a divider was used to prevent the participants seeing the cursor or arm of the other player. In the single-player condition subjects saw the same screen that would be displayed to two players in the game condition.</p>
</sec></sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1000468.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000468.s001" xlink:type="simple"><label>Text S1</label><caption>
<p>Supplementary Materials</p>
<p>(0.15 MB PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We thank Aldo Faisal, Ian Howard, James Ingram and Luc Selen for their assistance.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1000468-Fudenberg1"><label>1</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fudenberg</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Tirole</surname><given-names>J</given-names></name>
</person-group>             <year>1991</year>             <source>Game theory</source>             <publisher-loc>Cambridge, Mass.</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000468-Camerer1"><label>2</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Camerer</surname><given-names>C</given-names></name>
</person-group>             <year>2003</year>             <source>Behavioral game theory: experiments in strategic interaction</source>             <publisher-loc>Princeton, N.J.</publisher-loc>             <publisher-name>Princeton University Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000468-Sanfey1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sanfey</surname><given-names>AG</given-names></name>
</person-group>             <year>2007</year>             <article-title>Social decision-making: insights from game theory and neuroscience.</article-title>             <source>Science</source>             <volume>318</volume>             <fpage>598</fpage>             <lpage>602</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Jensen1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Jensen</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Call</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Tomasello</surname><given-names>M</given-names></name>
</person-group>             <year>2007</year>             <article-title>Chimpanzees are rational maximizers in an ultimatum game.</article-title>             <source>Science</source>             <volume>318</volume>             <fpage>107</fpage>             <lpage>109</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Memmert1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Memmert</surname><given-names>D</given-names></name>
</person-group>             <year>2006</year>             <article-title>Self-controlled practice of decision-making skills.</article-title>             <source>Percept Mot Skills</source>             <volume>103</volume>             <fpage>879</fpage>             <lpage>882</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-KingCasas1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>King-Casas</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Tomlin</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Anen</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Camerer</surname><given-names>CF</given-names></name>
<name name-style="western"><surname>Quartz</surname><given-names>SR</given-names></name>
<etal/></person-group>             <year>2005</year>             <article-title>Getting to know you: reputation and trust in a two-person economic exchange.</article-title>             <source>Science</source>             <volume>308</volume>             <fpage>78</fpage>             <lpage>83</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Lee1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lee</surname><given-names>D</given-names></name>
<name name-style="western"><surname>McGreevy</surname><given-names>BP</given-names></name>
<name name-style="western"><surname>Barraclough</surname><given-names>DJ</given-names></name>
</person-group>             <year>2005</year>             <article-title>Learning and decision making in monkeys during a rock-paper-scissors game.</article-title>             <source>Brain Res Cogn Brain Res</source>             <volume>25</volume>             <fpage>416</fpage>             <lpage>430</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Shafir1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Shafir</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Tversky</surname><given-names>A</given-names></name>
</person-group>             <year>1992</year>             <article-title>Thinking through uncertainty: nonconsequential reasoning and choice.</article-title>             <source>Cognit Psychol</source>             <volume>24</volume>             <fpage>449</fpage>             <lpage>474</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Nash1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nash</surname><given-names>JF</given-names></name>
</person-group>             <year>1950</year>             <article-title>Equilibrium Points in N-Person Games.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>36</volume>             <fpage>48</fpage>             <lpage>49</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Glicksberg1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Glicksberg</surname><given-names>IL</given-names></name>
</person-group>             <year>1952</year>             <article-title>A Further Generalization of the Kakutani Fixed Point Theorem, with Application to Nash Equilibrium Points.</article-title>             <source>Proceedings of the American Mathematical Society</source>             <volume>3</volume>             <fpage>170</fpage>             <lpage>174</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Fan1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fan</surname><given-names>K</given-names></name>
</person-group>             <year>1952</year>             <article-title>Fixed-point and Minimax Theorems in Locally Convex Topological Linear Spaces.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>38</volume>             <fpage>121</fpage>             <lpage>126</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Debreu1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Debreu</surname><given-names>G</given-names></name>
</person-group>             <year>1952</year>             <article-title>A Social Equilibrium Existence Theorem.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>38</volume>             <fpage>886</fpage>             <lpage>893</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Le1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Le</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Boyd</surname><given-names>R</given-names></name>
</person-group>             <year>2007</year>             <article-title>Evolutionary dynamics of the continuous iterated prisoner's dilemma.</article-title>             <source>J Theor Biol</source>             <volume>245</volume>             <fpage>258</fpage>             <lpage>267</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Papavassilopoulos1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Papavassilopoulos</surname><given-names>GP</given-names></name>
<name name-style="western"><surname>Medanic</surname><given-names>JV</given-names></name>
<name name-style="western"><surname>Cruz</surname><given-names>JB</given-names></name>
</person-group>             <year>1979</year>             <article-title>Existence of Nash strategies and solutions to coupled Riccati equations in linear-quadratic games.</article-title>             <source>J Optim Theory Appl</source>             <volume>28</volume>             <fpage>49</fpage>             <lpage>76</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Basar1"><label>15</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Basar</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Olsder</surname><given-names>GJ</given-names></name>
</person-group>             <year>1999</year>             <source>Dynamic noncooperative game theory</source>             <publisher-loc>Philadelphia, Pa.</publisher-loc>             <publisher-name>SIAM</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000468-Poundstone1"><label>16</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Poundstone</surname><given-names>W</given-names></name>
</person-group>             <year>1992</year>             <source>Prisoner's dilemma.</source>             <publisher-name>New York Doubleday</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000468-Howard1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Howard</surname><given-names>IS</given-names></name>
<name name-style="western"><surname>Ingram</surname><given-names>JN</given-names></name>
<name name-style="western"><surname>Wolpert</surname><given-names>DM</given-names></name>
</person-group>             <year>2009</year>             <article-title>A modular planar robotic manipulandum with end-point torque control.</article-title>             <source>Journal of Neuroscience Methods</source>             <volume>181</volume>             <fpage>199</fpage>             <lpage>211</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Todorov1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Todorov</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name>
</person-group>             <year>2002</year>             <article-title>Optimal feedback control as a theory of motor coordination.</article-title>             <source>Nature neuroscience</source>             <volume>5</volume>             <fpage>1226</fpage>             <lpage>1235</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Diedrichsen1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Diedrichsen</surname><given-names>J</given-names></name>
</person-group>             <year>2007</year>             <article-title>Optimal task-dependent changes of bimanual feedback control and adaptation.</article-title>             <source>Curr Biol</source>             <volume>17</volume>             <fpage>1675</fpage>             <lpage>1679</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Kelso1"><label>20</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kelso</surname><given-names>JAS</given-names></name>
</person-group>             <year>1995</year>             <source>Dynamic patterns : the self-organization of brain and behavior</source>             <publisher-loc>Cambridge, Mass.; London</publisher-loc>             <publisher-name>MIT Press</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">xvii,334</size></element-citation></ref>
<ref id="pcbi.1000468-Schaal1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Schaal</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Mohajerian</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Ijspeert</surname><given-names>A</given-names></name>
</person-group>             <year>2007</year>             <article-title>Dynamics systems vs. optimal control–a unifying view.</article-title>             <source>Progress in brain research</source>             <volume>165</volume>             <fpage>425</fpage>             <lpage>445</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Ringelmann1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ringelmann</surname><given-names>M</given-names></name>
</person-group>             <year>1913</year>             <article-title>Recherches sur les moteurs animés: Travail de l'homme.</article-title>             <source>Annales de l'Institut National Argonomique</source>             <volume>12</volume>             <fpage>1</fpage>             <lpage>40</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Karau1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Karau</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Williams</surname><given-names>KD</given-names></name>
</person-group>             <year>1993</year>             <article-title>Social Loafing: A Meta-Analytic Review and Theoretical Integration.</article-title>             <source>Journal of Personality and Social Psychology</source>             <volume>65</volume>             <fpage>681</fpage>             <lpage>706</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Reichenbach1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reichenbach</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Mobilia</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Frey</surname><given-names>E</given-names></name>
</person-group>             <year>2007</year>             <article-title>Mobility promotes and jeopardizes biodiversity in rock-paper-scissors games.</article-title>             <source>Nature</source>             <volume>448</volume>             <fpage>1046</fpage>             <lpage>1049</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Kerr1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kerr</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Riley</surname><given-names>MA</given-names></name>
<name name-style="western"><surname>Feldman</surname><given-names>MW</given-names></name>
<name name-style="western"><surname>Bohannan</surname><given-names>BJ</given-names></name>
</person-group>             <year>2002</year>             <article-title>Local dispersal promotes biodiversity in a real-life game of rock-paper-scissors.</article-title>             <source>Nature</source>             <volume>418</volume>             <fpage>171</fpage>             <lpage>174</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Bshary1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bshary</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Grutter</surname><given-names>AS</given-names></name>
<name name-style="western"><surname>Willener</surname><given-names>AS</given-names></name>
<name name-style="western"><surname>Leimar</surname><given-names>O</given-names></name>
</person-group>             <year>2008</year>             <article-title>Pairs of cooperating cleaner fish provide better service quality than singletons.</article-title>             <source>Nature</source>             <volume>455</volume>             <fpage>964</fpage>             <lpage>966</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Stephens1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stephens</surname><given-names>DW</given-names></name>
<name name-style="western"><surname>McLinn</surname><given-names>CM</given-names></name>
<name name-style="western"><surname>Stevens</surname><given-names>JR</given-names></name>
</person-group>             <year>2002</year>             <article-title>Discounting and reciprocity in an Iterated Prisoner's Dilemma.</article-title>             <source>Science</source>             <volume>298</volume>             <fpage>2216</fpage>             <lpage>2218</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Smith1"><label>28</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Smith</surname><given-names>JM</given-names></name>
</person-group>             <year>1982</year>             <source>Evolution and the theory of games</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000468-Colman1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Colman</surname><given-names>AM</given-names></name>
</person-group>             <year>2003</year>             <article-title>Cooperation, psychological game theory, and limitations of rationality in social interaction.</article-title>             <source>The Behavioral and brain sciences</source>             <volume>26</volume>             <fpage>139</fpage>             <lpage>153; discussion 153–198</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Acevedo1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Acevedo</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Krueger</surname><given-names>JI</given-names></name>
</person-group>             <year>2005</year>             <article-title>Evidential reasoning in the prisoner's dilemma.</article-title>             <source>Am J Psychol</source>             <volume>118</volume>             <fpage>431</fpage>             <lpage>457</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-McNamara1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>McNamara</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Barta</surname><given-names>Z</given-names></name>
<name name-style="western"><surname>Houston</surname><given-names>AI</given-names></name>
</person-group>             <year>2004</year>             <article-title>Variation in behaviour promotes cooperation in the Prisoner's Dilemma game.</article-title>             <source>Nature</source>             <volume>428</volume>             <fpage>745</fpage>             <lpage>748</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Fowler1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fowler</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Johnson</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Smirnov</surname><given-names>O</given-names></name>
</person-group>             <year>2005</year>             <article-title>Human behaviour: Egalitarian motive and altruistic punishment.</article-title>             <source>Nature</source>             <volume>433</volume>             <fpage>E1</fpage>          </element-citation></ref>
<ref id="pcbi.1000468-Roberts1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Roberts</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Renwick</surname><given-names>JS</given-names></name>
</person-group>             <year>2003</year>             <article-title>The development of cooperative relationships: an experiment.</article-title>             <source>Proc Biol Sci</source>             <volume>270</volume>             <fpage>2279</fpage>             <lpage>2283</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Nowak1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nowak</surname><given-names>MA</given-names></name>
</person-group>             <year>2006</year>             <article-title>Five rules for the evolution of cooperation.</article-title>             <source>Science</source>             <volume>314</volume>             <fpage>1560</fpage>             <lpage>1563</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Axelrod1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Axelrod</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Hamilton</surname><given-names>WD</given-names></name>
</person-group>             <year>1981</year>             <article-title>The evolution of cooperation.</article-title>             <source>Science</source>             <volume>211</volume>             <fpage>1390</fpage>             <lpage>1396</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Milinski1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Milinski</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Wedekind</surname><given-names>C</given-names></name>
</person-group>             <year>1998</year>             <article-title>Working memory constrains human cooperation in the Prisoner's Dilemma.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>95</volume>             <fpage>13755</fpage>             <lpage>13758</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Nowak2"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nowak</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Sigmund</surname><given-names>K</given-names></name>
</person-group>             <year>1993</year>             <article-title>A strategy of win-stay, lose-shift that outperforms tit-for-tat in the Prisoner's Dilemma game.</article-title>             <source>Nature</source>             <volume>364</volume>             <fpage>56</fpage>             <lpage>58</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Aumann1"><label>38</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Aumann</surname><given-names>R</given-names></name>
</person-group>             <year>1959</year>             <article-title>Acceptable points in general cooperative n-person games.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Tucker</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Luce</surname><given-names>R</given-names></name>
</person-group>             <source>  Contribution to the Theory of Games, Vol IV, Annals of Mathematics Studies</source>             <fpage>287</fpage>             <lpage>324</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-Polezzi1"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Polezzi</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Daum</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Rubaltelli</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Lotto</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Civai</surname><given-names>C</given-names></name>
<etal/></person-group>             <year>2008</year>             <article-title>Mentalizing in economic decision-making.</article-title>             <source>Behav Brain Res</source>             <volume>190</volume>             <fpage>218</fpage>             <lpage>223</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-VonNeumann1"><label>40</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Von Neumann</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Morgenstern</surname><given-names>O</given-names></name>
</person-group>             <year>1944</year>             <source>Theory of games and economic behavior</source>             <publisher-loc>Princeton</publisher-loc>             <publisher-name>Princeton University Press</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">xviii,625</size>          </element-citation></ref>
<ref id="pcbi.1000468-Harsanyi1"><label>41</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Harsanyi</surname><given-names>JC</given-names></name>
</person-group>             <year>1982</year>             <source>Papers in game theory</source>             <publisher-loc>Dordrecht</publisher-loc>             <publisher-name>D. Reidel Publishing Co</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">xii,258</size>       </element-citation></ref>
<ref id="pcbi.1000468-Hu1"><label>42</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hu</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Wellman</surname><given-names>MP</given-names></name>
</person-group>             <year>1998</year>             <article-title>Multiagent Reinforcement Learning: Theoretical Framework and an Algorithm.</article-title>             <fpage>242</fpage>             <lpage>250</lpage>             <comment>Proceedings of the Fifteenth International Conference on Machine Learning: Morgan Kaufmann</comment>          </element-citation></ref>
<ref id="pcbi.1000468-Fudenberg2"><label>43</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fudenberg</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Levine</surname><given-names>DK</given-names></name>
</person-group>             <year>1998</year>             <source>The theory of learning in games</source>             <publisher-loc>Cambridge, Mass.</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000468-Claus1"><label>44</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Claus</surname><given-names>C</given-names></name>
<name name-style="western"><surname>C.</surname><given-names>B</given-names></name>
</person-group>             <year>1998</year>             <article-title>The dynamics of reinforcement learning in cooperative multiagent systems.</article-title>             <fpage>746</fpage>             <lpage>752</lpage>             <comment>Proceedings of the fifteenth national conference on Artificial intelligence</comment>          </element-citation></ref>
<ref id="pcbi.1000468-Littman1"><label>45</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Littman</surname><given-names>M</given-names></name>
</person-group>             <year>1994</year>             <article-title>Markov Games as a Framework for Multi-Agent Reinforcement Learning.</article-title>             <fpage>157</fpage>             <lpage>163</lpage>             <comment>Proceedings of the Eleventh International Conference on Machine Learning</comment>          </element-citation></ref>
<ref id="pcbi.1000468-Stone1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stone</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Veloso</surname><given-names>M</given-names></name>
</person-group>             <year>2000</year>             <article-title>Multiagent Systems: A Survey from a Machine Learning Perspective.</article-title>             <source>Autonomous Robots</source>             <volume>8</volume>             <fpage>345</fpage>             <lpage>383</lpage>          </element-citation></ref>
<ref id="pcbi.1000468-CriscimagnaHemminger1"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Criscimagna-Hemminger</surname><given-names>SE</given-names></name>
<name name-style="western"><surname>Donchin</surname><given-names>O</given-names></name>
<name name-style="western"><surname>Gazzaniga</surname><given-names>MS</given-names></name>
<name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name>
</person-group>             <year>2003</year>             <article-title>Learned dynamics of reaching movements generalize from dominant to nondominant arm.</article-title>             <source>Journal of neurophysiology</source>             <volume>89</volume>             <fpage>168</fpage>             <lpage>176</lpage>          </element-citation></ref>
</ref-list>

</back>
</article>
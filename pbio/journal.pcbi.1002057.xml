<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PCOMPBIOL-D-10-00314</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002057</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Computational biology</subject>
            <subj-group>
              <subject>Computational neuroscience</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Computational neuroscience</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computational Biology</subject>
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Attracting Dynamics of Frontal Cortex Ensembles during Memory-Guided Decision-Making</article-title><alt-title alt-title-type="running-head">Neural Attractor States during Decision-Making</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
          <name name-style="western">
            <surname>Balaguer-Ballester</surname>
            <given-names>Emili</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
          <name name-style="western">
            <surname>Lapish</surname>
            <given-names>Christopher C.</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Seamans</surname>
            <given-names>Jeremy K.</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Durstewitz</surname>
            <given-names>Daniel</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Bernstein-Center for Computational Neuroscience Heidelberg-Mannheim, Central Institute of Mental Health, Medical Faculty Mannheim, Heidelberg University, Mannheim, Germany</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Department of Psychology, Indiana University-Purdue University, Indianapolis, Indiana, United States of America</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Brain Research Center &amp; Department of Psychiatry, University of British Columbia, Vancouver, Canada</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Friston</surname>
            <given-names>Karl J.</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">emili.balaguer@zi-mannheim.de</email>  (EBB); <email xlink:type="simple">daniel.durstewitz@zi-mannheim.de</email> (DD)</corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: CCL JKS DD. Performed the experiments: CCL. Analyzed the data: EBB. Contributed reagents/materials/analysis tools: EBB. Wrote the paper: EBB CCL JKS DD.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>5</month>
        <year>2011</year>
      </pub-date><pub-date pub-type="epub">
        <day>19</day>
        <month>5</month>
        <year>2011</year>
      </pub-date><volume>7</volume><issue>5</issue><elocation-id>e1002057</elocation-id><history>
        <date date-type="received">
          <day>24</day>
          <month>11</month>
          <year>2010</year>
        </date>
        <date date-type="accepted">
          <day>31</day>
          <month>3</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Balaguer-Ballester et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>A common theoretical view is that attractor-like properties of neuronal dynamics underlie cognitive processing. However, although often proposed theoretically, direct experimental support for the convergence of neural activity to stable population patterns as a signature of attracting states has been sparse so far, especially in higher cortical areas. Combining state space reconstruction theorems and statistical learning techniques, we were able to resolve details of anterior cingulate cortex (ACC) multiple single-unit activity (MSUA) ensemble dynamics during a higher cognitive task which were not accessible previously. The approach worked by constructing high-dimensional state spaces from delays of the original single-unit firing rate variables and the interactions among them, which were then statistically analyzed using kernel methods. We observed cognitive-epoch-specific neural ensemble states in ACC which were stable across many trials (in the sense of being predictive) and depended on behavioral performance. More interestingly, <italic>attracting</italic> properties of these cognitively defined ensemble states became apparent in high-dimensional expansions of the MSUA spaces due to a proper unfolding of the neural activity flow, with properties common across different animals. These results therefore suggest that ACC networks may process different subcomponents of higher cognitive tasks by transiting among different attracting states.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>For understanding how neural processes give rise to cognitive operations, it is essential to understand how aspects of the underlying neural network dynamics reconstructed from neurophysiological measurements relate to behavior. For instance, different actions may be represented by neural states characterized by stable population patterns to which activity converges in time, called <italic>attractors</italic> in the language of dynamical systems. However, experimental demonstrations of neural attractors associated with cognitive entities have been rare so far. One problem may have been that in behaving animals, in-vivo one can access only a relatively small fraction of the total number of neural units comprising the whole system, even with modern multiple single-unit (MSU) recording techniques. Therefore, the neural activity dynamics are necessarily projected from a very high-dimensional into the empirically accessible much lower-dimensional space in which attractor properties may be lost due to ambiguities and entanglement in the flow of trajectories. In the present study, principles from nonlinear time series analysis and statistical learning are applied to MSU recordings from the rat's prefrontal cortex during decision-making tasks. By expanding the empirically accessed neural state space (semi-) attracting properties of neural states corresponding to cognitively defined task-epochs became apparent, in line with many neuro-computational theories.</p>
      </abstract><funding-group><funding-statement>This work was funded by grants from the Deutsche Forschungsgemeinschaft to D.D. (Du 354/5-1 &amp; 6-1) and by the German ministry for education and research (BMBF, 01GQ1003B) through the Bernstein Center for Computational Neuroscience initiative. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="19"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>To fully understand how neural processes give rise to cognitive operations, it is essential to reconstruct the underlying neural network dynamics from electrophysiological or neuroimaging measurements in relation to behavior. A common theoretical idea is that these <italic>dynamical properties</italic> of the nervous system, like the convergence of activity to specific stable population patterns (attractors), are what ultimately implement the computational operations that link inputs to outputs <xref ref-type="bibr" rid="pcbi.1002057-Wilson1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-Colgin1">[6]</xref>. For instance, different attracting states may represent different active memories or cognitive entities, and movement between these states may correspond to the recall of a memory sequence or the execution of a behavioral or motor plan. Attractor states as a basis for cognition received particular attention in the context of working memory <xref ref-type="bibr" rid="pcbi.1002057-Durstewitz1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Machens1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Durstewitz3">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-Brunel1">[9]</xref> and decision making tasks <xref ref-type="bibr" rid="pcbi.1002057-Wang1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Albantakis1">[10]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-Wang3">[12]</xref>.</p>
      <p>Especially in recent years, along with the advances in multiple single-unit recording techniques <xref ref-type="bibr" rid="pcbi.1002057-Miller1">[13]</xref>, there has been a dramatic rise in the attempts to reconstruct cognitively relevant aspects of the population dynamics. Many of these relied on methods from multivariate statistics and machine learning (as reviewed in <xref ref-type="bibr" rid="pcbi.1002057-Brown1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Churchland1">[15]</xref>). These studies gave a number of valuable insights into mechanisms of neural information processing like the information content of the transient dynamics connecting steady states <xref ref-type="bibr" rid="pcbi.1002057-Mazor1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Bathellier1">[17]</xref>, the representation or processing of stimuli by reproducible sequences of states <xref ref-type="bibr" rid="pcbi.1002057-Jones1">[18]</xref>, or the sudden nature of transitions among representational states during learning <xref ref-type="bibr" rid="pcbi.1002057-Durstewitz4">[19]</xref>. Several experimental studies also suggested that spatial representations in the rodent hippocampus <xref ref-type="bibr" rid="pcbi.1002057-Colgin1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Wills1">[20]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-vanderMeer1">[22]</xref> or olfactory representations in zebrafish <xref ref-type="bibr" rid="pcbi.1002057-Mazor1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Niessing1">[23]</xref> may have attractor-like properties with sometimes stochastic transitions among them <xref ref-type="bibr" rid="pcbi.1002057-Deco2">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Miller2">[25]</xref>. In these studies, attractor states were indicated by discrete switches in the population activity patterns eventually attained (after some transient) when stimulus parameters were continuously varied. Strictly speaking, however, these studies did not attempt to explicitly demonstrate a convergent flow of neural trajectories (as sometimes pointed out by the authors themselves, <xref ref-type="bibr" rid="pcbi.1002057-Niessing1">[23]</xref>), as another important signature of attracting states. Moreover, they mostly focused on (stimulus-driven) sensory or spatial representations rather than on presumably intrinsically-driven higher cognitive processes. In addition, since most of these previous approaches worked directly in the space of observed variables, i.e. the recorded units' firing rates or spike times, they could potentially miss some important structural details of neural space organization, especially in high-noise situations, as they try to infer the dynamics of a large complex system by selecting only a few of its dimensions (recorded neurons). Thus, experimental evidence for the hypothesis that higher cognitive processes proceed by moving among attracting states is still sparse.</p>
      <p>Here we combined and adapted two approaches well established in statistical learning theory <xref ref-type="bibr" rid="pcbi.1002057-BenHur1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Vapnik1">[27]</xref> and nonlinear time series analysis <xref ref-type="bibr" rid="pcbi.1002057-Sauer1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Kantz1">[29]</xref> in an attempt to move beyond some of the limitations that could arise in previous analyses of electrophysiological data. These methods were applied to multiple single-unit recordings from the rat anterior cingulate cortex (ACC) during a complex memory-guided decision making task in a radial arm maze (<xref ref-type="supplementary-material" rid="pcbi.1002057.s001">Figure S1</xref>). The ACC is assumed to play a key role in higher-level cognitive processes like monitoring of behavior <xref ref-type="bibr" rid="pcbi.1002057-vanVeen1">[30]</xref>, processing error feedback <xref ref-type="bibr" rid="pcbi.1002057-Botvinick1">[31]</xref>, making choices <xref ref-type="bibr" rid="pcbi.1002057-Rushworth1">[32]</xref> and dissecting task structure <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>. Thus, the ACC is a brain area with complex intrinsic dynamics and computational properties that presumably demand a sophisticated multivariate analysis to much larger degree than comparatively simpler early sensory systems (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Mazor1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Niessing1">[23]</xref>). The present analysis was designed to be more sensitive to potential state space structure, suggesting previously unrecognized convergence properties of ACC neural ensemble states associated with cognitive processing steps and stable across multiple trials.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Neural state space reconstruction: Motivating the approach</title>
        <p>A state space is a coordinate map spanned by all relevant dynamical variables of a system (e.g. the membrane voltages or firing rates of neurons). A single (vector) point in this space represents the whole state of the recorded neural system at a given point in time (e.g. the current firing rates of all neurons), while a trajectory in this space charts how its state changes over time. Most computational theories of the brain work by linking geometrical objects in these spaces (e.g. attractors) and the temporal evolution of neural activity (the trajectories) to specific computational and cognitive functions (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Durstewitz1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Machens1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Hopfield1">[34]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-BalaguerBallester1">[37]</xref>). However, inferring the dynamics of a large complex system from experimental data by selecting only the observable dimensions (recorded neurons) can lead to incorrect conclusions <xref ref-type="bibr" rid="pcbi.1002057-Sauer1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Kantz1">[29]</xref>: Neural trajectories may not be sufficiently “unfolded”, i.e. may follow apparently convoluted patterns where they frequently “intersect” themselves and exhibit ambiguities with regards to their direction of flow (<xref ref-type="fig" rid="pcbi-1002057-g001">Figure 1A</xref>, left). This is due to the fact that other dimensions along which the flow would have been disambiguated are missing (e.g. the third axis in <xref ref-type="fig" rid="pcbi-1002057-g001">Figure 1A</xref>, top left; <xref ref-type="bibr" rid="pcbi.1002057-Sauer1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Takens1">[38]</xref>). Thus, a state space construed solely from the activities of the simultaneously recorded units (termed multiple single-unit activity, MSUA, space in the following) is not guaranteed to properly represent the geometry of the underlying dynamical system's attractors.</p>
        <fig id="pcbi-1002057-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002057.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Unfolding trajectories by expanding state space dimensionality.</title>
            <p><bold>A.</bold> Left: In this schema, the two-dimensional reconstruction of a three-dimensional dynamical system in the plane (<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>) causes two trajectories to intersect with themselves and with each other multiple times (as indicated by the dots). At each of these intersection points, the flow of the system (the change of activity in time) is not uniquely defined as indicated by the arrows and question marks. However, such a unique determination of flow would be important for assessing, e.g., the convergence of trajectories. Center: A potential solution: While it may not be possible to discriminate between two trajectories within a two-dimensional plane spanned by the firing rates of two neurons, (ν<sub>1</sub>(<italic>t</italic>), ν<sub>2</sub>(<italic>t</italic>)), adding a third axis containing an appropriate time delay for one of the units permits to fully disentangle the two trajectories. Right: High-order products of delayed firing rates, e.g. ν<sup>2</sup><sub>1</sub>(<italic>t</italic>-τ<italic><sub>1</sub></italic>) ν<sup>3</sup><sub>2</sub>(<italic>t</italic>-τ<italic><sub>2</sub></italic>), further amplify the trajectory separation already achieved through the delays. Thus, dimensions missing from the original space can be substituted by new axes formed from the measured variables. <bold>B.</bold> Three-dimensional projections obtained by Principal Components Analysis (PCA) for a single trial (#1) of rat #1 (see text). Brown curves represent the training and test phases, and the dark blue curve indicates the delay period in the radial arm-maze task shown in <xref ref-type="fig" rid="pcbi-1002057-g002">Figure 2A</xref>. Left: PCA reduction of the MSUA space. Right: Kernel-PCA reduction of the expanded space containing higher-order activity products. The neural trajectories intermingled on the left become nicely unfolded on the right.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.g001" xlink:type="simple"/>
        </fig>
        <p>A potential solution to this problem was provided by time series embedding theorems <xref ref-type="bibr" rid="pcbi.1002057-Sauer1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Takens1">[38]</xref> which demonstrated that the structure of the underlying attractor dynamics could be fully recovered (under ideal, noise-free conditions) if the dimensionality of the space is expanded by adding a sufficient number <italic>p</italic> of time-lagged versions ν(<italic>t-τ<sub>i</sub></italic>) of the present observations ν(<italic>t</italic>) as new variables to the space, where the time lags <italic>τ<sub>i</sub></italic> are determined such that these new variables do not contain redundant information with respect to the original MSUA axes, i.e., are only weakly correlated with them (<xref ref-type="fig" rid="pcbi-1002057-g001">Figure 1A</xref>, center). In principle, the optimum number of delay axes is constrained by the dimensionality of the underlying attractor of the system <xref ref-type="bibr" rid="pcbi.1002057-Sauer1">[28]</xref>. Unfortunately, however, due to the sparseness of the MSUA spaces and the noise levels in these data it cannot be reliably computed. Moreover, given that for neural systems the true dimensionality could be (much) higher than the number of dimensions one has experimentally access to, the number of time lags required for a statistically optimal disambiguation of trajectory flows may be so high that it cannot be accommodated by the (experimentally) limited length of the time series (<xref ref-type="sec" rid="s4">Materials and Methods</xref>).</p>
        <p>Therefore, it may be necessary to consider also other types of state space expansion that allow to effectively discern the neural dynamics associated with different cognitive events. Adding interactions between units' firing rates as dimensions to the space seems a particularly suitable choice since neuronal cross-correlations have often been postulated to play an important role in cognitive processes (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Vaadia1">[39]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-Averbeck1">[43]</xref>). From a mathematical point of view products of neural firing rates would correspond to terms of a multinomial basis expansion frequently employed in statistical classification procedures <xref ref-type="bibr" rid="pcbi.1002057-Vapnik1">[27]</xref>. Hence, such an expansion would have both a neuroscientific meaning and a theoretical foundation. Therefore, in our approach the delay-coordinate (DC) map of the MSUA space (DC-MSUA space) is further expanded by adding pairwise and higher order cross-products of the recorded units' firing rates, up to some order <italic>O</italic>, as new dimensions. For example, an expanded state space of <italic>3<sup>rd</sup></italic> order will contain all the original MSUA axes, plus time-delayed versions of the firing rates of all <italic>n</italic> recorded units, ν<sub>1</sub>(<italic>t</italic>-τ<italic><sub>1</sub></italic>), ν<sub>2</sub>(<italic>t</italic>-τ<italic><sub>2</sub></italic>),…, ν<italic><sub>n</sub></italic>(<italic>t</italic>-τ<italic><sub>n</sub></italic>) as well as new axes corresponding to third order products like ν<sub>1</sub>(<italic>t</italic>-τ<italic><sub>1</sub></italic>) ν<sub>2</sub>(<italic>t</italic>-τ<italic><sub>2</sub></italic>) ν<sub>3</sub>(<italic>t</italic>-τ<italic><sub>3</sub></italic>) or ν<sub>1</sub>(<italic>t</italic>-τ<italic><sub>1</sub></italic>)<sup>2</sup> ν<italic><sub>3</sub></italic>(<italic>t</italic>-τ<italic><sub>3</sub></italic>). Vectors in these high-dimensional spaces will be denoted by <bold>Φ</bold>(t) – each such vector corresponds to a specific (spatio-temporal) pattern of neural firing rates and firing rate correlations up to the order set by the expansion. Since the dimensionality of such spaces can be extremely high, specialized algorithms (so-called <italic>kernel</italic>-methods <xref ref-type="bibr" rid="pcbi.1002057-Bishop1">[44]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-Hastie1">[46]</xref>) were used for the statistical analyses, as discussed below. As illustrated in <xref ref-type="fig" rid="pcbi-1002057-g001">Figure 1A</xref> (right), adding these cross-product terms can help to further disentangle neural trajectories by amplifying small differences present in the DC-MSUA space.</p>
        <p>Why this 2-stage process in expanding the original MSUA space? If trajectories in the originally recorded MSUA space are already nicely disentangled and noise levels are very low, no further expansion may be necessary. However, many of the simultaneously recorded neurons may fire very sparsely, or may otherwise be non-informative about the system's dynamics, or there may simply not be enough of them which access “sufficiently different aspects” of the system's dynamics. Adding delay coordinates (with delays chosen such as to minimize cross-correlations among the firing-rates of different neurons, see <xref ref-type="sec" rid="s4">Materials and Methods</xref>) will increase the amount of information about the neural dynamics captured by the space by removing ambiguities in the neural flow which may occur in the MSUA space (<xref ref-type="fig" rid="pcbi-1002057-g001">Figure 1A</xref>, center). Adding product terms, on the other hand, may not add further information about the dynamics to the space (although it may make information contained in neuronal correlations explicitly accessible), but it will help to pull trajectories apart and thus enhance task-related differences in the activity flow in situations of high noise (<xref ref-type="fig" rid="pcbi-1002057-g001">Figure 1A</xref>, right; see also <xref ref-type="sec" rid="s4">Materials and Methods</xref>). It may also take care of the fact that putative attractor geometries may be highly nonlinear structures that are not easily captured by linearly separating hyperplanes. Hence, by combining these two types of expansion we arrive at a space which should be both, more informative due to the addition of delay coordinates, and at the same time “less noisy” and more apt for detecting nonlinear structures. Here we show that the identification of ensemble dynamics for different animals and behavioral performance levels will, in general, indeed significantly improve by combining both types of expansion.</p>
        <p>As an example, <xref ref-type="fig" rid="pcbi-1002057-g001">Figure 1B</xref> shows a single <italic>trial</italic> of an animal performing a higher cognitive task explained in the next section. A type of principal component analysis (PCA) suitable for very high-dimensional <italic>O<sup>th</sup></italic> order spaces, termed <italic>kernel</italic>-PCA <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf2">[47]</xref> (for <italic>O</italic> = 1 equivalent to conventional PCA), was used to visualize the neural dynamics in the 3 most variance-explaining dimensions. While for both the MSUA and <italic>O</italic> = 5 spaces the two illustrated task phases (blue and red dots in <xref ref-type="fig" rid="pcbi-1002057-g001">Figure 1B</xref>) can be clearly discerned, the actual trajectories (the lines connecting the dots) are quite entangled in the MSUA space but are nicely unfolded for high-order expansion spaces, exposing attracting orbits and properties of the two task phases (<xref ref-type="fig" rid="pcbi-1002057-g001">Figure 1B</xref>; see also <xref ref-type="supplementary-material" rid="pcbi.1002057.s008">Video S1</xref>).</p>
      </sec>
      <sec id="s2b">
        <title>Visual analysis of task-epoch specific population states</title>
        <p>The techniques introduced above were used to analyze MSU recordings obtained from the rat ACC (<xref ref-type="supplementary-material" rid="pcbi.1002057.s001">Figure S1</xref>) while the animals were situated in a radial-arm-maze decision-making task with temporal delay (<xref ref-type="fig" rid="pcbi-1002057-g002">Figure 2A</xref>). This task is considered to be ecologically valid in the sense that it mimics key aspects of rats' natural foraging, food-hording, and retrieval behavior (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Timberlake1">[48]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Olton1">[49]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>). The entire time on task was divided into six epochs with differing cognitive demands as illustrated in <xref ref-type="fig" rid="pcbi-1002057-g002">Figure 2A</xref> (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> for precise definition of the cognitive epochs). Two data sets were available for the present analyses: 1) Three animals recorded for up to 15 trials solely for the purposes of the present study. From these, only trials with good performance were selected ( = less than 3 test phase errors; median errors across all trials were 1, 0.5 and 2 for respectively for each animal), with an error defined as re-entrance into an arm from which food was already retrieved. 2) Six animals recorded for one or two trials from a previous study <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>, which will be used to further confirm the results obtained with the “multiple-trial animals” and to conduct an explicit comparison of high (&lt;2 errors) vs. low (&gt;4 errors) performance trials. Average trial duration (±SEM) was 159.3±19.7 s across all trials and animals. With a standard binning for the spike density estimates of 0.2 s, this resulted in an average of 797±99 firing-rate vectors per trial (see further below for a discussion on data size effects).</p>
        <fig id="pcbi-1002057-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002057.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Visualization of task-epoch-specific dynamics.</title>
            <p><bold>A.</bold> Schema of the delayed win-shift radial arm maze with the definition of separate task epochs (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> for exact definition). <bold>B.</bold> Three-dimensional projections of the MSUA space combining trials 1 to 5 of animal #1, obtained by PCA (left) and by Multi-Dimensional Scaling (right). <bold>C.</bold> Three-dimensional projections obtained by a Fisher Discriminant Analysis (FDA) of the training and test choice and reward epochs (multiple classes, centered and normalized for clarity) with the flow field (velocity vectors) indicated by arrows, i.e. these vectors give the magnitude and direction of change of the projected neural activity. Left: MSUA space. Right: Expanded <italic>5</italic><sup>th</sup> order space (using kernel-FDA). As in <bold>B</bold>, trials 1–5 of animal #1 were combined for this graph.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.g002" xlink:type="simple"/>
        </fig>
        <p>To provide a direct comparison with previous approaches for constructing neural state spaces, <xref ref-type="fig" rid="pcbi-1002057-g002">Figure 2</xref> shows three dimensional projections obtained in different ways from the first five trials of one of the multiple-trial animals which performs the task with less than three errors per trial. Consistent with our previous observations <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>, the MSUA space shows a visually apparent segregation among the different task epochs (indicated by the color-coding), using either PCA (<xref ref-type="fig" rid="pcbi-1002057-g002">Figure 2B</xref>, left) or multi-dimensional scaling (MDS; <xref ref-type="fig" rid="pcbi-1002057-g002">Figure 2B</xref>, right) for the 3-dimensional reconstruction.</p>
        <p><xref ref-type="fig" rid="pcbi-1002057-g002">Figure 2C</xref> shows the same data projected into a 3-dimensional space using a Fisher discriminant analysis technique (FDA; see e.g. an application to MSUA spaces in <xref ref-type="bibr" rid="pcbi.1002057-Durstewitz4">[19]</xref>). Like PCA, FDA amounts to just a linear transformation of the original variables. However, unlike PCA, the directions sought are such that the differences between group means are maximized while at the same time within-group jitter is minimized along them (for the <italic>O<sup>th</sup></italic> order higher-dimensional spaces we used a regularized kernel-FDA which is equivalent to a standard (regularized) FDA for <italic>O</italic> = 1 <xref ref-type="bibr" rid="pcbi.1002057-Mika1">[50]</xref>; see <xref ref-type="sec" rid="s4">Materials and Methods</xref> and <xref ref-type="supplementary-material" rid="pcbi.1002057.s006">Text S1</xref>). The figure displays the <italic>flow field</italic> in addition to the data points, i.e. the speed and direction of movement of the neural population state at each time bin (computed as the difference between temporally consecutive vector pairs). While the flow field in the FDA-reduced original MSUA space may appear relatively disordered (<xref ref-type="fig" rid="pcbi-1002057-g002">Figure 2C</xref>, left), in the expanded space (<xref ref-type="fig" rid="pcbi-1002057-g002">Figure 2C</xref>, right) a consistent movement into each of the task related clusters at points far from any cluster center appears to occur (as will be statistically confirmed below). In summary, these 3-dimensional visualizations seem to suggest that different cognitively defined task epochs are associated with different population states which exhibit attractor-like properties (convergence of flow), a phenomenon that becomes apparent only after expanding the spaces to sufficiently high dimensionality using the techniques outlined in the previous section.</p>
        <p>We stress that, in principle, expansion of spaces to much higher dimensionality is a well-known technique in statistical classification approaches to improve the linear separability of classes <xref ref-type="bibr" rid="pcbi.1002057-Vapnik1">[27]</xref>. However, a serious statistical issue with such approaches is the potential problem of “over-fitting” the data: For instance, <italic>n</italic>+1 points can always be perfectly linearly separated in a <italic>n</italic>-dimensional space, even if their configuration is purely random. To circumvent this problem, two approaches which are standard in statistics (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Hastie1">[46]</xref>) and machine learning (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Bishop1">[44]</xref>) were employed here: First, a regularization term (fixed throughout the study; Eq. S3 in <xref ref-type="supplementary-material" rid="pcbi.1002057.s006">Text S1</xref>), which penalizes model complexity and thus reduces the <italic>efficient</italic> dimensionality of the fitted classifier (typically way beyond the nominal dimensionality), was included in the optimization criterion for the kernel-FDA. The technique of cross-validation (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Bishop1">[44]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Hastie1">[46]</xref>) is used in the next section for deriving this regularization term and the expansion order optimal for across-trial predictions (<xref ref-type="sec" rid="s4">Materials and Methods</xref>). Over-fitting would imply poor generalization to new data sets not used for fitting the classifier, i.e. a high out-of-sample prediction error across trials. Second, the performance of the classification statistics on the original data was compared to bootstrap data in which the relation between neural population vectors and cognitive-class labels has been randomized. Such bootstrap samples have to be devised carefully such that they retain features of the original time series (like their temporal autocorrelations) which are not necessarily related to task-imposed structure, as explained in the sections to follow.</p>
      </sec>
      <sec id="s2c">
        <title>Stability of task-epoch specific states across trials</title>
        <p>For determining the optimal state space we assessed whether the assignment of population-interaction patterns to task epochs could be correctly predicted in a test set of trials based on information obtained solely from a non-overlapping training set of trials, or, from another perspective, how stable the task-epoch-specific clusters in <italic>O<sup>th</sup></italic>-order expansion space are across multiple trials. To these ends, state spaces were reconstructed exclusively from the first set of 4 to 8 well-performed trials, and data points from the (non-overlapping) set of the last 4–8 well-performed trials were projected into this space (“forward predictions”). Vice versa, “backward predictions” from the last to the first trials were also obtained. If the neural dynamics remain largely invariant across multiple trials, then vector points on any subsequent trial should fall into the same clusters derived only from the first few trials. This analysis was performed for any pair of task epochs using the most discriminating direction as obtained by kernel-FDA within the expanded high-dimensional spaces. Assuming that the projections of the <italic>O<sup>th</sup></italic>-order population vectors from any two task epochs onto this maximally separating direction are normally distributed (which will almost inevitably be the case due to the central limit theorem, as the projections are sums of many random variables), for each population pattern <bold>ν</bold>(<italic>t</italic>) the probabilities <italic>P</italic>(<bold>ν</bold>(<italic>t</italic>)|<italic>C</italic><sub>1</sub>) and <italic>P</italic>(<bold>ν</bold>(<italic>t</italic>)|<italic>C</italic><sub>2</sub>) that it comes from one task-epoch or the other can be evaluated. Assigning population vectors to task epochs based on these probabilities yields a segregation error (SE) for each pair of task epochs defined as the relative number of misclassified population patterns <bold>ν</bold>(<italic>t</italic>) (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> for discussion of further advantages this brings over other kernel-based approaches). By chance this misclassification rate will be 50% since we fixed the <italic>prior</italic> probabilities <italic>P</italic>(<italic>C</italic><sub>1</sub>) and <italic>P</italic>(<italic>C</italic><sub>2</sub>) at 0.5 for any pair of epochs, such that the results would not be biased towards the longer-lasting epochs. Note that all time bins (population vectors) from a given task epoch class were entered into this analysis, regardless of whether they came from the same or from different trials.</p>
        <p>For checking predictability across trials, the crucial aspect now is that the optimal discriminant direction was solely obtained from the first (or last) couple of (reference) trials, and then fixed and used for out-of-sample predicting the corresponding misclassification rate SE<sub>predic</sub> (for “predicted SE”) of population interaction patterns to task-epochs for the non-overlapping set of last (or first, respectively) prediction trials (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> for more details). To evaluate the significance of the observed SE<sub>predic</sub>, bootstrap data were constructed by randomly shuffling stretches of the <bold>ν</bold>(<italic>t</italic>) vector time series that retained entire trajectories form a given specific task epoch, i.e. each bootstrap replication preserved all temporal autocorrelations up to the length of the relevant task epochs. Consistent with the visual displays presented above, for <italic>O</italic>∼5 SE<sub>predic</sub> was significantly lower (p&lt;0.01) in the original as compared to the bootstrap data (<xref ref-type="fig" rid="pcbi-1002057-g003">Figure 3A</xref>; see <xref ref-type="supplementary-material" rid="pcbi.1002057.s002">Figure S2</xref> for a schema on bootstrap construction). Note, however, that SE<sub>predic</sub> for the bootstraps is also less than what would be expected by chance, i.e. &lt;0.5, such that prediction <italic>accuracy</italic> in the bootstraps is above chance level. This is because the bootstraps retain original auto-correlations as indicated above, which by themselves may induce some state space clustering, irrespective of task-epoch membership. Surprisingly, in contrast to the case <italic>O</italic>∼5, for <italic>O</italic> = 1 (i.e., within the DC-MSUA space) predictability across trials was not significantly better in the original than in the bootstrap data. Thus there does not seem to be sufficient information in the lower-dimensional state spaces to allow prediction of population pattern assignments across trials. Rather, given the experimental noise and the potentially nonlinear state space structures, neural interactions have to be included to establish stable associations between task epochs and population patterns, or, in other words, further trajectory separation beyond the one achieved by delay-coordinates is indeed necessary to reveal across-trial stability. Specific comparisons for each pair of task epochs are shown in <xref ref-type="fig" rid="pcbi-1002057-g003">Figure 3B</xref>. Finally, for <italic>O</italic>&gt;5 predictability starts to deteriorate again. Hence, it seems that there is a maximum order of activity products which would be required to optimally resolve task-epoch-related structure in the neural state spaces, a finding consistent across the different data sets studied (<xref ref-type="fig" rid="pcbi-1002057-g003">Figure 3C</xref>). We emphasize that this result does not imply that neural activity interactions up to some precise order (<italic>3<sup>rd</sup>–5<sup>th</sup></italic>) are important– it only shows that below or above a certain expansion order <italic>generalization</italic> performance degrades, which can be the case for purely statistical reasons (i.e., simply because there are too few data or too few simultaneously recorded neurons to reliably estimate the optimum order of interactions).</p>
        <fig id="pcbi-1002057-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002057.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Out-of-sample (across trials) predictability of the task-epoch-specific organization of population activity.</title>
            <p><bold>A.</bold> Statistical analysis of across-trial predictability for animal #1. The predicted SE (SE<sub>predic</sub>) is obtained by first constructing a classifier for each pair of task epochs based on a regularized version of Fisher's discriminant criterion exclusively from the first few trials, and then applying it for assigning activity vectors from the last few trials (the test set) to task epochs. SE<sub>predic</sub> values averaged across all task-epoch pairs (error bars = SEM) reach a minimum at the rate-interactions order <italic>O</italic> = 5 and are significantly lower than those obtained for matched bootstrap data (one-sided non-parametric test at p = 0.01). In contrast, the DC-MSUA space (<italic>O</italic> = 1) does not reveal this predictive structure (p&gt;0.1). Note that chance level is 50% here since a-priori probabilities were set to 0.5 for each pair of task epochs. Reward epochs were excluded from the comparisons due to too few data points. <italic>y-axis</italic> scale is logarithmic in plots A and C. The asterisk indicates a significant difference in the comparison <italic>O</italic> = 1 vs. <italic>O</italic> = 5 for the original data (t-test, Wilcoxon ranksum test, n = 6, both p&lt;0.05; normality assumptions valid according to Lilliefors and Chi-square tests, p&gt;0.12). The regularization penalty was selected such that it provides the minimum SE<sub>predic</sub> for different orders <italic>O</italic> for this particular animal, and then was fixed for all other analyses (see <xref ref-type="supplementary-material" rid="pcbi.1002057.s003">Figure S3</xref> for results obtained with different values of the regularization parameter used in the kernel-FDA). <bold>B.</bold> Individual comparisons for all task-epoch pairs for the <italic>O</italic> = 5 space. <bold>C.</bold> Mean SE<sub>predic</sub> averaged across all three recorded animals, attaining a significant minimum at the rate-interactions order <italic>O</italic> = 5 (Wilcoxon rank-sum test, n = 3 animals, p&lt;0.05). Both forward (from the first to the last set of trials) and backward (from the last to the first set) are shown. Detailed results for animals #2, 3 are shown in <xref ref-type="fig" rid="pcbi-1002057-g004">Figure 4</xref>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.g003" xlink:type="simple"/>
        </fig>
        <p>On the other hand, the optimal orders we obtained do not seem to be completely arbitrary (in the sense of being determined purely by the number of data points and recorded units): First, similar optimal orders were also observed for the other two animals (<xref ref-type="fig" rid="pcbi-1002057-g004">Figure 4</xref>) which differed in the number of recorded units (18, 13 and 21, respectively) and the size of the training and prediction sample sets (5, 8 and 4 trials, respectively). Second, we performed additional controls by including subsets of neurons of differing size (<xref ref-type="fig" rid="pcbi-1002057-g004">Figure 4</xref>, upper left) and by artificially augmenting or decimating the data sets in a way that preserved the original distributions (<xref ref-type="fig" rid="pcbi-1002057-g004">Figure 4</xref>, right). Hence, we conclude that there is an organization of task-related population interaction patterns predictable across many trials which is optimally revealed by expanding the MSUA space by taking higher orders of activity interactions into account.</p>
        <fig id="pcbi-1002057-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002057.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Robustness of across-trials predictability of task-epoch-specific organization of population activity.</title>
            <p>Plots show results for different ACC networks (different animals), numbers of recorded units, and sample sizes (numbers of trials). <bold>A.</bold> Left: Statistical analysis of SE<sub>predic</sub> for different numbers of selected units from animal #1. Right: Analysis of SE<sub>predic</sub> for animal #1 for different numbers of data points obtained by artificially augmenting or decimating the original data set (by either bootstrapping the original data or randomly removing vectors from it). <bold>B.</bold> Same for animal #2. <bold>C.</bold> Same for animal #3. Note that optimal prediction always occurs around similar high-orders of rate interactions as for animal #1 (<xref ref-type="fig" rid="pcbi-1002057-g003">Figure 3</xref>). Asterisks indicate significant differences for the comparisons indicated (Wilcoxon rank-sum test, n = 6, p&lt;0.05 for both animals #2 and #3; nonparametric tests were used because Lilliefors [p&lt;0.003, 0.04] and Chi-square [p&lt;0.003, 0.01] tests indicated that the data significantly deviated from normality, thus violating the assumptions for parametric testing).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.g004" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2d">
        <title>Relation of state space structure to behavioral performance</title>
        <p>In a previous study <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref> we had compared animals performing well on the task to animals which committed a lot of behavioral errors. We observed that in animals performing poorly state space segregation (task-epoch-dependent clustering) was generally comprised compared to trials on which only few (0 or 1) errors were committed. Here we re-addressed this issue using the methods developed above (<xref ref-type="fig" rid="pcbi-1002057-g005">Figure 5</xref>). Data from 8 trials (coming from 4 different animals) performing with less than two errors ( = “good performers”) and 8 trials (coming from 5 animals) with more than four errors ( = “bad performers”) were used. These two groups of trials were combined into two separate data sets for analysis (termed “single-trial” datasets). This works since the basic structure of the cognitively-defined classes was the same for all animals, i.e., the task obviously was the same for all animals, and population patterns specific for different task episodes like choices, rewards, or the delay phase, were a common feature of ACC activity. Since only a single trial with electrophysiological recordings, however, was generally available from each of these animals, results were cross-validated by removing each single one of the animals from the data set in turn (i.e., a jackknife validation <xref ref-type="bibr" rid="pcbi.1002057-Efron1">[51]</xref>).</p>
        <fig id="pcbi-1002057-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002057.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Statistical analysis of task-epoch separation in state spaces for the many-animal single-trial data set.</title>
            <p>Black solid curves from 8 trials in which animals performed with less than two incorrect arm choices, gray dotted curves from 8 trials where more than four incorrect arm choices were made. <bold>A.</bold> Task-epoch mean segregation errors (SE) for the good (grey) and bad (black) performance groups averaged across all task-epoch pairs (n = 14, error bars = SEM). Asterisks indicate significant differences for the comparisons indicated. For high-performance animals, a two-tailed non-parametric Wilcoxon rank-sum test was used (n = 14, p&lt;0.04), as data significantly deviated from normality (two-sided Lilliefors test, p&lt;0.03; Chi-square test, p&lt;0.01). For the low-performance group, normality held (Lilliefors test, p&gt;0.44, 0.41), and the comparison between <italic>O</italic> = 2 and <italic>O</italic> = 4 conditions is highly significant using either a t-test (p&lt;0.0001) or Wilcoxon ranksum test (p&lt;0.0001). Comparisons between low- and high- performance groups are also significant for <italic>O</italic>&gt;3 (n = 14; p&lt;0.03, Wilcoxon ranksum test). <bold>B.</bold> Individual task-epoch-pair comparisons. <bold>C.</bold> Kullback-Leibler distance between task-epoch distributions averaged across all task-epoch pairs for high- (black) and low- (gray) behavioral performance trials (asterisk and error bars as in <bold>A</bold>). Task-epoch distributions chart the probabilities of the animal being in a task-epoch <italic>C</italic> given a population activity vector <bold>ν</bold>(<italic>t</italic>), i.e. <italic>P</italic>(<italic>C</italic>|<bold>Φ</bold>(<italic>t</italic>)). See <xref ref-type="sec" rid="s4">Materials and Methods</xref> for more details.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.g005" xlink:type="simple"/>
        </fig>
        <p>Consistent with our previous observations <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>, discriminability in the MSUA space is significantly worse (Wilcoxon rank-sum test T<sub>13</sub> = 113, p&lt;0.05) for “bad performers” (<xref ref-type="fig" rid="pcbi-1002057-g005">Figure 5A</xref>, dark curve for <italic>O</italic> = 1) when compared to “good performers” (<xref ref-type="fig" rid="pcbi-1002057-g005">Figure 5A</xref>, gray curve for <italic>O</italic> = 1). However, as <xref ref-type="fig" rid="pcbi-1002057-g005">Figure 5A</xref> shows, for <italic>both</italic> groups discriminability significantly increases just up to expansion orders of about 5, i.e. the segregation error (SE) as defined further above (computed from FDA with the same regularization as above, see <xref ref-type="sec" rid="s4">Materials and Methods</xref>) significantly decreases (Wilcoxon ranksum tests, p&lt;0.03; see details in <xref ref-type="fig" rid="pcbi-1002057-g005">Figure 5</xref> legend). Thus, as the maximum order <italic>O</italic> of the reconstructed state space is increased, cognitively relevant features of the neural dynamics are increasingly better resolved to the extent that an organized dynamics becomes evident even in situations where previous methods had failed (see <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>). However, as for the multiple-trials data analyzed in the previous section, SE for <italic>O</italic>&gt;5 grows again for both groups (<xref ref-type="fig" rid="pcbi-1002057-g005">Figure 5A</xref>), suggesting once again that there may be a maximum order of activity interactions for which trajectories are optimally resolved.</p>
        <p>Finally, and again consistent with previous results <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>, although SE decreases for both groups, there still remains a significant difference between the low and the high performance groups even for <italic>O</italic>&gt;3 (Wilcoxon test, p&lt;0.04), confirming that still some of the state space organization is corrupted in bad performers. Detailed task-epoch comparisons are shown in <xref ref-type="fig" rid="pcbi-1002057-g005">Figure 5B</xref>. Similar results were obtained with information-theoretic measures of task-epoch segregation like the relative entropy (Kullback-Leibler divergence, e.g. <xref ref-type="bibr" rid="pcbi.1002057-Bishop1">[44]</xref>) between the conditional probability distributions of task-epochs given a specific firing-rate vector (<xref ref-type="fig" rid="pcbi-1002057-g005">Figure 5C</xref>; see <xref ref-type="sec" rid="s4">Materials and Methods</xref> section). Moreover, further control analyses indicated that results are not significantly altered by using state spaces constructed by using different types of expansion, other classification criterions, or other smoothing parameters for the spike trains (as shown in <xref ref-type="supplementary-material" rid="pcbi.1002057.s003">Figure S3</xref>).</p>
      </sec>
      <sec id="s2e">
        <title>Convergence towards task-epoch-specific neural ensemble states</title>
        <p>The most interesting aspect of the present methodological approach is that it permits to examine the <italic>flow</italic> of neural trajectories during performance of a cognitive task, dynamical properties that may not be well accessible in the unprocessed representation of MSU activity as demonstrated in the previous sections (<xref ref-type="fig" rid="pcbi-1002057-g003">Figure 3B</xref>, left). Here we analyzed the attracting behavior suggested by the three-dimensional visualizations more systematically. First, a simple statistical approach was taken. Activity flows were evaluated in the low-dimensional kernel-PCA projections of task epochs, since velocity vectors cannot be reliably obtained in the extremely high-dimensional expanded spaces (for similar reasons for which we used kernel methods before; see <xref ref-type="supplementary-material" rid="pcbi.1002057.s004">Figure S4</xref> and <xref ref-type="supplementary-material" rid="pcbi.1002057.s007">Text S2</xref> for further discussion). <xref ref-type="fig" rid="pcbi-1002057-g006">Figure 6</xref> displays the speed of movement at each data point in these projections as a function of the likelihood of a population pattern given the task epoch to which it belongs, i.e. <italic>p</italic>(<bold>ν</bold>(<italic>t</italic>)|<italic>correct task-epoch classification</italic>), evaluated using FDA in the high-dimensional <italic>O<sup>th</sup></italic>-order spaces for the prediction set of trials (see <xref ref-type="fig" rid="pcbi-1002057-g003">Figure 3</xref>). If the task-epoch states have indeed attracting properties, one would expect that vector points which exhibit little movement should have a high likelihood of correct classification, reflecting the fact that these points should be found close to the cluster centers. Consistent with the idea that in low-order spaces trajectory flows should appear convoluted and disordered, for <italic>O</italic> = 1 velocities were evenly distributed across all regions of the state space, i.e. the velocity of movement of the neural state was largely independent of the likelihood of correct classification (<xref ref-type="fig" rid="pcbi-1002057-g006">Figure 6</xref>, left-top; <italic>O</italic> = 1). In contrast, for higher-order expansions the likelihood of correct classification rapidly falls off as the speed of neural state changes increases (<xref ref-type="fig" rid="pcbi-1002057-g006">Figure 6</xref>, left-bottom; <italic>O</italic> = 5), confirming that regions where trajectories move quickly are on average far from the cluster centers.</p>
        <fig id="pcbi-1002057-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002057.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Convergence of trajectories as assessed from 3-dimensional projections.</title>
            <p>As an approximate measure of convergence to task-epoch states the likelihoods of correct classification of population vectors <bold>ν</bold>(<italic>t</italic>) into task-epoch sets, i.e. <italic>p</italic>(<bold>ν</bold>(<italic>t</italic>)|<italic>Task-Epoch</italic>) were charted as a function of the amplitude of the velocity vector in the 3-dimensional PCA projection (determination of velocities directly in the <italic>O<sup>th</sup></italic>-<italic>order</italic> spaces is very unreliable due to their high dimensionality; e.g. <xref ref-type="bibr" rid="pcbi.1002057-Bishop1">[44]</xref>). In other words, these graphs give the probability density of correct assignment of a neural activity pattern to the right task epoch, or correct-class-likelihood, as a function of the rate of activity change at this point (normalized values across all vectors). Class-likelihoods were based on Bayes-optimal classifiers within the high-dimensional <italic>O<sup>th</sup></italic>-order spaces and were assessed on test sets of trials (as explained in <xref ref-type="fig" rid="pcbi-1002057-g003">Figure 3</xref>), i.e. refer to out-of sample predictions. Graphs are for increasing rate-interaction orders <italic>O</italic> from top to bottom. Left: original data; right: bootstrap data (inversion of time). Error bars of insets give 99% confidence intervals. As <italic>O</italic> increases, lower velocities are associated with higher likelihoods of correct classification, indicating that the neural system dynamic slows down as it approaches the center of such putative attracting sets (see <xref ref-type="sec" rid="s3">discussion</xref> in the main text). Linear fits to the averages of <italic>log</italic>(<italic>P</italic>(<bold>ν</bold>(<italic>t</italic>)|<italic>Task-Epoch</italic>)) versus velocity across the 20 bins into which the x-axis was divided (RMS error of fits &lt;1% of the geometric mean; numbers <italic>b</italic> refer to the slopes of the fits) revealed that differences in slope between the original and bootstrap data were highly significant for <italic>O</italic> = 5 (p&lt;0.006, t-test, n = 20) but not <italic>O</italic> = 1 or <italic>O</italic> = 3. Data shown are for multiple-trial datasets. Insets give the full distributions of data points.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.g006" xlink:type="simple"/>
        </fig>
        <p>Although these results are suggestive, they by themselves do not conclusively rule out alternative explanations unrelated to the potentially attracting nature of the task-specific ensemble states, e.g. the tendency of extreme values to be followed by values closer to the mean simply by laws of probability (“regression to the mean”), auto-correlative properties of the time series, or by systematic deformations of the flow field induced by PCA. To statistically control for such alternatives, we performed a bootstrap test. The right column of <xref ref-type="fig" rid="pcbi-1002057-g006">Figure 6</xref> shows results from the same analysis as performed on the bootstrap data when the temporal sequence of binned firing rates was inverted for all neurons within task-epochs. Therefore, task-epoch-specific lengths are preserved, but any causal relationships in the original time series are destroyed. For <italic>O</italic> = 1, the correct classification likelihood as a function of velocity behaves similar for bootstrap and original time series, but at higher expansion orders the fall-off of correct classification likelihood with vector velocity is significantly less steep in the bootstrap than in the original time series (paired <italic>t-test</italic> between the two slopes, p&lt;0.001 for <italic>O</italic> = 5, see <xref ref-type="fig" rid="pcbi-1002057-g006">Figure 6</xref> caption) as demonstrated by the linear fits to the log-linear graphs. In summary, different cognitively defined task epochs may potentially act as attracting states of the neural dynamics, i.e. regions of state space towards which all trajectories tend to converge with high likelihood and within which they remain bounded for some time.</p>
        <p>While this analysis suggests attracting behavior related to the task epochs, it was performed on a three-dimensional representation in which velocity vectors could still be reliably determined. We therefore next sought to precisely quantify within the <italic>full high-dimensional spaces</italic> to which degree the (mathematical) conditions defining attracting states were met in the empirical data, with the statistical analysis based on the task-epoch boundaries defined previously. As the definition of these boundaries did not include any knowledge about putative attractor states, there is no a-priori reason why there should be strong convergence over time towards the center of these states. Attracting state conditions are illustrated in <xref ref-type="fig" rid="pcbi-1002057-g007">Figure 7A</xref> which shows a schema of different kind of convergent trajectories in the high-dimensional state spaces. <xref ref-type="fig" rid="pcbi-1002057-g007">Figure 7B</xref> shows within the 3-dimensional PCA projections some <italic>empirical</italic> examples of such trajectories which either cycle within or return to the task-epoch-specific population states. <xref ref-type="fig" rid="pcbi-1002057-g007">Figure 7C</xref> precisely quantifies, both for the single-trial data sets (red bars, left y-axis) and for the prediction-sets of trials in the multiple-trial data (blue bars, right y-axis), the fraction of trajectories which escaped again from the task-epoch specific clusters without returning to them within the given period (i.e. trajectories which are not of the kind “a” or “b” in <xref ref-type="fig" rid="pcbi-1002057-g007">Figure 7A</xref>). For <italic>O</italic>≈3–5, consistently across all task epochs this was only the case for ∼15% of the trajectories (across all 3 animals) when escape behavior was determined in the prediction trials while event boundaries were those defined in the non-overlapping reference set of trials, as shown in <xref ref-type="fig" rid="pcbi-1002057-g007">Figure 7C</xref> (blue bars, right y-axis; and ∼8% of the escaped trajectories when assessed within the reference set of trials, see red bars, left y-axis). Thus, these results further support the hypothesis that the task-epoch clusters constitute regions of convergence with &gt;80% of trajectories returning to these states or bound within them. In summary, the quantitative analysis of trajectory flows in the optimal state spaces seems to confirm that different cognitively defined task epochs of the present memory-based decision making task act as high probability regions of convergence.</p>
        <fig id="pcbi-1002057-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002057.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Quantitative assessment of the attracting behavior of task-epoch specific ensemble states within the full high-dimensional spaces.</title>
            <p><bold>A.</bold> Schema illustrating different types of trajectories which would constitute evidence for an attracting region defined by the task epochs: Trajectory “a” is completely confined within the task-epoch state, trajectory “b” leaves the task-epoch state (for instance, due to perturbation by noise) and then quickly converges back to it, and trajectory “c” is rapidly attracted into the task-epoch state. Black dots in the figure highlight incorrectly classified firing-rate vectors. If only trajectories of types a-c were present, this would strongly suggest that the task-epoch states are indeed attractors. This condition is formally evaluated in C. <bold>B.</bold> Examples of convergent trajectories, cycling within or returning to the task-epoch states, in the 5<sup>th</sup>-order expanded spaces (corresponding to different trials of the task). <bold>C.</bold> Percentage of trajectories which escape from task-epoch states for the single-trial data sets (red) and as predicted across trials for the multiple-trial data sets (white) within the full high-dimensional <italic>O<sup>th</sup></italic>-order spaces. A total of ∼20 trajectories was available for each task-epoch specific state during the prediction set of trials. The absence of any trajectories escaping from a bounded region of state space (as defined by the task epochs), i.e. if only trajectories of types a-c were present, would suggest the existence of a basin of attraction which is stable across trials. Asterisk indicates significance for the comparison <italic>O</italic> = 1 vs. <italic>O</italic> = 5 (nonparametric Mann-Whitney-U test, p&lt;0.05). Inset: A weaker condition (attracting set condition) will be met if trajectories escaping from the task-epoch set still remain within a trapping region <xref ref-type="bibr" rid="pcbi.1002057-Wiggins1">[70]</xref>. The graph gives the average percentage of trajectories violating this attracting set definition. Note that task-epoch specific states were defined by narrow (∼1 s) temporal windows around the relevant event such that the majority of available data points are not included in the definition of any one of these states. Hence, the attracting properties revealed here are not just a trivial consequence of a very broad definition of the neural states.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.g007" xlink:type="simple"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>According to many neuro-computational theories, cognitive processes in the brain are implemented through the system's dynamical properties, i.e. the movement of neural trajectories among different attracting states that represent the contents of cognition (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Durstewitz1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Colgin1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Hopfield1">[34]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-OReilly1">[36]</xref>). A number of previous experimental observations have therefore suggested the existence of attractor-like behavior in the nervous system, or were at least interpreted this way: Many of these studies dealt with forms of persistent <xref ref-type="bibr" rid="pcbi.1002057-Aksay1">[52]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Egorov1">[53]</xref> or reoccurring spatio-temporal activity patterns <xref ref-type="bibr" rid="pcbi.1002057-Cossart1">[54]</xref> as they may be relevant to computational demands in working memory, e.g. temporary active maintenance of stimulus information required in a forthcoming choice situation <xref ref-type="bibr" rid="pcbi.1002057-Durstewitz1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Wang1">[5]</xref>. Other studies tried to establish direct links between neural attracting behavior and sensory or environmental representations <xref ref-type="bibr" rid="pcbi.1002057-Mazor1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Wills1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Niessing1">[23]</xref>. With the recent progress in multiple single-unit recordings there has also been a rise in the application of advanced techniques from multivariate statistics and machine learning for reconstructing properties of the neural system dynamics or identifying re-occurring patterns, including different dimensionality reduction <xref ref-type="bibr" rid="pcbi.1002057-Mazor1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Deadwyler1">[55]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-Yu1">[57]</xref>, pattern classification <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Deadwyler1">[55]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Fellous1">[58]</xref>, and time series analysis approaches <xref ref-type="bibr" rid="pcbi.1002057-Jones1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Durstewitz4">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Seidemann1">[59]</xref>. However, most of the previous experimental studies inferred attracting dynamics indirectly from, e.g., the property that neural activity after some time settled into one of several discrete states (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Niessing1">[23]</xref>). In contrast, a more direct demonstration of a convergent flow of neural trajectories as a defining property of attractor-like structures has been, to our knowledge, mostly lacking so far. This may at least partly be attributed to the methodological difficulties associated with revealing the flow of trajectories directly in the experimentally accessed low-dimensional subspaces, i.e. the spaces spanned by the spiking activities of the set of recorded neurons (cf. <xref ref-type="fig" rid="pcbi-1002057-g001">Figure 1</xref>).</p>
      <p>Here we therefore combined well-established approaches from nonlinear dynamics <xref ref-type="bibr" rid="pcbi.1002057-Sauer1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Kantz1">[29]</xref> and statistical learning theory <xref ref-type="bibr" rid="pcbi.1002057-Vapnik1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Hastie1">[46]</xref> for expanding spaces to a sufficiently high dimensionality such that the flow of trajectories becomes resolved. Since the expanded <italic>O<sup>th</sup></italic>-order embedding space can have very high dimensionality (for instance, for <italic>O</italic> = 5 and <italic>n</italic> = 30 neurons the dimensionality would be on the order of 10<sup>6</sup>), specialized and strongly regularized algorithms (<italic>kernel</italic>-methods) were necessary to perform the relevant computations in these spaces <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref>. However, in the present study this was done solely for computational tractability and numerical stability: The kernel function employed here is mathematically equivalent to vector products in the high-dimensional expanded spaces (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>), and hence does not change the nature of any of the results or arguments. We furthermore emphasize that kernel algorithms designed for very high-dimensional systems <xref ref-type="bibr" rid="pcbi.1002057-BenHur1">[26]</xref> are well-benchmarked techniques developed during the last decade <xref ref-type="bibr" rid="pcbi.1002057-Bishop1">[44]</xref>, as are the delay embedding <xref ref-type="bibr" rid="pcbi.1002057-Takens1">[38]</xref> and multinomial basis expansion <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref> procedures employed here. All of these methods have been extensively tested with both simulated and real data in many areas of science <xref ref-type="bibr" rid="pcbi.1002057-BenHur1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Bishop1">[44]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-Hastie1">[46]</xref>. For instance, in functional neuroimaging the usage of kernel methods and high-dimensional classifiers becomes more and more of a routine now (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Pereira1">[60]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-Friston1">[63]</xref>). The particular combination of these techniques for their application to electrophysiological data, on the other hand, to our knowledge presents a novel aspect of this work.</p>
      <p>Using those approaches, we found that by augmenting the space with dimensions defined as products of neural firing rates, population interaction patterns belonging to distinct, cognitively defined task epochs were maximally separated and predictive of neural-behavioral state associations on future trials (cf. <xref ref-type="fig" rid="pcbi-1002057-g003">Figures 3</xref>, <xref ref-type="fig" rid="pcbi-1002057-g004">4</xref> and <xref ref-type="fig" rid="pcbi-1002057-g007">7</xref>). More importantly, a consistent flow of neural trajectories and their convergence to task-epoch-specific ensemble states became apparent that was not obvious in the lower-dimensional embeddings of neural activity. Thus, the present memory-based decision making task seems to involve different (semi-)attracting states (in a statistical, probabilistic sense) among which neural activity may travel to implement task-related cognitive processes. These states had a cognitive interpretation as they were specific to particular task epochs. The organization of neural activity into different attracting states was furthermore related to behavioral performance: In animals exhibiting a high number of behavioral errors this structure was significantly degraded (<xref ref-type="fig" rid="pcbi-1002057-g005">Figure 5</xref>; see also <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>), perhaps reflecting a general “flattening of attractor basins” associated with diminished memory- and choice-related functions <xref ref-type="bibr" rid="pcbi.1002057-Durstewitz5">[64]</xref>. Therefore our results seem to support long-standing computational theories about the neural implementation of cognitive functions <xref ref-type="bibr" rid="pcbi.1002057-Wills1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Rabinovich1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Aksay1">[52]</xref>–<xref ref-type="bibr" rid="pcbi.1002057-Cossart1">[54]</xref>.</p>
      <sec id="s3a">
        <title>Implications of higher-order neural activity interactions</title>
        <p>We observed that unfolding of trajectories and separation of task-epoch clusters became stable across trials when higher-order activity products were taken into account, but did not improve further when moving to arbitrarily high expansion orders. This, in other words, seems to imply that considering the joint activity constellations of a couple of neurons will still add information about the neural dynamics not easily or directly available from single unit activities, while still higher-order interactions may not be relevant: For sub-optimal state spaces the clustering into task-epoch-specific patterns was either unclear (<italic>O</italic> = 1) or had no predictive power across trials (<italic>O</italic>&gt;6; cf. <xref ref-type="fig" rid="pcbi-1002057-g003">Figure 3</xref>). Note, however, that higher-order activity products are used here mainly as a statistical tool for disentangling trajectory flows and not for assessing the cognitive relevance of neural correlations. Thus, we cannot conclusively rule out, for instance, that adding many more neurons and data points to the state spaces than were available in the present study would shift the optimal expansion dimensionality to different orders. The specific value for the optimal expansion order obtained here may just reflect the well-known (in statistics; e.g. <xref ref-type="bibr" rid="pcbi.1002057-Hastie1">[46]</xref>) “bias-variance tradeoff” for our data set (in the sense of yielding low generalization errors, i.e. without over-fitting the data).</p>
        <p>Nevertheless it is still remarkable that for all the different types of data sets studied here (multiple-trials vs. many animals), different numbers of recorded units, and different numbers of trials (and hence data points) a similar order of activity interactions appeared to be optimal. Similarly, the control studies reported in <xref ref-type="fig" rid="pcbi-1002057-g004">Figure 4</xref> suggest that sample size effects cannot completely account for the specific optimality value obtained here. Indeed, a recent study, performed in visual cortex, revealed the importance of higher-order correlations in local neural ensembles like recorded here, while only second-order correlations seemed to be the relevant for information transmission across larger cortical distances <xref ref-type="bibr" rid="pcbi.1002057-Ohiorhenuan1">[65]</xref>. The importance of higher-order correlations among neurons for information processing has also been stressed by many previous authors <xref ref-type="bibr" rid="pcbi.1002057-Averbeck1">[43]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Montani1">[66]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Schneidman1">[67]</xref>, e.g. by relating multiple-spike coincidence statistics to significant behavioral events <xref ref-type="bibr" rid="pcbi.1002057-Riehle1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Fujisawa1">[42]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Grn1">[68]</xref>, or by computing the information gained from correlations while decoding the current stimulus from the neural activity <xref ref-type="bibr" rid="pcbi.1002057-QuianQuiroga1">[69]</xref>. Some research had suggested that higher than second order correlations are redundant, at least in some preparations like the retina which may strongly differ in their structural and computational properties from the neocortex <xref ref-type="bibr" rid="pcbi.1002057-Schneidman1">[67]</xref>. On the other hand, most recently it was suggested that some of the low bounds found in earlier studies may be an artifact of the limited number of experimentally accessed units <xref ref-type="bibr" rid="pcbi.1002057-QuianQuiroga1">[69]</xref>. Finally, studies in somatosensory cortex also found similar bounds on the maximum order of perceptually relevant neural activity interactions as suggested here <xref ref-type="bibr" rid="pcbi.1002057-Montani1">[66]</xref>.</p>
      </sec>
      <sec id="s3b">
        <title>Attracting states in neural computation</title>
        <p>Within the optimal order expansion spaces, the stable and attracting nature of the task-epoch-specific states became apparent (cf. <xref ref-type="fig" rid="pcbi-1002057-g007">Figure 7</xref>): The neural dynamics progressively slows down as trajectories approach the cluster centers (<xref ref-type="fig" rid="pcbi-1002057-g006">Figure 6</xref>) and the majority of trajectories cycles within or returns towards these states (<xref ref-type="fig" rid="pcbi-1002057-g007">Figure 7</xref>), indicating that there should be bounded regions of the neural state space which capture and contain neural trajectories. Just like in most previous studies indicating attractor-like dynamics (e.g., <xref ref-type="bibr" rid="pcbi.1002057-Mazor1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Wills1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Niessing1">[23]</xref>), we cannot rule out, however, that these states are stimulus-driven, i.e. become attracting states only under the influence of certain (sensory or motor) stimulus conditions, rather than being a property of the intrinsic (autonomous) dynamics. For instance, in Wills et al. <xref ref-type="bibr" rid="pcbi.1002057-Wills1">[20]</xref> or in Niessing and Friedrich <xref ref-type="bibr" rid="pcbi.1002057-Niessing1">[23]</xref> the different “categorical” steady state population responses which reflect attracting dynamics are observed for different types of external stimuli (spatial layout of a maze in the first and olfactory composite stimuli in the second case). Likewise, in our case specific spatial, motor, olfactory, or visual properties may be associated with the choice and reward periods.</p>
        <p>There are three observations, however, which make it less likely that only external factors account for establishing different attracting states: First, also the delay period where the animals are confined to one arm of the maze and lights are switched off approximately acts as an attracting set of the dynamics, just like the other task epochs (<xref ref-type="fig" rid="pcbi-1002057-g003">Figures 3B</xref> and <xref ref-type="fig" rid="pcbi-1002057-g005">5B</xref>). Second, the training and test epoch choice periods act as separate attracting states although they should share all sensory and motor features, but differ only in their memory requirements. Third, task-epoch specific states break down if the animals commit a lot of behavioral mistakes in the test period, yet one would assume that they experience similar sensory input and perform similar movements at each choice point. Thus, there must be some internal component in the generation of task-epoch specific states.</p>
        <p>Nevertheless, true attractor states as mathematically defined (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Wiggins1">[70]</xref>) may be unlikely to exist in such an extremely non-stationary and high-dimensional complex system like the neocortex – rather, it seems more likely that neural information processing proceeds by stochastically itinerating among “semi-attracting” states which, for instance, may attract trajectories along most dimensions yet allow them to escape again along others <xref ref-type="bibr" rid="pcbi.1002057-Durstewitz6">[71]</xref>. This idea underlies many more recent conceptualizations of neural information processing (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Rabinovich1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Ashwin1">[72]</xref>), and has also been advanced as a theoretical explanation of experimental results on sensory processing in locusts <xref ref-type="bibr" rid="pcbi.1002057-Mazor1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Friedrich1">[73]</xref>. For instance, a specific population activity pattern may be temporarily stable until some slow negative feedback mechanism has build up sufficiently to inhibit this currently active configuration <xref ref-type="bibr" rid="pcbi.1002057-Compte1">[74]</xref>, or until noise has driven the system out of this state again, i.e. until a stochastic transition between states has occurred <xref ref-type="bibr" rid="pcbi.1002057-Deco2">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Miller2">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Crowe1">[75]</xref>. It will be very difficult or even impossible to experimentally prove in such a high-dimensional and almost never stationary system under constant bombardment from external sources that any neural activity configuration is formally an attractor. Moreover, whether physiological phenomena as the ones reported here really match formal definitions of attracting states may be largely irrelevant from a computational perspective <xref ref-type="bibr" rid="pcbi.1002057-Rabinovich1">[35]</xref>. Rather, neural objects with semi-attracting properties as shown here could serve equally well (or even better, e.g. with regards to sequence processing) in most computational ideas about cognitive processing.</p>
        <p>Does the high expansion order needed to fully reveal the converging dynamics of neural trajectories imply that the attracting states are very high-dimensional? Not necessarily: The key point of the delay embedding is to add more dimensions which are <italic>informative</italic> about the dynamics; many of the single-unit firing rate dimensions may be non-informative, i.e. may not contribute much to disentangling trajectories <xref ref-type="bibr" rid="pcbi.1002057-Sauer1">[28]</xref>, and thus in principle could be omitted. The multinomial expansion on the other hand primarily serves to optimally pull apart <italic>noisy</italic> trajectories <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref>. In a purely deterministic, noise-free system these dimensions would not be needed either to reveal the attractor. Indeed, the fact that convergent properties of the dynamics could be reasonably well evaluated in the 3-dimensional projections obtained by kernel-PCA suggests that the attracting states may in fact live in much lower dimensional subspaces <xref ref-type="bibr" rid="pcbi.1002057-Yu1">[57]</xref>; which however were only fully revealed by properly expanding the space first before reducing it to the most informative dimensions by using kernel-PCA <xref ref-type="bibr" rid="pcbi.1002057-Braun1">[76]</xref>.</p>
        <p>Finally, we stress that methods like the ones introduced here are widely applicable to almost any multivariate neural time series, including those obtained from various optical or functional imaging techniques, EEG, MEG <xref ref-type="bibr" rid="pcbi.1002057-Pereira1">[60]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Friston1">[63]</xref> or electrochemical techniques generating spatio-temporal time series. Thus, they may allow to address a number of previously unanswered questions about neural dynamics in many fields that require a proper unfolding and detailed resolution of trajectories not aided by across-trial averaging. Such techniques may also aid the discovery of common dynamical phenomena across tasks, species, and recording techniques. Here they revealed that ACC networks move among different state space regions, defined by specific population constellations of neural firing rates and their interactions, with a high likelihood of attracting neural trajectories. In this manner ACC networks may parse experience into meaningful task-relevant subcomponents.</p>
      </sec>
    </sec>
    <sec id="s4" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>Ethics statement</title>
        <p>All animals in this study were treated in accordance with the ethical guidelines set forth by the University of British Columbia and Canadian Council for Animal Care.</p>
      </sec>
      <sec id="s4b">
        <title>Animals and behavior</title>
        <p>Briefly, animals were placed on a reverse light cycle upon arrival and given <italic>ad libitum</italic> access to food for one week. Surgery was then performed and the animals were allowed two weeks of recovery before maze training. For an in depth description of the multi electrode array fabrication and surgical procedures see Lapish et al. <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>.</p>
        <p>After recovery from surgery, all animals were trained on the delayed spatial win shift run on an eight arm radial maze. Each trial consisted of a training and test phase separated by a one minute delay phase. Prior to the task, the terminal end of all eight arms were baited with a sugar pellet (Research Diets, Inc., New Brunswick, NJ, USA). The training phase commenced by opening four of eight arms. Upon retrieval of the fourth sugar pellet in the training phase, the animal was locked in the last arm visited and the lights were extinguished for the delay. After the delay, the test phase began by allowing access to all eight arms and errors were scored as re-entries into previously visited arms. Upon completion of the trial by retrieving all eight sugar pellets, all arms were closed and the animal was re-confined to the center of the maze. Animals received one trial per day until they made one error or less for two days in a row, and then received a minimum of 10 trials per day. Data sets for the multiple trials analysis were selected from animals that were able to remain vigilant and attend to the task for ∼15 trials as evidenced by uninterrupted foraging.</p>
        <p>In order to assess the population dynamic as the cognitive demands of the task vary, the whole time on task was divided into the following six epochs (<xref ref-type="fig" rid="pcbi-1002057-g002">Figure 2A</xref>): reward epochs (dark gray and red dots) during the training or test phases, respectively, correct choice epochs during training and test phases (blue and green, respectively), incorrect arm choice periods (yellow) during the test phase; and the entire delay period (light gray). Reward epochs were defined as the 1 s periods starting 200 ms before the points where the animal's nose reached a food cup during the training and test phase, respectively. Choice epochs were defined as periods starting 1.5 s before the arm choice and finishing 500 ms after it or before the reward period starts (assessed by visual video inspection).</p>
      </sec>
      <sec id="s4c">
        <title>Electrophysiology</title>
        <p>Behavioral data were captured via a video camera (Cohu, Poway, CA, USA), recorded in Noldus Ethovision (Noldus, Leesburg, VA, USA), and exported via voltage in real time as Cartesian coordinates to the Neuralyx recording system and then scored offline. All data was acquired with arrays of 24 single-wire tungsten (diameter = 25 µm, impedance = 150–300 kΏ, California Fine Wire) electrodes implanted into the ACC (<xref ref-type="supplementary-material" rid="pcbi.1002057.s001">Figure S1A</xref>). Recordings were sampled at ∼30 kHz, band-pass filtered from 600–6000 Hz, and stored off-line for sorting and analysis. Spike channels were amplified 5,000–10,000 times and thresholds for detection were set to ∼50 µV, which corresponded to &gt;5 times the root mean squared noise amplitude for the system. Spike sorting and classification was performed in Neuralynx Spikesort 3D (Neuralynx, Bozeman, MT, USA). Spike cluster assignments were based upon investigation of numerous principle components of the waveform (), and clusters lacking a well-defined boundary were excluded After classification, unrealistically low ISIs (≤10 ms) were removed as well as neurons with unrealistically high cross-correlations indicating the same neuron may have been captured on two different channels.</p>
      </sec>
      <sec id="s4d">
        <title>Statistical analysis</title>
        <p>An intuitive introduction to our statistical methodology was provided at the beginning of the <xref ref-type="sec" rid="s2">Results</xref> section, while most of the mathematical details can be found in the Supplementary Material.</p>
        <p>Spike-trains from the <italic>n</italic> simultaneously recorded units were convolved with Gaussian functions to obtain statistically reliable estimates of spike densities from single trials (checking the range σ = 5–200 ms, see <xref ref-type="supplementary-material" rid="pcbi.1002057.s003">Figure S3</xref> for values from 5–50 ms), normalized to the length of the whole trial (to yield a true probability density) and then summed and binned at 200 ms (approximately the inverse of the average single unit firing rate). Single unit spike densities were then combined into n-dimensional population vectors with components ν<italic><sub>i</sub></italic>(<italic>t</italic>) for each unit <italic>i</italic> (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Seidemann1">[59]</xref> as a function of time bin <italic>t</italic>. Small bin sizes (&lt;50 ms) produce extremely sparse ν<italic><sub>i</sub></italic>(<italic>t</italic>) series which became computationally prohibitive for the exact algorithm described below, and numerical approximations were required <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref> Units for which 〈ν<italic><sub>i</sub></italic>〉 &lt;2% of the most responsive unit were excluded.</p>
        <p>For the across-trial analysis, three different datasets consisting of 15 trials recorded on the same day were obtained from 3 animals. For each animal, only trials with ≥20 responsive units (see criterion above) were selected (10 trials from animal #1, 16 trials from animal #2, and 8 trials from animal #3). The first set of trials obeying above criteria constituted the reference set (trials 1–5 for animal #1, trials 1–8 for animal #2, and trials 1–4 for animal #3), while the last set of trials in the sequence formed the prediction set selected such that it had no overlap with the reference set. Furthermore, for each task-epoch, time series from the reference and prediction sets were constrained to have about the same length (number of vectors). For each of these two (reference and prediction) data sets, for each animal firing-rate vectors were then concatenated across trials to yield the two data matrices which entered into the analysis described further below. From our previous study <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref> where animals were run only on a single trial after reaching criterion, two separate data sets from six animals were constructed from 8 trials performing with less than two errors (“good performers”) and 8 trials with over four errors (“bad performers”). Neurons from different networks were ordered according to their mean firing-rate, while low-responsive units were excluded as in the multiple-trial dataset.</p>
        <p>For standard parametric testing, statistical test details can be found in the corresponding figure captions. For testing attracting properties of the task-epoch sets, nonparametric tests were used based on conservatively designed bootstrap data (100 replications used for one-sided comparisons at p = 0.01) as explained in the corresponding text sections and in <xref ref-type="supplementary-material" rid="pcbi.1002057.s002">Figure S2</xref>. For the control analyses shown in <xref ref-type="fig" rid="pcbi-1002057-g004">Figure 4</xref>, original task epochs were artificially augmented 5–20 times (generating ∼10<sup>4</sup> data points) and decimated by a factor of 0.8-0.6. This process did not significantly alter the original distributions, auto- and cross-correlations for all units.</p>
      </sec>
      <sec id="s4e">
        <title>State space construction</title>
        <p>An instantaneous population firing rate vector in MSUA space, obtained by convolution of the spike trains with Gaussian functions as described above, is given by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002057.e001" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002057-Lapish1">[33]</xref>. For univariate time series <bold>ν</bold>(<italic>t</italic>), delay embeddings are usually constructed by forming vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002057.e002" xlink:type="simple"/></inline-formula> from temporally delayed values with delays (lags) τ<italic><sub>i</sub></italic>. These are typically chosen to correspond to <italic>p</italic> successive minima of the autocorrelation function (or mutual information) where <italic>p</italic> would be high enough to unfold (pull apart) trajectories within this delay-coordinate space <xref ref-type="bibr" rid="pcbi.1002057-Takens1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Cat1">[77]</xref>. In general, the reconstructed spaces should have dimensionality <italic>p</italic> = 2×<italic>D</italic>+1, where <italic>D</italic> is the attractor dimension <xref ref-type="bibr" rid="pcbi.1002057-Sauer1">[28]</xref>. Similar ideas can be applied to multivariate systems <xref ref-type="bibr" rid="pcbi.1002057-Kantz1">[29]</xref>. The attractor dimension is often estimated via the correlation dimension, which, however, will not provide sensible answers in sparse high-dimensional spaces as the ones examined here (see <xref ref-type="bibr" rid="pcbi.1002057-Kantz1">[29]</xref>; <xref ref-type="supplementary-material" rid="pcbi.1002057.s004">Figure S4</xref> and <xref ref-type="supplementary-material" rid="pcbi.1002057.s007">Text S2</xref>). Moreover, the use of large delay coordinate maps would result in an extensive loss of data and hence poor statistics. Therefore, additional non-delay variables are sought to effectively disentangle noisy trajectories.</p>
        <p>The first step in our approach is to construct a reduced multivariate delay-coordinate map which should simply ensure that trajectories do not significantly cross each other. This auxiliary DC-MSUA space, defined by vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002057.e003" xlink:type="simple"/></inline-formula>, contains only a single lag for each unit optimized to be the first minimum of the average cross-correlation between pairs of units' firing-rates. The resulting lags ranged from just one time bin to &lt;5% of the task-phase length. Note that the main purpose of these lagged variables is to add axes to the space which contain information about the system dynamics not captured by the current state of the firing rate variables, therefore the choice of lags such as to minimize cross-correlations. In fact, the use of more than one delay per unit did not improve across-trial predictions (data not shown).</p>
        <p>After this step, differences between trajectories were further amplified by combining these variables into new functional forms, in accordance with ideas from statistical learning theory <xref ref-type="bibr" rid="pcbi.1002057-Vapnik1">[27]</xref>. As we were specifically interested in functional forms with a biological meaning, this was done by adding higher-order products of the units' firing rates as new coordinates to the neural state space. The <italic>o<sup>th</sup></italic>-order interaction of <italic>n</italic>-units omitting lags for notational convenience, is defined by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.e004" xlink:type="simple"/><label>(1)</label></disp-formula>By construction of the smoothed firing rate vector (see above) each axis φ(<italic>t</italic>) is the net sum of probabilities of <italic>o</italic> multiple spikes independently occurring across <italic>n</italic> neurons (e.g. <xref ref-type="bibr" rid="pcbi.1002057-BalaguerBallester2">[78]</xref>). For the frequent case that a single spike is contained within a single bin, and for small smoothing windows σ, φ(<italic>t</italic>) tends to represent a pattern of multiple spike-co-occurrences (a “poly-synchronous” pattern <xref ref-type="bibr" rid="pcbi.1002057-Izhikevich1">[79]</xref>). Now, the <italic>O</italic><sup>th</sup>-order delay-interactions coordinate map consists of <italic>all o</italic><sup>th</sup>-order firing-rate products with <italic>o = 1…O</italic>. Vectors in this high-dimensional space will be denoted by <bold>Φ</bold>(<italic>t</italic>). For instance, a vector in the space corresponding to <italic>O</italic> = 2 is defined by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.e005" xlink:type="simple"/><label>(2)</label></disp-formula>The dimensionality <italic>p</italic>(<italic>O</italic>) of such a space is typically <italic>p</italic>∼10<sup>5</sup>–10<sup>9</sup>, much larger than the number of task-epoch vectors which is on the order of ∼10<sup>3</sup>. Note that this approach sharply contrasts with other methods where the MSUA space dimensionality is instead further reduced by exploiting correlations among units (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Brown1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Churchland1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Chapin1">[80]</xref>). As was noted further above, the delay-coordinate map suffices to remove overlap between trajectories in an ideal, purely deterministic system. On the other hand, the multinomial basis expansion defined above helps to achieve an optimal separation in a statistical learning sense when dealing with highly noisy systems (e.g. <xref ref-type="fig" rid="pcbi-1002057-g003">Figure 3</xref>).</p>
        <p>Explicit computations in such extremely high-dimensional spaces are associated with numerical and computational problems which can be solved by the so-called “kernel trick” <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref>. In this context a kernel is a function which represents a vector product in a high-dimensional space without explicitly computing the dot product of the vectors. Here, for any two high-dimensional vectors <bold>Φ</bold>(<italic>t</italic>) from the expanded <italic>O<sup>th</sup></italic>-order space occurring at times <italic>t<sub>a</sub></italic> and <italic>t<sub>b</sub></italic>, respectively, the kernel function is given by</p>
        <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.e006" xlink:type="simple"/><label>(3)</label></disp-formula>Thus, the function on the right hand side operating on the low-dimensional firing rate vectors <bold>ν</bold>(<italic>t</italic>) is mathematically equivalent to (and uniquely defined for) a dot product between vectors <bold>Φ</bold>(<italic>t</italic>) from the much higher-dimensional <italic>O<sup>th</sup></italic>-order space <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref>. See <xref ref-type="supplementary-material" rid="pcbi.1002057.s006">Text S1</xref> and <xref ref-type="bibr" rid="pcbi.1002057-Smola1">[81]</xref> for further motivation for the use of this kernel.</p>
      </sec>
      <sec id="s4f">
        <title>State space analysis</title>
        <p>Within the mathematical framework of kernel algorithms, high-dimensional covariance matrices are replaced by kernel matrices in the reformulation of classical statistical procedures like PCA or FDA. Kernel matrices were computed for each possible pair of task epochs (such that <italic>t</italic><sub>a</sub> and <italic>t</italic><sub>b</sub> in Equation 4 may correspond to two different time points of the same epoch, or to time points from two different epochs), and then used to build a classifier using Fisher's discriminant (FD) criterion. FD analysis works by maximizing the difference between task-epoch means while minimizing within-task-epoch (co-) variances, i.e., by finding the direction <bold>Ω</bold> of the high-dimensional <italic>O<sup>th</sup></italic>-order space along which the overlap between two task-epoch distributions is minimized <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Mika1">[50]</xref>. Since in the expanded spaces the number of dimensions (variables) <italic>d</italic> is extremely high, in fact much higher than the number of observations <italic>m</italic>, means and covariance matrices cannot be explicitly computed, as stated above, and thus for the FD analysis all computations on high-dimensional vectors are reformulated in terms of a kernel matrix <italic>K</italic> of much smaller dimensionality (equal to <italic>m<sup>2</sup></italic>&lt;&lt;<italic>d</italic><sup>2</sup>; see <xref ref-type="supplementary-material" rid="pcbi.1002057.s006">Text S1</xref>). By usage of the kernel matrix <italic>K</italic>, the projections <italic>x</italic>(<italic>t</italic><sub>i</sub>) of high-dimensional vectors <bold>Φ</bold>(<italic>t</italic><sub>i</sub>) onto the optimally discriminating direction <bold>Ω</bold> are obtained by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.e007" xlink:type="simple"/><label>(4)</label></disp-formula>where the <italic>m</italic> elements of the vector <bold>α</bold> are derived as e.g. explained in Schölkopf and Smola, <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref> and in <xref ref-type="supplementary-material" rid="pcbi.1002057.s006">Text S1</xref>. Since the projected values <italic>x</italic>(<italic>t</italic><sub>i</sub>) on the most discriminating axis represent linear combinations of up to 10<sup>9</sup> random variables (one variable per dimension), the projected data will be approximately normally distributed according to the central limit theorem (e.g. <xref ref-type="bibr" rid="pcbi.1002057-Bishop1">[44]</xref>). Hence, building on this assumption of approximate normality, a Bayes-optimal classifier (the one with theoretically best performance) can be defined on this most-discriminating axis (where equal priors were used here for not biasing the results according to the lengths of the sampled task epochs). From this, classification (separation) errors (SE; cf. <xref ref-type="fig" rid="pcbi-1002057-g005">Figure 5</xref>), likelihoods <italic>p</italic>(<bold>ν</bold>(<italic>t</italic>)|<italic>C</italic>) of classification into task-epoch <italic>C</italic>, posterior probabilities <italic>P</italic>(<italic>C|</italic><bold>ν</bold>(<italic>t</italic>)) (using Bayes criterion), and 99% confidence intervals are straightforward to obtain. The (discretized) Kullbach-Leibler divergence <xref ref-type="bibr" rid="pcbi.1002057-Bishop1">[e.g. 44]</xref> was computed as a measure of the distance between these Gaussian posterior distributions corresponding to any two tasks epochs <italic>C<sub>1</sub></italic> and <italic>C<sub>2</sub></italic>. It was estimated for each <italic>O<sup>th</sup></italic> order expansion (<xref ref-type="fig" rid="pcbi-1002057-g005">Figure 5C</xref>) and is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.e008" xlink:type="simple"/><label>(5)</label></disp-formula>The utilization of normal probability theory represents a fundamental advantage over other approaches specialized for high-dimensional spaces (e.g. support-vector-based classifiers <xref ref-type="bibr" rid="pcbi.1002057-Vapnik1">[27]</xref>) which may have similar classification performance <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref> but do not easily permit other aspects of the present statistical analysis.</p>
        <p>For the across-trial analyses, optimal directions <bold>Ω</bold> for each task epoch pair were obtained using exclusively the first set of (reference) trials, <bold>Φ</bold><sup>r<italic>ef</italic></sup>. This direction was then fixed for computing the projections <italic>x<sub>predic</sub></italic>(<italic>t</italic><sub>i</sub>) of vectors <bold>Φ</bold><italic><sup>predic</sup></italic>(<italic>t</italic><sub>i</sub>) from the prediction set onto <bold>Ω</bold> to yield the predicted SE (SE<sub>predic</sub>):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.e009" xlink:type="simple"/><label>(6)</label></disp-formula>where the vector <bold>α<sup>ref</sup></bold> is the one obtained from the reference set and <italic>K</italic> represents projections of prediction set vectors into the reference space. A brief summary of these algorithms can be found in <xref ref-type="supplementary-material" rid="pcbi.1002057.s006">Text S1</xref> <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref>.</p>
        <p>A regularization penalty was furthermore added to the kernel matrices to ensure a low <italic>generalization error</italic> (loosely speaking, a regularization factor automatically constrains the number of free parameters to reduce out-of-sample prediction errors; e.g. <xref ref-type="bibr" rid="pcbi.1002057-Vapnik1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref>). This regularization was optimized such that SE<sub>predic</sub> was minimal for animal #1 and then it was fixed for all other analyses (because of this regularization, for instance, <italic>in-sample</italic> SE never decreases to zero for the expanded spaces in <xref ref-type="fig" rid="pcbi-1002057-g003">Figures 3A</xref> and <xref ref-type="fig" rid="pcbi-1002057-g005">5A</xref>). Prediction errors were found to be invariant for large enough values of this regularization penalty (as demonstrated in <xref ref-type="supplementary-material" rid="pcbi.1002057.s003">Figure S3</xref>). The robustness of the present approach with regards to different basis functions used in the expansion (and thus different definitions of the kernel) is also discussed in <xref ref-type="supplementary-material" rid="pcbi.1002057.s003">Figure S3</xref>. Finally, we also investigated how unsupervised clustering approaches perform on the DC-MSUA spaces, and noticed that they reliably pick up only the delay vs. training/test phase differences in this lower-dimensional representation (see <xref ref-type="supplementary-material" rid="pcbi.1002057.s005">Figure S5</xref> for an example).</p>
        <p>Kernel-FDA <xref ref-type="bibr" rid="pcbi.1002057-Mika1">[50]</xref> and kernel-PCA <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf2">[47]</xref> were used to obtain three-dimensional visualizations for each high-dimensional task-epoch state. Three-dimensional projections were also used for determining velocity vectors (cf. <xref ref-type="fig" rid="pcbi-1002057-g006">Figure 6</xref>), as these cannot be efficiently computed in high dimensions (a problem running under the label “curse of dimensionality”; e.g. <xref ref-type="bibr" rid="pcbi.1002057-Bishop1">[44]</xref>). Kernel-PCA proceeds in much the same way as ordinary PCA, except that – like kernel-FDA – it works on the kernel matrices defined above instead of directly on the high-dimensional covariance matrices (see brief summary in <xref ref-type="supplementary-material" rid="pcbi.1002057.s006">Text S1</xref>). Thus, the three orthogonal dimensions capturing the largest amount of data variance in the high-dimensional spaces were obtained. Additional discussion about the adequacy of these three-dimensional velocity vectors as obtained by kernel-PCA can be found in <xref ref-type="supplementary-material" rid="pcbi.1002057.s004">Figure S4</xref> and in <xref ref-type="supplementary-material" rid="pcbi.1002057.s007">Text S2</xref>. Finally, note that, apart from the convergence analysis shown in <xref ref-type="fig" rid="pcbi-1002057-g006">Figure 6</xref>, these three-dimensional reductions served only for the purpose of visualization, while all statistical analyses were performed on the full high-dimensional spaces (see <xref ref-type="fig" rid="pcbi-1002057-g007">Figure 7C</xref>).</p>
        <p>Analysis software was implemented in MatLab (Mathworks Inc., MA, USA) and is freely available in <ext-link ext-link-type="uri" xlink:href="http://www.bccn-heidelberg-mannheim.de" xlink:type="simple">http://www.bccn-heidelberg-mannheim.de</ext-link> under the terms of the general public license (<ext-link ext-link-type="uri" xlink:href="http://www.gnu.org/licenses/" xlink:type="simple">http://www.gnu.org/licenses/</ext-link>).</p>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pcbi.1002057.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.s001" xlink:type="simple">
        <label>Figure S1</label>
        <caption>
          <p>Multiple single-unit recordings from ACC in a memory-guided decision making task. <bold>A.</bold> Electrode location. All brains were sectioned and electrode placement confirmed. Gray circles delineate the boundary within which electrodes were placed and were confirmed to be in the Anterior Cingulate Cortex (ACC). Cortical map is adapted from Paxinos and Watson <xref ref-type="bibr" rid="pcbi.1002057-Paxinos1">[82]</xref>. <bold>B.</bold> A representative example of a channel containing 3 units. The averaged waveform is shown on top with the color corresponding to the cluster in the map below.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002057.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.s002" xlink:type="simple">
        <label>Figure S2</label>
        <caption>
          <p>Schema of the bootstrap procedures. <bold>A.</bold> Original data. <bold>B.</bold> Bootstrap series used in <xref ref-type="fig" rid="pcbi-1002057-g003">Figures 3</xref> and <xref ref-type="fig" rid="pcbi-1002057-g004">4</xref> were constructed by randomly shuffling stretches of the time series that retained entire trajectories form a given task epoch such that each replication preserved all temporal autocorrelations up to the length of the relevant task epoch.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002057.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.s003" xlink:type="simple">
        <label>Figure S3</label>
        <caption>
          <p>Robustness of the state space reconstruction approach to different parameter settings. <bold>A.</bold> Misclassification error, SE, for different standard deviations (σ) of the Gaussian smoothing function used for constructing the firing-rate vectors. Blue and red lines show SE for low- and high-performance trials, respectively. Results are averages across all task-epoch pair comparisons (error bars = SEM). Results are largely the same for 5&lt;σ&lt;200 ms. <bold>B.</bold> SE for different settings of the regularization parameter of the kernel matrix which penalizes the number of state space dimensions <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Steinke1">[83]</xref>. Regularization (η) is expressed as % of the mean value of the kernel matrix (see <xref ref-type="supplementary-material" rid="pcbi.1002057.s006">Text S1</xref>). For η&lt;1%, SE approaches zero (p&gt;0.5) for sufficiently high <italic>O</italic>, and the discrimination between low- and high-performance trials disappears, while for larger values (∼1–40%), discrimination between behavioral performance groups is retained. <bold>C.</bold> SE<sub>predic</sub> in the optimum expansion spaces as a function of the regularization parameter. Very low penalties (η≤1%) are associated with larger SE<sub>predic</sub> while for η&gt;1% mean SE<sub>predic</sub> does not change anymore (n = 3 animals). This result indicates that the very low “naïve” SEs obtained in graph B for η&lt;1% are purely due to “overfitting” <xref ref-type="bibr" rid="pcbi.1002057-Bishop1">[44]</xref>, <xref ref-type="bibr" rid="pcbi.1002057-Schlkopf1">[45]</xref> and therefore are not informative. Beyond this lower limit for η, results of this study are largely independent of this regularization parameter. <bold>D.</bold> SE<sub>predic</sub> for an optimal <italic>O<sup>th</sup></italic>-order space which, however, contains only interactions of <italic>O<sup>th</sup></italic>-order, and not those of order <italic>o</italic>&lt;<italic>O</italic> (black bars). In contrast to the <italic>O<sup>th</sup></italic>-order space used in this work (white bars), this space is not functionally meaningful in the sense that high-order spike correlations across neurons necessarily imply lower order ones which are not present in this space. However, one would expect that SE<sub>predic</sub> within such a space remains unaltered because the change in dimensionality is negligible (e.g., for <italic>O</italic> = 3 the dimensionality would decrease only by ∼8% by neglecting lower order interactions, while instead the dimensionality increases by ∼900% when going from <italic>O</italic> = 3<sup>rd</sup> to <italic>O</italic> = 4<sup>th</sup> order). Surprisingly, however, SE<sub>predic</sub> deteriorates for these “non-meaningful” spaces despite their similar dimensionality, indicating that the optimum full <italic>O<sup>th</sup></italic>-order embedding space is also the functionally most relevant one.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002057.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.s004" xlink:type="simple">
        <label>Figure S4</label>
        <caption>
          <p>Assessment of the validity of the three-dimensional kernel-PCA projections for representing task-epoch-specific dynamics within the optimal full <italic>O<sup>th</sup></italic>-order space. See discussion of this Figure in <xref ref-type="supplementary-material" rid="pcbi.1002057.s007">Text S2</xref>. <bold>A.</bold> Correlation dimension (<italic>d<sub>2</sub></italic>) of task-epoch specific sets in the three-dimensional space obtained from a <italic>5<sup>th</sup></italic>-order expansion during high-performance trials. <italic>d<sub>2</sub></italic> is defined as the slope of <italic>log S</italic>(ε)- <italic>log</italic>(ε) in the limit of an infinite number of samples and ε→0, where <italic>S</italic>(ε) is the fraction of data points falling into spheres of radius ε centered on each of the data points in turn (termed <italic>correlation sum</italic>; <xref ref-type="bibr" rid="pcbi.1002057-Kantz1">[29]</xref>). The inset shows the mean Takens maximum likelihood estimator of <italic>d<sub>2</sub></italic> <xref ref-type="bibr" rid="pcbi.1002057-Theiler1">[84]</xref>, which turns out to be smaller than one. According to the fractal delay-coordinate embedding theorem <xref ref-type="bibr" rid="pcbi.1002057-Sauer1">[28]</xref>, the minimum required dimensionality of a proper low-dimensional embedding for each of the task-epoch-specific putative <italic>attractors</italic> is therefore 3 (i.e. 2 <italic>d<sub>2</sub></italic>+1). Thus, these three-dimensional visualizations provide reliable representations of task-epoch trajectories. <bold>B.</bold> <italic>Time-Space separation plots</italic> <xref ref-type="bibr" rid="pcbi.1002057-Provenzale1">[85]</xref> used to estimate the minimum number of temporally consecutive vectors (abscissa), <italic>Δsamples</italic>, which should not be included in the <italic>S</italic>(ε) counts, termed <italic>b<sub>min</sub></italic>. Since <italic>d<sub>2</sub></italic> is supposed to be a measure of the spatial geometry of a putative attractor <xref ref-type="bibr" rid="pcbi.1002057-Grassberger1">[86]</xref>, spatial neighborhood relationships purely due to different short-term autocorrelations within trajectories have to be excluded by choosing <italic>b<sub>min</sub></italic> appropriately. For <italic>b<sub>min</sub></italic> = 4–29 samples the variation in <italic>S</italic>(ε) across <italic>Δ</italic><italic>samples</italic> was less than 5% for all ε.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002057.s005" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.s005" xlink:type="simple">
        <label>Figure S5</label>
        <caption>
          <p>Example of unsupervised hierarchical clustering analysis performed on the DC-MSUA space for animal #1. For the purpose of visualization, 3D-projections obtained by PCA or Multi-Dimensional Scaling are shown. <bold>A.</bold> Optimal unsupervised two-group clustering solution showing the delay phase in gray and the training plus test phases in brown (these were the most distinct classes as revealed by the dendrogram shown in the upper right). Different clustering criteria (centroid, average, median, nearest neighbor, weighted and Ward's) and metrics (Euclidean, various Minkowsky metrics, Mahalanobis, and Pearson correlation) were tried. The “optimal” clustering criterion (Ward's in this case) and optimal metric (Euclidean in this case) were the ones which yielded the lowest percent of misclassified firing-rate vectors (CE) with respect to the experimenter-determined task-phase assignments. The upper graphs show results for trial #3, where only 15.5 (3.0) % of vectors were misclassified on average across task-phases (standard error), while the bottom graph shows results when all training set trials (#1–5) were combined, yielding an average of 30.0 (9.3) % misclassified vectors. These results suggest that within the DC-MSUA spaces unsupervised methods reliably pick up the difference between the delay phase and the other task phases. <bold>B.</bold> Optimal six-group clustering solution. In this case any of the hierarchical clustering methods resulted in an average number of misclassified vectors &gt;30% (mean CE across the six task-epochs is 69.3 (11.7) %). Thus, at least within the low-dimensional DC-MSUA spaces unsupervised methods were not able to reliably detect different task-epochs with predictive power. This of course does not rule out that <italic>kernelized</italic> versions of unsupervised cluster analyses could identify task epochs in the high-dimensional expanded spaces, an issue which can be studied in future extensions of the present work.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002057.s006" mimetype="application/msword" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.s006" xlink:type="simple">
        <label>Text S1</label>
        <caption>
          <p>Brief summary of kernel algorithms.</p>
          <p>(DOC)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002057.s007" mimetype="application/msword" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.s007" xlink:type="simple">
        <label>Text S2</label>
        <caption>
          <p>Three-dimensional representations.</p>
          <p>(DOC)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002057.s008" mimetype="video/x-msvideo" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002057.s008" xlink:type="simple">
        <label>Video S1</label>
        <caption>
          <p>Kernel-PCA reduction of the expanded space containing higher-order activity products (<xref ref-type="fig" rid="pcbi-1002057-g001">Figure 1B</xref>, right), showing attracting-like orbits for the different task-phases.</p>
          <p>(AVI)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank Andreas Meyer-Lindenberg for detailed comments on a previous version of this manuscript and three anonymous Referees for their detailed revision.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002057-Wilson1">
        <label>1</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wilson</surname><given-names>HR</given-names></name></person-group>             <year>1999</year>             <source>Spikes, decisions, and actions: The dynamical foundations of neuroscience</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Oxford University Press</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">307</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002057-Durstewitz1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Durstewitz</surname><given-names>D</given-names></name><name name-style="western"><surname>Seamans</surname><given-names>JK</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>2000a</year>             <article-title>Neurocomputational models of working memory.</article-title>             <source>Nat Neurosci</source>             <volume>3</volume>             <fpage>1184</fpage>             <lpage>1191</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Durstewitz2">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Durstewitz</surname><given-names>D</given-names></name></person-group>             <year>2003</year>             <article-title>Self-organizing neural integrator predicts interval times through climbing activity.</article-title>             <source>J Neurosci</source>             <volume>23</volume>             <fpage>5342</fpage>             <lpage>5353</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Machens1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Machens</surname><given-names>CK</given-names></name><name name-style="western"><surname>Romo</surname><given-names>R</given-names></name><name name-style="western"><surname>Brody</surname><given-names>CD</given-names></name></person-group>             <year>2005</year>             <article-title>Flexible control of mutual inhibition: a neural model for two-interval discrimination.</article-title>             <source>Science</source>             <volume>307</volume>             <fpage>1121</fpage>             <lpage>1124</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Wang1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>X-J</given-names></name></person-group>             <year>2002</year>             <article-title>Probabilistic decision making by slow reverberation in cortical circuits.</article-title>             <source>Neuron</source>             <volume>36</volume>             <fpage>955</fpage>             <lpage>968</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Colgin1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Colgin</surname><given-names>LL</given-names></name><name name-style="western"><surname>Leutgeb</surname><given-names>S</given-names></name><name name-style="western"><surname>Jezek</surname><given-names>K</given-names></name><name name-style="western"><surname>Leutgeb</surname><given-names>JK</given-names></name><name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Attractor-map versus autoassociation based attractor dynamics in the hippocampal network.</article-title>             <source>J Neurophysiol</source>             <volume>104</volume>             <fpage>35</fpage>             <lpage>50</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Durstewitz3">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Durstewitz</surname><given-names>D</given-names></name><name name-style="western"><surname>Seamans</surname><given-names>JK</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>2000b</year>             <article-title>Dopamine-mediated stabilization of delay-period activity in a network model of prefrontal cortex.</article-title>             <source>J Neurophysiol</source>             <volume>83</volume>             <fpage>1733</fpage>             <lpage>1750</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Wang2">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>X-J</given-names></name></person-group>             <year>1999b</year>             <article-title>Synaptic basis of cortical persistent activity: the importance of NMDA receptors to working memory.</article-title>             <source>J Neurosci</source>             <volume>19</volume>             <fpage>9587</fpage>             <lpage>9603</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Brunel1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brunel</surname><given-names>N</given-names></name><name name-style="western"><surname>Wang</surname><given-names>X-J</given-names></name></person-group>             <year>2001</year>             <article-title>Effects of neuromodulation in a cortical network model of object working memory dominated by recurrent inhibition.</article-title>             <source>J Comput Neurosci</source>             <volume>11</volume>             <fpage>63</fpage>             <lpage>85</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Albantakis1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Albantakis</surname><given-names>L</given-names></name><name name-style="western"><surname>Deco</surname><given-names>G</given-names></name></person-group>             <year>2009</year>             <article-title>The Encoding of Alternatives in Multiple-choice Decision Making.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>106</volume>             <fpage>10308</fpage>             <lpage>10313</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Deco1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Deco</surname><given-names>G</given-names></name><name name-style="western"><surname>Scarano</surname><given-names>L</given-names></name><name name-style="western"><surname>Soto-Faraco</surname><given-names>S</given-names></name></person-group>             <year>2007a</year>             <article-title>Weber's law in decision making: integrating behavioral data in humans with neurophysiological model.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>11192</fpage>             <lpage>11200</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Wang3">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>X-J</given-names></name></person-group>             <year>2008</year>             <article-title>Decision making in recurrent neuronal circuits.</article-title>             <source>Neuron</source>             <volume>60</volume>             <fpage>215</fpage>             <lpage>234</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Miller1">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Miller</surname><given-names>EK</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>MA</given-names></name></person-group>             <year>2008</year>             <article-title>All my circuits: Using multiple electrodes to understand functioning neural networks.</article-title>             <source>Neuron</source>             <volume>60</volume>             <fpage>483</fpage>             <lpage>488</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Brown1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brown</surname><given-names>EN</given-names></name><name name-style="western"><surname>Kass</surname><given-names>RE</given-names></name><name name-style="western"><surname>Mitra</surname><given-names>PP</given-names></name></person-group>             <year>2004</year>             <article-title>Multiple neural spike train data analysis: state-of-the-art and future challenges.</article-title>             <source>Nat Neurosci</source>             <volume>7</volume>             <fpage>456</fpage>             <lpage>461</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Churchland1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Churchland</surname><given-names>MM</given-names></name><name name-style="western"><surname>Yu</surname><given-names>B</given-names></name><name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name><name name-style="western"><surname>Shenoy</surname><given-names>K</given-names></name></person-group>             <year>2007</year>             <article-title>Techniques for extracting single-trial activity patterns from large-scale neural recordings.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>17</volume>             <fpage>609</fpage>             <lpage>618</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Mazor1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mazor</surname><given-names>O</given-names></name><name name-style="western"><surname>Laurent</surname><given-names>G</given-names></name></person-group>             <year>2005</year>             <article-title>Transient dynamics versus fixed points in odor representations by locust antennal lobe projection neurons.</article-title>             <source>Neuron</source>             <volume>48</volume>             <fpage>661</fpage>             <lpage>673</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Bathellier1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bathellier</surname><given-names>B</given-names></name><name name-style="western"><surname>Buhl</surname><given-names>DL</given-names></name><name name-style="western"><surname>Accolla</surname><given-names>R</given-names></name><name name-style="western"><surname>Carleton</surname><given-names>A</given-names></name></person-group>             <year>2008</year>             <article-title>Dynamic ensemble odor coding in the mamalian olfactory bulb: Sensory information at different time scales.</article-title>             <source>Neuron</source>             <volume>57</volume>             <fpage>586</fpage>             <lpage>598</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Jones1">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jones</surname><given-names>LM</given-names></name><name name-style="western"><surname>Fontanini</surname><given-names>A</given-names></name><name name-style="western"><surname>Sadacca</surname><given-names>BF</given-names></name><name name-style="western"><surname>Miller</surname><given-names>P</given-names></name><name name-style="western"><surname>Katz</surname><given-names>DB</given-names></name></person-group>             <year>2007</year>             <article-title>Natural stimuli evoke dynamic sequences of states in sensory cortical ensembles.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>104</volume>             <fpage>18772</fpage>             <lpage>18777</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Durstewitz4">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Durstewitz</surname><given-names>D</given-names></name><name name-style="western"><surname>Vittoz</surname><given-names>NM</given-names></name><name name-style="western"><surname>Floresco</surname><given-names>SB</given-names></name><name name-style="western"><surname>Seamans</surname><given-names>JK</given-names></name></person-group>             <year>2010</year>             <article-title>Abrupt transitions between prefrontal neural ensemble states accompany behavioral transitions during rule learning.</article-title>             <source>Neuron</source>             <volume>66</volume>             <fpage>438</fpage>             <lpage>448</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Wills1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wills</surname><given-names>TJ</given-names></name><name name-style="western"><surname>Lever</surname><given-names>C</given-names></name><name name-style="western"><surname>Cacucci</surname><given-names>F</given-names></name><name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name><name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name></person-group>             <year>2005</year>             <article-title>Attractor dynamics in the hippocampal representation of the local environment.</article-title>             <source>Science</source>             <volume>308</volume>             <fpage>873</fpage>             <lpage>876</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Pastalkova1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pastalkova</surname><given-names>E</given-names></name><name name-style="western"><surname>Itskov</surname><given-names>V</given-names></name><name name-style="western"><surname>Amarasingham</surname><given-names>A</given-names></name><name name-style="western"><surname>Buzsáki</surname><given-names>G</given-names></name></person-group>             <year>2008</year>             <article-title>Internally generated cell assembly sequences in the rat hippocampus.</article-title>             <source>Science</source>             <volume>321</volume>             <fpage>1322</fpage>             <lpage>1327</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-vanderMeer1">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>van der Meer</surname><given-names>MAA</given-names></name><name name-style="western"><surname>Johnson</surname><given-names>A</given-names></name><name name-style="western"><surname>Schmitzer-Torbert</surname><given-names>NC</given-names></name><name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name></person-group>             <year>2010</year>             <article-title>Triple dissociation of information processing in dorsal striatum, ventral striatum, and hippocampus on a learned spatial decision task.</article-title>             <source>Neuron</source>             <volume>67</volume>             <fpage>25</fpage>             <lpage>32</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Niessing1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Niessing</surname><given-names>J</given-names></name><name name-style="western"><surname>Friedrich</surname><given-names>RW</given-names></name></person-group>             <year>2010</year>             <article-title>Olfactory pattern classification by discrete neuronal network states.</article-title>             <source>Nature</source>             <volume>465</volume>             <fpage>47</fpage>             <lpage>54</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Deco2">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Deco</surname><given-names>G</given-names></name><name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name><name name-style="western"><surname>Romo</surname><given-names>R</given-names></name></person-group>             <year>2009</year>             <article-title>Stochastic dynamics as a principle of brain function.</article-title>             <source>Prog Neurobiol</source>             <volume>88</volume>             <fpage>1</fpage>             <lpage>16</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Miller2">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Miller</surname><given-names>P</given-names></name><name name-style="western"><surname>Katz</surname><given-names>DB</given-names></name></person-group>             <year>2010</year>             <article-title>Stochastic transitions between neural states in taste processing and decision-making.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>2559</fpage>             <lpage>2570</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-BenHur1">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ben-Hur</surname><given-names>A</given-names></name><name name-style="western"><surname>Ong</surname><given-names>CS</given-names></name><name name-style="western"><surname>Sonnenburg</surname><given-names>S</given-names></name><name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name><name name-style="western"><surname>Rätsch</surname><given-names>G</given-names></name></person-group>             <year>2008</year>             <article-title>Support vector machines and kernels for computational biology.</article-title>             <source>PLoS Comput Biol</source>             <volume>4</volume>             <fpage>e1000173</fpage>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000173" xlink:type="simple">10.1371/journal.pcbi.1000173</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Vapnik1">
        <label>27</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Vapnik</surname><given-names>VN</given-names></name></person-group>             <year>1998</year>             <source>Statistical learning theory</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Wiley-Interscience</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">736</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002057-Sauer1">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sauer</surname><given-names>T</given-names></name><name name-style="western"><surname>Yorke</surname><given-names>J</given-names></name><name name-style="western"><surname>Casdagli</surname><given-names>M</given-names></name></person-group>             <year>1992</year>             <article-title>Embedology.</article-title>             <source>J Stat Phys</source>             <volume>65</volume>             <fpage>579</fpage>             <lpage>616</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Kantz1">
        <label>29</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kantz</surname><given-names>H</given-names></name><name name-style="western"><surname>Schreiber</surname><given-names>T</given-names></name></person-group>             <year>2004</year>             <source>Nonlinear time series analysis</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">388</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002057-vanVeen1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>van Veen</surname><given-names>V</given-names></name><name name-style="western"><surname>Carter</surname><given-names>CS</given-names></name></person-group>             <year>2002</year>             <article-title>The timing of action-monitoring processes in the anterior cingulate cortex.</article-title>             <source>J Cognitive Neurosci</source>             <volume>14</volume>             <fpage>593</fpage>             <lpage>602</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Botvinick1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Botvinick</surname><given-names>MM</given-names></name><name name-style="western"><surname>Braver</surname><given-names>TS</given-names></name><name name-style="western"><surname>Barch</surname><given-names>DM</given-names></name><name name-style="western"><surname>Carter</surname><given-names>CS</given-names></name><name name-style="western"><surname>Cohen</surname><given-names>JD</given-names></name></person-group>             <year>2001</year>             <article-title>Conflict monitoring and cognitive control.</article-title>             <source>Psychol Rev</source>             <volume>108</volume>             <fpage>624</fpage>             <lpage>652</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Rushworth1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rushworth</surname><given-names>MF</given-names></name><name name-style="western"><surname>Walton</surname><given-names>ME</given-names></name><name name-style="western"><surname>Kennerley</surname><given-names>SW</given-names></name><name name-style="western"><surname>Bannerman</surname><given-names>DM</given-names></name></person-group>             <year>2004</year>             <article-title>Action sets and decisions in the medial frontal cortex.</article-title>             <source>Trends Cogn Sci</source>             <volume>8</volume>             <fpage>410</fpage>             <lpage>417</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Lapish1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lapish</surname><given-names>CL</given-names></name><name name-style="western"><surname>Durstewitz</surname><given-names>D</given-names></name><name name-style="western"><surname>Chandler</surname><given-names>LJ</given-names></name><name name-style="western"><surname>Seamans</surname><given-names>JK</given-names></name></person-group>             <year>2008</year>             <article-title>Successful choice behavior is associated with distinct and coherent network states in anterior cingulate cortex.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>105</volume>             <fpage>12010</fpage>             <lpage>12015</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Hopfield1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hopfield</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Brody</surname><given-names>CD</given-names></name></person-group>             <year>2001</year>             <article-title>What is a moment? Transient synchrony as a collective mechanism for spatiotemporal integration.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>98</volume>             <fpage>1282</fpage>             <lpage>1287</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Rabinovich1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rabinovich</surname><given-names>MI</given-names></name><name name-style="western"><surname>Varona</surname><given-names>P</given-names></name><name name-style="western"><surname>Selverston</surname><given-names>AI</given-names></name><name name-style="western"><surname>Abarbanel</surname><given-names>HDI</given-names></name></person-group>             <year>2006</year>             <article-title>Dynamical principles in neuroscience.</article-title>             <source>Reviews of Modern Physics</source>             <volume>78</volume>             <fpage>1213</fpage>             <lpage>1265</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-OReilly1">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>O'Reilly</surname><given-names>RC</given-names></name></person-group>             <year>2006</year>             <article-title>Biologically Based Computational Models of High-Level Cognition.</article-title>             <source>Science</source>             <volume>314</volume>             <fpage>91</fpage>             <lpage>94</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-BalaguerBallester1">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Balaguer-Ballester</surname><given-names>E</given-names></name><name name-style="western"><surname>Coath</surname><given-names>M</given-names></name><name name-style="western"><surname>Denham</surname><given-names>SL</given-names></name></person-group>             <year>2007</year>             <article-title>A model of perceptual segregation based on clustering the time series of the simulated auditory nerve firing probability.</article-title>             <source>Biol Cybern</source>             <volume>97</volume>             <fpage>479</fpage>             <lpage>491</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Takens1">
        <label>38</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Takens</surname><given-names>F</given-names></name></person-group>             <year>1981</year>             <source>Detecting strange attractors in turbulence. Lecture Notes in Mathematics 898</source>             <publisher-loc>Berlin</publisher-loc>             <publisher-name>Springer</publisher-name>             <fpage>366</fpage>             <lpage>381</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Vaadia1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Vaadia</surname><given-names>E</given-names></name><name name-style="western"><surname>Haalman</surname><given-names>I</given-names></name><name name-style="western"><surname>Abeles</surname><given-names>M</given-names></name><name name-style="western"><surname>Bergman</surname><given-names>H</given-names></name><name name-style="western"><surname>Prut</surname><given-names>Y</given-names></name><etal/></person-group>             <year>1995</year>             <article-title>Dynamics of neuronal interactions in monkey cortex in relation to behavioral events.</article-title>             <source>Nature</source>             <volume>373</volume>             <fpage>515</fpage>             <lpage>518</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Riehle1">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Riehle</surname><given-names>A</given-names></name><name name-style="western"><surname>Grun</surname><given-names>S</given-names></name><name name-style="western"><surname>Diesmann</surname><given-names>M</given-names></name><name name-style="western"><surname>Aertsen</surname><given-names>A</given-names></name></person-group>             <year>1997</year>             <article-title>Spike synchronization and rate modulation differentially involved in motor cortical function.</article-title>             <source>Science</source>             <volume>278</volume>             <fpage>1950</fpage>             <lpage>1953</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Csicsvari1">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Csicsvari</surname><given-names>J</given-names></name><name name-style="western"><surname>Hirase</surname><given-names>H</given-names></name><name name-style="western"><surname>Czurkó</surname><given-names>A</given-names></name><name name-style="western"><surname>Mamiya</surname><given-names>A</given-names></name><name name-style="western"><surname>Buzsáki</surname><given-names>G</given-names></name></person-group>             <year>1999</year>             <article-title>Oscillatory Coupling of Hippocampal Pyramidal Cells and Interneurons in the Behaving Rat.</article-title>             <source>J Neurosci</source>             <volume>19</volume>             <fpage>274</fpage>             <lpage>287</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Fujisawa1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fujisawa</surname><given-names>S</given-names></name><name name-style="western"><surname>Amarasingham</surname><given-names>A</given-names></name><name name-style="western"><surname>Harrison</surname><given-names>MT</given-names></name><name name-style="western"><surname>Buzsaki</surname><given-names>G</given-names></name></person-group>             <year>2008</year>             <article-title>Behavior-dependent short-term assembly dynamics in the medial prefrontal cortex.</article-title>             <source>Nat Neurosci</source>             <volume>11</volume>             <fpage>823</fpage>             <lpage>833</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Averbeck1">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Averbeck</surname><given-names>BB</given-names></name><name name-style="western"><surname>Latham</surname><given-names>PE</given-names></name><name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name></person-group>             <year>2006</year>             <article-title>Neural correlations, population coding and computation.</article-title>             <source>Nat Rev Neurosci</source>             <volume>7</volume>             <fpage>358</fpage>             <lpage>366</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Bishop1">
        <label>44</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bishop</surname><given-names>CM</given-names></name></person-group>             <year>2007</year>             <source>Pattern recognition and machine learning</source>             <publisher-loc>Singapore</publisher-loc>             <publisher-name>Springer</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">738</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002057-Schlkopf1">
        <label>45</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name><name name-style="western"><surname>Smola</surname><given-names>AJ</given-names></name></person-group>             <year>2002</year>             <source>Learning with kernels</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>427</fpage>             <lpage>452</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Hastie1">
        <label>46</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hastie</surname><given-names>T</given-names></name><name name-style="western"><surname>Tibshirani</surname><given-names>R</given-names></name><name name-style="western"><surname>Friedman</surname><given-names>J</given-names></name></person-group>             <year>2009</year>             <source>The elements of statistical learning</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Springer</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">746</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002057-Schlkopf2">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name><name name-style="western"><surname>Smola</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Müller</surname><given-names>K</given-names></name></person-group>             <year>1998</year>             <article-title>Kernel principal component analysis.</article-title>             <source>Neural Comput</source>             <volume>10</volume>             <fpage>1299</fpage>             <lpage>1316</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Timberlake1">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Timberlake</surname><given-names>W</given-names></name></person-group>             <year>2002</year>             <article-title>Niche-related learning in laboratory paradigms: the case of maze behavior in Norway rats.</article-title>             <source>Behav Brain Res</source>             <volume>134</volume>             <fpage>355</fpage>             <lpage>374</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Olton1">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Olton</surname><given-names>DS</given-names></name><name name-style="western"><surname>Samuelson</surname><given-names>RJ</given-names></name></person-group>             <year>1976</year>             <article-title>Remembrance of places passed: Spatial memory in rats.</article-title>             <source>J Exp Psychol Anim B</source>             <volume>2</volume>             <fpage>97</fpage>             <lpage>116</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Mika1">
        <label>50</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mika</surname><given-names>S</given-names></name><name name-style="western"><surname>Rätsch</surname><given-names>G</given-names></name><name name-style="western"><surname>Weston</surname><given-names>B</given-names></name><name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name><name name-style="western"><surname>Smola</surname><given-names>AJ</given-names></name><etal/></person-group>             <year>2000</year>             <article-title>Kernel-Fisher discriminant analysis.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Solla</surname><given-names>SA</given-names></name><name name-style="western"><surname>Leen</surname><given-names>K</given-names></name><name name-style="western"><surname>Müller</surname><given-names>K</given-names></name></person-group>             <source>Advances in neural information processing systems</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>526</fpage>             <lpage>542</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Efron1">
        <label>51</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Efron</surname><given-names>B</given-names></name><name name-style="western"><surname>Tibshirani</surname><given-names>RJ</given-names></name></person-group>             <year>1993</year>             <source>An introduction to the bootstrap</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Chapman, and Hall</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">456</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002057-Aksay1">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Aksay</surname><given-names>E</given-names></name><name name-style="western"><surname>Gamkrelidze</surname><given-names>G</given-names></name><name name-style="western"><surname>Seung</surname><given-names>HS</given-names></name><name name-style="western"><surname>Baker</surname><given-names>R</given-names></name><name name-style="western"><surname>Tank</surname><given-names>DW</given-names></name></person-group>             <year>2001</year>             <article-title>In vivo intracellular recording and perturbation of persistent activity in a neural integrator.</article-title>             <source>Nat Neurosci</source>             <volume>4</volume>             <fpage>184</fpage>             <lpage>193</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Egorov1">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Egorov</surname><given-names>AV</given-names></name><name name-style="western"><surname>Hamam</surname><given-names>BN</given-names></name><name name-style="western"><surname>Fransen</surname><given-names>E</given-names></name><name name-style="western"><surname>Hasselmo</surname><given-names>ME</given-names></name><name name-style="western"><surname>Alonso</surname><given-names>AA</given-names></name></person-group>             <year>2002</year>             <article-title>Graded persistent activity in entorhinal cortex neurons.</article-title>             <source>Nature</source>             <volume>420</volume>             <fpage>173</fpage>             <lpage>178</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Cossart1">
        <label>54</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cossart</surname><given-names>R</given-names></name><name name-style="western"><surname>Aronov</surname><given-names>D</given-names></name><name name-style="western"><surname>Yuste</surname><given-names>R</given-names></name></person-group>             <year>2003</year>             <article-title>Attractor dynamics of network UP states in the neocortex.</article-title>             <source>Nature</source>             <volume>423</volume>             <fpage>283</fpage>             <lpage>288</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Deadwyler1">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Deadwyler</surname><given-names>SA</given-names></name><name name-style="western"><surname>Hampson</surname><given-names>RE</given-names></name></person-group>             <year>1997</year>             <article-title>The significance of neural ensemble codes during behavior and cognition.</article-title>             <source>Annu Rev Neurosci</source>             <volume>20</volume>             <fpage>217</fpage>             <lpage>44</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Briggman1">
        <label>56</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Briggman</surname><given-names>KL</given-names></name><name name-style="western"><surname>Abarbanel</surname><given-names>HD</given-names></name><name name-style="western"><surname>Kristan</surname><given-names>WB</given-names><suffix>Jr</suffix></name></person-group>             <year>2005</year>             <article-title>Optical imaging of neuronal populations during decision-making.</article-title>             <source>Science</source>             <volume>307</volume>             <fpage>896</fpage>             <lpage>901</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Yu1">
        <label>57</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>BM</given-names></name><name name-style="western"><surname>Cunningham</surname><given-names>JP</given-names></name><name name-style="western"><surname>Santhanam</surname><given-names>G</given-names></name><name name-style="western"><surname>Ryu</surname><given-names>SI</given-names></name><name name-style="western"><surname>Shenoy</surname><given-names>KV</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity.</article-title>             <source>J Neurophysiol</source>             <volume>102</volume>             <fpage>614</fpage>             <lpage>635</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Fellous1">
        <label>58</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fellous</surname><given-names>J-M</given-names></name><name name-style="western"><surname>Tiesinga</surname><given-names>PHE</given-names></name><name name-style="western"><surname>Thomas</surname><given-names>PJ</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>2004</year>             <article-title>Discovering spike patterns in neuronal responses.</article-title>             <source>J Neurosci</source>             <volume>24</volume>             <fpage>2989</fpage>             <lpage>3001</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Seidemann1">
        <label>59</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Seidemann</surname><given-names>E</given-names></name><name name-style="western"><surname>Meilijson</surname><given-names>I</given-names></name><name name-style="western"><surname>Abeles</surname><given-names>M</given-names></name><name name-style="western"><surname>Bergman</surname><given-names>H</given-names></name><name name-style="western"><surname>Vaadia</surname><given-names>E</given-names></name></person-group>             <year>1995</year>             <article-title>Simultaneously recorded single units in the frontal cortex go through sequences of discrete and stable states in monkeys performing a delayed localization task.</article-title>             <source>J Neurosci</source>             <volume>16</volume>             <fpage>752</fpage>             <lpage>768</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Pereira1">
        <label>60</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pereira</surname><given-names>F</given-names></name><name name-style="western"><surname>Mitchell</surname><given-names>T</given-names></name><name name-style="western"><surname>Botvinick</surname><given-names>M</given-names></name></person-group>             <year>2008</year>             <article-title>Machine learning classifiers and fMRI: A tutorial overview.</article-title>             <source>Neuroimage</source>             <volume>45</volume>             <fpage>199</fpage>             <lpage>209</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Sato1">
        <label>61</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sato</surname><given-names>JR</given-names></name><name name-style="western"><surname>Fujita</surname><given-names>A</given-names></name><name name-style="western"><surname>Thomaz</surname><given-names>CE</given-names></name><name name-style="western"><surname>Martin Mda</surname><given-names>G</given-names></name><name name-style="western"><surname>Mourão-Miranda</surname><given-names>J</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>Evaluating SVM and MLDA in the extraction of discriminant regions for mental state prediction.</article-title>             <source>Neuroimage</source>             <volume>47</volume>             <fpage>423</fpage>             <lpage>425</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Wang4">
        <label>62</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name></person-group>             <year>2009</year>             <article-title>A hybrid SVM-GLM approach for fMRI data analysis.</article-title>             <source>Neuroimage</source>             <volume>46</volume>             <fpage>608</fpage>             <lpage>615</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Friston1">
        <label>63</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name></person-group>             <year>2009</year>             <article-title>Modalities, Models and Models in Functional Neuroimaging.</article-title>             <source>Science</source>             <volume>326</volume>             <fpage>299</fpage>             <lpage>403</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Durstewitz5">
        <label>64</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Durstewitz</surname><given-names>D</given-names></name><name name-style="western"><surname>Seamans</surname><given-names>JK</given-names></name></person-group>             <year>2008</year>             <article-title>The dual-state theory of prefrontal cortex dopamine function with relevance to COMT genotypes and schizophrenia.</article-title>             <source>Biol Psychiat</source>             <volume>64</volume>             <fpage>739</fpage>             <lpage>49</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Ohiorhenuan1">
        <label>65</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ohiorhenuan</surname><given-names>E</given-names></name><name name-style="western"><surname>Mechler</surname><given-names>F</given-names></name><name name-style="western"><surname>Purpura</surname><given-names>KP</given-names></name><name name-style="western"><surname>Schmid</surname><given-names>AM</given-names></name><name name-style="western"><surname>Hu</surname><given-names>Q</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Sparse conding and high-order correlations in fine-scale cortical networks.</article-title>             <source>Nature</source>             <volume>466</volume>             <fpage>617</fpage>             <lpage>621</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Montani1">
        <label>66</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Montani</surname><given-names>F</given-names></name><name name-style="western"><surname>Ince</surname><given-names>RAA</given-names></name><name name-style="western"><surname>Senatore</surname><given-names>R</given-names></name><name name-style="western"><surname>Arabzadeh</surname><given-names>A</given-names></name><name name-style="western"><surname>Diamond</surname><given-names>ME</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>The impact of high order interactions on the rate of synchronous discharge and information transmission in somatosensory cortex.</article-title>             <source>Philos T Roy Soc A</source>             <volume>367</volume>             <fpage>3279</fpage>             <lpage>3310</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Schneidman1">
        <label>67</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name><name name-style="western"><surname>Berry</surname><given-names>MJ</given-names><suffix>2nd</suffix></name><name name-style="western"><surname>Segev</surname><given-names>R</given-names></name><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name></person-group>             <year>2006</year>             <article-title>Weak pairwise correlations imply strongly correlated network states in a neural population.</article-title>             <source>Nature</source>             <volume>440</volume>             <fpage>1007</fpage>             <lpage>1012</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Grn1">
        <label>68</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Grün</surname><given-names>S</given-names></name></person-group>             <year>2009</year>             <article-title>Data-driven significance estimation for precise spike correlation.</article-title>             <source>J Neurophysiol</source>             <volume>101</volume>             <fpage>1126</fpage>             <lpage>1140</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-QuianQuiroga1">
        <label>69</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Quian Quiroga</surname><given-names>R</given-names></name><name name-style="western"><surname>Panzeri</surname><given-names>S</given-names></name></person-group>             <year>2009</year>             <article-title>Extracting information from neuronal populations: information theory and decoding approaches.</article-title>             <source>Nat Rev Neurosci</source>             <volume>10</volume>             <fpage>173</fpage>             <lpage>185</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Wiggins1">
        <label>70</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wiggins</surname><given-names>S</given-names></name></person-group>             <year>2003</year>             <source>Introduction to applied nonlinear dynamical systems and chaos</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Springer</publisher-name>             <fpage>107</fpage>             <lpage>110</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Durstewitz6">
        <label>71</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Durstewitz</surname><given-names>D</given-names></name><name name-style="western"><surname>Deco</surname><given-names>G</given-names></name></person-group>             <year>2008</year>             <article-title>Computational significance of transient dynamics in cortical networks.</article-title>             <source>Eur J Neurosci</source>             <volume>27</volume>             <fpage>217</fpage>             <lpage>27</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Ashwin1">
        <label>72</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ashwin</surname><given-names>P</given-names></name><name name-style="western"><surname>Timme</surname><given-names>M</given-names></name></person-group>             <year>2005</year>             <article-title>Nonlinear dynamics: When instability makes sense.</article-title>             <source>Nature</source>             <volume>436</volume>             <fpage>36</fpage>             <lpage>37</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Friedrich1">
        <label>73</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friedrich</surname><given-names>RW</given-names></name><name name-style="western"><surname>Laurent</surname><given-names>G</given-names></name></person-group>             <year>2001</year>             <article-title>Dynamic optimization of odor representations by slow temporal patterning of mitral cell activity.</article-title>             <source>Science</source>             <volume>291</volume>             <fpage>889</fpage>             <lpage>894</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Compte1">
        <label>74</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Compte</surname><given-names>A</given-names></name><name name-style="western"><surname>Brunel</surname><given-names>N</given-names></name><name name-style="western"><surname>Goldman-Rakic</surname><given-names>PS</given-names></name><name name-style="western"><surname>Wang</surname><given-names>X-J</given-names></name></person-group>             <year>2000</year>             <article-title>Synaptic mechanisms and network dynamics underlying spatial working memory in a cortical network model.</article-title>             <source>Cereb Cortex</source>             <volume>10</volume>             <fpage>910</fpage>             <lpage>923</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Crowe1">
        <label>75</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Crowe</surname><given-names>DA</given-names></name><name name-style="western"><surname>Averbeck</surname><given-names>B</given-names></name><name name-style="western"><surname>Chafee</surname><given-names>MV</given-names></name></person-group>             <year>2010</year>             <article-title>Rapid Sequences of Population Activity Patterns Dynamically Encode Task-Critical Spatial Information in Parietal Cortex.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>11640</fpage>             <lpage>11653</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Braun1">
        <label>76</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Braun</surname><given-names>ML</given-names></name><name name-style="western"><surname>Buhmann</surname><given-names>JM</given-names></name><name name-style="western"><surname>Müller</surname><given-names>K-R</given-names></name></person-group>             <year>2008</year>             <article-title>On relevant dimensions in kernel feature spaces.</article-title>             <source>Journal of Machine Learning Research</source>             <volume>9</volume>             <fpage>1875</fpage>             <lpage>1908</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Cat1">
        <label>77</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cat</surname><given-names>L</given-names></name><name name-style="western"><surname>Mees</surname><given-names>A</given-names></name><name name-style="western"><surname>Judd</surname><given-names>K</given-names></name></person-group>             <year>1998</year>             <article-title>Dynamics from multivariate time series.</article-title>             <source>Physica D</source>             <volume>121</volume>             <fpage>75</fpage>             <lpage>88</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-BalaguerBallester2">
        <label>78</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Balaguer-Ballester</surname><given-names>E</given-names></name><name name-style="western"><surname>Clark</surname><given-names>N</given-names></name><name name-style="western"><surname>Krumbholz</surname><given-names>K</given-names></name><name name-style="western"><surname>Denham</surname><given-names>SL</given-names></name></person-group>             <year>2009</year>             <article-title>Understanding pitch perception as a hierarchical process with to-down modulation.</article-title>             <source>PLoS Comput Biol</source>             <volume>5</volume>             <fpage>e1000301</fpage>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000301" xlink:type="simple">10.1371/journal.pcbi.1000301</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Izhikevich1">
        <label>79</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Izhikevich</surname><given-names>EM</given-names></name></person-group>             <year>2006</year>             <article-title>Polychronization: Computation with spikes.</article-title>             <source>Neural Comput</source>             <volume>18</volume>             <fpage>245</fpage>             <lpage>282</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Chapin1">
        <label>80</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chapin</surname><given-names>JK</given-names></name><name name-style="western"><surname>Nicolelis</surname><given-names>MA</given-names></name></person-group>             <year>1999</year>             <article-title>Principal component analysis of neuronal ensemble activity reveals multidimensional somatosensory representations.</article-title>             <source>J Neurosci Meth</source>             <volume>94</volume>             <fpage>121</fpage>             <lpage>140</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Smola1">
        <label>81</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Smola</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Óvári</surname><given-names>ZL</given-names></name><name name-style="western"><surname>Williamson</surname><given-names>RC</given-names></name></person-group>             <year>2001</year>             <article-title>Regularization with dot-product kernels.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Leen</surname><given-names>TK</given-names></name><name name-style="western"><surname>Dietterich</surname><given-names>TG</given-names></name><name name-style="western"><surname>Tresp</surname><given-names>V</given-names></name></person-group>             <source>Advances in Neural Information Processing Systems</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>308</fpage>             <lpage>314</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Paxinos1">
        <label>82</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Paxinos</surname><given-names>G</given-names></name><name name-style="western"><surname>Watson</surname><given-names>C</given-names></name></person-group>             <year>2007</year>             <source>The rat brain in stereotaxic coordinates</source>             <publisher-loc>London</publisher-loc>             <publisher-name>Elsevier</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">25</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002057-Steinke1">
        <label>83</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Steinke</surname><given-names>F</given-names></name><name name-style="western"><surname>Scholkopf</surname><given-names>B</given-names></name></person-group>             <year>2008</year>             <article-title>Kernels, regularization and differential equations.</article-title>             <source>Pattern Recogn</source>             <volume>41</volume>             <fpage>3271</fpage>             <lpage>3286</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Theiler1">
        <label>84</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Theiler</surname><given-names>J</given-names></name></person-group>             <year>1988</year>             <article-title>Lacunarity in a best estimator of fractal dimension.</article-title>             <source>Phys Lett A</source>             <volume>135</volume>             <fpage>195</fpage>             <lpage>210</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Provenzale1">
        <label>85</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Provenzale</surname><given-names>A</given-names></name><name name-style="western"><surname>Smith</surname><given-names>LA</given-names></name><name name-style="western"><surname>Vio</surname><given-names>R</given-names></name><name name-style="western"><surname>Murante</surname><given-names>G</given-names></name></person-group>             <year>1992</year>             <article-title>Distinguishing between low-dimensional dynamics and randomness in measured time series.</article-title>             <source>Physica D</source>             <volume>5</volume>             <fpage>28</fpage>             <lpage>31</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002057-Grassberger1">
        <label>86</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Grassberger</surname><given-names>P</given-names></name></person-group>             <year>1983</year>             <article-title>Generalized dimensions of strange attractors.</article-title>             <source>Phys Lett A</source>             <volume>976</volume>             <fpage>227</fpage>             <lpage>230</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>
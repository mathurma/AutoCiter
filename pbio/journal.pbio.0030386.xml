<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="publisher">pbio</journal-id><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="doi">10.1371/journal.pbio.0030386</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Evolutionary Biology/Animal Behavior</subject>
          <subject>Neuroscience</subject>
          <subject>Physiology</subject>
        </subj-group>
        <subj-group subj-group-type="System Taxonomy">
          <subject>Mus (mouse)</subject>
        </subj-group>
      </article-categories><title-group><article-title>Ultrasonic Songs of Male Mice</article-title><alt-title alt-title-type="running-head">Songs of Male Mice</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Holy</surname>
            <given-names>Timothy E</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Guo</surname>
            <given-names>Zhongsheng</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1">
        <label>1</label><addr-line>
        
      Department of Anatomy and Neurobiology, Washington University School of Medicine, St. Louis, Missouri, United States of America</addr-line></aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Kauer</surname>
            <given-names>John</given-names>
          </name>
          <role>Academic Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Tufts University School of Medicine, 
				
				
			United States of America</aff><author-notes>
        <corresp id="cor1">* To whom correspondence should be addressed. E-mail: <email xlink:type="simple">holy@wustl.edu</email></corresp>
        <fn fn-type="con" id="n1">
          <p> TEH conceived the experiments. TEH and ZG designed the experiments, built the custom hardware, and wrote the software. ZG collected the data. TEH analyzed the data and wrote the paper.</p>
        </fn>
      <fn fn-type="conflict">
        <p> The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="ppub">
        <month>12</month>
        <year>2005</year>
      </pub-date><pub-date pub-type="epub">
        <day>1</day>
        <month>11</month>
        <year>2005</year>
      </pub-date><volume>3</volume><issue>12</issue><elocation-id>e386</elocation-id><history>
        <date date-type="received">
          <day>7</day>
          <month>1</month>
          <year>2005</year>
        </date>
        <date date-type="accepted">
          <day>14</day>
          <month>9</month>
          <year>2005</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2005</copyright-year><copyright-holder>Holy and Guo</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article page="e420" related-article-type="companion" vol="3" xlink:href="info:doi/10.1371/journal.pbio.0030420" xlink:title="synopsis" xlink:type="simple">
				<article-title>Music to Her Ears? Male Mice Sing an Ultrasonic Tune</article-title>
			</related-article><abstract>
        <p>Previously it was shown that male mice, when they encounter female mice or their pheromones, emit ultrasonic vocalizations with frequencies ranging over 30–110 kHz. Here, we show that these vocalizations have the characteristics of song, consisting of several different syllable types, whose temporal sequencing includes the utterance of repeated phrases. Individual males produce songs with characteristic syllabic and temporal structure. This study provides a quantitative initial description of male mouse songs, and opens the possibility of studying song production and perception in an established genetic model organism.</p>
      </abstract><abstract abstract-type="toc">
        <p>Vocalizations emitted by male mice when encoutering female pheromones have the characteristics of song, including temporal structure and repeated syllables.</p>
      </abstract></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Many animals communicate using sound. Often, brief sounds are produced to warn of danger or mediate aggressive encounters. Some species, however, produce long sequences of vocalizations often called “songs.” Most commonly, these long sequences are generated as a part of courtship. For example, many insects and amphibians [<xref ref-type="bibr" rid="pbio-0030386-b01">1</xref>] advertise their presence and identity with a single type of utterance—which, depending on the species, might be described as a chirp, click, or whine—repeated several times to form a “phrase,” with silent gaps between phrases. The utterance, its repetition rate, and the number of repetitions in a phrase are characteristic of the species [<xref ref-type="bibr" rid="pbio-0030386-b01">1</xref>]. More complex vocalizations are observed in many birds [<xref ref-type="bibr" rid="pbio-0030386-b02">2</xref>], as well as in a few mammals such as whales [<xref ref-type="bibr" rid="pbio-0030386-b03">3</xref>] and bats [<xref ref-type="bibr" rid="pbio-0030386-b04">4</xref>]. These species generate multiple types of sounds organized in more intricate phrases.</p>
      <p>Rodents produce a variety of social vocalizations, including vocalizations audible to humans, like postpartum sounds and distress calls, as well as ultrasonic vocalizations [<xref ref-type="bibr" rid="pbio-0030386-b05">5</xref>,<xref ref-type="bibr" rid="pbio-0030386-b06">6</xref>]. In mice, ultrasonic vocalizations utilize frequencies higher than 30 kHz [<xref ref-type="bibr" rid="pbio-0030386-b07">7</xref>], and therefore cannot be detected directly by human ears. A number of studies have shown that mice produce ultrasonic vocalizations in at least two situations: pups produce “isolation calls” when cold or when removed from the nest [<xref ref-type="bibr" rid="pbio-0030386-b08">8</xref>], and males emit “ultrasonic vocalizations” in the presence of females or when they detect their urinary pheromones [<xref ref-type="bibr" rid="pbio-0030386-b06">6</xref>,<xref ref-type="bibr" rid="pbio-0030386-b09">9</xref>–<xref ref-type="bibr" rid="pbio-0030386-b11">11</xref>]. Most commonly, these sounds have been recorded using a detector with narrow frequency tuning [<xref ref-type="bibr" rid="pbio-0030386-b09">9</xref>,<xref ref-type="bibr" rid="pbio-0030386-b10">10</xref>], which suffices to estimate the amount of vocalization. However, because of its narrow frequency tuning, such a detector does not record the acoustical details of these vocalizations.</p>
      <p>While numerous studies have focused on the circumstances leading to ultrasound production, few have examined the sounds themselves. Sales [<xref ref-type="bibr" rid="pbio-0030386-b07">7</xref>] observed that these vocalizations consisted of a series of discrete utterances, with species-specific differences in vocalizations. Some diversity was also noted among the utterances within a species [<xref ref-type="bibr" rid="pbio-0030386-b06">6</xref>,<xref ref-type="bibr" rid="pbio-0030386-b07">7</xref>], but it was not determined whether this latter variability was continuous—as in the case, for example, of the “random” variability observed when a single word is spoken many times—or whether the utterances fall into distinct categories. In a recent quantitative study of mouse vocalizations, Liu et al. [<xref ref-type="bibr" rid="pbio-0030386-b12">12</xref>] studied changes in pup vocalizations during the first 2 wk after birth, and compared these to adult vocalizations. However, this study focused only on the aggregate properties of vocalizations, measuring parameters such as median pitch and call rate, which, if applied to humans, would be more analogous to “voice” than to speech. To date, no study that we know of has examined whether the discrete utterances consist of distinct syllable types, or whether these vocalizations have significant temporal structure.</p>
      <p>Here, we provide a quantitative description of the ultrasonic vocalizations of the adult male mouse, and show that they display unexpected richness, including several syllable types organized into phrases and motifs. Thus, these vocalizations display the characteristics of song [<xref ref-type="bibr" rid="pbio-0030386-b01">1</xref>,<xref ref-type="bibr" rid="pbio-0030386-b03">3</xref>,<xref ref-type="bibr" rid="pbio-0030386-b13">13</xref>]. Different males, even though genetically identical, show small but significant differences in syllable usage and the temporal structure of their songs. These results indicate that communication among mice may be more complex than previously appreciated. Because of the ubiquity of the mouse for physiological and genetic investigations, these observations may lead to new opportunities in studies of the biological basis of song production and perception.</p>
      <sec id="s1a">
        <title>Terminology</title>
        <p>As the terminology used to describe animal vocalizations is varied, we adopt the following definitions. A “syllable” is a unit of sound separated by silence from other sound units [<xref ref-type="bibr" rid="pbio-0030386-b14">14</xref>]; it may consist of one or more “notes,” continuous markings on a sonogram. A “syllable type” is a category of syllable, observed regularly in the animal's vocalization, distinct from other syllable types. A “phrase” is a sequence of syllables uttered in close succession. A “phrase type” or “motif” is a sequence of several syllables, falling into one or more syllable types, where the entire sequence is observed repeatedly in the animal's vocalization.</p>
        <p>The term “song” has been used with a variety of connotations, so that Broughton [<xref ref-type="bibr" rid="pbio-0030386-b13">13</xref>] offers three different definitions of song: a <italic>sensu latissimo,</italic> a “sound of animal origin which is not both accidental and meaningless,” which includes relatively simple vocalizations often described as “calls”; a <italic>sensu stricto,</italic> “a series of notes [or syllables], generally of more than one type, uttered in succession and so related as to form a recognizable sequence or pattern in time”; and a <italic>sensu strictissimo,</italic> “a complete succession of periods or phrases,” in which a song consists of several distinct motifs, often delivered in a characteristic sequence.</p>
      </sec>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Listening to Ultrasonic Vocalizations</title>
        <p>To induce ultrasonic vocalizations, male mice of the B6D2F1 strain were presented with sex-specific odors applied on cotton swabs (<xref ref-type="fig" rid="pbio-0030386-g001">Figure 1</xref>). We tested dilute urine of either sex (BALB/c strain) and mixtures of urine from both sexes. (The correspondence between stimulus identity and vocal response will be reported elsewhere.) We recorded all sounds in the chamber with a microphone with flat frequency response from 20 Hz to 100 kHz. While these vocalizations are well beyond the range of human hearing, we make them audible through two techniques. Most straightforward is to play them back slowly. When slowed 16×, these vocalizations sound like a series of breathy whistles (<xref ref-type="supplementary-material" rid="sa001">Audio S1</xref>). However, slow playback makes it difficult for human listeners to develop an appreciation of the temporal sequence of the vocalizations. Using a phase vocoder algorithm [<xref ref-type="bibr" rid="pbio-0030386-b15">15</xref>], the pitch of these vocalizations can be dropped several octaves without lengthening the duration of the playback. These pitch-shifted vocalizations are reminiscent of birdsong (<xref ref-type="supplementary-material" rid="sa002">Audio S2</xref>). Readers are urged to listen to these recordings.</p>
        <fig id="pbio-0030386-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030386.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Male Mice Vocalize in the Ultrasound after Olfactory Exploration of Urinary Cues</title>
            <p>A cotton swab containing female mouse urine (top) was introduced at approximately 30 s into a 210-s trial. Arrow indicates the time of first contact with the cotton swab. Recorded acoustical power is represented as a function of time and frequency, with shading increasing with power. Power below 25 kHz was truncated. Bottom, an expansion of a 2-s period showing vocalizations in greater detail. Individual syllables, as identified by an automated algorithm, are spanned by magenta lines below.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030386.g001" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2b">
        <title>Elementary Features of Vocalizations</title>
        <p>Male mouse ultrasonic vocalizations consisted of a rapid series of “chirp-like” syllables in the 30–110 kHz band (<xref ref-type="fig" rid="pbio-0030386-g001">Figure 1</xref>). Syllables were of varying duration (approximately 30–200 ms), uttered at rates of about ten per second. Most syllables involved rapid sweeps in frequency, with rates of approximately 1 kHz/ms typical. Over tens of seconds, periods of closely spaced syllables alternated with periods of silence. These features of adult male vocalizations, and their analogs for the isolation calls of mouse pups, have been previously described [<xref ref-type="bibr" rid="pbio-0030386-b07">7</xref>,<xref ref-type="bibr" rid="pbio-0030386-b12">12</xref>].</p>
        <p>The microphone recorded a variety of sounds in the test chamber, including noises from movement, gnawing, contact with the cage wall, audible squeaks, and ultrasonic vocalizations. For the purposes of this study, we excluded sounds other than ultrasonic vocalizations. The majority of extraneous sounds fell below 30 kHz, and were excluded by selecting the appropriate frequency band. However, some sounds, particularly brief “snaps,” penetrated into the frequency band of the ultrasonic vocalizations. We developed an automated algorithm to recognize ultrasonic vocalizations in terms of their generic features. Subjectively, the algorithm appears no worse than a well-trained human in identifying these vocalizations (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>; <xref ref-type="fig" rid="pbio-0030386-g001">Figure 1</xref>).</p>
      </sec>
      <sec id="s2c">
        <title>Features of Syllables: Pitch Changes</title>
        <p>As reported previously [<xref ref-type="bibr" rid="pbio-0030386-b07">7</xref>], inspection (<xref ref-type="fig" rid="pbio-0030386-g001">Figure 1</xref>) suggests that some syllables involve relatively sudden, large changes (“jumps”) in frequency. To determine whether these frequency jumps are stereotyped or random, we analyzed a collection of 750 syllables uttered by one mouse in a single 210-s trial. We simplified our description of each syllable by extracting the dominant frequency (the “pitch”) as a function of time (<xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>A). For each syllable, we compared the pitch at one moment with the pitch in the next time bin, approximately 1 ms later. These pitch pairs were pooled for all 750 syllables, resulting in a total of 31,303 consecutive pitch pairs. This analysis (<xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>B) revealed four distinct clusters of pitch changes. The long cluster along the diagonal corresponds to the gradual shift in pitch occurring at most time points in all syllables. Two distinct off-diagonal clusters reveal large, stereotyped jumps to or from comparatively low frequencies (35–50 kHz). These downward (“d”) and upward (“u”) jumps are often paired in a syllable (see below and insets for <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>B), and will be collectively described as “low jumps.” The cluster just below the diagonal, containing transitions from 70–90 kHz down to 55–70 kHz, results from a third type of jump (“high jump,” or “h”). These jumps were often, but not exclusively, associated with a brief “grace note” at the beginning of a syllable (see jump labeled “h” in lower inset, <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>B).</p>
        <fig id="pbio-0030386-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030386.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Characterization of Pitch Changes during Syllables</title>
            <p>(A) Two examples of syllables, represented in terms of their sonogram (top member of each pair of panels) and the extracted pitch versus time (bottom member of pairs).</p>
            <p>(B) Plot of pitch at one time point versus the next time point (Δ<italic>t</italic> = 1.02 ms). All such pitch pairs in all syllables from a single trial with 750 syllables are shown, representing a total of 31,303 pitch changes. Particular pitch jumps are placed within the context of their individual syllables at right (top syllable, 98 ms in duration; bottom syllable, 33 ms in duration).</p>
            <p>(C) Pitch pairs analyzed for single 210-s trials from 45 different mice, containing in aggregate 15,543 syllables and over 600,000 pitch pairs. The distribution of pitch pairs is represented as a two-dimensional histogram; the correspondence between grayscale and number of observations is indicated in the color bar at right. Polygons define the clusters corresponding to the three jump types “u,” “h,” and “d.”</p>
            <p>(D) Numbers of each type of pitch jump per trial (45 mice, one trial each).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030386.g002" xlink:type="simple"/>
        </fig>
        <p>These pitch jumps were identified in <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>B from a single 210-s recording from one mouse. To determine whether these jumps are stereotypic features of the ultrasonic vocalizations of all male mice, we performed the same analysis for a 210-s trial from each of 45 different males. The pitch changes in adjacent time bins are pooled across mice in <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>C. Both the number of clusters and their positions and sizes are essentially unchanged, and examples of all three types of jumps were broadly distributed across mice (<xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>D). Thus, at least for similarly aged males of the B6D2F1 strain, these pitch jumps are a universal feature of ultrasonic vocalizations.</p>
      </sec>
      <sec id="s2d">
        <title>Pitch Jumps and Mechanisms of Sound Production</title>
        <p>Many syllables with low jumps display both a fundamental frequency and a faint first harmonic during the low-frequency period (<xref ref-type="fig" rid="pbio-0030386-g003">Figure 3</xref>A; see also <xref ref-type="fig" rid="pbio-0030386-g001">Figures 1</xref> and <xref ref-type="fig" rid="pbio-0030386-g002">2</xref>A). The frequency of the harmonic is almost precisely twice that of the fundamental, suggesting the involvement of a resonator in the production of these sounds<italic>.</italic> A priori, this resonator might be the vocal folds of the larynx. However, based on the effect of partial replacement of air with helium, Roberts [<xref ref-type="bibr" rid="pbio-0030386-b16">16</xref>] argued that these sounds are not produced by the vibration of vocal cords. Instead, he proposed that ultrasound arises from an aerodynamic whistle, and showed that mechanical whistles can produce sounds similar to the examples described by Sales [<xref ref-type="bibr" rid="pbio-0030386-b07">7</xref>], including pitch jumps.</p>
        <fig id="pbio-0030386-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030386.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Features of Vocalizations Relating to Mechanisms of Sound Production</title>
            <p>(A) Syllable with both a fundamental and first harmonic.</p>
            <p>(B) Abundance of frequency (vertical axis is frequency, continued from [A]) in syllables with (LJ<sup>+</sup>) and without (LJ<sup>−</sup>) low jumps.</p>
            <p>(C) Average pitch (top) and mean ± standard deviation log<sub>10</sub>(power) (bottom) as a function of time, surrounding a downward low jump (for syllables with low jumps) or surrounding the upward crossing of 75 kHz (for syllables without low jumps). Power units are arbitrary but consistent between syllable types. Color scheme is as in (B).</p>
            <p>(D) Syllable showing extensive temporal overlap and independent frequency modulation among the different notes in the syllable. Syllables are from the same trial analyzed in <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>B.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030386.g003" xlink:type="simple"/>
        </fig>
        <p>While our recordings appear largely consistent with Roberts's results, several features of these vocalizations indicate that their production is more sophisticated than that of a whistle from a rigid, static pipe. The rigid whistles investigated by Roberts had a characteristic relationship between frequency and fluid velocity [<xref ref-type="bibr" rid="pbio-0030386-b16">16</xref>]. Frequency was fairly stable over a range of velocities, and would suddenly jump to a new frequency at yet higher or lower velocities. In contrast, the pitch of mouse vocalizations is modulated considerably, in both a continuous and discrete (jump) fashion. Despite their stereotyped form, jumps were not obligatory upon reaching a particular frequency. While down-type jumps began from frequencies of 65–80 kHz (see <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>B), these frequencies were well-sampled even in syllables that lack these jumps (<xref ref-type="fig" rid="pbio-0030386-g003">Figure 3</xref>B). Furthermore, if jumps were produced by changes in air velocity, one might expect to see differences in vocal power between cases where jumps do and do not occur. In contrast with this expectation, the power distributions of syllables both with and without “d” jumps overlap considerably (<xref ref-type="fig" rid="pbio-0030386-g003">Figure 3</xref>C), although variability in the mouse's head position and orientation relative to the microphone could obscure a true relationship.</p>
        <p>Finally, the fine-scale temporal structure of pitch jumps appears to be inconsistent with the nonlinear properties of purely static whistles. During a downward low jump, the pitch of the preceding phase overlaps in time with the pitch in the succeeding phase (<xref ref-type="fig" rid="pbio-0030386-g003">Figure 3</xref>A), often by 5–10 ms. This behavior is apparently not observed in pitch jumps arising from mode-locking nonlinearities [<xref ref-type="bibr" rid="pbio-0030386-b17">17</xref>], where changes in pitch are nearly instantaneous. In a few cases, both tones were present simultaneously for longer periods, with one frequency modulated and the other nearly fixed (<xref ref-type="fig" rid="pbio-0030386-g003">Figure 3</xref>D). In birdsong, similar observations were used by Greenewalt [<xref ref-type="bibr" rid="pbio-0030386-b18">18</xref>] to posit two sites of sound production—specifically, that birds could independently control the left and right sides of their syrinx. This assertion was later confirmed directly [<xref ref-type="bibr" rid="pbio-0030386-b19">19</xref>]. Examples such as <xref ref-type="fig" rid="pbio-0030386-g003">Figure 3</xref>D may indicate that mice have at least two sites of ultrasound production. However, the strength of this conclusion is tempered by our incomplete knowledge of the nonlinear properties of aerodynamic whistles [<xref ref-type="bibr" rid="pbio-0030386-b20">20</xref>].</p>
      </sec>
      <sec id="s2e">
        <title>Classifying Syllables into Distinct Types</title>
        <p>Because pitch jumps exist in three distinct categories, their presence or absence serves as a basis for classifying individual syllables into types. However, it is possible that other features of these vocalizations might also be a basis for classification. We therefore analyzed these syllables using multidimensional scaling, a technique that has been used previously to classify syllables in birdsong [<xref ref-type="bibr" rid="pbio-0030386-b21">21</xref>]. Multidimensional scaling provides a method to represent high-dimensional data in lower dimensions; it takes as an input the pairwise “distance” between any two pitch waveforms, and attempts to faithfully represent the set of all pairwise distances by proper placement of points, each representing a single syllable, in two dimensions (<xref ref-type="fig" rid="pbio-0030386-g004">Figure 4</xref>A). Because inspection suggested that a given syllable type can be uttered quickly or slowly, we first aligned the pairs by warping their time axes to place the pitch waveforms in maximal correspondence with each other (<xref ref-type="fig" rid="pbio-0030386-g004">Figure 4</xref>A; [<xref ref-type="bibr" rid="pbio-0030386-b22">22</xref>]). We also used a variant of multidimensional scaling, called isomap [<xref ref-type="bibr" rid="pbio-0030386-b23">23</xref>], which assembles global information from local features.</p>
        <fig id="pbio-0030386-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030386.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Multidimensional Scaling Analysis of Syllable Types</title>
            <p>(A) Pairs of pitch waveforms are temporally aligned using dynamic time warping, and pairwise distances (root mean squared difference) are computed. Using multidimensional scaling (MDS)/isomap, projections are found that approximately preserve the distances between pairs.</p>
            <p>(B) Isomap analysis of all pitch waveforms in the trial analyzed in <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>B. Points are colored according to the presence or absence of low jumps as in <xref ref-type="fig" rid="pbio-0030386-g003">Figure 3</xref>B.</p>
            <p>(C) A different isomap projection, focusing only on syllables containing low jumps. Sonograms of representative syllables in both clusters are shown in the insets. Pitch waveforms are from the same trial analyzed in <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>B.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030386.g004" xlink:type="simple"/>
        </fig>
        <p>The isomap analysis revealed the presence of several clusters, indicating distinct syllable types. The most prominent distinction is illustrated in <xref ref-type="fig" rid="pbio-0030386-g004">Figure 4</xref>B, with an almost perfect correspondence between cluster membership and the presence or absence of low-jump transitions. Closer examination of the cluster representing syllables containing low jumps reveals further clusters within this overall category. An example is shown in <xref ref-type="fig" rid="pbio-0030386-g004">Figure 4</xref>C, in which syllables again group into types that can be described in terms of their pitch jumps: one distinct cluster contains almost entirely syllables with an “h” jump followed by a “d” jump. Further projections (not shown) confirm the presence of additional clusters, which also correspond to particular sequences of pitch jumps.</p>
        <p>Therefore, general classification techniques confirm that syllables are naturally grouped by their pitch jumps. In fact, from the isomap analysis we have not found evidence for any other means to categorize syllables; in all cases we have examined, clear isomap clusters correspond to types defined by their sequence of pitch jumps. However, it remains possible that further subtypes exist, but that the isomap analysis fails to reveal these clusters. We therefore focused on the simplest syllable type, with no pitch jumps at all. These syllables take a variety of forms, some of which are illustrated in <xref ref-type="fig" rid="pbio-0030386-g005">Figure 5</xref>A. We noted that many had an oscillatory appearance. We therefore fit each pitch waveform to a sine wave, scaling and shifting both the time and frequency axes for maximal alignment. (We did not permit local time warping, as used in <xref ref-type="fig" rid="pbio-0030386-g004">Figure 4</xref>.) The quality of the fit could be assessed by scaling and shifting each pitch waveform to a common axis, revealing that the vast majority of these waveforms lie on top of each other, as well as the underlying sine wave (<xref ref-type="fig" rid="pbio-0030386-g005">Figure 5</xref>B). Based on this result, we call syllables lacking any pitch jumps “sinusoidal sweeps” (SSs).</p>
        <fig id="pbio-0030386-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030386.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Pitch Waveforms of Syllables Lacking Jumps</title>
            <p>(A) Sonograms of representative syllables, showing a range of oscillatory behavior.</p>
            <p>(B) Overlay of pitch waveforms for all 361 syllables lacking pitch jumps from the trial analyzed in <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>B. Time and frequency axes have been shifted and globally stretched independently for each syllable to bring waveforms into maximal overlap with a sine wave. The root mean squared error in fit to the sine wave is indicated by dashed lines.</p>
            <p>(C and D) Histogram of starting (C) and ending (D) phases.</p>
            <p>(E) Relationship between the oscillation rate (measured in periods/millisecond) and amplitude of the best-fit sine wave. Only syllables with at least 0.3 periods (160/361) are shown; syllables spanning a smaller fraction of a period do not permit an accurate measurement of oscillation rate or amplitude.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030386.g005" xlink:type="simple"/>
        </fig>
        <p>This analysis suggests that the pitch waveforms of SS syllables can be accurately described in terms of five variables (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>): the starting and ending phases, the rate of oscillation, the center frequency, and the pitch sine amplitude. Analysis of these parameters reveals that most SSs begin during (or just before) the rising phase of the sine wave (<xref ref-type="fig" rid="pbio-0030386-g005">Figure 5</xref>C), and that a large subset terminate at the peak of the sine wave (<xref ref-type="fig" rid="pbio-0030386-g005">Figure 5</xref>D). There is also a strong inverse relationship between the oscillation rate and the oscillation amplitude (<xref ref-type="fig" rid="pbio-0030386-g005">Figure 5</xref>E; see example in bottom two waveforms in <xref ref-type="fig" rid="pbio-0030386-g005">Figure 5</xref>A). An analogous inverse relationship has been found in birdsong, between the trill rate and the amplitude of pitch variation [<xref ref-type="bibr" rid="pbio-0030386-b24">24</xref>]. In birdsong, this relationship has been interpreted as evidence of a performance limit in the rate at which frequency can be modulated by changes in beak conformation. An analogous limit may constrain a mouse's ability to modulate the frequency of its whistle.</p>
        <p>While syllables are naturally grouped by their pitch jumps, and indeed we have not found any clear means of classifying them in a different way, it remains possible that other groupings exist. In particular, short stretches of a recording sometimes seem to provide evidence for further subtypes; an example is shown in the next section (<xref ref-type="fig" rid="pbio-0030386-g006">Figure 6</xref>A). <xref ref-type="table" rid="pbio-0030386-t001">Table 1</xref> shows a breakdown by prevalence of the most common syllable types in mouse ultrasonic vocalizations.</p>
        <fig id="pbio-0030386-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030386.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Examples of Temporal Regularities in Mouse Song</title>
            <p>(A) Sequences of syllables in a phrase. Here, “hdu” syllables have been classified as “A” or “B” depending on whether the lower frequency band fell or rose, respectively. SS and “h” (with a brief grace note) are labeled “C”.</p>
            <p>(B) Example of a phrase repeated three times without interruption in the original song. The three repeats are shown one above the other, aligned on the start time for the phrase. See <xref ref-type="supplementary-material" rid="sa004">Audio S4</xref> for entire sound recording.</p>
            <p>(C) Long time scale changes in syllable type. Syllable type is categorized by whether low jumps are present (LJ<sup>+</sup>) or absent (LJ<sup>−</sup>). Shown is the number of syllables without low jumps, out of the most recent 20 syllables. Insets contain sonograms from the indicated portions of the sequence.</p>
            <p>(A) and (C) are from the same trial analyzed in <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>B; (B) is from a different mouse.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030386.g006" xlink:type="simple"/>
        </fig>
        <table-wrap id="pbio-0030386-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.0030386.t001</object-id><label>Table 1</label><caption>
            <title>The Most Common Syllable Types in Mouse Ultrasonic Vocalizations, Labeled by Pitch Jump</title>
          </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030386.t001" xlink:type="simple"/><!-- <table>
					<thead>
					<TR>
					<TD COLSPAN="1" ROWSPAN="1">
					<HR>Syllable 
					<BREAK></BREAK>Type<sup>a</sup>
					</TD>
					<TD COLSPAN="1" ROWSPAN="1">
					<HR>Number 
					<BREAK></BREAK>(Trial A)
					</TD>
					<TD COLSPAN="1" ROWSPAN="1">
					<HR>Percent 
					<BREAK></BREAK>(Trial A)
					</TD>
					<TD COLSPAN="1" ROWSPAN="1">
					<HR>Percent 
					<BREAK></BREAK>(Population)
					</TD>
					</TR>
					</thead>
					<tbody>
					<TR>
					<TD COLSPAN="1" ROWSPAN="1">SS</TD>
					<TD COLSPAN="1" ROWSPAN="1">360</TD>
					<TD COLSPAN="1" ROWSPAN="1">48</TD>
					<TD COLSPAN="1" ROWSPAN="1">70&ndash;93</TD>
					</TR>
					<TR>
					<TD COLSPAN="1" ROWSPAN="1">du</TD>
					<TD COLSPAN="1" ROWSPAN="1">97</TD>
					<TD COLSPAN="1" ROWSPAN="1">13</TD>
					<TD COLSPAN="1" ROWSPAN="1">2&ndash;15</TD>
					</TR>
					<TR>
					<TD COLSPAN="1" ROWSPAN="1">h</TD>
					<TD COLSPAN="1" ROWSPAN="1">132</TD>
					<TD COLSPAN="1" ROWSPAN="1">18</TD>
					<TD COLSPAN="1" ROWSPAN="1">0&ndash;12</TD>
					</TR>
					<TR>
					<TD COLSPAN="1" ROWSPAN="1">d</TD>
					<TD COLSPAN="1" ROWSPAN="1">16</TD>
					<TD COLSPAN="1" ROWSPAN="1">2</TD>
					<TD COLSPAN="1" ROWSPAN="1">1&ndash;4</TD>
					</TR>
					<TR>
					<TD COLSPAN="1" ROWSPAN="1">hdu</TD>
					<TD COLSPAN="1" ROWSPAN="1">89</TD>
					<TD COLSPAN="1" ROWSPAN="1">12</TD>
					<TD COLSPAN="1" ROWSPAN="1">0&ndash;2</TD>
					</TR>
					<TR>
					<TD COLSPAN="1" ROWSPAN="1">u</TD>
					<TD COLSPAN="1" ROWSPAN="1">5</TD>
					<TD COLSPAN="1" ROWSPAN="1">1</TD>
					<TD COLSPAN="1" ROWSPAN="1">0&ndash;2</TD>
					</TR>
					<TR>
					<TD COLSPAN="1" ROWSPAN="1">hd</TD>
					<TD COLSPAN="1" ROWSPAN="1">20</TD>
					<TD COLSPAN="1" ROWSPAN="1">3</TD>
					<TD COLSPAN="1" ROWSPAN="1">0&ndash;1</TD>
					</TR>
					<TR>
					<TD COLSPAN="1" ROWSPAN="1">Remainder</TD>
					<TD COLSPAN="1" ROWSPAN="1">31</TD>
					<TD COLSPAN="1" ROWSPAN="1">4</TD>
					<TD COLSPAN="1" ROWSPAN="1">1&ndash;4</TD>
					</TR>
					</tbody>
					</table> --></table-wrap>
      </sec>
      <sec id="s2f">
        <title>Temporal Sequencing of Syllables</title>
        <p>In sonograms of mouse vocalizations, complex syllable sequences can be identified: <xref ref-type="fig" rid="pbio-0030386-g006">Figure 6</xref>A shows an example of a phrase in which three “hdu” syllables with descending low-frequency bands (labeled “A”) are followed by six “hdu” syllables with ascending low-frequency bands (labeled “B”); the phrase is finished off by an “h” syllable (almost a SS, but for the brief grace note), an A-type “hdu,” and an SS (<xref ref-type="supplementary-material" rid="sa003">Audio S3</xref>).</p>
        <p>An example of a motif can be seen in <xref ref-type="fig" rid="pbio-0030386-g006">Figure 6</xref>B, in which a phrase beginning with 2–3 SSs followed by 6–8 “du” syllables is repeated three times. The consistency of this repeated sequence, in the context of the whole, is easily noted in pitch-shifted playbacks (<xref ref-type="supplementary-material" rid="sa004">Audio S4</xref>).</p>
        <p>Finally, there are regularities in the syllable types over longer time scales. <xref ref-type="fig" rid="pbio-0030386-g006">Figure 6</xref>C shows an example of a trial that begins with a series of SSs, has a middle period with many syllables containing low jumps, and ends with repeated blocks of “h” syllables.</p>
        <p>To determine whether such examples are statistically significant, we investigated the temporal structure of these vocalizations quantitatively in terms of two models of syllable selection. To simplify the analysis, we grouped syllables into only two categories, depending on whether they did (“1”) or did not (“0”) contain one or more low jumps. We considered whether individual syllables might be selected randomly. In the first model, we tested whether the probability of selecting a syllable was based purely on the prevalence of each type, so that each syllable is selected independently of all others. In the second model, the selection probability depended on the identity of the previous syllable (<xref ref-type="fig" rid="pbio-0030386-g007">Figure 7</xref>A): from the data, we calculated the conditional probability <italic>p<sub>i</sub></italic><sub>→<italic>j</italic></sub> to choose a syllable of type <italic>j</italic> after a syllable of type <italic>i</italic> (<italic>i, j</italic> = 0, 1). We also used a third state (a “gap”) to represent a silent period lasting more than 0.5 s, to ensure that the analyzed state transitions occurred within a phrase. Omitting the gap state from the model did not qualitatively change the results.</p>
        <fig id="pbio-0030386-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030386.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Quantitative Modeling of Syllable Temporal Sequences</title>
            <p>(A) A three-state Markov model, where the states correspond to syllables with (“1”) or without (“0”) low jumps, and to a gap of greater than 0.5 s in the sequence. Arrows indicate possible choices for the next state; transition probabilities are calculated from the observed sequence of syllables and gaps.</p>
            <p>(B) Observed numbers of the eight distinct three-syllable combinations, and the number expected from two models: “syllable prevalence” picks the next syllable randomly based on the proportion of each type, whereas “transition probability” employs the Markov model diagrammed in (A).</p>
            <p>(C) Comparison of transition probabilities to type 1 syllables with the prevalence of type 1 syllables. “Prevalence of 1” is <italic>n</italic><sub>1</sub>/(<italic>n</italic><sub>0</sub> + <italic>n</italic><sub>1</sub>), where <italic>n<sub>i</sub></italic> is the number of syllables of type <italic>i;</italic> prevalence of transition <italic>g</italic>→1 is calculated as <italic>n<sub>g</sub></italic><sub>→1</sub>/(<italic>n<sub>g</sub></italic><sub>→0</sub> + <italic>n<sub>g</sub></italic><sub>→1</sub>), where <italic>n<sub>i</sub></italic><sub>→<italic>j</italic></sub> is the number of observed transitions from state <italic>i</italic> to state <italic>j</italic> (<italic>g</italic> = gap); and prevalence of 1→1 is <italic>n</italic><sub>1→1</sub>/(<italic>n</italic><sub>0→1</sub> + <italic>n</italic><sub>1→1</sub>). Each point represents the results from a single trial, of 81 qualifying trials (see text).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030386.g007" xlink:type="simple"/>
        </fig>
        <p>We then examined the prevalence of all possible three-syllable combinations (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>) in terms of these two models. As shown in <xref ref-type="fig" rid="pbio-0030386-g007">Figure 7</xref>B, the first model, based purely on prevalence, does a poor job of predicting the distribution of three-syllable combinations (<italic>p &lt;&lt;</italic> 10<sup>−10</sup>). The transition-probability model provides a much more accurate description of the temporal structure. However, it, too, is insufficient (<italic>p ≈</italic> 10<sup>−6</sup>) to capture all of the higher-order structure of these three-syllable sequences. Similar conclusions apply to four- and five-syllable sequences.</p>
        <p>Therefore, we find that syllables are not chosen independently in random order. From examples of raw sonograms (see <xref ref-type="fig" rid="pbio-0030386-g001">Figure 1</xref>), it appears that type 1 syllables (those with low jumps) tend to be grouped in blocks. To examine this aspect of sequencing, we compared the prevalence of type 1 syllables against the likelihood that the next syllable after a type 1 would also be a type 1. For the example in <xref ref-type="fig" rid="pbio-0030386-g007">Figure 7B,</xref> 258/750 (34%) of syllables were of type 1, but the likelihood of a successive type 1 was much higher (58%). On the basis of counting statistics (binomial distribution), this difference is highly significant (<italic>p &lt;&lt;</italic> 10<sup>−10</sup>).</p>
        <p>To determine whether this tendency to repeat low-jump syllables is a universal feature of these vocalizations, we recorded the vocalizations of 45 socially experienced males over a period of 3 wk. Over the 3 wk, each animal participated in nine trials, each 210 s in duration, during which the male was presented with either a blank (non-odorized) cotton swab or one with 20 μl of dilute mouse urine (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). Of the more than 400 trials, 81 (from a total of 32 different males) contained ten or more examples each of type 0 and 1 syllables, and were tagged as “qualifying trials.” These qualifying trials contained sufficient numbers of each syllable type to allow measurement of the syllable prevalence and transition probabilities. We consistently found that type 1 syllables were more likely following another type 1 (<xref ref-type="fig" rid="pbio-0030386-g007">Figure 7</xref>C): in 78/81 qualifying trials, type 1 syllables were more likely following another type 1 than would have been predicted from their overall prevalence. This demonstrates a strong tendency for male mice to utter low-jump syllables in blocks.</p>
        <p>Similarly, we found that type 1 syllables were very unlikely to be used at the beginning of a phrase: after a gap, the likelihood of a type 1 syllable was lower (in 78/81 trials) than would have been predicted from chance selection of syllable types (<xref ref-type="fig" rid="pbio-0030386-g007">Figure 7</xref>C). A related phenomenon is seen in zebra finch song, in which phrases often begin with an “introductory note” [<xref ref-type="bibr" rid="pbio-0030386-b25">25</xref>].</p>
        <p>We conclude that these vocalizations display strong temporal regularities. Therefore, mouse ultrasonic vocalizations contain the two elements most commonly used to define song [<xref ref-type="bibr" rid="pbio-0030386-b01">1</xref>,<xref ref-type="bibr" rid="pbio-0030386-b03">3</xref>,<xref ref-type="bibr" rid="pbio-0030386-b13">13</xref>]: the vocalizations contain multiple syllable types, and these syllables are uttered in regular, repeated temporal sequences. We therefore label these vocalizations as songs.</p>
      </sec>
      <sec id="s2g">
        <title>The Songs of Individual Males</title>
        <p>In many songbirds, individual males produce a characteristic song, which in the case of oscine songbirds is learned from a tutor. To determine whether individual male mice produce stereotyped songs, we recorded the songs of 45 males over a period of 3 wk. Seven of the 45 mice had four or more “qualifying trials” (see above) with enough syllabic diversity to permit analysis.</p>
        <p>As shown in <xref ref-type="fig" rid="pbio-0030386-g008">Figure 8</xref>A, individual mice displayed tendencies to use particular syllable types. For example, mouse 2 tended to utter an abundance of “du” syllables, whereas mouse 3 used a larger number of “h” syllables. To determine whether these tendencies were sufficiently reliable to characterize the song of individual males, we again used isomap to generate a graphical representation of the syllable selection probability across mice and trials (see <xref ref-type="fig" rid="pbio-0030386-g008">Figure 8</xref>B and <xref ref-type="sec" rid="s4">Materials and Methods</xref>). Importantly, the isomap analysis was blind to the singer's identity, so that any differences between mice were a feature discovered by, rather than imposed upon, this analysis. As shown in <xref ref-type="fig" rid="pbio-0030386-g008">Figure 8</xref>B, the choice of syllable types was fairly consistent over the 3-wk period among trials from an individual. With a single exception (the mouse labeled by cyan stars), trials from a given mouse tended to occupy one of the three arms, or the center, of this distribution. This tendency to cluster is corroborated by the fact that the mean “distance” (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>) between trials from a particular mouse (1.7 ± 0.1%, mean ± standard error of the mean) was significantly smaller than the mean distance between trials from different mice (2.09 ± 0.04%, <italic>p</italic> &lt; 0.001, one-sided <italic>t</italic>-test). In a two-alternative forced-choice experiment, individuals could typically be recognized by their song on the basis of a single trial.</p>
        <fig id="pbio-0030386-g008" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030386.g008</object-id>
          <label>Figure 8</label>
          <caption>
            <title>Regularities in the Songs of Individual Mice</title>
            <p>All seven mice with four or more qualifying trials (see text) are analyzed.</p>
            <p>(A) Syllable usage for three of the more common syllable types for three different mice. Error bars represent the standard error of the mean across trials.</p>
            <p>(B) Patterns of syllable usage on individual trials across mice. Each point corresponds to a single trial, where the trials from a particular mouse are marked with a consistent color and marker. For mice 1–3, colors are consistent between (A) and (B). Placement of points in the plane reflects the pairwise “distance” between trials, where that distance measures the overall differences in percentage of each syllable type (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). Projection into two dimensions was performed by isomap.</p>
            <p>(C) Temporal regularities in song structure. Transition probabilities for all qualifying trials grouped by mouse.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030386.g008" xlink:type="simple"/>
        </fig>
        <p>To determine whether these individual differences extend to the temporal domain, we calculated the syllable transition probabilities <italic>p</italic><sub>0→1</sub> and <italic>p</italic><sub>1→0</sub> from the observed sequence of syllables. For these seven males, the transition probabilities for all qualifying trials are plotted in <xref ref-type="fig" rid="pbio-0030386-g008">Figure 8</xref>. Inspection suggests that the spread in values for a single male is smaller than the spread for the population as a whole. To determine whether this effect is significant, we analyzed the spread of transition-probability values across trials using a bootstrap analysis, comparing the spread in the true dataset to simulated datasets in which the singer's identity was scrambled across trials (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). The average spread using the correct identities was significantly (<italic>p</italic> = 0.02, 10,000 bootstraps) less than the spread for scrambled datasets. Therefore, we conclude that individual males also have characteristic temporal structure to their songs: across males, the differences in temporal structure are larger than the variability across trials by a single male.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>This study reveals that the ultrasonic vocalizations of the mouse have the characteristics of song. Qualitatively, this is apparent directly from playback of pitch-shifted audio recordings; we have also provided quantitative evidence for the usage of distinct syllable types arranged in nonrandom, repeated temporal sequences. These songs satisfy Broughton's <italic>sensu stricto</italic> definition of song [<xref ref-type="bibr" rid="pbio-0030386-b13">13</xref>], as well as many aspects of his <italic>sensu strictissimo</italic> (see <xref ref-type="fig" rid="pbio-0030386-g006">Figure 6</xref>). While courtship songs are common among birds, insects, and frogs, song has only rarely been documented in mammals, and to our knowledge only in humans, whales, and bats [<xref ref-type="bibr" rid="pbio-0030386-b03">3</xref>,<xref ref-type="bibr" rid="pbio-0030386-b04">4</xref>]. However, some rodent species display a variety of calls [<xref ref-type="bibr" rid="pbio-0030386-b26">26</xref>] and at least one other, the rat <italic>Dactylomys dactylilnus,</italic> utters long sequences of vocalizations that contain some syllabic diversity [<xref ref-type="bibr" rid="pbio-0030386-b27">27</xref>]. More generally, a number of Central and South American rodent species display complex vocalization (L. H. Emmons, personal communication), but none has been characterized in detail. However, it seems likely that song is more widely distributed than we currently appreciate. While the neural and motor mechanisms used to produce song and other communication sounds vary across species, recent work has indicated some commonality at the molecular level: the Foxp2 transcription factor, expressed in the brain of zebra finches during vocal learning [<xref ref-type="bibr" rid="pbio-0030386-b28">28</xref>], seems to be required both for mouse ultrasonic vocalization [<xref ref-type="bibr" rid="pbio-0030386-b29">29</xref>] and normal human speech [<xref ref-type="bibr" rid="pbio-0030386-b30">30</xref>].</p>
      <p>Subjectively, mouse song has a diversity and complexity that exceeds that of most insect and amphibian advertisement songs, which often contain only a single syllable type [<xref ref-type="bibr" rid="pbio-0030386-b01">1</xref>], perhaps modulated in amplitude and cadence [<xref ref-type="bibr" rid="pbio-0030386-b31">31</xref>]. At the syllable level, diversity in mouse song comes in two forms, discrete and continuous. Discrete categories of syllables exist, as evidenced by the appearance of distinct clusters, by two criteria: in terms of the sequence of stereotyped frequency jumps (see <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>), and by a comparison of the pitch waveforms of individual syllables (see <xref ref-type="fig" rid="pbio-0030386-g004">Figure 4</xref>). Within syllable types, there also exists considerable continuous variability (see <xref ref-type="fig" rid="pbio-0030386-g005">Figures 5</xref> and <xref ref-type="fig" rid="pbio-0030386-g006">6</xref>A). Because of our adoption of a strict quantitative classification of types, we have not used this continuous variability to define subtypes. This does not, however, argue that additional types are not present, merely that our analysis does not yet support further subdivision of types. Our quantitative classification scheme may be stricter than that employed in some analyses. A comparison of both subjective and quantitative classification has been carried out for the song of swamp sparrows: subjective methods [<xref ref-type="bibr" rid="pbio-0030386-b32">32</xref>] were used to classify notes into either 96 subtypes (which they termed the “splitter's classification”), or into six major categories (termed the “lumper's classification”). A later quantitative analysis carried out by the same laboratory, using techniques related to those employed here, found that notes clustered in general agreement with the major categories identified in the “lumper's classification,” with no evidence for further subdivision [<xref ref-type="bibr" rid="pbio-0030386-b21">21</xref>].</p>
      <p>The richness and complexity of mouse song appear to approach that of many songbirds. For example, in the zebra finch, a widely used model organism for studying song production, individuals have a number (3–7) of syllable types [<xref ref-type="bibr" rid="pbio-0030386-b25">25</xref>,<xref ref-type="bibr" rid="pbio-0030386-b33">33</xref>] similar to the number of common types we find in mice (<xref ref-type="table" rid="pbio-0030386-t001">Table 1</xref>). There are other species, for example, canaries, whose vocal repertoire would appear to exceed that of mice [<xref ref-type="bibr" rid="pbio-0030386-b34">34</xref>]. Both mice (see <xref ref-type="fig" rid="pbio-0030386-g006">Figure 6</xref>) and birds [<xref ref-type="bibr" rid="pbio-0030386-b25">25</xref>,<xref ref-type="bibr" rid="pbio-0030386-b33">33</xref>] exhibit regular temporal structure in their songs, including the production of repeated themes with sharp transitions between syllable types. However, mice also exhibit more gradual changes in syllable structure (see <xref ref-type="fig" rid="pbio-0030386-g001">Figure 1</xref>). Overall, the tendency to repeat a syllable, with sharp transitions between types, appears to be stronger in some birds [<xref ref-type="bibr" rid="pbio-0030386-b34">34</xref>] and whales [<xref ref-type="bibr" rid="pbio-0030386-b03">3</xref>] than in mice. However, in birds these sharp transitions are a feature of the adult “crystallized” song; juvenile or isolation-reared birds are more experimental and less predictable in terms of the temporal structure of their song [<xref ref-type="bibr" rid="pbio-0030386-b33">33</xref>,<xref ref-type="bibr" rid="pbio-0030386-b35">35</xref>]. Indeed, our pitch-shifted recordings of mouse song sound similar to the early “plastic” song of species such as swamp sparrows (<xref ref-type="supplementary-material" rid="sa005">Audio S5</xref>). For this reason, any comparison between birds and mice should consider the development of mouse song over the lifetime of the animal. Such a study has been undertaken for properties like mean pitch and cadence over the first 2 wk of life [<xref ref-type="bibr" rid="pbio-0030386-b12">12</xref>], but is lacking for the more complex features that compose song.</p>
      <p>Because mouse songs are ultrasonic and therefore inaudible to human ears, it is worth noting that laboratory domestication has probably not acted to preserve the full richness of mouse song through generations inbreeding. One study documented considerable variability in the amount of vocalization by different laboratory strains [<xref ref-type="bibr" rid="pbio-0030386-b36">36</xref>]. In contrast, domesticated bird populations have been subject to song selection, and indeed sub-strains such as the Waterschlager canary have been bred for particular vocal qualities. It therefore seems possible that wild mice might exhibit considerably greater diversity and/or more complex structure in their songs. Future comparisons between the songs of mice and birds may benefit from using wild mice.</p>
      <p>A final question is whether mice, like birds, learn their songs through experience. The fact that different males have characteristic syllable usage and temporal structure to their songs (see <xref ref-type="fig" rid="pbio-0030386-g008">Figure 8</xref>) is evidence for individual variability in song. Directly testing the role of experience will require that the auditory environment during development be explicitly controlled.</p>
      <p>In sum, we have demonstrated that the ultrasonic vocalizations of mice are songs, containing different syllable types sequenced in regular temporal patterns. Different individuals sing recognizably different songs. These results open new possibilities for molecular and physiological studies of the production and perception of song in a well-studied laboratory organism.</p>
    </sec>
    <sec id="s4">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>Signal acquisition and testing environment</title>
        <p>Sounds were recorded with a microphone and amplifier (1/4” microphone, model 4939, Brüel and Kjær, Nærum, Denmark) with flat frequency response out to 100 kHz and diminishing sensitivity at higher frequencies. Sounds were digitized at 250 kHz, 16 bits (National Instruments, Austin, Texas, United States) and captured to disk within a custom MATLAB-based program. To attenuate environmental noise, trials were conducted in a wooden enclosure with a transparent Plexiglas front. A slow stream of fresh air flowed through each chamber.</p>
      </sec>
      <sec id="s4b">
        <title>Experimental design</title>
        <p>Four-week-old males of the B6D2F1 strain (an F1 cross between C57Bl/6 and DBA2/J) were purchased from Jackson Laboratory (Bar Harbor, Maine, United States). Mice were kept on a 12 h/12 h light/dark cycle and were individually housed starting at 8 wk. Trials were conducted in April and May when the animals were at least 100 d old. Males were given two 3-min social experiences per day for 4 d, one to a BALB/c female and one to a BALB/c castrated male painted with 50 μl of 0.316× intact BALB/c male mouse urine [<xref ref-type="bibr" rid="pbio-0030386-b11">11</xref>]. The order of female/male social experiences was balanced across days.</p>
        <p>Animals were acclimatized to the testing environment with three 12–15 min episodes in the testing chamber. A given male was then tested 1 d/wk over a period of 3 wk. A day's test consisted of 15 min of acclimatization followed by three 210-s trials: presentation of an odorized (20-μl drop of mouse urine, see below) swab, presentation of a non-odorized (blank) swab, and presentation of a second odorized swab. For a given mouse, the gap between trials was typically approximately 20 min. Swabs were introduced through a hole in the lid of the enclosure at 30 s into the trial; they were removed immediately after the end of a trial.</p>
        <p>Urine stimuli used to trigger vocalizations were either 0.316× male mouse urine, 0.316× female mouse urine, or any of nine different mixtures of male and female mouse urine, where the concentration of each component was one of 0.316×, 0.1×, or 0.0316×. The correlation between stimulus identity and vocal response will be reported separately.</p>
      </sec>
      <sec id="s4c">
        <title>Data analysis</title>
        <p>Stored acoustical waveforms were processed in MATLAB to compute the sonogram (512 samples/block, half-overlap, resulting in a time resolution of 1.02 ms and a frequency resolution of 0.98 kHz). Sonograms were thresholded to eliminate the white noise component of the signal, frequencies outside 25–110 kHz were truncated, and the resulting sonograms were stored to disk as sparse complex matrices. This procedure greatly reduced the storage and processing requirements for later analysis, and also eliminated hiss when playing back reconstructed acoustical waveforms.</p>
        <p>Syllables were identified by computing three time-varying parameters from the sparse sonograms: the mean frequency, the “spectral purity” (fraction of total power concentrated into a single frequency bin), and the “spectral discontinuity,” which is computed in the following manner: if <italic>p<sub>i</sub></italic>(<italic>f<sub>j</sub></italic>)
					 is the normalized power as a function of frequency <italic>f<sub>i</sub></italic> in the <italic>i</italic>th time bin, then the spectral discontinuity δ<italic><sub>i</sub></italic> between two neighboring time bins is
				</p>
        <p>
					<disp-formula id="pbio-0030386-e001"><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030386.e001" xlink:type="simple"/><!-- <mml:math xmlns:mml="<ext-link ext-link-type="uri" xlink:href="http://www.w3.org/1998/Math/MathML"">http://www.w3.org/1998/Math/MathML"</ext-link> xmlns:xlink="<ext-link ext-link-type="uri" xlink:href="http://www.w3.org/1999/xlink"">http://www.w3.org/1999/xlink"</ext-link> DISPLAY="block" OVERFLOW="scroll">
							<mml:mrow>
								<mml:msub>
									<mml:mi>&delta;</mml:mi>
									<mml:mi>i</mml:mi>
								</mml:msub>
								<mml:mo>=</mml:mo>
								<mml:munder>
									<mml:mrow>
										<mml:mtext>min</mml:mtext>
									</mml:mrow>
									<mml:mrow>
										<mml:mi>&Delta;</mml:mi>
										<mml:mi>j</mml:mi>
									</mml:mrow>
								</mml:munder>
								<mml:mstyle DISPLAYSTYLE="true">
									<mml:munder>
										<mml:mo>&sum;</mml:mo>
										<mml:mi>j</mml:mi>
									</mml:munder>
								</mml:mstyle>
								<mml:mtext>&thinsp;</mml:mtext>
								<mml:mo>|</mml:mo>
								<mml:msub>
									<mml:mstyle DISPLAYSTYLE="true">
										<mml:mover ACCENT="true">
											<mml:mi>p</mml:mi>
											<mml:mo>^</mml:mo>
										</mml:mover>
									</mml:mstyle>
									<mml:mrow>
										<mml:mi>i</mml:mi>
										<mml:mo>+</mml:mo>
										<mml:mn>1</mml:mn>
									</mml:mrow>
								</mml:msub>
								<mml:mo STRETCHY="false">(</mml:mo>
								<mml:msub>
									<mml:mi>f</mml:mi>
									<mml:mrow>
										<mml:mi>j</mml:mi>
										<mml:mo>+</mml:mo>
										<mml:mi>&Delta;</mml:mi>
										<mml:mi>j</mml:mi>
									</mml:mrow>
								</mml:msub>
								<mml:mo STRETCHY="false">)</mml:mo>
								<mml:mo>&minus;</mml:mo>
								<mml:msub>
									<mml:mstyle DISPLAYSTYLE="true">
										<mml:mover ACCENT="true">
											<mml:mi>p</mml:mi>
											<mml:mo>^</mml:mo>
										</mml:mover>
									</mml:mstyle>
									<mml:mi>i</mml:mi>
								</mml:msub>
								<mml:mo STRETCHY="false">(</mml:mo>
								<mml:msub>
									<mml:mi>f</mml:mi>
									<mml:mi>j</mml:mi>
								</mml:msub>
								<mml:mo STRETCHY="false">)</mml:mo>
								<mml:mo>|</mml:mo>
								<mml:mo>.</mml:mo>
							</mml:mrow>
						</mml:math> --></disp-formula>
				</p>
        <p>Essentially, δ measures the change in the allocation of power across frequencies between two adjacent time bins; to accommodate the fact that syllables involve rapid sweeps in frequency, we permit a slight shift in frequency (Δ<italic>j</italic> up to three bins in either direction, almost 3 kHz) to maximize the alignment between adjacent time bins. Note that because <italic>p̂</italic>
					 is normalized, 0 ≤ δ<italic><sub>i</sub></italic> ≤ 2.
				</p>
        <p>These three parameters were median-filtered over 10 ms, and syllables were identified as periods longer than 5 ms in which mean frequency exceeded 35 kHz, spectral purity exceeded 0.25, and δ was less than one. Because faint syllables were occasionally interrupted by brief periods of dropout when the power approached the noise level, candidate syllables separated by less than 30 ms were merged.</p>
        <p>The performance of this algorithm was compared with human inspection on 50 randomly selected 210-s trials. The algorithm successfully identified the vast majority (&gt;95%) of human-identified syllables, with systematic omission occurring only on the faintest and briefest syllables. False positives were encountered so rarely (two clear examples in 10,500 s of recording) that it was difficult to estimate their frequency, but they were clearly rarer than true syllables by several orders of magnitude. The algorithm also identified numerous vocalizations that were initially missed by a human observer, but which proved upon closer inspection to be correctly identified (verified graphically and by audible playback). The algorithm also identified the timing of the beginning and end of each syllable with high accuracy; occasional discrepancies with a human observer arose from interfering sounds or when the beginning or end of the syllable was unusually faint.</p>
        <p>Pitch was defined as the dominant frequency as a function of time, discarding periods of dropout. Note that pitch was occasionally corrupted by other noises, contributing particularly to background “hash” in <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>. The criteria used to define the three pitch jump types “d,” “u,” and “h” are illustrated in <xref ref-type="fig" rid="pbio-0030386-g002">Figure 2</xref>C.</p>
        <p>Alignment of pairs of pitch waveforms (see <xref ref-type="fig" rid="pbio-0030386-g004">Figure 4</xref>) was performed by dynamic time warping [<xref ref-type="bibr" rid="pbio-0030386-b22">22</xref>]. The distance between any two pitch waveforms was defined as the root mean squared distance between the aligned waveforms. The isomap analysis of pitch waveforms used a neighborhood distance criterion of 3 kHz; in <xref ref-type="fig" rid="pbio-0030386-g004">Figure 4</xref> and other such figures, only the largest connected component is shown.</p>
        <p>In fitting SSs to a sine wave (see <xref ref-type="fig" rid="pbio-0030386-g005">Figure 5</xref>), the sine wave was described in terms of the following parameters: <inline-formula id="pbio-0030386-x001"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0030386.x001" xlink:type="simple"/></inline-formula>
					, where φ<sub>0</sub> is the starting phase, <italic>f</italic> is the rate of oscillation, <italic>ȳ</italic>
					 is the center frequency, and <italic>A</italic> is the pitch sine amplitude. The total duration of the syllable, <italic>T,</italic> defines the ending phase φ<sub>end</sub> by φ<sub>end</sub> = 2π<italic>ft</italic> + φ<sub>0</sub>.
				</p>
        <p>In analyzing the temporal structure of mouse songs (see <xref ref-type="fig" rid="pbio-0030386-g007">Figure 7</xref>), the prevalence of a syllable type was defined as follows: if <italic>n</italic><sub>0</sub> and <italic>n</italic><sub>1</sub> are the numbers of type 0 and type 1 syllables, respectively, then the prevalence of type 0 (within that trial) is defined as <italic>p</italic><sub>0</sub> = <italic>n</italic><sub>0</sub>/(<italic>n</italic><sub>0</sub> + <italic>n</italic><sub>1</sub>)
					. The prevalences of other types are defined similarly. The prevalence of a particular transition, for example, <italic>p</italic><sub>1→1</sub>, is defined analogously in terms of the numbers of each transition type <italic>n</italic><sub>1→0</sub> and <italic>n</italic><sub>1→1</sub> observed during the trial. In <xref ref-type="fig" rid="pbio-0030386-g007">Figure 7</xref>B, sequences interrupted by a gap were discarded. The expected number of a given three-syllable combination “abc” was calculated as <italic>Np<sub>a</sub>p<sub>b</sub>p<sub>c</sub></italic> for the “syllable prevalence” model, and as <italic>Np<sub>a</sub>p<sub>a</sub></italic><sub>→<italic>b</italic></sub><italic>p<sub>b</sub></italic><sub>→<italic>c</italic></sub> for the transition-probability model, where <italic>N</italic> is the total number of three-syllable combinations.
				</p>
        <p>The analysis of syllable usage across mice (see <xref ref-type="fig" rid="pbio-0030386-g008">Figure 8</xref>B) defined the distance between trials in terms of the differences in percentage utilization of each syllable type. More precisely, if <italic>p<sub>i</sub></italic><sub>1</sub> is the fraction of syllables of type <italic>i</italic> used in trial 1, and <italic>p<sub>i</sub></italic><sub>2</sub> is the fraction of the same syllable type in trial 2, then <italic>d</italic><sub>12</sub> = 〈|<italic>p<sub>i</sub></italic><sub>1</sub> − <italic>p<sub>i</sub></italic><sub>2</sub>|〉<italic><sub>i</sub></italic>. The pairwise distances were used to project into two dimensions using isomap, much as schematized for pitch waveforms in <xref ref-type="fig" rid="pbio-0030386-g004">Figure 4</xref>A (rightmost panel). The isomap analysis used a local neighborhood definition consisting of the five closest points; this criterion incorporated all trials into a single connected component.</p>
        <p>The bootstrap analysis of the spread in transition probabilities across individuals (see <xref ref-type="fig" rid="pbio-0030386-g008">Figure 8</xref>C) was performed as follows: starting from the median value (calculated separately for each condition, 0→1 or 1→0, and for each mouse), we calculated the absolute deviation for each trial. We then calculated the mean absolute deviation across all mice, conditions, and trials. We compared this mean deviation to the same quantity calculated from synthesized datasets in which the singers' identities were scrambled across trials.</p>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="sa001" mimetype="audio/wav" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0030386.sa001" xlink:type="simple">
        <label>Audio S1</label>
        <caption>
          <title>Slowed (16×) Playback of the 2-s Section Expanded in the Lower Panel of <xref ref-type="fig" rid="pbio-0030386-g001">Figure 1</xref></title>
          <p>(977 KB WAV).</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="sa002" mimetype="audio/wav" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0030386.sa002" xlink:type="simple">
        <label>Audio S2</label>
        <caption>
          <title>Pitch-Shifted (16×) Playback of the 2-s Section Expanded in the Lower Panel of <xref ref-type="fig" rid="pbio-0030386-g001">Figure 1</xref></title>
          <p>(61 KB WAV).</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="sa003" mimetype="audio/wav" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0030386.sa003" xlink:type="simple">
        <label>Audio S3</label>
        <caption>
          <title>Pitch-Shifted (16×) Playback of the Phrase in <xref ref-type="fig" rid="pbio-0030386-g006">Figure 6</xref>A</title>
          <p>(48 KB WAV).</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="sa004" mimetype="audio/wav" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0030386.sa004" xlink:type="simple">
        <label>Audio S4</label>
        <caption>
          <title>Pitch-Shifted (16×) Playback of a Longer Segment of Song</title>
          <p>The triply repeated phrase shown in <xref ref-type="fig" rid="pbio-0030386-g006">Figure 6</xref>B begins at 40 s into the recording.</p>
          <p>(1.6 MB WAV).</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="sa005" mimetype="audio/wav" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0030386.sa005" xlink:type="simple">
        <label>Audio S5</label>
        <caption>
          <title>Recording of Juvenile Swamp Sparrow Song</title>
          <p>For comparison between bird and mouse songs. Courtesy of Peter Marler.</p>
          <p>(2.4 MB WAV).</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>We are grateful to Markus Meister for encouraging these investigations, to Eric Dorner for his help in initiating these experiments, to Bence Ölveczky for drawing our attention to the fine-scale temporal structure of pitch jumps (see <xref ref-type="fig" rid="pbio-0030386-g003">Figure 3</xref>A), to Peter Marler for the swamp sparrow sound recording and helpful discussions, and to Louise Emmons and Robert Pless for helpful discussions. We thank Greg DeAngelis, Rebecca Hendrickson, Markus Meister, Bence Ölveczky, and the anonymous referees for comments on the manuscript. This work was supported by startup funds from Washington University School of Medicine, a grant from the National Institutes of Health (TEH, 5R01DC005964–02), and the Pew Scholars Program (TEH).</p>
    </ack>
    
    <ref-list>
      <title>References</title>
      <ref id="pbio-0030386-b01">
        <label>1</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="editor">
            <name name-style="western">
              <surname>Simmons</surname>
              <given-names>AM</given-names>
            </name>
            <name name-style="western">
              <surname>Popper</surname>
              <given-names>AN</given-names>
            </name>
            <name name-style="western">
              <surname>Fay</surname>
              <given-names>RR</given-names>
            </name>
          </person-group>
          <source>Acoustic communication. Volume 16, Springer handbook of auditory research</source>
          <year>2003</year>
          <publisher-loc>New York</publisher-loc>
          <publisher-name>Springer</publisher-name>
          <page-count count="404"/>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b02">
        <label>2</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="editor">
            <name name-style="western">
              <surname>Marler</surname>
              <given-names>P</given-names>
            </name>
            <name name-style="western">
              <surname>Slabbekoorn</surname>
              <given-names>H</given-names>
            </name>
          </person-group>
          <source>Nature's music: The science of birdsong</source>
          <year>2004</year>
          <publisher-loc>Boston</publisher-loc>
          <publisher-name>Elsevier</publisher-name>
          <page-count count="513"/>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b03">
        <label>3</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Payne</surname>
              <given-names>RS</given-names>
            </name>
            <name name-style="western">
              <surname>McVay</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Songs of humpback whales.</article-title>
          <source>Science</source>
          <year>1971</year>
          <volume>173</volume>
          <fpage>585</fpage>
          <lpage>597</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b04">
        <label>4</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Behr</surname>
              <given-names>O</given-names>
            </name>
            <name name-style="western">
              <surname>von Helversen</surname>
              <given-names>O</given-names>
            </name>
          </person-group>
          <article-title>Bat serenades—Complex courtship songs of the sac-winged bat <italic>Saccopteryx bilineata</italic>.</article-title>
          <source>Behav Ecol Sociobiol</source>
          <year>2004</year>
          <volume>56</volume>
          <fpage>106</fpage>
          <lpage>115</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b05">
        <label>5</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Whitney</surname>
              <given-names>G</given-names>
            </name>
            <name name-style="western">
              <surname>Nyby</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name name-style="western">
              <surname>Willott</surname>
              <given-names>JR</given-names>
            </name>
          </person-group>
          <article-title>Sound communication among adults.</article-title>
          <source>The auditory psychobiology of the mouse</source>
          <year>1983</year>
          <publisher-loc>Springfield (Illinois)</publisher-loc>
          <publisher-name>C. C. Thomas</publisher-name>
          <fpage>98</fpage>
          <lpage>129</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b06">
        <label>6</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Gourbal</surname>
              <given-names>BEF</given-names>
            </name>
            <name name-style="western">
              <surname>Barthelemy</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Petit</surname>
              <given-names>G</given-names>
            </name>
            <name name-style="western">
              <surname>Gabrion</surname>
              <given-names>C</given-names>
            </name>
          </person-group>
          <article-title>Spectrographic analysis of the ultrasonic vocalisations of adult male and female BALB/c mice.</article-title>
          <source>Naturwissenschaften</source>
          <year>2004</year>
          <volume>91</volume>
          <fpage>381</fpage>
          <lpage>385</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b07">
        <label>7</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Sales</surname>
              <given-names>GD</given-names>
            </name>
          </person-group>
          <article-title>Ultrasound and mating behavior in rodents with some observations on other behavioural situations.</article-title>
          <source>J Zool Lond</source>
          <year>1972</year>
          <volume>168</volume>
          <fpage>149</fpage>
          <lpage>164</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b08">
        <label>8</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Haack</surname>
              <given-names>B</given-names>
            </name>
            <name name-style="western">
              <surname>Markl</surname>
              <given-names>H</given-names>
            </name>
            <name name-style="western">
              <surname>Ehret</surname>
              <given-names>G</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name name-style="western">
              <surname>Willott</surname>
              <given-names>JF</given-names>
            </name>
          </person-group>
          <article-title>Sound communication between parents and offspring.</article-title>
          <source>The auditory psychobiology of the mouse</source>
          <year>1983</year>
          <publisher-loc>Springfield (Illinois)</publisher-loc>
          <publisher-name>C. C. Thomas</publisher-name>
          <fpage>57</fpage>
          <lpage>97</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b09">
        <label>9</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Wysocki</surname>
              <given-names>C</given-names>
            </name>
            <name name-style="western">
              <surname>Nyby</surname>
              <given-names>J</given-names>
            </name>
            <name name-style="western">
              <surname>Whitney</surname>
              <given-names>G</given-names>
            </name>
            <name name-style="western">
              <surname>Beauchamp</surname>
              <given-names>G</given-names>
            </name>
            <name name-style="western">
              <surname>Katz</surname>
              <given-names>Y</given-names>
            </name>
          </person-group>
          <article-title>The vomeronasal organ: Primary role in mouse chemosensory gender recognition.</article-title>
          <source>Physiol Behav</source>
          <year>1982</year>
          <volume>29</volume>
          <fpage>315</fpage>
          <lpage>327</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b10">
        <label>10</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Sipos</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Kerchner</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Nyby</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>An ephemeral sex pheromone in the urine of female house mice <italic>(Mus domesticus)</italic>.</article-title>
          <source>Behav Neural Biol</source>
          <year>1992</year>
          <volume>58</volume>
          <fpage>138</fpage>
          <lpage>143</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b11">
        <label>11</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Stowers</surname>
              <given-names>L</given-names>
            </name>
            <name name-style="western">
              <surname>Holy</surname>
              <given-names>T</given-names>
            </name>
            <name name-style="western">
              <surname>Meister</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Dulac</surname>
              <given-names>C</given-names>
            </name>
            <name name-style="western">
              <surname>Koentges</surname>
              <given-names>G</given-names>
            </name>
          </person-group>
          <article-title>Loss of sex discrimination and male-male aggression in mice deficient for TRP2.</article-title>
          <source>Science</source>
          <year>2002</year>
          <volume>295</volume>
          <fpage>1493</fpage>
          <lpage>1500</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b12">
        <label>12</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Liu</surname>
              <given-names>RC</given-names>
            </name>
            <name name-style="western">
              <surname>Miller</surname>
              <given-names>KD</given-names>
            </name>
            <name name-style="western">
              <surname>Merzenich</surname>
              <given-names>MM</given-names>
            </name>
            <name name-style="western">
              <surname>Schreiner</surname>
              <given-names>CE</given-names>
            </name>
          </person-group>
          <article-title>Acoustic variability and distinguishability among mouse ultrasound vocalizations.</article-title>
          <source>J Acoust Soc Am</source>
          <year>2003</year>
          <volume>114</volume>
          <fpage>3412</fpage>
          <lpage>3422</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b13">
        <label>13</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Broughton</surname>
              <given-names>WP</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name name-style="western">
              <surname>Burnel</surname>
              <given-names>RG</given-names>
            </name>
          </person-group>
          <article-title>[Glossary].</article-title>
          <source>Accoustic behavior of animals</source>
          <year>1963</year>
          <publisher-loc>Boston</publisher-loc>
          <publisher-name>Elsevier</publisher-name>
          <page-count count="883"/>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b14">
        <label>14</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Doupe</surname>
              <given-names>AJ</given-names>
            </name>
            <name name-style="western">
              <surname>Kuhl</surname>
              <given-names>PK</given-names>
            </name>
          </person-group>
          <article-title>Birdsong and human speech: Common themes and mechanisms.</article-title>
          <source>Annu Rev Neurosci</source>
          <year>1999</year>
          <volume>22</volume>
          <fpage>567</fpage>
          <lpage>631</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b15">
        <label>15</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Moulines</surname>
              <given-names>E</given-names>
            </name>
            <name name-style="western">
              <surname>Laroche</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Non-parametric techniques for pitch-scale and time-scale modification of speech.</article-title>
          <source>Speech Commun</source>
          <year>1995</year>
          <volume>16</volume>
          <fpage>175</fpage>
          <lpage>205</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b16">
        <label>16</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Roberts</surname>
              <given-names>L</given-names>
            </name>
          </person-group>
          <article-title>The rodent ultrasound production mechanism.</article-title>
          <source>Ultrasonics</source>
          <year>1975</year>
          <volume>13</volume>
          <fpage>83</fpage>
          <lpage>88</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b17">
        <label>17</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Fee</surname>
              <given-names>MS</given-names>
            </name>
            <name name-style="western">
              <surname>Shraiman</surname>
              <given-names>B</given-names>
            </name>
            <name name-style="western">
              <surname>Pesaran</surname>
              <given-names>B</given-names>
            </name>
            <name name-style="western">
              <surname>Mitra</surname>
              <given-names>PP</given-names>
            </name>
          </person-group>
          <article-title>The role of nonlinear dynamics of the syrinx in the vocalizations of a songbird.</article-title>
          <source>Nature</source>
          <year>1998</year>
          <volume>395</volume>
          <fpage>67</fpage>
          <lpage>71</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b18">
        <label>18</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Greenewalt</surname>
              <given-names>C</given-names>
            </name>
          </person-group>
          <source>Bird song: Acoustics and physiology</source>
          <year>1968</year>
          <publisher-loc>Washington (D. C.)</publisher-loc>
          <publisher-name>Smithsonian Institution Press</publisher-name>
          <page-count count="194"/>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b19">
        <label>19</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Suthers</surname>
              <given-names>RA</given-names>
            </name>
          </person-group>
          <article-title>Contributions to birdsong from the left and right sides of the intact syrinx.</article-title>
          <source>Nature</source>
          <year>1990</year>
          <volume>347</volume>
          <fpage>473</fpage>
          <lpage>477</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b20">
        <label>20</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Chanaud</surname>
              <given-names>RC</given-names>
            </name>
          </person-group>
          <article-title>Aerodynamic whistles.</article-title>
          <source>Sci Am</source>
          <year>1970</year>
          <volume>222</volume>
          <fpage>40</fpage>
          <lpage>46</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b21">
        <label>21</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Clark</surname>
              <given-names>CW</given-names>
            </name>
            <name name-style="western">
              <surname>Marler</surname>
              <given-names>P</given-names>
            </name>
            <name name-style="western">
              <surname>Beeman</surname>
              <given-names>K</given-names>
            </name>
          </person-group>
          <article-title>Quantitative analysis of animal vocal phonology: An application to swamp sparrow song.</article-title>
          <source>Ethology</source>
          <year>1987</year>
          <volume>76</volume>
          <fpage>101</fpage>
          <lpage>115</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b22">
        <label>22</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Rabiner</surname>
              <given-names>L</given-names>
            </name>
            <name name-style="western">
              <surname>Rosenberg</surname>
              <given-names>A</given-names>
            </name>
            <name name-style="western">
              <surname>Levinson</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Considerations in dynamic time warping algorithms for discrete word recognition.</article-title>
          <source>IEEE Trans Acoust</source>
          <year>1978</year>
          <volume>26</volume>
          <fpage>575</fpage>
          <lpage>582</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b23">
        <label>23</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Tenenbaum</surname>
              <given-names>JB</given-names>
            </name>
            <name name-style="western">
              <surname>de Silva</surname>
              <given-names>V</given-names>
            </name>
            <name name-style="western">
              <surname>Langford</surname>
              <given-names>JC</given-names>
            </name>
          </person-group>
          <article-title>A global geometric framework for nonlinear dimensionality reduction.</article-title>
          <source>Science</source>
          <year>2000</year>
          <volume>290</volume>
          <fpage>2319</fpage>
          <lpage>2323</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b24">
        <label>24</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Podos</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>A performance constraint on the evolution of trilled vocalizations in a songbird family (Passeriformes: Emberizidae).</article-title>
          <source>Evolution</source>
          <year>1997</year>
          <volume>51</volume>
          <fpage>537</fpage>
          <lpage>551</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b25">
        <label>25</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Price</surname>
              <given-names>PH</given-names>
            </name>
          </person-group>
          <article-title>Developmental determinants of structure in zebra finch song.</article-title>
          <source>J Comp Physiol Psychol</source>
          <year>1979</year>
          <volume>93</volume>
          <fpage>260</fpage>
          <lpage>277</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b26">
        <label>26</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Hafner</surname>
              <given-names>MS</given-names>
            </name>
            <name name-style="western">
              <surname>Hafner</surname>
              <given-names>DJ</given-names>
            </name>
          </person-group>
          <article-title>Vocalizations of grasshopper mice (genus <italic>Onychomys</italic>).</article-title>
          <source>J Mammol</source>
          <year>1979</year>
          <volume>60</volume>
          <fpage>85</fpage>
          <lpage>94</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b27">
        <label>27</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Emmons</surname>
              <given-names>LH</given-names>
            </name>
          </person-group>
          <article-title>Morphological, ecological, and behavioral adaptations for arboreal browsing in <italic>Dactylomys dactylinus</italic> (Rodentia, Echimyidae).</article-title>
          <source>J Mammal</source>
          <year>1981</year>
          <volume>62</volume>
          <fpage>183</fpage>
          <lpage>189</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b28">
        <label>28</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Haesler</surname>
              <given-names>S</given-names>
            </name>
            <name name-style="western">
              <surname>Wada</surname>
              <given-names>K</given-names>
            </name>
            <name name-style="western">
              <surname>Nshdejan</surname>
              <given-names>A</given-names>
            </name>
            <name name-style="western">
              <surname>Morrisey</surname>
              <given-names>EE</given-names>
            </name>
            <name name-style="western">
              <surname>Lints</surname>
              <given-names>T</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>FoxP2 expression in avian vocal learners and non-learners.</article-title>
          <source>J Neurosci</source>
          <year>2004</year>
          <volume>24</volume>
          <fpage>3164</fpage>
          <lpage>3175</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b29">
        <label>29</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Shu</surname>
              <given-names>W</given-names>
            </name>
            <name name-style="western">
              <surname>Cho</surname>
              <given-names>JY</given-names>
            </name>
            <name name-style="western">
              <surname>Jiang</surname>
              <given-names>Y</given-names>
            </name>
            <name name-style="western">
              <surname>Zhang</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Weisz</surname>
              <given-names>D</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Altered ultrasonic vocalization in mice with a disruption in the Foxp2 gene.</article-title>
          <source>Proc Natl Acad Sci U S A</source>
          <year>2005</year>
          <volume>102</volume>
          <fpage>9643</fpage>
          <lpage>9648</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b30">
        <label>30</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Lai</surname>
              <given-names>CS</given-names>
            </name>
            <name name-style="western">
              <surname>Fisher</surname>
              <given-names>SE</given-names>
            </name>
            <name name-style="western">
              <surname>Hurst</surname>
              <given-names>JA</given-names>
            </name>
            <name name-style="western">
              <surname>Vargha-Khadem</surname>
              <given-names>F</given-names>
            </name>
            <name name-style="western">
              <surname>Monaco</surname>
              <given-names>AP</given-names>
            </name>
          </person-group>
          <article-title>A forkhead-domain gene is mutated in a severe speech and language disorder.</article-title>
          <source>Nature</source>
          <year>2001</year>
          <volume>413</volume>
          <fpage>519</fpage>
          <lpage>523</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b31">
        <label>31</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Kelley</surname>
              <given-names>DB</given-names>
            </name>
            <name name-style="western">
              <surname>Tobias</surname>
              <given-names>ML</given-names>
            </name>
            <name name-style="western">
              <surname>Horng</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name name-style="western">
              <surname>Ryan</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>Producing and perceiving frog songs; dissecting the neural bases for vocal behaviors in <italic>Xenopus laevis</italic>.</article-title>
          <source>Anuran communication</source>
          <year>2001</year>
          <publisher-loc>Washington (D. C.)</publisher-loc>
          <publisher-name>Smithsonian Institution Press</publisher-name>
          <fpage>156</fpage>
          <lpage>166</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b32">
        <label>32</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Marler</surname>
              <given-names>P</given-names>
            </name>
            <name name-style="western">
              <surname>Pickert</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <article-title>Species-universal microstructure in the learned song of the swamp sparrow, <italic>Melospiza geogiana</italic>.</article-title>
          <source>Anim Behav</source>
          <year>1984</year>
          <volume>32</volume>
          <fpage>673</fpage>
          <lpage>689</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b33">
        <label>33</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Immelmann</surname>
              <given-names>K</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name name-style="western">
              <surname>Hinde</surname>
              <given-names>RA</given-names>
            </name>
          </person-group>
          <article-title>Song development in the zebra finch and other estrildid finches.</article-title>
          <source>Bird vocalizations: Their relations to current problems in biology and psychology</source>
          <year>1969</year>
          <publisher-loc>Cambridge</publisher-loc>
          <publisher-name>Cambridge University Press</publisher-name>
          <fpage>61</fpage>
          <lpage>74</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b34">
        <label>34</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Nottebohm</surname>
              <given-names>F</given-names>
            </name>
            <name name-style="western">
              <surname>Nottebohm</surname>
              <given-names>ME</given-names>
            </name>
            <name name-style="western">
              <surname>Crane</surname>
              <given-names>L</given-names>
            </name>
          </person-group>
          <article-title>Developmental and seasonal changes in canary song and their relation to changes in the anatomy of song-control nuclei.</article-title>
          <source>Behav Neural Biol</source>
          <year>1986</year>
          <volume>46</volume>
          <fpage>445</fpage>
          <lpage>471</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b35">
        <label>35</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Ölveczky</surname>
              <given-names>BP</given-names>
            </name>
            <name name-style="western">
              <surname>Andalman</surname>
              <given-names>AS</given-names>
            </name>
            <name name-style="western">
              <surname>Fee</surname>
              <given-names>MS</given-names>
            </name>
          </person-group>
          <article-title>Vocal experimentation in the juvenile songbird requires a basal ganglia circuit.</article-title>
          <source>PLoS Biol</source>
          <year>2005</year>
          <volume>3</volume>
          <fpage>e153</fpage>
          <comment>doi: <ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0030153" xlink:type="simple">10.1371/journal.pbio.0030153</ext-link></comment>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030386-b36">
        <label>36</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Maggio</surname>
              <given-names>J</given-names>
            </name>
            <name name-style="western">
              <surname>Whitney</surname>
              <given-names>G</given-names>
            </name>
          </person-group>
          <article-title>Ultrasonic vocalizing by adult female mice <italic>(Mus musculus)</italic>.</article-title>
          <source>J Comp Psychol</source>
          <year>1985</year>
          <volume>99</volume>
          <fpage>420</fpage>
          <lpage>436</lpage>
        </nlm-citation>
      </ref>
    </ref-list>
    <glossary>
      <title>Abbreviations</title>
      <def-list>
        <def-item>
          <term>“d,”</term>
          <def>
            <p>downward low jump</p>
          </def>
        </def-item>
        <def-item>
          <term>“h,”</term>
          <def>
            <p>high jump</p>
          </def>
        </def-item>
        <def-item>
          <term>SS</term>
          <def>
            <p>sinusoidal sweep</p>
          </def>
        </def-item>
        <def-item>
          <term>“u,”</term>
          <def>
            <p>upward low jump</p>
          </def>
        </def-item>
      </def-list>
    </glossary>
  </back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN"><front><journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="publisher">pcbi</journal-id><journal-id journal-id-type="allenpress-id">plcb</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1371/journal.pcbi.0030147</article-id><article-id pub-id-type="publisher-id">07-PLCB-RA-0021R2</article-id><article-id pub-id-type="sici">plcb-03-08-03</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology</subject></subj-group><subj-group subj-group-type="System Taxonomy"><subject>None</subject></subj-group></article-categories><title-group><article-title>Distributed Representations Accelerate Evolution of Adaptive Behaviours</article-title><alt-title alt-title-type="running-head">Accelerated Evolution</alt-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Stone</surname><given-names>James V</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>Psychology Department, Sheffield University, Sheffield, United Kingdom</addr-line></aff><contrib-group><contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>Karl J</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes><fn fn-type="con" id="ack1"><p>JVS conceived and designed the experiments, performed the experiments, analyzed the data, and wrote the paper.</p></fn><corresp id="cor1">* To whom correspondence should be addressed. E-mail: <email xlink:type="simple">j.v.stone@shef.ac.uk</email></corresp><fn fn-type="conflict" id="ack3"><p> The author has declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="ppub"><month>8</month><year>2007</year></pub-date><pub-date pub-type="epub"><day>3</day><month>8</month><year>2007</year></pub-date><pub-date pub-type="epreprint"><day>11</day><month>6</month><year>2007</year></pub-date><volume>3</volume><issue>8</issue><elocation-id>e147</elocation-id><history><date date-type="received"><day>15</day><month>1</month><year>2007</year></date><date date-type="accepted"><day>11</day><month>6</month><year>2007</year></date></history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2007</copyright-year><copyright-holder>James V. Stone</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><p>Animals with rudimentary innate abilities require substantial learning to transform those abilities into useful skills, where a skill can be considered as a set of sensory–motor associations. Using linear neural network models, it is proved that if skills are stored as distributed representations, then within-lifetime learning of part of a skill can induce automatic learning of the remaining parts of that skill. More importantly, it is shown that this “free-lunch” learning (FLL) is responsible for accelerated evolution of skills, when compared with networks which either 1) cannot benefit from FLL or 2) cannot learn. Specifically, it is shown that FLL accelerates the appearance of adaptive behaviour, both in its innate form and as FLL-induced behaviour, and that FLL can accelerate the rate at which learned behaviours become innate.</p></abstract><abstract abstract-type="summary"><title>Author Summary</title><sec id="st1"><title/><p>Some behaviours are purely innate (e.g., blinking), whereas other, “apparently innate,” behaviours require a degree of learning to refine them into a useful skill (e.g., nest building). In terms of biological fitness, it matters how quickly such learning occurs, because time spent learning is time spent not eating, or time spent being eaten, both of which reduce fitness. Using artificial neural networks as model organisms, it is proven that it is possible for an organism to be born with a set of “primed” connections which guarantee that learning part of a skill induces automatic learning of other skill components, an effect known as free-lunch learning (FLL). Critically, this effect depends on the assumption that associations are stored as distributed representations. Using a genetic algorithm, it is shown that primed organisms can evolve within 30 generations. This has three important consequences. First, primed organisms learn quickly, which increases their fitness. Second, the presence of FLL effectively accelerates the rate of evolution, for both learned and innate skill components. Third, FLL can accelerate the rate at which learned behaviours become innate. These findings suggest that species may depend on the presence of distributed representations to ensure rapid evolution of adaptive behaviours.</p></sec></abstract><funding-group><funding-statement>The author received no specific funding for this study.</funding-statement></funding-group><counts><page-count count="9"/></counts><!--===== Restructure custom-meta-wrap to custom-meta-group =====--><custom-meta-group><custom-meta><meta-name>citation</meta-name><meta-value>Stone JV (2007) Distributed representations accelerate evolution of adaptive behaviours. PLoS Comput Biol 3(7): e147. doi:<ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.0030147" xlink:type="simple">10.1371/journal.pcbi.0030147</ext-link></meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1"><title>Introduction</title><p>Both evolution and learning may be considered as different types of adaptation. Learning occurs within a lifetime, whereas genetic change occurs across lifetimes [<xref ref-type="bibr" rid="pcbi-0030147-b001">1</xref>]. Whereas genetic change ensures that a task can be executed innately, learning permits even the most rudimentary innate ability to be honed into a useful skill.</p><p>In an environment that fluctuates from generation to generation, learning permits an innate ability to be adapted to the particular physical environment into which each generation is born. If the environment ceases to fluctuate, then genetic assimilation [<xref ref-type="bibr" rid="pcbi-0030147-b002">2</xref>] can transform a rudimentary innate ability, which requires much learning, into an innate skill, which requires minimal learning. This transformation is more likely to occur if the cost of learning is high [<xref ref-type="bibr" rid="pcbi-0030147-b003">3</xref>,<xref ref-type="bibr" rid="pcbi-0030147-b004">4</xref>], and, in this case, computer simulations suggest that learning can accelerate the rate of genetic assimilation [<xref ref-type="bibr" rid="pcbi-0030147-b005">5</xref>] via the Baldwin effect [<xref ref-type="bibr" rid="pcbi-0030147-b006">6</xref>]. However, if learning is sufficiently inexpensive, then genetic change may not occur at all [<xref ref-type="bibr" rid="pcbi-0030147-b007">7</xref>,<xref ref-type="bibr" rid="pcbi-0030147-b008">8</xref>]. Overall, there appears to be a tradeoff between learning and genetic assimilation, such that learning can subsidize genetic change, especially if learning is inexpensive.</p><p>All but the most primitive organisms learn in order to survive, and organisms which learn quickly are at a selective advantage relative to those that learn slowly. Therefore, a mechanism which reduces the time required to learn a given behaviour confers a selective advantage. One candidate for such a mechanism is FLL [<xref ref-type="bibr" rid="pcbi-0030147-b009">9</xref>,<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>].</p><p>As explained below, FLL ensures that in the process of learning one set of associations or behaviours another set of associations is usually learned. These associations could comprise either perceptual skills (such as face recognition, predator recognition [<xref ref-type="bibr" rid="pcbi-0030147-b011">11</xref>], or prey recognition), or motor skills (such as catching prey, flying, seed pecking, or nest building).</p><sec id="s1a"><title>Free-Lunch Learning</title><p>Before considering how FLL can accelerate evolution of certain types of behaviours, FLL will be described in its original context of spontaneous recovery of memory in humans [<xref ref-type="bibr" rid="pcbi-0030147-b009">9</xref>] and in neural network models [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>]. Note that FLL is not unique to a specific class of network architectures, although it does assume that associations are learned using a form of supervised learning.</p><p>In humans, FLL has been demonstrated using a task in which participants learned the positions of letters on a nonstandard computer keyboard [<xref ref-type="bibr" rid="pcbi-0030147-b009">9</xref>]. After a period of forgetting, participants relearned a proportion of these letter positions. Crucially, it was found that this relearning induced recovery of the non-relearned letter positions.</p><p>More recently, a set of theorems provided a formal characterization of FLL in linear neural network models [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>]. In essence, FLL occurs in neural network models because each association is distributed amongst all connection weights (synapses) between units (model neurons). After partial forgetting, relearning some of the associations forces all of the weights closer to pre-forgetting values, resulting in improved performance even on non-relearned associations; a general proof is provided in [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>]. A geometric demonstration of FLL for a network with two connection weights is given in <xref ref-type="fig" rid="pcbi-0030147-g001">Figure 1</xref>. Networks with multiple input and output units can be considered without loss of generality [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>].</p><fig id="pcbi-0030147-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0030147.g001</object-id><label>Figure 1</label><caption><title>Geometry of Free-Lunch Learning</title><p>(A) Given a network with two input units and one output unit, its connection weights <italic>w<sub>a</sub></italic> and <italic>w<sub>b</sub></italic> define a weight vector <bold>w</bold> = (<italic>w<sub>a</sub></italic>,<italic>w<sub>b</sub></italic>). The network learns two subsets <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub>. In this example, each subset is a single association, where <italic>A</italic><sub>1</sub> (for example) is the mapping from input vector <bold>x</bold><sub>1</sub> = (<italic>x</italic><sub>11</sub>,<italic>x</italic><sub>12</sub>) to desired output value <italic>d</italic><sub>1</sub>, and learning <italic>A</italic><sub>1</sub> consists of adjusting <bold>w</bold> until the network output <italic>y</italic><sub>1</sub> = <bold>w</bold> · <bold>x</bold><sub>1</sub> equals <italic>d</italic><sub>1</sub>.</p><p>(B) Each association <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> defines a constraint line <italic>L</italic><sub>1</sub> and <italic>L</italic><sub>2</sub>, respectively. The intersection of <italic>L</italic><sub>1</sub> and <italic>L</italic><sub>1</sub> defines a point <bold>w</bold><sub>0</sub> which satisfies both constraints, so that zero performance error on <italic>A</italic> = <italic>A</italic><sub>1</sub> ∪ <italic>A</italic><sub>2</sub> is obtained if <bold>w</bold> = <bold>w</bold><sub>0</sub>. After partial forgetting, the weight vector is a randomly chosen point <bold>w</bold><sub>1</sub> on the circle <italic>C</italic> of radius <italic>r</italic>, and the performance error on <italic>A</italic><sub>1</sub> is given by the squared distance <italic>p</italic><sup>2</sup>. After relearning <italic>A</italic><sub>2</sub>, the weight vector <bold>w</bold><sub>2</sub> lies in <italic>L</italic><sub>2</sub>, and performance error on <italic>A</italic><sub>1</sub> is the squared distance <italic>q</italic><sup>2</sup>. FLL occurs if performance error on <italic>A</italic><sub>1</sub> is decreased by relearning <italic>A</italic><sub>2</sub>, or equivalently if <italic>p</italic><sup>2</sup> &gt; <italic>q</italic><sup>2</sup>. Relearning <italic>A</italic><sub>2</sub> has three possible effects, depending on the position of <bold>w</bold><sub>1</sub> on <italic>C</italic>: 1) if <bold>w</bold><sub>1</sub> is under the larger (dashed) arc <italic>C<sub>FLL</sub></italic> (as shown here), then <italic>p</italic><sup>2</sup> &gt; <italic>q</italic><sup>2</sup>; therefore, FLL is observed, 2) if <bold>w</bold><sub>1</sub> is under the smaller (dotted) arc, then <italic>p</italic><sup>2</sup> &lt; <italic>q</italic><sup>2</sup>; therefore, negative FLL is observed, and 3) if <bold>w</bold><sub>1</sub> is at the critical point <bold>w</bold><italic><sub>crit</sub></italic>, then <italic>p</italic><sup>2</sup> = <italic>q</italic><sup>2</sup>; therefore, no FLL is observed. Given that <bold>w</bold><sub>1</sub> is a randomly chosen point on the circle <italic>C</italic>, the probability of FLL is equal to the proportion of the upper semicircle under the (dashed) arc <italic>C<sub>FLL</sub></italic>. Symmetry implies the above analysis also applies to the lower half of <italic>C</italic>. In terms of evolution, a network “born” with <bold>w</bold> = <bold>w</bold><sup>*</sup> has zero error on both <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> after learning only <italic>A</italic><sub>2</sub> (see text).</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0030147.g001" xlink:type="simple"/></fig><p>The protocol used to examine FLL in neural networks is as follows (see <xref ref-type="fig" rid="pcbi-0030147-g002">Figure 2</xref>). A network with <italic>n</italic> input units and one output unit has <italic>n</italic> connection weights. This network learns a set <italic>A</italic> of <italic>m</italic> ≤ <italic>n</italic> associations, where <italic>A</italic> = <italic>A</italic><sub>1</sub> ∪ <italic>A</italic><sub>2</sub> comprises two subsets <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> of <italic>n</italic><sub>1</sub> and <italic>n</italic><sub>2</sub> associations, respectively (note that <italic>m</italic> = <italic>n</italic><sub>1</sub> + <italic>n</italic><sub>2</sub>). After the associations <italic>A</italic> have been learned and then partially forgotten, performance error on subset <italic>A</italic><sub>1</sub> is measured (forgetting is induced by adding isotropic noise to weights). Finally, <italic>only A</italic><sub>2</sub> is relearned, and then performance error on <italic>A</italic><sub>1</sub> is remeasured. FLL occurs if relearning <italic>A</italic><sub>2</sub> improves performance on <italic>A</italic><sub>1</sub>. It has been proven that the probability of FLL approaches unity as the number of weights increases [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>]. For the sake of brevity, this is reflected in phrases such as “learning <italic>A</italic><sub>2</sub> <italic>usually</italic> improves performance on <italic>A</italic><sub>2</sub>” in this paper.</p><fig id="pcbi-0030147-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0030147.g002</object-id><label>Figure 2</label><caption><title>Free-Lunch Learning within and across Generations</title><p>(A) FLL within the single lifetime of a neural network model. Two subsets of associations <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> are learned. After partial forgetting (see text), performance error on subset <italic>A</italic><sub>1</sub> is measured. Subset <italic>A</italic><sub>2</sub> is then relearned, and performance error on subset <italic>A</italic><sub>1</sub> is measured again. If performance error on <italic>A</italic><sub>1</sub> decreases as a result of learning <italic>A</italic><sub>2</sub>, then FLL has occurred.</p><p>(B) FLL across generations. Using a genetic algorithm, a network is born with connections similar to those of the network in <bold>a</bold> after it has learned and then partially forgotten subsets <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub>. Consequently, innate performance error on <italic>A</italic><sub>1</sub> is similar to that of the network in <bold>a</bold> after it has partially forgotten both subsets. After measuring performance error on <italic>A</italic><sub>1</sub> at birth, subset <italic>A</italic><sub>2</sub> is learned for the first time, and performance error on subset <italic>A</italic><sub>1</sub> is measured again. After many generations, the innate connection values of each network ensure that if subset <italic>A</italic><sub>2</sub> is learned <italic>for the first time,</italic> then this induces automatic learning of subset <italic>A</italic><sub>1</sub>.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0030147.g002" xlink:type="simple"/></fig></sec><sec id="s1b"><title>FLL and Evolution</title><p>Now consider an organism <italic>b</italic><sub>2</sub> which is born with a genetically specified set of neuronal connections [<xref ref-type="bibr" rid="pcbi-0030147-b012">12</xref>]. These connections are organised such that, if <italic>b</italic><sub>2</sub> learns one subset <italic>A</italic><sub>2</sub> of associations then another subset <italic>A</italic><sub>1</sub> is usually learned. In other words, <italic>the organism b</italic><sub>2</sub> <italic>happens to be born with neuronal connections similar to the connections of an organism b</italic><sub>1</sub> <italic>which had once learned and then forgotten subsets A</italic><sub>1</sub> <italic>and A</italic><sub>2</sub> (e.g., isotropically distributed around w<sub>0</sub> in <xref ref-type="fig" rid="pcbi-0030147-g001">Figure 1</xref>). Just as FLL ensures that if organism <italic>b</italic><sub>1</sub> relearns <italic>A</italic><sub>2</sub> then subset <italic>A</italic><sub>1</sub> is usually relearned (see <xref ref-type="fig" rid="pcbi-0030147-g002">Figure 2</xref>), so <italic>if b</italic><sub>2</sub> <italic>learns A</italic><sub>2</sub> <italic>then A</italic><sub>1</sub> <italic>is usually learned</italic>. In both cases, FLL ensures that learning one subset of associations induces learning of the other subset. Critically, whereas the FLL exhibited by organism <italic>b</italic><sub>1</sub> depends on previous learning and forgetting, FLL in organism <italic>b</italic><sub>2</sub> depends on being born in a state such that the first time <italic>A</italic><sub>2</sub> is learned, the associations <italic>A</italic><sub>1</sub> are also usually acquired. Such a network can be evolved using a genetic algorithm, as shown below.</p><p>The use of two distinct subsets in this paper is clearly unrealistic when considered in the context of skill learning. However, the use of two subsets lies at one extreme along a continuum of tasks. At one extreme, associations are learned one by one in a strict order, and at the other extreme, all associations are learned simultaneously. In a biological context, the components of a skill which are learned first act as “scaffold” for others, and this effectively imposes a temporal order to the acquisition of different skill components. This is the type of scenario assumed for the simulations reported in this paper. Essentially, learning <italic>A</italic><sub>2</sub> is assumed to consist of a subset of skill components which provide a scaffold for the skill components in <italic>A</italic><sub>1</sub>.</p></sec><sec id="s1c"><title>The Geometry of FLL</title><p>This section is a brief account of the basic geometry underlying FLL, in the absence of its interactions with evolution. For the present, and without loss of generality (see [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>]), we assume that the network has one output unit and two input units, which implies <italic>n</italic> = 2 connection weights, and that <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> each consist of <italic>n</italic><sub>1</sub> = <italic>n</italic><sub>2</sub> = 1 association, as in <xref ref-type="fig" rid="pcbi-0030147-g001">Figure 1</xref>. Input units are connected to the output unit via weights <italic>w<sub>a</sub></italic> and <italic>w<sub>b</sub></italic>, which define a weight vector <bold>w</bold> = (<italic>w<sub>a</sub></italic>,<italic>w<sub>b</sub></italic>). Associations <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> consist of different mappings from the input vectors <bold>x</bold><sub>1</sub> = (<italic>x</italic><sub>11</sub>,<italic>x</italic><sub>12</sub>) and <bold>x</bold><sub>2</sub> = (<italic>x</italic><sub>21</sub>,<italic>x</italic><sub>22</sub>) to desired output values <italic>d</italic><sub>1</sub> and <italic>d</italic><sub>2</sub>, respectively. If a network is presented with input vectors <bold>x</bold><sub>1</sub> and <bold>x</bold><sub>2</sub>, then its output values are <italic>y</italic><sub>1</sub> = <bold>w</bold> · <bold>x</bold><sub>1</sub> = <italic>w<sub>a</sub>x</italic><sub>11</sub> + <italic>w<sub>b</sub>x</italic><sub>12</sub> and <italic>y</italic><sub>2</sub> = <bold>w</bold> ·<bold> x</bold><sub>2</sub> = <italic>w<sub>a</sub>x</italic><sub>21</sub> + <italic>w<sub>b</sub>x</italic><sub>22</sub>, respectively. More generally, network performance error for <italic>k</italic> associations is defined as
					<disp-formula id="pcbi-0030147-e001"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030147.e001" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mstyle mathvariant='bold' mathsize='normal'><mml:mi>w</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy='false'>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math> --></disp-formula>
				</p><p>The weight vector <bold>w</bold> defines a point in the (<italic>w<sub>a</sub></italic>,<italic>w<sub>b</sub></italic>) plane. For an input vector <bold>x</bold><sub>1</sub>, there are many different combinations of weight values <italic>w<sub>a</sub></italic> and <italic>w<sub>b</sub></italic> that give the desired output <italic>d</italic><sub>1</sub>. These combinations lie on a straight line <italic>L</italic><sub>1</sub>, because the network output is a linear weighted sum of input values. A corresponding constraint line <italic>L</italic><sub>2</sub> exists for <italic>A</italic><sub>2</sub>. The intersection of <italic>L</italic><sub>1</sub> and <italic>L</italic><sub>2</sub> therefore defines the only point <bold>w</bold><sub>0</sub> that satisfies both constraints, so that zero error on <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> is obtained if and only if <bold>w</bold> = <bold>w</bold><sub>0</sub>. Without loss of generality, we define the origin <bold>w</bold><sub>0</sub> to be the intersection of <italic>L</italic><sub>1</sub> and <italic>L</italic><sub>2</sub>. A general prerequisite for FLL is that <italic>L</italic><sub>1</sub> is not orthogonal to <italic>L</italic><sub>2</sub>.</p><p>We now consider the geometric effect of partial forgetting of both associations, followed by relearning <italic>A</italic><sub>2</sub>. This geometric account applies to a network with two weights (see <xref ref-type="fig" rid="pcbi-0030147-g001">Figure 1</xref>), and depends on the following observation: if the length of the input vector <bold>x</bold><sub>1</sub> is unity, then the performance error <italic>E</italic>(<bold>w</bold>,<italic>A</italic><sub>1</sub>) = (<italic>d</italic><sub>1</sub> − <italic>y</italic><sub>1</sub>)<sup>2</sup> of a network with weight vector <bold>w</bold> when tested on association <italic>A</italic><sub>1</sub> is equal to the squared distance between <bold>w</bold> and the constraint line <italic>L</italic><sub>1</sub> [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>]. For example, if <bold>w</bold> is in <italic>L</italic><sub>1</sub>, then <italic>E</italic>(<bold>w</bold>,<italic>A</italic><sub>1</sub>) = 0, but as the distance between <bold>w</bold> and <italic>L</italic><sub>1</sub> increases so <italic>E</italic>(<bold>w</bold>,<italic>A</italic><sub>1</sub>) must increase. For the purposes of this geometric account, we assume the length of the input vectors is unity.</p><p>If partial forgetting is induced by adding isotropic noise <bold>g</bold> to the weight vector <bold>w</bold> = <bold>w</bold><sub>0</sub>, then this effectively moves <bold>w</bold> to a randomly chosen point <bold>w</bold><sub>1</sub> = <bold>w</bold><sub>0</sub> + <bold>g</bold> on the circle <italic>C</italic> of radius <italic>r</italic>, where <italic>r</italic> is the length of <bold>g</bold>, and represents the amount of forgetting. For a network with <bold>w</bold> = <bold>w</bold><sub>1</sub>, learning <italic>A</italic><sub>2</sub> moves <bold>w</bold> to the nearest point <bold>w</bold><sub>2</sub> on <italic>L</italic><sub>1</sub> [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>], so that <bold>w</bold><sub>2</sub> is the orthogonal projection of <bold>w</bold> on <italic>L</italic><sub>2</sub>. Before relearning <italic>A</italic><sub>2</sub>, the performance error <italic>E</italic>(<bold>w</bold>,<italic>A</italic><sub>1</sub>) on <italic>A</italic><sub>1</sub> is the squared distance <italic>p</italic><sup>2</sup> between <bold>w</bold><sub>1</sub> and its orthogonal projection on <italic>L</italic><sub>1</sub>. After relearning <italic>A</italic><sub>2</sub>, the performance error <italic>E<sub>post</sub></italic> is the squared distance <italic>q</italic><sup>2</sup> between <bold>w</bold><sub>2</sub> and its orthogonal projection on <italic>L</italic><sub>1</sub>. The amount of FLL is <italic>δ</italic> = E(<bold>w</bold><sub>1,</sub> <italic>A</italic><sub>1</sub>) − E(<bold>w</bold><sub>2,</sub> <italic>A</italic><sub>1</sub>), and (for a network with two weights) is also given by <italic>Q</italic> = <italic>p</italic><sup>2</sup> − <italic>q</italic><sup>2</sup>. The probability <italic>P</italic>(<italic>δ</italic> &gt; 0) of FLL given <italic>L</italic><sub>1</sub> and <italic>L</italic><sub>2</sub> is equal to the proportion of points on <italic>C</italic> for which <italic>δ</italic> &gt; 0 (or equivalently, for which <italic>Q</italic> &gt; 0). For example, it can be shown that the mean value of this proportion is <italic>P</italic>(<italic>δ</italic> &gt; 0) for a two-weight network like the one shown in <xref ref-type="fig" rid="pcbi-0030147-g001">Figure 1</xref>A. Given the particular configuration shown in <xref ref-type="fig" rid="pcbi-0030147-g001">Figure 1</xref>A, the critical point <bold>w</bold><italic><sub>crit</sub></italic> is defined such that the performance error before and after learning is the same (i.e., <italic>δ</italic> = 0).</p></sec><sec id="s1d"><title>FLL Induces Perfect Performance</title><p>Given a network with <italic>n</italic> weights <bold>w</bold> and two subsets <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> of <italic>n</italic><sub>1</sub> and <italic>n</italic><sub>2</sub> associations, respectively, it is shown that weights <bold>w</bold><sup>*</sup> exist such that learning associations <italic>A</italic><sub>2</sub> is guaranteed to yield zero performance error on <italic>A</italic><sub>1</sub>, provided <italic>n</italic> ≥ <italic>n</italic><sub>1</sub> + <italic>n</italic><sub>2</sub>.</p><p>Consider a network with <italic>n</italic> = 2 weights and subsets <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub>, each of which comprises a single association. Each association defines a constraint line <italic>L</italic><sub>1</sub> and <italic>L</italic><sub>2</sub>, respectively (see <xref ref-type="fig" rid="pcbi-0030147-g001">Figure 1</xref>). If the weight vector <bold>w</bold> is in <italic>L</italic><sub>1</sub>, then performance error on <italic>A</italic><sub>1</sub> is zero, and if <bold>w</bold> is in <italic>L</italic><sub>2</sub>, then performance error on <italic>A</italic><sub>2</sub> is zero. Clearly, if and only if <bold>w</bold> is at the intersection <bold>w</bold><sub>0</sub> of <italic>L</italic><sub>1</sub> and <italic>L</italic><sub>2</sub>, then performance error on both <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> is zero. If <bold>w</bold> is not in <italic>L</italic><sub>2</sub>, then learning <italic>A</italic><sub>2</sub> moves <bold>w</bold> from its current position to its orthogonal projection onto <italic>L</italic><sub>2</sub> [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>]. Crucially, if <bold>w</bold> = <bold>w</bold><sup>*</sup> in <xref ref-type="fig" rid="pcbi-0030147-g001">Figure 1</xref>, then learning <italic>A</italic><sub>2</sub> moves <bold>w</bold> to the optimal weight vector <bold>w</bold><sub>0</sub>. In this case, learning <italic>A</italic><sub>2</sub> reduces performance error to zero on both <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub>, and therefore learning <italic>A</italic><sub>2</sub> implies perfect performance on <italic>A</italic><sub>1</sub>.</p><p>This line of reasoning generalises to networks with more than two weights, as follows. If a network has more than two input units, then subsets <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> can have <italic>n</italic><sub>1</sub> &gt; 1 and <italic>n</italic><sub>2</sub> &gt; 1 associations. If <italic>n</italic> ≥ <italic>n</italic><sub>1</sub> + <italic>n</italic><sub>2</sub>, then <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> define an (<italic>n</italic> − <italic>n</italic><sub>1</sub>)-dimensional subspace <italic>L</italic><sub>1</sub> and an (<italic>n</italic> − <italic>n</italic><sub>2</sub>)-dimensional subspace <italic>L</italic><sub>2</sub>, respectively. The intersection <italic>L</italic><sub>12</sub> of <italic>L</italic><sub>1</sub> and <italic>L</italic><sub>2</sub> corresponds to weight vectors which generate zero error on <italic>A</italic> = <italic>A</italic><sub>1</sub> ∪ <italic>A</italic><sub>2</sub>. In this case, the circle in <xref ref-type="fig" rid="pcbi-0030147-g001">Figure 1</xref> corresponds to an <italic>n</italic>-dimensional hypersphere, with its centre <bold>w</bold><sub>0</sub> in <italic>L</italic><sub>12</sub>. Given that learning <italic>A</italic><sub>2</sub> provides an orthogonal projection of <bold>w</bold> onto <italic>L</italic><sub>2</sub>, and that there exists a <bold>w</bold> = <bold>w</bold><sup>*</sup> such that its orthogonal projection onto <italic>L</italic><sub>2</sub> is <bold>w</bold><sub>0</sub>, it follows that learning <italic>A</italic><sub>2</sub> in a network with <bold>w</bold> = <bold>w</bold><sup>*</sup> yields zero performance error on both <italic>A</italic><sub>2</sub> and <italic>A</italic><sub>1</sub>.</p><p>Given that the weight vector <bold>w</bold> is genetically specified with finite precision, a network is necessarily born with its weight vector <bold>w</bold> = <bold>w</bold><sub>1</sub> at a non-zero distance <italic>r</italic> from the optimal weight vector <bold>w</bold><sub>0</sub>. This finite precision defines a hypersphere <italic>C</italic> around <bold>w</bold><sub>0</sub>, and the location of <bold>w</bold><sub>1</sub> on <italic>C</italic> determines the amount of FLL. If a network is born with <bold>w</bold><sub>1</sub> = <bold>w</bold><sup>*</sup>, then learning <italic>A</italic><sub>2</sub> induces perfect performance on <italic>A</italic><sub>1</sub>. If fitness depends on performance on both <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> after learning only <italic>A</italic><sub>2</sub>, then there is selective pressure for networks to be born with weight vectors close to <bold>w</bold><sup>*</sup>, given a specific degree of genetic precision <italic>r</italic>. More generally, there is pressure for networks to be born with weight vectors close to the subspace with contains <bold>w</bold><sub>0</sub> and <bold>w</bold><sup>*</sup>.</p></sec><sec id="s1e"><title>Terminology: Evolution, Innateness, and FLL</title><p>As this paper deals with subtle combinations of evolution and learning, involving two distinct subsets of associations (<italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub>), it is important to be clear about terminology. Specifically, we need to be careful about which subset is being referred to, and whether we are referring to innate performance or not. Accordingly, performance error on <italic>A</italic><sub>1</sub> before learning <italic>A</italic><sub>2</sub> is called just that, “innate performance error on <italic>A</italic><sub>1</sub>.” Behaviours that are induced by learning <italic>A</italic><sub>2</sub> are called <italic>FLL-induced</italic> behaviours, because they are not innate, nor are they learned, so that performance error on <italic>A</italic><sub>1</sub> after learning <italic>A</italic><sub>2</sub> is called “FLL-induced performance error on <italic>A</italic><sub>1</sub>.” If learning <italic>A</italic><sub>2</sub> does not affect performance on <italic>A</italic><sub>1</sub> (as in condition NoFLL, below), then this is referred to as “post-learning performance.” More generally, performance will be quoted with a specified context (e.g., performance on <italic>A</italic><sub>1</sub> after learning <italic>A</italic><sub>2</sub>).</p></sec></sec><sec id="s2" sec-type="methods"><title>Methods</title><p>The effect of FLL on evolution was tested by measuring performance on <italic>A</italic><sub>1</sub> after learning <italic>A</italic><sub>2</sub> across generations. To eliminate the possibility that the observed results are artefacts, the effects of FLL were compared with two control conditions (described below).</p><p>Each generation consisted of 1,000 neural networks, each of which consisted of 20 input units and one output unit. The genome of each network was defined by a one-to-one mapping of the <italic>n</italic> = 20 weight values in the network to a single string of <italic>n</italic> genes, where the value of each gene was set to the value of a corresponding network weight. The number of offspring generated by each network was proportional to its fitness, which depended only on its ability to provide the correct desired output value for each of 20, <italic>n</italic>-element input vectors. The mapping from each input vector to its output value defines one association (see <xref ref-type="fig" rid="pcbi-0030147-g001">Figure 1</xref>).</p><p>A network's output <italic>y<sub>i</sub></italic> is a weighted sum of input values <inline-formula id="pcbi-0030147-ex001"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.0030147.ex001" xlink:type="simple"/></inline-formula>
				, where <italic>x<sub>ij</sub></italic> is the <italic>j</italic>th value of the <italic>i</italic>th input vector <bold>x</bold><italic><sub>i</sub></italic>, and each weight <italic>w<sub>i</sub></italic> is one input–output connection.
			</p><p>The fitness of each network was assessed with respect to its performance error on a single common set <italic>A</italic> = <italic>A</italic><sub>1</sub> ∪ <italic>A</italic><sub>2</sub> of <italic>m</italic> = 20 associations, where <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> are two disjoint subsets of <italic>n</italic><sub>1</sub> = 10 and <italic>n</italic><sub>2</sub> = 10 associations, respectively. The <italic>m</italic> associations in <italic>A</italic> were allocated randomly to the two subsets, <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub>. The subsets <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> were intended to represent different components of a task, and were therefore the same <italic>for all networks,</italic> and <italic>across all generations</italic>. In the first generation, each network's weight values were chosen from a Gaussian distribution (see below for details).</p><p>The desired output value <italic>d<sub>i</sub></italic> for each input vector <bold>x</bold><italic><sub>i</sub></italic> was drawn from a Gaussian distribution with variance 1/<italic>n</italic>. An analytic method was used to solve for the optimal weight vector <bold>w</bold><sub>0</sub> which maps inputs to outputs: <italic>d<sub>i</sub></italic> = <bold>w</bold><sub>0</sub> · <bold>x</bold><italic><sub>i</sub></italic> (see below). Given the variances of the inputs and outputs, the expected length of <bold>w</bold><sub>0</sub> is unity.</p><p>Each new generation was formed from 1,000 matings between 1,000 pairs of networks. The <italic>K</italic><sup>th</sup> network was chosen for mating according to its fitness <italic>F</italic>(<italic>K</italic>) with probability <italic>p</italic>(<italic>K</italic>). Networks were chosen with replacement to ensure that the number of offspring from a given network was proportional to <italic>p</italic>(<italic>K</italic>), which is defined as
				<disp-formula id="pcbi-0030147-e002"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030147.e002" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy='false'>)</mml:mo></mml:mrow><mml:mrow><mml:mstyle displaystyle='true'><mml:msubsup><mml:mo>&sum;</mml:mo><mml:mi>k</mml:mi><mml:mrow><mml:mn>1000</mml:mn></mml:mrow></mml:msubsup></mml:mstyle><mml:mi>F</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy='false'>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>where the denominator ensures ∑<italic><sub>k</sub>p</italic>(<italic>k</italic>) = 1. Half the weights of each offspring were copied from (randomly chosen) corresponding weight locations in one parent network, and half from the other parent. Aside from mutations, weight values inherited by an offspring were the same as those inherited by its parents (i.e., inheritance was Darwinian, not Lamarckian).
			</p><p>Mutation was applied to each weight with a probability of 0.05, using a uniform probability density function. Then Gaussian noise with a standard deviation of 0.05 was added to the value of those weights that had been chosen for mutation.</p><p>There were three conditions: <italic>FLL, NoFLL,</italic> and <italic>NoLearn</italic>, with corresponding fitness functions <italic>F<sub>FLL</sub>, F<sub>NoFLL</sub>,</italic> and <italic>F<sub>NoLearn</sub></italic>. The initial randomly chosen weight values (see Network Learning Algorithm) of the population of networks were the same in all conditions. Networks were selected for mating according to their performance on the combined set <italic>A</italic> = <italic>A</italic><sub>1</sub> ∪ <italic>A</italic><sub>2</sub>, according to <xref ref-type="disp-formula" rid="pcbi-0030147-e002">Equation 2</xref> for all fitness functions, as described next.</p><sec id="s2a"><title>Condition FLL</title><p>Networks that exhibited high levels of FLL were preferentially selected for mating. Only associations <italic>A</italic><sub>2</sub> were learned, but the fitness of each network depended on its performance on both the learned associations <italic>A</italic><sub>2</sub> and on the unlearned associations <italic>A</italic><sub>1</sub>. The fitness <italic>F<sub>FLL</sub></italic>(<italic>K</italic>) of the <italic>K</italic><sup>th</sup> network is defined in terms of its innate performance error <italic>E<sub>pre</sub></italic> on <italic>A</italic> = <italic>A</italic><sub>1</sub> ∪ <italic>A</italic><sub>2</sub>, and on its performance error <italic>E<sub>post</sub></italic> on <italic>A</italic> after learning <italic>A</italic><sub>2</sub>:
					<disp-formula id="pcbi-0030147-e003"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030147.e003" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>L</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>c</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>&plus;</mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&minus;</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>where <italic>E<sub>pre</sub></italic> and <italic>E<sub>post</sub></italic> are:
					<disp-formula id="pcbi-0030147-e004"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030147.e004" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>&equals;</mml:mo><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:munderover></mml:mstyle><mml:msubsup><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math> --></disp-formula>
					<disp-formula id="pcbi-0030147-e005"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030147.e005" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&equals;</mml:mo><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:munderover></mml:mstyle><mml:msubsup><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mo>&ap;</mml:mo><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:munderover></mml:mstyle><mml:msubsup><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>where <inline-formula id="pcbi-0030147-ex002"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.0030147.ex002" xlink:type="simple"/></inline-formula>
					 and <inline-formula id="pcbi-0030147-ex003"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.0030147.ex003" xlink:type="simple"/></inline-formula>
					 are the network's output errors in response to the <italic>i</italic>th input vector before and after learning <italic>A</italic><sub>2</sub> (respectively). The parameter <italic>c</italic> = 0.05 defines the balance between performance error on innate versus post-learning (e.g., FLL-induced) behaviours, and is interpreted as a cost-of-learning parameter (see below). The network's fitness error <italic>D<sub>i</sub></italic> is a function of the difference <italic>e<sub>i</sub></italic> = <italic>y<sub>i</sub></italic> − <italic>d<sub>i</sub></italic> between the network's response <italic>y<sub>i</sub></italic> to the <italic>i</italic>th input vector and the desired output value <italic>d<sub>i</sub></italic>:
					<disp-formula id="pcbi-0030147-e006"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030147.e006" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mrow><mml:mo stretchy='true'>&lcub;</mml:mo><mml:mtable columnalign='left'><mml:mtr><mml:mtd><mml:msubsup><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mspace width='2.5pt'/><mml:mtext>if</mml:mtext><mml:mspace width='2.5pt'/><mml:msubsup><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&le;</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mspace width='2.5pt'/><mml:mtext>if</mml:mtext><mml:mspace width='2.5pt'/><mml:msubsup><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mspace width='2.5pt'/><mml:mo>&gt;</mml:mo><mml:mspace width='2.5pt'/><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math> --></disp-formula>This ensures that output errors above <italic>D<sub>thresh</sub></italic> have a disproportionately large and detrimental effect on fitness, as shown in <xref ref-type="fig" rid="pcbi-0030147-g003">Figure 3</xref>. This, in turn, ensures that only those networks with “good” performance are likely to be selected for reproduction. The value of <italic>D<sub>thresh</sub></italic> was set to 0.01.
				</p><fig id="pcbi-0030147-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0030147.g003</object-id><label>Figure 3</label><caption><title>Network Fitness Error Function</title><p>The response of the network to a given input vector <bold>x</bold> is y = <bold>w</bold> · <bold>x</bold>. Given a desired (target) output <italic>d</italic>, the solid curve shows how the fitness penalty <italic>D</italic> for an incorrect response increases sharply (to unity) if the magnitude of the difference <italic>e</italic> = <italic>y</italic> − <italic>d</italic> is greater than 0.1 (i.e., if <italic>e</italic><sup>2</sup> &gt; 0.01). For comparison, the quadratic error function <italic>e</italic><sup>2</sup> = (<italic>y</italic> − <italic>d</italic>)<sup>2</sup>, which is minimised during learning, is shown as a dashed curve. The range of <italic>e</italic>-values shown are typical for the simulations reported here. See <xref ref-type="sec" rid="s2">Methods</xref> section for details.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0030147.g003" xlink:type="simple"/></fig><p>For later use, we also define the fitness errors <italic>E<sub>pre</sub></italic> = <italic>E<sub>pre</sub></italic>(<italic>A</italic><sub>1</sub>) + <italic>E<sub>pre</sub></italic>(<italic>A</italic><sub>2</sub>), and <italic>E<sub>post</sub></italic> = <italic>E<sub>post</sub></italic> (<italic>A</italic><sub>1</sub>) + <italic>E<sub>post</sub></italic>(<italic>A</italic><sub>2</sub>) ≈ <italic>E<sub>post</sub></italic>(<italic>A</italic><sub>1</sub>). The approximation here and in <xref ref-type="disp-formula" rid="pcbi-0030147-e005">Equation 5</xref> emphasises the fact that the total fitness error is attributable almost exclusively to <italic>A</italic><sub>1</sub> after learning <italic>A</italic><sub>2</sub> (because error on <italic>A</italic><sub>2</sub> is then almost zero).</p><p>The inclusion of innate performance error <italic>E<sub>pre</sub></italic> in <italic>F<sub>FLL</sub></italic> ensures that the cost of learning is taken into account when assessing fitness. If <italic>c</italic> is small, then <italic>E<sub>pre</sub></italic> tends to be large, so that much learning is required to increase fitness. Conversely, if <italic>c</italic> is large, then <italic>E<sub>pre</sub></italic> tends to be small, so that little learning is required to increase fitness. Thus, <italic>E<sub>pre</sub></italic> is an implicit measure of the cost of learning (where <italic>c</italic> multiplies <italic>E<sub>pre</sub></italic>), and ensures that networks which require minimal learning have high innate fitness (although the small value of <italic>c</italic> used in <xref ref-type="disp-formula" rid="pcbi-0030147-e003">Equation 3</xref> defines a relatively low cost of learning).</p></sec><sec id="s2b"><title>Condition NoFLL</title><p>This was identical to condition FLL, except that the effects of FLL were precluded by making all input vectors in <italic>A</italic> mutually orthogonal, whilst retaining the length of each vector as in condition FLL, using Gram-Schmidt orthogonalisation. This makes the input vectors in <italic>A</italic><sub>1</sub> orthogonal to those in <italic>A</italic><sub>2</sub>, which ensures <italic>L</italic><sub>1</sub> and <italic>L</italic><sub>2</sub> are orthogonal. This, in turn, ensures that learning <italic>A</italic><sub>2</sub> cannot affect performance on <italic>A</italic><sub>1</sub>. The fitness function <italic>F<sub>NoFLL</sub></italic> was the same as in condition FLL (i.e., <italic>F<sub>NoFLL</sub></italic> = <italic>F<sub>FLL</sub></italic>).</p></sec><sec id="s2c"><title>Condition NoLearn</title><p>No learning occurred, so that improvement in performance over successive generations was due only to selection of innate performance on <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub>. Fitness was defined as <italic>F<sub>NoLearn</sub></italic> = 1/ <italic>E<sub>pre</sub></italic>, where <italic>E<sub>pre</sub></italic> is defined in <xref ref-type="disp-formula" rid="pcbi-0030147-e004">Equation 4</xref>. This is equivalent to setting <italic>c</italic> = 1 in <xref ref-type="disp-formula" rid="pcbi-0030147-e003">Equation 3</xref>.</p></sec><sec id="s2d"><title>Network Learning Algorithm</title><p>The network learning algorithm used here involves a type of supervised learning. Note that <xref ref-type="disp-formula" rid="pcbi-0030147-e001">Equation 1</xref> defines the network error used for learning, whereas <xref ref-type="disp-formula" rid="pcbi-0030147-e003">Equation 3</xref> defines the fitness of a network.</p><p>Each network was initialised with <italic>n</italic> weight values drawn randomly from a Gaussian distribution with unit variance. This was then divided by <italic>n</italic><sup>1/2</sup>, which ensures that the expected length of weight vectors in the population is unity.</p><p>Given a network with <italic>n</italic> input units and one output unit, the set <italic>A</italic> of <italic>m</italic>, <italic>n</italic>-element input vectors <bold>x</bold><italic><sub>i</sub></italic>: <italic>i</italic> = 1…<italic>m</italic> and <italic>m</italic> desired scalar output target values <italic>d<sub>i</sub></italic> were chosen randomly from a Gaussian distribution with unit variance. Each input vector was then divided by <italic>n</italic><sup>1/2</sup> so that the expected length of input vectors was unity (i.e., the variance of input values was 1/<italic>n</italic>).</p><p>In conditions FLL and NoFLL, each network learned <italic>n</italic><sub>2</sub> associations. Rather than using the iterative weight update normally associated with the delta rule, an analytic solution was obtained. Learning <italic>n</italic><sub>2</sub> associations consists of finding the orthogonal projection operator which projects the initial weight vector <bold>w</bold><sub>1</sub> to its nearest point in the subspace (e.g., <italic>L</italic><sub>2</sub>) defined by the <italic>n</italic><sub>2</sub> input vectors being learned. The end result <bold>w</bold><sub>2</sub> is the same as that obtained using the standard delta rule for infinitesimal learning rates [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>]. As with the standard delta rule, this yielded a value of approximately zero for post-learning performance error on the learned associations <italic>A</italic><sub>1</sub>. This type of learning is most plausibly associated with motor learning in the cerebellum and basal ganglia [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>].</p></sec></sec><sec id="s3"><title>Results</title><p>The results are based on ten computer simulation runs for each of the three conditions, FLL, NoFLL, and NoLearn, described above, and graphs show the mean of these ten runs. Each run involved a different fixed set <italic>A</italic> of 20 associations. As a reminder, the two free parameters are: 1) the cost-of-learning parameter, which was set to <italic>c</italic> = 0.05, and 2) the threshold of the fitness error function, which was set to <italic>D</italic><sub>thresh</sub> = 0.01.</p><p>The main results are shown in <xref ref-type="fig" rid="pcbi-0030147-g004">Figure 4</xref>, which is a summary of more detailed results in <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>. Condition FLL yields a FLL-induced error (i.e., error on <italic>A</italic><sub>1</sub> after learning <italic>A</italic><sub>2</sub>) of approximately zero after 30 generations, whereas condition NoFLL requires about 60 generations to achieve an error of less than unity. Condition NoLearn (dotted curve) yields the slowest innate learning, and is included for comparison.</p><fig id="pcbi-0030147-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0030147.g004</object-id><label>Figure 4</label><caption><title>Effect of Free-Lunch Learning on Performance Error</title><p>The graph shows the mean results of ten computer simulation runs, in three conditions: FLL, NoFLL, and NoLearn (see text). In each run, the fitness of each of 1,000 networks was determined by performance error on a fixed set <italic>A</italic> = <italic>A</italic><sub>1</sub> ∪ <italic>A</italic><sub>2</sub> of 20 associations; a different set <italic>A</italic> was used for each run. For all graphs in this paper, the median (of error, here) of 1,000 networks was obtained throughout each run, and the mean of ten medians is shown for each generation in each condition (standard errors were no greater than 0.5, and are not shown for clarity). </p><p><bold>Condition FLL</bold> (solid line): mean performance error <italic>E<sub>post</sub></italic>(<italic>A</italic><sub>1</sub>) on the ten associations in <italic>A</italic><sub>1</sub> after learning the ten associations in subset <italic>A</italic><sub>2</sub>. Learning <italic>A</italic><sub>2</sub> had a beneficial effect on performance on <italic>A</italic><sub>1</sub> over 100 generations, corresponding to an increase in the amount and prevalence of FLL (see <xref ref-type="fig" rid="pcbi-0030147-g006">Figure 6</xref>). <bold>Condition NoFLL</bold> (dashed line): mean performance error <italic>E<sub>post</sub></italic>(<italic>A</italic><sub>1</sub>) was evaluated as in condition FLL, except that the input vectors in <italic>A</italic><sub>1</sub> were orthogonal to those in <italic>A</italic><sub>2</sub>, so that learning <italic>A</italic><sub>2</sub> could not have any effect on performance on <italic>A</italic><sub>1</sub> (see text). <bold>Condition NoLearn</bold> (dotted line): mean performance error <italic>E<sub>pre</sub></italic> on <italic>A</italic><sub>1</sub> was evaluated “at birth” (i.e., no within-lifetime learning was allowed).</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0030147.g004" xlink:type="simple"/></fig><fig id="pcbi-0030147-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0030147.g005</object-id><label>Figure 5</label><caption><title>Effect of Free-Lunch Learning on Evolution</title><p>Performance error in three conditions (FLL, NoFLL, and NoLearn). Different performance errors are drawn as follows: <bold>solid line</bold>, <italic>E<sub>post</sub></italic>(<italic>A</italic><sub>1</sub>), performance error on <italic>A</italic><sub>1</sub> after learning only <italic>A</italic><sub>2;</sub> <bold>dashed line</bold>, <italic>E<sub>pre</sub></italic>(<italic>A</italic><sub>1</sub>), innate performance error on <italic>A</italic><sub>1</sub>; <bold>dotted line</bold>, <italic>E<sub>pre</sub></italic>(<italic>A</italic><sub>2</sub>), innate performance error on <italic>A</italic><sub>2</sub>.</p><p>(A)<bold> Condition FLL</bold>: mean performance error <italic>E<sub>post</sub></italic>(<italic>A</italic><sub>1</sub>) on <italic>A</italic><sub>1</sub> (solid line) after learning <italic>A</italic><sub>2</sub> decreased over generations most rapidly in this condition. Innate error on <italic>A</italic><sub>1</sub> is slightly lower than on <italic>A</italic><sub>2</sub>.</p><p>(B)<bold> Condition NoFLL</bold>: precluding FLL ensured that mean innate error on <italic>A</italic><sub>1</sub> (dashed line) was essentially the same as after learning <italic>A</italic><sub>2</sub> (solid line). The dashed line has been plotted 0.1 units above the solid line for clarity. Innate error on <italic>A</italic><sub>2</sub> is large because the fitness cost of innate errors is low (<italic>c</italic> = 0.05).</p><p>(C)<bold> Condition NoLearn</bold>: mean innate performance error <italic>E<sub>pre</sub></italic>(<italic>A</italic><sub>1</sub>) and <italic>E<sub>pre</sub></italic>(<italic>A</italic><sub>2</sub>) on <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub>. For comparison, mean performance errors on <italic>A</italic><sub>1</sub> in each condition (i.e., the solid lines here) are summarised in <xref ref-type="fig" rid="pcbi-0030147-g004">Figure 4</xref>.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0030147.g005" xlink:type="simple"/></fig><fig id="pcbi-0030147-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0030147.g006</object-id><label>Figure 6</label><caption><title>Prevalence and Amount of Free-Lunch Learning</title><p>The lines in each graph correspond to the conditions: FLL = <bold>solid line</bold>, NoFLL = <bold>dashed line</bold>. Performance error on <italic>A</italic><sub>1</sub> was tested after learning <italic>A</italic><sub>2</sub> in conditions FLL and NoFLL. Each plotted line is the mean of ten computer simulation runs (see <xref ref-type="fig" rid="pcbi-0030147-g004">Figure 4</xref> for details).</p><p>(A)<bold> Prevalence of FLL</bold>: the proportion of networks which showed improved performance on <italic>A</italic><sub>1</sub> after learning <italic>A</italic><sub>2</sub>. In condition FLL, the prevalence of FLL was non-zero in the first generation, as expected (see text), and increased across subsequent generations. In condition NoFLL, the prevalence remained at zero, as expected.</p><p>(B)<bold> Amount of FLL</bold>: in condition FLL, the amount of FLL increased dramatically over the first 30 generations. The absence of FLL in condition NoFLL is as expected (see text). The amount of FLL defined for this graph only is the difference in fitness error on <italic>A</italic><sub>1</sub> before and after learning <italic>A</italic><sub>2</sub>, expressed as a proportion of the error on <italic>A</italic><sub>1</sub> before learning <italic>A</italic><sub>2</sub>; or, equivalently, as [<italic>E<sub>pre</sub></italic>(<italic>A</italic><sub>1</sub>) − <italic>E<sub>post</sub></italic>(<italic>A</italic><sub>1</sub>)]/<italic>E<sub>pre</sub></italic>(<italic>A</italic><sub>1</sub>).</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0030147.g006" xlink:type="simple"/></fig><p>The proportion of networks that exhibit FLL over generations is shown in <xref ref-type="fig" rid="pcbi-0030147-g006">Figure 6</xref>A, and the amount of FLL is shown in <xref ref-type="fig" rid="pcbi-0030147-g006">Figure 6</xref>B. The proportion and amount of FLL increases in condition FLL, as indicated by the solid line in each figure. The zero prevalence of FLL in condition NoFLL (dashed line) is associated with zero FLL as indicated in <xref ref-type="fig" rid="pcbi-0030147-g006">Figure 6</xref>B. More detailed results are shown in <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>A–<xref ref-type="fig" rid="pcbi-0030147-g005">5</xref>C.</p><sec id="s3a"><title>Performance on <italic>A</italic><sub>1</sub></title><p>Performance on <italic>A</italic><sub>1</sub> (solid line in <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>A) after learning <italic>A</italic><sub>2</sub> is better in condition FLL than in condition NoFLL (solid line, 5B). Innate performance on <italic>A</italic><sub>1</sub> is also better in condition FLL (dashed line, <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>A) than in conditions NoFLL (dashed line, <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>B) and NoLearn (dashed line, <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>C). Together, these results suggest that FLL accelerates both the rate at which FLL-induced behaviours (<italic>A</italic><sub>1</sub>) appear, as well as the rate at which FLL-induced behaviours (<italic>A</italic><sub>1</sub>) become genetically assimilated.</p></sec><sec id="s3b"><title>Performance on <italic>A</italic><sub>2</sub></title><p>Innate performance on subset <italic>A</italic><sub>2</sub> is better in condition FLL (dotted curve, <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>A) than in conditions NoFLL (dotted curve, <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>B) and NoLearn (dotted curve, <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>C).</p><p>Learning <italic>A</italic><sub>2</sub> reduces error on subset <italic>A</italic><sub>1</sub> even in the first generation in conditions FLL (<xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>A). Additionally, the proportion of networks showing FLL is greater than 0.5 (<xref ref-type="fig" rid="pcbi-0030147-g006">Figure 6</xref>A), and the amount of FLL is greater than zero (<xref ref-type="fig" rid="pcbi-0030147-g006">Figure 6</xref>B) in the first generation. These effects are not due to any special properties of the networks nor of the associations. Indeed they are entirely expected, and are consistent with the theoretical analysis in [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>]. In essence, FLL is observed in the first generation because it is very unlikely that the mainfolds <italic>L</italic><sub>1</sub> and <italic>L</italic><sub>2</sub> defined by <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> (respectively) are orthogonal, so that learning <italic>A</italic><sub>2</sub> usually reduces error on <italic>A</italic><sub>1</sub> (albeit by a small amount in the first generation).</p></sec></sec><sec id="s4"><title>Discussion</title><p>Before discussing results in detail, it is important to clarify precisely what is being claimed here. The main claim is that, given a population of organisms which can learn, the presence of FLL accelerates the rate at which a given set of advantageous behaviours evolves relative to populations which 1) can learn but which do not have FLL (e.g., condition NoFLL) and 2) cannot learn (e.g., condition NoLearn). Specifically, it is claimed that FLL accelerates the appearance of adaptive behaviour, both in its innate form and as FLL-induced behaviour, and that FLL can accelerate the rate at which learned behaviours become innate.</p><p>It is also claimed that FLL increases the rate at which a set of behaviours (e.g., <italic>A</italic>) is acquired within a lifetime. Clearly, if learning one subset (e.g., <italic>A</italic><sub>2</sub>) induces learning of another subset (e.g., <italic>A</italic><sub>1</sub>), then the amount of learning required to learn both subsets (e.g., <italic>A</italic>) is reduced.</p><p>It is worth noting that FLL is not related to generalisation (see [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>]), which cannot therefore be responsible for the effects reported here.</p><sec id="s4a"><title>Task Difficulty</title><p>The task was purposely made difficult, such that network outputs which were not close to desired target values were assigned an error value of unity. This heavily penalises networks that do not generate near-correct responses. This type of task may emulate tasks for which being “almost correct” provides no fitness benefit. Such tasks are exemplified by a predator which almost catches prey (e.g., a kingfisher almost catching a fish, or where each failed attempt yields a large fitness cost), or where learning is incremental and stepwise (e.g., learning to catch progressively larger prey). Such tasks give rise to “needle-in-a-haystack” search spaces [<xref ref-type="bibr" rid="pcbi-0030147-b005">5</xref>], which have rugged or uncorrelated landscapes [<xref ref-type="bibr" rid="pcbi-0030147-b013">13</xref>].</p></sec><sec id="s4b"><title>Is Accelerated Evolution due to Learning?</title><p>A cogent critique of research by Nolfi et al. [<xref ref-type="bibr" rid="pcbi-0030147-b014">14</xref>] argues that accelerated evolution (specifically, assimilation) is a generic consequence of learning per se [<xref ref-type="bibr" rid="pcbi-0030147-b015">15</xref>]. In results not shown here, replacing <italic>A</italic><sub>2</sub> with a new, randomly chosen subset every generation in condition FLL yields a more gradual evolution of FLL-induced and innate behaviours than is obtained in any of the conditions used here. This effectively excludes the possibility that the accelerated evolution reported here is due to learning per se.</p></sec><sec id="s4c"><title>Reaction Norms</title><p>In terms of evolutionary theory, FLL-induced behaviours can be considered as the establishment of a new reaction norm. The specific “environment” that induces the reaction norm is learning a particular subset of behaviours (<italic>A</italic><sub>2</sub>), and the phenotypic reaction to this environment is another subset of behaviours (<italic>A</italic><sub>1</sub>).</p></sec><sec id="s4d"><title>Genetic Assimilation</title><p>FLL does not necessarily force FLL-induced behaviours to become genetically assimilated. In fact, there is a tradeoff between the amount of acceleration induced by FLL and the extent to which behaviours become innate. If the cost-of-learning parameter is set to <italic>c</italic> = 1, then there is no incentive for FLL to increase over generations. In contrast, if <italic>c</italic> ≈ 0 (as in the simulations reported here), then the rapid evolution of FLL-induced behaviour shown in <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>A (solid line) is obtained, alongside the slower evolution of innate behaviour (dashed line in <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>A). Thus, even the small value of <italic>c</italic> (0.05) used here puts pressure on learned behaviours to become innate, as indicated by the decreasing innate performance errors on <italic>A</italic><sub>1</sub> (dashed line) and <italic>A</italic><sub>2</sub> (dotted line) in <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>A.</p><p>In practice, learning always has a non-zero fitness cost, if only in terms of the time required for that learning to occur. This is because time spent learning is time spent not eating, or time spent being eaten, both of which reduce fitness. Thus, the small value of <italic>c</italic> used here represents one value along the spectrum of learning costs. It therefore seems likely that even the simplest learned behaviours have a tendency to become innate, and that this tendency increases with the cost of learning. For example, in results not shown here, increasing the cost-of-learning parameter <italic>c</italic> decreases the rate at which FLL-induced performance on <italic>A</italic><sub>1</sub> improves, and increases the rate at which performance on <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> becomes innate (innate performance with <italic>c</italic> = 1 is effectively obtained in condition NoLearn (see <xref ref-type="fig" rid="pcbi-0030147-g005">Figure 5</xref>C)). It is therefore not easy to classify the effect reported here as a clear-cut example of the Baldwin effect [<xref ref-type="bibr" rid="pcbi-0030147-b006">6</xref>], although these effects are almost certainly related.</p></sec><sec id="s4e"><title>General Free-Lunch Effects</title><p>The basic geometry which underpins FLL within a lifetime (as in [<xref ref-type="bibr" rid="pcbi-0030147-b010">10</xref>]) and across lifetimes (as here) can also be applied in two other contexts: 1) evolution of innate behaviours without learning, and 2) evolution of general phenotypic traits. These two cases are considered in the next two paragraphs. Both of these effects require the presence of environmental conditions that fluctuate over successive generations (e.g., fluctuations in temperature induced by ice ages, salinity, prey numbers, or predation pressure).</p><p>1) Accelerated evolution of innate behaviours without learning can be understood by considering an organism that has no learning ability, and which relies on genetic specification of its neuronal connections [<xref ref-type="bibr" rid="pcbi-0030147-b012">12</xref>]. Natural selection ensures that its neuronal connections at birth yield innate behaviour matched to its environment. If the environment changes, then natural selection will induce a corresponding shift to a new set of innate connections. If the environment then shifts back to its original state, then organisms' connections will tend to revert to their original values. Let us assume that some connections revert faster than others over successive generations. For example, some connections may be specified by genes linked to other innate behaviours, and this genetic linkage would tend to reduce the rate of genetic change. In fact, for simplicity, assume that half of the connections revert quickly and half revert slowly. If the required behaviours are encoded as distributed representations, then this connection reversion will induce a FLL-type effect, such that <italic>all</italic> associations benefit from the reversion of a proportion (half here) of connection values.</p><p>2) Accelerated evolution of general phenotypic traits can be understood if we assume an extreme form of pleiotropy: that each of a given set of genes affects every phenotypic trait. This is equivalent to assuming that the genome is a <italic>distributed representation</italic> of the phenotype. Consider a population in which the fittest organism has a genome <bold>w</bold><sub>0</sub> which is perfectly adapted to its environment <italic>e</italic><sub>0</sub>. If the environment changes to <italic>e</italic><sub>1</sub>, then the fittest organism's genome will eventually evolve to a new state <bold>w</bold><sub>1</sub> that is suited to <italic>e</italic><sub>1</sub> (this is analogous to forgetting in FLL). Now, consider what happens if the environment changes back to <italic>e</italic><sub>0</sub>. The fittest organism's genome will be forced back toward <bold>w</bold><sub>0</sub>, but inevitably some genes will revert faster than others. For the sake of argument, assume that a subset <italic>G</italic><sub>2</sub> of genes revert to their original values, while others <italic>G</italic><sub>1</sub> remain as they were in <bold>w</bold><sub>1</sub> (this is analogous to relearning only <italic>A</italic><sub>2</sub>). Because each gene in <italic>G</italic><sub>2</sub> contributes to every phenotypic trait, the reversion of genes in <italic>G</italic><sub>2</sub> to their original values will push the entire phenotype back toward its state in the original environment <italic>e</italic><sub>0</sub>. Thus, the reappearance of an entire set of phenotypic traits (e.g., changes in size) can occur more quickly if those traits are encoded within a set of pleiotropic genes than if each trait is represented by a non-pleiotropic gene, and suggests a form of <italic>free-lunch evolution</italic>.</p></sec><sec id="s4f"><title>Conclusion</title><p>It has been demonstrated that FLL accelerates the evolution of behaviours in neural network models. Given that FLL appears to be a fundamental property of distributed representations, and given the reliance of neuronal systems on distributed representations, FLL-induced behaviours may constitute a significant component of apparently innate behaviours (e.g., nest-building). Results presented here suggest that any organism that did not take advantage of such a fundamental and ubiquitous effect would be at a selective disadvantage. Finally, if FLL accelerates evolution in the natural world, then it may have been involved in the Cambrian explosion, an explosion that began when brains (and therefore learning) first appeared.</p></sec></sec></body><back><ack><p>Thanks to N. Hunkin and R. Lister for comments on this paper, and to P. Parpia for useful discussions. Thanks also to two anonymous reviewers for their detailed comments.</p></ack><glossary><title>Abbreviations</title><def-list><def-item><term>FLL</term><def><p>free-lunch learning</p></def></def-item></def-list></glossary><ref-list><title>References</title><ref id="pcbi-0030147-b001"><label>1</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Bateson</surname><given-names>G</given-names></name></person-group>
					<year>1979</year>
					<source>Mind and nature</source>
					<publisher-name>Flamingo</publisher-name>
				</element-citation></ref><ref id="pcbi-0030147-b002"><label>2</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Waddington</surname><given-names>C</given-names></name></person-group>
					<year>1959</year>
					<article-title>Canalisation of development and genetic assimilation of acquired characters.</article-title>
					<source>Nature</source>
					<volume>183</volume>
					<fpage>1654</fpage>
					<lpage>1655</lpage>
				</element-citation></ref><ref id="pcbi-0030147-b003"><label>3</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Mery</surname><given-names>F</given-names></name><name name-style="western"><surname>Kawecki</surname><given-names>T</given-names></name></person-group>
					<year>2003</year>
					<article-title>A fitness cost of learning in <named-content content-type="genus-species" xlink:type="simple">Drosophila melangaster</named-content>.</article-title>
					<source>Proc Roy Soc London B</source>
					<volume>270</volume>
					<fpage>2465</fpage>
					<lpage>2469</lpage>
				</element-citation></ref><ref id="pcbi-0030147-b004"><label>4</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Price</surname><given-names>T</given-names></name><name name-style="western"><surname>Qvarnstrom</surname><given-names>A</given-names></name><name name-style="western"><surname>Irwin</surname><given-names>D</given-names></name></person-group>
					<year>2003</year>
					<article-title>The role of phenotypic plasticity in driving genetic evolution.</article-title>
					<source>Proc Roy Soc Lond B</source>
					<volume>270</volume>
					<fpage>1433</fpage>
					<lpage>1440</lpage>
				</element-citation></ref><ref id="pcbi-0030147-b005"><label>5</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Hinton</surname><given-names>G</given-names></name><name name-style="western"><surname>Nowlan</surname><given-names>S</given-names></name></person-group>
					<year>1987</year>
					<article-title>How learning can guide evolution.</article-title>
					<source>Complex Systems</source>
					<volume>1</volume>
					<fpage>495</fpage>
					<lpage>502</lpage>
				</element-citation></ref><ref id="pcbi-0030147-b006"><label>6</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Baldwin</surname><given-names>J</given-names></name></person-group>
					<year>1896</year>
					<article-title>A new factor in evolution.</article-title>
					<source>Am Nat</source>
					<volume>30</volume>
					<fpage>441</fpage>
					<lpage>451</lpage>
					<comment>Additional pages: 536-553</comment>
				</element-citation></ref><ref id="pcbi-0030147-b007"><label>7</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Mery</surname><given-names>F</given-names></name><name name-style="western"><surname>Kawecki</surname><given-names>T</given-names></name></person-group>
					<year>2004</year>
					<article-title>The effect of learning on experimental evolution of resource preference in <named-content content-type="genus-species" xlink:type="simple">Drosophila melangaster</named-content>.</article-title>
					<source>Evolution</source>
					<volume>58</volume>
					<fpage>757</fpage>
					<lpage>767</lpage>
				</element-citation></ref><ref id="pcbi-0030147-b008"><label>8</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Dopazo</surname><given-names>H</given-names></name><name name-style="western"><surname>Gordon</surname><given-names>M</given-names></name><name name-style="western"><surname>Perazzo</surname><given-names>R</given-names></name><name name-style="western"><surname>Risau-Gusman</surname><given-names>S</given-names></name></person-group>
					<year>2001</year>
					<article-title>A model for the interaction of learning and evolution.</article-title>
					<source>Bull Math Biol</source>
					<volume>63</volume>
					<fpage>117</fpage>
					<lpage>134</lpage>
				</element-citation></ref><ref id="pcbi-0030147-b009"><label>9</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Stone</surname><given-names>J</given-names></name><name name-style="western"><surname>Hunkin</surname><given-names>N</given-names></name><name name-style="western"><surname>Hornby</surname><given-names>A</given-names></name></person-group>
					<year>2001</year>
					<article-title>Predicting spontaneous recovery of memory.</article-title>
					<source>Nature</source>
					<volume>414</volume>
					<fpage>167</fpage>
					<lpage>168</lpage>
				</element-citation></ref><ref id="pcbi-0030147-b010"><label>10</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Stone</surname><given-names>J</given-names></name><name name-style="western"><surname>Jupp</surname><given-names>P</given-names></name></person-group>
					<year>2007</year>
					<article-title>Free-lunch learning: Modelling spontaneous recovery of memory.</article-title>
					<source>Neural Comput</source>
					<volume>19</volume>
					<fpage>194</fpage>
					<lpage>217</lpage>
				</element-citation></ref><ref id="pcbi-0030147-b011"><label>11</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Tinbergen</surname><given-names>N</given-names></name></person-group>
					<year>1951</year>
					<source>The study of instinct</source>
					<publisher-loc>Oxford</publisher-loc>
					<publisher-name>Oxford University Press</publisher-name>
				</element-citation></ref><ref id="pcbi-0030147-b012"><label>12</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kaufman</surname><given-names>A</given-names></name><name name-style="western"><surname>Dror</surname><given-names>G</given-names></name><name name-style="western"><surname>Meilijson</surname><given-names>I</given-names></name><name name-style="western"><surname>Ruppin</surname><given-names>E</given-names></name></person-group>
					<year>2006</year>
					<article-title>Gene expression of <named-content content-type="genus-species" xlink:type="simple">Caenorhabditis elegans</named-content> neurons carries information on their synaptic connectivity.</article-title>
					<source>PLoS Comput Biol</source>
					<volume>2</volume>
					<fpage>1561</fpage>
					<lpage>1567</lpage>
				</element-citation></ref><ref id="pcbi-0030147-b013"><label>13</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kauffman</surname><given-names>S</given-names></name><name name-style="western"><surname>Levin</surname><given-names>S</given-names></name></person-group>
					<year>1987</year>
					<article-title>Towards a general theory of adaptive walks on rugged landscapes.</article-title>
					<source>J Theor Biol</source>
					<volume>128</volume>
					<fpage>11</fpage>
					<lpage>45</lpage>
				</element-citation></ref><ref id="pcbi-0030147-b014"><label>14</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Nolfi</surname><given-names>S</given-names></name><name name-style="western"><surname>Elman</surname><given-names>J</given-names></name><name name-style="western"><surname>Parisi</surname><given-names>D</given-names></name></person-group>
					<year>1994</year>
					<article-title>Learning and evolution in neural networks.</article-title>
					<source>Adaptive Behavior</source>
					<volume>3</volume>
					<fpage>5</fpage>
					<lpage>28</lpage>
				</element-citation></ref><ref id="pcbi-0030147-b015"><label>15</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Harvey</surname><given-names>I</given-names></name></person-group>
					<year>1996</year>
					<article-title>Relearning and evolution in neural networks.</article-title>
					<source>Adaptive Behaviour</source>
					<volume>4</volume>
					<fpage>81</fpage>
					<lpage>84</lpage>
				</element-citation></ref></ref-list></back></article>
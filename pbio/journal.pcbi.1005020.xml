<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005020</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-16-00227</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Behavior</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Economics</subject><subj-group><subject>Experimental economics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Decision theory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Decision theory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject><subj-group><subject>Agent-based modeling</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Systems science</subject><subj-group><subject>Agent-based modeling</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Systems science</subject><subj-group><subject>Agent-based modeling</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Mental health and psychiatry</subject><subj-group><subject>Behavioral disorders</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Thermodynamics</subject><subj-group><subject>Entropy</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Intrinsic Valuation of Information in Decision Making under Uncertainty</article-title>
<alt-title alt-title-type="running-head">Intrinsic Valuation of Information</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6608-9026</contrib-id>
<name name-style="western">
<surname>Bennett</surname>
<given-names>Daniel</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Bode</surname>
<given-names>Stefan</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Brydevall</surname>
<given-names>Maja</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9863-3644</contrib-id>
<name name-style="western">
<surname>Warren</surname>
<given-names>Hayley</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Murawski</surname>
<given-names>Carsten</given-names>
</name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Melbourne School of Psychological Sciences, The University of Melbourne, Parkville, Victoria, Australia</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Department of Finance, The University of Melbourne, Parkville, Victoria, Australia</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>O'Reilly</surname>
<given-names>Jill X</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Oxford University, UNITED KINGDOM</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: DB SB CM. Performed the experiments: DB MB HW. Analyzed the data: DB MB HW. Contributed reagents/materials/analysis tools: DB. Wrote the paper: DB SB MB HW CM.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">daniel.bennett@unimelb.edu.au</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>14</day>
<month>7</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<month>7</month>
<year>2016</year>
</pub-date>
<volume>12</volume>
<issue>7</issue>
<elocation-id>e1005020</elocation-id>
<history>
<date date-type="received">
<day>9</day>
<month>2</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>14</day>
<month>6</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Bennett et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005020"/>
<abstract>
<p>In a dynamic world, an accurate model of the environment is vital for survival, and agents ought regularly to seek out new information with which to update their world models. This aspect of behaviour is not captured well by classical theories of decision making, and the cognitive mechanisms of information seeking are poorly understood. In particular, it is not known whether information is valued only for its instrumental use, or whether humans also assign it a non-instrumental intrinsic value. To address this question, the present study assessed preference for non-instrumental information among 80 healthy participants in two experiments. Participants performed a novel information preference task in which they could choose to pay a monetary cost to receive advance information about the outcome of a monetary lottery. Importantly, acquiring information did not alter lottery outcome probabilities. We found that participants were willing to incur considerable monetary costs to acquire payoff-irrelevant information about the lottery outcome. This behaviour was well explained by a computational cognitive model in which information preference resulted from aversion to temporally prolonged uncertainty. These results strongly suggest that humans assign an intrinsic value to information in a manner inconsistent with normative accounts of decision making under uncertainty. This intrinsic value may be associated with adaptive behaviour in real-world environments by producing a bias towards exploratory and information-seeking behaviour.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Acquiring information about the external world is vital for planning and decision making. However, recent research has shown that some animals choose to acquire information at considerable cost even when the information is of no practical benefit, a counter-intuitive behavior associated with suboptimal outcomes. In this study, we demonstrate that humans also engage in this suboptimal behavior by forfeiting future monetary reward in exchange for early but unusable information about future outcomes. Our results suggest that participants attach a value to information beyond its purely instrumental value. This preference for information may help account for apparent anomalies in human choice behavior such as compulsive checking behaviors in obsessive-compulsive disorder, and excessive and wasteful use of uninformative laboratory testing in hospitals.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000923</institution-id>
<institution>Australian Research Council</institution>
</institution-wrap>
</funding-source>
<award-id>DE140100350</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Bode</surname>
<given-names>Stefan</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>Faculty of Business and Economics (The University of Melbourne)</institution>
</funding-source>
<award-id>Strategic Initiatives Grant 2011</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Murawski</surname>
<given-names>Carsten</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution>Faculty of Business and Economics (The University of Melbourne)</institution>
</funding-source>
<award-id>Strategic Initiatives Grant 2011</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Bode</surname>
<given-names>Stefan</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by a Faculty of Business and Economics (<ext-link ext-link-type="uri" xlink:href="http://fbe.unimelb.edu.au/" xlink:type="simple">http://fbe.unimelb.edu.au/</ext-link>) Strategic Initiatives Grant 2011 to SB and CM, and by an Australian Research Council (<ext-link ext-link-type="uri" xlink:href="http://www.arc.gov.au/" xlink:type="simple">http://www.arc.gov.au/</ext-link>) Discovery Early Career Researcher Award (DE140100350) to SB. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="1"/>
<page-count count="21"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All behavioural datafiles are available from the Open Science Framework database (URL: <ext-link ext-link-type="uri" xlink:href="https://osf.io/my2zq" xlink:type="simple">https://osf.io/my2zq</ext-link>).</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>In many decision situations, agents possess only incomplete information about decision outcomes, and may choose to seek out further information before choosing a course of action [<xref ref-type="bibr" rid="pcbi.1005020.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref002">2</xref>]. For instance, a surgeon considering whether to operate on a tumor might first request a biopsy to determine whether the tumor is malignant or benign. Despite being a key feature of choice problems in natural settings, information seeking is not considered within many standard accounts of decision making under risk and uncertainty [<xref ref-type="bibr" rid="pcbi.1005020.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref005">5</xref>]. Moreover, it has been shown that some animals choose to seek information even when that information cannot be used to improve future outcomes [<xref ref-type="bibr" rid="pcbi.1005020.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref008">8</xref>]. This behaviour, which is suboptimal from the perspective of expected reward maximization, suggests that biological agents may attach a value to information which is not solely defined in terms of tangible future outcomes [<xref ref-type="bibr" rid="pcbi.1005020.ref009">9</xref>].</p>
<p>Historically, many theories of information valuation have adopted an <italic>instrumental</italic> framework, in which the value of information is calculated solely in terms of expected instrumental benefit [<xref ref-type="bibr" rid="pcbi.1005020.ref010">10</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref012">12</xref>]. These theories predict that a decision-maker should seek information only if the information is expected to impart a tangible benefit in excess of its cost [<xref ref-type="bibr" rid="pcbi.1005020.ref011">11</xref>]. For instance, a clairvoyant charging $100 to reveal whether stock prices will rise or fall should only be consulted if a payoff greater than $100 is expected to result from using this information. Instrumental valuation of information is normatively optimal, in the sense that it maximises expected monetary reward. However, one strong prediction of instrumental valuation is that information of no instrumental use for acquiring payoffs (henceforth termed <italic>non-instrumental information</italic>) should not affect choice behaviour. As a result, instrumental valuation of information cannot easily explain curiosity-driven or purely exploratory behaviours [<xref ref-type="bibr" rid="pcbi.1005020.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref014">14</xref>].</p>
<p>An alternative proposal is that biological agents may attach an <italic>intrinsic</italic> value to information, such that information about relevant future outcomes is valued for its own sake, independent of direct, tangible payoffs [<xref ref-type="bibr" rid="pcbi.1005020.ref015">15</xref>]. Similarly, economic decision theory has posited that humans might possess a preference for early resolution of uncertainty which would result in intrinsic value of information [<xref ref-type="bibr" rid="pcbi.1005020.ref016">16</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref018">18</xref>], and recent theories of active inference propose that choice behaviour can be explained by sensitivity to information gain as well as to extrinsic reward [<xref ref-type="bibr" rid="pcbi.1005020.ref019">19</xref>]. In support of intrinsic valuation of information, human participants have been shown to prefer early to late information about receiving an unavoidable electric shock [<xref ref-type="bibr" rid="pcbi.1005020.ref020">20</xref>], and to be conditioned by non-instrumental information in a behavioural conditioning paradigm [<xref ref-type="bibr" rid="pcbi.1005020.ref021">21</xref>]. Moreover, neural data from humans and non-human primates have shown that non-instrumental information is encoded using similar mechanisms, and within similar circuits, to primary and monetary reward [<xref ref-type="bibr" rid="pcbi.1005020.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref024">24</xref>]. These findings are consistent with the hypothesis that biological agents assign an intrinsic reward value to non-instrumental information about future outcomes using a coding scheme commensurate with primary and monetary reward.</p>
<p>One limitation of previous empirical work assessing preference for information in humans is that information available in decision-making tasks is usually of instrumental benefit to participants, such that it is difficult to dissociate the intrinsic value of information from its instrumental value [<xref ref-type="bibr" rid="pcbi.1005020.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref026">26</xref>]. To address this issue, the present study adapted a task from the animal literature which allowed preferences for non-instrumental information to be elicited in a well-controlled and incentive-compatible manner [<xref ref-type="bibr" rid="pcbi.1005020.ref022">22</xref>]. Using this task, we sought to test one counterintuitive prediction of intrinsic valuation of information: that, like starlings and pigeons, human participants would trade off information against extrinsic reward by sacrificing part of an uncertain future reward in exchange for early but non-instrumental information about reward likelihood [<xref ref-type="bibr" rid="pcbi.1005020.ref027">27</xref>].</p>
<p>Furthermore, among theories positing an intrinsic value of information, the source of this value is often unspecified. For instance, the Kreps-Porteus model in economic decision theory predicts a preference for early resolution of uncertainty from a particular axiomatic formulation of utility, but does not specify a cognitive mechanism which might drive this preference [<xref ref-type="bibr" rid="pcbi.1005020.ref016">16</xref>]. One proposal is that preference for non-instrumental information might result from an aversion to temporally prolonged uncertainty, such that agents may seek information in order to obtain relief from uncertainty [<xref ref-type="bibr" rid="pcbi.1005020.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref028">28</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref030">30</xref>]. We therefore tested a novel computational cognitive model, which assumed that inter-individual variability in the intrinsic value of information resulted from stable trait-level individual differences in degree of aversion to uncertainty, against a standard expected reward maximization model, which assumed that information was assigned solely instrumental value [<xref ref-type="bibr" rid="pcbi.1005020.ref011">11</xref>]. Finally, in order to determine whether the duration of uncertainty affected participants’ preference for information, we also conducted an additional experiment in the rate at which non-instrumental information was delivered was experimentally manipulated.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<p>To titrate preferences for non-instrumental information in human participants, we developed a novel variant of an experimental task used in animal research [<xref ref-type="bibr" rid="pcbi.1005020.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref022">22</xref>]. In each trial of this task, a lottery was played out in which participants could either win (receiving 20 cents) or lose (receiving 0 cents), with equal probability (see <xref ref-type="fig" rid="pcbi.1005020.g001">Fig 1a</xref>). Participants were asked to express their preference for observing one of two stimuli (termed ‘Set A’ and ‘Set B’) in the delay period prior to the presentation of the lottery outcome. Both stimuli took the form of five-slot arrays of red and black cards, with card colours initially hidden and then revealed one-by-one at a constant rate (see <xref ref-type="fig" rid="pcbi.1005020.g001">Fig 1b</xref>). One of the two stimuli (the ‘informative stimulus’) imparted information regarding the lottery outcome: a majority of black cards indicated that the participant would win, whereas a majority of red cards indicated a loss. By contrast, the other stimulus (the ‘non-informative stimulus’) consisted of five black and red cards whose colours were determined pseudo-randomly, and which therefore imparted no information about the lottery outcome. Informative and non-informative stimuli were therefore perceptually equivalent, but only the informative stimulus imparted information regarding the lottery outcome. Crucially, the information gained by observing the informative stimulus was non-instrumental, since it affected only the participant’s certainty regarding the lottery outcome, not the probabilities of the lottery itself.</p>
<fig id="pcbi.1005020.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005020.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Task schematic.</title>
<p>(A) Choice schematic. In the informative stimulus, the colour composition of cards perfectly predicted lottery outcome. In the non-informative stimulus, cards had no predictive validity for the lottery outcome. The information cost <italic>c</italic> was subtracted from lottery winnings only in the case of a win outcome. As a result, a loss always resulted in the same outcome (receive 0 cents) regardless of the participant’s choice of stimulus. (B) Trial schematic. Participants first received information regarding the identity and cost of the informative stimulus (both counterbalanced across trials), and then made a choice using left and right arrow keys within 2 seconds (left/right mapping of A and B counterbalanced across trials). Participants were then presented for 2 seconds with a choice information screen, following which cards from the chosen stimulus were revealed sequentially at a constant rate of 3 seconds per card (18 seconds total delay). Participants were informed that all outcomes were predetermined, and that choice of stimulus was unrelated to win probability. If the participant failed to respond during the choice window, the non-informative stimulus was shown and no reward was subsequently delivered.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.g001" xlink:type="simple"/>
</fig>
<p>To assess participants’ willingness to sacrifice monetary reward for non-instrumental information, on each trial a monetary cost was associated with the informative stimulus. Four cost conditions were assessed: 0 cents (free information), 1 cent, 3 cents, and 5 cents. If participants chose the informative stimulus, this cost was deducted from lottery winnings in the case of a win outcome, but not in the case of a loss outcome (see <xref ref-type="fig" rid="pcbi.1005020.g001">Fig 1a</xref>). Participants could not lose money by observing the informative stimulus, ensuring that information preference was not confounded by loss aversion. Since lottery probabilities were unaffected by participants’ choice of stimulus, expected reward was greater for the non-informative stimulus than the informative stimulus in all non-zero cost conditions. In the zero-cost condition, the expected monetary reward of informative and non-informative stimuli was equal.</p>
<p>We conducted two separate experiments using this paradigm. In Experiment 1, only information cost varied between trials. In Experiment 2, both information cost and information rate (the speed at which cards were revealed) differed between trials.</p>
<sec id="sec003">
<title>Preference for non-instrumental information</title>
<p>Experiment 1 assessed participants’ willingness to forfeit monetary reward in exchange for non-instrumental information, and examined the effect of information cost on information preference. Across cost conditions, participants chose the informative stimulus on 43.95 percent of trials (<italic>SD</italic> = 20.28), while showing good task engagement as evidenced by a low proportion of missed responses (<italic>M</italic> = 1.67 percent, <italic>SD</italic> = 1.72). On average, across cost conditions participants sacrificed 2.87 percent of available winnings in exchange for early information about the lottery outcome (<italic>SD</italic> = 3.21). A one-way repeated-measures analysis of variance (ANOVA) revealed that choice proportions were modulated by the cost of information (<italic>F</italic>(1.89, 73.60) = 65.68, <italic>p</italic> &lt; .001; partial <italic>η</italic><sup>2</sup> = 0.63; see <xref ref-type="fig" rid="pcbi.1005020.g002">Fig 2a</xref>), with information choice proportion monotonically decreasing with increases in information cost. Control analyses revealed that behaviour was not significantly affected by the key used to select responses (left versus right arrow: <italic>t</italic>(39) = -0.71, <italic>p</italic> = .24) or the nominal identity of the informative stimulus (A versus B: <italic>t</italic>(39) = 1.40, <italic>p</italic> = .08).</p>
<fig id="pcbi.1005020.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005020.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Behavioral results for Experiment 1.</title>
<p>(A) Mean proportion of informative stimulus choices (denoted <italic>Pr(Info)</italic>) as a function of information cost. Error bars represent the standard error of the mean (SEM). Mean proportion of information-seeking choices was monotonically decreasing in cost of information. (B) Histogram of overall proportion of informative stimulus choices across participants, demonstrating inter-individual differences in behaviour. N = 40.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.g002" xlink:type="simple"/>
</fig>
<p>We next used post-hoc <italic>t</italic>-tests with Bonferroni correction to assess whether participants’ behavior was consistent with expected reward maximization. Expected reward maximization, which implies solely instrumental valuation of information, predicts that participants should be indifferent between the informative and non-informative stimulus when information is free, and that the non-informative stimulus should dominate the informative stimulus for any non-zero information cost [<xref ref-type="bibr" rid="pcbi.1005020.ref011">11</xref>]. In the zero-cost condition, informative stimulus choice proportion was significantly greater than the indifference point of 0.5 (<italic>t</italic>(39) = 16.83, <italic>p</italic> &lt; .001). In each of the non-zero cost conditions, informative stimulus choice proportion was significantly greater than zero (1-cent condition: <italic>t</italic>(39) = 7.17, <italic>p</italic> &lt; .001; 3-cent: <italic>t</italic>(39) = 5.41, <italic>p</italic> &lt; .001; 5-cent: <italic>t</italic>(39) = 4.76, <italic>p</italic> &lt; .001). These results indicate that participants sacrificed future reward for early information, which is inconsistent with expected reward maximization. In addition, we observed notable individual differences in patterns of information seeking behaviour (see <xref ref-type="fig" rid="pcbi.1005020.g002">Fig 2b</xref>), indicating heterogeneity of task strategies between participants.</p>
</sec>
<sec id="sec004">
<title>Computational model of intrinsic value of information</title>
<p>To formalise the comparison between instrumental and intrinsic theories of information valuation, we implemented these theories as competing computational cognitive models, and assessed which model provided the best account of both group- and individual-level data.</p>
<p>The two models we assessed were termed the Expected Value of Information (EVI) model, which incorporated solely instrumental valuations of information, and the Uncertainty Penalty (UP) model, which also incorporated intrinsic valuation of information by assuming that the source of information’s intrinsic value was an aversion to temporally prolonged uncertainty [<xref ref-type="bibr" rid="pcbi.1005020.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref028">28</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref030">30</xref>]. Both models considered the task in a Markov Decision Process (MDP) framework, and differed only in choice of state value function [<xref ref-type="bibr" rid="pcbi.1005020.ref031">31</xref>] (see also <italic>Experimental Protocols</italic>). We found that, in addition to providing the best overall account of choices across participants (smallest overall Bayesian Information Criterion (BIC) value; see <xref ref-type="table" rid="pcbi.1005020.t001">Table 1</xref> and <xref ref-type="fig" rid="pcbi.1005020.g003">Fig 3</xref>), the UP model provided the best fit for a large majority of individual participants. Accordingly, a likelihood-ratio test revealed that including the participant-specific uncertainty penalty parameter <italic>k</italic> greatly improved the overall fit of the UP model relative to the EVI model (χ<sup>2</sup>(40) = 1338.34, <italic>p</italic> &lt; .001). Moreover, the UP model provided an unbiased fit to the data of all participants, including those who displayed a relatively weak overall preference for information (see <xref ref-type="fig" rid="pcbi.1005020.g004">Fig 4</xref><italic>)</italic>. By contrast, the EVI model systematically underestimated informative stimulus choice proportions across all participants.</p>
<table-wrap id="pcbi.1005020.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005020.t001</object-id>
<label>Table 1</label> <caption><title>Behavioural model fits for 4405 choices by 40 participants.</title></caption>
<alternatives>
<graphic id="pcbi.1005020.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Model</th>
<th align="center">Free parameters (per participant)</th>
<th align="center"><italic>-LL</italic></th>
<th align="center"><italic>BIC</italic></th>
<th align="center">McFadden’s R<sup>2</sup></th>
<th align="center"><italic>n</italic> best fit</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">EVI</td>
<td align="center">1</td>
<td align="char" char=".">934.06</td>
<td align="char" char=".">2212.13</td>
<td align="char" char=".">0.51</td>
<td align="center">3</td>
</tr>
<tr>
<td align="center">UP</td>
<td align="center">2</td>
<td align="char" char=".">264.89</td>
<td align="char" char=".">1209.40</td>
<td align="char" char=".">0.86</td>
<td align="center">37</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p><italic>-LL</italic>: negative log-likelihood. <italic>BIC</italic>: Bayesian Information Criterion. Numbers in the <italic>n</italic> best fit column are based on a comparison of individual-participant BIC values for each model.</p></fn>
</table-wrap-foot>
</table-wrap>
<fig id="pcbi.1005020.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005020.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Model fit.</title>
<p> Actual (blue) and UP-predicted (grey) group-level mean proportions of information-seeking choices as a function of information cost across participants. Error bars represent SEM. N = 40.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.g003" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005020.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005020.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Individual-participant model fits.</title>
<p>(A) Actual informative choice proportion, denoted Pr(Info) (horizontal axis) versus informative choice proportion as predicted by the UP model (vertical axis). Each circle indicates one participant. Euclidean distance from the diagonal (grey line) represents error in prediction. (B) Actual informative choice proportion (horizontal axis) versus informative choice proportion as predicted by the EVI model (vertical axis). Each circle indicates one participant. Euclidean distance from the diagonal (grey line) represents error in prediction. Across all participants, the EVI systematically under-predicted informative choice proportions (all participants fell below the diagonal).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.g004" xlink:type="simple"/>
</fig>
<p>Furthermore, we found that the best-fitting values of the UP’s scaling parameter <italic>k</italic> were greater than zero across participants (Wilcoxon signed-rank test: <italic>Z</italic> = 5.51, <italic>p</italic> &lt; .001) and, in addition, were strongly correlated with overall proportion of information-seeking choices across participants (Spearman’s rho = 0.95, <italic>p</italic> &lt; .001). This indicates that participants with a stronger aversion to uncertainty (higher <italic>k</italic> values) assigned a greater intrinsic value to information, and therefore made more information-seeking choices (see also <italic>SI</italic> section 1 for individual parameter estimates and parameter-behaviour correlations). Although unsurprising given the structural design of the UP model, the strength of this relationship serves to demonstrate that the UP model parameter designed to capture individual differences in information preference succeeded in doing so.</p>
<p>In addition, since the UP model’s implementation of intrinsic valuation of information assumes that aversion to uncertainty is a stable trait of participants, a secondary prediction of this model is that information’s intrinsic value ought to be stable across time for each participant. In order to test this prediction, we calculated information choice proportion separately in each of the seven experimental blocks in Experiment 1, and assessed the effect of block number on information preference using a 4×7 repeated-measures ANOVA with within-subjects factors of information cost (0, 1, 3, 5 cents) and task block (1 to 7). We found no significant main effect of task block on information choice proportion (F(3, 117.37) = 1.73, <italic>p</italic> = .16) and no significant interaction between task block and information cost (<italic>F</italic>(9.58, 373.59) = 1.05, <italic>p</italic> = .40). These results indicate that informative stimulus choice proportions did not differ significantly across the task (see <xref ref-type="fig" rid="pcbi.1005020.g005">Fig 5</xref>), as predicted by the UP model.</p>
<fig id="pcbi.1005020.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005020.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Block-wise behavioural results for Experiment 1.</title>
<p>Mean proportion of information-seeking choices, denoted <italic>Pr(Info)</italic>, as a function of information cost and block number across participants. Choice proportions for blocks one to seven are presented in ascending order left to right within each of the four cost conditions. Error bars represent SEM. Preference for information was static across the task.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.g005" xlink:type="simple"/>
</fig>
<p>Finally, we performed an additional control analysis to ensure that the relative advantage of the UP model relative to the EVI model was not simply due to its better performance in the zero-cost condition. To this end, we repeated the model-fitting procedure while excluding all trials in the zero-cost condition (that is, the models were fit solely on the basis of the 1, 3, and 5-cent cost conditions). Once again, we found that the UP model (BIC = 718.31) provided a significantly better fit to data than the EVI model (BIC = 1031.60; likelihood ratio test: χ<sup>2</sup>(40) = 489.88, <italic>p</italic> &lt; .001). This indicates that the UP model, which incorporated intrinsic valuation of information, outperformed the EVI model even when zero-cost trials were excluded from analysis.</p>
</sec>
<sec id="sec005">
<title>The effect of information rate on preference for information</title>
<p>A logical consequence of intrinsic valuation of information is that the temporal profile of uncertainty ought to affect participants’ preference for observing an informative stimulus. In particular, the same amount of information should have a different value to participants depending on the rate at which it resolves uncertainty. In Experiment 2, we tested this prediction among a new sample of participants. In Experiment 2, cards could be revealed at a rate of either 1, 3 or 5 seconds per card in each trial, instead of a constant rate of 3 seconds per card as in Experiment 1.</p>
<p>Participants in Experiment 2 made information-seeking choices on 42.89 percent of trials (<italic>SD</italic> = 24.72), indicating comparable task performance to Experiment 1. Participants showed good levels of task engagement, with low levels of missed responses (<italic>M</italic> = 1.11 percent, <italic>SD</italic> = 1.87). On average, participants sacrificed 2.75 percent of available winnings in exchange for early information about the lottery outcome (<italic>SD</italic> = 3.49). A 4×3 repeated-measures ANOVA was used to assess the effect of information cost (0, 1, 3, 5 cents) and information rate (1, 3, 5 seconds per card) on information-seeking choice proportions. The significant main effect of information cost on information-seeking choice proportions was replicated, (<italic>F</italic>(1.86, 72.70) = 84.16, <italic>p</italic> &lt; .001; partial <italic>η</italic><sup>2</sup> = 0.68), and, crucially, we also found a significant main effect of information rate on information-seeking choice proportions (<italic>F</italic>(2, 78) = 3.60, <italic>p &lt;</italic> .05; partial <italic>η</italic><sup>2</sup> = 0.08; see <xref ref-type="fig" rid="pcbi.1005020.g006">Fig 6</xref>). This indicates that behaviour was modulated by the rate as well as the cost of information, though the effect size of information rate was substantially smaller than the effect size of information cost. There was no significant interaction between information cost and information rate (<italic>F</italic>(6, 234) = 1.85, <italic>p</italic> = .09) although there was a non-significant trend for the effect of information rate to be larger in the positive cost conditions (1, 3, and 5 cents) than in the zero-cost condition.</p>
<fig id="pcbi.1005020.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005020.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Behavioural results for Experiment 2.</title>
<p>Mean proportion of informative stimulus choices (denoted <italic>Pr(Info)</italic>) as a function of information cost and information rate. Light blue bars represent the fast speed condition, medium blue bars the moderate speed condition, and dark blue bars the slow rate conditions. Error bars represent SEM. Proportions of information-seeking choices decreased as information rate slowed, particularly for positive information cost conditions (costs of 1, 3, and 5 cents). N = 40.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.g006" xlink:type="simple"/>
</fig>
<p>One potential explanation of this effect is that participants may have preferred sooner rather than later resolution of uncertainty. To explore this possibility, we formulated and compared additional computational models assuming temporal discounting of future states. For most participants, these models did not provide a better fit to data than the undiscounted UP and EVI models. However, the degree to which participants discounted future information was associated with individual differences in the effect size of information rate (see <xref ref-type="supplementary-material" rid="pcbi.1005020.s003">S3 Text</xref>).</p>
</sec>
</sec>
<sec id="sec006" sec-type="conclusions">
<title>Discussion</title>
<p>Participants in the present study consistently preferred an informative stimulus to a perceptually equivalent non-informative stimulus, despite the fact that information could not be used to improve future outcomes. Moreover, in many cases participants were willing to sacrifice future monetary reward in exchange for this early but non-instrumental information. Since the non-informative stimulus was always of equal or greater expected monetary reward, this pattern of results strongly suggests that participants assigned an intrinsic value to information. This stands in contrast to predictions of instrumental theories of information valuation based on expected reward maximization [<xref ref-type="bibr" rid="pcbi.1005020.ref010">10</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref012">12</xref>], but is consistent with the preference for early resolution of uncertainty posited by decision theory [<xref ref-type="bibr" rid="pcbi.1005020.ref016">16</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref018">18</xref>], and with the behavioural sensitivity to information gain proposed by active inference [<xref ref-type="bibr" rid="pcbi.1005020.ref019">19</xref>]. Although it has previously been conjectured that intrinsic valuation of information may result in willingness to pay for payoff-irrelevant information [<xref ref-type="bibr" rid="pcbi.1005020.ref027">27</xref>], this effect has not previously been demonstrated in humans using a well-controlled cognitive task.</p>
<p>We found that the UP model, a novel computational model of information seeking, provided a good account of intrinsic valuation of information by assuming that preference for information resulted from aversion to temporally prolonged uncertainty [<xref ref-type="bibr" rid="pcbi.1005020.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref028">28</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref030">30</xref>]. Notably, we found that the model was able to capture individual differences in strength of information preference across participants, as well as providing a good account of group-level results. It is important to note that aversion to temporally prolonged uncertainty as implemented in the UP model is mathematically and conceptually distinct from the economic concept of risk aversion [<xref ref-type="bibr" rid="pcbi.1005020.ref032">32</xref>]. Risk aversion as commonly understood cannot predict the preference for information exhibited by participants in the present task, since at the point of choice informative and non-informative stimuli were associated with identical outcome probabilities, and differed only in the rate at which outcome uncertainty was resolved. Similarly, although the informative stimulus was associated with reduced payoff variance in non-zero cost conditions, a simple mean-variance tradeoff [<xref ref-type="bibr" rid="pcbi.1005020.ref033">33</xref>] does not provide a coherent account of preference for information either, since participants’ information preference was strongest in the zero-cost condition, where both mean and variance of payoffs were identical for the two stimuli. Notwithstanding this result, however, we also found that the UP model fit data well even when trials in the zero-cost condition were excluded from analysis, thus giving us confidence that participants assigned an intrinsic value to information in both zero and non-zero information cost conditions.</p>
<p>Furthermore, consistent with the theory that information valuation is a stable trait-level feature of individuals, we found that information preference was stable across time within the task. This would not have been expected if, for instance, participants only sought information in order to learn payoff contingencies in early blocks of the task. In addition, we found that preference for information was modulated by the rate at which uncertainty was resolved, such that participants exhibited a stronger preference for non-instrumental information when information was delivered at a faster rate. This result is analogous to the preference for faster monetary reward rate in choice behaviour [<xref ref-type="bibr" rid="pcbi.1005020.ref034">34</xref>]. Moreover, although the effect of information rate cannot be directly captured within the UP model, the direction of the information rate effect is consistent with discounting of future information, analogous to the temporal discounting of future rewards in human judgment and decision making [<xref ref-type="bibr" rid="pcbi.1005020.ref035">35</xref>]. As such, the results of the present study are in line with the proposal that humans treat information as though it has an intrinsic reward value commensurable with (and perhaps encoded in the same neural circuits as) primary and monetary reward [<xref ref-type="bibr" rid="pcbi.1005020.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref022">22</xref>]. However, we also note that the results of Experiment 2 demonstrated a relatively small effect size of information rate; future research should therefore further investigate the nature and robustness of this effect.</p>
<p>Participants in the present study sacrificed future monetary reward in exchange for early but payoff-irrelevant information. This behaviour, which is suboptimal from the perspective of expected reward maximization, has previously been observed in pigeons and starlings [<xref ref-type="bibr" rid="pcbi.1005020.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref008">8</xref>]. In the present study we present for the first time a well-controlled cognitive paradigm with which to assess this behaviour in humans. We note that previous studies in human participants have reported results generally consistent with a willingness to pay for early resolution of uncertainty, such as a greater preference for a risky lottery whose uncertainty was resolved immediately relative to an equivalent lottery whose uncertainty was resolved gradually [<xref ref-type="bibr" rid="pcbi.1005020.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref037">37</xref>], and a willingness to pay for immediate resolution of uncertainty rather than a 50 percent probability of delayed resolution of uncertainty [<xref ref-type="bibr" rid="pcbi.1005020.ref038">38</xref>]. Among cognitive studies explicitly assessing the value of non-instrumental information, Pierson &amp; Goodman (2014) found that participants self-reported a willingness to pay for non-instrumental information [<xref ref-type="bibr" rid="pcbi.1005020.ref039">39</xref>]. However, this behaviour was only assessed using a hypothetical survey task, which may have confounded results given the well-documented disparity in behaviour between hypothetical and incentive-compatible choice tasks [<xref ref-type="bibr" rid="pcbi.1005020.ref040">40</xref>]. Separately, a behavioural economic study using an incentive-compatible task concluded that observing non-instrumental information was related not to intrinsic valuation of information <italic>per se</italic>, but to a desire to increase one’s post-hoc confidence regarding an earlier decision [<xref ref-type="bibr" rid="pcbi.1005020.ref041">41</xref>]. This explanation predicts that participants will only seek non-instrumental information if it provides feedback on an earlier decision. Our results are inconsistent with this explanation, since no such decision was present in the task used in the present study. The strength of our conclusions is based on a well-controlled task in which informative and non-informative stimuli were perceptually identical, and in which preferences for information were elicited in a fully incentive-compatible fashion.</p>
<p>The results of the present study are also conceptually consistent with the preference for early resolution of uncertainty described in economic decision theory by the Kreps-Porteus model [<xref ref-type="bibr" rid="pcbi.1005020.ref016">16</xref>], and used to account for anomalous patterns of stock pricing in finance by Epstein and Zin [<xref ref-type="bibr" rid="pcbi.1005020.ref018">18</xref>]. Our empirical and computational findings complement these theories: whereas the Kreps-Porteus model demonstrates that preference for early resolution of uncertainty is a consequence of a particular formulation of recursive utility, in the present study we present a cognitive process model which provides a psychologically plausible account of information-seeking behaviour. Specifically, our results provide evidence that information seeking may result from an aversion to temporally prolonged uncertainty [<xref ref-type="bibr" rid="pcbi.1005020.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref028">28</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref030">30</xref>]. One interesting finding in this respect was that there was a negative correlation across participants between the UP model’s information preference parameter <italic>k</italic> and its response stochasticity parameter <italic>β</italic>. This correlation was such that participants who assigned a stronger intrinsic value to information also tended to exhibit greater response stochasticity. This relationship is of theoretical interest, since it has been proposed that information-seeking behaviour may result from high levels of response stochasticity in exploration-exploitation dilemmas (e.g. [<xref ref-type="bibr" rid="pcbi.1005020.ref025">25</xref>], but see also [<xref ref-type="bibr" rid="pcbi.1005020.ref042">42</xref>]), or via <italic>ε</italic>-greedy action selection methods in reinforcement learning [<xref ref-type="bibr" rid="pcbi.1005020.ref043">43</xref>]. Although the superior goodness-of-fit of the UP model in the present study clearly indicates that response stochasticity alone cannot account for participants’ information-seeking choices, the correlation between <italic>k</italic> and <italic>β</italic> raises the interesting possibility that intrinsic valuation of information and response stochasticity may make separable but related contributions to exploratory behaviours. Under this hypothesis, the <italic>k</italic> parameter would correspond to directed exploration, a goal-directed process aimed specifically at reducing uncertainty, whereas the <italic>β</italic> parameter would correspond to a more diffuse form of undirected exploration. Future research should further investigate this hypothesis.</p>
<p>However, it is also important to note that behaviour could also be explained by an appetitive drive for information as well as an aversion to uncertainty. Because, according to information theory, uncertainty and information are mathematical conjugates [<xref ref-type="bibr" rid="pcbi.1005020.ref044">44</xref>], aversion to uncertainty makes similar behavioural predictions to an appetitive desire for information. Accordingly, it is possible to reparametrise the UP model to explain behaviour in terms of an information value bonus, rather than an uncertainty penalty, with equivalent behavioural predictions. As such, behavioural data alone may not be sufficient to distinguish between behaviour driven by uncertainty aversion and behaviour driven by an appetitive desire for information. One possibility for future research is that, since appetitive and aversive stimuli are processed in distinct neural circuits [<xref ref-type="bibr" rid="pcbi.1005020.ref045">45</xref>], it may be possible to use neural recordings to disentangle these two potential cognitive mechanisms for information valuation.</p>
<p>In accounting for the results of the present study we have primarily drawn upon theories proposing that intrinsic valuation of information can result from an aversion to temporally prolonged uncertainty [<xref ref-type="bibr" rid="pcbi.1005020.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref028">28</xref>–<xref ref-type="bibr" rid="pcbi.1005020.ref030">30</xref>]. However, alternative theoretical frameworks can also account for the present study’s results in terms of a positive information bonus (consistent with an alternate parametrisation of the UP model described below). For instance, it has been proposed that agents may derive utility from maintaining an internal model of the environment which is well-adapted to the statistics of natural stimuli [<xref ref-type="bibr" rid="pcbi.1005020.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref047">47</xref>]. A natural consequence of this model is that agents should place a non-zero value on information about the external environment, even when no behaviour can be directly conditioned on this information (for instance, an intrinsic curiosity reward, as proposed by Schmidhuber, 2009 [<xref ref-type="bibr" rid="pcbi.1005020.ref048">48</xref>]). Similar intuitions regarding the appetitive value of information have been formalised in several general theories of cognition, including active inference theory [<xref ref-type="bibr" rid="pcbi.1005020.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1005020.ref047">47</xref>] and optimal Bayesian exploration [<xref ref-type="bibr" rid="pcbi.1005020.ref049">49</xref>]. Such theories can be extended to account for seemingly paradoxical attitudes towards information in other settings, such as participants’ preference for maximising entropy over choice options as well as simply maximising expected reward [<xref ref-type="bibr" rid="pcbi.1005020.ref050">50</xref>], as well as seemingly paradoxical patterns of self-deception in financial choices [<xref ref-type="bibr" rid="pcbi.1005020.ref051">51</xref>]. At a neurocomputational level, appetitive valuation of information is also consistent with the notion of dopaminergic novelty or exploration bonuses [<xref ref-type="bibr" rid="pcbi.1005020.ref052">52</xref>].</p>
<p>Notwithstanding the above, however, a further possibility proposed by Beierholm and Dayan (2010) is that an apparent preference for informative stimuli might, in fact, be driven by task disengagement, leading to a relatively greater decrease in the subjective value of the non-informative stimulus [<xref ref-type="bibr" rid="pcbi.1005020.ref053">53</xref>]. The paradigm tested in the present study sought to prevent such task disengagement by means of pseudo-randomly occurring ‘catch trials’, in which participants were required to make a rapid button-press response to one of the cards in either the informative or the non-informative stimulus. This manipulation helped to ensure that participants maintained task engagement even when observing the non-informative stimulus. Although this cannot conclusively rule out the possibility that participants were somewhat more engaged by the informative than the non-informative stimulus, it does ensure that participants could not fully disengage from the task during observation of non-informative stimuli. Moreover, the behavioural paradigm that we tested allows for well-controlled manipulation of task engagement: by increasing or decreasing the frequency of catch trials, it should be possible to manipulate the degree to which participants disengage during viewing of the non-informative stimulus. The Beierholm and Dayan model makes the empirical prediction, which could be tested in future research, that information preference ought to be strongest for greater degrees of task disengagement (that is, low catch trial frequency), and that information preference ought to decrease in strength with increasing catch trial frequency.</p>
<p>These theoretical caveats notwithstanding, the results of the present study provide clear behavioural evidence that human participants derive utility from non-instrumental information in a manner inconsistent with traditional models of information valuation. The behavioural task assessed in the present study provides a well-controlled means for assessing intrinsic valuation of non-instrumental information, and the UP model allows for individual differences in the strength of information valuation to be quantified in a principled and mathematically tractable fashion.</p>
<p>Since intolerance of uncertainty has been proposed as a trans-diagnostic treatment marker for emotional disorders [<xref ref-type="bibr" rid="pcbi.1005020.ref054">54</xref>], understanding information-seeking behaviours may shed light on the symptomatology of disorders including generalised anxiety disorder and obsessive compulsive disorder [<xref ref-type="bibr" rid="pcbi.1005020.ref055">55</xref>]. For instance, the compulsive checking behaviours which are a hallmark of obsessive compulsive disorder may represent a form of pathological information-seeking behaviour. From this perspective, it might be possible to redescribe some behavioural features of obsessive compulsive disorder as an excessive intrinsic valuation of information driven by excessive levels of aversion to uncertainty. As such, we would hypothesise that individuals with obsessive compulsive disorder would exhibit a high willingness to pay for non-instrumental information in the task used in the present study.</p>
<p>The results of the present study also have bearing on studies of the exploration-exploitation dilemma, in which participants trade off information seeking and reward seeking [<xref ref-type="bibr" rid="pcbi.1005020.ref025">25</xref>]. A common finding in this literature is that participants seek out more information than is optimal [<xref ref-type="bibr" rid="pcbi.1005020.ref026">26</xref>]. Our results may help shed light on this finding: intrinsic valuation of information may cause participants to place a premium on information, resulting in a valuation of information in excess of its purely instrumental value. More broadly, we note that although preference for information in the present task was suboptimal from the restricted perspective of monetary reward maximisation, intrinsic valuation of information may be adaptive in more naturalistic environments. Choices in natural settings often resemble dynamic constrained optimisation problems, in that organisms are presented with epistemic uncertainty and poorly defined action-outcome contingencies. In these environments, the instrumental value of seeking information may be computationally intractable, and intrinsic valuation of information might induce a bias toward gathering information that encourages exploratory behaviour even when the usefulness of that exploratory behaviour is not immediately clear. As such, intrinsic valuation of information may induce patterns of behaviour akin to an exploration or novelty bonus [<xref ref-type="bibr" rid="pcbi.1005020.ref052">52</xref>]. Therefore, in dynamic and uncertain environments intrinsic valuation of information may be associated with profound long-run benefit, in spite of locally suboptimal outcomes in artificial task environments such as that employed by the present study. More broadly, we do not propose that there exists any single level of intrinsic information valuation that will produce optimal behaviour across all environmental conditions. For instance, a strong intrinsic valuation of information may be beneficial when exploration costs are low and overall uncertainty is high, but result in suboptimal performance in situations where exploration is relatively expensive, or where overall environmental uncertainty is low.</p>
<p>In summary, our results provide strong evidence for intrinsic valuation of information in humans, and we present a novel cognitive process model which suggests that aversion to prolonged uncertainty may be an important psychological determinant of this value. We show that intrinsic valuation of information can result in seemingly suboptimal behaviours, such as a willingness to sacrifice future monetary reward in exchange for immediate but unusable information about relevant future outcomes. More broadly, our results provide a plausible psychological mechanism for human curiosity and exploration, and may explain features of decision making under uncertainty that have hitherto been considered irrational.</p>
</sec>
<sec id="sec007" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="sec008">
<title>Participants</title>
<p>Participants were staff and students of the University of Melbourne. In Experiment 1, we recruited forty-one participants (15 male, 26 female; 40 right-handed, 1 left-handed), aged 18 to 31 (<italic>M</italic> = 22.28, <italic>SD</italic> = 2.63). In Experiment 2, we recruited 40 participants (14 male, 26 female; all right-handed) aged 18 to 32 (<italic>M</italic> = 22.90, <italic>SD</italic> = 4.04). Participants gave voluntary informed consent, research was conducted in accordance with the Declaration of Helsinki, and protocols were approved by the University of Melbourne Human Research Ethics Committee (ID 1341084). As compensation for participation, participants received a flat payment of AUD $10 plus all lottery winnings (lottery winnings in Experiment 1: <italic>M</italic> = $9.10, <italic>SD</italic> = $1.86; Experiment 2: <italic>M</italic> = $7.15, <italic>SD</italic> = $0.91).</p>
</sec>
<sec id="sec009">
<title>Procedure</title>
<p>Stimuli were presented using the Psychophysics Toolbox [<xref ref-type="bibr" rid="pcbi.1005020.ref056">56</xref>] and MATLAB R2012b (The Mathworks, Natick, MA) on a Macintosh Mini connected to an LCD monitor with resolution 1920×1080 pixels at a screen refresh rate of 60Hz.</p>
<p>Experiment 1 comprised seven blocks, each consisting of sixteen trials total: four trials in each of the four cost conditions (0, 1, 3, 5 cents), with win probabilities pseudo-randomised to ensure that win rates for each cost condition were identical. As is standard practice in computational modelling studies, participants were randomly assigned to one of four pre-generated trial sequences. Participants completed the task in approximately 1 hour. In Experiment 2, the rate at which cards were revealed differed between blocks. In each block, information could be revealed at a rate of either 1, 3, or 5 seconds per card. As such, the lottery delay period varied across blocks (6 seconds total in 1 sec/card blocks, 18 seconds for 3 sec/card blocks, 30 seconds for 5 sec/card blocks). Participants completed 6 blocks of 12 trials each. Each participant was assigned to one of three counterbalanced trial orders, in which no two adjacent blocks belonged to the same information rate condition. Participants completed the task in approximately forty minutes. The primary dependent variable <italic>Pr(Info)</italic> was the proportion of all choices (excluding missed responses) in which participants elected to observe the informative stimulus.</p>
<p>To ensure that participants maintained task engagement and attended to each stimulus type equally, approximately 10 per cent of all trials were designated as <italic>catch trials</italic>. In catch trials, instead of revealing a black or red card, one of the cards was revealed to be a white X, to which participants responded by pressing any key within 1.5 seconds. A successful response led to progression to the subsequent trial without penalty; failure to respond resulted in a $1 penalty. Participants who failed to respond to more than two catch trials across the experiment were excluded from all further analyses. This resulted in the exclusion of one participant in Experiment 1 (successful catch trial responses in Experiment 1: <italic>M</italic> = 96.88%, <italic>SD</italic> = 5.56%; Experiment 2: <italic>M</italic> = 97.5%, <italic>SD</italic> = 5.80%). Rates of successful responses to catch trials did not differ significantly between informative and non-informative stimuli (Experiment 1: <italic>t</italic>(37) = 0.74, <italic>p</italic> = .46; Experiment 2: <italic>t</italic>(37) = 0.61. <italic>p</italic> = .55). There is therefore no evidence to suggest that participants’ catch trial performance differed as a function of stimulus type.</p>
</sec>
<sec id="sec010">
<title>Computational models</title>
<p>Models represented the task as an MDP, in which each trial was a decision problem with two actions (informative/non-informative stimuli), discrete states corresponding to different configurations of red and black cards (see <xref ref-type="fig" rid="pcbi.1005020.g007">Fig 7</xref>), and state transition probabilities corresponding to relative probabilities of red/black cards. Using dynamic programming, we calculated the action value of observing each of the two stimuli under varying assumptions about the nature of valuation, and used these action values to predict choice proportions. Competing models used identical MDP task representations, and differed only in the definition of the equation used to calculate action values.</p>
<fig id="pcbi.1005020.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005020.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Trial structure represented as a Markov Decision Process.</title>
<p>Open circles represent states, filled circles represent actions, and squares represent terminal (trial-end) states. Lines connecting states represent state transitions; implicit in the above representation is that where no lines connect two states, the transition probability between these states is zero. Participants begin each trial in the topmost state, and can make one of two actions: to observe the informative signal (left filled circle), or to observe the non-informative signal (right filled circle). Following this choice, participants move stochastically through one of two state trees, representing the two signal types. Within each tree, transition probabilities are defined by the relative probabilities of drawing black and red cards (transitions represented respectively by black and red lines). State transitions which do not involve drawing a card are indicated in grey. The structure of the two signal trees is identical, with the exception that in the informative signal tree, each of the six states which can result after all cards are drawn (bottom row of circles) transitions to one of the two possible lottery outcomes (win/loss) with probability 1. In the non-informative signal tree, states after all cards are drawn may transition to either of the two possible outcomes.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.g007" xlink:type="simple"/>
</fig>
<p>The information seeking task used in the present study can be formally characterised as follows: in each trial <italic>x</italic>, participants chose an action <italic>a</italic><sub><italic>x</italic></sub> from the set <italic>A</italic> = {<italic>I</italic>, <italic>N</italic>}, where <italic>I</italic> denotes a choice to observe the informative signal and <italic>N</italic> denotes a choice to observe the non-informative signal. The outcome of each trial was denoted <italic>y</italic><sub><italic>x</italic></sub> and could be either a win, <italic>y</italic><sub><italic>x</italic></sub> = 1, with probability <italic>P</italic><sub><italic>black</italic></sub>, or a loss, <italic>y</italic><sub><italic>x</italic></sub> = 0, with probability <italic>P</italic><sub><italic>red</italic></sub>. By definition, <italic>P</italic><sub><italic>red</italic></sub> = 1—<italic>P</italic><sub><italic>black</italic></sub>, and in the present study, it was always the case that <italic>P</italic><sub><italic>black</italic></sub> <italic>= P</italic><sub><italic>red</italic></sub> <italic>=</italic> 0.5. Let <italic>c</italic><sub><italic>x</italic></sub> denote the cost in cents of observing the informative signal on a given trial, drawn from the set <italic>C</italic> = {0, 1, 3, 5}. Each trial’s winnings, denoted <italic>r</italic><sub><italic>x</italic></sub>, depended only on the action selected and the predetermined outcomes of the trial lottery, such that
<disp-formula id="pcbi.1005020.e001">
<alternatives>
<graphic id="pcbi.1005020.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>20</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mo> </mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mo> </mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>20</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mo> </mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mo> </mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula></p>
<p>The task’s structure was implemented as an MDP by considering every different possible configuration of red and black cards as a separate state. This is a natural way of discretising trials of the task such that each state represents a perceptually distinct epoch within the trial. The general structure can be described as follows: depending on the action selected, a participant traverses one of two state trees, corresponding to the two signal types. As such, the two state trees are structurally identical and differ only in the sense that the final card state reached in the informative signal tree perfectly predicts whether the lottery outcome will be a win or a loss, whereas the final card state in the non-informative signal tree may transition to either outcome. Since transitions within the state trees depend on the relative likelihood of drawing red and black cards, state transitions are governed by the probabilities <italic>P</italic><sub><italic>black</italic></sub> and <italic>P</italic><sub><italic>red</italic></sub>. This structure is illustrated schematically in <xref ref-type="fig" rid="pcbi.1005020.g007">Fig 7</xref>.</p>
<p>The structure and parameters described above give a complete description of the states, actions, rewards, and state transition probabilities of the information seeking task. As a result, standard analytic techniques of MDPs can be applied to solve this decision problem. Specifically, using dynamic programming [<xref ref-type="bibr" rid="pcbi.1005020.ref057">57</xref>], it is possible to calculate the action value <italic>Q</italic> of each of the actions <italic>I</italic> and <italic>N</italic>, and to use these action values to predict choice proportions for the two actions. Each of the competing behavioural models used an identical MDP framework, and models differed only in how the action values are calculated. More precisely, in each of the models assessed, action values were calculated by solving a Bellman optimality equation, where only the definition of this equation and its free parameters varied between models. Model fitting procedures were identical for each of the models.</p>
<sec id="sec011">
<title>Expected Value of Information (EVI) model</title>
<p>The EVI model assumed that agents consider solely the instrumental value of information [<xref ref-type="bibr" rid="pcbi.1005020.ref011">11</xref>]. As such, the state value equation for this model is simply the standard recursive Bellman optimality equation for stochastic programming in MDPs [<xref ref-type="bibr" rid="pcbi.1005020.ref057">57</xref>]:
<disp-formula id="pcbi.1005020.e002">
<alternatives>
<graphic id="pcbi.1005020.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:munder><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mrow/></mml:munder></mml:mrow><mml:mi>a</mml:mi></mml:msub><mml:msub><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow/></mml:munder></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula></p>
<p>This equation can be interpreted as a probability-weighted sum over future rewards and states, where <italic>a</italic> represents an action taken in state <italic>s</italic>, causing a transition to a successor state <italic>s′</italic> with probability <italic>Pr</italic>(<italic>s</italic>′|<italic>s</italic>, <italic>a</italic>), with concurrent receipt of a transition reward <italic>R</italic>(<italic>s</italic>′, <italic>s</italic>, <italic>a</italic>) (corresponding to monetary payoffs in the present task). The value of the successor state <italic>s′</italic> is denoted <italic>V</italic>(<italic>s</italic>′) and is itself also calculated recursively according to <xref ref-type="disp-formula" rid="pcbi.1005020.e002">Eq 2</xref>. As such, the action-value equation for this model was simply the standard recursive Bellman optimality equation for stochastic programming in MDPs:
<disp-formula id="pcbi.1005020.e003">
<alternatives>
<graphic id="pcbi.1005020.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>Σ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>The quantity <italic>Q</italic>(<italic>a</italic>) represents the value of taking the action <italic>a</italic> in state <italic>s</italic>, causing a transition to a successor state <italic>s′</italic> with probability <italic>Pr</italic>(<italic>s</italic>′|<italic>s</italic>, <italic>a</italic>), with concurrent receipt of a transition reward <italic>R</italic>(<italic>s</italic>′, <italic>s</italic>, <italic>a</italic>) (corresponding to monetary payoffs). Note that since there was only one state in the present study from which actions could be taken (see <xref ref-type="fig" rid="pcbi.1005020.g007">Fig 7</xref>), we henceforth use the shorthand <italic>Q</italic>(<italic>a</italic>) to denote the value of the action <italic>a</italic>.</p>
<p>An implicit assumption of the EVI model is that information is only valuable to the extent that it can be used by agents to increase future expected reward; that is, agents should only seek information when it increases their expected reward. This follows from the fact that state values in <xref ref-type="disp-formula" rid="pcbi.1005020.e002">Eq 2</xref> are calculated solely on the basis of the monetary reward matrix <italic>R</italic>. In a task such as that used in the present study, where information and expected reward are orthogonal, this model predicts that participants should display no preference for information. Specifically, the EVI model’s prediction is that when there is no cost placed on observing the informative signal participants should be indifferent between the two signals, and that when any non-zero cost is placed on the informative signal, participants should prefer observing the non-informative signal.</p>
<p>In describing the task as an MDP, we have adopted a somewhat different framework for modelling the structure of the decision to standard decision analysis. However, for the model presented above, the value of observing the informative signal <italic>Q</italic>(<italic>I</italic>) closely resembles the decision-analytic quantity termed the Expected Value of Sample Information [EVSI; <xref ref-type="bibr" rid="pcbi.1005020.ref011">11</xref>]. In decision analysis, the EVSI is theoretically always non-negative, since information can either increase future expected reward (in which case EVSI &gt; 0) or not alter future expected reward (in which case EVSI = 0). In the task used in the present study, observing the informative signal had an EVSI equal to 0, since observing information could not increase future expected reward. When the cost of observing the informative signal was also considered, this meant that observing the informative signal always had a EVSI equal to zero (for <italic>c</italic> = 0), or less than zero (for <italic>c</italic> &gt; 0).</p>
</sec>
<sec id="sec012">
<title>Uncertainty Penalty (UP) model</title>
<p>The UP model was a hierarchical extension of the EVI model, and assumed that as well as seeking to maximise expected reward, agents were averse to the presence of uncertainty over time [<xref ref-type="bibr" rid="pcbi.1005020.ref029">29</xref>]. This aversion was implemented in UP model as a penalty of all states <italic>s</italic> of the MDP according to the relative probabilities of winning and losing from state <italic>s</italic>: <italic>P</italic><sub><italic>win</italic></sub>(<italic>s</italic>) and <italic>P</italic><sub><italic>loss</italic></sub>(<italic>s</italic>). We defined this penalty function <italic>H</italic>(<italic>s</italic>) to be the binary entropy function from information theory, since this function is zero in the case of complete certainty and maximal in the case of equal probabilities of winning and losing:
<disp-formula id="pcbi.1005020.e004">
<alternatives>
<graphic id="pcbi.1005020.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula></p>
<p>The state value equation for the UP model is created by incorporating this penalty function into normative value equation of the EVI model via an additional exponential term:
<disp-formula id="pcbi.1005020.e005">
<alternatives>
<graphic id="pcbi.1005020.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mi>a</mml:mi></mml:msub><mml:msub><mml:mi>Σ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula></p>
<p><xref ref-type="disp-formula" rid="pcbi.1005020.e005">Eq 5</xref> describes the value of different states in the UP model; as such, this equation is functionally equivalent to <xref ref-type="disp-formula" rid="pcbi.1005020.e002">Eq 2</xref> from the EVI model. However, these two equations differ in that <xref ref-type="disp-formula" rid="pcbi.1005020.e005">Eq 5</xref> penalises the values of successor states according to their outcome uncertainty (which, in turn, is calculated using <xref ref-type="disp-formula" rid="pcbi.1005020.e004">Eq 4</xref>). Importantly, <xref ref-type="disp-formula" rid="pcbi.1005020.e005">Eq 5</xref> allowed for the strength of the uncertainty penalty to vary between participants according to a participant-specific scaling parameter <italic>k</italic>. When <italic>k</italic> is equal to 0, the exponential term in <xref ref-type="disp-formula" rid="pcbi.1005020.e005">Eq 5</xref> is equal to one, meaning that states’ values are unaffected by outcome uncertainty; in this case, the UP model reduces to the EVI model. For <italic>k</italic> &gt; 0, an uncertainty penalty is applied to all states. Since the informative stimulus reduces uncertainty faster and in more states than the non-informative stimulus, non-informative states are penalised more heavily than informative states, inducing a preference for observing the informative stimulus. For <italic>k</italic> &lt; 0, the converse is true: an uncertainty bonus applies to all states, inducing a preference for the non-informative stimulus. The UP model therefore predicts information seeking from the fact that, although monetary reward is received at the same time for each stimulus, the informative stimulus is associated with less time spent in uncertain states. Given this framework, action values for the UP model can then be calculated as:
<disp-formula id="pcbi.1005020.e006">
<alternatives>
<graphic id="pcbi.1005020.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>Σ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula></p>
<p>As an aside, we note that although the UP model used in the present study quantifies information valuation in terms of aversion to states’ uncertainty, there exist alternative specifications of the action-value equation which can produce equivalent quantitative predictions regarding behaviour. In particular, it is possible to reparametrise <xref ref-type="disp-formula" rid="pcbi.1005020.e006">Eq 6</xref> such that intrinsic valuation of information is expressed in terms of value bonus for information, rather than an aversion to states’ uncertainty (see also Sun, Gomez &amp; Schmidhuber, 2011 [<xref ref-type="bibr" rid="pcbi.1005020.ref049">49</xref>] for a discussion of conceptual differences between information reward signals and standard reinforcement learning rewards). This is because moving from one uncertain (and therefore aversive) state to a less uncertain (and therefore less aversive) state is mathematically equivalent to receiving an information-related value bonus during the state transition. This value bonus will be equal to the amount of uncertainty which has been reduced in the transition, scaled by an individual information preference parameter:
<disp-formula id="pcbi.1005020.e007">
<alternatives>
<graphic id="pcbi.1005020.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>Σ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>.</mml:mo><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula>
where <inline-formula id="pcbi.1005020.e008"><alternatives><graphic id="pcbi.1005020.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mover accent="true"><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is a reparametrised information scaling parameter, and <italic>I</italic>(<italic>s</italic>′, <italic>s</italic>, <italic>a</italic>) is an information value bonus quantified as the difference in entropy of beliefs following a state transition, as follows:
<disp-formula id="pcbi.1005020.e009">
<alternatives>
<graphic id="pcbi.1005020.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula></p>
<p>Notwithstanding the above, all model fits and reported parameter values in the present study are calculated using the uncertainty-aversion parametrisation of the UP model (<xref ref-type="disp-formula" rid="pcbi.1005020.e006">Eq 6</xref>), not the information-bonus parametrisation (<xref ref-type="disp-formula" rid="pcbi.1005020.e007">Eq 7</xref>).</p>
</sec>
<sec id="sec013">
<title>Model fitting procedure</title>
<p>Given that the two models described above share a common MDP structure, it is possible to specify an overall choice rule and likelihood estimation procedure that is independent of how each individual model calculates action values. For every cost condition <italic>c</italic>, each of the models supplies a state-action value for observing the informative signal, <italic>Q</italic><sub><italic>c</italic></sub>(<italic>I</italic>), and a state-action value for observing the non-informative signal, <italic>Q</italic><sub><italic>c</italic></sub>(<italic>N</italic>). A mapping from these model-derived action values to informative signal choice probability can be accomplished separately for each cost condition using a “softmax” or Luce choice rule:
<disp-formula id="pcbi.1005020.e010">
<alternatives>
<graphic id="pcbi.1005020.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mi>Q</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mi>Q</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mi>Q</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>N</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
</alternatives>
<label>(9)</label>
</disp-formula></p>
<p>In this equation, <italic>β</italic> is an inverse temperature parameter, <italic>β</italic> ≥ 0, governing the determinism of choices, and is constant across different cost conditions. As the value of <italic>β</italic> increases, agents deterministically choose the action with the higher action value; for <italic>β</italic> = 0, choices are unrelated to action values, and all actions are equally likely to be selected. Applying <xref ref-type="disp-formula" rid="pcbi.1005020.e010">Eq 9</xref> with the action value of the non-informative signal in the numerator, it is also possible to show that <italic>P</italic><sub><italic>c</italic></sub>(<italic>N</italic>) = 1 –<italic>P</italic><sub>c</sub>(<italic>I</italic>).</p>
<p>All models used in the present study also included an additional parameter representing the probability of making an incorrect button press. The rationale for including this additional parameter was that during post-task debriefing, some participants who otherwise behaved in a relatively deterministic fashion reported making one or more mistaken button press because of the task’s randomised response mapping. While one practice is to account for errors of this kind by the softmax equation’s <italic>β</italic> parameter, when responses are otherwise strongly deterministic, a single mistaken button press can substantially affect model likelihood (for instance, when a participant mistakenly selects the informative signal in a condition where the model’s predicted probability of this action would otherwise have been at or near zero). To overcome this issue, choice probabilities in the models presented above were represented by a latent mixture model (<xref ref-type="fig" rid="pcbi.1005020.g008">Fig 8</xref>). In this latent mixture model it was assumed that on any given trial there was a small but non-zero probability <italic>ε</italic> that a participant would make a mistaken button press. The parameter <italic>ε</italic> was fit as a free parameter across participants. However, in order to ensure that our results were not compromised by this assumption, we also performed a control analysis assessing model fits for <italic>ε</italic> = 0, corresponding to the assumption that participants made no erroneous button presses (see <xref ref-type="supplementary-material" rid="pcbi.1005020.s002">S2 Text</xref>).</p>
<fig id="pcbi.1005020.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005020.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Latent mixture model of choice probability.</title>
<p>In the present study, choice probabilities were assumed to be a latent mixture of erroneous button presses (with probability <italic>ε</italic>) and accurate button presses (with probability 1−<italic>ε</italic>). Since erroneous button presses are by definition undirected, these choices are therefore equally likely to result in the selection of the informative signal or the non-informative signal. This has the effect of placing a floor of <inline-formula id="pcbi.1005020.e011"><alternatives><graphic id="pcbi.1005020.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mrow><mml:mfrac bevelled="true"><mml:mi>ε</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> and a ceiling of 1−<inline-formula id="pcbi.1005020.e012"><alternatives><graphic id="pcbi.1005020.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:mrow><mml:mfrac bevelled="true"><mml:mi>ε</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> on choice probabilities for each option.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.g008" xlink:type="simple"/>
</fig>
<p>Therefore, <italic>Pr</italic>(<italic>a</italic> = <italic>I</italic> | <italic>c</italic>), the overall choice probability for observing the informative set in the cost condition <italic>c</italic>, is given by simple probability calculus (note that <italic>Pr</italic>(<italic>a</italic> = <italic>I</italic> | <italic>c</italic>) = <italic>P</italic><sub><italic>c</italic></sub>(<italic>I</italic>) for <italic>ε</italic> = 0):
<disp-formula id="pcbi.1005020.e013">
<alternatives>
<graphic id="pcbi.1005020.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mo>|</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mi>ε</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ε</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(10)</label>
</disp-formula></p>
<p>Since there were only two actions available to participants on each trial, the probability <italic>Pr</italic>(<italic>a</italic> = <italic>I</italic>) can be interpreted as a binomial rate parameter. Each model’s overall likelihood can therefore be calculated as a product of binomial likelihoods across the four cost conditions in the set <italic>C</italic>:
<disp-formula id="pcbi.1005020.e014">
<alternatives>
<graphic id="pcbi.1005020.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005020.e014" xlink:type="simple"/>
<mml:math display="block" id="M14">
<mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∏</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>4</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo> </mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow>
</mml:math>
</alternatives>
<label>(11)</label>
</disp-formula>
Where <italic>n</italic><sub><italic>i</italic></sub> represents the number of trials in cost condition <italic>C</italic><sub><italic>i</italic></sub> and <italic>m</italic><sub><italic>i</italic></sub> represents the number of times the informative signal was observed in cost condition <italic>C</italic><sub><italic>i</italic>.</sub> Trials in which participants did not record a response were excluded.</p>
<p>All models were fit with maximum-likelihood estimation, using the interior point algorithm as implemented in MATLAB R2015b (The Mathworks, Natick, MA).</p>
</sec>
</sec>
</sec>
<sec id="sec014">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1005020.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>UP model parameters.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005020.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.s002" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Fit and interpretation of <italic>ε</italic> parameter.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005020.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.s003" xlink:type="simple">
<label>S3 Text</label>
<caption>
<title>Model fits for Experiment 2.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005020.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.s004" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title><italic>k</italic> parameter and behavioural data.</title>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005020.s005" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005020.s005" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title><italic>β</italic> parameter and behavioural data.</title>
<p>(TIFF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1005020.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gottlieb</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hayhoe</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hikosaka</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Rangel</surname> <given-names>A</given-names></name>. <article-title>Attention, reward, and information seeking</article-title>. <source>J Neurosci</source>. <year>2014</year>;<volume>34</volume>(<issue>46</issue>):<fpage>15497</fpage>–<lpage>504</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3270-14.2014" xlink:type="simple">10.1523/JNEUROSCI.3270-14.2014</ext-link></comment> <object-id pub-id-type="pmid">25392517</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kidd</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Hayden</surname> <given-names>BY</given-names></name>. <article-title>The psychology and neuroscience of curiosity</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>88</volume>(<issue>3</issue>):<fpage>449</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2015.09.010" xlink:type="simple">10.1016/j.neuron.2015.09.010</ext-link></comment> <object-id pub-id-type="pmid">26539887</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tversky</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kahneman</surname> <given-names>D</given-names></name>. <article-title>Advances in prospect theory: Cumulative representation of uncertainty</article-title>. <source>J Risk Uncertainty</source>. <year>1992</year>;<volume>5</volume>(<issue>4</issue>):<fpage>297</fpage>–<lpage>323</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Camerer</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Weber</surname> <given-names>M</given-names></name>. <article-title>Recent developments in modeling preferences: Uncertainty and ambiguity</article-title>. <source>J Risk Uncertainty</source>. <year>1992</year>;<volume>5</volume>(<issue>4</issue>):<fpage>325</fpage>–<lpage>70</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Platt</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Huettel</surname> <given-names>SA</given-names></name>. <article-title>Risky business: the neuroeconomics of decision making under uncertainty</article-title>. <source>Nat Neurosci</source>. <year>2008</year>;<volume>11</volume>(<issue>4</issue>):<fpage>398</fpage>–<lpage>403</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn2062" xlink:type="simple">10.1038/nn2062</ext-link></comment> <object-id pub-id-type="pmid">18368046</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gipson</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Alessandri</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>HC</given-names></name>, <name name-style="western"><surname>Zentall</surname> <given-names>TR</given-names></name>. <article-title>Preference for 50% reinforcement over 75% reinforcement by pigeons</article-title>. <source>Learn Behav</source>. <year>2009</year>;<volume>37</volume>(<issue>4</issue>):<fpage>289</fpage>–<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3758/LB.37.4.289" xlink:type="simple">10.3758/LB.37.4.289</ext-link></comment> <object-id pub-id-type="pmid">19815925</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zentall</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Stagner</surname> <given-names>J</given-names></name>. <article-title>Maladaptive choice behaviour by pigeons: an animal analogue and possible mechanism for gambling (sub-optimal human decision-making behaviour)</article-title>. <source>Philos T R Soc B</source>. <year>2011</year>;<volume>278</volume>(<issue>1709</issue>):<fpage>1203</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vasconcelos</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Monteiro</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Kacelnik</surname> <given-names>A</given-names></name>. <article-title>Irrational choice and the value of information</article-title>. <source>Sci Rep</source>. <year>2015</year>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bromberg-Martin</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Hikosaka</surname> <given-names>O</given-names></name>. <article-title>Lateral habenula neurons signal errors in the prediction of reward information</article-title>. <source>Nat Neurosci</source>. <year>2011</year>;<volume>14</volume>(<issue>9</issue>):<fpage>1209</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2902" xlink:type="simple">10.1038/nn.2902</ext-link></comment> <object-id pub-id-type="pmid">21857659</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hirshleifer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Riley</surname> <given-names>JG</given-names></name>. <article-title>The analytics of uncertainty and information-an expository survey</article-title>. <source>J Econ Lit</source>. <year>1979</year>;<volume>17</volume>(<issue>4</issue>):<fpage>1375</fpage>–<lpage>421</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref011"><label>11</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Raiffa</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Schlaifer</surname> <given-names>R</given-names></name>. <source>Applied Statistical Decision Theory</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Division of Research, Graduate School of Business Administration, Harvard University</publisher-name>; <year>1961</year>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Howard</surname> <given-names>R</given-names></name>. <article-title>Information value theory</article-title>. <source>IEEE T Syst Sci Cyb</source>. <year>1966</year>;<volume>2</volume>(<issue>1</issue>):<fpage>22</fpage>–<lpage>6</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref013"><label>13</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Berlyne</surname> <given-names>DE</given-names></name>. <source>Conflict, Arousal, and Curiosity</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>; <year>1960</year>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Litman</surname> <given-names>J</given-names></name>. <article-title>Curiosity and the pleasures of learning: Wanting and liking new information</article-title>. <source>Cognition Emotion</source>. <year>2005</year>;<volume>19</volume>(<issue>6</issue>):<fpage>793</fpage>–<lpage>814</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grant</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kajii</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Polak</surname> <given-names>B</given-names></name>. <article-title>Intrinsic preference for information</article-title>. <source>J Econ Theory</source>. <year>1998</year>;<volume>83</volume>(<issue>2</issue>):<fpage>233</fpage>–<lpage>59</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kreps</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Porteus</surname> <given-names>EL</given-names></name>. <article-title>Temporal resolution of uncertainty and dynamic choice theory</article-title>. <source>Econometrica</source>. <year>1978</year>;<volume>46</volume>(<issue>1</issue>):<fpage>185</fpage>–<lpage>200</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chew</surname> <given-names>SH</given-names></name>, <name name-style="western"><surname>Ho</surname> <given-names>JL</given-names></name>. <article-title>Hope: An empirical study of attitude toward the timing of uncertainty resolution</article-title>. <source>J Risk Uncertainty</source>. <year>1994</year>;<volume>8</volume>(<issue>3</issue>):<fpage>267</fpage>–<lpage>88</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Epstein</surname> <given-names>LG</given-names></name>, <name name-style="western"><surname>Zin</surname> <given-names>SE</given-names></name>. <article-title>Substitution, risk aversion, and the temporal behavior of consumption and asset returns: A theoretical framework</article-title>. <source>Econometrica</source>. <year>1989</year>;<volume>57</volume>(<issue>4</issue>):<fpage>937</fpage>–<lpage>69</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Schwartenbeck</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Fitzgerald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Moutoussis</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>The anatomy of choice: active inference and agency</article-title>. <source>Front Hum Neurosci</source>. <year>2013</year>;<volume>7</volume>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lanzetta</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Driscoll</surname> <given-names>JM</given-names></name>. <article-title>Preference for information about an uncertain but unavoidable outcome</article-title>. <source>J Pers Soc Psychol</source>. <year>1966</year>;<volume>3</volume>(<issue>1</issue>):<fpage>96</fpage>–<lpage>102</lpage>. <object-id pub-id-type="pmid">5902081</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perone</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Baron</surname> <given-names>A</given-names></name>. <article-title>Reinforcement of human observing behavior by a stimulus correlated with extinction or increased effort</article-title>. <source>J Exp Anal Behav</source>. <year>1980</year>;<volume>34</volume>(<issue>3</issue>):<fpage>239</fpage>–<lpage>61</lpage>. <object-id pub-id-type="pmid">16812189</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bromberg-Martin</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Hikosaka</surname> <given-names>O</given-names></name>. <article-title>Midbrain dopamine neurons signal preference for advance information about upcoming rewards</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>63</volume>(<issue>1</issue>):<fpage>119</fpage>–<lpage>26</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2009.06.009" xlink:type="simple">10.1016/j.neuron.2009.06.009</ext-link></comment> <object-id pub-id-type="pmid">19607797</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blanchard</surname> <given-names>TC</given-names></name>, <name name-style="western"><surname>Hayden</surname> <given-names>BY</given-names></name>, <name name-style="western"><surname>Bromberg-Martin</surname> <given-names>ES</given-names></name>. <article-title>Orbitofrontal cortex uses distinct codes for different choice attributes in decisions motivated by curiosity</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>85</volume>(<issue>3</issue>):<fpage>602</fpage>–<lpage>14</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.12.050" xlink:type="simple">10.1016/j.neuron.2014.12.050</ext-link></comment> <object-id pub-id-type="pmid">25619657</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kang</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Hsu</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Krajbich</surname> <given-names>IM</given-names></name>, <name name-style="western"><surname>Loewenstein</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>McClure</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>JT-y</given-names></name>, <etal>et al</etal>. <article-title>The wick in the candle of learning epistemic curiosity activates reward circuitry and enhances memory</article-title>. <source>Psychol Sci</source>. <year>2009</year>;<volume>20</volume>(<issue>8</issue>):<fpage>963</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1467-9280.2009.02402.x" xlink:type="simple">10.1111/j.1467-9280.2009.02402.x</ext-link></comment> <object-id pub-id-type="pmid">19619181</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>O'Doherty</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Cortical substrates for exploratory decisions in humans</article-title>. <source>Nature</source>. <year>2006</year>;<volume>441</volume>(<issue>7095</issue>):<fpage>876</fpage>–<lpage>9</lpage>. <object-id pub-id-type="pmid">16778890</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tversky</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Edwards</surname> <given-names>W</given-names></name>. <article-title>Information versus reward in binary choices</article-title>. <source>J Exp Psychol</source>. <year>1966</year>;<volume>71</volume>(<issue>5</issue>):<fpage>680</fpage>. <object-id pub-id-type="pmid">5939707</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Chan</surname> <given-names>S</given-names></name>. <article-title>On the value of information and other rewards</article-title>. <source>Nat Neurosci</source>. <year>2011</year>;<volume>14</volume>(<issue>9</issue>):<fpage>1095</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2918" xlink:type="simple">10.1038/nn.2918</ext-link></comment> <object-id pub-id-type="pmid">21878921</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Caplin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Leahy</surname> <given-names>J</given-names></name>. <article-title>Psychological expected utility theory and anticipatory feelings</article-title>. <source>Q J Econ</source>. <year>2001</year>:<fpage>55</fpage>–<lpage>79</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Epstein</surname> <given-names>LG</given-names></name>. <article-title>Living with risk</article-title>. <source>Rev Econ Stud</source>. <year>2008</year>;<volume>75</volume>(<issue>4</issue>):<fpage>1121</fpage>–<lpage>41</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daddaoua</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Lopes</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gottlieb</surname> <given-names>J</given-names></name>. <article-title>Intrinsically motivated oculomotor exploration guided by uncertainty reduction and conditioned reinforcement in non-human primates</article-title>. <source>Scientific Reports</source>. <year>2016</year>;<volume>6</volume>:20202.</mixed-citation></ref>
<ref id="pcbi.1005020.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Averbeck</surname> <given-names>BB</given-names></name>. <article-title>Theory of Choice in Bandit, Information Sampling and Foraging Tasks</article-title>. <source>PLoS Comp Biol</source>. <year>2015</year>;<volume>11</volume>(<issue>3</issue>):<fpage>e1004164</fpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref032"><label>32</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Von Neumann</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Morgenstern</surname> <given-names>O</given-names></name>. <source>Theory of Games and Economic Behaviour</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>; <year>1944</year>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Markowitz</surname> <given-names>H</given-names></name>. <article-title>Portfolio selection</article-title>. <source>J Financ</source>. <year>1952</year>;<volume>7</volume>(<issue>1</issue>):<fpage>77</fpage>–<lpage>91</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>. <article-title>Banburismus and the brain: decoding the relationship between sensory stimuli, decisions, and reward</article-title>. <source>Neuron</source>. <year>2002</year>;<volume>36</volume>(<issue>2</issue>):<fpage>299</fpage>–<lpage>308</lpage>. <object-id pub-id-type="pmid">12383783</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Frederick</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Loewenstein</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>O'donoghue</surname> <given-names>T</given-names></name>. <article-title>Time discounting and time preference: A critical review</article-title>. <source>Journal of Economic Literature</source>. <year>2002</year>;<volume>40</volume>(<issue>2</issue>):<fpage>351</fpage>–<lpage>401</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Luhmann</surname> <given-names>CC</given-names></name>, <name name-style="western"><surname>Chun</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Yi</surname> <given-names>D-J</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>X-J</given-names></name>. <article-title>Neural dissociation of delay and uncertainty in intertemporal choice</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>(<issue>53</issue>):<fpage>14459</fpage>–<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5058-08.2008" xlink:type="simple">10.1523/JNEUROSCI.5058-08.2008</ext-link></comment> <object-id pub-id-type="pmid">19118180</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kocher</surname> <given-names>MG</given-names></name>, <name name-style="western"><surname>Krawczyk</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>van Winden</surname> <given-names>F</given-names></name>. <article-title>‘Let me dream on!’ Anticipatory emotions and preference for timing in lotteries</article-title>. <source>J Econ Behav &amp; Org</source>. <year>2014</year>;<volume>98</volume>:<fpage>29</fpage>–<lpage>40</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brown</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>H</given-names></name>. <article-title>Do individuals have preferences used in macro-finance models? An experimental investigation</article-title>. <source>Management Science</source>. <year>2014</year>;<volume>60</volume>(<issue>4</issue>):<fpage>939</fpage>–<lpage>58</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pierson</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Goodman</surname> <given-names>N</given-names></name>. <article-title>Uncertainty and denial: a resource-rational model of the value of information</article-title>. <source>PLoS One</source>. <year>2014</year>;<volume>9</volume>(<issue>11</issue>):<fpage>e113342</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0113342" xlink:type="simple">10.1371/journal.pone.0113342</ext-link></comment> <object-id pub-id-type="pmid">25426631</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mørkbak</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Olsen</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Campbell</surname> <given-names>D</given-names></name>. <article-title>Behavioral implications of providing real incentives in stated choice experiments</article-title>. <source>J Econ Psychol</source>. <year>2014</year>;<volume>45</volume>:<fpage>102</fpage>–<lpage>16</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eliaz</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Schotter</surname> <given-names>A</given-names></name>. <article-title>Paying for confidence: An experimental study of the demand for non-instrumental information</article-title>. <source>Game Econ Behav</source>. <year>2010</year>;<volume>70</volume>(<issue>2</issue>):<fpage>304</fpage>–<lpage>24</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Speekenbrink</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Konstantinidis</surname> <given-names>E</given-names></name>. <article-title>Uncertainty and exploration in a restless bandit problem</article-title>. <source>Topics in Cognitive Science</source>. <year>2015</year>;<volume>7</volume>(<issue>2</issue>):<fpage>351</fpage>–<lpage>67</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/tops.12145" xlink:type="simple">10.1111/tops.12145</ext-link></comment> <object-id pub-id-type="pmid">25899069</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref043"><label>43</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>. <source>Reinforcement Learning: An Introduction</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>1998</year>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shannon</surname> <given-names>CE</given-names></name>. <article-title>A mathematical theory of communication</article-title>. <source>Bell Syst Tech J</source>. <year>1948</year>;<volume>27</volume>:<fpage>379</fpage>–<lpage>423</lpage>, <fpage>623</fpage>–<lpage>56</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>O'Doherty</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Koltzenburg</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Wiech</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Frackowiak</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Opponent appetitive-aversive neural processes underlie predictive learning of pain relief</article-title>. <source>Nat Neurosci</source>. <year>2005</year>;<volume>8</volume>(<issue>9</issue>):<fpage>1234</fpage>–<lpage>40</lpage>. <object-id pub-id-type="pmid">16116445</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berkes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Orbán</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Fiser</surname> <given-names>J</given-names></name>. <article-title>Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment</article-title>. <source>Science</source>. <year>2011</year>;<volume>331</volume>(<issue>6013</issue>):<fpage>83</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1195870" xlink:type="simple">10.1126/science.1195870</ext-link></comment> <object-id pub-id-type="pmid">21212356</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Ognibene</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fitzgerald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Pezzulo</surname> <given-names>G</given-names></name>. <article-title>Active inference and epistemic value</article-title>. <source>Cogn Neurosci</source>. <year>2015</year>;<volume>6</volume>(<issue>4</issue>):<fpage>1</fpage>–<lpage>28</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schmidhuber</surname> <given-names>J</given-names></name>. <article-title>Simple algorithmic theory of subjective beauty, novelty, surprise, interestingness, attention, curiosity, creativity, art, science, music, jokes</article-title>. <source>Journal of SICE</source>. <year>2009</year>;<volume>48</volume>(<issue>1</issue>):<fpage>21</fpage>–<lpage>32</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sun</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Gomez</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Schmidhuber</surname> <given-names>J</given-names></name>. <article-title>Planning to be surprised: Optimal bayesian exploration in dynamic environments</article-title>. <source>Artificial General Intelligence</source>. <year>2011</year>:<fpage>41</fpage>–<lpage>51</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwartenbeck</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>FitzGerald</surname> <given-names>TH</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kronbichler</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>. <article-title>Evidence for surprise minimization over value maximization in choice behavior</article-title>. <source>Scientific Reports</source>. <year>2015</year>;<volume>5</volume>:<fpage>16575</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/srep16575" xlink:type="simple">10.1038/srep16575</ext-link></comment> <object-id pub-id-type="pmid">26564686</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mijović-Prelec</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Prelec</surname> <given-names>D</given-names></name>. <article-title>Self-deception as self-signalling: a model and experimental evidence</article-title>. <source>Philosophical Transactions of the Royal Society of London B: Biological Sciences</source>. <year>2010</year>;<volume>365</volume>(<issue>1538</issue>):<fpage>227</fpage>–<lpage>40</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rstb.2009.0218" xlink:type="simple">10.1098/rstb.2009.0218</ext-link></comment> <object-id pub-id-type="pmid">20026461</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kakade</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Dopamine: generalization and bonuses</article-title>. <source>Neural Networks</source>. <year>2002</year>;<volume>15</volume>(<issue>4</issue>):<fpage>549</fpage>–<lpage>59</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005020.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beierholm</surname> <given-names>UR</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Pavlovian-instrumental interaction in ‘observing behavior’</article-title>. <source>PLoS Comput Biol</source>. <year>2010</year>;<volume>6</volume>(<issue>9</issue>):<fpage>e1000903</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000903" xlink:type="simple">10.1371/journal.pcbi.1000903</ext-link></comment> <object-id pub-id-type="pmid">20838580</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boswell</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Thompson-Hollands</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Farchione</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Barlow</surname> <given-names>DH</given-names></name>. <article-title>Intolerance of uncertainty: A common factor in the treatment of emotional disorders</article-title>. <source>J Clin Psychol</source>. <year>2013</year>;<volume>69</volume>(<issue>6</issue>):<fpage>630</fpage>–<lpage>45</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/jclp.21965" xlink:type="simple">10.1002/jclp.21965</ext-link></comment> <object-id pub-id-type="pmid">23381685</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lind</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Boschen</surname> <given-names>MJ</given-names></name>. <article-title>Intolerance of uncertainty mediates the relationship between responsibility beliefs and compulsive checking</article-title>. <source>J Anxiety Disord</source>. <year>2009</year>;<volume>23</volume>(<issue>8</issue>):<fpage>1047</fpage>–<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.janxdis.2009.07.005" xlink:type="simple">10.1016/j.janxdis.2009.07.005</ext-link></comment> <object-id pub-id-type="pmid">19656653</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brainard</surname> <given-names>DH</given-names></name>. <article-title>The psychophysics toolbox</article-title>. <source>Spatial Vision</source>. <year>1997</year>;<volume>10</volume>:<fpage>433</fpage>–<lpage>6</lpage>. <object-id pub-id-type="pmid">9176952</object-id></mixed-citation></ref>
<ref id="pcbi.1005020.ref057"><label>57</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Bertsekas</surname> <given-names>DP</given-names></name>. <source>Dynamic Programming and Stochastic Control</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Academic Press</publisher-name>; <year>1976</year>.</mixed-citation></ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="publisher">pbio</journal-id><journal-id journal-id-type="flc">plbi</journal-id><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="doi">10.1371/journal.pbio.0040387</article-id><article-id pub-id-type="publisher-id">06-PLBI-RA-1003R2</article-id><article-id pub-id-type="sici">plbi-04-12-12</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Evolutionary Biology/Animal Behavior</subject>
          <subject>Evolutionary Biology</subject>
          <subject>Neuroscience</subject>
        </subj-group>
        <subj-group subj-group-type="System Taxonomy">
          <subject>None</subject>
        </subj-group>
      </article-categories><title-group><article-title>How Behavioral Constraints May Determine Optimal Sensory Representations</article-title><alt-title alt-title-type="running-head">Optimal Sensory Tuning Curves and Behavior</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Salinas</surname>
            <given-names>Emilio</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
        </contrib>
      </contrib-group><aff id="aff1">
        <label>1</label><addr-line>
        
      Department of Neurobiology and Anatomy, Wake Forest University School of Medicine, Winston-Salem, North Carolina, United States of America</addr-line></aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Abbott</surname>
            <given-names>Larry</given-names>
          </name>
          <role>Academic Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Columbia University, United States of America</aff><author-notes>
        <corresp id="cor1">E-mail: <email xlink:type="simple">esalinas@wfubmc.edu</email></corresp>
      <fn fn-type="conflict" id="ack3">
        <p>The author has declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="ppub">
        <month>12</month>
        <year>2006</year>
      </pub-date><pub-date pub-type="epub">
        <day>28</day>
        <month>11</month>
        <year>2006</year>
      </pub-date><volume>4</volume><issue>12</issue><elocation-id>e387</elocation-id><history>
        <date date-type="received">
          <day>12</day>
          <month>6</month>
          <year>2006</year>
        </date>
        <date date-type="accepted">
          <day>15</day>
          <month>9</month>
          <year>2006</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2006</copyright-year><copyright-holder>Emilio Salinas</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article page="e429" related-article-type="companion" vol="4" xlink:href="info:doi/10.1371/journal.pbio.0040429" xlink:title="Synopsis" xlink:type="simple">
				<article-title>For Some Sensory Neurons, Motor Response Shapes Their Output</article-title>
			</related-article><abstract>
        <p>The sensory-triggered activity of a neuron is typically characterized in terms of a tuning curve, which describes the neuron's average response as a function of a parameter that characterizes a physical stimulus. What determines the shapes of tuning curves in a neuronal population? Previous theoretical studies and related experiments suggest that many response characteristics of sensory neurons are optimal for encoding stimulus-related information. This notion, however, does not explain the two general types of tuning profiles that are commonly observed: unimodal and monotonic. Here I quantify the efficacy of a set of tuning curves according to the possible downstream motor responses that can be constructed from them. Curves that are optimal in this sense may have monotonic or nonmonotonic profiles, where the proportion of monotonic curves and the optimal tuning-curve width depend on the general properties of the target downstream functions. This dependence explains intriguing features of visual cells that are sensitive to binocular disparity and of neurons tuned to echo delay in bats. The numerical results suggest that optimal sensory tuning curves are shaped not only by stimulus statistics and signal-to-noise properties but also according to their impact on downstream neural circuits and, ultimately, on behavior.</p>
      </abstract><abstract abstract-type="toc">
        <p>A quantitative theoretical approach demonstrates how optimal sensory tuning curves are shaped not only by stimulus statistics and signal-to-noise properties, but also according to their impact on downstream neural circuits and behavior. </p>
      </abstract><funding-group><funding-statement>Research was partially supported by the National Institute of Neurological Disorders and Stroke grant NS044894.</funding-statement></funding-group><counts>
        <page-count count="10"/>
      </counts><!--===== Restructure custom-meta-wrap to custom-meta-group =====--><custom-meta-group>
        <custom-meta>
          <meta-name>citation</meta-name>
          <meta-value>Salinas E (2006) How behavioral constraints may determine optimal sensory representations. PLoS Biol 4(12): e387. DOI: <ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0040387" xlink:type="simple">10.1371/journal.pbio.0040387</ext-link></meta-value>
        </custom-meta>
      </custom-meta-group></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Sensory neurons respond to physical stimuli, and this relationship is often quantified by plotting their evoked activity—for instance, the mean firing rate—as a function of a relevant stimulus parameter. The resulting response functions or tuning curves have been the subject of much theoretical work, particularly relating to vision. In trying to understand such tuning curves, the emphasis has been on information maximization, the main idea being that sensory neurons should represent the sensory world as accurately and efficiently as possible [<xref ref-type="bibr" rid="pbio-0040387-b001">1</xref>–<xref ref-type="bibr" rid="pbio-0040387-b003">3</xref>]. This principled approach, known as the efficient coding hypothesis, has been extremely successful at predicting the receptive field properties of neurons in early visual [<xref ref-type="bibr" rid="pbio-0040387-b004">4</xref>–<xref ref-type="bibr" rid="pbio-0040387-b007">7</xref>] and auditory [<xref ref-type="bibr" rid="pbio-0040387-b008">8</xref>,<xref ref-type="bibr" rid="pbio-0040387-b009">9</xref>] areas, and it is consistent with numerous experimental observations [<xref ref-type="bibr" rid="pbio-0040387-b010">10</xref>–<xref ref-type="bibr" rid="pbio-0040387-b013">13</xref>].</p>
      <p>However, information maximization is not enough. Such a principle cannot completely account for the response characteristics of cortical neurons, particularly beyond early sensory areas, because it does not consider how the encoded information will be used, if at all. It would not make sense for sensory neurons to pack a lot of information into parts of feature space that are of little relevance to the animal. A recent study [<xref ref-type="bibr" rid="pbio-0040387-b014">14</xref>] investigating auditory responses in grasshoppers illustrates this. Primary auditory receptors in grasshoppers do not respond equally well to different types of environmental sounds. Instead, the stimulus ensemble that maximizes their information rate consists of short segments of grasshopper songs that mark the transitions between song syllables [<xref ref-type="bibr" rid="pbio-0040387-b014">14</xref>]. Thus, such early receptor neurons seem to be highly specialized for describing a rather small set of sounds that are relevant for a specific behavior, namely, discriminating grasshopper songs [<xref ref-type="bibr" rid="pbio-0040387-b015">15</xref>].</p>
      <p>This raises an interesting question: does an animal's behavior influence the shapes of its sensory tuning curves? If so, what features would be most sensitive to behavioral constraints? There are, in fact, two motivations for addressing this problem: first, the limitations just discussed of the efficient coding principle; second, the ubiquity of monotonic tuning curves, which I see as a theoretical mystery. Tuning curves come in two main flavors, single-peaked and monotonic (increasing or decreasing). Bell-shaped curves with a single peak are the textbook example of tuning functions. They are indeed quite common [<xref ref-type="bibr" rid="pbio-0040387-b016">16</xref>–<xref ref-type="bibr" rid="pbio-0040387-b020">20</xref>], and many modeling studies have investigated the coding properties of arrays of such unimodal curves subject to some form of noise [<xref ref-type="bibr" rid="pbio-0040387-b021">21</xref>–<xref ref-type="bibr" rid="pbio-0040387-b025">25</xref>]. Monotonic dependencies on stimulus parameters, however, have also been amply documented, not only in the somatosensory system [<xref ref-type="bibr" rid="pbio-0040387-b026">26</xref>–<xref ref-type="bibr" rid="pbio-0040387-b028">28</xref>] but also in other modalities [<xref ref-type="bibr" rid="pbio-0040387-b029">29</xref>–<xref ref-type="bibr" rid="pbio-0040387-b031">31</xref>]. Monotonic tuning curves have received little attention from theorists. No analysis has been reported from the standpoint of efficient coding, and it is not clear whether they present any advantage regarding other criteria, such as learning [<xref ref-type="bibr" rid="pbio-0040387-b032">32</xref>]. To complicate matters further, some neuronal populations show mixtures of monotonic and peaked curves [<xref ref-type="bibr" rid="pbio-0040387-b033">33</xref>–<xref ref-type="bibr" rid="pbio-0040387-b035">35</xref>].</p>
      <p>Why is there such a range of tuning curve shapes? And, in particular, what promotes the development of monotonic profiles? To investigate more closely whether behavioral factors play a role in this problem, here I evaluate the responses of a neuronal population not only in relation to their sensory inputs but also in terms of the range of outputs that they are capable of generating. The sensory tuning curves are seen as a set of basis functions from which other functions of the stimulus parameters can be easily constructed [<xref ref-type="bibr" rid="pbio-0040387-b036">36</xref>,<xref ref-type="bibr" rid="pbio-0040387-b037">37</xref>]. These other functions represent motor activity or actions that are generated in response to a stimulus. The idea is that if something can be said about the statistics of the downstream motor activity, then we should be able to say something about the sensory tuning curves that are optimal for driving such activity.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Tuning Curves as Basis Functions</title>
        <p>To begin, the problem needs to be defined mathematically. The situation can be described using some of the tools of classic function approximation [<xref ref-type="bibr" rid="pbio-0040387-b038">38</xref>,<xref ref-type="bibr" rid="pbio-0040387-b039">39</xref>] and is schematized in <xref ref-type="fig" rid="pbio-0040387-g001">Figure 1</xref>: <italic>n</italic> basis neurons respond to <italic>M</italic> stimuli or conditions and drive <italic>N</italic> additional downstream neurons whose output should approximate a set of desired functions <bold>F</bold>. The basis neurons represent sensory neurons in whose tuning curves we are interested, and the downstream units represent motor neurons that contribute to generating actions. The key quantity to study is the matrix <bold>r</bold>, where <italic>r<sub>ik</sub></italic> is the firing rate of basis neuron <italic>i</italic> evoked by stimulus <italic>k</italic>. These basis responses may have intrinsic variability (noise), so their mean values are denoted as 〈<italic>r<sub>ik</sub></italic>〉, where the brackets indicate an average over multiple presentations of the same stimulus. Because the second index parameterizes stimulus values, the tuning curve of cell <italic>i</italic> is simply 〈<italic>r<sub>ik</sub></italic>〉 plotted as a function of <italic>k</italic>. As mentioned above, the rationale of this approach is that although the motor responses <bold>F</bold> may be largely unknown in reality, if they have some regularity or statistical structure, this should partially determine the optimal shapes of the sensory tuning curves 〈<bold>r</bold>〉. For the moment, however, pretend that the repertoire of motor responses <bold>F</bold> that should be elicited by the stimuli is fully known.</p>
        <fig id="pbio-0040387-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0040387.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Schematic of the Model</title>
            <p>There are <italic>n</italic> sensory or basis neurons that respond to <italic>M</italic> stimuli and drive <italic>N</italic> motor neurons downstream. The firing rate of motor neuron <italic>α</italic> (shown filled) when stimulus <italic>k</italic> is presented is equal to <italic>R</italic><sub>α<italic>k</italic></sub> =<inline-formula id="pbio-0040387-ex023"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex023" xlink:type="simple"/></inline-formula>
							 <italic>w</italic><sub>α<italic>i</italic></sub><italic>r<sub>ik</sub></italic>, where <italic>r<sub>ik</sub></italic> is the firing rate of sensory neuron <italic>i,</italic> and <italic>w<sub>αi</sub></italic> is the connection (shown in red) from sensory neuron <italic>i</italic> to downstream neuron <italic>α</italic>. For each motor neuron <italic>α,</italic> the driven response <italic>R<sub>αk</sub></italic> should approximate as closely as possible a desired response <italic>F<sub>αk</sub></italic>.
						</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040387.g001" xlink:type="simple"/>
        </fig>
        <p>To proceed, a mechanism is needed for the sensory neurons to communicate with the motor neurons. The simplest assumption is that the downstream motor units are driven through weighted sums. Thus, the response of downstream unit <italic>α</italic> to stimulus <italic>k</italic> is <italic>R<sub>ak</sub></italic> = <inline-formula id="pbio-0040387-ex001"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex001" xlink:type="simple"/></inline-formula>
					 <italic>w</italic><sub>α<italic>i</italic></sub><italic>r<sub>ik</sub></italic>, where <italic>w</italic><sub>α<italic>i</italic></sub> represents the synaptic connection from sensory neuron <italic>i</italic> to downstream neuron <italic>α</italic> (<xref ref-type="fig" rid="pbio-0040387-g001">Figure 1</xref>). In matrix notation, this is <bold>R</bold> = <bold>wr</bold>. In this simple model, the shapes of the tuning curves become important when there are more downstream neurons than basis neurons (<italic>n</italic> &lt; <italic>N</italic>) and when there is noise, so both conditions are assumed to be true.
				</p>
        <p>Next, recall that the job of downstream unit <italic>α</italic> is to produce the target motor response <italic>
					F→</italic><sub>α</sub> (where <italic>
					F→</italic><sub>α</sub> is row <italic>α</italic> of <bold>F</bold>). Therefore, what is needed is for the driven responses, <bold>R</bold> = <bold>wr</bold>, to approximate as closely as possible the desired ones, <bold>F</bold>. Crucially, however, different sets of tuning curves 〈<bold>r</bold>〉 will vary in their capacity to generate the target downstream responses. This capacity is quantified using an error measure denoted as <italic>E<sub>B</sub></italic>. When <italic>E<sub>B</sub></italic> is 0, the sensory (basis) neurons are most accurate and the driven responses are equal to the desired ones; when <italic>E<sub>B</sub></italic> is 1, the driven activity has little or no resemblance to the desired activity and the error is maximal. The derivation of <italic>E<sub>B</sub></italic> is presented in the Methods section. What is important, however, is to understand its dependencies, which are as follows: <italic>E<sub>B</sub></italic> = <italic>E<sub>B</sub></italic>(〈<bold>r</bold>〉, <bold>σ</bold>, {<italic>s<sub>k</sub></italic>}, <bold>Φ</bold>). First, the error depends on the sensory tuning curves 〈<bold>r</bold>〉 and on their noise, <bold>σ</bold>. Second, note that there is no dependence on the synaptic weights. This is because <italic>E<sub>B</sub></italic> is constructed assuming that, for each 〈<bold>r</bold>〉, the best possible synaptic weights are always used. Third, <italic>E<sub>B</sub></italic> depends on how often each stimulus is shown; that is, on the set of coefficients {<italic>s<sub>k</sub></italic>}, where <italic>s<sub>k</sub></italic> is the probability that stimulus <italic>k</italic> is presented. Finally, <italic>E<sub>B</sub></italic> does not depend directly on the actual motor responses <bold>F</bold>. Instead, the key independent quantity is their correlation matrix <bold>Φ</bold>, which captures their overall statistical structure. Its components are
					<disp-formula id="pbio-0040387-e001"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e001" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>&Phi;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>&alpha;</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>&alpha;</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>&alpha;</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> --></disp-formula>In essence, <bold>Φ</bold> represents an average over all the downstream motor responses that the basis neurons have to approximate. This average corresponds to drawing the <italic>F<sub>αk</sub></italic> values from given distributions, or equivalently, to choosing multiple functions <italic>
					F→</italic><sub>α</sub> from a given class (see below).
				</p>
        <p>In summary, given the noise of the neurons (<bold>σ</bold>), the statistics of the stimuli ({<italic>s<sub>k</sub></italic>}), and the statistics of the downstream responses (<bold>Φ</bold>), the error <italic>E<sub>B</sub></italic> can be calculated for any set of sensory tuning curves 〈<bold>r</bold>〉.</p>
      </sec>
      <sec id="s2b">
        <title>What Determines the Optimal Tuning Curves?</title>
        <p>So far, what I have done is set up the problem and developed a quantity that measures the effectiveness of the sensory tuning curves as building blocks for constructing the desired motor responses. Recall, however, that the goal is to find the best tuning curves. In the present formalism, this is the same as asking what tuning curves 〈<bold>r</bold>〉 minimize <italic>E<sub>B</sub></italic>.</p>
        <p>However, <italic>E<sub>B</sub></italic> cannot completely determine the optimal tuning curves. This is because the problem is fundamentally under-constrained: because the network model is linear (<bold>R = wr</bold>), any transformation by an invertible matrix <bold>A</bold> such that <bold>w</bold> → <bold>wA</bold> and <bold>r</bold> → <bold>A</bold><sup>−1</sup><bold>r</bold> produces the same approximation and thus leaves the error unchanged. Therefore, additional conditions on <bold>w</bold> or <bold>r</bold> are required to make the solution unique. These conditions are crucial, in that they can lead to quite different results [<xref ref-type="bibr" rid="pbio-0040387-b006">6</xref>,<xref ref-type="bibr" rid="pbio-0040387-b040">40</xref>], but it is instructive to ignore them momentarily; this provides some intuition into the problem, as well as a lower bound on <italic>E<sub>B</sub></italic>.</p>
        <p>Before considering specific examples, it is important to discuss the key factors that will determine the solution. Intuitively, the tuning curves should match, as much as possible, the <italic>N</italic> target functions <italic>
					F→</italic><sub>α</sub>. If all the functions are different, then clearly a lot of tuning curves will be needed for accurate approximation. In this case, “different” means “not highly correlated,” which in turn means that <bold>Φ</bold> will have large values along its diagonal (see below). On the other hand, if the functions <italic>
					F→</italic><sub>α</sub> are similar to each other, then very few tuning curves should suffice. Or, if more tuning curves are available, many of them can be used to cover specific regions where <bold>Φ</bold> varies more abruptly. Therefore, what matters when designing tuning curves is really the number of distinct functions that need to be approximated, as measured both by how big <italic>N</italic> is and how correlated the functions <italic>
					F→</italic><sub>α</sub> are.
				</p>
        <p>The rest of this section formalizes this intuition and describes more precisely the dependence of the optimal tuning curves on <bold>Φ</bold>. The reader who wishes to skip the mathematical details may safely move on to the next section.</p>
        <p>To better understand the effect of <bold>Φ</bold>, it is useful to decompose it using a special set of vectors (eigenvectors) and their corresponding coefficients (eigenvalues). The idea is to use the eigenvectors of <bold>Φ</bold> to construct the optimal tuning curves. Assuming that all stimuli are equally probable, the key property of <bold>Φ</bold> is that its <italic>M</italic> eigenvalues are all non-negative and add up to <italic>M</italic> (see <xref ref-type="sec" rid="s4">Methods</xref>). When <bold>Φ</bold> results from averaging either just a few functions (≪<italic>M</italic>) or many functions with similar shapes, only a few eigenvalues are significantly larger than 0. Conversely, when the average involves many different functions, most eigenvalues are close to 1 and <bold>Φ</bold> is strongly diagonal.</p>
        <p>Keeping these properties in mind, as well as the fact that <italic>E<sub>B</sub></italic> varies between 0 and 1, now consider a single basis neuron. Assume that its tuning curve is proportional to an eigenvector of <bold>Φ</bold> with eigenvalue λ. In that case, <italic>E<sub>B</sub></italic> depends on only two numbers, λ and a signal-to-noise ratio ρ that is equal to the mean response squared divided by the mean variance of the neuron. That is,
					<disp-formula id="pbio-0040387-e002"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e002" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:mi>n</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&minus;</mml:mo><mml:mstyle scriptlevel='+1'><mml:mfrac><mml:mtext>&lambda;</mml:mtext><mml:mi>M</mml:mi></mml:mfrac></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>&rho;</mml:mtext><mml:mo>&plus;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext>&rho;</mml:mtext><mml:mo>&plus;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math> --></disp-formula>(see <xref ref-type="sec" rid="s4">Methods</xref>). This expression leads to three important observations. (1) When the neuron's variance increases, ρ tends to 0 and the error tends to 1. Thus, as expected, higher noise always pushes the error toward its maximum. (2) The worst-case scenario is λ = 0. This produces the maximum error, regardless of the noise, and occurs when the tuning curve is completely different from (orthogonal to) all the target functions used to compute <bold>Φ</bold>. (3) For any signal-to-noise ratio, the lowest error occurs when λ is the largest eigenvalue of <bold>Φ</bold>, in which case the single tuning curve is equal to the so-called first principal component [<xref ref-type="bibr" rid="pbio-0040387-b041">41</xref>] of <bold>Φ</bold>. This one tuning curve may suffice to generate a very small error, if the noise is low and λ = λ<sup>max</sup> ≈ <italic>M</italic>. But, on the other hand, if λ<sup>max</sup> is small, the error will be large even if the tuning curve has the optimal shape and zero noise.
				</p>
        <p>The efficacy of the single basis neuron thus depends on its variability, on the largest eigenvalue of <bold>Φ</bold>, and on the similarity between the tuning curve and the eigenvectors. An analogous result is obtained with more neurons, except that additional eigenvalues and eigenvectors become involved (see <xref ref-type="sec" rid="s4">Methods</xref>). Specifically, with <italic>n</italic> basis neurons and no noise, the minimum error that can be achieved is
					<disp-formula id="pbio-0040387-e003"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e003" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mtext>min</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn><mml:mo>&minus;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mtext>&lambda;</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> --></disp-formula>where λ<sub>1</sub>, … , λ<italic><sub>n</sub></italic> are the <italic>n</italic> largest eigenvalues of <bold>Φ</bold>. The key in this expression is that the sum involves <italic>n</italic> terms only. This is important because if <bold>Φ</bold> has just a few large eigenvalues, the sum of the <italic>n</italic> largest ones may approach <italic>M</italic> even if <italic>n</italic> ≪ <italic>M</italic>, so few noiseless tuning curves with the right shapes will suffice for representing accurately all the desired motor responses. This happens, for instance, when the motor responses are similar to each other, i.e., when they are highly correlated. Conversely, if many eigenvalues are close to 1, then <bold>Φ</bold> is strongly diagonal, and it is certain that a much larger number of sensory neurons will be needed even if noise is not a factor. Numerical results support these theoretical conclusions (see <xref ref-type="supplementary-material" rid="pbio-0040387-sd001">Protocol S1</xref>).
				</p>
      </sec>
      <sec id="s2c">
        <title>Monotonic Versus Nonmonotonic Tuning Curves</title>
        <p>Armed with a criterion that quantifies the accuracy of the sensory tuning curves and takes into account the statistics of the motor outputs, now we can ask: what sets of tuning curves are optimal when there is variability and when specific families of downstream functions are considered? To investigate this, each tuning curve was parameterized by four numbers, such that either monotonic or unimodal profiles with a large variety of shapes could be produced, and a numerical routine was used to find optimal parameter combinations that minimized <italic>E<sub>B</sub></italic> (see <xref ref-type="sec" rid="s4">Methods</xref>). By limiting the possible tuning-curve shapes, this procedure eliminated the ambiguity problem mentioned earlier.</p>
        <p><xref ref-type="fig" rid="pbio-0040387-g002">Figure 2</xref> illustrates the results of computer experiments in which optimal tuning curves were obtained numerically for four classes of downstream responses. Examples of functions within each class are shown on the top row, next to the corresponding <bold>Φ</bold> matrices (<xref ref-type="fig" rid="pbio-0040387-g002">Figure 2</xref>A–<xref ref-type="fig" rid="pbio-0040387-g002">2</xref>D). The graphs below show the sets of two, four, and eight tuning curves that minimized <italic>E<sub>B</sub></italic> in each case. When the target functions are nonmonotonic (<xref ref-type="fig" rid="pbio-0040387-g002">Figure 2</xref>A and <xref ref-type="fig" rid="pbio-0040387-g002">2</xref>B), the optimal tuning curves are themselves nonmonotonic (<xref ref-type="fig" rid="pbio-0040387-g002">Figure 2</xref>E and <xref ref-type="fig" rid="pbio-0040387-g002">2</xref>F). Similarly, when the target functions are monotonic (<xref ref-type="fig" rid="pbio-0040387-g002">Figure 2</xref>C and <xref ref-type="fig" rid="pbio-0040387-g002">2</xref>D), the optimal tuning curves are also monotonic (<xref ref-type="fig" rid="pbio-0040387-g002">Figure 2</xref>G and <xref ref-type="fig" rid="pbio-0040387-g002">2</xref>H), even though the target classes comprise both increasing and decreasing functions. The detailed features of the optimal tuning curves clearly depend on the specifics of the target class. For instance, the number of peaks and troughs of the oscillating target functions affects the optimal width of the unimodal curves (compare <xref ref-type="fig" rid="pbio-0040387-g002">Figure 2</xref>E and <xref ref-type="fig" rid="pbio-0040387-g002">2</xref>F). Most notably, however, because the noise properties and stimulus statistics remained constant, all the differences across columns are due to constraints that act downstream from the sensory neurons.</p>
        <fig id="pbio-0040387-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0040387.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Optimal Tuning Curves for Four Classes of Downstream Functions</title>
            <p>(A) High-frequency oscillating functions. Each function <italic>
							F→</italic> was composed of eight sinusoids of random phase and amplitude. Four examples are shown. The inset depicts the correlation matrix obtained from 5000 functions.
						</p>
            <p>(B) Low-frequency oscillating functions.</p>
            <p>(C) Saturating monotonic functions. Each <italic>
							F→</italic> was an increasing or decreasing sigmoidal curve of random steepness and center point.
						</p>
            <p>(D) Nonsaturating monotonic functions. Each <italic>
							F→</italic> was an increasing or decreasing exponential curve with random steepness.
						</p>
            <p>(E–H) Optimal sets of two, four, and eight tuning curves for the classes in the corresponding columns. Shown responses minimized <italic>E<sub>B</sub></italic> and were constrained to remain between 0 and 40 spikes/s.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040387.g002" xlink:type="simple"/>
        </fig>
        <p>These results were highly robust with respect to various manipulations (<xref ref-type="supplementary-material" rid="pbio-0040387-sd001">Protocol S1</xref>). Increasing the noise, adding a power constraint, using nonuniform stimulus probabilities, or parameterizing the tuning curves differently did not alter the main finding: optimal tuning curves are predominantly monotonic or nonmonotonic depending on the type of downstream activity they are meant to evoke. Furthermore, manipulating the stimulus probabilities alone never gave rise to monotonic curves; for this, a monotonic trend in the downstream responses was necessary.</p>
        <p>As mentioned in the Introduction, both unimodal and monotonic tuning curves are found in various parts of the brain, and this diversity has remained unexplained (see also the <xref ref-type="sec" rid="s3">Discussion</xref>). The above results suggest that the two types of responses may arise not because of information-coding considerations but because of differences in the actions that various types of stimuli ultimately trigger. For instance, some stimulus parameters, such as the orientation of a bar, should lead to approximately the same sorts of movements regardless of the parameter's value. But other parameters or features, such as image contrast or sound intensity, have an obvious directionality, in that salient stimuli of high contrast or high intensity are more likely to lead to action. Thus, sensory neurons might respond in a qualitatively different way to features with and without such a behavioral bias, because that is the most effective way to generate the appropriate actions. The next two sections present two realistic situations where such motor asymmetries may arise.</p>
      </sec>
      <sec id="s2d">
        <title>Mixed Tuning Curves for Binocular Disparity</title>
        <p>Binocular disparity provides an interesting example of a signal that is likely associated with an intrinsic bias in behavior. To see the source of the asymmetry, consider what possible movements may be triggered by a visual stimulus at a given disparity. If a stimulus is seen near zero disparity (i.e., at the plane of fixation), many subsequent actions are possible, such as reaching, biting, fixating, etc. In contrast, if a relevant stimulus appears at a positive disparity (i.e., behind the plane of fixation), a diverging eye movement should typically follow, because that will bring the object onto the plane of fixation for more detailed examination. Conversely, converging eye movements should be seen more often after stimuli of negative disparity (i.e., in front of the plane of fixation). As a consequence, an oculomotor unit that is strongly activated at positive disparities should have a tendency to fire weakly at negative disparities, and vice versa. This rationale implies that for any relevant oculomotor cell, the responses at opposite ends of the disparity range should tend to be anticorrelated, and these should be approximately independent of the responses triggered near zero disparity. The downstream functions in <xref ref-type="fig" rid="pbio-0040387-g003">Figure 3</xref>A are meant to capture this statistical regularity. They vary strongly in the middle of the stimulus range but have much more stereotyped values at the extremes.</p>
        <fig id="pbio-0040387-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0040387.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Optimal Tuning Curves for Downstream Functions That Have Both Peaked and Monotonic Components</title>
            <p>(A) Four examples of functions <italic>
							F→</italic> obtained by combining a localized oscillatory function (with a Gaussian envelope) and a saturating monotonic function. Such functions represent hypothetical motor responses to stimuli at various binocular disparities. The inset depicts the correlation matrix obtained from 5000 functions.
						</p>
            <p>(B) Optimal sets of two, four, and eight sensory tuning curves obtained with low noise.</p>
            <p>(C) As in (B), but with high noise and high power cost. In all plots, the <italic>x</italic>-axis represents binocular disparity.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040387.g003" xlink:type="simple"/>
        </fig>
        <p>Optimal tuning curves for this class of downstream functions are shown in <xref ref-type="fig" rid="pbio-0040387-g003">Figure 3</xref>B and <xref ref-type="fig" rid="pbio-0040387-g003">3</xref>C. These curves have two novel features: they mix unimodal and monotonic profiles, and they include intermediate curves with a peak superimposed on a monotonic component. Recently, it has been shown that disparity tuning curves in area V4 have precisely these characteristics. The V4 population comprises a continuum of disparity tuning patterns that includes monotonic (the classic near and far cells), unimodal (the classic tuned cells), and intermediate cells [<xref ref-type="bibr" rid="pbio-0040387-b033">33</xref>].</p>
      </sec>
      <sec id="s2e">
        <title>Widening Tuning Curves for Echo Delay</title>
        <p>The final example addresses the issue of tuning curve width. The downstream functions illustrated in <xref ref-type="fig" rid="pbio-0040387-g004">Figure 4</xref>A are meant to capture a distinctive aspect of the behavior of bats, which locate prey by means of echolocation. In this case, consider a bat pursuing a moth. From far away, the bat can approach the moth by following its average path, smoothing out the moth's high-frequency maneuvers. At a close distance, however, the bat must turn at least as sharply as the moth itself in order to catch it, particularly in a cluttered environment [<xref ref-type="bibr" rid="pbio-0040387-b042">42</xref>,<xref ref-type="bibr" rid="pbio-0040387-b043">43</xref>]. Thus—this is the crucial assumption—when a bat flies toward a small target, its maneuvers must get faster as the target is approached. This postulate is translated into a statement about motor responses by generating functions that vary rapidly near stimulus 1 (corresponding to near targets, or short echo delays) and vary progressively more slowly at higher stimuli (corresponding to far targets, or long echo delays). Examples of such hypothetical motor responses are shown in <xref ref-type="fig" rid="pbio-0040387-g004">Figure 4</xref>A. The optimal tuning curves for this case are nonmonotonic, as might have been expected, but most notably, their widths increase as functions of the preferred stimuli (<xref ref-type="fig" rid="pbio-0040387-g004">Figure 4</xref>B). This effect is extremely robust. It was also observed when the tuning curves were parameterized differently and when high noise and high power cost were used (<xref ref-type="fig" rid="pbio-0040387-g004">Figure 4</xref>C). Many auditory neurons of the bat's sonar system have this particular property. They are tuned to echo delay, and their tuning-curve widths vary linearly with the so-called “best delay” [<xref ref-type="bibr" rid="pbio-0040387-b044">44</xref>,<xref ref-type="bibr" rid="pbio-0040387-b045">45</xref>], which is the echo delay at which the peak response is elicited.</p>
        <fig id="pbio-0040387-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0040387.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Optimal Tuning Curves for Downstream Functions That Vary More Rapidly near One End of the Stimulus Range</title>
            <p>(A) Three examples of continuous, oscillatory functions (with Gaussian envelopes) that oscillate at high frequency near stimulus 1 and at progressively lower frequency near stimulus 50. They represent hypothetical motor responses of bats as functions of echo delay or target distance.</p>
            <p>(B) Set of eight tuning curves that minimized <italic>E<sub>B</sub></italic> given the correlation matrix in (A) and low noise.</p>
            <p>(C) As in (B), but with high noise and high power cost.</p>
            <p>(D) Three examples of discontinuous <italic>
							F→</italic> functions. Each one is a collection of constant segments placed randomly. Segment width increased linearly as a function of segment location on the <italic>x</italic>-axis.
						</p>
            <p>(E) Set of eight tuning curves that minimized <italic>E<sub>B</sub></italic> given the correlation matrix in (D) and low noise.</p>
            <p>(F) As in (E), but with high noise and high power cost. In all plots, the <italic>x</italic>-axis represents echo delay.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040387.g004" xlink:type="simple"/>
        </fig>
        <p>Again, note that the model generates this result based on a single statistical assumption about the motor responses, which is a progressive change in their absolute rate of variation along the echo-delay range. This is confirmed in <xref ref-type="fig" rid="pbio-0040387-g004">Figure 4</xref>D, for which radically different downstream functions were generated. In <xref ref-type="fig" rid="pbio-0040387-g004">Figure 4</xref>D, piecewise-constant functions were used, each composed of a variable number of segments that had random amplitudes and locations. The only structure was a correlation between segment length and segment location along the <italic>x</italic>-axis. It is this correlation that gives rise to the systematic change in tuning-curve width (<xref ref-type="fig" rid="pbio-0040387-g004">Figure 4</xref>E and <xref ref-type="fig" rid="pbio-0040387-g004">4</xref>F).</p>
        <p>A key question here, however, is whether curves of increasing width could also result from an uneven distribution of stimulus probabilities <italic>s<sub>k</sub></italic> without assuming an asymmetry in the downstream functions. Technically the answer is yes—a progressive widening was obtained by using monotonically increasing stimulus probabilities together with the downstream functions in <xref ref-type="fig" rid="pbio-0040387-g002">Figure 2</xref>A and <xref ref-type="fig" rid="pbio-0040387-g002">2</xref>B. But there were three severe problems with this purely sensory mechanism: (1) the effect required high noise; (2) it was much weaker, meaning that variations in width were small; and (3) most importantly, it placed the narrow tuning curves in the region of highly probable stimuli, which for the bat means that nearby targets must be encountered much more often than far away ones are. Therefore, the puzzling widening of sensory tuning curves documented in the bat may be explained more parsimoniously by assuming that flight control needs to be faster as the target gets closer.</p>
      </sec>
      <sec id="s2f">
        <title>Other Tuning Curve Shapes</title>
        <p>The parametric approach presented here allows a direct comparison between monotonic and peaked tuning curves. Would the results hold, however, if other shapes were allowed? To address this question, optimal tuning curves were recalculated using drastically different constraints. The basis responses were simply required to be positive and bounded, whereas the synaptic weights were constrained to be sparse. With sparse connectivity, each downstream function is approximated using only a subset of all the available basis neurons. The optimal tuning curves obtained with this method were much more variable, as expected given the absence of restrictions on their shapes, and they often had multiple peaks. However, an index measuring the monotonicity of the curves in each population was computed, and in terms of this index, the results were very similar to those obtained with parameterized curves: the monotonicity of the basis responses was determined by the monotonicity of the downstream functions, and conversely, strongly monotonic tuning curves could not be produced by manipulating the stimulus statistics alone. Details of these numerical experiments are discussed in <xref ref-type="supplementary-material" rid="pbio-0040387-sd001">Protocol S1</xref>.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>Both unimodal- and monotonic-encoding populations of neurons are common and are maintained by different brain regions [<xref ref-type="bibr" rid="pbio-0040387-b016">16</xref>–<xref ref-type="bibr" rid="pbio-0040387-b020">20</xref>,<xref ref-type="bibr" rid="pbio-0040387-b026">26</xref>–<xref ref-type="bibr" rid="pbio-0040387-b031">31</xref>], including areas beyond the periphery where tuning curves seem to be actively synthesized [<xref ref-type="bibr" rid="pbio-0040387-b028">28</xref>,<xref ref-type="bibr" rid="pbio-0040387-b046">46</xref>]. Yet the factors that determine whether a specific neuronal population develops monotonic, unimodal, or mixed responses have remained a mystery. Computationally, unimodal curves are different from monotonic ones in two ways. First, they allow learning to be local, in the sense that changing the weight of a peaked curve affects the output function only over the range of the curve, not over the entire input space [<xref ref-type="bibr" rid="pbio-0040387-b036">36</xref>,<xref ref-type="bibr" rid="pbio-0040387-b038">38</xref>]. Second, it seems that representing multiple values simultaneously would be much easier with peaked curves, especially when the difference between coded values is large relative to the curve width. Although these differences still have unclear importance, they further illustrate the lack of theoretical justification for monotonic sensory responses. A possible solution to this enigma, however, is to consider the types of actions that various stimuli ultimately trigger.</p>
      <sec id="s3a">
        <title>Maximizing Fisher Information Is Not Enough</title>
        <p>The classical approach to sensory coding involves information maximization [<xref ref-type="bibr" rid="pbio-0040387-b025">25</xref>]. Thus, it would seem that some of the examples discussed above could be formulated in more familiar terms by requiring that more Fisher information [<xref ref-type="bibr" rid="pbio-0040387-b023">23</xref>,<xref ref-type="bibr" rid="pbio-0040387-b024">24</xref>], or equivalently, higher accuracy, be found in certain parts of the sensory space. For instance, in analogy with <xref ref-type="fig" rid="pbio-0040387-g003">Figure 3</xref>A, what happens if much higher accuracy is needed in the middle of the stimulus range than at the edges? Could such conditions lead to monotonic tuning curves?</p>
        <p>The answer is no. This is because a function specifying a desired relative accuracy at each point in the stimulus range is exactly equivalent to the set of coefficients <italic>s<sub>k</sub></italic> that were used to represent stimulus probabilities. That is, <italic>s<sub>k</sub></italic> can also be interpreted as the weight or importance of the error between driven and desired motor responses when stimulus <italic>k</italic> is presented (see <xref ref-type="disp-formula" rid="pbio-0040387-e006">Equation 6</xref>). For instance, when these coefficients had a Gaussian instead of a uniform profile, the results were entirely consistent with an increase in Fisher information at the middle of the range; more tuning curves were located near the middle, and those were narrower than the ones at the edges. These effects depended on the level of noise, as expected, and were rather subtle, but the key point is that such manipulations had no bearing on whether the optimal tuning curves were monotonic or not (see <xref ref-type="supplementary-material" rid="pbio-0040387-sd001">Protocol S1</xref> for further results). Therefore, although information maximization is clearly important, the downstream functions in this model have a much stronger influence on the optimal tuning-curve shapes.</p>
      </sec>
      <sec id="s3b">
        <title>Inputs, Outputs, and Optimality</title>
        <p>Previous theoretical studies have attempted to explain the properties of sensory neurons based on two elements: an optimality assumption (efficient coding) and the statistics of their inputs; i.e., the statistics of natural images or natural sounds [<xref ref-type="bibr" rid="pbio-0040387-b003">3</xref>,<xref ref-type="bibr" rid="pbio-0040387-b005">5</xref>–<xref ref-type="bibr" rid="pbio-0040387-b009">9</xref>,<xref ref-type="bibr" rid="pbio-0040387-b013">13</xref>,<xref ref-type="bibr" rid="pbio-0040387-b014">14</xref>]. Conceptually, the approach here was not dissimilar. An optimality assumption, accurate function approximation, together with the statistics of motor responses were used to infer the shapes of sensory tuning curves. However, the present model works backwards in that it requires knowledge about downstream rather than upstream events (note, however, that stimulus statistics are still taken into account through the coefficients <italic>s<sub>k</sub></italic> and through correlations with the downstream functions they evoke). Clearly, whereas measuring the statistics of natural images or sounds is straightforward, determining the statistics of motor activity associated with specific stimuli poses a challenge. However, assuming that such motor statistics have some structure, because of the animal's behavior, the results of the present model are straightforward: the shapes of the optimal sensory tuning curves should be adapted to that structure.</p>
        <p>Two main conclusions follow from these results—a general one and a specific one. The general observation is that contrary to what is implicitly assumed in most studies, the optimality of sensory-triggered responses depends not only on their variability and on the statistics of stimuli but also on the downstream events driven by those responses [<xref ref-type="bibr" rid="pbio-0040387-b014">14</xref>]. If the downstream demands change, the responses considered optimal will change as well, at least as required by minimization of the performance measure used here, <italic>E<sub>B</sub></italic>. One particular consequence of this is that the optimal width of peaked tuning curves is not uniquely determined by signal-to-noise considerations [<xref ref-type="bibr" rid="pbio-0040387-b023">23</xref>,<xref ref-type="bibr" rid="pbio-0040387-b025">25</xref>] (more on this below). This suggests that a comprehensive understanding of the firing properties of sensory neurons requires knowledge of the downstream impact of their responses.</p>
        <p>In retrospect, this point may seem obvious. If the motor functions to be approximated are monotonic, so should be the tuning curves of upstream neurons that drive them. However, this idea has not been formally articulated before. Furthermore, previous explanations of key features of tuning curves—tuning-curve width, degree of overlap between curves, number of peaks, etc.—have always been based on arguments about coding efficiency. The simple model presented here indicates that such features may also generally depend on the motor actions performed by the animal. This, I believe, is a new insight, because it applies to neurons that are firmly considered as sensory.</p>
        <p>The specific point is that monotonic and nonmonotonic curves are optimal under subtly different circumstances, which may depend on what can be termed a “behavioral bias.” This simply refers to an asymmetry in the relevant sensory stimulus. A bias exists when different parts of the stimulus range lead to different sets of possible actions, so that not all stimulus values are equal. The classes of downstream functions used here were meant to abstract this distinction in a simple way, and the results suggest that monotonic curves are efficient when there is such an asymmetry. Image contrast [<xref ref-type="bibr" rid="pbio-0040387-b030">30</xref>] and pressure on the skin [<xref ref-type="bibr" rid="pbio-0040387-b027">27</xref>] are good examples, because just on the basis of detection probability, high values are much more likely to lead to behavioral responses than low ones are. But in general, weaker or more restricted biases may lead to populations of neurons with both monotonic and peaked tuning curves, as seen experimentally [<xref ref-type="bibr" rid="pbio-0040387-b033">33</xref>–<xref ref-type="bibr" rid="pbio-0040387-b035">35</xref>].</p>
      </sec>
      <sec id="s3c">
        <title>Model Predictions</title>
        <p>If the model is correct, some variations in tuning properties across sensory populations should correspond to adaptations that enhance motor activity. Specifically in the case of arrays of Gaussian tuning curves [<xref ref-type="bibr" rid="pbio-0040387-b021">21</xref>–<xref ref-type="bibr" rid="pbio-0040387-b025">25</xref>], the model predicts that downstream motor responses should vary more rapidly in the stimulus range where the Gaussian curves are narrower. For instance, according to <xref ref-type="fig" rid="pbio-0040387-g004">Figure 4</xref>, echolocating bats must compute motor functions that vary a lot around zero echo delay. Elegant experimental studies by Moss and collaborators are consistent with this interpretation. They show not only that the rate of turning of bats indeed increases as a target is approached [<xref ref-type="bibr" rid="pbio-0040387-b042">42</xref>,<xref ref-type="bibr" rid="pbio-0040387-b043">43</xref>], as was argued earlier, but also that their vocalizations speed up in several ways: (1) the rate at which sonar calls are emitted increases as the target gets near, (2) the duration of each call decreases, and (3) each frequency-modulated call consists of a sweep from a high to a low frequency, and the speed with which the frequencies are swept also increases. These three quantities vary by a factor of about three from the beginning to the end of a capture [<xref ref-type="bibr" rid="pbio-0040387-b043">43</xref>]. Furthermore, in the brown bat, microstimulation of the superior colliculus produces not only movements of the head and pinna but also sonar calls, where the number of evoked sonar pulses increases as a function of both the duration and the amplitude of the injected current [<xref ref-type="bibr" rid="pbio-0040387-b047">47</xref>]. These data strongly suggest that relevant motor neuron activity is indeed generally faster in the region where narrow tuning curves are found.</p>
        <p>The model may also be useful for understanding sensory responses associated with escape or evasive behaviors in which the motor reaction should be faster as a potential threat approaches. This is a behavioral-bias scenario: if the likelihood or the speed of an evasive movement increases monotonically as a function of the proximity and speed of an incoming object, then one should expect the driving sensory neurons to have monotonic profiles. This indeed is reported to happen in several systems. For example, flying locusts make a characteristic dive when predator-sized stimuli are looming on one side. The key for triggering the glide is thought to be a single movement-detector unit, the so-called DCMD neuron, and this neuron fires with increasing frequency as the looming stimulus gets nearer [<xref ref-type="bibr" rid="pbio-0040387-b048">48</xref>]. Similar monotonic responses as functions of distance [<xref ref-type="bibr" rid="pbio-0040387-b049">49</xref>,<xref ref-type="bibr" rid="pbio-0040387-b050">50</xref>] and speed [<xref ref-type="bibr" rid="pbio-0040387-b019">19</xref>] have also been documented in other neurophysiological preparations where escape or collision avoidance is important. Even in monkeys, neurons that are sensitive to the distance of an object approaching the face seem to have monotonic dependencies on object distance (see <xref ref-type="fig" rid="pbio-0040387-g004">Figure 4</xref> in [<xref ref-type="bibr" rid="pbio-0040387-b051">51</xref>]). Likewise, cortical neurons that respond to optic flow, which are particularly useful for avoiding obstacles during locomotion [<xref ref-type="bibr" rid="pbio-0040387-b052">52</xref>], encode heading speed (i.e., the speed of one's own motion) in a predominantly monotonic way [<xref ref-type="bibr" rid="pbio-0040387-b053">53</xref>].</p>
        <p>Perhaps the most counterintuitive consequence of the model is that when behavior does not require high accuracy, the sensory representation should be correspondingly coarse, even if in principle it could be made more precise. As illustrated in <xref ref-type="fig" rid="pbio-0040387-g002">Figure 2</xref>B and <xref ref-type="fig" rid="pbio-0040387-g002">2</xref>F, when the motor response functions are broad, so should be the sensory tuning curves. An impressive data set collected by Heffner and colleagues supports this notion [<xref ref-type="bibr" rid="pbio-0040387-b054">54</xref>,<xref ref-type="bibr" rid="pbio-0040387-b055">55</xref>]. They have shown that sound localization capacity in mammals varies tremendously, with discrimination thresholds ranging from about 1° in humans and elephants to about 30° in mice and horses. These differences are not accounted for by variations in interaural distance, animal lifestyle, or environmental cues. Instead, “sound localization acuity in mammals appears to be a function of the precision required of the visual orienting response to sound” [<xref ref-type="bibr" rid="pbio-0040387-b054">54</xref>]. The argument is as follows. A primary purpose of auditory localization is to generate an orienting response, i.e., to bring the sound source into the fovea for detailed visual analysis. Consequently, species with small areas of best vision (e.g., human, elephant) need to generate highly precise movements, whereas species with large areas or streaks of best vision (e.g., mouse, horse) do not. Based on 24 mammalian species, the correlation between sound localization acuity and foveal width is 0.92. Crucially, however, the correlation with visual acuity itself is −0.31, so a purely sensory explanation again fails. According to classic sensory coding notions, species with high acuity must have tuning curves that are correspondingly narrower or less noisy. Therefore, in view of the behavioral data, large variations in the width of sound localization tuning curves are expected across species. These would be explained by motor constraints, as predicted by the theory. Similar interpretations should be possible in other systems, as long as sensory tuning curves can be directly related to clearly defined behaviors.</p>
      </sec>
      <sec id="s3d">
        <title>Conclusion</title>
        <p>The model developed here is based on an optimality criterion for neuronal tuning curves that takes into account both sensory (upstream) and motor (downstream) processes. This simple model is useful when sensory responses can be functionally related to specific behaviors, in which case it may explain some features of sensory representations that appear intriguing from the traditional perspective of sensory coding based on information maximization. In particular, this approach provides a theoretical rationale for the existence of monotonic tuning curves, which so far have lacked a plausible explanation, and it yields some insight into the apparently idiosyncratic varieties of sensory tuning curves observed across neurophysiological preparations.</p>
      </sec>
      <sec id="s4">
        <title>Materials and Methods</title>
        <sec id="s4a">
          <title>Numerical methods.</title>
          <p>All calculations were performed using Matlab (The Mathworks, Natick, Massachusetts, United States). Results are shown for <italic>n</italic> between two and eight neurons and <italic>M</italic> = 50 stimuli. The mean response of neuron <italic>i</italic> as a function of stimulus <italic>k</italic>, where <italic>k</italic> = 1,…, 50, was parameterized as follows
						<disp-formula id="pbio-0040387-e004"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e004" xlink:type="simple"/><!-- <mml:math display='block'><mml:mspace width='-2pc'/><mml:mrow><mml:mrow><mml:mo>&lang;</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&rang;</mml:mo></mml:mrow><mml:mo>&equals;</mml:mo><mml:mrow><mml:mo>&lsqb;</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mstyle displaystyle='true'><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&plus;</mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>&rsqb;</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>&lsqb;</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&plus;</mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&minus;</mml:mo><mml:mi>k</mml:mi><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width='7pc'/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&plus;</mml:mo><mml:mrow><mml:mtext>exp</mml:mtext><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>&rsqb;</mml:mo></mml:mrow></mml:mrow></mml:math> --></disp-formula>where <italic>a<sub>i</sub></italic> is the amplitude of the curve for neuron <italic>i, c<sub>i</sub></italic> is the center point, <italic>h<sub>i</sub></italic> is the half width, and <italic>m<sub>i</sub></italic> is a factor that determines the slope. This expression produces either unimodal curves, which may have positive or negative kurtosis, or monotonic curves, which may vary in steepness. The correlation matrix <bold>C</bold> was obtained by assuming that noise is independent across neurons, in which case <italic>C<sub>ij</sub></italic> = 〈<italic>r<sub>ik</sub>r<sub>jk</sub></italic>〉 = 〈<italic>r<sub>ik</sub></italic>〉〈<italic>r<sub>jk</sub></italic>〉 + δ<italic><sub>ij</sub></italic><inline-formula id="pbio-0040387-ex002"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex002" xlink:type="simple"/></inline-formula>
						, where δ<italic><sub>ij</sub></italic> = 1 if <italic>i</italic> = <italic>j</italic> and is 0 otherwise. For each neuron <italic>i</italic>, the standard deviation of the noise during stimulus <italic>k</italic> was σ<italic><sub>ik</sub></italic> = α(<italic>r</italic><sub>max</sub>/2 + <inline-formula id="pbio-0040387-ex003"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex003" xlink:type="simple"/></inline-formula>
						), but other choices produced similar results. In the low- and high-noise conditions, <italic>α</italic> = 0.05 and 0.5, respectively.
					</p>
          <p>Matrices <bold>Φ</bold> were produced directly by generating 5000 functions <italic>
						F→</italic><sub>α</sub> within a class and averaging the pairwise products <italic>F</italic><sub>α<italic>k</italic></sub><italic>F<sub>αl</sub></italic>. The functions in each class were determined by small numbers of parameters. For example, for the saturating monotonic curves (<xref ref-type="fig" rid="pbio-0040387-g002">Figure 2</xref>C), <italic>F</italic><sub>α<italic>k</italic></sub> = <italic>a</italic> + <italic>b</italic>(1 + exp((<italic>c</italic> − <italic>k</italic>)/<italic>d</italic>))<sup>−1</sup>, where for each <italic>α,</italic> the center point <italic>c</italic> and slope factor <italic>d</italic> were chosen randomly within a range, and <italic>a</italic> and <italic>b</italic> were set to satisfy two normalization conditions. The first one was <inline-formula id="pbio-0040387-ex004"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex004" xlink:type="simple"/></inline-formula>
						 <italic>s<sub>k</sub>F</italic><sub>α<italic>k</italic></sub> = 0 for all <italic>α,</italic> so the mean of each downstream function was set to 0. This was simply to shift the baseline of each <italic>
						F→</italic><sub>α</sub> and make the resulting <bold>Φ</bold> matrix easier to visualize in the plots; it had little or no effect on the optimal tuning curves. The second normalization condition was <inline-formula id="pbio-0040387-ex005"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex005" xlink:type="simple"/></inline-formula>
						 <italic>s<sub>k</sub></italic>Φ<italic><sub>kk</sub></italic> = 1. It limited the amplitude of the downstream responses. Final values of Φ<italic><sub>kl</sub></italic> varied depending on the chosen class of functions, but never exceeded the range [−2.4, 4].
					</p>
          <p>Given the terms <italic>s<sub>k</sub></italic> and Φ<italic><sub>kl</sub></italic>, a routine searched for the combinations of parameters <italic>a, h, c,</italic> and <italic>m</italic> in <xref ref-type="disp-formula" rid="pbio-0040387-e004">Equation 4</xref> that minimized <italic>E<sub>B</sub></italic> (<xref ref-type="disp-formula" rid="pbio-0040387-e008">Equation 8</xref>). The minimization routine used the Nelder-Mead downhill simplex method [<xref ref-type="bibr" rid="pbio-0040387-b056">56</xref>]. A set of tuning curves was deemed optimal only after extensive testing and refining to ensure that the solution was near the global minimum. Additional constraints were included by adding suitable penalty terms to <italic>E<sub>B</sub></italic>. For instance, to constrain the total power, a term proportional to <inline-formula id="pbio-0040387-ex006"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex006" xlink:type="simple"/></inline-formula>
						 <italic>s<sub>k</sub></italic><inline-formula id="pbio-0040387-ex007"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex007" xlink:type="simple"/></inline-formula>
						 was added.
					</p>
          <p>Tuning curves were also generated using a second parameterization (<xref ref-type="fig" rid="pbio-0040387-g003">Figure 3</xref> and <xref ref-type="supplementary-material" rid="pbio-0040387-sd001">Protocol S1</xref>). In this case, <xref ref-type="disp-formula" rid="pbio-0040387-e004">Equation 4</xref> was substituted with a combination of two half-Gaussians with different widths and baselines but a common peak [<xref ref-type="bibr" rid="pbio-0040387-b033">33</xref>],
						<disp-formula id="pbio-0040387-e005"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e005" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mrow><mml:mo>&lang;</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&rang;</mml:mo></mml:mrow><mml:mo>&equals;</mml:mo><mml:mrow><mml:mo stretchy='true'>&lcub;</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mo>&minus;</mml:mo></mml:msubsup><mml:mo>&plus;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&minus;</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mo>&minus;</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&minus;</mml:mo><mml:msup><mml:mrow><mml:mo stretchy='false'>(</mml:mo><mml:mi>k</mml:mi><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy='false'>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mo stretchy='false'>(</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mo>&minus;</mml:mo></mml:msubsup><mml:mo stretchy='false'>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if</mml:mtext><mml:mspace width="2pt"/><mml:mi>k</mml:mi><mml:mo>&le;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mo>&plus;</mml:mo></mml:msubsup><mml:mo>&plus;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&minus;</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mo>&plus;</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&minus;</mml:mo><mml:msup><mml:mrow><mml:mo stretchy='false'>(</mml:mo><mml:mi>k</mml:mi><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy='false'>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mo stretchy='false'>(</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mo>&plus;</mml:mo></mml:msubsup><mml:mo stretchy='false'>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mspace width="2pt"/><mml:mi>k</mml:mi><mml:mspace width="2pt"/><mml:mo>&gt;</mml:mo><mml:mspace width="2pt"/><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math> --></disp-formula>Here there are six free parameters per basis neuron: the center point <italic>c<sub>i</sub> ,</italic> amplitude <italic>a<sub>i</sub> ,</italic> left and right baseline levels <inline-formula id="pbio-0040387-ex008"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex008" xlink:type="simple"/></inline-formula>
						 and <inline-formula id="pbio-0040387-ex009"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex009" xlink:type="simple"/></inline-formula>
						<italic>,</italic> and left and right widths <inline-formula id="pbio-0040387-ex010"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex010" xlink:type="simple"/></inline-formula>
						 and <inline-formula id="pbio-0040387-ex011"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex011" xlink:type="simple"/></inline-formula>
						.
					</p>
        </sec>
        <sec id="s4b">
          <title>Derivation of <italic>E<sub>B</sub></italic>.</title>
          <p>The objective here is to derive an expression that quantifies how well the sensory tuning curves 〈<bold>r</bold>〉 approximate a desired set of downstream responses <bold>F</bold>. The standard procedure is to consider the average squared difference between driven and desired responses, i.e., the norm |<bold>R</bold> − <bold>F</bold>|. Because <bold>R</bold> = <bold>wr</bold>, this produces
						<disp-formula id="pbio-0040387-e006"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e006" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>&alpha;</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover></mml:mstyle><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy='true'>&lang;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy='true'>(</mml:mo><mml:mrow><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>&alpha;</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>&alpha;</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy='true'>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo stretchy='true'>&rang;</mml:mo></mml:mrow></mml:mrow></mml:math> --></disp-formula>where the coefficient <italic>s<sub>k</sub></italic> represents the probability of stimulus <italic>k</italic>, such that <inline-formula id="pbio-0040387-ex012"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex012" xlink:type="simple"/></inline-formula>
						 <italic>s<sub>k</sub></italic> = 1, and the average indicated by angle brackets is over repeated presentations of a given stimulus. <italic>E<sub>L</sub></italic> is the linear approximation error. This number quantifies how accurately the sensory (basis) neurons and associated synaptic weights are able to generate the desired motor activity downstream.
					</p>
          <p>The next step is to obtain an expression for the error that no longer depends on the synaptic connections. To do this, the idea is to assume that the sensory tuning curves are known, and then find the set of synaptic weights <bold>w</bold><sup>opt</sup> that minimize <italic>E<sub>L</sub></italic>. These optimal weights are then substituted back into <xref ref-type="disp-formula" rid="pbio-0040387-e006">Equation 6</xref>, and the result is an expression for the mean square error that assumes that the synaptic connections are always the best possible ones. This is as follows.</p>
          <p>First, find the optimal connections by calculating the partial derivatives of <italic>E<sub>L</sub></italic> in <xref ref-type="disp-formula" rid="pbio-0040387-e006">Equation 6</xref> with respect to <italic>w<sub>αi</sub></italic> and equating the result to 0. This gives the optimal weights
						<disp-formula id="pbio-0040387-e007"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e007" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>&alpha;</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext>opt</mml:mtext></mml:mrow></mml:msubsup><mml:mo>&equals;</mml:mo><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover></mml:mstyle><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>&alpha;</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>&lang;</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&rang;</mml:mo></mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>&minus;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math> --></disp-formula>where <bold>C</bold><sup>−1</sup> is the inverse of <bold>C</bold>, and <italic>C<sub>ij</sub></italic> = <inline-formula id="pbio-0040387-ex013"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex013" xlink:type="simple"/></inline-formula>
						 <italic>s<sub>k</sub></italic>〈<italic>r<sub>ik</sub>r<sub>jk</sub></italic>〉 is the correlation between sensory neurons <italic>i</italic> and <italic>j</italic>. The weights <bold>w</bold><sup>opt</sup> generate linearly driven responses <bold>R</bold> that, on average, approximate the target motor responses as accurately as possible given the mean firing rates of the sensory neurons and the statistics of the stimuli.
					</p>
          <p>Having minimized <italic>E<sub>L</sub></italic> with respect to the connections, next, find out how big it is by substituting the optimal weights of Equation 7 back into <xref ref-type="disp-formula" rid="pbio-0040387-e006">Equation 6</xref> and rearranging terms. Calling the result <italic>E<sub>B</sub></italic>, this gives
						<disp-formula id="pbio-0040387-e008"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e008" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn><mml:mo>&minus;</mml:mo><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mstyle><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>&minus;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math> --></disp-formula>where
						<disp-formula id="pbio-0040387-e009"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e009" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&equals;</mml:mo><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover></mml:mstyle><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mrow><mml:mo>&lang;</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&rang;</mml:mo></mml:mrow><mml:msub><mml:mi>&Phi;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>&lang;</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&rang;</mml:mo></mml:mrow></mml:mrow></mml:math> --></disp-formula>and Φ<italic><sub>kl</sub></italic> = (1/<italic>N</italic>) <inline-formula id="pbio-0040387-ex014"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex014" xlink:type="simple"/></inline-formula>
						 <italic>F</italic><sub>α<italic>k</italic></sub><italic>F</italic><sub>α<italic>l</italic></sub>, as mentioned in the main text. Thus, <italic>E<sub>B</sub></italic> is a function of the first and second moments of the sensory responses, the stimulus probabilities, and the output correlations <bold>Φ</bold>.
					</p>
          <p>Importantly, in the expression above, the following normalization condition was imposed: <inline-formula id="pbio-0040387-ex015"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex015" xlink:type="simple"/></inline-formula>
						 <italic>s<sub>k</sub></italic>Φ<italic><sub>kk</sub></italic> = 1. This limits the amplitude of the downstream functions and bounds <italic>E<sub>B</sub></italic> between 0 and 1. That the error cannot be negative follows directly from the definition of <italic>E<sub>L</sub></italic> above. That it is bounded by 1 is not immediately obvious, but is a consequence of the fact that the eigenvalues of <bold>Φ</bold> are non-negative, and the normalization restricts their total sum. The next section gives more details.
					</p>
        </sec>
        <sec id="s4c">
          <title>Lower bounds on the approximation error.</title>
          <p>In this section, the two analytic results discussed in the main text—<xref ref-type="disp-formula" rid="pbio-0040387-e002">Equations 2</xref> and <xref ref-type="disp-formula" rid="pbio-0040387-e003">3</xref>—are developed. The main expression derived below is, in fact, a slightly more general statement about the accuracy of the sensory tuning curves.</p>
          <p>Here, a key simplifying assumption is that all stimulus probabilities are equal, so <italic>s<sub>k</sub></italic> = 1/<italic>M</italic> for all <italic>k</italic>. As a consequence, the maximum eigenvalue of <bold>Φ</bold> satisfies 1 ≤ λ<sup>max</sup> ≤ <italic>M</italic>. This important property is true for two reasons: first, because <bold>Φ</bold> results from the product of a matrix times its transpose, which guarantees that all its eigenvalues are non-negative; and second, because of the normalization condition on <bold>Φ</bold>, which in this case is
						<disp-formula id="pbio-0040387-e010"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e010" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>&Phi;</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>&lambda;</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> --></disp-formula>This condition makes the sum over all eigenvalues equal to <italic>M</italic>. Hence, λ<sup>max</sup> is bounded between 1 and <italic>M</italic>.
					</p>
          <p>To see how <italic>E<sub>B</sub></italic> depends on the sensory responses, recall that their correlation matrix <bold>C</bold> is such that <italic>C<sub>ij</sub></italic> = <inline-formula id="pbio-0040387-ex016"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex016" xlink:type="simple"/></inline-formula>
						 <italic>s<sub>k</sub></italic>〈<italic>r<sub>ik</sub>r<sub>jk</sub></italic>〉. Then, for a single basis neuron (<italic>n</italic> = 1) with mean response 〈<italic>r<sub>k</sub></italic>〉, <bold>C</bold> becomes a scalar <italic>C</italic> = <italic>
						rİ</italic><sup>2</sup> + 
						σİ<sup>2</sup>, where
						<disp-formula id="pbio-0040387-e011"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e011" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msup><mml:mover accent='true'><mml:mi>r</mml:mi><mml:mo>&#x304;</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover></mml:mstyle><mml:msup><mml:mstyle displaystyle='true'><mml:mrow><mml:mrow><mml:mo>&lang;</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>&rang;</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mn>2</mml:mn></mml:msup><mml:mtext>&emsp;and&emsp;</mml:mtext><mml:msup><mml:mover accent='true'><mml:mi>&sigma;</mml:mi><mml:mo>&#x304;</mml:mo></mml:mover><mml:mtext>2</mml:mtext></mml:msup><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover></mml:mstyle><mml:mrow><mml:mo stretchy='true'>&lang;</mml:mo><mml:mrow><mml:msup><mml:mstyle displaystyle='true'><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>&minus;</mml:mo><mml:mrow><mml:mo>&lang;</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>&rang;</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo stretchy='true'>&rang;</mml:mo></mml:mrow></mml:mrow></mml:math> --></disp-formula>Also, if the tuning curve is an eigenvector of <bold>Φ</bold> with eigenvalue λ, then <inline-formula id="pbio-0040387-ex017"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex017" xlink:type="simple"/></inline-formula>
						 Φ<italic><sub>kl</sub></italic>〈<italic>r<sub>l</sub></italic>〉 = λ〈<italic>r<sub>k</sub></italic>〉, by definition, and <xref ref-type="disp-formula" rid="pbio-0040387-e009">Equation 9</xref> gives <italic>Q</italic> = λ<italic>
						rİ</italic><sup>2</sup>/<italic>M</italic>. Substituting into <xref ref-type="disp-formula" rid="pbio-0040387-e008">Equation 8</xref> and defining ρ = <italic>
						rİ</italic><sup>2</sup>/
						σİ<sup>2</sup> leads to <xref ref-type="disp-formula" rid="pbio-0040387-e002">Equation 2</xref>, which is the approximation error for a single neuron.
					</p>
          <p>With more neurons, it is possible to derive a lower bound on the error that is more general than <xref ref-type="disp-formula" rid="pbio-0040387-e003">Equation 3</xref>. First, assume that <italic>s<sub>k</sub></italic> = 1/<italic>M</italic> and that the noise has equal magnitude and is uncorrelated across neurons, such that
						<disp-formula id="pbio-0040387-e012"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e012" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mstyle mathvariant='bold' mathsize='normal'><mml:mi>C</mml:mi></mml:mstyle><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:mrow><mml:mo stretchy='true'>&lang;</mml:mo><mml:mrow><mml:mstyle mathvariant='bold' mathsize='normal'><mml:mi>r</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant='bold' mathsize='normal'><mml:mi>r</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow><mml:mo stretchy='true'>&rang;</mml:mo></mml:mrow><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:mrow><mml:mo>&lang;</mml:mo><mml:mstyle mathvariant='bold' mathsize='normal'><mml:mi>r</mml:mi></mml:mstyle><mml:mo>&rang;</mml:mo></mml:mrow><mml:msup><mml:mstyle displaystyle='true'><mml:mrow><mml:mrow><mml:mo>&lang;</mml:mo><mml:mstyle mathvariant='bold' mathsize='normal'><mml:mi>r</mml:mi></mml:mstyle><mml:mo>&rang;</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mo>&plus;</mml:mo><mml:msup><mml:mover accent='true'><mml:mi>&sigma;</mml:mi><mml:mo>&#x304;</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mstyle mathvariant='bold' mathsize='normal'><mml:mi>I</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math> --><!-- <mml:math display='block'><mml:mrow><mml:mstyle mathvariant='bold' mathsize='normal'><mml:mi>Q</mml:mi></mml:mstyle><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mrow><mml:mo>&lang;</mml:mo><mml:mstyle mathvariant='bold' mathsize='normal'><mml:mi>r</mml:mi></mml:mstyle><mml:mo>&rang;</mml:mo></mml:mrow><mml:mstyle mathvariant='bold' mathsize='normal'><mml:mi>&Phi;</mml:mi></mml:mstyle></mml:mrow><mml:msup><mml:mstyle displaystyle='true'><mml:mrow><mml:mrow><mml:mo>&lang;</mml:mo><mml:mstyle mathvariant='bold' mathsize='normal'><mml:mi>r</mml:mi></mml:mstyle><mml:mo>&rang;</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:math> --></disp-formula>where <bold>I</bold><italic><sub>n</sub></italic> is the <italic>n × n</italic> identity matrix and 
						σİ<sup>2</sup>, the variance averaged over stimuli, is the same for all neurons. To proceed, consider the singular value decomposition (SVD) of the matrix of mean responses, 〈<bold>r</bold>〉 = <bold>uSV</bold><sup>T</sup>, where <bold>u</bold> is an <italic>n × n</italic> unitary matrix, <bold>V</bold> is an <italic>M × M</italic> unitary matrix, and <bold>S</bold> is an n <italic>× M</italic> matrix with <italic>n</italic> singular values along the diagonal and zeros elsewhere [<xref ref-type="bibr" rid="pbio-0040387-b056">56</xref>]. This is assuming that the <italic>n</italic> tuning curves are independent; if not, then the number of nonzero elements of <bold>S</bold> will equal the number of independent curves (the rank of 〈<bold>r</bold>〉). The SVD is a generalization to rectangular matrices of the classic eigenvalue decomposition. Substituting <bold>C</bold> and <bold>Q</bold> into <xref ref-type="disp-formula" rid="pbio-0040387-e008">Equation 8</xref> and using the SVD representation of 〈<bold>r</bold>〉 leads to
						<disp-formula id="pbio-0040387-e013"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e013" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn><mml:mo>&minus;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:mrow></mml:mrow></mml:mstyle><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mtext mathvariant='bold'>V</mml:mtext><mml:mtext>T</mml:mtext></mml:msup><mml:mi>&Phi;</mml:mi><mml:msup><mml:mrow><mml:mtext mathvariant='bold'>VS</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mtext mathvariant='bold'>SS</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msup><mml:mo>&plus;</mml:mo><mml:mi>M</mml:mi><mml:msup><mml:mover accent='true'><mml:mi>&sigma;</mml:mi><mml:mo>&#x304;</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mtext mathvariant='bold'>I</mml:mtext><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&minus;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mtext mathvariant='bold'>S</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mspace width='-5.2pc'/><mml:mrow><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn><mml:mo>&minus;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:mrow></mml:mrow></mml:mstyle><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mtext mathvariant='bold'>V</mml:mtext><mml:mtext>T</mml:mtext></mml:msup><mml:mi mathvariant='bold'>&Phi;</mml:mi><mml:mtext mathvariant='bold'>VD</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> --></disp-formula>The first equality results from the defining property of unitary matrices, such that <bold>uu</bold><sup>T</sup> = <bold>I</bold><italic><sub>n</sub></italic> and <bold>VV</bold><sup>T</sup> = <bold>I</bold><italic><sub>M</sub></italic>. The second equality results from grouping into <bold>D</bold> all the terms involving <bold>S</bold>. The matrix <bold>D</bold> turns out to be <italic>M × M</italic> and diagonal, with entries <italic>D<sub>i</sub></italic> = <inline-formula id="pbio-0040387-ex018"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex018" xlink:type="simple"/></inline-formula>
						/(<inline-formula id="pbio-0040387-ex019"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex019" xlink:type="simple"/></inline-formula>
						 + <italic>M</italic>
						σİ<sup>2</sup>), where a single index is used to indicate relevant elements in diagonal matrices. Note, however, that only the first <italic>n</italic> diagonal elements are nonzero, because <bold>S</bold> itself only has at most <italic>n</italic> nonzero singular values along the diagonal (recall that <bold>S</bold> is diagonal but rectangular, <italic>n × M</italic>). The lower bound on the expression above thus involves a sum of only <italic>n</italic> terms; the bound is
						<disp-formula id="pbio-0040387-e014"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040387.e014" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>&ge;</mml:mo><mml:mn>1</mml:mn><mml:mo>&minus;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&sum;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>&lambda;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&plus;</mml:mo><mml:mi>M</mml:mi><mml:msup><mml:mover accent='true'><mml:mi>&sigma;</mml:mi><mml:mo>&#x304;</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math> --></disp-formula>where λ<sub>1</sub>, … , λ<italic><sub>n</sub></italic> are the <italic>n</italic> largest eigenvalues of <bold>Φ</bold>.
					</p>
          <p>To see this, first write <bold>Φ</bold> in terms of its eigenvalue decomposition, so that <bold>V</bold><sup>T</sup><bold>ΦV</bold> = <bold>V</bold><sup>T</sup><bold>EΛE</bold><sup>T</sup><bold>V</bold>, where <bold>E</bold> is the matrix of (right) eigenvectors of <bold>Φ</bold>. Suppose that the eigenvalues <bold>Λ</bold> are sorted in decreasing order, so that λ<sub>1</sub> is the largest. Now note that the diagonal elements of the matrix <bold>V</bold><sup>T</sup><bold>ΦV</bold> depend on the match between <bold>V</bold> and <bold>E</bold>. In particular, the best possible match occurs when <bold>V</bold> is identical to <bold>E</bold>; then <bold>V</bold><sup>T</sup><bold>EΛE</bold><sup>T</sup><bold>V = Λ</bold>, and the equality in <xref ref-type="disp-formula" rid="pbio-0040387-e014">Equation 14</xref> follows directly from <xref ref-type="disp-formula" rid="pbio-0040387-e013">Equation 13</xref>. This means that equality is obtained when the basis tuning curves are constructed using the eigenvectors of <bold>Φ</bold> sorted in decreasing order (i.e., <bold>V</bold> is equal to <bold>E</bold>). In contrast, if, for example, <bold>V</bold> has the same columns as <bold>E</bold> but sorted in the reverse order, then the resulting sum is similar to that in <xref ref-type="disp-formula" rid="pbio-0040387-e014">Equation 14</xref> except that it involves the <italic>n</italic> smallest eigenvalues. That <italic>E<sub>B</sub></italic> varies between 0 and 1 follows from <xref ref-type="disp-formula" rid="pbio-0040387-e010">Equation 10</xref>.</p>
          <p><xref ref-type="disp-formula" rid="pbio-0040387-e014">Equation 14</xref> is the main analytic result and provides important intuitions about the mean basis responses, or sensory tuning curves, 〈<bold>r</bold>〉. These are as follows.</p>
          <p>With <italic>n</italic> = 1, the result is <xref ref-type="disp-formula" rid="pbio-0040387-e002">Equation 2</xref> written as an inequality, with the signal-to-noise ratio equal to <italic>S</italic><sup>2</sup>/(<italic>M</italic>
						σİ<sup>2</sup>). Also, <xref ref-type="disp-formula" rid="pbio-0040387-e003">Equation 3</xref> is obtained when 
						σİ<sup>2</sup> = 0.
					</p>
          <p>Noise always increases the error, because 
						σİ<sup>2</sup> effectively decreases every eigenvalue in <xref ref-type="disp-formula" rid="pbio-0040387-e014">Equation 14</xref>. However, noise partially determines the optimal shapes of the tuning curves. For example, if λ<sub>1</sub> &gt; λ<sub>2</sub> but <italic>S</italic><sub>2</sub> &gt;&gt; <italic>S</italic><sub>1</sub><italic>,</italic> then the second eigenvector should take precedence over the first, because its signal-to-noise ratio will be much higher. In other words, in this case, the first column in <bold>V</bold> should contain the second eigenvector of <bold>Φ</bold>. Thus, noise also determines which eigenvectors should be chosen in what order, and therefore the optimal shapes of the basis responses.
					</p>
          <p>Because of the last point, noise helps solve the ambiguity discussed earlier—that the set of basis responses is determined up to an invertible transformation. However, it does not entirely solve the problem, and this is why. When 
						σİ = 0, both matrices <bold>u</bold> and <bold>S</bold> are absent from <xref ref-type="disp-formula" rid="pbio-0040387-e014">Equation 14</xref>. Therefore, they are arbitrary; they do not affect the error (as long as they are unitary and diagonal, as required). In contrast, with noise, there is a criterion for setting the <italic>S<sub>i</sub></italic> values, so only <bold>u</bold> remains arbitrary. Thus, without noise, 〈<bold>r</bold>〉 is ambiguous up to an invertible transformation, whereas with noise, it is ambiguous up to a unitary transformation.
					</p>
          <p>In addition, it is important to mention that this ambiguity remains when the stimulus probabilities are not uniform. When arbitrary probability values <italic>s<sub>k</sub></italic> are included in the calculation of <xref ref-type="disp-formula" rid="pbio-0040387-e013">Equation 13</xref>, the resulting expression for the error still does not depend on <bold>u</bold>. Therefore, manipulating the stimulus statistics does not solve this problem.</p>
          <p>Finally, to minimize <italic>E<sub>B</sub></italic> in the presence of noise it is best to increase <inline-formula id="pbio-0040387-ex020"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex020" xlink:type="simple"/></inline-formula>
						 as much as possible. However, the total power in the mean responses is <inline-formula id="pbio-0040387-ex021"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex021" xlink:type="simple"/></inline-formula>
						 〈<italic>r<sub>ik</sub></italic>〉<sup>2</sup> = <inline-formula id="pbio-0040387-ex022"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040387.ex022" xlink:type="simple"/></inline-formula>
						. Therefore, with noise, additional constraints that effectively limit the power are necessary to obtain optimal responses of finite amplitude.
					</p>
        </sec>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pbio-0040387-sd001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040387.sd001" xlink:type="simple">
        <label>Protocol S1</label>
        <caption>
          <title>Combined Supporting Information</title>
          <p>(154 KB PDF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>I thank Terry Stanford for useful discussions and Peter Latham for many valuable suggestions.</p>
    </ack>
    
    <ref-list>
      <title>References</title>
      <ref id="pbio-0040387-b001">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name></person-group>
					<year>1992</year>
					<article-title>Could information theory provide an ecological theory of sensory processing?</article-title>
					<source>Network</source>
					<volume>3</volume>
					<fpage>213</fpage>
					<lpage>251</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b002">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Barlow</surname><given-names>H</given-names></name></person-group>
					<year>2001</year>
					<article-title>Redundancy reduction revisited.</article-title>
					<source>Network</source>
					<volume>12</volume>
					<fpage>241</fpage>
					<lpage>253</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b003">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group>
					<year>2003</year>
					<article-title>Vision and the statistics of the visual environment.</article-title>
					<source>Curr Opin Neurobiol</source>
					<volume>13</volume>
					<fpage>144</fpage>
					<lpage>149</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b004">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name></person-group>
					<year>1990</year>
					<article-title>Towards a theory of early visual processing.</article-title>
					<source>Neural Comput</source>
					<volume>2</volume>
					<fpage>308</fpage>
					<lpage>320</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b005">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name></person-group>
					<year>1992</year>
					<article-title>What does the retina know about natural scenes?</article-title>
					<source>Neural Comput</source>
					<volume>4</volume>
					<fpage>196</fpage>
					<lpage>210</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b006">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name><name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name></person-group>
					<year>1996</year>
					<article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images.</article-title>
					<source>Nature</source>
					<volume>381</volume>
					<fpage>607</fpage>
					<lpage>609</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b007">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Bell</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>
					<year>1997</year>
					<article-title>The ‘independent components' of natural scenes are edge filters.</article-title>
					<source>Vision Res</source>
					<volume>37</volume>
					<fpage>3327</fpage>
					<lpage>3338</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b008">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name></person-group>
					<year>2002</year>
					<article-title>Efficient coding of natural sounds.</article-title>
					<source>Nat Neurosci</source>
					<volume>5</volume>
					<fpage>356</fpage>
					<lpage>363</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b009">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>EC</given-names></name><name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name></person-group>
					<year>2006</year>
					<article-title>Efficient auditory coding.</article-title>
					<source>Nature</source>
					<volume>439</volume>
					<fpage>978</fpage>
					<lpage>982</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b010">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Reid</surname><given-names>C</given-names></name></person-group>
					<year>1996</year>
					<article-title>Efficient coding of natural scenes in the lateral geniculate nucleus: Experimental test of a computational theory.</article-title>
					<source>J Neurosci</source>
					<volume>16</volume>
					<fpage>3351</fpage>
					<lpage>3362</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b011">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Vinje</surname><given-names>WE</given-names></name><name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name></person-group>
					<year>2000</year>
					<article-title>Sparse coding and decorrelation in primary visual cortex during natural vision.</article-title>
					<source>Science</source>
					<volume>287</volume>
					<fpage>1273</fpage>
					<lpage>1276</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b012">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group>
					<year>2001</year>
					<article-title>Natural signal statistics and sensory gain control.</article-title>
					<source>Nat Neurosci</source>
					<volume>4</volume>
					<fpage>819</fpage>
					<lpage>825</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b013">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Caywood</surname><given-names>MS</given-names></name><name name-style="western"><surname>Willmore</surname><given-names>B</given-names></name><name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name></person-group>
					<year>2004</year>
					<article-title>Independent components of color natural scenes resemble V1 neurons in their spatial and color tuning.</article-title>
					<source>J Neurophysiol</source>
					<volume>91</volume>
					<fpage>2859</fpage>
					<lpage>2873</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b014">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Machens</surname><given-names>CK</given-names></name><name name-style="western"><surname>Gollisch</surname><given-names>T</given-names></name><name name-style="western"><surname>Kolesnikova</surname><given-names>O</given-names></name><name name-style="western"><surname>Herz</surname><given-names>AV</given-names></name></person-group>
					<year>2005</year>
					<article-title>Testing the efficiency of sensory coding with optimal stimulus ensembles.</article-title>
					<source>Neuron</source>
					<volume>47</volume>
					<fpage>447</fpage>
					<lpage>456</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b015">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Machens</surname><given-names>CK</given-names></name><name name-style="western"><surname>Schütze</surname><given-names>H</given-names></name><name name-style="western"><surname>Franz</surname><given-names>A</given-names></name><name name-style="western"><surname>Kolesnikova</surname><given-names>O</given-names></name><name name-style="western"><surname>Stemmler</surname><given-names>MB</given-names></name><etal/></person-group>
					<year>2003</year>
					<article-title>Single auditory neurons rapidly discriminate conspecific communication signals.</article-title>
					<source>Nat Neurosci</source>
					<volume>6</volume>
					<fpage>341</fpage>
					<lpage>342</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b016">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Albright</surname><given-names>TD</given-names></name></person-group>
					<year>1984</year>
					<article-title>Direction and orientation selectivity of neurons in visual area MT of the macaque.</article-title>
					<source>J Neurophysiol</source>
					<volume>52</volume>
					<fpage>1106</fpage>
					<lpage>1130</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b017">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Funahashi</surname><given-names>S</given-names></name><name name-style="western"><surname>Bruce</surname><given-names>CJ</given-names></name><name name-style="western"><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group>
					<year>1989</year>
					<article-title>Mnemonic coding of visual space in the monkeys's dorsolateral prefrontal cortex.</article-title>
					<source>J Neurophysiol</source>
					<volume>61</volume>
					<issue>2</issue>
					<fpage>331</fpage>
					<lpage>349</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b018">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Taube</surname><given-names>JS</given-names></name><name name-style="western"><surname>Muller</surname><given-names>RU</given-names></name><name name-style="western"><surname>Ranck</surname><given-names>JB</given-names><suffix>Jr</suffix></name></person-group>
					<year>1990</year>
					<article-title>Head-direction cells recorded from the postsubiculum in freely moving rats. I. Description and quantitative analysis.</article-title>
					<source>J Neurosci</source>
					<volume>10</volume>
					<fpage>420</fpage>
					<lpage>435</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b019">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Miller</surname><given-names>JP</given-names></name><name name-style="western"><surname>Jacobs</surname><given-names>GA</given-names></name><name name-style="western"><surname>Theunissen</surname><given-names>F</given-names></name></person-group>
					<year>1991</year>
					<article-title>Representation of sensory information in the cricket cercal sensory system. I. Response properties of the primary interneurons.</article-title>
					<source>J Neurophysiol</source>
					<volume>66</volume>
					<fpage>1680</fpage>
					<lpage>1689</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b020">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name><name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name></person-group>
					<year>1996</year>
					<article-title>Geometric determinants of the place fields of hippocampal neurons.</article-title>
					<source>Nature</source>
					<volume>381</volume>
					<fpage>425</fpage>
					<lpage>428</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b021">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Paradiso</surname><given-names>MA</given-names></name></person-group>
					<year>1988</year>
					<article-title>A theory for the use of visual orientation information which exploits the columnar structure of striate cortex.</article-title>
					<source>Biol Cybern</source>
					<volume>58</volume>
					<fpage>35</fpage>
					<lpage>49</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b022">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Salinas</surname><given-names>E</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name></person-group>
					<year>1994</year>
					<article-title>Vector reconstruction from firing rates.</article-title>
					<source>J Comput Neurosci</source>
					<volume>1</volume>
					<fpage>89</fpage>
					<lpage>107</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b023">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>K</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>
					<year>1999</year>
					<article-title>Neuronal tuning: To sharpen or broaden?</article-title>
					<source>Neural Comput</source>
					<volume>11</volume>
					<fpage>75</fpage>
					<lpage>84</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b024">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Deneve</surname><given-names>S</given-names></name><name name-style="western"><surname>Latham</surname><given-names>PE</given-names></name><name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name></person-group>
					<year>1999</year>
					<article-title>Reading population codes: A neural implementation of ideal observers.</article-title>
					<source>Nat Neurosci</source>
					<volume>2</volume>
					<fpage>740</fpage>
					<lpage>745</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b025">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Butts</surname><given-names>DA</given-names></name><name name-style="western"><surname>Goldman</surname><given-names>MS</given-names></name></person-group>
					<year>2006</year>
					<article-title>Tuning curves, neuronal variability and sensory coding.</article-title>
					<source>PLoS Biol</source>
					<volume>4</volume>
					<issue>4</issue>
					<elocation-id>e92.</elocation-id>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b026">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Romo</surname><given-names>R</given-names></name><name name-style="western"><surname>Brody</surname><given-names>CD</given-names></name><name name-style="western"><surname>Hernández</surname><given-names>A</given-names></name><name name-style="western"><surname>Lemus</surname><given-names>L</given-names></name></person-group>
					<year>1999</year>
					<article-title>Neuronal correlates of parametric working memory in the prefrontal cortex.</article-title>
					<source>Nature</source>
					<volume>399</volume>
					<fpage>470</fpage>
					<lpage>473</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b027">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Pruett</surname><given-names>JR</given-names></name><name name-style="western"><surname>Sinclair</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Burton</surname><given-names>H</given-names></name></person-group>
					<year>2000</year>
					<article-title>Response patterns in second somatosensory cortex (SII) of awake monkeys to passively applied tactile gratings.</article-title>
					<source>J Neurophysiol</source>
					<volume>84</volume>
					<fpage>780</fpage>
					<lpage>797</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b028">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Salinas</surname><given-names>E</given-names></name><name name-style="western"><surname>Hernández</surname><given-names>H</given-names></name><name name-style="western"><surname>Zainos</surname><given-names>A</given-names></name><name name-style="western"><surname>Romo</surname><given-names>R</given-names></name></person-group>
					<year>2000</year>
					<article-title>Periodicity and firing rate as candidate neural codes for the frequency of vibrotactile stimuli.</article-title>
					<source>J Neurosci</source>
					<volume>20</volume>
					<fpage>5503</fpage>
					<lpage>5515</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b029">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Bremmer</surname><given-names>F</given-names></name><name name-style="western"><surname>Ilg</surname><given-names>UJ</given-names></name><name name-style="western"><surname>Thiele</surname><given-names>A</given-names></name><name name-style="western"><surname>Distler</surname><given-names>C</given-names></name><name name-style="western"><surname>Hoffmann</surname><given-names>KP</given-names></name></person-group>
					<year>1997</year>
					<article-title>Eye position effects in monkey cortex. I. Visual and pursuit-related activity in extrastriate areas MT and MST.</article-title>
					<source>J Neurophysiol</source>
					<volume>77</volume>
					<fpage>944</fpage>
					<lpage>961</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b030">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Albrecht</surname><given-names>DG</given-names></name><name name-style="western"><surname>Geisler</surname><given-names>WS</given-names></name><name name-style="western"><surname>Frazor</surname><given-names>RA</given-names></name><name name-style="western"><surname>Crane</surname><given-names>AM</given-names></name></person-group>
					<year>2002</year>
					<article-title>Visual cortex neurons of monkeys and cats: Temporal dynamics of the contrast response function.</article-title>
					<source>J Neurophysiol</source>
					<volume>88</volume>
					<fpage>888</fpage>
					<lpage>913</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b031">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kayaert</surname><given-names>G</given-names></name><name name-style="western"><surname>Biederman</surname><given-names>I</given-names></name><name name-style="western"><surname>Op de Beeck</surname><given-names>HP</given-names></name><name name-style="western"><surname>Vogels</surname><given-names>R</given-names></name></person-group>
					<year>2005</year>
					<article-title>Tuning for shape dimensions in macaque inferior temporal cortex.</article-title>
					<source>Eur J Neurosci</source>
					<volume>22</volume>
					<fpage>212</fpage>
					<lpage>224</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b032">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Guigon</surname><given-names>E</given-names></name></person-group>
					<year>2003</year>
					<article-title>Computing with populations of monotonically tuned neurons.</article-title>
					<source>Neural Comput</source>
					<volume>15</volume>
					<fpage>2115</fpage>
					<lpage>2127</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b033">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Hinkle</surname><given-names>DA</given-names></name><name name-style="western"><surname>Connor</surname><given-names>CE</given-names></name></person-group>
					<year>2005</year>
					<article-title>Quantitative characterization of disparity tuning in ventral pathway area V4.</article-title>
					<source>J Neurophysiol</source>
					<volume>94</volume>
					<fpage>2726</fpage>
					<lpage>2737</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b034">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>T</given-names></name><name name-style="western"><surname>Heuer</surname><given-names>HW</given-names></name><name name-style="western"><surname>Britten</surname><given-names>KH</given-names></name></person-group>
					<year>2004</year>
					<article-title>Parietal area VIP neuronal responses to heading stimuli are encoded in head-centered coordinates.</article-title>
					<source>Neuron</source>
					<volume>42</volume>
					<fpage>993</fpage>
					<lpage>1001</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b035">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Peng</surname><given-names>X</given-names></name><name name-style="western"><surname>Van Essen</surname><given-names>DC</given-names></name></person-group>
					<year>2005</year>
					<article-title>Peaked encoding of relative luminance in macaque areas V1 and V2.</article-title>
					<source>J Neurophysiol</source>
					<volume>93</volume>
					<fpage>1620</fpage>
					<lpage>1632</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b036">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Poggio</surname><given-names>T</given-names></name></person-group>
					<year>1990</year>
					<article-title>A theory of how the brain might work.</article-title>
					<source>Cold Spring Harbor Symp Quant Biol</source>
					<volume>5</volume>
					<fpage>899</fpage>
					<lpage>910</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b037">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>
					<year>1997</year>
					<article-title>Spatial tranformations in the parietal cortex using basis functions.</article-title>
					<source>J Cog Neurosci</source>
					<volume>9</volume>
					<fpage>222</fpage>
					<lpage>237</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b038">
        <label>38</label>
        <element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Poggio</surname><given-names>T</given-names></name><name name-style="western"><surname>Girosi</surname><given-names>F</given-names></name></person-group>
					<year>1989</year>
					<article-title>A theory of networks for approximation and learning.</article-title>
					<source>AI Memo 1140</source>
					<publisher-name>Massasachusetts Institute of Technology</publisher-name>
					<publisher-loc>Cambridge (Massasachusetts)</publisher-loc>
					<!--===== Restructure page-count as size[@units="page"] =====--><size units="page">65</size>
					
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b039">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Salinas</surname><given-names>E</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name></person-group>
					<year>2000</year>
					<article-title>Do simple cells in primary visual cortex form a tight frame?</article-title>
					<source>Neural Computation</source>
					<volume>12</volume>
					<fpage>313</fpage>
					<lpage>335</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b040">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>DD</given-names></name><name name-style="western"><surname>Seung</surname><given-names>HS</given-names></name></person-group>
					<year>1999</year>
					<article-title>Learning the parts of objects by non-negative matrix factorization.</article-title>
					<source>Nature</source>
					<volume>401</volume>
					<fpage>788</fpage>
					<lpage>791</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b041">
        <label>41</label>
        <element-citation publication-type="other" xlink:type="simple">
					<collab xlink:type="simple">Jollife</collab>
					<year>2002</year>
					<source>Principal component analysis</source>
					<publisher-loc>New York</publisher-loc>
					<publisher-name>Springer-Verlag</publisher-name>
					<!--===== Restructure page-count as size[@units="page"] =====--><size units="page">487</size>
					
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b042">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Ghose</surname><given-names>K</given-names></name><name name-style="western"><surname>Moss</surname><given-names>CF</given-names></name></person-group>
					<year>2006</year>
					<article-title>Steering by hearing: A bat's acoustic gaze is linked to its flight motor output by a delayed, adaptive linear law.</article-title>
					<source>J Neurosci</source>
					<volume>26</volume>
					<fpage>1704</fpage>
					<lpage>1710</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b043">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Moss</surname><given-names>CF</given-names></name><name name-style="western"><surname>Bohn</surname><given-names>K</given-names></name><name name-style="western"><surname>Gilkenson</surname><given-names>H</given-names></name><name name-style="western"><surname>Surlykke</surname><given-names>A</given-names></name></person-group>
					<year>2006</year>
					<article-title>Active listening for spatial orientation in a complex auditory scene.</article-title>
					<source>PLoS Biol</source>
					<volume>4</volume>
					<issue>4</issue>
					<elocation-id>e79.</elocation-id>
					<comment>DOI: <ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0040079" xlink:type="simple">10.1371/journal.pbio.0040079</ext-link></comment>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b044">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Suga</surname><given-names>N</given-names></name><name name-style="western"><surname>Horikawa</surname><given-names>J</given-names></name></person-group>
					<year>1986</year>
					<article-title>Multiple time axes for representation of echo delays in the auditory cortex of the mustached bat.</article-title>
					<source>J Neurophysiol</source>
					<volume>55</volume>
					<fpage>776</fpage>
					<lpage>805</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b045">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Olsen</surname><given-names>JF</given-names></name><name name-style="western"><surname>Suga</surname><given-names>N</given-names></name></person-group>
					<year>1991</year>
					<article-title>Combination-sensitive neurons in the medial geniculate body of the mustached bat: Encoding of relative velocity information.</article-title>
					<source>J Neurophysiol</source>
					<volume>65</volume>
					<fpage>1254</fpage>
					<lpage>1274</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b046">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Adolphs</surname><given-names>R</given-names></name></person-group>
					<year>1993</year>
					<article-title>Bilateral inhibition generates neuronal responses tuned to interaural level differences in the auditory brainstem of the barn owl.</article-title>
					<source>J Neurosci</source>
					<volume>9</volume>
					<fpage>3647</fpage>
					<lpage>3668</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b047">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Valentine</surname><given-names>DE</given-names></name><name name-style="western"><surname>Sinha</surname><given-names>SR</given-names></name><name name-style="western"><surname>Moss</surname><given-names>CF</given-names></name></person-group>
					<year>2002</year>
					<article-title>Orienting responses and vocalizations produced by microstimulation in the superior colliculus of the echolocating bat, <named-content content-type="genus-species" xlink:type="simple">Eptesicus fuscus</named-content>.</article-title>
					<source>J Comp Physiol A Neuroethol Sens Neural Behav Physiol</source>
					<volume>188</volume>
					<fpage>89</fpage>
					<lpage>108</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b048">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Santer</surname><given-names>RD</given-names></name><name name-style="western"><surname>Rind</surname><given-names>FC</given-names></name><name name-style="western"><surname>Stafford</surname><given-names>R</given-names></name><name name-style="western"><surname>Simmons</surname><given-names>PJ</given-names></name></person-group>
					<year>2006</year>
					<article-title>Role of an identified looming-sensitive neuron in triggering a flying locust's escape.</article-title>
					<source>J Neurophysiol</source>
					<volume>95</volume>
					<fpage>3391</fpage>
					<lpage>3400</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b049">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Edwards</surname><given-names>DH</given-names></name><name name-style="western"><surname>Heitler</surname><given-names>WJ</given-names></name><name name-style="western"><surname>Krasne</surname><given-names>FB</given-names></name></person-group>
					<year>1999</year>
					<article-title>Fifty years of a command neuron: The neurobiology of escape behavior in the crayfish.</article-title>
					<source>Trends Neurosci</source>
					<volume>22</volume>
					<fpage>153</fpage>
					<lpage>161</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b050">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Gallagher</surname><given-names>SP</given-names></name><name name-style="western"><surname>Northmore</surname><given-names>DP</given-names></name></person-group>
					<year>2006</year>
					<article-title>Responses of the teleostean nucleus isthmi to looming objects and other moving stimuli.</article-title>
					<source>Vis Neurosci</source>
					<volume>23</volume>
					<fpage>209</fpage>
					<lpage>219</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b051">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Graziano</surname><given-names>MSA</given-names></name><name name-style="western"><surname>Hu</surname><given-names>TX</given-names></name><name name-style="western"><surname>Gross</surname><given-names>CG</given-names></name></person-group>
					<year>1997</year>
					<article-title>Visuospatial properties of ventral premotor cortex.</article-title>
					<source>J Neurophysiol</source>
					<volume>77</volume>
					<fpage>2268</fpage>
					<lpage>2292</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b052">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Graziano</surname><given-names>MS</given-names></name><name name-style="western"><surname>Cooke</surname><given-names>DF</given-names></name></person-group>
					<year>2006</year>
					<article-title>Parieto-frontal interactions, personal space, and defensive behavior.</article-title>
					<source>Neuropsychologia</source>
					<volume>44</volume>
					<fpage>845</fpage>
					<lpage>859</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b053">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Duffy</surname><given-names>CJ</given-names></name><name name-style="western"><surname>Wurtz</surname><given-names>RH</given-names></name></person-group>
					<year>1997</year>
					<article-title>Medial superior temporal area neurons respond to speed patterns in optic flow.</article-title>
					<source>J Neurosci</source>
					<volume>17</volume>
					<fpage>2839</fpage>
					<lpage>2851</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b054">
        <label>54</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Heffner</surname><given-names>RS</given-names></name></person-group>
					<year>1997</year>
					<article-title>Comparative study of sound localization and its anatomical correlates in mammals.</article-title>
					<source>Acta Otolaryngological (Stockholm), Suppl</source>
					<volume>532</volume>
					<fpage>46</fpage>
					<lpage>53</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b055">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Heffner</surname><given-names>RS</given-names></name></person-group>
					<year>2004</year>
					<article-title>Primate hearing from a mammalian perspective.</article-title>
					<source>The Anatomical Record Part A</source>
					<volume>281A</volume>
					<fpage>1111</fpage>
					<lpage>1122</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0040387-b056">
        <label>56</label>
        <element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Press</surname><given-names>WH</given-names></name><name name-style="western"><surname>Flannery</surname><given-names>BP</given-names></name><name name-style="western"><surname>Teukolsky</surname><given-names>SA</given-names></name><name name-style="western"><surname>Vetterling</surname><given-names>WT</given-names></name></person-group>
					<year>1992</year>
					<source>Numerical recipes in C</source>
					<publisher-loc>New York</publisher-loc>
					<publisher-name>Cambridge University Press</publisher-name>
					<!--===== Restructure page-count as size[@units="page"] =====--><size units="page">994</size>
					
				</element-citation>
      </ref>
    </ref-list>
  </back>
</article>
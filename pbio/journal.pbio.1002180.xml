<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.1002180</article-id>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-14-03694</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A Sensitive and Specific Neural Signature for Picture-Induced Negative Affect</article-title>
<alt-title alt-title-type="running-head">Emotion Signature</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Chang</surname>
<given-names>Luke J.</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Gianaros</surname>
<given-names>Peter J.</given-names>
</name>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Manuck</surname>
<given-names>Stephen B.</given-names>
</name>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Krishnan</surname>
<given-names>Anjali</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Wager</surname>
<given-names>Tor D.</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Department of Psychology &amp; Neuroscience, University of Colorado, Boulder, Colorado, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Department of Psychology, University of Pittsburgh, Pittsburgh, Pennsylvania, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Adolphs</surname>
<given-names>Ralph</given-names>
</name>
<role>Academic Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>California Institute of Technology, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: PJG SBM AK TDW. Performed the experiments: PJG SBM AK. Analyzed the data: LJC TDW. Wrote the paper: LJC TDW.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">luke.chang@colorado.edu</email> (LJC); <email xlink:type="simple">tor.wager@colorado.edu</email> (TDW)</corresp>
</author-notes>
<pub-date pub-type="epub">
<day>22</day>
<month>6</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="collection">
<month>6</month>
<year>2015</year>
</pub-date>
<volume>13</volume>
<issue>6</issue>
<elocation-id>e1002180</elocation-id>
<history>
<date date-type="received">
<day>22</day>
<month>10</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>12</day>
<month>5</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Chang et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.1002180" xlink:type="simple"/>
<related-article ext-link-type="uri" id="related001" related-article-type="companion" xlink:href="info:doi/10.1371/journal.pbio.1002179" xlink:type="simple">
<article-title>Brain Signature Predicts Negative Emotion in Individuals</article-title>
</related-article>
<abstract>
<p>Neuroimaging has identified many correlates of emotion but has not yet yielded brain representations predictive of the intensity of emotional experiences in individuals. We used machine learning to identify a sensitive and specific signature of emotional responses to aversive images. This signature predicted the intensity of negative emotion in individual participants in cross validation (<italic>n</italic> =121) and test (<italic>n</italic> = 61) samples (high–low emotion = 93.5% accuracy). It was unresponsive to physical pain (emotion–pain = 92% discriminative accuracy), demonstrating that it is not a representation of generalized arousal or salience. The signature was comprised of mesoscale patterns spanning multiple cortical and subcortical systems, with no single system necessary or sufficient for predicting experience. Furthermore, it was not reducible to activity in traditional “emotion-related” regions (e.g., amygdala, insula) or resting-state networks (e.g., “salience,” “default mode”). Overall, this work identifies differentiable neural components of negative emotion and pain, providing a basis for new, brain-based taxonomies of affective processes.</p>
</abstract>
<abstract abstract-type="toc">
<p>By using images to induce negative emotions in human participants, this study uses neuroimaging to develop and validate a distributed brain signature of emotion that can predict the magnitude and type of negative affective experience in new individuals.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Emotions are an important aspect of human experience and behavior; yet, we do not have a clear understanding of how they are processed in the brain. We have identified a neural signature of negative emotion—a neural activation pattern distributed across the brain that accurately predicts how negative a person will feel after viewing an aversive image. This pattern encompasses multiple brain subnetworks in the cortex and subcortex. This neural activation pattern dramatically outperforms other brain indicators of emotion based on activation in individual regions (e.g., amygdala, insula, and anterior cingulate) as well as networks of regions (e.g., limbic and “salience” networks). In addition, no single subnetwork is necessary or sufficient for accurately determining the intensity and type of affective response. Finally, this pattern appears to be specific to picture-induced negative affect, as it did not respond to at least one other aversive experience: painful heat. Together, these results provide a neurophysiological marker for feelings induced by a widely used probe of negative affect and suggest that brain imaging has the potential to accurately uncover how someone is feeling based purely on measures of brain activity.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by National Institutes of Health grants PO1 HL040962 (SBM), R01 HL089850 (PJG), and R01DA035484 and 2R01MH076136 (TDW). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="2"/>
<page-count count="28"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>Data are available via NeuroVault, a public repository of unthresholded brain activation maps. The emotion data set can be found at <ext-link ext-link-type="uri" xlink:href="http://neurovault.org/collections/503" xlink:type="simple">http://neurovault.org/collections/503</ext-link> and the pain data set can be accessed at <ext-link ext-link-type="uri" xlink:href="http://neurovault.org/collections/504/" xlink:type="simple">http://neurovault.org/collections/504/</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Emotions are a class of psychological states comprised of physiological responses, expressive behavior, and subjective experiences that are central to our daily lives and to multiple forms of psychopathology [<xref rid="pbio.1002180.ref001" ref-type="bibr">1</xref>] and chronic medical diseases [<xref rid="pbio.1002180.ref002" ref-type="bibr">2</xref>]. Emotional information organizes physiological, cognitive, and motor systems into adaptive [<xref rid="pbio.1002180.ref003" ref-type="bibr">3</xref>], organism-wide responses to events and situations relevant for survival and well-being [<xref rid="pbio.1002180.ref004" ref-type="bibr">4</xref>–<xref rid="pbio.1002180.ref006" ref-type="bibr">6</xref>]. These responses allow us to pursue resources and avoid harm [<xref rid="pbio.1002180.ref007" ref-type="bibr">7</xref>], translate cognitive goals into motivated behavior [<xref rid="pbio.1002180.ref008" ref-type="bibr">8</xref>], and navigate the social world [<xref rid="pbio.1002180.ref009" ref-type="bibr">9</xref>,<xref rid="pbio.1002180.ref010" ref-type="bibr">10</xref>]. Conversely, emotional dysregulation is at the heart of many brain- and body-related disorders (e.g., mood, anxiety, personality, cardiovascular, and substance use disorders) and likely cuts across traditional diagnostic boundaries [<xref rid="pbio.1002180.ref011" ref-type="bibr">11</xref>]. Thus, understanding the neurobiological mechanisms that generate and mitigate negative emotional experience is paramount to understanding both human flourishing and dysfunction.</p>
<p>The importance of understanding the “emotional brain” has motivated hundreds of neuroimaging studies in healthy humans [<xref rid="pbio.1002180.ref012" ref-type="bibr">12</xref>,<xref rid="pbio.1002180.ref013" ref-type="bibr">13</xref>] and those suffering from psychopathology [<xref rid="pbio.1002180.ref014" ref-type="bibr">14</xref>–<xref rid="pbio.1002180.ref016" ref-type="bibr">16</xref>]. The promise of these studies for basic research is that they will permit a brain-based taxonomy of emotional processes, avoiding the sole reliance on psychological categories [<xref rid="pbio.1002180.ref017" ref-type="bibr">17</xref>,<xref rid="pbio.1002180.ref018" ref-type="bibr">18</xref>], while the hope for clinical development is to provide transdiagnostic markers for psychopathology that can identify functional brain dysregulation [<xref rid="pbio.1002180.ref019" ref-type="bibr">19</xref>] and physical health risk [<xref rid="pbio.1002180.ref002" ref-type="bibr">2</xref>,<xref rid="pbio.1002180.ref020" ref-type="bibr">20</xref>], predict treatment response [<xref rid="pbio.1002180.ref021" ref-type="bibr">21</xref>,<xref rid="pbio.1002180.ref022" ref-type="bibr">22</xref>], and guide new, brain-based treatments [<xref rid="pbio.1002180.ref023" ref-type="bibr">23</xref>,<xref rid="pbio.1002180.ref024" ref-type="bibr">24</xref>].</p>
<p>In spite of this promise, fundamental requirements must be met before neuroimaging findings can be considered brain representations of emotion that are useful for translational purposes [<xref rid="pbio.1002180.ref025" ref-type="bibr">25</xref>]. Previous work has identified many brain correlates of emotional versus nonemotional stimuli [<xref rid="pbio.1002180.ref012" ref-type="bibr">12</xref>] and physiological responses [<xref rid="pbio.1002180.ref026" ref-type="bibr">26</xref>,<xref rid="pbio.1002180.ref027" ref-type="bibr">27</xref>] but has yet to uncover brain signatures diagnostic of an individual’s emotional experience. For example, the amygdala, dorsal anterior cingulate (dACC), anterior insula (aINS), and other regions reliably respond to aversive stimuli [<xref rid="pbio.1002180.ref028" ref-type="bibr">28</xref>], and functional alterations in these regions are considered prominent features of anxiety disorders [<xref rid="pbio.1002180.ref014" ref-type="bibr">14</xref>,<xref rid="pbio.1002180.ref029" ref-type="bibr">29</xref>]. However, activation in these regions does not imply an emotional experience. Amygdala activation can occur in the absence of emotional experience [<xref rid="pbio.1002180.ref030" ref-type="bibr">30</xref>] and does not appear to be involved in all aversive experiences [<xref rid="pbio.1002180.ref031" ref-type="bibr">31</xref>]. In addition, the dACC and aINS are among the most frequently activated regions in the brain across all types of emotional and nonemotional states [<xref rid="pbio.1002180.ref028" ref-type="bibr">28</xref>] and have recently been conceptualized as network “hubs” that may be integrating cognitive, emotional, and motivational information [<xref rid="pbio.1002180.ref032" ref-type="bibr">32</xref>,<xref rid="pbio.1002180.ref033" ref-type="bibr">33</xref>].</p>
<p>One factor that contributes to this limitation is that the vast majority of studies focus on comparing types of stimuli [<xref rid="pbio.1002180.ref012" ref-type="bibr">12</xref>], e.g., “negative” versus “neutral” images, rather than finer grained differences in reported experience [<xref rid="pbio.1002180.ref034" ref-type="bibr">34</xref>]. While these emotion-related comparisons are assumed to reflect “affective processing,” confounds with attention, salience, and other processes may render many findings superfluous to emotional experience.</p>
<p>Thus, there is a pressing need for neural signatures that are optimized to predict emotional experiences and functional outcomes. These indicators should: (1) specify a precise set of brain voxels that can be tested in new individuals and prospectively applied to new samples and (2) be sensitive and specific to a class of affective experiences (e.g., negative emotion and not other states such as attention or arousal) [<xref rid="pbio.1002180.ref035" ref-type="bibr">35</xref>].</p>
<p>Machine learning provides a new toolbox of algorithms suited for developing sensitive and specific signatures of psychological processes [<xref rid="pbio.1002180.ref036" ref-type="bibr">36</xref>–<xref rid="pbio.1002180.ref039" ref-type="bibr">39</xref>], particularly when those signatures involve measures across multiple neural systems, as is likely to be the case with emotional experience [<xref rid="pbio.1002180.ref012" ref-type="bibr">12</xref>,<xref rid="pbio.1002180.ref018" ref-type="bibr">18</xref>,<xref rid="pbio.1002180.ref040" ref-type="bibr">40</xref>]. Standard neuroimaging methods generally preclude estimation and optimization of the strength of the brain experience correspondence [<xref rid="pbio.1002180.ref028" ref-type="bibr">28</xref>,<xref rid="pbio.1002180.ref041" ref-type="bibr">41</xref>–<xref rid="pbio.1002180.ref043" ref-type="bibr">43</xref>], but cross validated machine learning analyses can identify whether brain effects are of sufficient magnitude (e.g., sensitive enough) and specific enough to have translational utility. These techniques have recently shown great promise in identifying patterns that discriminate among types of affective experiences from brain [<xref rid="pbio.1002180.ref035" ref-type="bibr">35</xref>,<xref rid="pbio.1002180.ref044" ref-type="bibr">44</xref>–<xref rid="pbio.1002180.ref046" ref-type="bibr">46</xref>] and physiology [<xref rid="pbio.1002180.ref047" ref-type="bibr">47</xref>], discriminating patient from control groups [<xref rid="pbio.1002180.ref019" ref-type="bibr">19</xref>,<xref rid="pbio.1002180.ref048" ref-type="bibr">48</xref>], and predicting treatment response [<xref rid="pbio.1002180.ref049" ref-type="bibr">49</xref>].</p>
<p>Here, we use machine learning in a large sample <italic>(n</italic> = 183) to identify the brain systems that predict the intensity of negative affective experiences elicited by viewing images from the International Affective Picture System (IAPS) [<xref rid="pbio.1002180.ref050" ref-type="bibr">50</xref>], which is among the most robust methods of eliciting brief affective experiences (d = 0.81) [<xref rid="pbio.1002180.ref051" ref-type="bibr">51</xref>]. In spite of the widespread use of IAPS images in basic and clinical research (e.g., it is the primary affective task in the human connectome project [<xref rid="pbio.1002180.ref052" ref-type="bibr">52</xref>]), the brain mechanisms that underlie the genesis of the negative experiences they evoke have not been clearly identified. In addition, it is unclear (a) whether it is possible to identify a pattern that strongly predicts emotional experience prospectively in out-of-sample individuals, (b) which brain systems are involved (cortical, subcortical, or both), and (c) whether brain activity that tracks negative affect is specific for negative affect, or whether it codes for “salience,” arousal, or more general features of stimulus processing. Answers to all of these questions are critical for continued progress in both basic affective and clinical sciences.</p>
<p>We address each of these questions by developing a multivariate pattern that predicts negative emotion and assess its sensitivity and specificity relative to pain—another type of arousing, salient, negative experience. Finally, to examine the distributed versus localized nature of the signature, we examined the subsystems necessary and sufficient for accurately predicting negative emotional experience.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>The PINES Signature</title>
<p>We used Least Absolute Shrinkage and Selection Operator and Principle Components Regression (LASSO-PCR) [<xref rid="pbio.1002180.ref035" ref-type="bibr">35</xref>,<xref rid="pbio.1002180.ref053" ref-type="bibr">53</xref>] to identify a distributed Picture Induced Negative Emotion Signature (PINES) that monotonically increased with increasing affective ratings in leave-one-subject-out cross validated analyses <italic>(n</italic> = 121). To apply the model to data from individual test subjects in both cross validation (<italic>n</italic> = 121) and separate hold-out test datasets (<italic>n</italic> = 61), we calculated the pattern response—the dot product of the PINES weight map and the test image—for individual subjects’ activation maps for each of 5 levels of reported negative emotion (see <xref rid="pbio.1002180.g001" ref-type="fig">Fig 1</xref>). The resulting continuous values reflect the predicted intensity of negative emotion for a given activation map. We used these values to classify which of two conditions elicited a stronger negative emotion for an individual (a “forced-choice” test) [<xref rid="pbio.1002180.ref035" ref-type="bibr">35</xref>], providing accuracy estimates (<xref rid="pbio.1002180.g001" ref-type="fig">Fig 1E</xref>). We also used similar classification tests, described below, to evaluate the sensitivity and specificity of PINES responses to negative emotion versus pain. We focus primarily on results for the test sample, as it was completely independent of all model-training procedures and provides the strongest evidence for generalizability [<xref rid="pbio.1002180.ref054" ref-type="bibr">54</xref>].</p>
<fig id="pbio.1002180.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002180.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Experimental paradigm and analysis overview.</title>
<p>Panel A depicts the sequence of events for a given trial. Participants view an initial fixation cross and then are instructed to look at the picture (compared to reappraise). Participants then see a photo and are asked to rate how negative they feel on a likert scale of 1–5. Panel B illustrates the temporal data reduction for each rating level using voxel-wise univariate analysis and an assumed hemodynamic response function. Panel C: these voxels are then treated as features and trained to predict ratings using LASSO-PCR with leave-one-subject-out cross validation. Subject’s data for each rating is concatenated across participants. Panel D: this multivoxel weight map pattern can be tested on new data using matrix multiplication to produce a scalar affective rating prediction. Panel E: we calculated two different types of classification accuracy: (a) the ability to discriminate between high (rating = 5) and low (rating = 1) affective ratings and (b) the ability to discriminate between high affective and high pain data.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.g001" position="float" xlink:type="simple"/>
</fig>
<p>The PINES accurately predicted ratings of negative emotional experience in both cross validation and hold-out test datasets (<xref rid="pbio.1002180.g002" ref-type="fig">Fig 2</xref>). For individual participants in the cross validation sample, the average root mean squared error (RMSE) was 1.23 ± 0.06 (standard error; SE) rating units, and the average within-subject correlation between predicted and actual ratings was r = 0.85 ± 0.02). Accuracy was comparable in the test sample (RMSE = 0.99 ± 0.07, r = 0.92 ± 0.01). The PINES accurately classified highly aversive (rating 5) versus nonaversive (rating 1) pictures with 100% forced-choice accuracy in both cross validation and test samples (<xref rid="pbio.1002180.g002" ref-type="fig">Fig 2B</xref>). Classification accuracy was also high in both the highly aversive range (rating of 5 versus 3: forced-choice = 91%; test sample) and the moderately aversive range (rating of 3 versus 1: 100%; test sample) (See <xref rid="pbio.1002180.s012" ref-type="supplementary-material">S1 Table</xref>). We also assessed single-interval classification based on a single image rather than a relative comparison (<xref rid="pbio.1002180.t001" ref-type="table">Table 1</xref>), which were only slightly less accurate (<xref rid="pbio.1002180.t001" ref-type="table">Table 1</xref>). Comparisons with Support Vector Regression (SVR), another popular algorithm, indicate that these results appear to be robust to the choice of algorithm and, to a large extent, the amount of data used in the training procedure (see <xref rid="pbio.1002180.s011" ref-type="supplementary-material">S1 Methods</xref>).</p>
<fig id="pbio.1002180.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002180.g002</object-id>
<label>Fig 2</label>
<caption>
<title>PINES.</title>
<p>Panel A depicts the PINES pattern thresholded using a 5,000 sample bootstrap procedure at <italic>p</italic> &lt; 0.001 uncorrected. Blowout sections show the spatial topography of the pattern in the left amygdala, right insula, and posterior cingulate cortex. Panel B shows the predicted affective rating compared to the actual ratings for the cross validated participants (<italic>n</italic> = 121) and the separate holdout test data set (<italic>n</italic> = 61). Accuracies reflect forced-choice comparisons between high and low and high, medium, and low ratings. Panel C depicts an average peristimulus plot of the PINES response to the holdout test dataset (<italic>n</italic> = 61). This reflects the average PINES response at every repetition time (TR) in the timeseries separated by the rating. Panel D illustrates an item analysis which shows the average PINES response to each photo by the average ratings to the photos in the separate test dataset (<italic>n</italic> = 61). Error bars reflect ±1 standard error.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.g002" position="float" xlink:type="simple"/>
</fig>
<table-wrap id="pbio.1002180.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002180.t001</object-id>
<label>Table 1</label> <caption><title>Patten sensitivity and specificity.</title></caption>
<alternatives>
<graphic id="pbio.1002180.t001g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.t001" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"/>
<th align="left" rowspan="1" colspan="1">Map</th>
<th align="left" rowspan="1" colspan="1">Emotion 5 versus 1 (SE)</th>
<th align="left" rowspan="1" colspan="1">Pain High versus Low (SE)</th>
<th align="left" rowspan="1" colspan="1">Emotion versus Pain (SE)<xref rid="t001fn002" ref-type="table-fn"><sup>☨</sup></xref></th>
<th align="left" rowspan="1" colspan="1">Emotion Correlation (SE)</th>
<th align="left" rowspan="1" colspan="1">Pain Correlation (SE)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Pattern</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">PINES</td>
<td align="left" rowspan="1" colspan="1">93.6 (2.6%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">60.7 (8%)</td>
<td align="left" rowspan="1" colspan="1">93.2 (2.9%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.92 (0.01)</td>
<td align="left" rowspan="1" colspan="1">0.64 (0.11)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Neurologic Pain Signature (NPS)</td>
<td align="left" rowspan="1" colspan="1">27.7 (5%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref><xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">82.1 (5.6%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">10.7 (3.6%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref><xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">-0.35 (0.06)</td>
<td align="left" rowspan="1" colspan="1">0.91 (0.04)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Average Region of Interest (ROI)</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Amygdala</td>
<td align="left" rowspan="1" colspan="1">55.3 (6%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">64.3 (8%)</td>
<td align="left" rowspan="1" colspan="1">50.5 (5.8%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.31 (0.07)</td>
<td align="left" rowspan="1" colspan="1">0.62 (0.09)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Anterior Cingulate (ACC)</td>
<td align="left" rowspan="1" colspan="1">55.3 (5.6%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">75 (6.7%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">50.5 (5.8%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.26 (0.07)</td>
<td align="left" rowspan="1" colspan="1">0.9 (0.02)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Insula</td>
<td align="left" rowspan="1" colspan="1">55.3 (6%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">78.6 (6.2%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">45.6 (5.7%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.32 (0.07)</td>
<td align="left" rowspan="1" colspan="1">0.92 (0.02)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Network</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Visual</td>
<td align="left" rowspan="1" colspan="1">50 (6.5%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">57.1 (8%)</td>
<td align="left" rowspan="1" colspan="1">78.6 (4.7%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref><xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">-0.01 (0.08)</td>
<td align="left" rowspan="1" colspan="1">0.22 (0.13)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Somatomotor</td>
<td align="left" rowspan="1" colspan="1">36.2 (6.2%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref><xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">71.4 (7.1%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">28.1 (5.2%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref><xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">-0.38 (0.06)</td>
<td align="left" rowspan="1" colspan="1">0.78 (0.09)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Dorsal Attention</td>
<td align="left" rowspan="1" colspan="1">57.4 (6.4%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">71.4 (6.2%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">61.2 (5.6%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.34 (0.07)</td>
<td align="left" rowspan="1" colspan="1">0.57 (0.12)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Ventral Attention (Salience)</td>
<td align="left" rowspan="1" colspan="1">51.1 (6%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">71.4 (6.2%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">13.5 (3.9%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref><xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.14 (0.07)</td>
<td align="left" rowspan="1" colspan="1">0.56 (0.13)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Limbic</td>
<td align="left" rowspan="1" colspan="1">57.4 (6%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">35.7 (8%)</td>
<td align="left" rowspan="1" colspan="1">53.4 (5.8%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.28 (0.06)</td>
<td align="left" rowspan="1" colspan="1">-0.5 (0.13)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Frontoparietal</td>
<td align="left" rowspan="1" colspan="1">51.1 (5.8%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">60.7 (7.6%)</td>
<td align="left" rowspan="1" colspan="1">42.7 (5.7%)<xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.29 (0.07)</td>
<td align="left" rowspan="1" colspan="1">0.34 (0.13)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Default</td>
<td align="left" rowspan="1" colspan="1">63.8 (5.4%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref><xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">57.1 (7.6%)</td>
<td align="left" rowspan="1" colspan="1">70.8 (5.3%)<xref rid="t001fn003" ref-type="table-fn"><sup>+</sup></xref><xref rid="t001fn004" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.34 (0.06)</td>
<td align="left" rowspan="1" colspan="1">-0.03 (0.15)</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p>All balanced accuracies reported in this table result from single-interval classification on the test dataset <italic>(n</italic> = 47; see <xref rid="pbio.1002180.s012" ref-type="supplementary-material">S1 Table</xref> for forced-choice test). Analyses involving Level 5 and/or Level 1 comparisons exclude participants that did not rate any stimuli with that label. Accuracy values reflect the ability to discriminate the conditions compared, but are signed, so that values &gt;50% indicate the proportion of participants for which high intensity was classified as greater than low intensity, for high vs. low analyses, or emotion was greater than pain, for Emotion vs. Pain analyses.  Values &lt; 50% indicate the proportion of participants for which low intensity was classified as greater than high intensity or pain was classified as greater than emotion.  For example, the 10.7% emotion classification of the NPS in the Emotion vs. Pain analysis should be interpreted as a 89.3% hit rate in discriminating pain from emotion. Correlations reflect Pearson correlations between participant’s pattern responses to levels of affective intensity and self-reported ratings averaged across participants.</p></fn>
<fn id="t001fn002"><p><sup>☨</sup>Please note that this column does not reflect accuracy but rather percent classified as emotion.</p></fn>
<fn id="t001fn003"><p><sup>+</sup>Indicates that accuracy is significantly different from chance (50%), using a two-tailed dependent binomial test.</p></fn>
<fn id="t001fn004"><p>*Indicates accuracy significantly different from PINES performance using a two-sample two-tailed z-test for proportions (only tested on Emotion 5 versus 1 and Emotion versus Pain columns).</p></fn>
</table-wrap-foot>
</table-wrap>
<p>The PINES pattern included reliable predictive weights across a number of cortical and subcortical regions (<xref rid="pbio.1002180.g002" ref-type="fig">Fig 2A</xref>). Positive weights (greater activity predicts more negative emotion) were found in many regions typically associated with negative emotion [<xref rid="pbio.1002180.ref012" ref-type="bibr">12</xref>,<xref rid="pbio.1002180.ref040" ref-type="bibr">40</xref>], including the amygdala, periaqueductal gray (PAG), aINS, dorsomedial prefrontal cortex (dmPFC), ventral occipital cortex, presupplementary motor area (preSMA), ventromedial temporal lobe (mTL), and posterior cingulate cortex (PCC). Negative weights were found in the bilateral parahippocampal gyrus, right superior temporal gyrus, left temporal parietal junction (TPJ), right caudate, and occipital and somatomotor cortices. These regions likely comprise multiple functional systems, as we describe in more detail below. Though the PINES comprises nonzero predictive weights across the brain (see <xref rid="pbio.1002180.s003" ref-type="supplementary-material">S1 Fig</xref>), supplementary analyses indicated that a sparse pattern thresholded at <italic>p</italic> &lt; .001, as shown in <xref rid="pbio.1002180.g002" ref-type="fig">Fig 2</xref> (1.6% of in-brain voxels), was sufficient to predict emotional experience with comparable sensitivity to the full model (see <xref rid="pbio.1002180.s011" ref-type="supplementary-material">S1 Methods</xref> and <xref rid="pbio.1002180.s007" ref-type="supplementary-material">S5 Fig</xref>).</p>
<sec id="sec004">
<title>Moderation by demographic variables</title>
<p>An important issue for any biomarker is whether the relationship between predicted (i.e., PINES responses) and observed responses (i.e., negative emotion) is different for different subject populations. Here, all participants (<italic>n</italic> = 182) demonstrated a positive association between the magnitude of the PINES response and negative emotion. In addition, the slope of the relationship between the PINES response and test participants’ (<italic>n</italic> = 61) ratings was not moderated by demographic variables, including age (F(1,56) = 0.37, <italic>p</italic> = 0.54), sex (F(1,56) = 0.80, <italic>p</italic> = 0.38), ethnicity (Caucasian (86% of sample) versus African American (13%); F(1,56) = 0.29, <italic>p</italic> = 0.59), or IQ (F(1,56) = 0.96, <italic>p</italic> = 0.33).</p>
</sec>
<sec id="sec005">
<title>Chronometry of the PINES response</title>
<p>To characterize the time course of PINES responses during and after picture viewing, we applied the PINES pattern to the entire timeseries in the test dataset (<italic>n</italic> = 61) and examined responses at each time point following stimulus onset (<xref rid="pbio.1002180.g002" ref-type="fig">Fig 2C</xref>). Monotonic increases with negative emotional experiences began approximately 4 sec following picture onset and peaked at approximately 6 sec following picture offset, validating the adequacy of the hemodynamic model used here and verifying that the PINES response is linked to responses during picture viewing.</p>
</sec>
<sec id="sec006">
<title>Item analysis</title>
<p>IAPS images vary in multiple ways, including the visual and social content of the images. To test whether the PINES pattern predicted negative emotion across the various images included in this study, we performed an item analysis to test how strongly the PINES expression correlated with ratings across individual pictures in the test dataset. We found a strong linear relationship between the average ratings and pattern response for each image r = .95, t(28) = 15.66, <italic>p</italic> &lt; 0.001, even within only the negative pictures r = .67, t(13) = 3.22, <italic>p</italic> = 0.006 (<xref rid="pbio.1002180.g002" ref-type="fig">Fig 2D</xref>). This finding suggests that the PINES response reflects emotional experience across the heterogeneous visual characteristics (e.g., color, luminance, spatial frequency) and content in the pictures. One potential confound is that most of the negative images depicted a social scene, while most of the neutral images were nonsocial. <xref rid="pbio.1002180.s009" ref-type="supplementary-material">S7 Fig</xref> shows an item analysis highlighting the PINES response to counterexamples of each condition; the results suggest that the signature is not driven by the degree of sociality. In addition, the average PINES response across these images also strongly correlated with normative ratings of multiple discrete emotions from an independent study [<xref rid="pbio.1002180.ref055" ref-type="bibr">55</xref>] (sadness, r = 0.92; anger, r = 0.94; disgust, r = 0.94; and fear, r = 0.88). This suggests that the PINES may be tracking a general negative emotional response rather than a specific emotional state, consistent with previous factor analyses of emotional elicitation using the IAPS [<xref rid="pbio.1002180.ref055" ref-type="bibr">55</xref>]. However, as the normative emotion ratings are highly intercorrelated in this set of images, further studies are needed to examine the mapping between PINES responses and emotional content in more detail.</p>
</sec>
<sec id="sec007">
<title>Within-subject prediction</title>
<p>In addition, it is important to assess the degree of individual variability in the spatial pattern of the PINES. It is possible that some brain regions important for affect may be highly variable across participants in both interparticipant spatial registration and functional topography. Therefore, in this analysis, we looked at the performance of patterns trained on individual participant data. Overall, the individualized predictive maps were able to predict affect ratings on individual trials (mean cross validated r = 0.54 ± 0.02). Interestingly, the cross validated PINES performed significantly better than the within-subject patterns (mean trial-by-trial r = 0.66 ±0.01), t(120) = 6.28, <italic>p</italic> &lt; 0.001 (<xref rid="pbio.1002180.g003" ref-type="fig">Fig 3C</xref>). The relative high accuracy of the PINES can be attributed to larger amounts of between-participant than within-participant trial data. The spatial topography of the average within-participant predictive map was similar to the PINES (spatial correlation r = .37), though the peaks of the most predictive regions were more spatially diffuse (see <xref rid="pbio.1002180.g003" ref-type="fig">Fig 3A</xref>, <xref rid="pbio.1002180.s003" ref-type="supplementary-material">S1 Fig</xref>). No individual participant’s weight map was more spatially similar to the PINES than the group mean (average r = 0.11 ± 0.01), which suggests that the individualized maps were much noisier than the PINES. The tradeoff between using the group (PINES) to regularize predictions compared to the individual alone reflects a classic bias and variance tradeoff fundamental throughout statistics. Introducing some bias towards the group can reduce variance in estimation, improving estimates and predictions. This is the general principle underlying empirical Bayes estimation, which is widely used throughout the statistical sciences.</p>
<fig id="pbio.1002180.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002180.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Within participant emotion prediction.</title>
<p>This figure depicts results from our within-participant analysis, in which the PINES was retrained separately for each participant to predict ratings to individual photos. Panel A shows the voxels in the weight map that are consistently different from zero across participants using a one sample <italic>t</italic> test thresholded at <italic>p</italic> &lt; 0.001 uncorrected. Panel B shows a histogram of standardized emotion predictions (correlation) for each participant. The dotted red line reflects the average cross validated PINES correlation for predicting each photo’s rating. Panel C depicts how well each participant’s ratings were predicted by the PINES (y-axis) versus an idiographically trained, cross-validated map using their individual brain data (x-axis).  Each point on the graph reflects one participant. The dotted red line reflects the identity line. Any data point above the identity line indicates that the participant was better fit by the PINES than their own weight map.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.g003" position="float" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec008">
<title>Dependence on visual processing</title>
<p>Though the PINES includes weights in ventral occipital and temporal regions, which may be related to emotional experience or aspects of high-level visual processing correlated with emotion, accurate predictions do not depend on these regions. Accuracy for the test sample was maintained even when the PINES was retrained excluding the entire occipital lobe (forced-choice rating 5 versus 1 = 100%, RMSE = 0.96 ± 0.06, r = 0.89 ± 0.01; <xref rid="pbio.1002180.s004" ref-type="supplementary-material">S2 Fig</xref>).</p>
</sec>
</sec>
<sec id="sec009">
<title>Pattern Specificity</title>
<p>Affect systems may be organized by valence so that a brain signature for negative affect may be found across stimulus modalities and contexts, or in a modality-specific manner, such that there is not one “negative affect system” but many. Testing these hypotheses requires comparing multiple types of negative affect across modalities. Here, we assessed the generalizability and specificity of the PINES response across IAPS pictures and somatic pain, which is a negative, arousing experience arising from a different modality.</p>
<p>We employed two types of analyses to examine the PINES specificity. First, we compared the spatial topography of the PINES to another pattern map, the Neurologic Pain Signature (NPS), which shows high sensitivity and specificity to somatic pain across multiple studies [<xref rid="pbio.1002180.ref035" ref-type="bibr">35</xref>]. The PINES and NPS maps were almost completely uncorrelated (robust ranked spatial correlation, <inline-formula id="pbio.1002180.e001"><alternatives><graphic id="pbio.1002180.e001g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.e001" xlink:type="simple"/><mml:math display="inline" id="M1" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> = −0.01; <xref rid="pbio.1002180.g004" ref-type="fig">Fig 4</xref>). Several regions showed positive weights in both maps, including the anterior cingulate (ACC), insula, and amygdala. As shown in <xref rid="pbio.1002180.g005" ref-type="fig">Fig 5C</xref>, however, the weight patterns within these regions were also uncorrelated (bilateral ACC, <inline-formula id="pbio.1002180.e002"><alternatives><graphic id="pbio.1002180.e002g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.e002" xlink:type="simple"/><mml:math display="inline" id="M2" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> = 0.04, insula, <inline-formula id="pbio.1002180.e003"><alternatives><graphic id="pbio.1002180.e003g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.e003" xlink:type="simple"/><mml:math display="inline" id="M3" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> = −0.05), though weights in the amygdala were modestly correlated (<inline-formula id="pbio.1002180.e004"><alternatives><graphic id="pbio.1002180.e004g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.e004" xlink:type="simple"/><mml:math display="inline" id="M4" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> = 0.21).</p>
<fig id="pbio.1002180.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002180.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Affective and pain responses to PINES and NPS.</title>
<p>This figure illustrates differences in the spatial topography in the thresholded PINES and NPS patterns and their predictions in independent emotion (<italic>n</italic> = 61) and pain (<italic>n</italic> = 28) test data. Panel A depicts the PINES thresholded at <italic>p</italic> &lt; 0.001 uncorrected (see <xref rid="pbio.1002180.g002" ref-type="fig">Fig 2</xref>). Panel B depicts the average standardized PINES and NPS pattern responses at each level of emotion calculated using a spatial correlation. Error bars reflect ±1 standard error. Panel C depicts the NPS thresholded at false discovery rate (FDR) q &lt; 0.05 whole-brain corrected. Panel D depicts the average standardized PINES and NPS pattern responses at each pain level calculated using a spatial correlation. Error bars reflect ±1 standard error.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.g004" position="float" xlink:type="simple"/>
</fig>
<fig id="pbio.1002180.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002180.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Region of interest analysis.</title>
<p>Panel A illustrates the spatial distribution of the three anatomical ROIs used in all analyses (amygdala = yellow, insula = red, ACC = cyan). Panel B depicts the average activation within each ROI across participants for each level of emotion and pain in the emotion hold out (<italic>n</italic> = 61) and pain test datasets (<italic>n</italic> = 28). Error bars reflect ±1 standard error. Panel C illustrates the spatial topography of the PINES and NPS patterns within each of these anatomical ROIs. While these plots show one region, correlations reported in the text reflect bilateral patterns.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.g005" position="float" xlink:type="simple"/>
</fig>
<p>Second, we assessed the specificity of the pattern responses in the test IAPS (<italic>n</italic> = 61) and thermal pain (<italic>n</italic> = 28) [<xref rid="pbio.1002180.ref056" ref-type="bibr">56</xref>] datasets. The PINES accurately predicted negative affect in the IAPS dataset (<italic>n</italic> = 61) but showed no response to increasing pain intensity in the pain dataset (<xref rid="pbio.1002180.g004" ref-type="fig">Fig 4</xref>). Conversely, the NPS responded robustly to increasing pain but showed no response to increasing negative affect in the IAPS dataset. To further assess sensitivity and specificity, we examined how well responses in each pattern could discriminate (a) high pain versus high negative affect, (b) high versus low pain, and (c) high versus low negative affect (<xref rid="pbio.1002180.t001" ref-type="table">Table 1</xref>). Because this involves comparing responses from two separate, imbalanced test sets (<italic>n</italic> = 61 versus <italic>n</italic> = 28), the analyses described below employ single interval classification, in which individual images are tested for suprathreshold responses independently (as compared to relative within-subject differences in forced-choice classification). The threshold was determined by finding the point that minimized signal detection response bias (see <xref rid="sec020" ref-type="sec">Methods</xref> for details), and we report balanced emotion classification accuracy (chance = 50%), sensitivity, and specificity (See <xref rid="pbio.1002180.s013" ref-type="supplementary-material">S2 Table</xref> for equivalent forced-choice analyses).</p>
<sec id="sec010">
<title>Pain versus emotion</title>
<p>The PINES responded more strongly to emotion than pain and accurately discriminated between the two (93.2 ± 2.9% [SE] accuracy, 93.6% sensitivity, and 92.9% specificity); conversely, the NPS responded more strongly to pain and accurately discriminated pain from emotion (89.3 ± 3.6% accuracy, 89.4% sensitivity, and 89.3% specificity). Thus, both patterns discriminated between the two modalities.</p>
</sec>
<sec id="sec011">
<title>High versus low intensity in each modality</title>
<p>The NPS successfully classified high versus low pain (82.1 ± 5.1% accuracy, 82.1% sensitivity, and 82.1% specificity). It also significantly, though less accurately, classified high versus low emotion (Rating 5 versus 1; 70.4 ± 4.4%, 70.2% sensitivity, and 70.5% specificity), but NPS responses were actually strongest for low-intensity emotion. Examining responses across emotion levels revealed that this was caused by deactivation of the NPS for all levels of emotion &gt;1, resulting in nonmonotonic responses. In contrast, the PINES successfully classified high versus low emotion ratings (93.5 ± 2.4% accuracy, 93.6% sensitivity, and 93.4% specificity) but was at chance in discriminating high versus low pain (60.7 ± 6.5% accuracy, 60.7%, sensitivity, 60.7% specificity).</p>
<p>Together, these analyses suggest that the PINES is specific to negative emotion, at least as compared with pain, and that both the PINES and NPS capture distinct aversive states. Importantly, we are only assessing specificity to one type of construct (e.g., pain) among many possible options. Future work must build on these initial novel observations to examine relationships across many types of positive and negative affect and stimulus modalities to provide a comprehensive picture of the organization of negative affect systems.</p>
</sec>
</sec>
<sec id="sec012">
<title>PINES Outperforms Prediction Based on ROIs and Resting-State Networks</title>
<p>Another question is whether the precise pattern of activity specified in the PINES uniquely captures negative affect, or whether regions and networks previously used in the literature are sufficient. In order to fully appreciate the sensitivity and specificity of the PINES, it is necessary to compare it to the standard univariate approach, which typically examines average activation within ROIs compared to baseline activity. In this analysis, we examined the average response to emotion and pain stimuli within anatomical ROIs and canonical networks defined in large-scale resting-state studies [<xref rid="pbio.1002180.ref057" ref-type="bibr">57</xref>].</p>
<sec id="sec013">
<title>PINES outperforms ROIs</title>
<p>We tested three a priori ROIs that play prominent roles in negative emotion: ACC, insula, and amygdala (see <xref rid="pbio.1002180.t001" ref-type="table">Table 1</xref>, <xref rid="pbio.1002180.g005" ref-type="fig">Fig 5A</xref>). All ROIs showed linear increases across levels of emotion (<xref rid="pbio.1002180.g005" ref-type="fig">Fig 5B</xref>; <xref rid="pbio.1002180.s011" ref-type="supplementary-material">S1 Methods</xref>), but the effects were not strong enough to predict emotion ratings. For the amygdala, prediction—outcome correlations were positive (test dataset RMSE = 3.04 ± 0.05; r = 0.31 ± 0.07), but high versus low classification accuracy was at chance (55.3 ± 6%, sensitivity = 55.3%, specificity = 55.3%; <xref rid="pbio.1002180.t001" ref-type="table">Table 1</xref>). Comparable effects were found in the ACC and insula. For the ACC: RMSE = 2.96 ± 0.05, r = 0.32 ± 0.07, accuracy = 55.3 ± 5.6%, sensitivity = 55.3%, specificity = 55.3%. For the insula: RMSE = 2.88 ± 0.05, r = 0.37 ± 0.07, accuracy = 55.3 ± 6%, sensitivity = 55.3%, specificity = 55.3%. In addition, the amygdala and insula showed a nonmonotonic response function across levels of emotion (<xref rid="pbio.1002180.g005" ref-type="fig">Fig 5</xref>), as evidenced by significant linear and quadratic effects in both regions (see <xref rid="pbio.1002180.s011" ref-type="supplementary-material">S1 Methods</xref>). Together, these results indicate that averaged activity in these ROIs is not sufficient to predict emotional experience. See <xref rid="pbio.1002180.s011" ref-type="supplementary-material">S1 Methods</xref> for a whole-brain searchlight analysis that shows local regions predictive of emotion and also local patterns that cross predict pain experiences.</p>
</sec>
<sec id="sec014">
<title>PINES outperforms network maps</title>
<p>Many types of brain representations may be encoded in distributed functional networks, and there is a growing consensus that functional connectivity in a small set of canonical networks may capture some representations important for cognition and emotion [<xref rid="pbio.1002180.ref057" ref-type="bibr">57</xref>–<xref rid="pbio.1002180.ref062" ref-type="bibr">62</xref>]. In this analysis, we compared the PINES to predictive information in a popular seven-network whole-brain parcellation based on resting-state activity in 1,000 participants [<xref rid="pbio.1002180.ref057" ref-type="bibr">57</xref>], treating each of the network masks as a pattern (see <xref rid="sec020" ref-type="sec">Methods</xref>). While “somatomotor” (accuracy = 63.8 ± 6.2%) and “default” (accuracy = 63.8 ± 5.4%) networks discriminated between high and low levels of emotion above chance, none of the networks performed nearly as well as the PINES (see <xref rid="pbio.1002180.t001" ref-type="table">Table 1</xref> and <xref rid="pbio.1002180.s008" ref-type="supplementary-material">S6 Fig</xref> for all results), including the “ventral attention network,” (also frequently referred to as the “salience” network) [<xref rid="pbio.1002180.ref057" ref-type="bibr">57</xref>,<xref rid="pbio.1002180.ref063" ref-type="bibr">63</xref>], which performed at chance in discriminating high versus low negative emotional experience (51.1 ± 6%).</p>
<p>Activity in four networks successfully discriminated between responses to emotion and pain (<xref rid="pbio.1002180.t001" ref-type="table">Table 1</xref>). The “visual” and “default mode” networks were more strongly activated by high levels of emotion than high levels of pain (78.6 ± 4.7% and 70.8 ± 5.3%), while the ventral attention and somatomotor networks responded more strongly to pain than emotion (86.5 ± 3.9% and 71.9 ± 5.2%, respectively). These results suggest that the brain patterns that define commonly used resting-state networks can identify the sensory modality of aversive stimulation with moderate accuracy, but they are not sufficient for predicting the intensity of emotional experience.</p>
</sec>
</sec>
<sec id="sec015">
<title>The PINES Is Composed of Distinct Subnetworks</title>
<p>Defining a brain pattern sensitive and specific to a type of negative emotion is a critical first step towards developing meaningful models of brain representations of emotion. Here, the development of the PINES affords the opportunity to characterize the basis of this pattern representation within and across brain networks. Constructionist theories of emotion [<xref rid="pbio.1002180.ref012" ref-type="bibr">12</xref>,<xref rid="pbio.1002180.ref018" ref-type="bibr">18</xref>] predict that negative affect is created by interactions among discrete subnetworks that span multiple brain systems, whereas more traditional modular views predict that one system may be sufficient. We tested whether the PINES might be composed of multiple distinct subnetworks and whether responses in multiple subnetworks are necessary for predicting emotional responses. If so, the negative affect captured by the PINES might be considered a truly multisystem distributed process.</p>
<p>For this analysis, we calculated pattern responses within each of the largest regions in the PINES (<italic>p</italic> &lt; .001, k = 10 voxels; see <xref rid="pbio.1002180.s011" ref-type="supplementary-material">S1 Methods</xref>) for every individual trial within each participant and used a robust clustering algorithm to group the PINES regions into separate networks based on similar patterns of trial-by-trial covariation (see <xref rid="sec020" ref-type="sec">Methods</xref>). The best solution contained nine separate clusters, which provides a descriptive characterization of the subnetworks that comprise the PINES (<xref rid="pbio.1002180.g006" ref-type="fig">Fig 6</xref>, <xref rid="pbio.1002180.s014" ref-type="supplementary-material">S3 Table</xref>) that is broadly consistent with constructionist accounts of emotion [<xref rid="pbio.1002180.ref012" ref-type="bibr">12</xref>] and previous meta-analyses of emotion-related networks [<xref rid="pbio.1002180.ref017" ref-type="bibr">17</xref>]. These subnetworks included (a) two networks encompassing different parts of the visual cortex (e.g., lateral occipital cortex [LOC] and occipital pole) consistent with the visual modality of the stimuli, (b) a left amygdala-right aINS-right putamen network, which has been implicated in multiple forms of arousal and salience, (c) a network that includes bilateral posterior parahippocampi and the precuneus, which are broadly involved in memory and other forms of contextual processing, and (d) a network that includes parts of the dmPFC and PCC that are likely involved in social cognition but are distinct from more executive processes [<xref rid="pbio.1002180.ref064" ref-type="bibr">64</xref>,<xref rid="pbio.1002180.ref065" ref-type="bibr">65</xref>]. An additional network that includes the right somatosensory cortex and contralateral cerebellum may be involved in preparing for the rating action but may also play a more fundamental role in the emotion generation process [<xref rid="pbio.1002180.ref066" ref-type="bibr">66</xref>].</p>
<fig id="pbio.1002180.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002180.g006</object-id>
<label>Fig 6</label>
<caption>
<title>PINES clustering based on shared patterns of connectivity.</title>
<p>This figure depicts the results of the hierarchical clustering analysis of the functional connectivity of the largest regions from the <italic>p</italic> &lt; 0.001 thresholded PINES pattern. Clusters were defined by performing hierarchical agglomerative clustering with ward linkage on the trial-by-trial local pattern responses for each region using Euclidean distance.  Data were ranked and normalized within each participant and then aggregated by concatenating all 61 subjects’ trial x region data matrices. Panel A depicts the dendrogram separated by each functional network. Panel B depicts the spatial distribution of the networks. Colors correspond to the dendrogram labels.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.g006" position="float" xlink:type="simple"/>
</fig>
<sec id="sec016">
<title>“Virtual lesion” analysis</title>
<p>Because the PINES is a statistical model of a distributed neural representation of emotion, it is possible to evaluate how well subsets of the brain model can predict emotional experiences. An interesting question is whether each subsystem is either necessary or sufficient to predict the emotional experience. Thus, in a “virtual lesion” analysis, we tested (a) how well each network cluster could discriminate between high versus low ratings and between pain versus emotion and (b) how much the predictive accuracy was reduced by removing each network from the predictive map. As expected by the substantial discrepancies in the task modalities (e.g., visual pictures versus thermal pain and motor response in the IAPS task), several networks individually performed well at discriminating between the emotion and pain including the visual LOC (85.4 ± 4.1%), occipital pole (85.4 ± 4.1%), and sensorimotor and cerebellar networks (93.2 ± 2.9%). These networks were also able to discriminate between levels of emotion significantly above chance, but importantly, all were significantly outperformed by the PINES (see <xref rid="pbio.1002180.t002" ref-type="table">Table 2</xref>). Removing individual networks resulted in slight decreases in high versus low emotion classification accuracy but had a negligible difference on discriminating between pain and emotion. Classification accuracy remained above 80% for high versus low emotion and above 90% for emotion versus pain after removing each single network, and none of these were significantly different from the PINES. These analyses indicate that no specific subsystem was either necessary or sufficient for predicting negative affect, supporting the multisystem view.</p>
<table-wrap id="pbio.1002180.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002180.t002</object-id>
<label>Table 2</label> <caption><title>Single-cluster and “virtual lesion” analysis.</title></caption>
<alternatives>
<graphic id="pbio.1002180.t002g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.t002" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"/>
<th align="left" rowspan="1" colspan="1">Map</th>
<th align="left" rowspan="1" colspan="1">nVoxels</th>
<th align="left" rowspan="1" colspan="1">Emotion 5 versus 1 (SE)</th>
<th align="left" rowspan="1" colspan="1">Pain H versus L (SE)</th>
<th align="left" rowspan="1" colspan="1">Emotion versus Pain (SE)</th>
<th align="left" rowspan="1" colspan="1">Emotion Correlation (SE)</th>
<th align="left" rowspan="1" colspan="1">Pain Correlation (SE)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Pattern</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">PINES</td>
<td align="left" rowspan="1" colspan="1">328796</td>
<td align="left" rowspan="1" colspan="1">93.5 (2.4%)</td>
<td align="left" rowspan="1" colspan="1">60.7 (6.5%)</td>
<td align="left" rowspan="1" colspan="1">93.2 (2.9%)</td>
<td align="left" rowspan="1" colspan="1">0.92 (0.01)</td>
<td align="left" rowspan="1" colspan="1">0.64 (0.11)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">PINES (<italic>p</italic> &lt; .001)</td>
<td align="left" rowspan="1" colspan="1">5303</td>
<td align="left" rowspan="1" colspan="1">91.5 (3%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">67.9 (7.6%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">97.2 (1.9%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.89 (0.01)</td>
<td align="left" rowspan="1" colspan="1">0.51 (0.13)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Single Cluster</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Visual (LOC)</td>
<td align="left" rowspan="1" colspan="1">981</td>
<td align="left" rowspan="1" colspan="1">83 (4.3%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref><xref rid="t001fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">64.3 (7.1%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">85.4 (4.1%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.73 (0.03)</td>
<td align="left" rowspan="1" colspan="1">0.56 (0.12)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Somatosensory and superior temporal gyrus (STG)</td>
<td align="left" rowspan="1" colspan="1">308</td>
<td align="left" rowspan="1" colspan="1">59.6 (5.8%)<xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">32.1 (7.1%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">61.2 (5.6%)<xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.12 (0.07)</td>
<td align="left" rowspan="1" colspan="1">-0.66 (0.11)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Sensorimotor and V1</td>
<td align="left" rowspan="1" colspan="1">335</td>
<td align="left" rowspan="1" colspan="1">57.4 (6.2%)<xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">67.9 (7.6%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">57.3 (5.7%)<xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.23 (0.07)</td>
<td align="left" rowspan="1" colspan="1">0.8 (0.07)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">DMPFC and PCC</td>
<td align="left" rowspan="1" colspan="1">318</td>
<td align="left" rowspan="1" colspan="1">70.2 (5.4%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref><xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">60.7 (7.6%)</td>
<td align="left" rowspan="1" colspan="1">70.8 (5.3%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref><xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.47 (0.06)</td>
<td align="left" rowspan="1" colspan="1">0.61 (0.1)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Sensorimotor and Cerebellum</td>
<td align="left" rowspan="1" colspan="1">1227</td>
<td align="left" rowspan="1" colspan="1">78.7 (4.5%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref><xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">60.7 (7.6%)</td>
<td align="left" rowspan="1" colspan="1">93.2 (2.9%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.72 (0.04)</td>
<td align="left" rowspan="1" colspan="1">0.39 (0.14)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Parahippocampal Gyrus</td>
<td align="left" rowspan="1" colspan="1">1025</td>
<td align="left" rowspan="1" colspan="1">51.1 (6.4%)<xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">39.3 (7.1%)</td>
<td align="left" rowspan="1" colspan="1">39.9 (5.7%)<xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">-0.05 (0.07)</td>
<td align="left" rowspan="1" colspan="1">-0.43 (0.13)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Occipital Pole</td>
<td align="left" rowspan="1" colspan="1">118</td>
<td align="left" rowspan="1" colspan="1">55.3 (6.7%)<xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">53.6 (8%)</td>
<td align="left" rowspan="1" colspan="1">85.4 (4.1%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.29 (0.08)</td>
<td align="left" rowspan="1" colspan="1">0.22 (0.14)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Precuneus and Caudate</td>
<td align="left" rowspan="1" colspan="1">537</td>
<td align="left" rowspan="1" colspan="1">48.9 (6.2%)<xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">28.6 (7.1%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">53.4 (5.8%)<xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">-0.15 (0.07)</td>
<td align="left" rowspan="1" colspan="1">-0.82 (0.06)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Amygdala and Insula</td>
<td align="left" rowspan="1" colspan="1">454</td>
<td align="left" rowspan="1" colspan="1">59.6 (6%)<xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">75 (6.7%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">54.4 (5.7%)<xref rid="t002fn003" ref-type="table-fn">*</xref></td>
<td align="left" rowspan="1" colspan="1">0.39 (0.06)</td>
<td align="left" rowspan="1" colspan="1">0.76 (0.08)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Virtual Lesion-Cluster Removed</td>
<td align="left" rowspan="1" colspan="1">Visual (LOC)</td>
<td align="left" rowspan="1" colspan="1">4322</td>
<td align="left" rowspan="1" colspan="1">85.1 (4%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">46.4 (8.4%)</td>
<td align="left" rowspan="1" colspan="1">96.1 (2.3%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.72 (0.05)</td>
<td align="left" rowspan="1" colspan="1">-0.17 (0.13)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Somatosensory and STG</td>
<td align="left" rowspan="1" colspan="1">4995</td>
<td align="left" rowspan="1" colspan="1">91.5 (3%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">64.3 (8%)</td>
<td align="left" rowspan="1" colspan="1">93.2 (2.9%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.87 (0.01)</td>
<td align="left" rowspan="1" colspan="1">0.67 (0.11)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Sensorimotor and V1</td>
<td align="left" rowspan="1" colspan="1">4968</td>
<td align="left" rowspan="1" colspan="1">95.7 (2.1%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">50 (8%)</td>
<td align="left" rowspan="1" colspan="1">97.2 (1.9%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.9 (0.01)</td>
<td align="left" rowspan="1" colspan="1">0.08 (0.15)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">DMPFC and PCC</td>
<td align="left" rowspan="1" colspan="1">4985</td>
<td align="left" rowspan="1" colspan="1">89.4 (3.4%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">57.1 (8.7%)</td>
<td align="left" rowspan="1" colspan="1">97.2 (1.9%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.9 (0.01)</td>
<td align="left" rowspan="1" colspan="1">0.37 (0.14)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Sensorimotor and Cerebellum</td>
<td align="left" rowspan="1" colspan="1">4076</td>
<td align="left" rowspan="1" colspan="1">91.5 (3%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">60.7 (8.4%)</td>
<td align="left" rowspan="1" colspan="1">96.1 (2.3%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.84 (0.02)</td>
<td align="left" rowspan="1" colspan="1">0.56 (0.11)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Parahippocampal Gyrus</td>
<td align="left" rowspan="1" colspan="1">4278</td>
<td align="left" rowspan="1" colspan="1">85.1 (4%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">67.9 (7.1%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">96.1 (2.3%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.83 (0.02)</td>
<td align="left" rowspan="1" colspan="1">0.62 (0.11)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Occipital Pole</td>
<td align="left" rowspan="1" colspan="1">5185</td>
<td align="left" rowspan="1" colspan="1">93.6 (2.6%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">64.3 (7.6%)</td>
<td align="left" rowspan="1" colspan="1">97.2 (1.9%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.89 (0.01)</td>
<td align="left" rowspan="1" colspan="1">0.46 (0.14)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Precuneus and Caudate</td>
<td align="left" rowspan="1" colspan="1">4766</td>
<td align="left" rowspan="1" colspan="1">89.4(3.4%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">66.1(7.8%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">96.1(2.3%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.85(0.02)</td>
<td align="left" rowspan="1" colspan="1">0.76(0.07)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">Amygdala and Insula</td>
<td align="left" rowspan="1" colspan="1">4849</td>
<td align="left" rowspan="1" colspan="1">91.5(3%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">57.1(8.4%)</td>
<td align="left" rowspan="1" colspan="1">97.2(1.9%)<xref rid="t002fn002" ref-type="table-fn"><sup>+</sup></xref></td>
<td align="left" rowspan="1" colspan="1">0.9(0.01)</td>
<td align="left" rowspan="1" colspan="1">0.25(0.15)</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>All balanced accuracies reported in this table result from single interval classification on the test sample (<italic>n</italic> = 47; see <xref rid="pbio.1002180.s013" ref-type="supplementary-material">S2 Table</xref> for forced-choice test). Analyses involving Level 5 and/or Level 1 comparisons exclude participants that did not rate any stimuli with that label. Accuracy values reflect the ability to discriminate the conditions compared, but are signed so that values &gt;50% indicate the proportion of participants for which high intensity was classified as greater than low intensity for high vs. low analyses, or emotion was greater than pain for Emotion vs. Pain analyses.  Values &lt; 50% indicate the proportion of participants for which low intensity was classified as greater than high intensity or pain was classified as greater than emotion.  For example, the 10.7% emotion classification of the NPS in the Emotion vs. Pain analysis should be interpreted as a 89.3% hit rate in discriminating pain from emotion. Correlations reflect Pearson correlations between participant’s pattern responses to levels of affective intensity and self-reported ratings averaged across participants.</p></fn>
<fn id="t002fn002"><p><sup>+</sup>Indicates that accuracy is significantly different from chance (50%) using a two-tailed binomial test.</p></fn>
<fn id="t002fn003"><p>*Indicates accuracy is significantly different from PINES performance using a two-sample, two-tailed z-test for proportions (only tested on Emotion 5 versus 1 and Emotion versus Pain columns).</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
</sec>
<sec id="sec017" sec-type="conclusions">
<title>Discussion</title>
<p>For neuroimaging to be useful in translational applications (e.g., psychiatry, neurology, etc.), sensitive and specific brain signatures must be developed that can be applied to individual people to yield information about their emotional experiences, neuropathology, or treatment prognosis [<xref rid="pbio.1002180.ref025" ref-type="bibr">25</xref>]. Thus far, the neuroscience of emotion has yielded many important results but no such indicators for emotional experiences. Signatures that are sensitive and specific for particular affective processes are presumably much closer to brain representations of emotional experience, which can then be interrogated to better understand the mechanisms and typology of emotion at the neurophysiological level.</p>
<p>The goals of the present study were to: (a) develop a brain signature capable of reliably and accurately predicting the intensity of negative emotional responses to evocative images, (b) characterize the signature’s performance in generalizing across individual participants and images, (c) examine its specificity related to another negative and arousing affective experience (pain), and (d) explore the structure of the subnetworks necessary and sufficient to predict negative emotional experience.</p>
<p>We used cross validated machine learning analyses to identify a distributed pattern of activity predictive of emotional experiences, which we term PINES. The PINES fulfills the basic criteria for a brain signature of negative affect. It accurately predicted monotonic increases in negative affect ratings in 93.5% of individual test participants (<italic>n</italic> = 61; single interval). In forced-choice tests, it correctly identified which of two sets of images was rated as more negative in 90%–100% of individuals, as long as the images differed by two or more subjective rating points (on a five point scale). This demonstrates sensitivity to negative affect across the full range of the measurement scale.</p>
<p>PINES responses were also surprisingly specific to negative emotion. The PINES did not respond to increased levels of physical pain, another type of arousing, aversive, salient experience. Conversely, the NPS [<xref rid="pbio.1002180.ref035" ref-type="bibr">35</xref>]—a signature previously found to be sensitive and specific to physical pain—responded strongly to physical pain but not to increasing levels of picture-induced emotional intensity. This double dissociation implies that neither pattern is driven by general arousal, salience, or negative affect. Though the PINES and NPS independently tracked the intensity of negative affect elicited in visual and somatosensory modalities, respectively, we do not believe they are dissociable based simply on differences in sensory processing for two reasons: (1) the PINES was just as accurate in predicting negative emotion without the occipital lobe, and when subnetworks associated with modality-specific processes were removed (e.g., visual, somatosensory, etc.) and (2) the local PINES and NPS patterns within traditional “affect” regions, such as the ACC and insula, were uncorrelated. This is consistent with our previous work demonstrating that pain is distinct from other emotional processes based on distributed spatial topography both across brain regions [<xref rid="pbio.1002180.ref028" ref-type="bibr">28</xref>] and within local regions [<xref rid="pbio.1002180.ref035" ref-type="bibr">35</xref>,<xref rid="pbio.1002180.ref067" ref-type="bibr">67</xref>].</p>
<p>Further analyses explored the nature of emotion-predictive brain representations. The PINES was comprised of multiple separable subnetworks. Each network independently contributed to the prediction of participants’ negative emotion ratings controlling for other brain regions, and no single network was necessary or sufficient for predicting emotional experience. This pattern of results suggests that the PINES is a distributed pattern that encompasses a number of functional systems, and that multiple systems are required to capture negative affective experience.</p>
<sec id="sec018">
<title>Implications for Theory and Measurement of Emotion</title>
<p>These results have theoretical implications for the neurobiology of emotion in terms of both the diversity of processes underlying affective experiences and how they are represented in the brain. Emotions are often defined as a composite of multiple intrinsically inter-related processes (e.g., autonomic arousal, expressive behavior, action tendencies, interoception, and conscious experiences). Theories differ widely on how these processes combine to give rise to emotional experience [<xref rid="pbio.1002180.ref001" ref-type="bibr">1</xref>], but most major theories suggest that cognitive, sensory, motor, motivational, and interoceptive processes are critical ingredients of emotional experience. For example, appraisal theories view emotion as a dynamically unfolding process and emphasize the role of appraisals [<xref rid="pbio.1002180.ref008" ref-type="bibr">8</xref>,<xref rid="pbio.1002180.ref068" ref-type="bibr">68</xref>,<xref rid="pbio.1002180.ref069" ref-type="bibr">69</xref>], embodied affect theories emphasize interoceptive and somatomotor representations [<xref rid="pbio.1002180.ref070" ref-type="bibr">70</xref>], and constructionist theories view emotions as being constructed from all of these component processes [<xref rid="pbio.1002180.ref012" ref-type="bibr">12</xref>,<xref rid="pbio.1002180.ref018" ref-type="bibr">18</xref>].</p>
<p>In spite of this richness, since MacLean [<xref rid="pbio.1002180.ref071" ref-type="bibr">71</xref>], theories of the emotional brain have treated emotion as a singular faculty that is localizable to a specific system. Often, this view has translated into “structure-centric” theories of emotional experience; e.g., the amygdala is critical for fear [<xref rid="pbio.1002180.ref072" ref-type="bibr">72</xref>], the ACC for pain affect [<xref rid="pbio.1002180.ref073" ref-type="bibr">73</xref>], and the insula for disgust [<xref rid="pbio.1002180.ref074" ref-type="bibr">74</xref>]. In other cases, this view translates into circumscribed pathways or networks for “core affect” [<xref rid="pbio.1002180.ref017" ref-type="bibr">17</xref>] and emotional awareness [<xref rid="pbio.1002180.ref075" ref-type="bibr">75</xref>].</p>
<p>It remains unclear how far the structure-centric view can take us in understanding the brain bases of emotional experience. The regions most strongly identified with emotion are also intimately involved in a wide array of cognitive functions such as attention, error monitoring, associative learning, and executive control [<xref rid="pbio.1002180.ref033" ref-type="bibr">33</xref>]. Recent connectivity [<xref rid="pbio.1002180.ref063" ref-type="bibr">63</xref>] and functional diversity analyses [<xref rid="pbio.1002180.ref032" ref-type="bibr">32</xref>] suggest that these regions are not solely processing affective signals but rather represent functional “hubs” for integrating many types of information.</p>
<p>As the limitations of the structure-centric view are increasingly widely recognized [<xref rid="pbio.1002180.ref012" ref-type="bibr">12</xref>,<xref rid="pbio.1002180.ref033" ref-type="bibr">33</xref>], researchers have moved towards the identification of intrinsically connected networks conserved both at rest and during active tasks [<xref rid="pbio.1002180.ref076" ref-type="bibr">76</xref>]. These networks have been labeled with process-general names including the “salience network” [<xref rid="pbio.1002180.ref063" ref-type="bibr">63</xref>], “default mode” network [<xref rid="pbio.1002180.ref077" ref-type="bibr">77</xref>], and others, and a modern incarnation of the “emotional brain” theory suggests that the basis of emotional experience is encapsulated in one or a few of these networks such as the “limbic” network named after MacLean’s original formulation.</p>
<p>Our results corroborate the view that structure-centric—and even network-centric—models of emotion are limited and provide an alternative model for the brain representation of emotional experience. In this study, we targeted the conscious experience component, which is the defining feature of subjective distress and suffering. None of the anatomical regions identified in previous literature (e.g., amygdala, ACC, insula) predicted the intensity of emotional experience or discriminated emotion from pain in this study. This suggests that the effects identified in previous work using traditional statistical parametric mapping approaches are small and unlikely to serve as effective signatures of the type or magnitude of an emotional experience in an individual person.</p>
<p>Furthermore, activity in predefined networks was insufficient to capture negative emotion ratings, demonstrating that the pattern we identified using targeted machine-learning analysis is not reducible to these more process-general networks. The fact that networks and regions defined a priori, even from very large resting-state samples [<xref rid="pbio.1002180.ref057" ref-type="bibr">57</xref>], were insufficient to capture emotional experience here has broad implications for the study of emotion and attempts to identify biomarkers for mental health disorders going forward [<xref rid="pbio.1002180.ref021" ref-type="bibr">21</xref>,<xref rid="pbio.1002180.ref025" ref-type="bibr">25</xref>,<xref rid="pbio.1002180.ref049" ref-type="bibr">49</xref>].</p>
<p>Finally, our clustering analysis of the PINES map indicated that multiple, separable subnetworks distributed widely throughout the brain made independent contributions to predicting emotional experience. Importantly, no single subnetwork appeared to be necessary or sufficient in characterizing the emotional experience, as the accuracy in predicting the magnitude or type of experience did not significantly decrease when any given network was omitted. This pattern is consistent with both appraisal [<xref rid="pbio.1002180.ref068" ref-type="bibr">68</xref>,<xref rid="pbio.1002180.ref069" ref-type="bibr">69</xref>] and constructionist theories of emotion [<xref rid="pbio.1002180.ref012" ref-type="bibr">12</xref>,<xref rid="pbio.1002180.ref078" ref-type="bibr">78</xref>], which posit that emotional experiences result from interactions between core affect, sensory, memory, motor, and cognitive systems [<xref rid="pbio.1002180.ref040" ref-type="bibr">40</xref>].</p>
</sec>
<sec id="sec019">
<title>Conclusions, Limitations, and Future Directions</title>
<p>Overall, these results provide an important step towards identifying emotion-related patterns that can serve as indicators for components of emotional experience. Such signatures can be used as intermediate phenotypes for genetic or risk-stratification studies, and they may provide objective neurobiological measures that can supplement self-report. The identification of intermediate brain-based phenotypes is critical, as self-reported emotion can be affected by many independent processes [<xref rid="pbio.1002180.ref008" ref-type="bibr">8</xref>,<xref rid="pbio.1002180.ref018" ref-type="bibr">18</xref>,<xref rid="pbio.1002180.ref068" ref-type="bibr">68</xref>]—e.g., core experience, self-reflection, decision-making heuristics, and communicative intentions—which have different implications for understanding what exactly treatments that modulate emotion are measuring and which processes are affected by interventions.</p>
<p>We close with several key points and future directions. Importantly, the PINES is not necessarily a biomarker of negative emotion in general. We have demonstrated that it is a signature for the type of affect induced by aversive IAPS images, but its transferability to other emotional states (e.g., emotion induced by recall, rejection, positive emotion, or stress) remains to be tested. Such tests are a long-term program of future research that must span many studies and papers. We still know very little about the underlying structure of affect and which types of emotional responses can be cross predicted by the same brain markers. It is possible that the PINES captures some types of negative emotion and not others, and findings to this effect will help us move beyond the categories proscribed in our language to develop a more nuanced, brain-based view of affective processes [<xref rid="pbio.1002180.ref007" ref-type="bibr">7</xref>,<xref rid="pbio.1002180.ref017" ref-type="bibr">17</xref>].</p>
<p>In addition, testing the specificity and transfer of the PINES across many different kinds of affect is a key to developing more robust and specific markers. The PINES can undoubtedly be improved. For example, with further development and testing, it may be differentiated into markers for more specific types of emotional experiences (e.g., emotion categories like fear, disgust, etc. or canonical affect-inducing appraisals). In addition to types of affect, the PINES can be tested for responses across patient groups (e.g., schizophrenia, depression, or anxiety) and treatments thought to affect emotion (e.g., self-regulation, drug treatment, psychotherapy, etc.). This study provides a foundation and a benchmark for such future developments.</p>
</sec>
</sec>
<sec id="sec020" sec-type="materials|methods">
<title>Methods</title>
<p>All participants provided written informed consent, and experimental procedures were approved by the Institutional Review Board of the University of Pittsburgh for the IAPS study and the University of Colorado, Boulder for the pain study.</p>
<sec id="sec021">
<title>IAPS Data Set</title>
<sec id="sec022">
<title>Participants</title>
<p>One hundred eighty three participants (mean age = 42.77 y, SD = 7.3 y; female = 52%; Caucasian = 87%) were recruited from the greater Pittsburgh area to participate in this study. One participant was excluded due to missing data. Participants were recruited from a larger study on health and full details regarding recruitment procedures, the study sample, and testing procedures have been previously reported [<xref rid="pbio.1002180.ref079" ref-type="bibr">79</xref>]. The findings reported in this paper have not been previously reported and do not overlap with those in published reports from this larger study.</p>
</sec>
<sec id="sec023">
<title>Stimuli</title>
<p>Task stimuli consisted of 15 negative photographs and 15 neutral photographs selected from the IAPS [<xref rid="pbio.1002180.ref050" ref-type="bibr">50</xref>]. Pictures were presented using the E-Prime stimulus presentation software (Psychology Software Tools, Sharpsburg, PA). A small mirror was attached to the head coil enabling the viewing of projected images onto a screen while in the scanner. Negative photographs (Pictures: 2053, 3051, 3102, 3120, 3350, 3500, 35550, 6831, 9040, 9050, 9252, 9300, 9400, 9810, and 9921) depicted bodily illness and injury (ten photographs), acts of aggression (two photographs), members of hate groups (one photograph), transportation accidents (one photograph), and human waste (one photograph). Neutral photographs (Pictures: 5720, 5800, 7000, 7006, 7010, 7040, 7060, 7090, 7100, 7130, 7150, 7217, 7490, 7500, 9210) depicted inanimate objects (ten photographs) or neutral scenes (five photographs).</p>
</sec>
<sec id="sec024">
<title>Task</title>
<p>Participants completed a reappraisal task and were instructed to either (a) “look” and maintain their attention to the photos when they came on screen and allow their emotional reactions to occur naturally or (b) “decrease” and change the way they thought about the image to feel less negative (see [<xref rid="pbio.1002180.ref079" ref-type="bibr">79</xref>] for full task and IAPS stimulus details). Each trial consisted of a 2 sec instructional cue, “look”, followed by the 7 sec presentation of either a negative or neutral image. After the stimulus presentation, participants were given a 4 sec opportunity to report their emotional state using a 5-point Likert scale (where 1 indicated feeling neutral and 5 indicated feeling strongly negative). Finally, there was a variable (jittered) 1–3 sec rest period before the next cue (<xref rid="pbio.1002180.g001" ref-type="fig">Fig 1A</xref>). We emphasized to participants to base their ratings on how negative they felt at the end of the image-viewing period. Only “look” trials were included in analyses for this paper. Though we use participants’ ratings to train and test our brain model, not every participant reported every level of emotion. For the training sample (<italic>n</italic> = 121), 98% used a “1,” 88% used a “2,” 98% used a “3,” 88% used a “4,” and 80% used a “5” in their response. For the test sample (<italic>n</italic> = 61), 100% used a “1,” 89% used a “2,” 93% used a “3,” 95% used a “4,” and 77% used a “5” in their response. The lower frequency of participants making a rating of “5” resulted in smaller sample sizes in “1” versus “5” rating accuracy tests.</p>
</sec>
<sec id="sec025">
<title>Imaging data acquisition</title>
<p>Imaging data were acquired on a 3T Trio TIM whole-body scanner (Siemens, Erlangen, Germany) using a 12-channel, phased-array head coil. Each session included a structural scan for coregistration of the functional images (FOV = 200 × 200 mm, matrix = 256 ×256, TR = 3,000 ms, inversion time (TI) = 100 ms, TE = 11/101 ms, and FA = 150°, 36 slices, 3 mm thick, no gap) and a functional scan, which included 344 blood oxygen level dependent (BOLD) images (FOV = 200 × 200 mm, matrix = 64 × 64, TR = 2,000 ms, TE = 29 ms, flip angle (FA) = 90°, 34 3 mm slices with no gap).</p>
</sec>
<sec id="sec026">
<title>Imaging preprocessing</title>
<p>fMRI data were preprocessed and analyzed using SPM8 (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm" xlink:type="simple">http://www.fil.ion.ucl.ac.uk/spm</ext-link>) and custom Matlab (MATLAB, The MathWorks, Inc., Natick, MA) code available from the authors’ website (<ext-link ext-link-type="uri" xlink:href="http://canlab.colorado.edu" xlink:type="simple">http://canlab.colorado.edu</ext-link>). Images were first unwarped and realigned to the first image of the series using a six-parameter, rigid-body transformation. The realigned images were then coregistered to each participant’s T2-weighted structural image and normalized to the 152 MNI template using a 12-parameter nonlinear and affine transformation. Spatially normalized images were smoothed with a 6 mm full-width-at-half-maximum (FWHM) Gaussian kernel and filtered with a high pass filter (180 sec cutoff). When using whole-brain prediction, smoothing is thought to improve sensitivity to large-scale patterns [<xref rid="pbio.1002180.ref080" ref-type="bibr">80</xref>], which can likely improve between subject predictions.</p>
<p>A univariate general linear model (GLM) was used to create images for the prediction analysis (<xref rid="pbio.1002180.g001" ref-type="fig">Fig 1B</xref>). The model included one boxcar regressor indicating the rating period, to model any effects related to motor activity, and another modeling the mean picture viewing epoch. The model also include five separate boxcar regressors indicating the onset times for each IAPS picture, which allowed us to model brain activity in response to each picture separately for each rating level (e.g., [<xref rid="pbio.1002180.ref001" ref-type="bibr">1</xref>–<xref rid="pbio.1002180.ref005" ref-type="bibr">5</xref>]). All regressors were convolved with a double gamma HRF function, and an additional 24 covariate regressors modeled movement effects (6 realignment parameters demeaned, their 1st derivatives, and the squares of these 12 regressors).</p>
</sec>
</sec>
<sec id="sec027">
<title>Pain Data Set</title>
<sec id="sec028">
<title>Participants</title>
<p>Thirty healthy, right-handed participants (Mean Age = 25.2 y, STD = 7.4 y, female = 40%) were recruited to participate in an fMRI study in which they received thermal pain stimulation (details on additional counterbalanced sessions is described in a separate manuscript [<xref rid="pbio.1002180.ref056" ref-type="bibr">56</xref>]). Twenty-eight participants completed the thermal pain session. Participants with psychiatric, physiological, or pain disorders, and neurological conditions were excluded.</p>
</sec>
<sec id="sec029">
<title>Pain calibration</title>
<p>All participants completed a pain calibration session to determine if they could tolerate the thermal stimulations that they would receive in the fMRI experiment. Thermal stimulation was applied on the volar surface of the left forearm and dorsal surface of the left foot using a TSA-II Neurosensory Analyzer (Medoc Ltd., Chapel Hill, NC) with a 16 mm Peltier thermode end plate. Three levels of thermal stimulation (pseudorandomly assigned to each participant)—low (44 or 45°C), medium (46 or 47°C), and high (48 or 49°C)—were applied to four different locations on both the upper limb (i.e., volar surface of the left forearm) and lower limb (i.e., dorsal surface of the left foot). Each stimulation lasted a total of 11 seconds with a 2 sec ramp-up, a 2 sec ramp-down, and 7 sec at the peak target temperature. The participants made responses on a Visual Analog Scale (VAS), which had anchors based on a labeled magnitude rating scale [<xref rid="pbio.1002180.ref081" ref-type="bibr">81</xref>,<xref rid="pbio.1002180.ref082" ref-type="bibr">82</xref>]. Participants first made a moment-by-moment rating where they used a pointer on the screen to move continuously along the rating scale and indicate the level of sensation they felt at each moment. They then made an overall rating at the end of each trial to indicate the maximum overall sensation they experienced in that trial. Participants who successfully completed the calibration procedure were then scheduled for the fMRI sessions.</p>
</sec>
<sec id="sec030">
<title>fMRI session</title>
<p>Participants completed a separate scanning session for thermal pain that contained 11 runs and lasted about an hour. Each stimulation (i.e., 46, 47, and 48°C of heat) was preceded by a predictive cue (i.e., three levels of cues that corresponded to three levels of stimulation). Prior to being scanned, participants completed a short training in which they learned the levels of the three cues that were to be later presented in the scanner through an explicit learning task [<xref rid="pbio.1002180.ref083" ref-type="bibr">83</xref>]. The first two fMRI runs consisted of a conditioning task where the participant learned the association between the cues they encountered in the prescan training and the level of stimulation for that session. During both the conditioning (two runs) and experimental runs (nine runs), participants received a cue—stimulus pair for each trial and were asked to make a rating on a visual analogue scale (same as the calibration session) about the sensation they felt after each trial. The participants rated the intensity of pain they felt during each trial. Each experimental run contained nine trials (81 total), which were counterbalanced for each participant using a Latin Square design. Experimental trials (i.e., postconditioning) began with a 2 sec cue followed by a systematic jitter separating the cue from stimulation (i.e., 5, 7, 11 sec). Participants then received stimulation for 11 sec followed by a jittered fixation (2, 6, or 14 s). The 11 sec trial duration for somatic pain included a 2 sec ramp-up, 2 sec ramp-down, and 7 sec at-target temperature. Finally, participants had 4 sec to make a rating of the sensation they experienced for the stimulation on a visual analogue scale using a trackball (responses were confirmed with a button click). There was an intertrial jittered fixation (1, 4, or 10 sec) that was counterbalanced across trials within a run so that all runs were of equal duration. Stimulus presentation and behavioral data acquisition were controlled using Matlab software.</p>
</sec>
<sec id="sec031">
<title>Imaging acquisition</title>
<p>fMRI data were acquired on a Siemens Tim Trio 3T MRI scanner at the Intermountain Neuroimaging Consortium facility at the University of Colorado, Boulder. Structural images were acquired using high-resolution T1 spoiled gradient recall images (SPGR) for anatomical localization and warped to Montréal Neurological Institute or MNI space. Functional images were acquired with an echoplanar imaging sequence (TR = 1,300 ms, TE = 25 ms, field of view = 220 mm, 64 x6 4 matrix, 3.4 x 3.4 x 3.4 mm voxels, 26 interleaved slices with ascending acquisition, parallel imaging with an iPAT acceleration of 2).</p>
</sec>
<sec id="sec032">
<title>Preprocessing</title>
<p>All images were preprocessed using SPM8 (Wellcome Trust Centre for Neuroimaging, London, UK) and custom Matlab functions. Mean structural T1-weighted images were computed for each participant from all imaging sessions. The mean structural images were then coregistered to the first functional image for each participant with an iterative procedure of automated registration using mutual information from the coregistration in SPM8 and manual adjustment of the automated algorithm’s starting point until the automated procedure provided satisfactory alignment, and were normalized to MNI space using SPM8, interpolated to 2 × 2 × 2 mm voxels.</p>
<p>Functional images were corrected for slice-acquisition-timing and motion using SPM8. They were then warped to SPM’s normative atlas using warping parameters estimated from coregistered, high-resolution structural images, interpolated to 2 × 2 × 2 mm voxels, and smoothed with an 8 mm FWHM Gaussian kernel.</p>
<p>Prior to preprocessing of functional images, global outlier time points (i.e., “spikes” in signal) were identified by computing both the mean and the standard deviation (across voxels) of values for each image for all slices. Mahalanobis distances for the matrix of slicewise mean and standard deviation values (concatenated) were computed for all functional volumes (time), and any values with a significant χ<sup>2</sup> value (corrected for multiple comparisons) were considered outliers (less than 1% of images were outliers). The output of this procedure was later used as a covariate of noninterest in the first level models.</p>
</sec>
<sec id="sec033">
<title>fMRI analysis</title>
<p>First-level GLM analyses were conducted in SPM8. The first six volumes of each run were discarded, and the nine experimental runs were concatenated for each participant (the first two conditioning runs were excluded). Boxcar regressors, convolved with the canonical hemodynamic response function, were constructed to model periods for the 2 sec cue presentation, the 5, 7, or 11 sec variable prestimulus fixation period, the 11 sec thermal stimulation, and the 4 sec rating periods. The fixation cross epoch was used as an implicit baseline. A high-pass filter of 224 sec was used for the somatic pain session, which was determined based on a first-level analysis on the two conditioning runs, in which the variance inflation factor was determined to be less than 5%. Contrasts of interest included the low, medium, and high stimulation period collapsed across cues (i.e., low, medium, and high) and body site (i.e., upper limb and lower limb).</p>
</sec>
</sec>
<sec id="sec034">
<title>Analysis Methods</title>
<sec id="sec035">
<title>Machine learning</title>
<p>We used whole-brain multivariate machine learning pattern analysis [<xref rid="pbio.1002180.ref035" ref-type="bibr">35</xref>,<xref rid="pbio.1002180.ref053" ref-type="bibr">53</xref>] to find global patterns of brain activity that best predicted participants’ self-reported affective ratings (e.g., 1–5; <xref rid="pbio.1002180.g001" ref-type="fig">Fig 1C</xref>). A machine-learning prediction algorithm simply refers to a function that uses a vector of features (independent variables) to predict the value of a continuous outcome variable (see [<xref rid="pbio.1002180.ref084" ref-type="bibr">84</xref>] for an introduction to this approach in the context of fMRI analysis). Here, we used individual voxels of brain activity as features and used them to predict participants’ affective ratings of the pictures they viewed while undergoing fMRI. The LASSO-PCR algorithm [<xref rid="pbio.1002180.ref035" ref-type="bibr">35</xref>,<xref rid="pbio.1002180.ref053" ref-type="bibr">53</xref>] combines principal components regression with an L1 least squares regularization [<xref rid="pbio.1002180.ref085" ref-type="bibr">85</xref>]. Each 3-D map of beta weights from the first level analysis was converted into a single vector and used to predict the affective rating value. Because there are considerably more voxels (<italic>n</italic> = 352,328) than subjects (<italic>n</italic> = 182), we first reduced the brain data into the same number of components as observations in our training dataset (<italic>n</italic> = 121) using a principal components analysis. Each component represents many different brain voxels that share a similar pattern. These components were then used to predict affective ratings using least squares regression with an L-1 regularization (LASSO). This regularization shrinks beta parameters to zero. Components with a nonzero beta were selected and then refit using OLS to ensure that they were not unduly affected by the shrinkage (see [<xref rid="pbio.1002180.ref085" ref-type="bibr">85</xref>]). The betas were then back-projected into voxels in 3-D MNI space.</p>
</sec>
<sec id="sec036">
<title>Cross validation</title>
<p>To minimize the possibility of our algorithm overfitting the data, we used a rigorous cross validation procedure [<xref rid="pbio.1002180.ref085" ref-type="bibr">85</xref>,<xref rid="pbio.1002180.ref086" ref-type="bibr">86</xref>]. The general principle of cross validation is to divide a dataset into two parts; one is used to “train” the classifier, and the other is used to “test” the accuracy of the classifier. This procedure minimizes overfitting and ensures that the predictive power of the algorithm generalizes beyond the training dataset. There are a variety of cross validation procedures, and here we used a very conservative stratified double cross validation approach to maximize the generalizability of our results [<xref rid="pbio.1002180.ref054" ref-type="bibr">54</xref>]. We first divided the dataset into a training set (2/3 of sample, <italic>n</italic> = 121) and a final test dataset (1/3 of sample, <italic>n</italic> = 61) by stratifying the data along each participant’s average negative rating (this ensured that the average ratings were equal across groups). The training data were then subjected to a leave-one-subject-out cross validation. In this approach, N-1 participants’ beta images are trained to predict the corresponding affective rating, and then these weights are tested on the left out participant’s data. This process provides an efficient procedure to allow every data point to serve as both training and test data. The master holdout set, which was not used in the training cross validation procedure was then used to assess the final accuracy of the algorithm.</p>
</sec>
<sec id="sec037">
<title>Determining predictive voxels</title>
<p>The cross validated PINES pattern consists of the weights of each voxel in predicting the affective rating plus the intercept. However, to determine the voxels that made the most reliable contributions to the classification, we performed a bootstrap test [<xref rid="pbio.1002180.ref087" ref-type="bibr">87</xref>]. This involved taking 5,000 samples with replacement from the training dataset and repeating the prediction process with each bootstrap sample. We then converted this distribution into a z-value at each voxel and thresholded the map based on the corresponding <italic>p</italic>-value. We used multiple thresholds to highlight the regions that were most consistently predictive in the classification procedure (i.e., <italic>p</italic> &lt; 0.01, 0.005, 0.001 uncorrected, and FDR <italic>p</italic> &lt; 0.05 corrected). All predictions using the test data were performed with the full set of unthresholded weights, which included all nonzero voxels. We use <italic>p</italic> &lt; 0.001 for display purposes as we found that this sparse map was able to predict responses almost as well as the full weight map (<xref rid="pbio.1002180.s004" ref-type="supplementary-material">S2 Fig</xref>). However, we use the full weight map for all analyses reported in this manuscript.</p>
</sec>
<sec id="sec038">
<title>Prediction</title>
<p>To test the performance of the PINES, we applied the pattern to novel test datasets to quantify the degree to which the pattern was expressed in other datasets. This approach is critical to assessing the convergent and discriminant validity of the PINES response [<xref rid="pbio.1002180.ref088" ref-type="bibr">88</xref>]. The degree to which the PINES was expressed in other datasets, i.e., the PINES response (PR), was estimated for each test subject in each test condition by taking the dot product of the vectorized activation images (<inline-formula id="pbio.1002180.e005"><alternatives><graphic id="pbio.1002180.e005g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.e005" xlink:type="simple"/><mml:math display="inline" id="M5" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>) with the signature pattern (<inline-formula id="pbio.1002180.e006"><alternatives><graphic id="pbio.1002180.e006g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.e006" xlink:type="simple"/><mml:math display="inline" id="M6" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>), i.e., (<inline-formula id="pbio.1002180.e007"><alternatives><graphic id="pbio.1002180.e007g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.e007" xlink:type="simple"/><mml:math display="inline" id="M7" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>⋅</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>) yielding a single scalar value. Pattern response values were averaged across subjects in the test datasets. This method allows us to make a pointed prediction about the affective rating akin to regression. We also used spatial correlation to compare the relationship between the pattern and various maps. This method facilitates comparing relationships across maps with different numbers of voxels and intensities and is proportional to the dot product except scaled between −1–1. For binary maps (e.g., resting-state network parcellations [<xref rid="pbio.1002180.ref057" ref-type="bibr">57</xref>]), we used point-biserial correlations, and for comparing specific regions of the weight maps, we used robust regression.</p>
</sec>
<sec id="sec039">
<title>Within subject prediction</title>
<p>To examine the possibility of the prediction weights being influenced by poor anatomical registration, we ran an additional analysis in which we trained a separate model for each subject in the training sample (<italic>n</italic> = 121) and evaluated the consistency of each weight for every voxel in the brain across subjects using a one-sample <italic>t</italic> test. We used the LASSO-PCR algorithm with a 5-fold cross validation to predict participant ratings for individual IAPS pictures. We compared the performance of these individual weight maps to the cross-validated PINES map. This allowed us to test the performance of the PINES on an individual participant’s trial-level data without blurring the boundary between training and test data. Functional alignment techniques [<xref rid="pbio.1002180.ref089" ref-type="bibr">89</xref>] are a promising solution to addressing issues concerning individual variability in anatomical registrations and should be considered in future work.</p>
</sec>
<sec id="sec040">
<title>Evaluation</title>
<p>To evaluate the performance of the LASSO-PCR algorithm, we compared the model’s prediction with the actual rating by calculating the RMSE to illustrate overall prediction error and a Pearson correlation to indicate the effect size. Accuracy was determined using both forced-choice and single-interval classification methods from receiver operator characteristic curves (ROC). Forced-choice accuracy is “threshold free” in that it takes the maximum value of a relative comparison within a subject. It has an interesting property that the ROC curves are symmetrical, and sensitivity, specificity, and positive predictive value are equivalent to each other and to decision accuracy (i.e., the probability with which the more painful of the two conditions is selected). For single-interval classification, we used balanced accuracy [<xref rid="pbio.1002180.ref090" ref-type="bibr">90</xref>] formalized as,
<disp-formula id="pbio.1002180.e008">
<alternatives>
<graphic id="pbio.1002180.e008g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002180.e008" xlink:type="simple"/>
<mml:math display="block" id="M8" overflow="scroll">
<mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) are defined relative to the threshold that minimizes signal detection response bias [<xref rid="pbio.1002180.ref091" ref-type="bibr">91</xref>]. We used a two-tailed dependent binomial z-test to assess the significance of single-interval classification accuracy, a two-tailed independent binomial test for forced-choice classification accuracy, and McNemar’s z-test for comparing two dependent proportions to compare the classification accuracy between the PINES and all other maps [<xref rid="pbio.1002180.ref092" ref-type="bibr">92</xref>].</p>
</sec>
<sec id="sec041">
<title>Clustering</title>
<p>We used hierarchical agglomerative clustering to find predictive regions that showed similar response profiles across trials. For this analysis, we extracted contiguous regions from the PINES that survived the <italic>p</italic> &lt; .001 uncorrected threshold and contained a minimum of ten voxels. These regions provided the strongest contributions to the PINES. Region-specific pattern response values to each trial (<italic>n</italic> = 30) were rank ordered and normalized within-subject to (a) provide statistically robust connectivity estimates, as in nonmetric multidimensional scaling algorithms [<xref rid="pbio.1002180.ref093" ref-type="bibr">93</xref>], and (b) reflect within-subject “beta-series” connectivity, which is both less susceptible to imaging artifacts than raw connectivity [<xref rid="pbio.1002180.ref094" ref-type="bibr">94</xref>] and insensitive to individual differences in hemodynamic variables. Inter-region connectivity matrices were calculated aggregating across trials and subjects and subjected to hierarchical agglomerative clustering with Euclidean distance using the Ward minimum variance algorithm. Clusters were determined using an arbitrary threshold of 31% of the maximum distance, which resulted in nine distinct clusters.</p>
</sec>
</sec>
</sec>
<sec id="sec042">
<title>Supporting Information</title>
<supplementary-material id="pbio.1002180.s001" xlink:href="info:doi/10.1371/journal.pbio.1002180.s001" mimetype="text/csv" position="float" xlink:type="simple">
<label>S1 Data</label>
<caption>
<title>Trial level emotion and pain data.</title>
<p>Contains information about each participant’s trial for the emotion datasets. Pain dataset is averaged within each pain level. File names correspond to nifti files located at <ext-link ext-link-type="uri" xlink:href="http://neurovault.org" xlink:type="simple">http://neurovault.org</ext-link>. Pattern responses to PINES, the within-subject PINES, and each PINES cluster (e.g., C_*).</p>
<p>(CSV)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s002" xlink:href="info:doi/10.1371/journal.pbio.1002180.s002" mimetype="text/csv" position="float" xlink:type="simple">
<label>S2 Data</label>
<caption>
<title>Rating level emotion and pain data.</title>
<p>Contains information about each participant’s average rating for the emotion and pain datasets. Contains average activation within ROIs, resting-state networks, PINES, and NPS pattern responses.</p>
<p>(CSV)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s003" xlink:href="info:doi/10.1371/journal.pbio.1002180.s003" mimetype="image/tiff" position="float" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Weight maps.</title>
<p>This figure depicts axial slice montages of different analytic techniques. PINES FDR: the PINES thresholded using a 5,000 sample bootstrap procedure at FDR q &lt; 0.05 whole-brain corrected with a cluster extent k = 10. PINES-LASSO-PCR the full unthresholded PINES pattern trained with LASSO-PCR (<italic>n</italic> = 121). PINES-n182: the PINES weight map when it is trained with the full dataset (<italic>n</italic> = 182). PINES-SVR: the PINES when it is trained with the training data (<italic>n</italic> = 121) using support vector regression. PINES-within: the average weight map for the within-participant analysis, in which a separate pattern was trained for each participant to predict ratings to individual photos (<italic>n</italic> = 121). PINES-searchlight: standardized prediction values (i.e., correlations) for each voxel from a whole-brain searchlight analysis (<italic>n</italic> = 182).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s004" xlink:href="info:doi/10.1371/journal.pbio.1002180.s004" mimetype="image/tiff" position="float" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>PINES pattern response without occipital lobe.</title>
<p>Panel A depicts the occipital mask excluded from the data prior to training the PINES. Panel B shows the predicted affective rating compared to the actual ratings for the cross validated participants (<italic>n</italic> = 121) and the separate holdout test dataset (<italic>n</italic> = 61).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s005" xlink:href="info:doi/10.1371/journal.pbio.1002180.s005" mimetype="application/eps" position="float" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Varying sample size prediction.</title>
<p>This figure depicts the results for the analysis in which we ran 20 iterations predicting emotion ratings using varying sample sizes. Each iteration randomly sampled participants’ data without replacement. Panel A shows the average standardized prediction (correlation) for each sample size ranging from <italic>n</italic> = 2 through <italic>n</italic> = 121 in the test dataset (<italic>n</italic> = 61). Panel B shows the average single interval cross predicted accuracy for discriminating between high and low levels of pain. Panel C shows the average single interval accuracy discriminating between high levels of emotion and pain in the test dataset. Panel D shows the average spatial correlation of the weight map trained using each sample size with the PINES. Error bars in all panels reflect ±1 standard deviation.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s006" xlink:href="info:doi/10.1371/journal.pbio.1002180.s006" mimetype="image/tiff" position="float" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Searchlight analysis.</title>
<p>This figure depicts results from a whole-brain searchlight analysis in which we trained a searchlight (five voxel radius) to predict emotion rating using LASSO-PCR with the full dataset (<italic>n</italic> = 182) and 5-fold cross validation. Panel A shows the thresholded correlation values for each searchlight (<italic>p</italic> &lt; 0.001, uncorrected). Panel B shows the distribution of the correlation values of all searchlights in the brain. The dotted line shows the cross validated PINES correlation (<italic>n</italic> = 121) for comparison.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s007" xlink:href="info:doi/10.1371/journal.pbio.1002180.s007" mimetype="image/tiff" position="float" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Thresholded PINES pattern response.</title>
<p>Panel A depicts the average forced-choice accuracy between high and low emotion ratings for the hold out test dataset (<italic>n</italic> = 61). The only threshold level that is significantly different from the PINES is the FDR q &lt; 0.01 pattern. Panel B shows the average pattern correlation between each thresholded pattern for each emotion level. Panel C shows the average pattern correlation between each thresholded pattern for each level of pain. Error bars reflect ±1 standard error.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s008" xlink:href="info:doi/10.1371/journal.pbio.1002180.s008" mimetype="image/tiff" position="float" xlink:type="simple">
<label>S6 Fig</label>
<caption>
<title>Network map pattern response.</title>
<p>This figure examines how well resting-state networks perform using the same testing benchmarks as the PINES, NPS, and affective ROIs. The line plot depicts the pattern response of the network parcellation from Yeo et al., 2007 on emotion and pain test datasets using point-biserial spatial correlations. Panel A shows the average network predictions for each level of emotion, while panel B shows the average prediction for each level of pain. Error bars reflect ±1 standard error.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s009" xlink:href="info:doi/10.1371/journal.pbio.1002180.s009" mimetype="application/eps" position="float" xlink:type="simple">
<label>S7 Fig</label>
<caption>
<title>Item analysis with social and nonsocial images.</title>
<p>This figure depicts the item analysis, in which the PINES pattern is tested on responses to individual photos in the test sample (<italic>n</italic> = 61). Error bars reflect ±1 standard error. The red item reflects the sole nonsocial negative image, while the cyan item reflects the sole social neutral image. This suggests that the PINES is not simply picking up on degree of socialness.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s010" xlink:href="info:doi/10.1371/journal.pbio.1002180.s010" mimetype="image/tiff" position="float" xlink:type="simple">
<label>S8 Fig</label>
<caption>
<title>Cross prediction searchlight analysis.</title>
<p>This figure depicts results from a whole-brain searchlight analysis in which we trained a searchlight (five voxel radius) to predict emotion rating using SVR with the training data set (<italic>n</italic> = 121) and 5-fold cross validation. We then applied each searchlight mask to the test pain data set (<italic>n</italic> = 28) to obtain a standardized pattern response, and calculated forced-choice accuracy within each participant to find searchlights that discriminated between high and low levels of pain. We show the accuracy results thresholded at <italic>p</italic> &lt; 0.001 (note FDR q &lt; 0.05 = <italic>p</italic> &lt; 0.0015).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s011" xlink:href="info:doi/10.1371/journal.pbio.1002180.s011" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S1 Methods</label>
<caption>
<title>Contains supplemental analyses and results including: alternative PINES algorithms and analysis strategies, searchlight and cross-prediction analyses, thresholded PINES analyses, and anatomical ROI analyses.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s012" xlink:href="info:doi/10.1371/journal.pbio.1002180.s012" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Pattern forced-choice classification.</title>
<p>All balanced accuracies reported in this table result from forced-choice classification on the test dataset (<italic>n</italic> = 47). This analysis excludes participants that did not make a rating of either “1” or “5.” <sup>+</sup>indicates that accuracy is significantly different from chance (50%) using a two-tailed independent samples binomial test. *indicates accuracy significantly different from PINES performance using a two-sample, two-tailed z-test for proportions.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s013" xlink:href="info:doi/10.1371/journal.pbio.1002180.s013" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S2 Table</label>
<caption>
<title>Virtual lesion forced-choice classification.</title>
<p>All balanced accuracies reported in this table result from forced-choice classification on the test dataset (<italic>n</italic> = 47). This analysis excludes participants that did not make a rating of either “1” or “5.” <sup>+</sup>indicates that accuracy is significantly different from chance (50%) using a two-tailed independent samples binomial test. *indicates accuracy significantly different from PINES performance using a two-sample, two-tailed z-test for proportions.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.1002180.s014" xlink:href="info:doi/10.1371/journal.pbio.1002180.s014" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:type="simple">
<label>S3 Table</label>
<caption>
<title>Thresholded PINES clusters (<italic>p</italic> &lt; 0.001, k = 10).</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We would also like to acknowledge Luka Ruzic and Choong-Wan Woo for their helpful discussions with the preparation of this manuscript. Imaging data is publically available at <ext-link ext-link-type="uri" xlink:href="http://www.neurovault.org" xlink:type="simple">www.neurovault.org</ext-link>.</p>
</ack>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>ACC</term>
<def><p>anterior cingulate</p></def>
</def-item>
<def-item><term>aINS</term>
<def><p>anterior insula</p></def>
</def-item>
<def-item><term>dACC</term>
<def><p>dorsal anterior cingulate</p></def>
</def-item>
<def-item><term>dmPFC</term>
<def><p>dorsomedial prefrontal cortex</p></def>
</def-item>
<def-item><term>FDR</term>
<def><p>false discovery rate</p></def>
</def-item>
<def-item><term>IAPS</term>
<def><p>International Affective Picture System</p></def>
</def-item>
<def-item><term>LASSO-PCR</term>
<def><p>Least Absolute Shrinkage and Selection Operator and Principle Components Regression</p></def>
</def-item>
<def-item><term>LOC</term>
<def><p>lateral occipital cortex</p></def>
</def-item>
<def-item><term>mTL</term>
<def><p>ventromedial temporal lobe</p></def>
</def-item>
<def-item><term>NPS</term>
<def><p>neurological pain signature</p></def>
</def-item>
<def-item><term>PAG</term>
<def><p>periaqueductal gray</p></def>
</def-item>
<def-item><term>PCC</term>
<def><p>posterior cingulate cortex</p></def>
</def-item>
<def-item><term>PINES</term>
<def><p>Picture Induced Negative Emotion Signature</p></def>
</def-item>
<def-item><term>preSMA</term>
<def><p>presupplementary motor area</p></def>
</def-item>
<def-item><term>RMSE</term>
<def><p>root mean squared error</p></def>
</def-item>
<def-item><term>ROI</term>
<def><p>region of interest</p></def>
</def-item>
<def-item><term>SE</term>
<def><p>standard error</p></def>
</def-item>
<def-item><term>STG</term>
<def><p>superior temporal gyrus</p></def>
</def-item>
<def-item><term>SVR</term>
<def><p>support vector regression</p></def>
</def-item>
<def-item><term>TPJ</term>
<def><p>temporary parietal junction</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.1002180.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gross</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Barrett</surname> <given-names>LF</given-names></name>. <article-title>Emotion Generation and Emotion Regulation: One or Two Depends on Your Point of View</article-title>. <source>Emot Rev</source>. <year>2011</year>;<volume>3</volume>(<issue>1</issue>):<fpage>8</fpage>–<lpage>16</lpage>. <object-id pub-id-type="pmid">21479078</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Suls</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bunde</surname> <given-names>J</given-names></name>. <article-title>Anger, anxiety, and depression as risk factors for cardiovascular disease: the problems and implications of overlapping affective dispositions</article-title>. <source>Psychol Bull</source>. <year>2005</year>;<volume>131</volume>(<issue>2</issue>):<fpage>260</fpage>–<lpage>300</lpage>. <object-id pub-id-type="pmid">15740422</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref003"><label>3</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Tooby</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Cosmides</surname> <given-names>L</given-names></name>. <chapter-title>The evolutionary psychology of the emotions and their relationship to internal regulatory variables</chapter-title>. In: <name name-style="western"><surname>Lewis</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Haviland-Jones</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Barrett</surname> <given-names>LF</given-names></name>, editors. <source>Handbook of Emotions</source>. <edition>3rd ed</edition>. <publisher-loc>NY</publisher-loc>: <publisher-name>Guilford Press</publisher-name>; <year>2008</year>.</mixed-citation></ref>
<ref id="pbio.1002180.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Keay</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Bandler</surname> <given-names>R</given-names></name>. <article-title>Parallel circuits mediating distinct emotional coping reactions to different types of stress</article-title>. <source>Neuroscience and biobehavioral reviews</source>. <year>2001</year>;<volume>25</volume>(<issue>7–8</issue>):<fpage>669</fpage>–<lpage>78</lpage>. <object-id pub-id-type="pmid">11801290</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Price</surname> <given-names>JL</given-names></name>. <article-title>Prefrontal cortical networks related to visceral function and mood</article-title>. <source>Ann N Y Acad Sci</source>. <year>1999</year>;<volume>877</volume>:<fpage>383</fpage>–<lpage>96</lpage>. <object-id pub-id-type="pmid">10415660</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Roy</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Shohamy</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>. <article-title>Ventromedial prefrontal-subcortical systems and the generation of affective meaning</article-title>. <source>Trends Cogn Sci</source>. <year>2012</year>;<volume>16</volume>(<issue>3</issue>):<fpage>147</fpage>–<lpage>56</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2012.01.005" xlink:type="simple">10.1016/j.tics.2012.01.005</ext-link></comment> <object-id pub-id-type="pmid">22310704</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Davidson</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Irwin</surname> <given-names>W</given-names></name>. <article-title>The functional neuroanatomy of emotion and affective style</article-title>. <source>Trends Cogn Sci</source>. <year>1999</year>;<volume>3</volume>(<issue>1</issue>):<fpage>11</fpage>–<lpage>21</lpage>. <object-id pub-id-type="pmid">10234222</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref008"><label>8</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Ortony</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Clore</surname> <given-names>GL</given-names></name>, <name name-style="western"><surname>Collins</surname> <given-names>A</given-names></name>. <source>The cognitive structure of emotions</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>1990</year>.</mixed-citation></ref>
<ref id="pbio.1002180.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chang</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Dufwenberg</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sanfey</surname> <given-names>AG</given-names></name>. <article-title>Triangulating the neural, psychological, and economic bases of guilt aversion</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>70</volume>(<issue>3</issue>):<fpage>560</fpage>–<lpage>72</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.02.056" xlink:type="simple">10.1016/j.neuron.2011.02.056</ext-link></comment> <object-id pub-id-type="pmid">21555080</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Xiang</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Lohrenz</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>. <article-title>Computational Substrates of Norms and Their Violations during Social Exchange</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>(<issue>3</issue>):<fpage>1099</fpage>–<lpage>108</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1642-12.2013" xlink:type="simple">10.1523/JNEUROSCI.1642-12.2013</ext-link></comment> <object-id pub-id-type="pmid">23325247</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref011"><label>11</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Kring</surname> <given-names>AM</given-names></name>. <chapter-title>Emotion disturbances as transdiagnostic processes in psychopathology</chapter-title>. In: <name name-style="western"><surname>Lewis</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Haviland-Jones</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Barrett</surname> <given-names>LF</given-names></name>, editors. <source>Handbook of Emotion</source>. <edition>3rd ed</edition>. <publisher-loc>New York</publisher-loc>: <publisher-name>Guilford Press</publisher-name>; <year>2008</year>.</mixed-citation></ref>
<ref id="pbio.1002180.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lindquist</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Kober</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Bliss-Moreau</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Barrett</surname> <given-names>LF</given-names></name>. <article-title>The brain basis of emotion: a meta-analytic review</article-title>. <source>Behav Brain Sci</source>. <year>2012</year>;<volume>35</volume>(<issue>3</issue>):<fpage>121</fpage>–<lpage>43</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S0140525X11000446" xlink:type="simple">10.1017/S0140525X11000446</ext-link></comment> <object-id pub-id-type="pmid">22617651</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref013"><label>13</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Feldman-Barrett</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Bliss-Moreau</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Lindquist</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Duncan</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kober</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <chapter-title>The Neuroimaging of Emotion</chapter-title>. In: <name name-style="western"><surname>Lewis</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Haviland-Jones</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Feldman-Barrett</surname> <given-names>L</given-names></name>, editors. <source>Handbook of emotions</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Guilford Press</publisher-name>; <year>2008</year>.</mixed-citation></ref>
<ref id="pbio.1002180.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Etkin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>. <article-title>Functional neuroimaging of anxiety: a meta-analysis of emotional processing in PTSD, social anxiety disorder, and specific phobia</article-title>. <source>Am J Psychiatry</source>. <year>2007</year>;<volume>164</volume>(<issue>10</issue>):<fpage>1476</fpage>–<lpage>88</lpage>. <object-id pub-id-type="pmid">17898336</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hamilton</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Etkin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Furman</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Lemus</surname> <given-names>MG</given-names></name>, <name name-style="western"><surname>Johnson</surname> <given-names>RF</given-names></name>, <name name-style="western"><surname>Gotlib</surname> <given-names>IH</given-names></name>. <article-title>Functional neuroimaging of major depressive disorder: a meta-analysis and new integration of base line activation and neural response data</article-title>. <source>Am J Psychiatry</source>. <year>2012</year>;<volume>169</volume>(<issue>7</issue>):<fpage>693</fpage>–<lpage>703</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1176/appi.ajp.2012.11071105" xlink:type="simple">10.1176/appi.ajp.2012.11071105</ext-link></comment> <object-id pub-id-type="pmid">22535198</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Drevets</surname> <given-names>WC</given-names></name>, <name name-style="western"><surname>Price</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Furey</surname> <given-names>ML</given-names></name>. <article-title>Brain structural and functional abnormalities in mood disorders: implications for neurocircuitry models of depression</article-title>. <source>Brain Struct Funct</source>. <year>2008</year>;<volume>213</volume>(<issue>1–2</issue>):<fpage>93</fpage>–<lpage>118</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00429-008-0193-1" xlink:type="simple">10.1007/s00429-008-0193-1</ext-link></comment> <object-id pub-id-type="pmid">18651174</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kober</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Barrett</surname> <given-names>LF</given-names></name>, <name name-style="western"><surname>Joseph</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bliss-Moreau</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Lindquist</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>. <article-title>Functional grouping and cortical-subcortical interactions in emotion: a meta-analysis of neuroimaging studies</article-title>. <source>Neuroimage</source>. <year>2008</year>;<volume>42</volume>(<issue>2</issue>):<fpage>998</fpage>–<lpage>1031</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2008.03.059" xlink:type="simple">10.1016/j.neuroimage.2008.03.059</ext-link></comment> <object-id pub-id-type="pmid">18579414</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barrett</surname> <given-names>LF</given-names></name>. <article-title>Are Emotions Natural Kinds?</article-title> <source>Perspect Psychol Sci</source>. <year>2006</year>;<volume>1</volume>(<issue>1</issue>):<fpage>28</fpage>–<lpage>58</lpage>.</mixed-citation></ref>
<ref id="pbio.1002180.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fu</surname> <given-names>CH</given-names></name>, <name name-style="western"><surname>Mourao-Miranda</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Costafreda</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Khanna</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Marquand</surname> <given-names>AF</given-names></name>, <name name-style="western"><surname>Williams</surname> <given-names>SC</given-names></name>, <etal>et al</etal>. <article-title>Pattern classification of sad facial processing: toward the development of neurobiological markers in depression</article-title>. <source>Biol Psychiatry</source>. <year>2008</year>;<volume>63</volume>(<issue>7</issue>):<fpage>656</fpage>–<lpage>62</lpage>. <object-id pub-id-type="pmid">17949689</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Gianaros</surname> <given-names>PJ</given-names></name>. <article-title>The social brain, stress, and psychopathology</article-title>. <source>JAMA psychiatry</source>. <year>2014</year>;<volume>71</volume>(<issue>6</issue>):<fpage>622</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1001/jamapsychiatry.2014.288" xlink:type="simple">10.1001/jamapsychiatry.2014.288</ext-link></comment> <object-id pub-id-type="pmid">24740473</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Siegle</surname> <given-names>GJ</given-names></name>, <name name-style="western"><surname>Carter</surname> <given-names>CS</given-names></name>, <name name-style="western"><surname>Thase</surname> <given-names>ME</given-names></name>. <article-title>Use of FMRI to predict recovery from unipolar depression with cognitive behavior therapy</article-title>. <source>Am J Psychiatry</source>. <year>2006</year>;<volume>163</volume>(<issue>4</issue>):<fpage>735</fpage>–<lpage>8</lpage>. <object-id pub-id-type="pmid">16585452</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baliki</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Petre</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Torbey</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Herrmann</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Huang</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Schnitzer</surname> <given-names>TJ</given-names></name>, <etal>et al</etal>. <article-title>Corticostriatal functional connectivity predicts transition to chronic back pain</article-title>. <source>Nature Neuroscience</source>. <year>2012</year>;<volume>15</volume>(<issue>8</issue>):<fpage>1117</fpage>–<lpage>+</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3153" xlink:type="simple">10.1038/nn.3153</ext-link></comment> <object-id pub-id-type="pmid">22751038</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mayberg</surname> <given-names>HS</given-names></name>, <name name-style="western"><surname>Lozano</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Voon</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>McNeely</surname> <given-names>HE</given-names></name>, <name name-style="western"><surname>Seminowicz</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Hamani</surname> <given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Deep brain stimulation for treatment-resistant depression</article-title>. <source>Neuron</source>. <year>2005</year>;<volume>45</volume>(<issue>5</issue>):<fpage>651</fpage>–<lpage>60</lpage>. <object-id pub-id-type="pmid">15748841</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schlaepfer</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>MX</given-names></name>, <name name-style="western"><surname>Frick</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Kosel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Brodesser</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Axmacher</surname> <given-names>N</given-names></name>, <etal>et al</etal>. <article-title>Deep Brain Stimulation to Reward Circuitry Alleviates Anhedonia in Refractory Major Depression</article-title>. <source>Neuropsychopharmacology</source>. <year>2007</year>.</mixed-citation></ref>
<ref id="pbio.1002180.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kapur</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Phillips</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Insel</surname> <given-names>TR</given-names></name>. <article-title>Why has it taken so long for biological psychiatry to develop clinical tests and what to do about it?</article-title> <source>Mol Psychiatry</source>. <year>2012</year>;<volume>17</volume>(<issue>12</issue>):<fpage>1174</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/mp.2012.105" xlink:type="simple">10.1038/mp.2012.105</ext-link></comment> <object-id pub-id-type="pmid">22869033</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Waugh</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Lindquist</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Noll</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Fredrickson</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>SF</given-names></name>. <article-title>Brain mediators of cardiovascular responses to social threat: part I: Reciprocal dorsal and ventral sub-regions of the medial prefrontal cortex and heart-rate reactivity</article-title>. <source>Neuroimage</source>. <year>2009</year>;<volume>47</volume>(<issue>3</issue>):<fpage>821</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2009.05.043" xlink:type="simple">10.1016/j.neuroimage.2009.05.043</ext-link></comment> <object-id pub-id-type="pmid">19465137</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Critchley</surname> <given-names>HD</given-names></name>. <article-title>Neural mechanisms of autonomic, affective, and cognitive integration</article-title>. <source>The Journal of comparative neurology</source>. <year>2005</year>;<volume>493</volume>(<issue>1</issue>):<fpage>154</fpage>–<lpage>66</lpage>. <object-id pub-id-type="pmid">16254997</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yarkoni</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Nichols</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Van Essen</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>. <article-title>Large-scale automated synthesis of human functional neuroimaging data</article-title>. <source>Nat Methods</source>. <year>2011</year>;<volume>8</volume>(<issue>8</issue>):<fpage>665</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nmeth.1635" xlink:type="simple">10.1038/nmeth.1635</ext-link></comment> <object-id pub-id-type="pmid">21706013</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hariri</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Mattay</surname> <given-names>VS</given-names></name>, <name name-style="western"><surname>Tessitore</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kolachana</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Fera</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Goldman</surname> <given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Serotonin transporter genetic variation and the response of the human amygdala</article-title>. <source>Science</source>. <year>2002</year>;<volume>297</volume>(<issue>5580</issue>):<fpage>400</fpage>–<lpage>3</lpage>. <object-id pub-id-type="pmid">12130784</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Whalen</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Kagan</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Cook</surname> <given-names>RG</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>FC</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Polis</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Human amygdala responsivity to masked fearful eye whites</article-title>. <source>Science</source>. <year>2004</year>;<volume>306</volume>(<issue>5704</issue>):<fpage>2061</fpage>. <object-id pub-id-type="pmid">15604401</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>van Ast</surname> <given-names>VA</given-names></name>, <name name-style="western"><surname>Hughes</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Davidson</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Lindquist</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Ochsner</surname> <given-names>KN</given-names></name>. <article-title>Brain mediators of cardiovascular responses to social threat, part II: Prefrontal-subcortical pathways and relationship with anxiety</article-title>. <source>Neuroimage</source>. <year>2009</year>;<volume>47</volume>(<issue>3</issue>):<fpage>836</fpage>–<lpage>51</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2009.05.044" xlink:type="simple">10.1016/j.neuroimage.2009.05.044</ext-link></comment> <object-id pub-id-type="pmid">19465135</object-id>.</mixed-citation></ref>
<ref id="pbio.1002180.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Uddin</surname> <given-names>LQ</given-names></name>, <name name-style="western"><surname>Kinnison</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Pessoa</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>ML</given-names></name>. <article-title>Beyond the tripartite cognition-emotion-interoception model of the human insular cortex</article-title>. <source>J Cogn Neurosci</source>. <year>2014</year>;<volume>26</volume>(<issue>1</issue>):<fpage>16</fpage>–<lpage>27</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn_a_00462" xlink:type="simple">10.1162/jocn_a_00462</ext-link></comment> <object-id pub-id-type="pmid">23937691</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pessoa</surname> <given-names>L</given-names></name>. <article-title>On the relationship between emotion and cognition</article-title>. <source>Nat Rev Neurosci</source>. <year>2008</year>;<volume>9</volume>(<issue>2</issue>):<fpage>148</fpage>–<lpage>58</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2317" xlink:type="simple">10.1038/nrn2317</ext-link></comment> <object-id pub-id-type="pmid">18209732</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Phan</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>SF</given-names></name>, <name name-style="western"><surname>Welsh</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Ho</surname> <given-names>SH</given-names></name>, <name name-style="western"><surname>Britton</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Liberzon</surname> <given-names>I</given-names></name>. <article-title>Neural correlates of individual ratings of emotional salience: a trial-related fMRI study</article-title>. <source>Neuroimage</source>. <year>2004</year>;<volume>21</volume>(<issue>2</issue>):<fpage>768</fpage>–<lpage>80</lpage>. <object-id pub-id-type="pmid">14980580</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Atlas</surname> <given-names>LY</given-names></name>, <name name-style="western"><surname>Lindquist</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Roy</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Woo</surname> <given-names>CW</given-names></name>, <name name-style="western"><surname>Kross</surname> <given-names>E</given-names></name>. <article-title>An fMRI-based neurologic signature of physical pain</article-title>. <source>The New England journal of medicine</source>. <year>2013</year>;<volume>368</volume>(<issue>15</issue>):<fpage>1388</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1056/NEJMoa1204471" xlink:type="simple">10.1056/NEJMoa1204471</ext-link></comment> <object-id pub-id-type="pmid">23574118</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name>, <name name-style="western"><surname>Gobbini</surname> <given-names>MI</given-names></name>, <name name-style="western"><surname>Furey</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Ishai</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schouten</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Pietrini</surname> <given-names>P</given-names></name>. <article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title>. <source>Science</source>. <year>2001</year>;<volume>293</volume>(<issue>5539</issue>):<fpage>2425</fpage>–<lpage>30</lpage>. <object-id pub-id-type="pmid">11577229</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kamitani</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Tong</surname> <given-names>F</given-names></name>. <article-title>Decoding the visual and subjective contents of the human brain</article-title>. <source>Nat Neurosci</source>. <year>2005</year>;<volume>8</volume>(<issue>5</issue>):<fpage>679</fpage>–<lpage>85</lpage>. <object-id pub-id-type="pmid">15852014</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mitchell</surname> <given-names>TM</given-names></name>, <name name-style="western"><surname>Hutchinson</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Niculescu</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Pereira</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>XR</given-names></name>, <name name-style="western"><surname>Just</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Learning to decode cognitive states from brain images</article-title>. <source>Mach Learn</source>. <year>2004</year>;<volume>57</volume>(<issue>1–2</issue>):<fpage>145</fpage>–<lpage>75</lpage>.</mixed-citation></ref>
<ref id="pbio.1002180.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kay</surname> <given-names>KN</given-names></name>, <name name-style="western"><surname>Naselaris</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Prenger</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name>. <article-title>Identifying natural images from human brain activity</article-title>. <source>Nature</source>. <year>2008</year>;<volume>452</volume>(<issue>7185</issue>):<fpage>352</fpage>–<lpage>U7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature06713" xlink:type="simple">10.1038/nature06713</ext-link></comment> <object-id pub-id-type="pmid">18322462</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>LeDoux</surname> <given-names>J</given-names></name>. <article-title>Rethinking the emotional brain</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>73</volume>(<issue>4</issue>):<fpage>653</fpage>–<lpage>76</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.02.004" xlink:type="simple">10.1016/j.neuron.2012.02.004</ext-link></comment> <object-id pub-id-type="pmid">22365542</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vul</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Harris</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Winkielman</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Pashler</surname> <given-names>H</given-names></name>. <article-title>Puzzlingly High Correlations in fMRI Studies of Emotion, Personality, and Social Cognition</article-title>. <source>Perspect Psychol Sci</source>. <year>2009</year>;<volume>4</volume>(<issue>3</issue>):<fpage>274</fpage>–<lpage>90</lpage>.</mixed-citation></ref>
<ref id="pbio.1002180.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name>. <article-title>Can cognitive processes be inferred from neuroimaging data?</article-title> <source>Trends in cognitive sciences</source>. <year>2006</year>;<volume>10</volume>(<issue>2</issue>):<fpage>59</fpage>–<lpage>63</lpage>. <object-id pub-id-type="pmid">16406760</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yarkoni</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Barch</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Gray</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Conturo</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Braver</surname> <given-names>TS</given-names></name>. <article-title>BOLD correlates of trial-by-trial reaction time variability in gray and white matter: a multi-study fMRI analysis</article-title>. <source>PLoS ONE</source>. <year>2009</year>;<volume>4</volume>(<issue>1</issue>):<fpage>e4257</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0004257" xlink:type="simple">10.1371/journal.pone.0004257</ext-link></comment> <object-id pub-id-type="pmid">19165335</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peelen</surname> <given-names>MV</given-names></name>, <name name-style="western"><surname>Atkinson</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Vuilleumier</surname> <given-names>P</given-names></name>. <article-title>Supramodal representations of perceived emotions in the human brain</article-title>. <source>J Neurosci</source>. <year>2010</year>;<volume>30</volume>(<issue>30</issue>):<fpage>10127</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2161-10.2010" xlink:type="simple">10.1523/JNEUROSCI.2161-10.2010</ext-link></comment> <object-id pub-id-type="pmid">20668196</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baucom</surname> <given-names>LB</given-names></name>, <name name-style="western"><surname>Wedell</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Blitzer</surname> <given-names>DN</given-names></name>, <name name-style="western"><surname>Shinkareva</surname> <given-names>SV</given-names></name>. <article-title>Decoding the neural representation of affective states</article-title>. <source>Neuroimage</source>. <year>2012</year>;<volume>59</volume>(<issue>1</issue>):<fpage>718</fpage>–<lpage>27</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2011.07.037" xlink:type="simple">10.1016/j.neuroimage.2011.07.037</ext-link></comment> <object-id pub-id-type="pmid">21801839</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kassam</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Markey</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Cherkassky</surname> <given-names>VL</given-names></name>, <name name-style="western"><surname>Loewenstein</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Just</surname> <given-names>MA</given-names></name>. <article-title>Identifying Emotions on the Basis of Neural Activation</article-title>. <source>PLoS ONE</source>. <year>2013</year>;<volume>8</volume>(<issue>6</issue>):<fpage>e66032</fpage>. <object-id pub-id-type="pmid">23840392</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kragel</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Labar</surname> <given-names>KS</given-names></name>. <article-title>Multivariate pattern classification reveals autonomic and experiential representations of discrete emotions</article-title>. <source>Emotion</source>. <year>2013</year>;<volume>13</volume>(<issue>4</issue>):<fpage>681</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0031820" xlink:type="simple">10.1037/a0031820</ext-link></comment> <object-id pub-id-type="pmid">23527508</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Craddock</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Holtzheimer</surname> <given-names>PE</given-names> <suffix>3rd</suffix></name>, <name name-style="western"><surname>Hu</surname> <given-names>XP</given-names></name>, <name name-style="western"><surname>Mayberg</surname> <given-names>HS</given-names></name>. <article-title>Disease state prediction from resting state functional connectivity</article-title>. <source>Magn Reson Med</source>. <year>2009</year>;<volume>62</volume>(<issue>6</issue>):<fpage>1619</fpage>–<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/mrm.22159" xlink:type="simple">10.1002/mrm.22159</ext-link></comment> <object-id pub-id-type="pmid">19859933</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doehrmann</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Ghosh</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Polli</surname> <given-names>FE</given-names></name>, <name name-style="western"><surname>Reynolds</surname> <given-names>GO</given-names></name>, <name name-style="western"><surname>Horn</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Keshavan</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Predicting treatment response in social anxiety disorder from functional magnetic resonance imaging</article-title>. <source>JAMA psychiatry</source>. <year>2013</year>;<volume>70</volume>(<issue>1</issue>):<fpage>87</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1001/2013.jamapsychiatry.5" xlink:type="simple">10.1001/2013.jamapsychiatry.5</ext-link></comment> <object-id pub-id-type="pmid">22945462</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref050"><label>50</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Lang</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Bradley</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Cuthbert</surname> <given-names>BN</given-names></name>. <source>International Affective Picture System (IAPS): Affective ratings of pictures and instruction manual</source>. <publisher-loc>Gainesville, FL</publisher-loc>: <publisher-name>University of Florida</publisher-name>, <year>2005</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.psychres.2015.04.002" xlink:type="simple">10.1016/j.psychres.2015.04.002</ext-link></comment> <object-id pub-id-type="pmid">25890694</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lench</surname> <given-names>HC</given-names></name>, <name name-style="western"><surname>Flores</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Bench</surname> <given-names>SW</given-names></name>. <article-title>Discrete Emotions Predict Changes in Cognition, Judgment, Experience, Behavior, and Physiology: A Meta-Analysis of Experimental Emotion Elicitations</article-title>. <source>Psychological Bulletin</source>. <year>2011</year>;<volume>137</volume>(<issue>5</issue>):<fpage>834</fpage>–<lpage>55</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0024244" xlink:type="simple">10.1037/a0024244</ext-link></comment> <object-id pub-id-type="pmid">21766999</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barch</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Burgess</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Harms</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Petersen</surname> <given-names>SE</given-names></name>, <name name-style="western"><surname>Schlaggar</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Corbetta</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Function in the human connectome: task-fMRI and individual differences in behavior</article-title>. <source>Neuroimage</source>. <year>2013</year>;<volume>80</volume>:<fpage>169</fpage>–<lpage>89</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2013.05.033" xlink:type="simple">10.1016/j.neuroimage.2013.05.033</ext-link></comment> <object-id pub-id-type="pmid">23684877</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Atlas</surname> <given-names>LY</given-names></name>, <name name-style="western"><surname>Leotti</surname> <given-names>LA</given-names></name>, <name name-style="western"><surname>Rilling</surname> <given-names>JK</given-names></name>. <article-title>Predicting individual differences in placebo analgesia: contributions of brain activity during anticipation and pain experience</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>2</issue>):<fpage>439</fpage>–<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3420-10.2011" xlink:type="simple">10.1523/JNEUROSCI.3420-10.2011</ext-link></comment> <object-id pub-id-type="pmid">21228154</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rao</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Fung</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rosales</surname> <given-names>R</given-names></name>, editors. <article-title>On the Dangers of Cross-Validation. An Experimental Evaluation</article-title>. <source>SDM</source>; <year>2008</year>: SIAM.</mixed-citation></ref>
<ref id="pbio.1002180.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Libkuman</surname> <given-names>TM</given-names></name>, <name name-style="western"><surname>Otam</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Kern</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Viger</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Novak</surname> <given-names>N</given-names></name>. <article-title>Multidimensional normative ratings for the international affective picture system</article-title>. <source>Behav Res Methods</source>. <year>2007</year>;<volume>39</volume>(<issue>2</issue>):<fpage>326</fpage>–<lpage>34</lpage>. <object-id pub-id-type="pmid">17695361</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krishnan</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Chang</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Woo</surname> <given-names>CW</given-names></name>, <name name-style="western"><surname>Ruzic</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Gu</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Fan</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Somatic and vicarious pain are represented by dissociable multivariate brain patterns</article-title>. <source>Under Review</source>.</mixed-citation></ref>
<ref id="pbio.1002180.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yeo</surname> <given-names>BT</given-names></name>, <name name-style="western"><surname>Krienen</surname> <given-names>FM</given-names></name>, <name name-style="western"><surname>Sepulcre</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sabuncu</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Lashkari</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Hollinshead</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title>. <source>Journal of neurophysiology</source>. <year>2011</year>;<volume>106</volume>(<issue>3</issue>):<fpage>1125</fpage>–<lpage>65</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00338.2011" xlink:type="simple">10.1152/jn.00338.2011</ext-link></comment> <object-id pub-id-type="pmid">21653723</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Functional and effective connectivity: a review</article-title>. <source>Brain connectivity</source>. <year>2011</year>;<volume>1</volume>(<issue>1</issue>):<fpage>13</fpage>–<lpage>36</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1089/brain.2011.0008" xlink:type="simple">10.1089/brain.2011.0008</ext-link></comment> <object-id pub-id-type="pmid">22432952</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Fox</surname> <given-names>PT</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Glahn</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Fox</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Mackay</surname> <given-names>CE</given-names></name>, <etal>et al</etal>. <article-title>Correspondence of the brain's functional architecture during activation and rest</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2009</year>;<volume>106</volume>(<issue>31</issue>):<fpage>13040</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0905267106" xlink:type="simple">10.1073/pnas.0905267106</ext-link></comment> <object-id pub-id-type="pmid">19620724</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Allen</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Erhardt</surname> <given-names>EB</given-names></name>, <name name-style="western"><surname>Damaraju</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Gruner</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Segall</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Silva</surname> <given-names>RF</given-names></name>, <etal>et al</etal>. <article-title>A baseline for the multivariate comparison of resting-state networks</article-title>. <source>Front Syst Neurosci</source>. <year>2011</year>;<volume>5</volume>:<fpage>2</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnsys.2011.00002" xlink:type="simple">10.3389/fnsys.2011.00002</ext-link></comment> <object-id pub-id-type="pmid">21442040</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bullmore</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Sporns</surname> <given-names>O</given-names></name>. <article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title>. <source>Nat Rev Neurosci</source>. <year>2009</year>;<volume>10</volume>(<issue>3</issue>):<fpage>186</fpage>–<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2575" xlink:type="simple">10.1038/nrn2575</ext-link></comment> <object-id pub-id-type="pmid">19190637</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Craddock</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Jbabdi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Yan</surname> <given-names>CG</given-names></name>, <name name-style="western"><surname>Vogelstein</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Castellanos</surname> <given-names>FX</given-names></name>, <name name-style="western"><surname>Di Martino</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Imaging human connectomes at the macroscale</article-title>. <source>Nat Methods</source>. <year>2013</year>;<volume>10</volume>(<issue>6</issue>):<fpage>524</fpage>–<lpage>39</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nmeth.2482" xlink:type="simple">10.1038/nmeth.2482</ext-link></comment> <object-id pub-id-type="pmid">23722212</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Seeley</surname> <given-names>WW</given-names></name>, <name name-style="western"><surname>Menon</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Schatzberg</surname> <given-names>AF</given-names></name>, <name name-style="western"><surname>Keller</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Glover</surname> <given-names>GH</given-names></name>, <name name-style="western"><surname>Kenna</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Dissociable intrinsic connectivity networks for salience processing and executive control</article-title>. <source>Journal of Neuroscience</source>. <year>2007</year>;<volume>27</volume>(<issue>9</issue>):<fpage>2349</fpage>–<lpage>56</lpage>. <object-id pub-id-type="pmid">17329432</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Denny</surname> <given-names>BT</given-names></name>, <name name-style="western"><surname>Kober</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Ochsner</surname> <given-names>KN</given-names></name>. <article-title>A meta-analysis of functional neuroimaging studies of self- and other judgments reveals a spatial gradient for mentalizing in medial prefrontal cortex</article-title>. <source>J Cogn Neurosci</source>. <year>2012</year>;<volume>24</volume>(<issue>8</issue>):<fpage>1742</fpage>–<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn_a_00233" xlink:type="simple">10.1162/jocn_a_00233</ext-link></comment> <object-id pub-id-type="pmid">22452556</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Snellenberg</surname> <given-names>JX</given-names></name>, <name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>. <article-title>Cognitive and motivational functions of the human prefrontal cortex</article-title>. <source>Luria's legacy in the 21st century</source>. <year>2009</year>:<fpage>30</fpage>–<lpage>62</lpage>.</mixed-citation></ref>
<ref id="pbio.1002180.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stoodley</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Schmahmann</surname> <given-names>JD</given-names></name>. <article-title>Evidence for topographic organization in the cerebellum of motor control versus cognitive and affective processing</article-title>. <source>Cortex</source>. <year>2010</year>;<volume>46</volume>(<issue>7</issue>):<fpage>831</fpage>–<lpage>44</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cortex.2009.11.008" xlink:type="simple">10.1016/j.cortex.2009.11.008</ext-link></comment> <object-id pub-id-type="pmid">20152963</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woo</surname> <given-names>CW</given-names></name>, <name name-style="western"><surname>Koban</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Kross</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Lindquist</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Banich</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Ruzic</surname> <given-names>L</given-names></name>, <etal>et al</etal>. <article-title>Separate Neural Representations for Physical Pain and Social Rejection</article-title>. <source>Nat Commun</source>. <year>2014</year>; <volume>5</volume>: <fpage>5380</fpage></mixed-citation></ref>
<ref id="pbio.1002180.ref068"><label>68</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Scherer</surname> <given-names>KR</given-names></name>. <chapter-title>Appraisal theories</chapter-title>. In <name name-style="western"><surname>Dalgleish</surname> <given-names>T.</given-names></name>, &amp; <name name-style="western"><surname>Power</surname> <given-names>M.</given-names></name> (Eds.). <source>Handbook of cognition and emotion</source>. <publisher-loc>Chichester</publisher-loc>: <publisher-name>Wiley</publisher-name>. <year>1999</year>; p. <fpage>637</fpage>–<lpage>63</lpage>.</mixed-citation></ref>
<ref id="pbio.1002180.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brosch</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sander</surname> <given-names>D</given-names></name>. <article-title>Comment: The Appraising Brain: Towards a Neuro-Cognitive Model of Appraisal Processes in Emotion</article-title>. <source>Emot Rev</source>. <year>2013</year>;<volume>5</volume>(<issue>2</issue>):<fpage>163</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="pbio.1002180.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niedenthal</surname> <given-names>PM</given-names></name>. <article-title>Embodying emotion</article-title>. <source>Science</source>. <year>2007</year>;<volume>316</volume>(<issue>5827</issue>):<fpage>1002</fpage>–<lpage>5</lpage>. <object-id pub-id-type="pmid">17510358</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>MacLean</surname> <given-names>P</given-names></name>. <article-title>Psychosomatic disease and the visceral brain; recent developments bearing on the Papez theory of emotion</article-title>. <source>Psychosomatic medicine</source>. <year>1949</year>;<volume>11</volume>(<issue>6</issue>):<fpage>338</fpage>–<lpage>53</lpage>. <object-id pub-id-type="pmid">15410445</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref072"><label>72</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Ledoux</surname> <given-names>J</given-names></name>. <source>The Emotional Brain</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Simon &amp; Schuster</publisher-name>; <year>1996</year>.</mixed-citation></ref>
<ref id="pbio.1002180.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rainville</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Duncan</surname> <given-names>GH</given-names></name>, <name name-style="western"><surname>Price</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Carrier</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Bushnell</surname> <given-names>MC</given-names></name>. <article-title>Pain affect encoded in human anterior cingulate but not somatosensory cortex</article-title>. <source>Science</source>. <year>1997</year>;<volume>277</volume>(<issue>5328</issue>):<fpage>968</fpage>–<lpage>71</lpage>. <object-id pub-id-type="pmid">9252330</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref074"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calder</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Keane</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Manes</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Antoun</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Young</surname> <given-names>AW</given-names></name>. <article-title>Impaired recognition and experience of disgust following brain injury</article-title>. <source>Nat Neurosci</source>. <year>2000</year>;<volume>3</volume>(<issue>11</issue>):<fpage>1077</fpage>–<lpage>8</lpage>. <object-id pub-id-type="pmid">11036262</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref075"><label>75</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Craig</surname> <given-names>AD</given-names></name>. <article-title>How do you feel—now? The anterior insula and human awareness</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2009</year>;<volume>10</volume>(<issue>1</issue>):<fpage>59</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2555" xlink:type="simple">10.1038/nrn2555</ext-link></comment> <object-id pub-id-type="pmid">19096369</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref076"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Fox</surname> <given-names>PT</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Glahn</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Fox</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Mackay</surname> <given-names>CE</given-names></name>, <etal>et al</etal>. <article-title>Correspondence of the brain's functional architecture during activation and rest</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2009</year>;<volume>106</volume>(<issue>31</issue>):<fpage>13040</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0905267106" xlink:type="simple">10.1073/pnas.0905267106</ext-link></comment> <object-id pub-id-type="pmid">19620724</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref077"><label>77</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raichle</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>MacLeod</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Snyder</surname> <given-names>AZ</given-names></name>, <name name-style="western"><surname>Powers</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Gusnard</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Shulman</surname> <given-names>GL</given-names></name>. <article-title>A default mode of brain function</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2001</year>;<volume>98</volume>(<issue>2</issue>):<fpage>676</fpage>–<lpage>82</lpage>. <object-id pub-id-type="pmid">11209064</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref078"><label>78</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barrett</surname> <given-names>LF</given-names></name>. <article-title>The Future of Psychology: Connecting Mind to Brain</article-title>. <source>Perspect Psychol Sci</source>. <year>2009</year>;<volume>4</volume>(<issue>4</issue>):<fpage>326</fpage>–<lpage>39</lpage>. <object-id pub-id-type="pmid">19844601</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref079"><label>79</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gianaros</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Marsland</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Kuan</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Schirda</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Jennings</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Sheu</surname> <given-names>LK</given-names></name>, <etal>et al</etal>. <article-title>An inflammatory pathway links atherosclerotic cardiovascular disease risk to neural activity evoked by the cognitive regulation of emotion</article-title>. <source>Biol Psychiatry</source>. <year>2014</year>;<volume>75</volume>(<issue>9</issue>):<fpage>738</fpage>–<lpage>45</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.biopsych.2013.10.012" xlink:type="simple">10.1016/j.biopsych.2013.10.012</ext-link></comment> <object-id pub-id-type="pmid">24267410</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref080"><label>80</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Op de Beeck</surname> <given-names>HP</given-names></name>. <article-title>Against hyperacuity in brain reading: spatial smoothing does not hurt multivariate fMRI analyses?</article-title> <source>Neuroimage</source>. <year>2010</year>;<volume>49</volume>(<issue>3</issue>):<fpage>1943</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2009.02.047" xlink:type="simple">10.1016/j.neuroimage.2009.02.047</ext-link></comment> <object-id pub-id-type="pmid">19285144</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref081"><label>81</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bartoshuk</surname> <given-names>LM</given-names></name>. <article-title>Comparing sensory experiences across individuals: recent psychophysical advances illuminate genetic variation in taste perception</article-title>. <source>Chem Senses</source>. <year>2000</year>;<volume>25</volume>(<issue>4</issue>):<fpage>447</fpage>–<lpage>60</lpage>. <object-id pub-id-type="pmid">10944509</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref082"><label>82</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Green</surname> <given-names>BG</given-names></name>, <name name-style="western"><surname>Dalton</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Cowart</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Shaffer</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rankin</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Higgins</surname> <given-names>J</given-names></name>. <article-title>Evaluating the 'Labeled Magnitude Scale' for measuring sensations of taste and smell</article-title>. <source>Chem Senses</source>. <year>1996</year>;<volume>21</volume>(<issue>3</issue>):<fpage>323</fpage>–<lpage>34</lpage>. <object-id pub-id-type="pmid">8670711</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref083"><label>83</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atlas</surname> <given-names>LY</given-names></name>, <name name-style="western"><surname>Bolger</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Lindquist</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>. <article-title>Brain mediators of predictive cue effects on perceived pain</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2010</year>;<volume>30</volume>(<issue>39</issue>):<fpage>12964</fpage>–<lpage>77</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0057-10.2010" xlink:type="simple">10.1523/JNEUROSCI.0057-10.2010</ext-link></comment> <object-id pub-id-type="pmid">20881115</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref084"><label>84</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pereira</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Mitchell</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Botvinick</surname> <given-names>M</given-names></name>. <article-title>Machine learning classifiers and fMRI: a tutorial overview</article-title>. <source>Neuroimage</source>. <year>2009</year>;<volume>45</volume>(<issue>1 Suppl</issue>):<fpage>S199</fpage>–<lpage>209</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2008.11.007" xlink:type="simple">10.1016/j.neuroimage.2008.11.007</ext-link></comment> <object-id pub-id-type="pmid">19070668</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref085"><label>85</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Hastie</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Friedman</surname> <given-names>J</given-names></name>. <source>The elements of statistical learning: Data mining, inference, and prediction</source>. <edition>2nd ed</edition>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2009</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neunet.2009.04.005" xlink:type="simple">10.1016/j.neunet.2009.04.005</ext-link></comment> <object-id pub-id-type="pmid">19443179</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref086"><label>86</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Kohavi</surname> <given-names>R</given-names></name>, editor <chapter-title>A study of cross-validation and bootstrap for accuracy estimation and model selection</chapter-title>. <source>International Joint Conference on Aartificial Intelligence</source>; <year>1995</year>; <publisher-loc>Montreal, Quebec</publisher-loc>.</mixed-citation></ref>
<ref id="pbio.1002180.ref087"><label>87</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Efron</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>. <source>An introduction to the bootstrap</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>1993</year>.</mixed-citation></ref>
<ref id="pbio.1002180.ref088"><label>88</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Campbell</surname> <given-names>DT</given-names></name>, <name name-style="western"><surname>Fiske</surname> <given-names>DW</given-names></name>. <article-title>Convergent and Discriminant Validation by the Multitrait-Multimethod Matrix</article-title>. <source>Psychological Bulletin</source>. <year>1959</year>;<volume>56</volume>(<issue>2</issue>):<fpage>81</fpage>–<lpage>105</lpage>. <object-id pub-id-type="pmid">13634291</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref089"><label>89</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name>, <name name-style="western"><surname>Guntupalli</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Connolly</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Halchenko</surname> <given-names>YO</given-names></name>, <name name-style="western"><surname>Conroy</surname> <given-names>BR</given-names></name>, <name name-style="western"><surname>Gobbini</surname> <given-names>MI</given-names></name>, <etal>et al</etal>. <article-title>A common, high-dimensional model of the representational space in human ventral temporal cortex</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>72</volume>(<issue>2</issue>):<fpage>404</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.08.026" xlink:type="simple">10.1016/j.neuron.2011.08.026</ext-link></comment> <object-id pub-id-type="pmid">22017997</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref090"><label>90</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Brodersen</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Ong</surname> <given-names>CS</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Buhmann</surname> <given-names>JM</given-names></name>, editors. <chapter-title>The balanced accuracy and its posterior distribution</chapter-title>. <source>International Conference on Pattern Recognition</source>; <year>2010</year>; <publisher-loc>Istanbul, Turkey</publisher-loc>.</mixed-citation></ref>
<ref id="pbio.1002180.ref091"><label>91</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Macmillan</surname> <given-names>NA</given-names></name>, <name name-style="western"><surname>Creelman</surname> <given-names>CD</given-names></name>. <source>Detection theory: A user's guide</source>: <publisher-name>Psychology Press</publisher-name>; <year>2005</year>.</mixed-citation></ref>
<ref id="pbio.1002180.ref092"><label>92</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Agresti</surname> <given-names>A</given-names></name>. <source>Categorical Data Analysis</source>. <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>John Wiley &amp; Sons, Inc.</publisher-name>; <year>2012</year>.</mixed-citation></ref>
<ref id="pbio.1002180.ref093"><label>93</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shepard</surname> <given-names>RN</given-names></name>. <article-title>Multidimensional scaling, tree-fitting, and clustering</article-title>. <source>Science</source>. <year>1980</year>;<volume>210</volume>(<issue>4468</issue>):<fpage>390</fpage>–<lpage>8</lpage>. <object-id pub-id-type="pmid">17837406</object-id></mixed-citation></ref>
<ref id="pbio.1002180.ref094"><label>94</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rissman</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gazzaley</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>D'Esposito</surname> <given-names>M</given-names></name>. <article-title>Measuring functional connectivity during distinct stages of a cognitive task</article-title>. <source>Neuroimage</source>. <year>2004</year>;<volume>23</volume>(<issue>2</issue>):<fpage>752</fpage>–<lpage>63</lpage>. <object-id pub-id-type="pmid">15488425</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
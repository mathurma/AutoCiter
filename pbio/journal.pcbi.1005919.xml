<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-01160</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005919</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical mechanics</subject><subj-group><subject>Motion</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical mechanics</subject><subj-group><subject>Motion</subject><subj-group><subject>Velocity</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Equipment</subject><subj-group><subject>Detectors</subject><subj-group><subject>Motion detectors</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Biological locomotion</subject><subj-group><subject>Flight (biology)</subject><subj-group><subject>Insect flight</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Biological locomotion</subject><subj-group><subject>Flight (biology)</subject><subj-group><subject>Insect flight</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Biological locomotion</subject><subj-group><subject>Flight (biology)</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Biological locomotion</subject><subj-group><subject>Flight (biology)</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject><subj-group><subject>Afferent neurons</subject><subj-group><subject>Photoreceptors</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject><subj-group><subject>Afferent neurons</subject><subj-group><subject>Photoreceptors</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory receptors</subject><subj-group><subject>Photoreceptors</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory receptors</subject><subj-group><subject>Photoreceptors</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory receptors</subject><subj-group><subject>Photoreceptors</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Signal transduction</subject><subj-group><subject>Sensory receptors</subject><subj-group><subject>Photoreceptors</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Local motion adaptation enhances the representation of spatial structure at EMD arrays</article-title>
<alt-title alt-title-type="running-head">Motion adaptation facilitates optic flow-based spatial vision</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1277-018X</contrib-id>
<name name-style="western">
<surname>Li</surname> <given-names>Jinglin</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Lindemann</surname> <given-names>Jens P.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Egelhaaf</surname> <given-names>Martin</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001">
<addr-line>Department of Neurobiology and Cluster of Excellence Cognitive Interaction Technology (CITEC), Bielefeld University, Bielefeld, Germany</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Ayers</surname> <given-names>Joseph</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Northeastern University, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">j.li@uni-bielefeld.de</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>12</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="epub">
<day>27</day>
<month>12</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>12</issue>
<elocation-id>e1005919</elocation-id>
<history>
<date date-type="received">
<day>13</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>13</day>
<month>11</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Li et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005919"/>
<abstract>
<p>Neuronal representation and extraction of spatial information are essential for behavioral control. For flying insects, a plausible way to gain spatial information is to exploit distance-dependent optic flow that is generated during translational self-motion. Optic flow is computed by arrays of local motion detectors retinotopically arranged in the second neuropile layer of the insect visual system. These motion detectors have adaptive response characteristics, i.e. their responses to motion with a constant or only slowly changing velocity decrease, while their sensitivity to rapid velocity changes is maintained or even increases. We analyzed by a modeling approach how motion adaptation affects signal representation at the output of arrays of motion detectors during simulated flight in artificial and natural 3D environments. We focused on translational flight, because spatial information is only contained in the optic flow induced by translational locomotion. Indeed, flies, bees and other insects segregate their flight into relatively long intersaccadic translational flight sections interspersed with brief and rapid saccadic turns, presumably to maximize periods of translation (80% of the flight). With a novel adaptive model of the insect visual motion pathway we could show that the motion detector responses to background structures of cluttered environments are largely attenuated as a consequence of motion adaptation, while responses to foreground objects stay constant or even increase. This conclusion even holds under the dynamic flight conditions of insects.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Insects, with their limited brain resources and high performance in a wide behavioral repertoire, are exquisite model systems for studying parsimonious signal processing. They extract spatial information by actively shaping their self-motion (e.g. when performing peering movements or during flight segments with fixed gaze) and estimate distance according to the speed of the resulting retinal displacements. The computation of retinal speed is accomplished by arrays of motion detector circuits retinotopically arranged in the second neuropile layer of the visual system. Sharing general adaptive response characteristics with other neurons and neuronal circuits, the responses of motion detectors depend on stimulus history. In the present study, we developed a novel adaptive model of the visual motion pathway of insects and analyzed the consequences of motion adaptation for computing spatial information about the 3D environment. We found that motion adaptation facilitates the segregation of nearby objects from their cluttered background during dynamic locomotion. The functional significance of motion adaptation is likely to generalize to optic flow-based spatial vision in other animals, and the motion adaptation mechanism implemented in our model could also be useful for artificial visual systems.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001659</institution-id>
<institution>Deutsche Forschungsgemeinschaft</institution>
</institution-wrap>
</funding-source>
<award-id>EX 277</award-id>
</award-group>
<funding-statement>The project is supported by the Cluster of Excellence Cognitive Interaction Technology “CITEC” (EXC277) at Bielefeld University, which is funded by DFG (<ext-link ext-link-type="uri" xlink:href="http://www.dfg.de/" xlink:type="simple">http://www.dfg.de/</ext-link>). We also acknowledge the support for the publication fee by the Deutsche Forschungsgemeinschaft and the Open Access Publication Funds of Bielefeld University. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="0"/>
<page-count count="23"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-01-09</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Files required for generating the stimuli, results and plots of the paper are available at the public repository PUB University Bielefeld DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.4119/unibi/2915797" xlink:type="simple">10.4119/unibi/2915797</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://pub.uni-bielefeld.de/data/2915797" xlink:type="simple">https://pub.uni-bielefeld.de/data/2915797</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Spatial vision is a fundamental challenge for animals moving in cluttered environments, and there is no exception for flying insects. Because of their small brains insects have to rely on parsimonious principles to compute spatial information about their environment. Possessing eyes that are close together, binocular spatial vision is no option in the spatial range that is behaviorally relevant for flight control. Alternatively, optic flow, i.e. the displacement of projections of surrounding objects on the retina during an animal’s locomotion, may provide the information needed about the surrounding depth structure. However, optic flow cues only provide depth information during translational self-motion, i.e. self-motion with the gaze direction kept constant over time. During pure rotations the retinal images of surrounding objects are displaced with the same angular velocity irrespective of distance [<xref ref-type="bibr" rid="pcbi.1005919.ref001">1</xref>]. Insects, such as flies and bees, shape their flight into rapid saccadic turns of head and body and translational segments where the gaze is largely kept constant [<xref ref-type="bibr" rid="pcbi.1005919.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1005919.ref006">6</xref>]. This behavioral strategy ‘purifies’ the translational flow by separating it from the rotational one and potentially serves the function of simplifying the computation of depth information.</p>
<p>Optic flow is not readily available at the input level of the visual system. Rather, motion detectors are required to compute optic flow information from the spatiotemporal retinal brightness changes induced during locomotion. In the visual systems of insects retinal intensity changes are encoded in membrane-potential changes by arrays of photoreceptors. The photoreceptor responses are band-pass filtered in the first visual neuropile, the lamina. The output of lamina cells is then used to compute local motion in the next neuropile, the medulla (e.g. [<xref ref-type="bibr" rid="pcbi.1005919.ref007">7</xref>]). Several variants of a particular model of motion detection, the correlation-type elementary motion detector (EMD), have been suggested to account for the functional properties of the insect motion detection circuit [<xref ref-type="bibr" rid="pcbi.1005919.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1005919.ref010">10</xref>]. As a common feature of all these model variants, motion is detected by correlating the non-delayed signal originating from one retinal input with a temporally delayed signal originating from a neighboring input. This model can successfully explain not only a wide range of electrophysiological data on the large-field motion sensitive lobula plate tangential cells (LPTCs), which spatially pool over arrays of EMDs, but also motion-induced behavior such as optomotor following (review: [<xref ref-type="bibr" rid="pcbi.1005919.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref011">11</xref>]). With genetic tools, more and more details about the neuronal basis of the motion detector circuits are being unraveled [<xref ref-type="bibr" rid="pcbi.1005919.ref012">12</xref>–<xref ref-type="bibr" rid="pcbi.1005919.ref020">20</xref>]. It has been shown in modeling studies that signals represented at the output of EMD arrays correlate well with the contrast-weighted nearness during behaviorally shaped translational self-motion [<xref ref-type="bibr" rid="pcbi.1005919.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref022">22</xref>].</p>
<p>Like photoreceptors, which adaptively encode light intensities, the neuronal circuits for motion detection are adaptive to motion. Adaptation is a general feature of neurons encoding information about the environment and allows to encode physical parameters that can vary over several decades by neurons with a limited operating range. Moreover, adaptive coding can also reduce redundancies in the sensory input, enhance changes in the signals, and may support energy efficiency of the neural computations [<xref ref-type="bibr" rid="pcbi.1005919.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1005919.ref025">25</xref>]. Since local motion detectors are difficult to access in electrophysiological experiments, most experimental evidence for adaptation of the motion detection pathway was obtained in LPTCs that are post-synaptic to the local motion detection circuits [<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>–<xref ref-type="bibr" rid="pcbi.1005919.ref032">32</xref>]. One major adaptive feature observed in LPTCs is the reduction of the cell responses during constant-velocity motion with retained or even enhanced sensitivity to brief velocity changes [<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref027">27</xref>]. This adaptive feature has been concluded to be generated, to a large extent, pre-synaptically to the LPTCs by a local retinotopic mechanism, although the exact location of this mechanism is still an open question [<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>].</p>
<p>Cluttered environments cause fluctuations in velocity across the retina under natural flight conditions, especially during translational flight at a constant velocity because of discontinuities in the depth structure of the surroundings. Therefore, we hypothesize that motion adaptation may enhance the representation of spatial information at the level of arrays of motion detectors. Following the same idea, Liang et al. [<xref ref-type="bibr" rid="pcbi.1005919.ref030">30</xref>] simulated the optic flow experienced by a free-flying fly in a box covered with photographs of a meadow scenery and a black cylinder positioned close to the loop-shaped flight trajectory. By repeatedly presenting this behaviorally generated optic flow to a fly, while recording from an LPTC, the consequences of motion adaptation for representing the cylinder in the neural response could be analyzed. Whereas responses to the walls of the flight arena were reduced by adaptation, the responses to the cylinder remained large [<xref ref-type="bibr" rid="pcbi.1005919.ref030">30</xref>]. Hence, the wide-field motion sensitive neuron became more sensitive to a nearby object relative to its background as a consequence of adaptation.</p>
<p>In the present study, this hypothesis was systematically tested and validated by model simulations. First, we developed an adaptive model of the visual motion pathway of insects that captures benchmark features of motion adaptation as analyzed in previous electrophysiological studies on LPTCs [<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>–<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>]. Our adaptive EMD model is based on an adaptation mechanism similar to the mechanisms previously proposed for light adaptation by photoreceptors [<xref ref-type="bibr" rid="pcbi.1005919.ref022">22</xref>], here however, operating on the output of EMDs and with much larger time constants. Based on this adaptive model of the visual motion pathway, our intention was to understand how motion adaptation affects the signal representation at the output of arrays of motion detectors and, in particular, the representation of the spatial layout of the environment during translational self-motion in 3D environments. With simulations of an insect model translating in both simple virtual and naturally cluttered 3D environments, we show that by reducing the response to background motion and maintaining large responses to nearby objects, motion adaptation can make nearby objects more salient. The conclusion that motion adaptation facilitates the segregation of nearby objects from their background during translational flight was further validated by taking the natural flight dynamics of insects into account.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and methods</title>
<p>Following the columnar and layered structure of the visual system of flies, our model of the visual motion pathway is composed of successive layers of retinotopic arrays of model photoreceptors (PRs), large monopolar cells (LMCs), EMDs, and of an LPTC integrating the output of large arrays of EMDs (<xref ref-type="fig" rid="pcbi.1005919.g001">Fig 1</xref>). The model parameters were tuned to qualitatively capture adaptive features revealed in previous electrophysiological studies (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2</xref>; [<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref027">27</xref>]). The model parameters were determined by systematic search in the chosen parameter range and by selecting the parameter combinations that correspond best to the electrophysiological benchmark data. The model was not only validated for the benchmark data, but also for a wider range of stimulus parameters (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3</xref>) and also by using other types of stimuli that were not used for its optimization (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4</xref>).</p>
<fig id="pcbi.1005919.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005919.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Adaptive model of the visual motion pathway.</title>
<p>(A) Schematic illustration of the organization of the insect (fly as an example) visual motion pathway (left), and the retinotopic structure of its model counterpart (right). (B) Computations performed in two neighboring channels of the model. Input light intensity (<italic>I</italic>) is processed at successive stages of (1) the adaptive photoreceptor (<italic>PR</italic>) model, which is realized by dividing a fast signal channel (low-pass filtered with small time constant <italic>PR</italic>.<italic>τ</italic><sub><italic>LP</italic>1</sub>) by a slow signal channel (low-pass filtered with large time constant <italic>PR</italic>.<italic>τ</italic><sub><italic>LP</italic>2</sub>) in a saturation-like Lipetz transformation; (2) LMC model, which consists of a high-pass filter, a half-wave rectification stage that splits the signal into an ON and an OFF channel, and a saturation-like Lipetz transformation; and (3) adaptive EMD model, which is composed of a basic Hassenstein-Reichhardt detector with a low-pass filter in its cross-channels, the output of which is adapted by dividing a fast branch (low- pass filtered by <italic>EMD</italic>.<italic>τ</italic><sub><italic>LP</italic>1</sub>) by a slow one representing motion direction-independent motion energy (average half-detector output low-pass filtered by <italic>EMD</italic>.<italic>τ</italic><sub><italic>LP</italic>2</sub>) in a saturation-like Lipetz transformation with adaptive exponent <italic>a</italic> to each component of the transformation (components involved in motion adaptation are overlayed by gray aera); and (4) a simple LPTC model pooling the half-detector output of ON and OFF pathway to preferred and anti-preferred direction over the entire receptive field. Parameters for the PR model: <italic>PR</italic>.<italic>τ</italic><sub><italic>LP</italic>1</sub> = 9<italic>ms</italic>; <italic>PR</italic>.<italic>τ</italic><sub><italic>LP</italic>2</sub> = 250<italic>ms</italic>; <italic>C</italic><sub><italic>PR</italic></sub> = 10. Parameters for LMC model: <italic>LMC</italic>.<italic>τ</italic><sub><italic>HP</italic></sub> = 10<italic>ms</italic>; <italic>C</italic><sub><italic>LMC</italic></sub> = 0.03. Parameters for EMD model: <italic>EMD</italic>.<italic>τ</italic><sub><italic>LP</italic></sub> = 50<italic>ms</italic>; <italic>EMD</italic>.<italic>τ</italic><sub><italic>LP</italic>1</sub> = 20<italic>ms</italic>; <italic>EMD</italic>.<italic>τ</italic><sub><italic>LP</italic>2</sub> = 4000<italic>ms</italic>; <italic>C</italic><sub><italic>EMD</italic></sub> = 0.8. <italic>a</italic> is adaptive to the average EMD response before adaptation (i.e. the output of “ave” icon) according to <xref ref-type="disp-formula" rid="pcbi.1005919.e003">Eq (3)</xref>. In this equation, <italic>a</italic><sub><italic>max</italic></sub> = 3; <italic>a</italic><sub><italic>min</italic></sub> = 0.5; <italic>p</italic><sub>1</sub> = 30; <italic>p</italic><sub>2</sub> = 150.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005919.g001" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005919.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005919.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Responses of a model LPTC to constant-velocity motion superimposed by brief velocity transients.</title>
<p>(A) LPTC model response (red) to constant motion of a sine-wave grating interspersed with incremental temporal frequency transients (inset, above the LPTC response), in comparison to electrophysiologically determined LPTC response (inset, from Figure 1 of [<xref ref-type="bibr" rid="pcbi.1005919.ref027">27</xref>]) to the same type of stimulus. (B) Same as (A), however, the velocity transients were decrements. In contrast to (A, B), in which the constant velocity is at the rising slope of the bell-shaped steady-state velocity tuning curve of motion detectors, in (C) the constant background velocity is at the falling slope of the velocity tuning curve, and (D) in the peak region of the bell-shaped tuning curve of motion detectors (red: high brightness contrast of grating, green: low contrast).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005919.g002" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005919.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005919.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Enhancement of response contrast by motion adaptation over a wide range of stimulus parameters.</title>
<p>(A) An example (corresponding to the condition marked by black frame in B) of model response to the same stimulus scheme as in <xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2</xref> (black), in which the peak response to the temporal frequency transient (red) and the response to the constant background temporal frequency (green) of the first and the last temporal frequency decrements were used to assess whether the response contrast to temporal frequency transients is enhanced by adaptation. (B) The changes of response contrast to temporal frequency transients (see <xref ref-type="disp-formula" rid="pcbi.1005919.e005">Eq (5)</xref>, red: enhancement and blue: reduction of response contrast with adaptation) assessed over a wide range of brightness contrasts of the sine-wave grating and the constant temporal frequencies (smaller plots: the same analysis for light conditions brighter by eight decades). (C, D) Same as (A, B), however, with transient temporal frequency increments rather than decrements superimposed on the background motion.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005919.g003" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005919.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005919.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Direction-independent motion adaptation and contrast gain reduction.</title>
<p>(A-C) Model responses (red) to 1 s of sine-wave grating motion before and after 4 s of motion adaptation (corresponding LPTC responses to the same type of stimulus, see Figure 2 and 5 in [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>]). During the motion adaptation period the sine-wave grating with high contrast and velocity moved in (A) the preferred direction (PD), (B) the null-direction (ND), or (C) an orthogonal direction. (D) For the same stimulus scheme, the brightness contrast of the grating during the reference and test period was systematically varied, and contrast gain was assessed by calculating the normalized response for the first 300 ms of the reference and test period (solid line: contrast gain before motion adaptation, dotted and dashed lines: contrast gain after PD and ND adaptation, see Figure 2 in [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>] for corresponding experimental data).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005919.g004" xlink:type="simple"/>
</fig>
<p>The overall goal of our model analysis was to find out how motion adaptation affects the representation of optic flow-based spatial information by arrays of EMDs. Therefore, we analyzed the responses to optic flow experienced in both virtual and natural 3D environments during constant-velocity motion (Figs <xref ref-type="fig" rid="pcbi.1005919.g005">5</xref>–<xref ref-type="fig" rid="pcbi.1005919.g007">7</xref>) and by taking the natural flight dynamics of flies into consideration (<xref ref-type="fig" rid="pcbi.1005919.g008">Fig 8</xref>). The structure of the model as well as the stimuli are described in the following.</p>
<fig id="pcbi.1005919.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005919.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Impact of motion adaptation on spatial vision during translation in an artificial 3D environment.</title>
<p>(A) Schematic illustration of spatial layout of the artificial 3D environment and the flight trajectory of an artificial agent translating parallel to a row of bars and a wall behind the bars. (B) The projection of the environment on the left hemisphere of a spherical eye. (C) The EMD response profile before adaptation (as the first bar passing by, left sub-Figure) and after adaptation (as the eighth bar passing by, right sub-Figure). (D) Motion energy averaged across elevation at 90° azimuth as a function of time; the response to the background wall is shown in the inset on a finer scale (red and green: section of response used to assess peak responses to bars and background for the purpose of assessing response contrast). (E) Response contrast between bar and background responses during the passage of each of the eight bars.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005919.g005" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005919.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005919.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Enhancement of motion detector response contrast with adaptation for different fore- and background depth differences.</title>
<p>(A) Schematic of the spatial layout of a 3D environment and the flight trajectory of an artificial agent, the same environmental design as in <xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5A</xref>, however, for three different wall distances in different scenarios (black: wall distance 0.55 m, green: 2 m, red: 4 m). (B) The average motion energy across elevations at 90° azimuth over time as assessed in <xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5D</xref>, however, averaged over 50 different wall and bar patterns. (C) Response contrast between each bar and background response with adaptation. Results obtained from 50 different random wall and bar patterns summarized in box plots (mid-line: median; box: 25–75 percentile: red cross: outlier). (D-G) Same as (B, C), however, with wall distances of 2 m and 4 m, respectively. (H) Averaged response contrast between bar and background as a function of time for all three scenarios with different wall distances over 50 different random wall and bar patterns.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005919.g006" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005919.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005919.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Impact of motion adaptation on the representation of spatial information by arrays of motion detectors during translational flight in a natural cluttered environment.</title>
<p>(A) Middle frame from an image sequence mimicking the retinal input during a translational motion in a forest. The whole stimulus sequence is composed of eight repetitions of a 900-ms-translational optic flow sequence. (B) EMD response profile before motion adaptation (in the middle of the first repetition, t = 450 ms) and (C) after motion adaptation (in the middle of the eighth repetition, t = 6750 ms). (D) Assessment of local response contrast changes with adaptation by subtracting the local response contrast of the EMD profile after adaptation (C) from that before adaptation (B) (red: enhancement and blue: attenuation of local EMD response contrast).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005919.g007" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005919.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005919.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Impact of motion adaptation on spatial vision for semi-natural flight dynamics.</title>
<p>Schematic of the spatial layout of a 3D environment and the flight trajectory of an artificial agent with (A) only translational movement or (C) with semi-natural flight consisting of eight cycles of a decagonal trajectory. (B) The same side view as the agent passes by a bar shared between conditions (A) and (C) for all three wall distances tested (black: 0.55 m, green: 2 m, and red: 4 m distance between wall and trajectory). (D) Average motion energy at 90° azimuth over time for the wall distance of 2 m averaged over 50 different wall and bar patterns (same as <xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6D</xref>). (F) Average response contrast (over 50 different wall and bar patterns) between bar and background responses over time for all three wall distances (same as <xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6H</xref>). (E, G) The same analysis as in (D, F), however, under semi-natural flight conditions in the environment as illustrated in (C).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005919.g008" xlink:type="simple"/>
</fig>
<sec id="sec003">
<title>Adaptive model of the visual motion pathway</title>
<sec id="sec004">
<title>Adaptive model of the peripheral visual system</title>
<p>The peripheral visual system consisting of PRs and LMCs was modeled according to Li et al. [<xref ref-type="bibr" rid="pcbi.1005919.ref022">22</xref>] (<xref ref-type="fig" rid="pcbi.1005919.g001">Fig 1B</xref>). In each input line, the brightness signal is split into two signal branches. One branch is low-pass filtered with a small time constant of 9 ms, leading to a signal that follows even high-frequency intensity fluctuations; the other branch is low-pass filtered with a large time constant of 250 ms, leading to a signal that indicates the current light condition on a much slower timescale. By adding a constant to the latter branch and dividing the output of the fast branch by this signal, a saturation-like transformation function is obtained that shifts adaptively over time according to the current light condition.
<disp-formula id="pcbi.1005919.e001"><alternatives><graphic id="pcbi.1005919.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005919.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mrow><mml:mi>P</mml:mi> <mml:msub><mml:mi>R</mml:mi> <mml:mrow><mml:mi>r</mml:mi> <mml:mi>e</mml:mi> <mml:mi>s</mml:mi> <mml:mi>p</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>L</mml:mi> <mml:mi>P</mml:mi> <mml:msub><mml:mn>1</mml:mn> <mml:mrow><mml:mi>P</mml:mi> <mml:mi>R</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>I</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mi>L</mml:mi> <mml:mi>P</mml:mi> <mml:msub><mml:mn>2</mml:mn> <mml:mrow><mml:mi>P</mml:mi> <mml:mi>R</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>I</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>P</mml:mi> <mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula>
In <xref ref-type="disp-formula" rid="pcbi.1005919.e001">Eq (1)</xref>, <italic>I</italic> is the input intensity, <italic>PR</italic><sub><italic>resp</italic></sub> is the photoreceptor response, <italic>LP</italic>1<sub><italic>PR</italic></sub> and <italic>LP</italic>2<sub><italic>PR</italic></sub> are first-order low-pass filters with small and large time constants, and <italic>C</italic><sub><italic>PR</italic></sub> is a constant. This adaptive photoreceptor model allows the visual system to operate over eight to ten decades of light intensities [<xref ref-type="bibr" rid="pcbi.1005919.ref022">22</xref>].</p>
<p>The photoreceptor output is then fed into the LMC model. The LMC model is a first-order high-pass filter that eliminates the information about the average brightness level. This high-pass filtering has been shown to be essential for extracting depth information by the motion detectors at the next processing stage [<xref ref-type="bibr" rid="pcbi.1005919.ref022">22</xref>]. As an elaboration of our earlier model [<xref ref-type="bibr" rid="pcbi.1005919.ref022">22</xref>], the LMC output is half-wave rectified and split into an ON and an OFF pathway according to its biological counterparts [<xref ref-type="bibr" rid="pcbi.1005919.ref033">33</xref>–<xref ref-type="bibr" rid="pcbi.1005919.ref035">35</xref>]. Furthermore, a saturation-like non-linearity was introduced to the LMC output by dividing the LMC output by the sum of the LMC output and a constant (<xref ref-type="fig" rid="pcbi.1005919.g001">Fig 1B</xref>).</p>
</sec>
<sec id="sec005">
<title>Adaptive elementary motion detector model</title>
<p>The LMC output of the ON and OFF pathway, respectively, is fed into the adaptive motion detector model (<xref ref-type="fig" rid="pcbi.1005919.g001">Fig 1B</xref>). This motion detector model is composed of a correlation-type motion detector and an adaptive processing of each half-detector output. The correlation-type motion detector is composed of two mirror-symmetric half-detectors sensitive to motion in opposite directions. Each half-detector detects motion by multiplying the delayed signal from one LMC output with the non-delayed signal from the corresponding neighboring LMC output. This leads to four EMD outputs for each column, two for preferred-direction (PD) motion of ON and OFF signals, respectively, and two for null-direction (ND) motion of ON and OFF signals. Each of the EMD outputs is processed by an adaptive mechanism similar to that of brightness adaptation of the photoreceptors (<xref ref-type="disp-formula" rid="pcbi.1005919.e001">Eq (1)</xref>, [<xref ref-type="bibr" rid="pcbi.1005919.ref022">22</xref>]), namely by dividing a fast signal branch following the fluctuations in the motion signal by a slow signal branch representing pattern velocities on a much slower timescale and embedding in a saturation-like Lipetz-transformation. Since motion adaption takes place on a much longer timescale than brightness adaptation in the peripheral visual system, the ‘fast’ and ‘slow’ time constants are much larger, 20 ms and 4 s, respectively, than the ‘fast’ and ‘slow’ time constants characteristic of brightness adaptation (see above). While the fast branches are the different half-detector outputs after being low-pass filtered with a small time constant, the slow branch is the average of all four half-detector outputs being low-pass filtered with a large time constant (<xref ref-type="fig" rid="pcbi.1005919.g001">Fig 1B</xref>). Adaptation of all four branches by the same slow signal was essential for achieving direction-independent motion adaptation. Moreover, to account for the increase of response transients to velocity changes an adaptive exponent is implemented in each component of the adaptation equation.
<disp-formula id="pcbi.1005919.e002"><alternatives><graphic id="pcbi.1005919.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005919.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mrow><mml:mi>E</mml:mi> <mml:mi>M</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mrow><mml:mi>a</mml:mi> <mml:mi>d</mml:mi> <mml:mi>p</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>L</mml:mi> <mml:mi>P</mml:mi> <mml:msub><mml:mn>1</mml:mn> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>M</mml:mi> <mml:mi>D</mml:mi></mml:mrow></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>E</mml:mi> <mml:mi>M</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>a</mml:mi> <mml:mi>d</mml:mi> <mml:mi>p</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>a</mml:mi></mml:msup></mml:mrow> <mml:mrow><mml:mi>L</mml:mi> <mml:mi>P</mml:mi> <mml:msub><mml:mn>2</mml:mn> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>M</mml:mi> <mml:mi>D</mml:mi></mml:mrow></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>E</mml:mi> <mml:mi>M</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mrow><mml:mi>a</mml:mi> <mml:mi>v</mml:mi> <mml:mi>e</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>a</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>C</mml:mi> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>M</mml:mi> <mml:mi>D</mml:mi></mml:mrow> <mml:mi>a</mml:mi></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula>
In <xref ref-type="disp-formula" rid="pcbi.1005919.e002">Eq (2)</xref>, <italic>EMD</italic><sub><italic>adpt</italic></sub> is the adapted EMD response of each branch, <italic>EMD</italic><sub><italic>nadpt</italic></sub> is the unadapted EMD response corresponding to the response after the multiplication, and <italic>EMD</italic><sub><italic>ave</italic></sub> is the average <italic>EMD</italic><sub><italic>nadpt</italic></sub> of all four branches. <italic>LP</italic>1<sub><italic>EMD</italic></sub> and <italic>LP</italic>2<sub><italic>EMD</italic></sub> are low-pass filters, <italic>C</italic><sub><italic>EMD</italic></sub> is a constant, and <italic>a</italic> is an adaptive exponent adjusted according to <italic>EMD</italic><sub><italic>ave</italic></sub>:
<disp-formula id="pcbi.1005919.e003"><alternatives><graphic id="pcbi.1005919.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005919.e003" xlink:type="simple"/><mml:math display="block" id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:mi>a</mml:mi></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>i</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>*</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>*</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>*</mml:mo> <mml:mi>L</mml:mi> <mml:mi>P</mml:mi> <mml:msub><mml:mn>2</mml:mn> <mml:mrow><mml:mi>E</mml:mi> <mml:mi>M</mml:mi> <mml:mi>D</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>E</mml:mi> <mml:mi>M</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mrow><mml:mi>a</mml:mi> <mml:mi>v</mml:mi> <mml:mi>e</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
In <xref ref-type="disp-formula" rid="pcbi.1005919.e003">Eq (3)</xref>, <italic>a</italic><sub><italic>max</italic></sub> and <italic>a</italic><sub><italic>min</italic></sub> are the upper and lower boundaries of exponent <italic>a</italic>, <italic>p</italic><sub>1</sub> and <italic>p</italic><sub>2</sub> are constants determining the speed of recovery and the strength of adaptive modification. <italic>LP</italic>2<sub><italic>EMD</italic></sub>(<italic>EMD</italic><sub><italic>ave</italic></sub>) is the unadapted EMD response of all four branches after they were averaged and low-pass filtered. Note that, the temporal frequency tuning of this correlation-type motion detector as well as its adaptive version are bell-shaped (Supplementary <xref ref-type="supplementary-material" rid="pcbi.1005919.s002">S2 Fig</xref>), i.e. with increasing stimulus temporal frequency the EMD response first increases, while with a further increase in temporal frequency the EMD response reaches an optimum and then decreases again.</p>
</sec>
<sec id="sec006">
<title>LPTC model</title>
<p>For simplicity, we assume that the outputs of the local motion detectors are linearly summated at the next stage of signal processing corresponding to the level of LPTCs (<xref ref-type="fig" rid="pcbi.1005919.g001">Fig 1B</xref>). Here, both half-detectors, i.e. ON and OFF, responding best to preferred-direction motion contribute to the sum with a positive sign, whereas both half-detectors responding best to null-direction motion contribute with a negative sign. The simplification of linearly summating the motion detector outputs instead of implementing a dynamic gain control at this processing stage [<xref ref-type="bibr" rid="pcbi.1005919.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref037">37</xref>] is justified in the context of the current paper, since the pattern size in all model simulations was kept constant. (Note that, the LPTC model is only used for the model development and characterization (Figs <xref ref-type="fig" rid="pcbi.1005919.g002">2</xref>–<xref ref-type="fig" rid="pcbi.1005919.g004">4</xref>), while the impact of motion adaptation on spatial vision is being analyzed at the level of adaptive EMD arrays (Figs <xref ref-type="fig" rid="pcbi.1005919.g005">5</xref>–<xref ref-type="fig" rid="pcbi.1005919.g008">8</xref>)).</p>
</sec>
</sec>
<sec id="sec007">
<title>Stimuli for model development and characterization</title>
<sec id="sec008">
<title>Stimulus set 1</title>
<p>The first stimulus set was characterized by a sine-wave grating moving at a constant velocity (7420 ms) superimposed by eight short (50 ms) velocity transients at regular time intervals (780 ms) (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2</xref> upper panel of insets). Before and after this motion stimulus the grating was stationary for 500 ms, as in the corresponding experiments by Kurtz et al. [<xref ref-type="bibr" rid="pcbi.1005919.ref027">27</xref>] and Maddess and Laughlin [<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>]. For convenience, we used in many places the term ‘velocity’ instead of ‘temporal frequency’, i.e. the ratio between the velocity and spatial wavelength. This is justified, because the spatial wavelength was kept constant throughout our simulations and, thus, velocity and temporal frequency are proportional. The transients are either increments in temporal frequency (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2A</xref>, from 2 Hz to 4 Hz) or decrements in temporal frequency (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2B</xref>, from 4 Hz to 2 Hz); the temporal frequency of the constant background motion was selected to be either smaller (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2A and 2B</xref>) or larger (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2C</xref>, 8 Hz background to 12 Hz transients) than the optimum of the bell-shaped, steady-state velocity tuning curve of EMDs, or it matched the optimum (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2D</xref>, 6 Hz background to 3 Hz transients); the brightness contrast was either high (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2</xref> red, <italic>c</italic> = 0.88) or low (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2</xref> green, <italic>c</italic> = 0.3). For all scenarios (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2A–2D</xref>) the sine-wave grating was a 3 × 360 pixel<sup>2</sup> matrix with average intensity <italic>I</italic><sub><italic>mean</italic></sub> = 1000 a.u., and spatial wave length λ = 19 pixel. (See [<xref ref-type="bibr" rid="pcbi.1005919.ref027">27</xref>] for the corresponding parameters used in the electrophysiological experiments.)</p>
<p>In order to assess under which conditions the sensitivity to velocity discontinuities is enhanced by motion adaptation we used the same stimulation scheme as described above and systematically varied the temporal frequency (0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8, and 25.6 Hz) and brightness contrast (0.05, 0.25, 0.45, 0.65, and 0.85) of the grating. For each combination of temporal frequency and contrast, the temporal frequency of the transients was either half (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3A and 3B</xref>) or twice as large (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3C and 3D</xref>) as the background temporal frequency. The model response was calculated for each of these conditions to assess whether the response contrast between the responses to the temporal frequency transients and the responses to constant background motion is enhanced by adaptation. The same stimulus scheme and response analysis was also done at a light level being brighter by eight decades (<italic>I</italic><sub><italic>mean</italic></sub> = 10<sup>12</sup> a.u. in <xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3B and 3D</xref> smaller plots in contrast to <italic>I</italic><sub><italic>mean</italic></sub> = 10<sup>3</sup> a.u. in <xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3B and 3D</xref> main plots) to test model performance for a wide range of light intensities.</p>
</sec>
<sec id="sec009">
<title>Stimulus set 2</title>
<p>Stimulus set 2 was used to test the responses of model LPTCs to a moving grating before and after adaptation with constant-velocity motion of a grating, as used by Harris et al. [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>]. Stimulus set 2 was characterized by the following sequence: a homogeneous screen of average brightness (500 ms), a reference stimulus consisting of motion of a sine-wave grating (1 s, <italic>c</italic> = 0.3, 3 Hz), a homogeneous screen of average brightness (50 ms), a long motion adaptation stimulus consisting of a grating of high contrast and constant velocity (4 s, <italic>c</italic> = 0.95, 5 Hz), immediately followed by a test stimulus of the same stimulus parameters as the reference stimulus, followed by a homogeneous screen (500 ms) (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4A–4C</xref>). During the adaptation phase the grating moved either in the preferred direction (PD) (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4A</xref>), in the null direction (ND) (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4B</xref>) or in the orthogonal direction (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4C</xref>). The sinewave grating was a 90 × 90 pixel<sup>2</sup> matrix with average brightness <italic>I</italic><sub><italic>mean</italic></sub> = 1000 a.u. and spatial wave length of 18 pixels.</p>
<p>Furthermore, under the same stimulus scheme as in <xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4A and 4B</xref>, the contrast of the grating of the reference and test stimulus was varied systematically (20 logarithmically and equally distributed contrast levels between 0.005 and 1) in order to analyze how motion adaptation modifies the contrast gain (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4D</xref>, see also Figure 2a in [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>]).</p>
</sec>
</sec>
<sec id="sec010">
<title>Stimuli for analyzing the role of motion adaptation for representing depth information</title>
<sec id="sec011">
<title>Visual stimuli generated by translational motion in virtual 3D environments</title>
<p>We used a virtual 3D environment consisting of a wall (1.1 m high, 16 m long, 0.55 m away from the flight trajectory) and a row of bars (5 cm wide, 1 m high, 1 m spacing, 0.5 m away from the flight trajectory) in front of the wall. An agent with one spherical eye (2° spatial resolution) moved parallel to the wall and the row of bars. It passed 1 bar/s during its 8 seconds of translational motion (<xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5A</xref>). The wall and the bars were textured with a random cloud pattern with 1/<italic>f</italic><sup>2</sup> statistics (<italic>f</italic> is the spatial frequency). The 3D environments were generated with Open Inventor 1.0 and the visual stimuli experienced by the agent were generated by Cyberfly toolbox developed by Lindemann et al. ([<xref ref-type="bibr" rid="pcbi.1005919.ref038">38</xref>]; <xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5B</xref>).</p>
<p>The spatial discontinuities between the bars and the background cause discontinuities in retinal velocities during translational motion. In order to compare the impact of motion adaptation on different depth differences we increased the distance between the objects and the wall without changing the distance between the bars and the agent (<xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6A</xref>). If we assume a flight speed of 1 m/s, the distance between the flight trajectory of the agent and the row of bars correspond to 0.5 m, and the walls in different scenarios to 0.55 m, 2 m, and 4 m. We adjusted the size of the wall accordingly to have the same-sized projection of the wall on the retina (<xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6A</xref>). As a result, different spatial scenarios were characterized by the same retinal size of wall texture elements and the bars, but a lower background velocity with increasing wall distance. In order to distinguish the influence of depth transients on the responses from the influence of a specific pattern texture 50 different random cloud walls and bar patterns were included in our analysis.</p>
</sec>
<sec id="sec012">
<title>Visual stimuli during translational motion in a natural 3D environment</title>
<p>We also tested a stimulus mimicking what flies experience during translational motion in a cluttered natural environment. By taking a sequence of panoramic photographs along a linear track with the help of a hyperbolic mirror in natural environments (for example in a forest) and applying corresponding rendering methods, image sequences mimicking the retinal image flow during translational motion at 1 m/s in a forest were generated (for details see [<xref ref-type="bibr" rid="pcbi.1005919.ref021">21</xref>] and published data [<xref ref-type="bibr" rid="pcbi.1005919.ref039">39</xref>]). The available image sequences recorded in natural environments were too short for investigating the effect of motion adaptation (if we assume a flight speed of 1 m/s, the image sequences correspond to only 900 ms, whereas motion adaptation has a timescale of several seconds [<xref ref-type="bibr" rid="pcbi.1005919.ref027">27</xref>]). Therefore, we repeated the same image sequence eight times via concatenation. The concatenated image sequences were then fed into our adaptive model of the visual motion pathway. A potential influence of the discontinuity in the scenery due to concatenation was minimized by analyzing the influence of motion adaptation for the frames in the middle of the individual image sequences (<xref ref-type="fig" rid="pcbi.1005919.g007">Fig 7A</xref>).</p>
</sec>
<sec id="sec013">
<title>Visual stimuli based on semi-natural flight dynamics</title>
<p>Natural flight of flies consists of segments of translation interspersed with quick saccadic rotations. In order to investigate the impact of motion adaptation on spatial vision under conditions of natural flight dynamics we designed an artificial 3D environment and an artificial flight trajectory taking the dynamics of real flight of flies into account. According to [<xref ref-type="bibr" rid="pcbi.1005919.ref002">2</xref>] the saccade frequency of free blowfly flights in a cubic box is approximately 10/s; the yaw angle of saccadic turns varies by up to 90°, and the corresponding yaw velocity can reach up to several thousands of degrees per second. Considering these features of real flight dynamics, we generated a semi-realistic flight trajectory by bending each second of the linear translational flight trajectory of a total duration of 8 s, as described, for the pure translational scenario (<xref ref-type="fig" rid="pcbi.1005919.g008">Fig 8A</xref>) into a decagon (<xref ref-type="fig" rid="pcbi.1005919.g008">Fig 8D</xref>). This trajectory was centered in a decagonal flight arena, and the distance from the flight trajectory to the bar and the wall as well as the size of the bar and the height of the wall were kept the same as for the straight trajectory. The bar and the walls were also textured with a random cloud pattern, and the frequency at which a bar was passed by (1 bar/s) was also kept the same. One cycle of the decagonal trajectory was composed of a sequence of 80-ms-pure-translations along the walls of the decagon and 20-ms-pure-rotations that led to a 36° saccadic turn in the corners of the decagon. During the saccadic turns in the corners roll and pitch were kept constant, and the dynamics of yaw-velocity was based on recorded free flight data [<xref ref-type="bibr" rid="pcbi.1005919.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref038">38</xref>] following the equation:
<disp-formula id="pcbi.1005919.e004"><alternatives><graphic id="pcbi.1005919.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005919.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mi>a</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>36</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>180</mml:mn></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>20</mml:mn></mml:mrow></mml:msubsup><mml:mi>G</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="2pt"/><mml:mi>w</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>σ</mml:mi><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>10.5</mml:mn><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>3.5</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:mn>20</mml:mn><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
In this way, the saccade frequency, the yaw angle and velocity during saccades were within a realistic range and the total length and duration of the trajectory were identical to the pure translational trajectory.</p>
</sec>
</sec>
</sec>
<sec id="sec014" sec-type="results">
<title>Results</title>
<sec id="sec015">
<title>Characterization of motion adaptation by modeling the responses to benchmark stimuli</title>
<p>The adaptive model of the fly visual motion pathway was first tested with visual stimuli that were used in previous electrophysiological studies on fly LPTCs [<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>–<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>]. The characteristic responses of the LPTCs were used as a benchmark to adjust the model parameters of our adaptive model.</p>
<p>When presenting a sine-wave grating moving at a constant velocity superimposed by short-velocity increments as in Kurtz et al. [<xref ref-type="bibr" rid="pcbi.1005919.ref027">27</xref>], both model and LPTC responses decayed over time (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2A</xref>). However, the short response increments induced by the increments in velocity were not reduced, but even slightly increased over time (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2A</xref>). Both model and cell responses revealed similar adaptive features when the constant-velocity motion was superimposed by velocity decrements: While the overall response amplitude considerably decreased, the response decrements evoked by the velocity decrements were even enhanced over time (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2B</xref>). A characteristic feature of both biological and model motion detectors is the bell-shaped steady-state velocity tuning: i.e. the motion detector response increases with velocity up to a certain velocity and then decreases again if the velocity further increases. Similar adaptive features as just described for the rising phase of the velocity-response characteristic (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2A and 2B</xref>) were observed when the constant background velocity was on the downward-sloping side of the bell-shaped velocity-response characteristic (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2C</xref>) as well at its optimum (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2D</xref>). Note that, in <xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2C</xref> transient velocity increments evoked transient response decrements, while in <xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2D</xref> transient velocity decrements evoked fluctuations around background response level. In conclusion, while motion adaptation leads to a reduction of motion-induced responses on a slow timescale, it enhances the relative sensitivity of both LPTCs and the adaptive model of the visual motion pathway to velocity transients under a wide range of stimulus conditions. Since peripheral brightness adaptation implemented in our model, which is in a steady state already within several hundreds of milliseconds [<xref ref-type="bibr" rid="pcbi.1005919.ref022">22</xref>], it does not much contribute to the described adaptive decay of the background activity and the enhancement of transient response on a timescale of several seconds as is characteristic of motion adaptation.</p>
<p>In order to systematically assess under which conditions the relative sensitivity to velocity increments (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3A and 3B</xref>) and decrements (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3C and 3D</xref>) is enhanced by adaptation we used the same stimulus scheme as in <xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2</xref> and systematically varied the velocity and the brightness contrast of the grating (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3B and 3D</xref>). The sensitivity to each velocity transient was quantified by calculating the response contrast between the response to the velocity transient and the response to the constant background velocity:
<disp-formula id="pcbi.1005919.e005"><alternatives><graphic id="pcbi.1005919.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005919.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>r</mml:mi> <mml:mi>e</mml:mi> <mml:mi>s</mml:mi> <mml:mi>p</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>R</mml:mi> <mml:mrow><mml:mi>b</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>R</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msub><mml:mi>R</mml:mi> <mml:mrow><mml:mi>b</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>R</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula>
In <xref ref-type="disp-formula" rid="pcbi.1005919.e005">Eq (5)</xref> <italic>C</italic><sub><italic>resp</italic></sub> is the response contrast; <italic>R</italic><sub><italic>bg</italic></sub> represents the LPTC model response to the constant background velocity calculated as the average response over 200 ms before the transient response (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3A and 3C</xref>, color-coded in green); and <italic>R</italic><sub><italic>pk</italic></sub> is the peak response within the transient response range (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3A and 3C</xref>, color-coded in red). To assess whether the response contrast was enhanced with adaptation we subtracted the response contrast to the first transient from the last one and used this value as an enhancement score (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3B and 3D</xref>, color code in black square frames). A positive enhancement score (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3B and 3D</xref>, warm colors) indicates an enhancement of response contrast to velocity transients, whereas a negative score (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3B and 3D</xref>, cold colors) indicates an attenuation of the response contrast. An enhancement of response contrast to velocity decrements (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3B</xref>) as well as increments (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3D</xref>) is evident under most examined stimulus conditions of brightness contrast and velocity as revealed by the dominantly warm-colored heat maps. As a consequence of brightness adaptation in the peripheral visual system, this performance was maintained even if the overall pattern brightness was increased by up to 8 decades (<xref ref-type="fig" rid="pcbi.1005919.g003">Fig 3B and 3D</xref> smaller plots).</p>
<p>We tested the model with another type of stimulus as used in a previous electrophysiological study on motion adaptation. As Harris et al. [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>] tested the adaptive performance of fly LPTCs, we tested how the response to a velocity step of our adaptive model was affected by adaptation stimuli moving in the preferred direction (PD), the null direction (ND), as well as orthogonal to these directions (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4A–4C</xref>). The LPTC model response resembled that of LPTCs in the following qualitative features: The responses after adaptation were considerably smaller than the reference responses before adaptation irrespective of the direction of motion during adaptation (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4A, 4B and 4C</xref>). Even if orthogonal pattern motion was used for adaptation, the adaptive effect was present, although both model and LPTCs almost did not respond to the adaptation stimulus (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4C</xref>). In the electrophysiological recordings the initial part of the test phase after PD adaptation was less depolarized for a short time interval than that after ND adaptation (see Figure 2a in [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>]). This was not the case in the corresponding model response (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4A and 4B</xref>). The observed difference between model and experimental data is mainly due to the after-hyperpolarization, which occurs at the LPTC level after a strong depolarization of the cell. Since our present study focuses on the impact of motion adaptation on the EMD-level, the after-hyperpolarization generated in the postsynaptic LPTC has not been taken into account.</p>
<p>Harris et al. [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>] further assessed the modulation of contrast gain by motion adaptation (see Figure 2a in [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>]) by systematically varying the brightness contrast of the reference and test stimulus and comparing response amplitudes before and after motion adaptation. Part of the response characteristics revealed in their study can be explained by our model, such as the rightward-shift of the contrast-gain curve after motion adaptation (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4D</xref>). Our model successfully accounts for the reduction of the contrast gain after both PD adaptation and ND adaptation. However, our model does not explain two other response characteristics described by Harris et al. [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>], namely the after-hyperpolarization following PD motion adaptation and the corresponding reduction of the output range of the cell (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4D</xref>). Both response characteristics have been concluded to occur at the LPTC level [<xref ref-type="bibr" rid="pcbi.1005919.ref040">40</xref>] which is not covered by our current model.</p>
</sec>
<sec id="sec016">
<title>Potential significance of motion adaptation for spatial vision</title>
<p>The above model was used to investigate the impact of motion adaptation on the representation of spatial information at the level of arrays of motion detectors. This was done by simulating the visual input as experienced during translational motion in both virtual 3D environments (Figs <xref ref-type="fig" rid="pcbi.1005919.g005">5</xref> and <xref ref-type="fig" rid="pcbi.1005919.g006">6</xref>) and cluttered natural 3D environments (<xref ref-type="fig" rid="pcbi.1005919.g007">Fig 7</xref>), employing pure translational motion (Figs <xref ref-type="fig" rid="pcbi.1005919.g005">5</xref>, <xref ref-type="fig" rid="pcbi.1005919.g006">6</xref> and <xref ref-type="fig" rid="pcbi.1005919.g007">7</xref>) or mimicking natural flight dynamics of flies (<xref ref-type="fig" rid="pcbi.1005919.g008">Fig 8</xref>).</p>
<sec id="sec017">
<title>Translational motion in virtual and natural 3D environments</title>
<p>According to available electrophysiological data and our model simulations, motion adaptation can enhance the relative sensitivity to discontinuities in the motion stimulus, while reducing the overall response to sustained motion (<xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2</xref>). This feature can potentially favor optic flow-based spatial vision, since during translational motion depth contours generate discontinuities in the optic flow profile, which might be enhanced as a consequence of motion adaptation. In order to test this hypothesis we first moved a virtual agent parallel to a row of bars in front of a wall (<xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5A</xref>). The environment projected on the left eye is illustrated in <xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5B</xref>.</p>
<p>We used the resulting motion sequence as the input to our model of the visual motion pathway and compared the response profile of the retinotopic EMD arrays before (<xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5C</xref> left) and after (<xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5C</xref> right) motion adaptation, i.e. when the first bar vs. when the last bar was passing the lateral part of the visual field. The responses to both the bars and the background wall were generally reduced after adaptation. However, as a consequence of motion adaptation, the response to the background wall pattern was much more reduced in comparison with the response to the bars making the bars more salient in the overall response profile of the EMDs (<xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5C</xref>).</p>
<p>In order to quantify this impression we assessed the sensitivity to the depth discontinuities in the following way: First, we combined the temporal development of EMD responses to bars and background wall to one variable. To this end, we chose the lateral (azimuth = 90°) part of the visual field for our response analysis, because for geometric reasons bars passing the visual field at 90° azimuth led to the strongest responses and covered most of the vertical extent of the visual field. We then calculated the average of the motion energy (i.e. absolute value of EMD responses) at 90° azimuth over time (<xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5D</xref>), which represents both bar and wall responses over time. Finally, based on these time-dependent bar and wall responses we calculated the response contrast according to <xref ref-type="disp-formula" rid="pcbi.1005919.e005">Eq (5)</xref> for each of the eight consecutive bars and the corresponding wall sections (<xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5E</xref>). Due to the strong reduction of background activity (<xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5D</xref> inset), the response contrast increased almost monotonically with adaptation (<xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5E</xref>).</p>
<p>To investigate the impact of the distance (and consequently retinal velocity) differences between the bars and the wall the wall was placed at a distance of 0.55 m, 2 m and 4 m from the flight trajectory in different scenarios, while the bars were kept unchanged at 0.5 m from the flight trajectory (<xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6A</xref>). Moreover, to reduce potential effects of a specific cloud pattern we assessed the bar and wall responses (<xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6B, 6D and 6F</xref>) and the response contrast between the bars and the wall (<xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6C, 6E and 6G</xref>) as in <xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5D and 5E</xref> for 50 random wall and bar patterns and averaged across textures (<xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6B, 6D, 6F and 6H</xref>). The response contrast evoked by the bars increased for all wall distances tested (<xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6H</xref>) as a consequence of a strong reduction of background wall responses with adaptation (<xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6B, 6D and 6F</xref> insets). This effect was the more pronounced the closer the wall was to the bars and, thus, the smaller the response contrast was before motion adaptation (<xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6H</xref>). Thus, motion adaptation enhances the sensitivity of the motion detection system to depth discontinuities.</p>
<p>This conclusion was further corroborated with more realistic stimuli mimicking the visual input during translational motion in a forest (<xref ref-type="fig" rid="pcbi.1005919.g007">Fig 7A</xref>). Because the original image sequence has a duration of only 900 ms (assuming 1 m/s flight speed) which is too short for investigating motion adaptation, the original image sequence was concatenated eight times. In order to see how motion adaptation affects the representation of the environment by arrays of motion detectors the response profiles of EMDs before adaptation (i.e. in the middle of the first repetition of a translational trajectory, <xref ref-type="fig" rid="pcbi.1005919.g007">Fig 7B</xref>) was compared with that after adaptation (i.e. in the middle of the eighth repetition, <xref ref-type="fig" rid="pcbi.1005919.g007">Fig 7C</xref>). Similar, but less prominent effects as in <xref ref-type="fig" rid="pcbi.1005919.g005">Fig 5C</xref> can be observed here: Motion adaptation led to a larger reduction of the responses to background structures than to the contours of nearby tree trunks, which makes the nearby tree trunks more salient. In order to better assess the influence of motion adaptation on signal representation by EMD arrays we calculated the local response contrast of the EMD response profile before and after motion adaptation and subtracted the local response contrast profile after adaptation from that before adaptation (<xref ref-type="fig" rid="pcbi.1005919.g007">Fig 7D</xref>). The red color indicates regions in the environment where the local response contrast was enhanced by adaptation, which corresponds mainly to the contours of nearby tree trunks.</p>
</sec>
<sec id="sec018">
<title>During semi-natural flight</title>
<p>According to our simulation results, motion adaptation enhances the segregation of foreground objects from their background if an agent performs pure translational motion (Figs <xref ref-type="fig" rid="pcbi.1005919.g005">5</xref>–<xref ref-type="fig" rid="pcbi.1005919.g007">7</xref>). However, the translational periods of insect flight are never as long, but frequently interspersed with fast saccadic turns. To test whether the image flow induced by saccadic turns affects our conclusion that the representation of nearby contours is enhanced by motion adaptation, we designed a semi-natural flight trajectory that takes several features of natural flight dynamics into account [<xref ref-type="bibr" rid="pcbi.1005919.ref002">2</xref>]. Furthermore, we shaped the trajectory and the virtual 3D environments into decagons, so that the visual stimulus was as similar as possible to that used to obtain the results shown in <xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6</xref> (<xref ref-type="fig" rid="pcbi.1005919.g008">Fig 8A–8C</xref>). The same response analysis was performed as in <xref ref-type="fig" rid="pcbi.1005919.g006">Fig 6</xref>. Under such semi-natural flight conditions (<xref ref-type="fig" rid="pcbi.1005919.g008">Fig 8E and 8G</xref>), the background activity was dominated by the rotational response. This background activity was strong and rather independent of wall distance. Therefore, the response contrast curves increased with motion adaptation, but with a relatively shallow slope. Moreover, the response amplitudes did not differ as much for different wall distances as those obtained during linear motion without saccadic turns interspersed (compare <xref ref-type="fig" rid="pcbi.1005919.g008">Fig 8F and 8G</xref>).</p>
<p>Without saccadic turns, the response contrast between the bars and the background increased most when the distance between wall and bars was smallest and, accordingly, the background and bar responses most similar. Thus, the adaptation is most effective when an enhancement of the response contrast is particularly relevant to segregate objects from their background. However, this characteristic is hardly visible under semi-naturalistic conditions, in which large responses were induced by saccades. However, the general qualitative feature of enhanced response contrast between nearby objects and background with motion adaptation was maintained even with saccades, though to a much smaller extent. There is evidence that responses to saccadic turns are suppressed in visual neurons (measured in LPTCs) by efference copy signals [<xref ref-type="bibr" rid="pcbi.1005919.ref041">41</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref042">42</xref>]. Although the exact location of the target of the efference copy is not yet clear, this mechanism can potentially counteract the above mentioned detrimental effects of saccades on the consequences of motion adaptation.</p>
</sec>
</sec>
</sec>
<sec id="sec019" sec-type="conclusions">
<title>Discussion</title>
<p>The present study shows by model simulations that local motion adaptation as observed in the fly visual pathway facilitates optic flow-based spatial vision by enhancing the representation of nearby objects in the response profile of arrays of local motion detectors. This is due to the fact that motion adaptation strongly reduces the responses to constant or slowly-varying background velocities, while maintaining or even enhancing the responses to velocity discontinuities. Because discontinuities in the optic flow in different regions of the visual field are caused by discontinuities in the depth structure of the environment during translational locomotion, the enhanced sensitivity to optic flow discontinuities is concluded to improve the representation of the depth structure.</p>
<p>The above conclusion has been obtained by model simulations with a novel adaptive model of the visual motion pathway of flies (<xref ref-type="fig" rid="pcbi.1005919.g001">Fig 1</xref>). The model was developed mainly based on response characteristics of fly motion sensitive neurons recorded in previous studies ([<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref027">27</xref>], <xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2</xref>). In this model, motion adaptation is accomplished by a modified version of a mechanism that has previously been used to model brightness adaptation of photoreceptors [<xref ref-type="bibr" rid="pcbi.1005919.ref022">22</xref>], although adaptation at the different processing stages operates on very different timescales, with motion adaptation being much slower than brightness adaptation. Motion adaptation is based on a divisive interaction of the relatively fast output signal of each half-detector with a much slower branch. The slower branch reflects the direction-independent motion energy by combining the temporally low-pass filtered output of all half-detectors at this retinal location irrespective of their preferred direction. Decisive for motion adaptation to enhance the response to optic flow discontinuities is an adaptation of the exponent of each component of the division by the direction-independent motion energy level (see Eqs <xref ref-type="disp-formula" rid="pcbi.1005919.e001">(1)</xref>–<xref ref-type="disp-formula" rid="pcbi.1005919.e003">(3)</xref>). The adaptive model of the visual motion pathway does not only account for the benchmark response features of fly motion sensitive neurons under a wide range of stimulus conditions (Figs <xref ref-type="fig" rid="pcbi.1005919.g002">2</xref> and <xref ref-type="fig" rid="pcbi.1005919.g003">3</xref>), but also reproduces the direction-independent component of motion adaptation (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4A–4C</xref>; [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>]) and the contrast gain reduction (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4D</xref>; [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>]) observed in the fly nervous system.</p>
<p>With this adaptive model of the visual motion pathway, we could show that during translational motion in artificial (Figs <xref ref-type="fig" rid="pcbi.1005919.g005">5</xref> and <xref ref-type="fig" rid="pcbi.1005919.g006">6</xref>) and in cluttered natural (<xref ref-type="fig" rid="pcbi.1005919.g007">Fig 7</xref>) 3D environments motion adaptation may enhance the sensitivity to velocity discontinuities in the retinal image induced by nearby objects. We could further show that this conclusion remains even valid under dynamic conditions mimicking the free flight behavior of insects (<xref ref-type="fig" rid="pcbi.1005919.g008">Fig 8</xref>).</p>
<sec id="sec020">
<title>Adaptive model of the insect visual motion pathway</title>
<p>Several previous modeling studies have been dedicated to explain motion adaptation in the fly visual pathway at the level of LPTCs [<xref ref-type="bibr" rid="pcbi.1005919.ref043">43</xref>–<xref ref-type="bibr" rid="pcbi.1005919.ref046">46</xref>] and to decompose the components of the mechanisms involved [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>].</p>
<p>Clifford and Ibbotson [<xref ref-type="bibr" rid="pcbi.1005919.ref045">45</xref>] explained the reduction of the cell response to constant-velocity motion, while maintaining or enhancing sensitivity to brief velocity changes [<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref027">27</xref>] by adaptive changes of the EMD low-pass filter time constant by feedback control. This time constant is specific for the motion detection circuit and, especially, for determining its velocity tuning. In contrast, the adaptation mechanism proposed in the present study is a more general-purpose feed-forward adaptive model. The computational principle underlying this mechanism can be used at different stages of the visual pathway to explain, after adjustment of the time constants to the particular functional needs, brightness adaptation of photoreceptors as well as motion adaptation of the motion detection circuits. This simple adaptation mechanism does not only explain the enhancement of response contrast with motion adaptation for a wide range of test conditions (Figs <xref ref-type="fig" rid="pcbi.1005919.g002">2</xref> and <xref ref-type="fig" rid="pcbi.1005919.g003">3</xref>). It also explains that motion adaptation in fly LPTCs is to a large extent direction-independent (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4</xref>; [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref044">44</xref>]), and reproduces the reduction of contrast gain (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4</xref>; [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>]). We could not validate these features (Figs <xref ref-type="fig" rid="pcbi.1005919.g002">2</xref>, <xref ref-type="fig" rid="pcbi.1005919.g003">3</xref> and <xref ref-type="fig" rid="pcbi.1005919.g004">4</xref>) by re-implementing and testing the model of Clifford [<xref ref-type="bibr" rid="pcbi.1005919.ref045">45</xref>] (see [<xref ref-type="bibr" rid="pcbi.1005919.ref047">47</xref>]).</p>
<p>Harris et al. [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>] analyzed the adaptive properties of LPTCs by confronting them with grating motion before and after a period of motion adaptation in PD, ND or in the orthogonal direction. They attributed motion adaptation observed in LPTCs to three components: (1) a motion-dependent, but direction-independent contrast gain reduction, (2) a strong direction-selective after-hyperpolarization, and (3) an activity-dependent reduction of the response range. Amongst these adaptive components, our model can account for the direction-independent contrast gain reduction (<xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4</xref>). The other two components of motion adaptation characterized by Harris et al. [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>] are not covered by the present model. This finding is in line with the conclusion that these components of motion adaptation have their origin post-synaptic to the EMDs at the LPTC level [<xref ref-type="bibr" rid="pcbi.1005919.ref040">40</xref>]. As pointed out above, it has not been the goal of the present study to model LPTCs, but to study the impact of local motion adaptation on the signal representation of environmental information at the level of EMD arrays. However, in principle, depending on the signal used to adapt each branch of the half- detector, this model can be adjusted to also account for direction-dependent motion adaptation.</p>
<p>Another modeling study on motion adaptation of LPTCs attempted to explain a different response feature of LPTCs, i.e. the shortening of the response transients induced by motion steps and motion impulses after adaptation [<xref ref-type="bibr" rid="pcbi.1005919.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref046">46</xref>]. This feature might potentially further enhance the representation of discontinuities in the optic flow pattern by increasing the temporal resolution of motion detectors. On the other hand, this model based on adapting time constants of filters in the cross-branches of the EMDs before the multiplication stage [<xref ref-type="bibr" rid="pcbi.1005919.ref046">46</xref>] cannot explain the adaptive benchmark features examined in this study (own results based on a reimplementation of the model of [<xref ref-type="bibr" rid="pcbi.1005919.ref046">46</xref>]; Supplementary <xref ref-type="supplementary-material" rid="pcbi.1005919.s001">S1 Fig</xref>).</p>
<p>Since motion adaptation in our model was realized at the output of the EMD half-detectors rather than by interfering with motion computation itself, this adaptive mechanism could also be applied at the output of other types of motion detector models such as recently published motion detector models combining preferred-direction enhancement and anti-preferred direction inhibition [<xref ref-type="bibr" rid="pcbi.1005919.ref010">10</xref>].</p>
</sec>
<sec id="sec021">
<title>Functional significance of local motion adaptation at EMDs</title>
<p>It was already in the fifties of the last century that each stage of signal processing in nervous systems had been suggested to reduce redundancy in order to efficiently use the limited information capacity of neurons and to extract eventually ecologically relevant information [<xref ref-type="bibr" rid="pcbi.1005919.ref048">48</xref>]. Given the limited coding capacity of all processing stages of a nervous system, it is expected for each layer of neurons to be adaptive, i.e. to be able to adjust its input-output relationship according to recent input history. Examples from insect visual systems (but restricted neither to the visual modality nor to insects [<xref ref-type="bibr" rid="pcbi.1005919.ref049">49</xref>–<xref ref-type="bibr" rid="pcbi.1005919.ref051">51</xref>]) are brightness adaptation in photoreceptors and LMCs [<xref ref-type="bibr" rid="pcbi.1005919.ref052">52</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref053">53</xref>], motion adaptation at the level of local motion detectors (although measured in large-field motion sensitive cells, [<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref054">54</xref>]), and wide-field motion adaptation at the level of LPTCs [<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref040">40</xref>]. It is generally assumed from the perspective of information theory that adaptive coding provides the advantage of an efficient use of the coding capacity of neural circuits by removing redundant (i.e. unchanging or only slowly changing) signals based on the recent input history [<xref ref-type="bibr" rid="pcbi.1005919.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref050">50</xref>]. Redundancy reduction can increase information transmission [<xref ref-type="bibr" rid="pcbi.1005919.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref024">24</xref>] and save encoding energy [<xref ref-type="bibr" rid="pcbi.1005919.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref055">55</xref>].</p>
<p>There have been several studies revealing adaptive features based on electrophysiological experiments on LPTCs using various system-analytical stimuli [<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>–<xref ref-type="bibr" rid="pcbi.1005919.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref043">43</xref>], and a major component of the adaptive mechanisms is suggested to occur locally pre-synaptic to the LPTCs [<xref ref-type="bibr" rid="pcbi.1005919.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref043">43</xref>]. However, how local motion adaptation affects signal representation in the responses of motion detector arrays during flight in the three dimensional world has by now only been analyzed experimentally in an indirect way at the level of LPTCs [<xref ref-type="bibr" rid="pcbi.1005919.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref031">31</xref>], but due to methodological constraints not at the level of the array of their pre-synaptic local input elements. With our adaptive model of the visual motion pathway, it was possible to analyze the impact of local motion adaptation on the signal representation at EMD arrays, at least by simulation approaches. In this way, we found that, as a consequence of motion adaptation, the representation of foreground objects in an environment is much more salient at the EMD output than the EMD responses to the background clutter (Figs <xref ref-type="fig" rid="pcbi.1005919.g005">5</xref>–<xref ref-type="fig" rid="pcbi.1005919.g007">7</xref>). Consistent with the experimental results on LPTCs [<xref ref-type="bibr" rid="pcbi.1005919.ref031">31</xref>], we could show that this segregation of foreground objects from background clutter is maintained, even if translational flights were interspersed with fast saccades, as are the characteristic of insect flight (<xref ref-type="fig" rid="pcbi.1005919.g008">Fig 8</xref>). However, saccades interspersed between translational self-motion segments of the agent attenuate the enhancement of the response contrast between fore- and background and its distance-dependency. This detrimental influence of saccades on representing spatial information by movement detectors may be counteracted by the experimentally established efference copy signals that were found to suppress saccade-driven visual motion responses [<xref ref-type="bibr" rid="pcbi.1005919.ref041">41</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref042">42</xref>].</p>
<p>What is the functional significance of an enhancement of nearby contours at the movement detector output resulting from motion adaptation? This question cannot yet be answered, because not much is known about how the output of EMD arrays, apart from being LPTC input, is processed. Furthermore, closed-loop control as is characteristic of most behaviors may add complexity to our understanding of the role of local motion adaptation. If the enhancement measured in our model simulations is sufficient to substantially change the detectability of objects is hard to assess without making assumptions on the signal-to-noise situation in a real system and the structure of the following processing steps.</p>
<p>In principle, the information provided by motion detector arrays during self-motion may serve later-stage signal processing subserving a wide range of behavioral tasks, such as (1) optic flow-based spatial vision which is important for detecting objects [<xref ref-type="bibr" rid="pcbi.1005919.ref056">56</xref>], collision avoidance [<xref ref-type="bibr" rid="pcbi.1005919.ref057">57</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref058">58</xref>] and landing [<xref ref-type="bibr" rid="pcbi.1005919.ref059">59</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref060">60</xref>], (2) gaze stabilization during locomotion [<xref ref-type="bibr" rid="pcbi.1005919.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref061">61</xref>], (3) flight speed control [<xref ref-type="bibr" rid="pcbi.1005919.ref057">57</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref062">62</xref>] and (4) visual odometry [<xref ref-type="bibr" rid="pcbi.1005919.ref063">63</xref>, <xref ref-type="bibr" rid="pcbi.1005919.ref064">64</xref>]. The impact of motion adaptation on signal processing in these behavioral contexts is still not clear. However, one potentially important aspect is that local motion adaptation at the EMD level is largely direction-independent ([<xref ref-type="bibr" rid="pcbi.1005919.ref028">28</xref>]; <xref ref-type="fig" rid="pcbi.1005919.g004">Fig 4</xref>). This feature could be functionally important in maintaining equal adaptive states and, thus, equal sensitivity of local motion detectors with different preferred directions. If the sensitivity of differently aligned motion detectors is changed by an adaptive mechanism depending on the direction of motion, the population responses of such detectors would indicate different directions of local motion in response to a given motion direction-depending stimulus history. Thus, direction-independent adaptation might be important in behavioral contexts where a correct representation of local motion direction is essential.</p>
<p>Although this model study is based on the electrophysiological data and flight data from blowflies, there is no reason why the adaptive model and the conclusions about how local motion adaptation enhances the segregation of foreground objects from their cluttered background in optic flow-based spatial vision should be restricted to flies. Moreover, the model may also be useful for implementing artificial motion vision systems.</p>
</sec>
</sec>
<sec id="sec022">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005919.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005919.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Characterization of Borst-Reisenmann-Haag model.</title>
<p>LPTC model response (based on reimplementation of model suggested in [<xref ref-type="bibr" rid="pcbi.1005919.ref046">46</xref>]) to (A) transient sine-wave grating before and after motion adaptation with sine-wave grating motion in preferred direction and (B) constant motion of sine-wave grating interspersed with eight transient velocity increments (as in <xref ref-type="fig" rid="pcbi.1005919.g002">Fig 2A</xref>). See Figure 4 in [<xref ref-type="bibr" rid="pcbi.1005919.ref029">29</xref>] and Figure 1 in [<xref ref-type="bibr" rid="pcbi.1005919.ref027">27</xref>] for corresponding electrophysiological data.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005919.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005919.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Temporal frequency tunning of the LPTC model.</title>
<p>Temporal frequency tunning without (A) and with (B) motion adaptation (see <xref ref-type="fig" rid="pcbi.1005919.g001">Fig 1</xref>). There is no substantial shift in the velocity tuning with additional modeling of motion adaptation.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Olivier Bertrand for inspiring discussions and introduction to the toolbox, Roland Kern for critically reading the manuscript, and Patricia Möller-Reusch for language editing.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005919.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Koenderink</surname> <given-names>JJ</given-names></name>. <article-title>Optic flow</article-title>. <source>Vision Research</source>. <year>1986</year>;<volume>26</volume>(<issue>1</issue>):<fpage>161</fpage>–<lpage>179</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0042-6989(86)90078-7" xlink:type="simple">10.1016/0042-6989(86)90078-7</ext-link></comment> <object-id pub-id-type="pmid">3716209</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van Hateren</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Schilstra</surname> <given-names>C</given-names></name>. <article-title>Blowfly flight and optic flow. II. Head movements during flight</article-title>. <source>Journal of Experimental Biology</source>. <year>1999</year>;<volume>202</volume>(<issue>11</issue>):<fpage>1491</fpage>–<lpage>1500</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005919.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schilstra</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>van Hateren</surname> <given-names>JH</given-names></name>. <article-title>Blowfly flight and optic flow. I. Thorax kinematics and flight dynamics</article-title>. <source>The Journal of Experimental Biology</source>. <year>1999</year>;<volume>202</volume>:<fpage>1481</fpage>–<lpage>1490</lpage>. <object-id pub-id-type="pmid">10229694</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Boeddeker</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dittmar</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Stürzl</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>The fine structure of honeybee head and body yaw movements in a homing task</article-title>. <source>Proceedings of the Royal Society of London B: Biological Sciences</source>. <year>2010</year>;<volume>277</volume>(<issue>1689</issue>):<fpage>1899</fpage>–<lpage>1906</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rspb.2009.2326" xlink:type="simple">10.1098/rspb.2009.2326</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Boeddeker</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Kern</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kurtz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Lindemann</surname> <given-names>JP</given-names></name>. <article-title>Spatial vision in insects is facilitated by shaping the dynamics of visual input through behavioral action</article-title>. <source>Frontiers in Neural Circuits</source>. <year>2012</year>;<volume>6</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncir.2012.00108" xlink:type="simple">10.3389/fncir.2012.00108</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kern</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Lindemann</surname> <given-names>JP</given-names></name>. <article-title>Motion as a source of environmental information: a fresh view on biological motion computation by insect brains</article-title>. <source>Frontiers in Neural Circuits</source>. <year>2014</year>;<volume>8</volume>(<issue>127</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncir.2014.00127" xlink:type="simple">10.3389/fncir.2014.00127</ext-link></comment> <object-id pub-id-type="pmid">25389392</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Haag</surname> <given-names>J</given-names></name>. <article-title>Neural networks in the cockpit of the fly</article-title>. <source>Journal of Comparative Physiology A: Neuroethology, Sensory, Neural, and Behavioral Physiology</source>. <year>2002</year>;<volume>188</volume>(<issue>6</issue>):<fpage>419</fpage>–<lpage>437</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00359-002-0316-8" xlink:type="simple">10.1007/s00359-002-0316-8</ext-link></comment> <object-id pub-id-type="pmid">12122462</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hassenstein</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Reichardt</surname> <given-names>W</given-names></name>. <article-title>Systemtheoretische Analyse der Zeit-, Reihenfolgen- und Vorzeichenauswertung bei der Bewegungsperzeption des Rüsselkäfers Chlorophanus</article-title>. <source>Zeitschrift für Naturforschung B</source>. <year>1956</year>;<volume>11</volume>(<issue>9-10</issue>).</mixed-citation>
</ref>
<ref id="pcbi.1005919.ref009">
<label>9</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>. <chapter-title>Movement detection in arthropods</chapter-title>. In: <name name-style="western"><surname>Miles</surname> <given-names>FA</given-names></name>, <name name-style="western"><surname>Wallman</surname> <given-names>J</given-names></name>, editors. <source>Visual motion and its role in the stabilization of gaze</source>. <publisher-loc>Amsterdam</publisher-loc>: <publisher-name>Elsevier</publisher-name>; <year>1993</year>. p. <fpage>53</fpage>–<lpage>77</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005919.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Haag</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Arenz</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Serbe</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Gabbiani</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>. <article-title>Complementary mechanisms create direction selectivity in the fly</article-title>. <source>Elife</source>. <year>2016</year>;<volume>5</volume>:<fpage>e17421</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.17421" xlink:type="simple">10.7554/eLife.17421</ext-link></comment> <object-id pub-id-type="pmid">27502554</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref011">
<label>11</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <chapter-title>The neural computation of visual motion information</chapter-title>. In: <name name-style="western"><surname>Warrant</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Nilsson</surname> <given-names>DE</given-names></name>, editors. <source>Invertebrate vision</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>2006</year>. p. <fpage>399</fpage>–<lpage>461</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005919.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Reiff</surname> <given-names>DF</given-names></name>, <name name-style="western"><surname>Plett</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Mank</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Griesbeck</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>. <article-title>Visualizing retinotopic half-wave rectified input to the motion detection circuitry of Drosophila</article-title>. <source>Nature Neuroscience</source>. <year>2010</year>;<volume>13</volume>(<issue>8</issue>):<fpage>973</fpage>–<lpage>978</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2595" xlink:type="simple">10.1038/nn.2595</ext-link></comment> <object-id pub-id-type="pmid">20622873</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Clark</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Bursztyn</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Horowitz</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Schnitzer</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Clandinin</surname> <given-names>TR</given-names></name>. <article-title>Defining the computational structure of the motion detector in Drosophila</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>70</volume>(<issue>6</issue>):<fpage>1165</fpage>–<lpage>1177</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2011.05.023" xlink:type="simple">10.1016/j.neuron.2011.05.023</ext-link></comment> <object-id pub-id-type="pmid">21689602</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Behnia</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Clark</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Carter</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Clandinin</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Desplan</surname> <given-names>C</given-names></name>. <article-title>Processing properties of ON and OFF pathways for Drosophila motion detection</article-title>. <source>Nature</source>. <year>2014</year>;<volume>512</volume>(<issue>7515</issue>):<fpage>427</fpage>–<lpage>430</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature13427" xlink:type="simple">10.1038/nature13427</ext-link></comment> <object-id pub-id-type="pmid">25043016</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mauss</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Meier</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Serbe</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>. <article-title>Optogenetic and pharmacologic dissection of feedforward inhibition in Drosophila motion vision</article-title>. <source>Journal of Neuroscience</source>. <year>2014</year>;<volume>34</volume>(<issue>6</issue>):<fpage>2254</fpage>–<lpage>2263</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3938-13.2014" xlink:type="simple">10.1523/JNEUROSCI.3938-13.2014</ext-link></comment> <object-id pub-id-type="pmid">24501364</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tuthill</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Borghuis</surname> <given-names>BG</given-names></name>. <article-title>Four to Foxtrot: How Visual Motion Is Computed in the Fly Brain</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>89</volume>(<issue>4</issue>):<fpage>677</fpage>–<lpage>680</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2016.02.006" xlink:type="simple">10.1016/j.neuron.2016.02.006</ext-link></comment> <object-id pub-id-type="pmid">26889807</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ammer</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Leonhardt</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bahl</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Dickson</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>. <article-title>Functional specialization of neural input elements to the Drosophila ON motion detector</article-title>. <source>Current Biology</source>. <year>2015</year>;<volume>25</volume>(<issue>17</issue>):<fpage>2247</fpage>–<lpage>2253</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2015.07.014" xlink:type="simple">10.1016/j.cub.2015.07.014</ext-link></comment> <object-id pub-id-type="pmid">26234212</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fisher</surname> <given-names>YE</given-names></name>, <name name-style="western"><surname>Silies</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Clandinin</surname> <given-names>TR</given-names></name>. <article-title>Orientation selectivity sharpens motion detection in Drosophila</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>88</volume>(<issue>2</issue>):<fpage>390</fpage>–<lpage>402</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.09.033" xlink:type="simple">10.1016/j.neuron.2015.09.033</ext-link></comment> <object-id pub-id-type="pmid">26456048</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Arenz</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Drews</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Richter</surname> <given-names>FG</given-names></name>, <name name-style="western"><surname>Ammer</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>. <article-title>The temporal tuning of the Drosophila motion detectors is determined by the dynamics of their input elements</article-title>. <source>Current Biology</source>. <year>2017</year>;<volume>27</volume>(<issue>7</issue>):<fpage>929</fpage>–<lpage>944</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2017.01.051" xlink:type="simple">10.1016/j.cub.2017.01.051</ext-link></comment> <object-id pub-id-type="pmid">28343964</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Haag</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Mishra</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>. <article-title>A common directional tuning mechanism of Drosophila motion-sensing neurons in the ON and in the OFF pathway</article-title>. <source>eLife</source>. <year>2017</year>;<volume>6</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.29044" xlink:type="simple">10.7554/eLife.29044</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schwegmann</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Lindemann</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Depth information in natural environments derived from optic flow by insect motion detection system: a model analysis</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2014</year>;<volume>8</volume>(<issue>83</issue>):<fpage>83</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncom.2014.00083" xlink:type="simple">10.3389/fncom.2014.00083</ext-link></comment> <object-id pub-id-type="pmid">25136314</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Li</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Lindemann</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Peripheral processing facilitates optic flow-based depth perception</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2016</year>;<volume>10</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncom.2016.00111" xlink:type="simple">10.3389/fncom.2016.00111</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Laughlin</surname> <given-names>SB</given-names></name>. <article-title>A simple coding procedure enhances a neuron’s information capacity</article-title>. <source>Zeitschrift für Naturforschung C</source>. <year>1981</year>;<volume>36</volume>(<issue>9-10</issue>):<fpage>910</fpage>–<lpage>912</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005919.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brenner</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>de Ruyter van Steveninck</surname> <given-names>R</given-names></name>. <article-title>Adaptive rescaling maximizes information transmission</article-title>. <source>Neuron</source>. <year>2000</year>;<volume>26</volume>(<issue>3</issue>):<fpage>695</fpage>–<lpage>702</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0896-6273(00)81205-2" xlink:type="simple">10.1016/S0896-6273(00)81205-2</ext-link></comment> <object-id pub-id-type="pmid">10896164</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rasumov</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Baker</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Niven</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Laughlin</surname> <given-names>SB</given-names></name>. <article-title>Adaptation reduces sensitivity to save energy without information loss in the fly visual system</article-title>. <source>Proceedings of The Physiological Society</source>. <year>2011</year>;Proc Physiol Soc <volume>22</volume>.</mixed-citation>
</ref>
<ref id="pcbi.1005919.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Maddess</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Laughlin</surname> <given-names>SB</given-names></name>. <article-title>Adaptation of the Motion-Sensitive Neuron H1 is Generated Locally and Governed by Contrast Frequency</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>1985</year>;<volume>225</volume>:<fpage>251</fpage>–<lpage>275</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005919.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kurtz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Meyer</surname> <given-names>HG</given-names></name>, <name name-style="western"><surname>Kern</surname> <given-names>R</given-names></name>. <article-title>Adaptation accentuates responses of fly motion-sensitive visual neurons to sudden stimulus changes</article-title>. <source>Proceedings of the Royal Society of London B: Biological Sciences</source>. <year>2009</year>;<volume>276</volume>(<issue>1673</issue>):<fpage>3711</fpage>–<lpage>3719</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rspb.2009.0596" xlink:type="simple">10.1098/rspb.2009.0596</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Harris</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>O’Carroll</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Laughlin</surname> <given-names>SB</given-names></name>. <article-title>Contrast gain reduction in fly motion adaptation</article-title>. <source>Neuron</source>. <year>2000</year>;<volume>28</volume>(<issue>2</issue>):<fpage>595</fpage>–<lpage>606</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0896-6273(00)00136-7" xlink:type="simple">10.1016/S0896-6273(00)00136-7</ext-link></comment> <object-id pub-id-type="pmid">11144367</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Reisenman</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Haag</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>. <article-title>Adaptation of response transients in fly motion vision. I: Experiments</article-title>. <source>Vision Research</source>. <year>2003</year>;<volume>43</volume>(<issue>11</issue>):<fpage>1293</fpage>–<lpage>1309</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0042-6989(03)00091-9" xlink:type="simple">10.1016/S0042-6989(03)00091-9</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liang</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Kern</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Motion adaptation enhances object-induced neural activity in three-dimensional virtual environment</article-title>. <source>Journal of Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>44</issue>):<fpage>11328</fpage>–<lpage>11332</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0203-08.2008" xlink:type="simple">10.1523/JNEUROSCI.0203-08.2008</ext-link></comment> <object-id pub-id-type="pmid">18971474</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liang</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Kern</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kurtz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Impact of visual motion adaptation on neural responses to objects and its dependence on the temporal characteristics of optic flow</article-title>. <source>Journal of Neurophysiology</source>. <year>2011</year>;<volume>105</volume>(<issue>4</issue>):<fpage>1825</fpage>–<lpage>1834</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00359.2010" xlink:type="simple">10.1152/jn.00359.2010</ext-link></comment> <object-id pub-id-type="pmid">21307322</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liang</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Heitwerth</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kern</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kurtz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Object representation and distance encoding in three-dimensional environments by a neural circuit in the visual system of the blowfly</article-title>. <source>Journal of Neurophysiology</source>. <year>2012</year>;<volume>107</volume>(<issue>12</issue>):<fpage>3446</fpage>–<lpage>3457</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00530.2011" xlink:type="simple">10.1152/jn.00530.2011</ext-link></comment> <object-id pub-id-type="pmid">22423002</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Eichner</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Joesch</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schnell</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Reiff</surname> <given-names>DF</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>. <article-title>Internal structure of the fly elementary motion detector</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>70</volume>(<issue>6</issue>):<fpage>1155</fpage>–<lpage>1164</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2011.03.028" xlink:type="simple">10.1016/j.neuron.2011.03.028</ext-link></comment> <object-id pub-id-type="pmid">21689601</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Riehle</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Franceschini</surname> <given-names>N</given-names></name>. <article-title>Motion detection in flies: parametric control over ON-OFF pathways</article-title>. <source>Experimental brain research</source>. <year>1984</year>;<volume>54</volume>(<issue>2</issue>):<fpage>390</fpage>–<lpage>394</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00236243" xlink:type="simple">10.1007/BF00236243</ext-link></comment> <object-id pub-id-type="pmid">6723860</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Helmstaedter</surname> <given-names>M</given-names></name>. <article-title>Common circuit design in fly and mammalian motion vision</article-title>. <source>Nature Neuroscience</source>. <year>2015</year>;<volume>18</volume>(<issue>8</issue>):<fpage>1067</fpage>–<lpage>1076</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4050" xlink:type="simple">10.1038/nn.4050</ext-link></comment> <object-id pub-id-type="pmid">26120965</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Haag</surname> <given-names>J</given-names></name>. <article-title>Mechanisms of dendritic integration underlying gain control in fly motion-sensitive interneurons</article-title>. <source>Journal of Computational Neuroscience</source>. <year>1995</year>;<volume>2</volume>(<issue>1</issue>):<fpage>5</fpage>–<lpage>18</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00962705" xlink:type="simple">10.1007/BF00962705</ext-link></comment> <object-id pub-id-type="pmid">8521280</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lindemann</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Kern</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Van Hateren</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ritter</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>On the computations analyzing natural optic flow: quantitative model analysis of the blowfly motion vision pathway</article-title>. <source>Journal of Neuroscience</source>. <year>2005</year>;<volume>25</volume>(<issue>27</issue>):<fpage>6435</fpage>–<lpage>6448</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1132-05.2005" xlink:type="simple">10.1523/JNEUROSCI.1132-05.2005</ext-link></comment> <object-id pub-id-type="pmid">16000634</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lindemann</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Weiss</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Möller</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Saccadic flight strategy facilitates collision avoidance: closed-loop performance of a cyberfly</article-title>. <source>Biological Cybernetics</source>. <year>2008</year>;<volume>98</volume>(<issue>3</issue>):<fpage>213</fpage>–<lpage>227</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00422-007-0205-x" xlink:type="simple">10.1007/s00422-007-0205-x</ext-link></comment> <object-id pub-id-type="pmid">18180948</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref039">
<label>39</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Schwegmann</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Lindemann</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <source>Translational sequences of panoramic high dynamic range images in natural environments</source>; <year>2014</year>. <publisher-name>Bielefeld University Open Data Publication</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1005919.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kurtz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Beckers</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Hundsdörfer</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Mechanisms of after-hyperpolarization following activation of fly visual motion-sensitive neurons</article-title>. <source>European Journal of Neuroscience</source>. <year>2009</year>;<volume>30</volume>(<issue>4</issue>):<fpage>567</fpage>–<lpage>577</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1460-9568.2009.06854.x" xlink:type="simple">10.1111/j.1460-9568.2009.06854.x</ext-link></comment> <object-id pub-id-type="pmid">19674090</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kim</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Fitzgerald</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Maimon</surname> <given-names>G</given-names></name>. <article-title>Cellular evidence for efference copy in Drosophila visuomotor processing</article-title>. <source>Nature neuroscience</source>. <year>2015</year>;<volume>18</volume>(<issue>9</issue>):<fpage>1247</fpage>–<lpage>1255</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4083" xlink:type="simple">10.1038/nn.4083</ext-link></comment> <object-id pub-id-type="pmid">26237362</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kim</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Fenk</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Lyu</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Maimon</surname> <given-names>G</given-names></name>. <article-title>Quantitative predictions orchestrate visual signaling in Drosophila</article-title>. <source>Cell</source>. <year>2017</year>;<volume>168</volume>(<issue>1</issue>):<fpage>280</fpage>–<lpage>294</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cell.2016.12.005" xlink:type="simple">10.1016/j.cell.2016.12.005</ext-link></comment> <object-id pub-id-type="pmid">28065412</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>De Ruyter van Steveninck</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Zaagman</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Mastebroek</surname> <given-names>HA</given-names></name>. <article-title>Adaptation of transient responses of a movement-sensitive neuron in the visual system of the blowfly Calliphora erythrocephala</article-title>. <source>Biological Cybernetics</source>. <year>1986</year>;<volume>54</volume>(<issue>4</issue>):<fpage>223</fpage>–<lpage>236</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00318418" xlink:type="simple">10.1007/BF00318418</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Temporal modulation of luminance adapts time constant of fly movement detectors</article-title>. <source>Biological Cybernetics</source>. <year>1987</year>;<volume>56</volume>(<issue>4</issue>):<fpage>209</fpage>–<lpage>215</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00365215" xlink:type="simple">10.1007/BF00365215</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Clifford</surname> <given-names>CW</given-names></name>, <name name-style="western"><surname>Ibbotson</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Langley</surname> <given-names>K</given-names></name>. <article-title>An adaptive Reichardt detector model of motion adaptation in insects and mammals</article-title>. <source>Visual Neuroscience</source>. <year>1997</year>;<volume>14</volume>(<issue>04</issue>):<fpage>741</fpage>–<lpage>749</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1017/S0952523800012694" xlink:type="simple">10.1017/S0952523800012694</ext-link></comment> <object-id pub-id-type="pmid">9279002</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Reisenman</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Haag</surname> <given-names>J</given-names></name>. <article-title>Adaptation of response transients in fly motion vision. II: Model studies</article-title>. <source>Vision Research</source>. <year>2003</year>;<volume>43</volume>(<issue>11</issue>):<fpage>1311</fpage>–<lpage>1324</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0042-6989(03)00092-0" xlink:type="simple">10.1016/S0042-6989(03)00092-0</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref047">
<label>47</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Li</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Lindemann</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <source>Motion adaptation facilitates optic flow-based spatial vision</source>; <year>2017</year>. <publisher-name>Bielefeld University Open Data Publication</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1005919.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Attneave</surname> <given-names>F</given-names></name>. <article-title>Some informational aspects of visual perception</article-title>. <source>Psychological Review</source>. <year>1954</year>;<volume>61</volume>(<issue>3</issue>):<fpage>183</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005919.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wark</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Lundstrom</surname> <given-names>BN</given-names></name>, <name name-style="western"><surname>Fairhall</surname> <given-names>A</given-names></name>. <article-title>Sensory adaptation</article-title>. <source>Current Opinion in Neurobiology</source>. <year>2007</year>;<volume>17</volume>(<issue>4</issue>):<fpage>423</fpage>–<lpage>429</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2007.07.001" xlink:type="simple">10.1016/j.conb.2007.07.001</ext-link></comment> <object-id pub-id-type="pmid">17714934</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kohn</surname> <given-names>A</given-names></name>. <article-title>Visual adaptation: physiology, mechanisms, and functional benefits</article-title>. <source>Journal of Neurophysiology</source>. <year>2007</year>;<volume>97</volume>(<issue>5</issue>):<fpage>3155</fpage>–<lpage>3164</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00086.2007" xlink:type="simple">10.1152/jn.00086.2007</ext-link></comment> <object-id pub-id-type="pmid">17344377</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ulanovsky</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Las</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Nelken</surname> <given-names>I</given-names></name>. <article-title>Processing of low-probability sounds by cortical neurons</article-title>. <source>Nature Neuroscience</source>. <year>2003</year>;<volume>6</volume>(<issue>4</issue>):<fpage>391</fpage>–<lpage>398</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1032" xlink:type="simple">10.1038/nn1032</ext-link></comment> <object-id pub-id-type="pmid">12652303</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Laughlin</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Hardie</surname> <given-names>RC</given-names></name>. <article-title>Common strategies for light adaptation in the peripheral visual systems of fly and dragonfly</article-title>. <source>Journal of Comparative Physiology</source>. <year>1978</year>;<volume>128</volume>(<issue>4</issue>):<fpage>319</fpage>–<lpage>340</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00657606" xlink:type="simple">10.1007/BF00657606</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Juusola</surname> <given-names>M</given-names></name>. <article-title>Transfer of graded potentials at the photoreceptor-interneuron synapse</article-title>. <source>The Journal of General Physiology</source>. <year>1995</year>;<volume>105</volume>(<issue>1</issue>):<fpage>117</fpage>–<lpage>148</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1085/jgp.105.1.117" xlink:type="simple">10.1085/jgp.105.1.117</ext-link></comment> <object-id pub-id-type="pmid">7537323</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Neri</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Laughlin</surname> <given-names>SB</given-names></name>. <article-title>Global versus local adaptation in fly motion-sensitive neurons</article-title>. <source>Proceedings of the Royal Society of London B: Biological Sciences</source>. <year>2005</year>;<volume>272</volume>(<issue>1578</issue>):<fpage>2243</fpage>–<lpage>2249</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rspb.2005.3191" xlink:type="simple">10.1098/rspb.2005.3191</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Heitwerth</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kern</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Van Hateren</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Motion adaptation leads to parsimonious encoding of natural optic flow by blowfly motion vision system</article-title>. <source>Journal of Neurophysiology</source>. <year>2005</year>;<volume>94</volume>(<issue>3</issue>):<fpage>1761</fpage>–<lpage>1769</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00308.2005" xlink:type="simple">10.1152/jn.00308.2005</ext-link></comment> <object-id pub-id-type="pmid">15917319</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dittmar</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Stürzl</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Baird</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Boeddeker</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Goal seeking in honeybees: matching of optic flow snapshots?</article-title> <source>Journal of Experimental Biology</source>. <year>2010</year>;<volume>213</volume>(<issue>17</issue>):<fpage>2913</fpage>–<lpage>2923</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1242/jeb.043737" xlink:type="simple">10.1242/jeb.043737</ext-link></comment> <object-id pub-id-type="pmid">20709919</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kern</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Boeddeker</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dittmar</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Blowfly flight characteristics are shaped by environmental features and controlled by optic flow information</article-title>. <source>Journal of Experimental Biology</source>. <year>2012</year>;<volume>215</volume>(<issue>14</issue>):<fpage>2501</fpage>–<lpage>2514</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1242/jeb.061713" xlink:type="simple">10.1242/jeb.061713</ext-link></comment> <object-id pub-id-type="pmid">22723490</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bertrand</surname> <given-names>OJ</given-names></name>, <name name-style="western"><surname>Lindemann</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>A bio-inspired collision avoidance model based on spatial information derived from motion detectors leads to common routes</article-title>. <source>PLoS computational biology</source>. <year>2015</year>;<volume>11</volume>(<issue>11</issue>):<fpage>e1004339</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004339" xlink:type="simple">10.1371/journal.pcbi.1004339</ext-link></comment> <object-id pub-id-type="pmid">26583771</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>. <article-title>Fly visual course control: behaviour, algorithms and circuits</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2014</year>;<volume>15</volume>(<issue>9</issue>):<fpage>590</fpage>–<lpage>599</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn3799" xlink:type="simple">10.1038/nrn3799</ext-link></comment> <object-id pub-id-type="pmid">25116140</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tammero</surname> <given-names>LF</given-names></name>, <name name-style="western"><surname>Dickinson</surname> <given-names>MH</given-names></name>. <article-title>The influence of visual landscape on the free flight behavior of the fruit fly Drosophila melanogaster</article-title>. <source>Journal of Experimental Biology</source>. <year>2002</year>;<volume>205</volume>(<issue>3</issue>):<fpage>327</fpage>–<lpage>343</lpage>. <object-id pub-id-type="pmid">11854370</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kress</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Egelhaaf</surname> <given-names>M</given-names></name>. <article-title>Gaze characteristics of freely walking blowflies Calliphora vicina in a goal-directed task</article-title>. <source>Journal of Experimental Biology</source>. <year>2014</year>;<volume>217</volume>(<issue>18</issue>):<fpage>3209</fpage>–<lpage>3220</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1242/jeb.097436" xlink:type="simple">10.1242/jeb.097436</ext-link></comment> <object-id pub-id-type="pmid">25013104</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref062">
<label>62</label>
<mixed-citation publication-type="other" xlink:type="simple">Baird E, Srinivasan MV, Zhang S, Lamont R, Cowling A. Visual control of flight speed and height in the honeybee. In: International Conference on Simulation of Adaptive Behavior. Springer; 2006. p. 40–51.</mixed-citation>
</ref>
<ref id="pcbi.1005919.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Srinivasan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lehrer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Collett</surname> <given-names>T</given-names></name>. <article-title>Honeybee navigation en route to the goal: visual flight control and odometry</article-title>. <source>Journal of Experimental Biology</source>. <year>1996</year>;<volume>199</volume>(<issue>1</issue>):<fpage>237</fpage>–<lpage>244</lpage>. <object-id pub-id-type="pmid">9317712</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005919.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wolf</surname> <given-names>H</given-names></name>. <article-title>Odometry and insect navigation</article-title>. <source>Journal of Experimental Biology</source>. <year>2011</year>;<volume>214</volume>(<issue>10</issue>):<fpage>1629</fpage>–<lpage>1641</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1242/jeb.038570" xlink:type="simple">10.1242/jeb.038570</ext-link></comment> <object-id pub-id-type="pmid">21525309</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
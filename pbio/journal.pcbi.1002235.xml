<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PCOMPBIOL-D-11-00287</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002235</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Computational biology</subject>
          </subj-group>
          <subj-group>
            <subject>Neuroscience</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computational Biology</subject>
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Grid Cells, Place Cells, and Geodesic Generalization for Spatial Reinforcement Learning</article-title><alt-title alt-title-type="running-head">Grid Cells, Place Cells, &amp; Reinforcement Learning</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Gustafson</surname>
            <given-names>Nicholas J.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Daw</surname>
            <given-names>Nathaniel D.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Center for Neural Science, New York University, New York, New York, United States of America</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Department of Psychology, New York University, New York, New York, United States of America</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Kording</surname>
            <given-names>Konrad P.</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Northwestern University, United States of America</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">njg245@nyu.edu</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: NJG NDD. Performed the experiments: NJG. Analyzed the data: NJG. Contributed reagents/materials/analysis tools: NJG NDD. Wrote the paper: NJG NDD.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>10</month>
        <year>2011</year>
      </pub-date><pub-date pub-type="epub">
        <day>27</day>
        <month>10</month>
        <year>2011</year>
      </pub-date><volume>7</volume><issue>10</issue><elocation-id>e1002235</elocation-id><history>
        <date date-type="received">
          <day>2</day>
          <month>3</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>2</day>
          <month>9</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Gustafson, Daw</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Reinforcement learning (RL) provides an influential characterization of the brain's mechanisms for learning to make advantageous choices. An important problem, though, is how complex tasks can be represented in a way that enables efficient learning. We consider this problem through the lens of spatial navigation, examining how two of the brain's location representations—hippocampal place cells and entorhinal grid cells—are adapted to serve as basis functions for approximating value over space for RL. Although much previous work has focused on these systems' roles in combining upstream sensory cues to track location, revisiting these representations with a focus on how they support this downstream decision function offers complementary insights into their characteristics. Rather than localization, the key problem in learning is generalization between past and present situations, which may not match perfectly. Accordingly, although neural populations collectively offer a precise representation of position, our simulations of navigational tasks verify the suggestion that RL gains efficiency from the more diffuse tuning of individual neurons, which allows learning about rewards to generalize over longer distances given fewer training experiences. However, work on generalization in RL suggests the underlying representation should respect the environment's layout. In particular, although it is often assumed that neurons track location in Euclidean coordinates (that a place cell's activity declines “as the crow flies” away from its peak), the relevant metric for value is geodesic: the distance along a path, around any obstacles. We formalize this intuition and present simulations showing how Euclidean, but not geodesic, representations can interfere with RL by generalizing inappropriately across barriers. Our proposal that place and grid responses should be modulated by geodesic distances suggests novel predictions about how obstacles should affect spatial firing fields, which provides a new viewpoint on data concerning both spatial codes.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>The central problem of learning is <italic>generalization</italic>: how to apply what was discovered in past experiences to future situations, which will inevitably be the same in some respects and different in others. Effective learning requires generalizing <italic>appropriately</italic>: to situations which are similar in relevant respects, though of course the trick is determining what is relevant. In this article, we quantify and investigate relevant generalization in the context of a particular learning problem often studied in the laboratory: learning to navigate in a spatial maze. In particular, we consider whether the brain's well-characterized systems for representing an organism's location in space generalize appropriately for this task. Our simulations of learning verify that to generalize effectively, these representations should treat nearby locations similarly (that is, neurons should fire similarly when an animal occupies nearby locations)—but, more subtly, that to enable successful learning, “nearby” must be defined in terms of paths around obstacles, rather than in absolute space “as the crow flies.” These considerations suggest new principles for understanding these spatial representations and why they appear warped and distorted in environments, such as mazes, with barriers and obstacles.</p>
      </abstract><funding-group><funding-statement>This research was supported by a McKnight Foundation Scholar Award, Human Frontiers Science Program grant RGP0036/2009-C, and US National Institutes of Health (NIH) grant MH087882, part of the CRCNS program. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="14"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>The rodent brain contains at least two representations of spatial location. Hippocampal place cells fire when a rat passes through a confined, roughly concentric, region of space <xref ref-type="bibr" rid="pcbi.1002235-OKeefe1">[1]</xref>, whereas the grid cells of dorsomedial enthorhinal cortex (dMEC) discharge at the vertices of regular triangular lattices <xref ref-type="bibr" rid="pcbi.1002235-Hafting1">[2]</xref>. Behaviorally, such codes likely support decisions about spatial navigation <xref ref-type="bibr" rid="pcbi.1002235-Foster1">[3]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Redish2">[7]</xref>, and more particularly reinforcement learning (RL <xref ref-type="bibr" rid="pcbi.1002235-Sutton1">[8]</xref>) or learning by trial and error where to navigate.</p>
      <p>Here we investigate the appropriateness of the brain's spatial codes for learning value functions, guided by the influential use of RL models across many varieties of decision problems in computational neuroscience <xref ref-type="bibr" rid="pcbi.1002235-Houk1">[9]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Doya1">[11]</xref>. Although much work in these systems tends to focus on the “upstream” mechanisms by which place or grid fields are constructed from different sorts of inputs, we focus instead on learning downstream from these representations (e.g., where place cells synapse on striatal neurons), to ask what does this function suggest about or require from the spatial representations. This provides a complementary perspective on aspects of the neural responses, which, we argue, are well adapted to support reinforcement learning.</p>
      <p>Importantly, this exercise views the brain's spatial codes less as a representation for location per se, and instead as basis sets for approximating other functions across space. In particular, most RL models work by learning to represent a <italic>value function</italic> over state space – a mapping of location to value. The value function measures the proximity of locations to rewards, and in this way can guide navigation towards reinforcement. Although a frequency-domain Fourier basis (often analogized to the grid representation <xref ref-type="bibr" rid="pcbi.1002235-Blair1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Solstad1">[13]</xref>) and a space-domain impulse basis (an idealized place map) are both complete representations for arbitrary functions over space, efficient RL—in the sense of rapid generalization from few experiences—depends on the features of the basis being well matched to the function being learned <xref ref-type="bibr" rid="pcbi.1002235-Mahadevan1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Konidaris1">[17]</xref>. For instance, just as efficient visual representations are motivated by the fact that the Fourier decompositions of natural images have most of their power at low frequencies, so also value functions tend to change smoothly across space: if a given location is near reward, then so are nearby positions.</p>
      <p>Thus, it is intuitive (and our simulations, below, verify) that low-frequency basis functions can speed up spatial RL by allowing experience about rewards to generalize over larger distances. However, we argue that considering generalization in the RL setting suggests a crucial and underappreciated refinement of this idea: in general, value functions are <italic>not</italic> maximally smooth over space “as the crow flies” (i.e. Euclidean distance). Instead, value functions exhibit discontinuities at obstacles, such as walls, which help to guide navigation around them. Building on a variety of work applying graph-theoretic distance metrics to different problems in machine learning <xref ref-type="bibr" rid="pcbi.1002235-Mahadevan1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Mahadevan2">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Konidaris1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Tenenbaum1">[18]</xref>, much work in reinforcement learning <xref ref-type="bibr" rid="pcbi.1002235-Mahadevan1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Konidaris1">[17]</xref> suggests that the demand of efficient generalization for navigation implies that basis functions—here, place or grid fields—should modulate their strength according to geodesic distance (i.e. the shortest navigable path between two points, around obstacles) rather than Euclidean.</p>
      <p>We formalize this idea in a model of grid and place cell responses. The model and its simulations suggest novel predictions about how grid cell and place cell firing fields should behave in the presence of obstacles and other navigational constraints: in effect, these should locally warp the geometry of the representation. These predictions offer a new perspective on existing results, such as the unidirectionality of place fields on the linear track <xref ref-type="bibr" rid="pcbi.1002235-Dragoi1">[19]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Muller1">[23]</xref> and the behavior of grid cells in mazes <xref ref-type="bibr" rid="pcbi.1002235-Derdikman1">[24]</xref>.</p>
      <sec id="s1a">
        <title>Background and previous work</title>
        <sec id="s1a1">
          <title>Place cells and grid cells</title>
          <p>Pyramidal neurons in the rat hippocampus have long been known to have firing fields in localized areas of space <xref ref-type="bibr" rid="pcbi.1002235-OKeefe1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Best1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Muller2">[26]</xref>. While much research has studied hippocampal neurons with small place fields <xref ref-type="bibr" rid="pcbi.1002235-Foster1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Blum1">[27]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Gerstner1">[29]</xref> (e.g., roughly the size of a rat) a range of place field scales have been reported <xref ref-type="bibr" rid="pcbi.1002235-Kjelstrup1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Jung1">[31]</xref>. Recently, electrophysiological recordings from a long linear track suggest that place cells in area CA3 are multiscale, with size ranging up to approximately 10 meters at the ventral pole of the hippocampus <xref ref-type="bibr" rid="pcbi.1002235-Kjelstrup1">[30]</xref>. In addition, it has been previously shown that changing environmental geometry can alter the electrophysiological characteristics of place cells <xref ref-type="bibr" rid="pcbi.1002235-OKeefe3">[32]</xref>. The scale of the place fields was topographically organized in a manner parallel to changes in scale of the afferent grid cell input <xref ref-type="bibr" rid="pcbi.1002235-Kjelstrup1">[30]</xref>.</p>
          <p>Grid cell neurons in dorsomedial entorhinal cortex, a principal input to the hippocampus, have firing fields whose hallmark is a regular triangular lattice <xref ref-type="bibr" rid="pcbi.1002235-Hafting1">[2]</xref>. Furthermore, grid cells show a variety of orientations, phases, and scales, with the relative size varying topographically from small to large along the dorsomedial to ventrolateral axis of the entorhinal cortex <xref ref-type="bibr" rid="pcbi.1002235-Hafting1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Brun1">[33]</xref>. Interestingly, the regularity of the firing field lattice can compress or expand under changes in the recording enclosure's aspect ratio <xref ref-type="bibr" rid="pcbi.1002235-Barry1">[34]</xref>, which shows their firing fields are malleable with respect to the environment's configuration, similar to findings with place cells.</p>
        </sec>
        <sec id="s1a2">
          <title>Models of entorhinal grid cell</title>
          <p>The discovery of grid cells spurred a great deal of computational modeling, mostly targeted at understanding their <italic>inputs</italic> and <italic>outputs</italic>. Specifically, much work considers how the characteristic triangular lattice grid cell firing fields arise <xref ref-type="bibr" rid="pcbi.1002235-Blair1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Fuhs1">[35]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Zilli1">[42]</xref> and how they might, in turn, serve as an input representation for producing the spatially localized place fields of hippocampal neurons <xref ref-type="bibr" rid="pcbi.1002235-Blair1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Solstad1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Rolls1">[43]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Molter1">[46]</xref>. Apart from these <italic>representational</italic> questions, the primary <italic>functional</italic> question examined in grid cell modeling concerns how the cells might participate in a circuit for path integration <xref ref-type="bibr" rid="pcbi.1002235-Fuhs1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Fiete1">[37]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Hasselmo3">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-OKeefe4">[47]</xref>. The present work considers a distinct, albeit nonexclusive, role for both grid and place cells as potential basis sets for representing value functions in spatial reinforcement learning. In the case of the grid cells, this draws on the work of several authors <xref ref-type="bibr" rid="pcbi.1002235-Blair1">[e.g. 12]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Solstad1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Moser1">[48]</xref> who note an analogy between the multiscale, oscillating grid cell basis and a sinusoidal Fourier-like basis.</p>
        </sec>
        <sec id="s1a3">
          <title>Models of RL in the brain</title>
          <p>A great deal of modeling work in neuroscience and psychology concerns the brain's mechanisms for RL, founded on the observation that dopaminergic neurons in the primate midbrain appear to carry a reward prediction error signal as used in temporal-difference (TD) RL algorithms <xref ref-type="bibr" rid="pcbi.1002235-Houk1">[9]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Doya1">[11]</xref>. A typical architecture <xref ref-type="bibr" rid="pcbi.1002235-Suri1">[e.g., 49]</xref> presumes that cortical neurons provide sensory or <italic>state</italic> information; striatal neurons learn to map this representation to a <italic>value function</italic> via dopaminergically gated plasticity at the corticostriatal synapse. In such models, the cortical “state” representation provides a linear <italic>basis</italic> for representing the value function: values in striatum are estimated as weighted sums of cortical inputs. In the context of spatial tasks <xref ref-type="bibr" rid="pcbi.1002235-Foster1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Brown1">[50]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Johnson1">[51]</xref>, it is typically assumed that the relevant striatal subregion is the nucleus accumbens, which is involved in locomotion <xref ref-type="bibr" rid="pcbi.1002235-Redish1">[see 4]</xref> and that the state input arises from the hippocampal place code.</p>
          <p>Here, we revisit this architecture, focusing on the role of both the hippocampal and entorhinal spatial codes as bases for building the value function, in order to connect neural observations to work in RL on advantageous representations for value function approximation <xref ref-type="bibr" rid="pcbi.1002235-Mahadevan1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Konidaris1">[17]</xref>. The main questions we investigate concern the generalization properties of spatial basis functions, and specifically how RL performance is affected by the distance metric (Euclidean or geodesic) over space that they embody. To illustrate the generality of these geometric ideas, we simulate our Euclidean and geodesic models under the standard assumption that place cells serve as the spatial representation for downstream value function learning, and also show that the same geometric conclusions hold even when taking the grid cell representation, which have quite differently behaved firing fields, as a direct basis for value learning. The latter hypothesis is clearly more speculative, and would depend on the existence of direct projections from the grid cells to the site of value learning, likely nucleus accumbens, as well as those via hippocampus. Grid cells are most commonly reported in the superficial layers (II–III) of dMEC, which project directly to hippocampus <xref ref-type="bibr" rid="pcbi.1002235-Fyhn1">[52]</xref> though they have also been reported in deep layers <xref ref-type="bibr" rid="pcbi.1002235-Canto1">[53]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Sargolini1">[54]</xref>, where intracortical and subcortical projections originate. Moreover, there is anatomical evidence of projections from entorhinal cortex to nucleus accumbens <xref ref-type="bibr" rid="pcbi.1002235-Canto1">[53]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Finch1">[55]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Totterdell1">[57]</xref>, with some connections possibly originating from areas near those where grid cells are found <xref ref-type="bibr" rid="pcbi.1002235-Totterdell1">[57]</xref>. Finally, lesions in both areas demonstrate an involvement of entorhinal cortex, not mediated via hippocampus, on instrumental (albeit, in this case, not spatial) learning <xref ref-type="bibr" rid="pcbi.1002235-Corbit1">[58]</xref>. Note that our model's geometric predictions about how the grid cell representation should behave do not depend on the idea that it serves as a direct substrate for value learning: since the grid cell representation is thought to serve as a precursor of the place cell representation (though see <xref ref-type="bibr" rid="pcbi.1002235-Langston1">[59]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Wills1">[60]</xref>), it would be likely to share the same geometry (geodesic or Euclidean) with that representation in any case.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Euclidean grid cell and place cell like basis functions</title>
        <p>First, we used TD(λ) learning in three simple environments (<xref ref-type="fig" rid="pcbi-1002235-g001">Figure 1A</xref>) to test the ability of multiscale grid cell- and place cell-like basis sets to learn value functions in spatial RL (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). In order to verify the importance of generalization over long spatial scales, we compared learning with the modeled grid and place cell bases to a standard, tabular RL basis learning the same task. This is like a place cell basis using only a single, fixed scale of representation that is small with respect to the task-relevant distances. The simulated agent had to learn to navigate from a randomly chosen starting point to a goal state that contained a reward. To quantify performance, the number of steps needed to reach the reward was plotted as a function of the training trial. Although our key qualitative points are robust to changes in the free parameters (simulations not shown), to ensure a fair comparison we optimized the learning rate (a crucial free parameter) separately for each condition (i.e. basis function and gridworld) to obtain its best performance. We additionally used the TD(λ) generalization of TD with a high value (0.9) of the eligibility trace parameter λ, since this provides another mechanism for learning to generalize along trajectories and might, in principle, help to compensate for the shortcomings of the tabular or Euclidean bases.</p>
        <fig id="pcbi-1002235-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002235.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Euclidean spatial generalization benefits learning in simple navigation tasks.</title>
            <p>(A) Each column displays the gridworld configuration whereby individual squares are discrete states, thick black lines are walls, and the star indicates the goal state with reward of 1. (B) Each column shows performance measured as the mean number of steps to goal over 10,000 runs for the environment in the corresponding column in A. The width of each line occupies at least the 95% confidence intervals on the means (range 3.9–4.4 steps). Within a given gridworld the different colored lines represent different basis sets with black for tabular, blue for grid cells, and red for place cells.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.g001" xlink:type="simple"/>
        </fig>
        <p>As <xref ref-type="fig" rid="pcbi-1002235-g001">Figure 1B</xref> shows, the grid and place cell basis sets drastically quicken learning the value function compared to the tabular code, demonstrating the benefits of spatial generalization. <xref ref-type="fig" rid="pcbi-1002235-g002">Figure 2</xref> illustrates the approximated value functions at different stages of learning and qualitatively shows the importance of generalization. In particular, the tabular basis does not take advantage of the spatial structure to generalize quickly and must learn each state's value separately from its neighbors by a slow process of TD chaining.</p>
        <fig id="pcbi-1002235-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002235.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Qualitative comparison of learned value functions using tabular, Euclidean grid cell, and Euclidean place cell bases.</title>
            <p>In each figure A–C, the column titles indicate the representation used to learn the value functions for a given gridworld configuration, and each row corresponds to an environment. White lines are walls, discrete squares indicate states, and the gray scale from dark to light indicates low to high value, respectively. To ease comparison between spatial representations within a given gridworld, the image brightness was normalized with respect to the optimal value function. (A) Snapshot of value representation after 15 learning trials. (B) Snapshot of value representation after 25 learning trials. (C) Snapshot of value representation after 50 learning trials. Notice that for both grid cells and place cells, the value representation bleeds across walls, indicated by red arrows where the estimated value is too low (relative to ground truth) on the side of a wall nearer a reward or too high on the far side.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.g002" xlink:type="simple"/>
        </fig>
        <p><xref ref-type="fig" rid="pcbi-1002235-g002">Figure 2</xref> also hints at a subtler problem of overgeneralization in Euclidean space. In particular, these grid and place cell basis functions tend to smear the value function across barriers, where it should change sharply (arrows in <xref ref-type="fig" rid="pcbi-1002235-g002">Figures 2B and 2C</xref>, where the effects are most apparent). Because of this, value is underrepresented at states inside the walls (i.e. locations closer to the reward, as in 2B) and overrepresented on the other side of the barrier (most visible in 2C). This distortion remains at asymptote and is likely not an artifact of insufficient experience.</p>
        <p>While this flaw does not notably degrade performance in these simple tasks, it can be detrimental when fine navigational precision is required. To demonstrate this, we tested the models in three environments that required the agent to navigate narrow halls or openings, and thus learn precise state value representations (<xref ref-type="fig" rid="pcbi-1002235-g003">Figure 3A</xref>). Here, the grid cell and place cell basis functions performed poorly, and were outperformed by the tabular basis (<xref ref-type="fig" rid="pcbi-1002235-g003">Figure 3B</xref>). Together, then, these simulations demonstrate that generalization due to spatial representations like those seen in the brain can help make reinforcement learning more efficient, but also that such generalization has drastic (and, presumably, behaviorally unrealistic) side effects, abolishing learning in tasks where paths are narrow.</p>
        <fig id="pcbi-1002235-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002235.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Geodesic representation required for learning when value function has sharp discontinuities in Euclidean space.</title>
            <p>(A) Each column displays the gridworld configuration whereby individual squares are discrete states, thick black lines are walls, and the star indicates the goal state with reward of 1. (B) Each column shows performance measured as the mean number of steps to goal, over 10,000 runs for the environment in the corresponding column in A. The width of each line occupies at least the 95% confidence interval on the means (range 3.2–4.5 steps). Notice that the collapse of learning, present in the Euclidean grid cells (labeled <italic>euc</italic>) and place cells (blue and red), is recovered by their geodesic counterparts (labeled <italic>geo</italic>, yellow and green, respectively).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.g003" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2b">
        <title>Geodesic grid cell and place cell like basis functions</title>
        <p>In general, as can be seen directly in the recursive definition of the value function, (Equation 1 in <xref ref-type="sec" rid="s4">Materials and Methods</xref>), the extent to which values are related between two states depends on how closely they are connected by the state-state transition probability function. Accordingly, work on value function approximation for reinforcement learning has proposed <xref ref-type="bibr" rid="pcbi.1002235-Mahadevan1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Konidaris1">[17]</xref> that basis functions should be constructed to respect distance along the state transition graph. For instance, in temporal prediction tasks, value functions are smooth in time <xref ref-type="bibr" rid="pcbi.1002235-Ludvig1">[61]</xref>. In a spatial task, the transition dynamics imply that states have similar values when they are near each other, but near as measured in geodesic (along-path) distance, rather than “as the crow flies” (Euclidean distance). Formally, geodesic distance measures the number of steps along the transition graph needed to get from one state to another. A basis over geodesic distances would treat states separated by a boundary as comparatively far apart, enabling their values to be discontinuous, whereas the Euclidean basis used above (and ubiquitously to characterize the spatial extent of place and grid fields) would inappropriately treat them as adjacent.</p>
        <p>These considerations suggest that for efficacious representation of value functions over state space, the brain should adopt basis functions that are smooth along geodesic rather than Euclidean distances. In the open field there should be no difference between geodesic and Euclidean representations, since these metrics coincide there. However, if an environment has barriers, then Euclidean and geodesic firing fields will differ. The effect of such a difference should be to introduce geometric distortion into geodesic firing fields nearby obstacles, where geodesic and Euclidean metrics differ. Such a distortion can be characterized (and indeed implemented) by mapping the original Euclidean vector coordinates through an additional transform that accounts for geodesic distance. However, in the present work our goal is to investigate the brain's spatial representations through the lens of their downstream computations; thus, in contrast to much work on the hippocampal system <xref ref-type="bibr" rid="pcbi.1002235-Blair1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Fuhs1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Burgess1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Hasselmo3">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Rolls1">[43]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Franzius1">[44]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-OKeefe4">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Moser1">[48]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Barry2">[62]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Hasselmo4">[63]</xref> we do not focus on the “upstream” computations by which the grid or place representations (or their hypothesized distortions) are themselves computed from inputs. That is, we take geodesic or Euclidean representations as a given and focus our analysis on hypothesized learning that relies on entorhinal and hippocampal outputs.</p>
        <p>In particular, we modeled how basis functions would appear in environments with barriers, if they followed a geodesic metric, by evaluating Euclidean grid or place fields (characterized by spatial grids or Gaussians) over a new set of x–y coordinates, chosen such that their pairwise Euclidean distances approximated the states' geodesic distances (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). When viewed in the original Euclidean space, the effect of barriers is to produce geometric distortions, such as variations in grid orientation and firing field shapes (<xref ref-type="fig" rid="pcbi-1002235-g004">Figure 4</xref>). As one might expect, the basis functions tend not to cross walls and instead skirt along connected paths.</p>
        <fig id="pcbi-1002235-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002235.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Example geodesic transformations of grid cells and place cells.</title>
            <p>(A) Geodesic coordinates for different environments. (B) Single grid-cell using respective geodesic coordinates. Each grid cell generated using the same spacing, orientation, and relative spatial phase. (C) Single place-cell using respective geodesic coordinates. Each place cell generated using the same mean and variance.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.g004" xlink:type="simple"/>
        </fig>
        <p>We tested the geodesic bases in the environments that stressed importance of along-path generalization (<xref ref-type="fig" rid="pcbi-1002235-g003">Figure 3A</xref>). As can be seen, the geodesic bases alleviated the poor learning caused by the indiscriminate generalization of their Euclidean counterparts (<xref ref-type="fig" rid="pcbi-1002235-g003">Figure 3B</xref>). Since the geodesic grid cells and place cells generalize using the state transition graph, they learn at least as fast as the tabular TD control (<xref ref-type="fig" rid="pcbi-1002235-g003">Figure 3B</xref>). <xref ref-type="fig" rid="pcbi-1002235-g005">Figure 5A–C</xref> depicts typical value functions at different stages of training using the geodesic basis functions (25 trials for <xref ref-type="fig" rid="pcbi-1002235-g005">Figure 5A–B</xref>, 50 trials for <xref ref-type="fig" rid="pcbi-1002235-g005">Figure 5C</xref>). Also note that both the Euclidean and geodesic bases used the same multiple granularities and tiling, with the sole difference the distance metric used. To test the role of multiple tilings in learning, we performed follow-up simulations for each of the six gridworlds using three different tiles bases. While the tile bases often learned faster than the tabular basis (which one would expect), overall the geodesic bases tended to perform best (data not shown). Together, these simulations demonstrate the representation benefits conferred by geodesic generalization, in particular how generalization along paths rather than across walls solves the problem of overgeneralization interfering with learning in the presence of obstacles. That the same qualitative results hold up using both grid-cell-like and place-cell-like representations points to their generality. In simulations not shown here, we also produced similar results using an overlapping tile code at a variety of single scales <xref ref-type="bibr" rid="pcbi.1002235-Sutton1">[8]</xref>, suggesting that the results relate to spatial generalization per se and not to the multiscale nature of the (biologically inspired) bases used here.</p>
        <fig id="pcbi-1002235-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002235.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Qualitative comparison of learned value functions using tabular, geodesic grid cell, and geodesic place cell bases.</title>
            <p>In each figure A–C, the column titles indicate the representation used to learn the value functions for a given gridworld configuration (denoted by row). White lines are walls, discrete squares indicate states, and the gray scale from dark to light indicates low to high value, respectively. To ease comparison between spatial representations within a given gridworld, the image brightness was normalized with respect to the optimal value function. (A) Snapshot of value representation after 25 learning trials. (B) Snapshot of value representation after 25 learning trials. (C) Snapshot of value representation after 50 learning trials. In contrast to Euclidean bases, the geodesic representation does <italic>not</italic> smear value across walls but instead tracks around them.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.g005" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2c">
        <title>Modeling previous grid cell and place cell data</title>
        <p>The foregoing simulations suggest that to support efficient navigation, the brain's spatial representations should generalize according to a geodesic rather than a Euclidean metric. Of course, these two representations coincide in the open field, where most studies have been conducted. However, we believe our model's predictions are consistent with a number of studies where researchers recorded neurophysiological activity while rats foraged in environments containing barriers. Here we compare our model to examples from three studies <xref ref-type="bibr" rid="pcbi.1002235-Derdikman1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Skaggs1">[64]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Muller3">[65]</xref>.</p>
        <p>Skaggs &amp; McNaughton <xref ref-type="bibr" rid="pcbi.1002235-Skaggs1">[64]</xref> recorded place cells as rats moved between two separate enclosures that were connected by a narrow corridor (schematized in <xref ref-type="fig" rid="pcbi-1002235-g006">Figure 6</xref>, top; cf. <xref ref-type="fig" rid="pcbi-1002235-g004">Figure 4</xref> in <xref ref-type="bibr" rid="pcbi.1002235-Skaggs1">[64]</xref>). Although this was not the major experimental question of the study, the narrow corridor provides a good test for our model's prediction that place fields should track along paths rather than (as a Euclidean place field predicts) across barriers. In the examples reproduced here, for instance, place cell spikes are almost exclusively confined to either the connecting corridor's entrance (<xref ref-type="fig" rid="pcbi-1002235-g006">Figure 6A</xref>, left) or the pathway between the two rooms (<xref ref-type="fig" rid="pcbi-1002235-g006">Figure 6A</xref>, right). The spikes do not generalize across the walls separating parts of the environment, but instead appear to track along paths around them (<xref ref-type="fig" rid="pcbi-1002235-g006">Figure 6</xref>), even though a standard isotropic Gaussian place field over Euclidean coordinates would clearly not respect these barriers. The data are, however, similar to place field responses from the geodesic model in a similar environment (<xref ref-type="fig" rid="pcbi-1002235-g006">Figure 6</xref>, bottom).</p>
        <fig id="pcbi-1002235-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002235.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Example of geodesic place cell model qualitatively capturing recorded place cell data.</title>
            <p>(A) Data adapted and replotted from <xref ref-type="bibr" rid="pcbi.1002235-Skaggs1">[64]</xref>. Light blue shows presence of rat, red &amp; yellow indicate action potentials of a two hippocampal place cells, and dark blue are areas rat did not visit. (B) Simulated geodesic place cell firing fields roughly resemble data in A (<italic>left</italic> and <italic>middle</italic>). The black to white color scale represents low to high firing rates.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.g006" xlink:type="simple"/>
        </fig>
        <p>In another study <xref ref-type="bibr" rid="pcbi.1002235-Muller3">[65]</xref>, a place field was first recorded in an open box and again after adding a barrier to the enclosure (<xref ref-type="fig" rid="pcbi-1002235-g007">Figure 7A</xref>; cf. to <xref ref-type="fig" rid="pcbi-1002235-g008">Figure 8</xref> in <xref ref-type="bibr" rid="pcbi.1002235-Muller3">[65]</xref>). Recorded hippocampal place cell responses in the open field vanished immediately when the firing field was bisected by a wall <xref ref-type="bibr" rid="pcbi.1002235-Muller3">[65]</xref>, <xref ref-type="fig" rid="pcbi-1002235-g006">Figure 6A</xref>. The geodesic model of neural spatial representation provides an elegant, intuitive account for why the place field disappears, whose graphical intuition is displayed in <xref ref-type="fig" rid="pcbi-1002235-g007">Figures 7A–B</xref>. In an environment without walls, one can think of the recorded place cell activity being measured over evenly spaced locations in 2D enclosure (<xref ref-type="fig" rid="pcbi-1002235-g007">Figure 7A</xref>, left). Once a barrier is introduced that bisects the field, the nearby locations on adjacent sides of the wall are pulled apart, which changes the spacing between neighboring points compared to its Euclidean counterpart. Locations on either side of the wall are far, in geodesic terms, from each other, and from the center of a place field centered in the wall itself. As a result, a sinkhole is created that swallows the place field in the geodesic coordinate space, thus muting its activity (<xref ref-type="fig" rid="pcbi-1002235-g007">Figure 7A–B</xref>).</p>
        <fig id="pcbi-1002235-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002235.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Geodesic spatial representation models can also account for the disappearance of place fields when a wall bisects the firing field.</title>
            <p>Muller &amp; Kubie <xref ref-type="bibr" rid="pcbi.1002235-Muller3">[65]</xref> observed that place fields disappeared when bisected with a wall. (A) Graphical intuition of the effect adding a wall has on the coordinates and hence the place cell firing properties. In the left panel are 20 by 20 evenly sampled points in an open square environment. Shown in the right panel are the geodesic transformed coordinates for a 20 by 20 state environment when a single vertical barrier bisects the middle section of the gridworld. Underlying each of the coordinates is a model place cell's firing field in Euclidean space (low to high firing represented by dark to light grayscale). (B) Left panel shows an open field place field, while right panel shows a geodesic place field for coordinate shown in A. Both simulated firing fields used the geodesic place cell model. Compare to <xref ref-type="fig" rid="pcbi-1002235-g008">Figures 8</xref> and <xref ref-type="fig" rid="pcbi-1002235-g009">9</xref> in <xref ref-type="bibr" rid="pcbi.1002235-Muller3">[65]</xref>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.g007" xlink:type="simple"/>
        </fig>
        <p>Similar results were also seen in a recent study of how place cell firing fields changed when mazes were reconfigured <xref ref-type="bibr" rid="pcbi.1002235-Alvernhe1">[66]</xref>. In particular, this work replicated the phenomenon of place fields diminishing or disappearing near newly introduced obstacles, and verified (as in our simulations) that such changes predominate near newly introduced obstacles. The study also demonstrates a rarer, complementary phenomenon whereby the introduction of obstacles caused firing to increase or even new place fields to appear, as verified in our simulations. In our model (<xref ref-type="fig" rid="pcbi-1002235-g008">Figure 8</xref>), increased firing is the flip side of responses diminishing for neurons coding “holes” in geodesic space; it occurs when geometric distortion “pushes” locations into areas previously off the map.</p>
        <fig id="pcbi-1002235-g008" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002235.g008</object-id>
          <label>Figure 8</label>
          <caption>
            <title>Example of geodesic place cell model qualitatively capturing recorded place cell data.</title>
            <p>(A) Two example environments used in <xref ref-type="bibr" rid="pcbi.1002235-Alvernhe1">[66]</xref>. Maze on the left was used for training &amp; exploration and maze on the right was used for testing whether the rat learned to take the shortcut route. (B) Geodesic embedding of mazes shown in A. Underlying each of the coordinates is a place field. (C) Example place field computed using coordinates shown in B; the place field center and half-width was the same in each condition. The geometric distortion in the coordinates introduced the wall can lead to increased activity in the geodesic place cell model.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.g008" xlink:type="simple"/>
        </fig>
        <p>Finally, Derdikman et al. <xref ref-type="bibr" rid="pcbi.1002235-Derdikman1">[24]</xref> recorded from grid cells as a rat ran along a hairpin maze. <xref ref-type="fig" rid="pcbi-1002235-g001">Figures 1</xref> and <xref ref-type="fig" rid="pcbi-1002235-g002">2</xref> from <xref ref-type="bibr" rid="pcbi.1002235-Derdikman1">[24]</xref> show typical grid cell firing fields in an open field and again in a hairpin maze. The standard hexagonal pattern of responding is extremely distorted; instead, responses tend to track along the hallways but not to cross walls, and firing fields are similar between alternate arms. Grid cells simulated in the geodesic space share a number of these characteristics (<xref ref-type="fig" rid="pcbi-1002235-g009">Figure 9</xref>), though not (as discussed below) all of them. One limitation of the model is that it does not capture the repetitive place field firing observed by Derdikman et al. <xref ref-type="bibr" rid="pcbi.1002235-Derdikman1">[24]</xref>.</p>
        <fig id="pcbi-1002235-g009" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002235.g009</object-id>
          <label>Figure 9</label>
          <caption>
            <title>Example of geodesic grid cell model qualitatively capturing recorded grid cell data.</title>
            <p>Derdikman et al. <xref ref-type="bibr" rid="pcbi.1002235-Derdikman1">[24]</xref> recorded while a rat explored a hairpin maze and observed fractionated grid cell firing fields that were phase locked to alternating arms of the maze. Shown is an example geodesic grid cell firing field for a similar hairpin maze that resembles that used in <xref ref-type="bibr" rid="pcbi.1002235-Derdikman1">[24]</xref>. The black to white color scale represents low to high firing rates.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.g009" xlink:type="simple"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>Although researchers widely assume that reinforcement learning methods such as temporal difference learning subserve learned action selection in the brain <xref ref-type="bibr" rid="pcbi.1002235-Houk1">[9]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Doya1">[11]</xref>, it is less clear how tasks involving many structured states can be represented in a way that enables these methods to learn efficiently, due in large part to the curse of dimensionality. In computer science, stylized spatial navigation (gridworld) problems are the classic domain for studying this issue, since the state space is large but transparently visualized and manipulated <xref ref-type="bibr" rid="pcbi.1002235-Sutton1">[8]</xref>. Here we consider rodents' neural representations of spatial location from this perspective, treating them as basis functions for downstream reinforcement learning in high-dimensional state spaces and asking how well adapted they are to this role. Though previous modeling work has not extensively considered the constraints on the brain's location codes implied by this function, much work has more or less implicitly exploited the idea that unlike the tabular basis often assumed in simple RL, the spatial extent of place fields can help to cope with the curse of dimensionality by allowing learning to generalize between nearby locations <xref ref-type="bibr" rid="pcbi.1002235-Foster1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Brown1">[50]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Johnson1">[51]</xref> even over multiple scales <xref ref-type="bibr" rid="pcbi.1002235-Kjelstrup1">[30]</xref>.</p>
      <p>The present study extends this idea to consider such generalization in light of work on efficient representation in machine learning <xref ref-type="bibr" rid="pcbi.1002235-Mahadevan1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Konidaris1">[17]</xref>. These theoretical considerations, illustrated and verified by our simple simulation results, suggest that to enable efficient representation of value (or other) functions over space, grid and place fields should operate in a distorted geometry: generalizing according to geodesic (on-path) rather than Euclidean (as-the-crow-flies) distances. Although these two distance metrics coincide in the open field, they differ in the presence of boundaries. The geodesic metric predicts that grid and place fields should not spill across walls but should instead track along paths, and should also exhibit geometric distortions, such as altered grid orientation, near boundaries. We have reviewed data from a number of experiments that seem largely in accord with these predictions. It should be noted that these predictions are all at the neural level, and could be most directly tested quantitatively by simply examining whether neural firing is modulated more reliably with distances measured by either metric: e.g., regressing distance (computed according to either definition) from a place field's center on firing rate.</p>
      <p>By contrast, since our argument is primarily one about learning efficiency (which is difficult to quantify behaviorally, since it is affected by many factors), our model does not make categorical behavioral predictions. Our simulations (<xref ref-type="fig" rid="pcbi-1002235-g003">Figure 3</xref>) demonstrate that simple TD models with Gaussian place fields (like that of <xref ref-type="bibr" rid="pcbi.1002235-Foster1">[3]</xref>) can entirely fail to solve simple navigation problems involving narrow apertures or hallways. However, the fact that rats do not exhibit such problems of course does not by itself demonstrate that the brain adopts the same solution for this problem as the one we propose. Also, to focus on our main questions of interest, we omit many features that other models use to explain various behavioral phenomena of navigation, among them mechanisms for allocentric route-planning (important for quick goal learning <xref ref-type="bibr" rid="pcbi.1002235-Foster1">[3]</xref> and for planning shortcuts <xref ref-type="bibr" rid="pcbi.1002235-Tolman1">[67]</xref>) and localization driven by combinations of cues and path integration <xref ref-type="bibr" rid="pcbi.1002235-Redish1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Collett1">[68]</xref>, both issues we discuss further below.</p>
      <p>The concept of geodesic generalization provides a formal perspective on spatial representation which is different from, but complementary to, much other work in this area. Whereas much experimental and theoretical work on the hippocampal formation concerns essentially sensory-side questions—how place or grid cells combine different sorts of inputs to produce their instantaneous representations, or to learn them over time—we attempt to isolate the downstream question of how the resulting representations serve downstream learning functions. To this end, we do not address the input-side question of how the hypothesized distorted spatial representations are themselves produced from more elementary inputs. We only assume, abstractly, that the basis functions are computed on the fly from a learned map of the barriers in the environment. In sparse environments such maps could easily be learned from observation in a single trial, and may implicate the “border cells” of entorhinal cortex <xref ref-type="bibr" rid="pcbi.1002235-Solstad2">[69]</xref>. All this leaves open the opportunity, in future work, for studying how the input- and output-side perspectives relate: whether the mechanisms studied by previous authors might be made to produce or approximate representations of the sort we envision. For instance, in the geodesic view, place fields tend to be unidirectional on the linear track <xref ref-type="bibr" rid="pcbi.1002235-Sharp1">[70]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Sharp2">[71]</xref> because the states of passing through them facing either direction are far apart in the state transition graph of a shuttling task. In input terms this more abstract relationship between states may be reflected in these situations being visually distinct <xref ref-type="bibr" rid="pcbi.1002235-Sharp1">[70]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Sharp2">[71]</xref> or anchored to a different prior reference point <xref ref-type="bibr" rid="pcbi.1002235-Redish3">[72]</xref>.</p>
      <p>More generally, unlike idealized RL models <xref ref-type="bibr" rid="pcbi.1002235-Foster1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Johnson1">[51]</xref>, theories of how place cells arise from sensory inputs (e.g. via competitive learning <xref ref-type="bibr" rid="pcbi.1002235-Sharp1">[70]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Sharp2">[71]</xref>, or self-organizing maps <xref ref-type="bibr" rid="pcbi.1002235-Gorchetchnikov1">[73]</xref>) do not necessarily imply the isotropic Gaussian firing fields we criticize, and thus may also offer (more mechanistic) explanations for phenomena such as place fields not crossing walls. It remains to be seen to what extent such local learning rules can be massaged to produce maps that accord with the globally geodesic ideal. However, such unsupervised learning models tend to envision that representations are acquired incrementally over time, which stands in contrast to our assumption (supported by data such as place field changes occurring immediately when barriers are added <xref ref-type="bibr" rid="pcbi.1002235-Muller3">[65]</xref>) that the geodesic basis is computed on the fly with respect to the current barrier locations. A different mechanism that could be useful in producing geodesic firing fields is the “arc length” cell posited by Hasselmo <xref ref-type="bibr" rid="pcbi.1002235-Hasselmo4">[63]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Hasselmo5">[74]</xref>, a circuit for computing along-path distance using oscillatory interference mechanisms related to those thought to be involved in grid formation. This mechanism has already been used to explain several examples of context-dependent firing of hippocampal neurons similar in spirit to the phenomena we consider here.</p>
      <p>The behavior of the entorhinal representation also raises interesting questions about the relationship between input- and output-side considerations. To start, it is often assumed that the place code is built up by linear combinations of grid cell inputs, e.g. by a sort of inverse Fourier transform <xref ref-type="bibr" rid="pcbi.1002235-Solstad1">[13]</xref>. In such a model, it can be shown (and simulations, not shown, verify) that place cells will inherit the geometry of their grid cell inputs. For this reason, we suggest that grid cells are likely to use a geodesic metric even if they do not directly serve as a basis for value function learning (but only indirectly, as a basis for geodesic place cells). However, this exposes some tension between the output-side imperative of generalization for RL, which we have argued calls for geodesic distortions, and the input-side implication of the system in path integration (i.e. tracking vector coordinates in a path-independent manner) <xref ref-type="bibr" rid="pcbi.1002235-Fuhs1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Fiete1">[37]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Hasselmo3">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-OKeefe4">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-McNaughton3">[75]</xref>, which is an inherently Euclidean operation.</p>
      <p>In this respect, the recent results of Derdikman et al. <xref ref-type="bibr" rid="pcbi.1002235-Derdikman1">[24]</xref> showing distorted and fractionated grid fields in a hairpin maze seem difficult to reconcile with a global Euclidean path integrator (since the hairpin barriers do not change the Euclidean coordinates), and at least qualitatively more in line with the geodesic view. One possible path toward reconciling these considerations is to consider a sort of hierarchical representation that treats the environment as a collection of rooms (in the hairpin maze, hallways) whose interrelationships are represented as by a geodesic graph, but with (disjoint) Euclidean representations maintained within each of them. This has resonance with multi-level navigation models from animal behavior (e.g. <xref ref-type="bibr" rid="pcbi.1002235-Collett1">[68]</xref>), with multiple map views of hippocampus <xref ref-type="bibr" rid="pcbi.1002235-Redish3">[72]</xref>, and, also, mechanistically, with some of the more detailed aspects of the Derdikman <xref ref-type="bibr" rid="pcbi.1002235-Derdikman1">[24]</xref> data that are not captured by our model. Most importantly, the Derdikman data suggest that the grid phase resets and “anchors” at left or right turns, producing similar patterns in alternating arms and suggesting a possible mechanism for separating adjacent hallways' representations. Such heuristics for grid resetting and anchoring (and also stretching) <xref ref-type="bibr" rid="pcbi.1002235-Derdikman1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Barry1">[34]</xref> may be able to produce a “good enough” approximation to the geodesic metric, at least in some environments, and have been examined in much more detail in more biologically detailed modeling of the task <xref ref-type="bibr" rid="pcbi.1002235-Hasselmo1">[38]</xref>. One sign of approximations is where they break down. In this respect, it is interesting that the rather extreme case of the hairpin maze results in badly fractionated downstream place fields as well <xref ref-type="bibr" rid="pcbi.1002235-Derdikman1">[24]</xref>, a phenomenon not predicted by the exact geodesic model. Finally, unlike our full model, a resetting mechanism would not in itself seem to explain phenomena related to barriers within a room, such as those we illustrate in <xref ref-type="fig" rid="pcbi-1002235-g007">Figure 7</xref>. A fuller understanding of these sorts of mechanisms demands additional research, both experimental and theoretical.</p>
      <p>Our simulations also demonstrate that the grid representation itself is a suitable basis for value function learning, even without an intermediate place cell representation. On one level, these results serve to underline the generality of our points about geometry and generalization, using a rather different basis. More speculatively, they point to the possibility that the grid representation might actually serve such a role in the brain, echoing other work on the usefulness of this Fourier-like basis for representing arbitrary functions <xref ref-type="bibr" rid="pcbi.1002235-Blair1">[12]</xref>, particularly (as also for standard uses of Fourier representations in engineering for compressing images and sounds) smooth ones. However, although a few studies have demonstrated anatomical connections from the entorhinal cortex to striatum <xref ref-type="bibr" rid="pcbi.1002235-Finch1">[55]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Totterdell1">[57]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Jeanblanc1">[76]</xref>, grid-like responses are less often reported in the deep layers that give rise to these subcortical projections (though see <xref ref-type="bibr" rid="pcbi.1002235-Canto1">[53]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Sargolini1">[54]</xref>).</p>
      <p>Finally, although for simplicity and concreteness we have focused on the principles of value function generalization in the context of a particular task (spatial navigation) and algorithm (TD(λ) learning), many of the same considerations apply more generally. First, across domains, in computational neuroscience, the need for (temporally) smooth basis functions been suggested to improve generalization also in learning about events separated in time rather than space <xref ref-type="bibr" rid="pcbi.1002235-Ludvig1">[61]</xref>, though there is no obvious counterpart to the geodesic distance metric in this setting.</p>
      <p>Second, across algorithms, TD-like learning mechanisms also likely interact with additional ones in the brain, and the core considerations we elucidate about efficient generalization due to appropriate state space representations crosscut these distinctions. For instance, value functions may also be updated using replay of previously experienced trajectories (e.g., during sleep) <xref ref-type="bibr" rid="pcbi.1002235-Foster2">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Johnson1">[51]</xref>. In models, this is typically envisioned to operate by the same TD learning rule operating again over the replayed experience <xref ref-type="bibr" rid="pcbi.1002235-Johnson1">[51]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Sutton2">[77]</xref>, and thus should imply parallel considerations of efficiency with respect to the number of replayed experiences required for convergence depending on the generalization characteristics of the basis. More distinct from these models, since the work of Tolman <xref ref-type="bibr" rid="pcbi.1002235-Tolman1">[67]</xref> it has been believed that spatial navigation may in part be accomplished by map-based route-planning processes that in RL terms correspond to model-based algorithms <xref ref-type="bibr" rid="pcbi.1002235-Daw1">[78]</xref>–<xref ref-type="bibr" rid="pcbi.1002235-Doya2">[82]</xref> rather than model-free algorithms like TD learning. These algorithms plan routes from a learned representation of the state transition matrix and rewards, typically using variants of the value iteration algorithm to compute state or action values. The core of this process is the iterative evaluation of Bellman's equation (Equation 1 in <xref ref-type="sec" rid="s4">Materials and Methods</xref>), the same equation sampled with each learning step of TD. Thus, there is reason to think that efficient value iteration (here defined as fast convergence of the value function over iterations) will analogously occur when the update is over state representations that provide better generalization over states at each step. In all, then, although we exemplify them in a highly simplified model, the principles of state representation for efficient reinforcement learning are quite general.</p>
      <p>Another issue arises when considering the present model in light of model-based RL. One of the hallmarks of model-based planning (and the behavioral phenomena that Tolman <xref ref-type="bibr" rid="pcbi.1002235-Tolman1">[67]</xref> used to argue for it, albeit not subsequently reliably demonstrated in the spatial domain), is the ability to plan novel routes without relearning, e.g. to make appropriate choices immediately when favored routes are blocked or new shortcuts are opened. Interestingly, rather than by explicit replanning, some such behaviors could instead be produced more implicitly by updating the basis functions to reflect the new maze, while maintaining the weights connecting them to value. This is easy to demonstrate in the successor representation <xref ref-type="bibr" rid="pcbi.1002235-Dayan1">[16]</xref>, a model closely related to ours. To behave similarly, the present model would require additional constraints to ensure the basis functions corresponding to different mazes are interchangeable, but this would be one route toward explaining shortcut phenomena in this framework. More generally, because the present proposal uses a state transition model, implicitly, to generate a basis function that is then used with model-free learning <xref ref-type="bibr" rid="pcbi.1002235-Dayan1">[see also 16]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Daw2">[83]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Dayan2">[84]</xref>, it resembles something of a cooperative hybrid of model-free and model-based techniques somewhat different from the competitive approaches suggested elsewhere <xref ref-type="bibr" rid="pcbi.1002235-Daw1">[78]</xref>.</p>
    </sec>
    <sec id="s4" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>Value functions and spatial reinforcement learning</title>
        <p>We simulate value function learning in a gridworld spatial navigation task in order to compare linear function approximation over several different spatial basis sets <xref ref-type="bibr" rid="pcbi.1002235-Sutton1">[8]</xref>. Our model learns to estimate the value function over states (i.e., positions in the grid), defined in the standard way as the expected future discounted reward:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.e001" xlink:type="simple"/><label>(1)</label></disp-formula></p>
        <p>To simplify notation, we omit the dependence of these quantities on the action policy throughout. The model learns approximations to these values by learning a set of N linear weights <italic>w<sub>1…N</sub></italic> for N spatial basis functions <italic>φ<sub>1…N</sub>(s)</italic> defined over the entire state space. The estimated value is thus:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.e002" xlink:type="simple"/><label>(2)</label></disp-formula></p>
        <p>We use a simple temporal-difference algorithm with eligibility traces <xref ref-type="bibr" rid="pcbi.1002235-Sutton1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Sutton3">[85]</xref> to learn weights. Specifically, at each run upon visiting state s receiving reward <italic>r(s)</italic> and transitioning into state <italic>s′</italic>, for each basis <italic>φ<sub>i</sub></italic>, weights <italic>w<sub>i</sub></italic> are updated at each time step using the following algorithm:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.e003" xlink:type="simple"/><label>(3)</label></disp-formula></p>
        <p>This is just the version of the familiar TD(λ) rule for linear value function approximation, with free parameters α (learning rate), <italic>λ</italic> (trace decay rate), and γ (discount factor).</p>
      </sec>
      <sec id="s4b">
        <title>Gridworld simulations</title>
        <p>We tested the model in 20-by-20 (M = 400 states) gridworlds in which the agent could move in any of the four cardinal directions, unless a wall blocked such a movement. Agents were started at a random location (i.e. state) at each trial, and had to reach the goal state, which was the only state with a reward, <italic>r(s)</italic> = 1. Individual trials ended when the agent reached the goal state, which was absorbing, or the maximum number of actions allowed, which was 500.</p>
        <p>For simplicity, as described above the agent learns the value function over states and uses this to guide actions toward the goal, rather than directly learning the full Q-function over states and actions. This is because, in a spatial gridworld task, the state-action-state transition model is transparent, so we assume the agent evaluates the value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002235.e004" xlink:type="simple"/></inline-formula> of each action in a state as the value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002235.e005" xlink:type="simple"/></inline-formula> of the appropriate neighboring state <xref ref-type="bibr" rid="pcbi.1002235-McClure1">[86]</xref>. Since the computation of Q involves a single step of what amounts to model-based lookahead, the approach is not as purely model-free as standard Q-learning or actor-critic algorithms. As with eligibility traces, we include this elaboration because it slightly improves generalization between states and actions, and might thus reduce the need for the sorts of basis-function-based generalization mechanisms we argue for.</p>
        <p>The agent chooses actions according to a softmax policy, i.e. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002235.e006" xlink:type="simple"/></inline-formula>, where actions unavailable (due to walls) are not considered and <italic>β</italic> is the inverse temperature that balances the amount of exploration and exploitation in action selection. For these simulations, the inverse temperature was fixed to <italic>β</italic> = 80 (a factor calibrated to provide a reasonable explore/exploit balance in choice probabilities given the scale of the action values learned). To maintain such balance, because each gridworld had a different distance between the goal state and other states, for each environment the discount factor was scaled to <italic>γ</italic> = 0.9<italic><sup>d/c</sup></italic> so that each gridworld had the same value range. Here, <italic>d</italic> is the shortest maximum distance from any state to the goal, across all gridworlds tested, and <italic>c</italic> is the maximum interstate distance for a given gridworld (range 26 to 105 states). In order to compare fairly the different basis functions, the learning rate <italic>α</italic> was chosen for each condition and each basis set to minimize the mean number of steps to termination over a fixed number of trials, using a grid search in the range [0,1]. All simulations and analyses were performed using Matlab (Natick, MA).</p>
      </sec>
      <sec id="s4c">
        <title>Basis functions</title>
        <p>We compare the model's learning using several different linear basis sets. Each basis is an M (states)×N (basis functions) matrix, with each column <italic>φ<sub>i</sub></italic> defining a function over the states. Bases were constructed as below, and lastly each row of the matrix was normalized by its L<sub>2</sub> norm. This ensures that the learning rate parameter <italic>α</italic> in the update rule (Equation 3) has a consistent interpretation (as a fractional stepsize) between different states and basis sets.</p>
        <sec id="s4c1">
          <title>Tabular</title>
          <p>The tabular basis is the M-by-M identity matrix, with one function corresponding uniquely to each state. It is easy to verify that using the identity basis that the value prediction and update equations (Equations 2 and 3, respectively) reduce to standard TD(λ) learning. In other words, the tabular basis is 1 at the current state and zero for all other states, thus the learned weights correspond directly to the values learned through standard TD(λ).</p>
        </sec>
        <sec id="s4c2">
          <title>Place cell</title>
          <p>We used isotropic 2D Gaussian basis functions at different standard deviations to model a multiscale place cell basis. Such a representation ignores the possibility that individual basis functions have multiple fields <xref ref-type="bibr" rid="pcbi.1002235-Fenton1">[e.g. 87]</xref>, a condition we explore using a grid cell-like basis. Each Gaussian was evaluated over all x–y locations in the grid, where a given pair of coordinates corresponded to a single, unique state. Standard deviations were chosen to be 0.25, 0.15, 0.1, and 0.075 (expressed as fractions of the environment width, i.e. 20 states), such that the scales of the place cell firing fields roughly equaled the scales of individual nodes in the grid cell basis (see below). The center locations were evenly tiled in the gridworld's x–y coordinates, with the smaller functions distributed more densely (with 25, 49, 100, and 225 functions going from large to small scale) to produce a regular tiling of the state space. We also included a constant function, for a total of 400 bases.</p>
        </sec>
        <sec id="s4c3">
          <title>Grid cell</title>
          <p>We used the sum of three 2D spatial cosine waves to model a hexagonal grid cell-like basis, akin to previous models of grid cell responses <xref ref-type="bibr" rid="pcbi.1002235-Blair1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Solstad1">[13]</xref>. Following the approach of Blair et al. <xref ref-type="bibr" rid="pcbi.1002235-Blair1">[12]</xref> a given basis function was represented as:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002235.e007" xlink:type="simple"/><label>(4)</label></disp-formula></p>
          <p>Here, the state <bold><italic>s</italic></bold> is expressed as a 2-vector of x–y coordinates on the gridworld; and a particular basis function <italic>φ<sub>i</sub></italic> is defined by its phases p<sub>i,j</sub>, orientation <italic>θ<sub>i</sub></italic>, and spacing λ<sub>i</sub>. Together, the grid orientation and spacing determine the vectors <bold>f</bold><sub>i,j</sub> onto which the planar cosine wave is projected. In particular, to produce a given grid orientation, <italic>θ<sub>i</sub></italic>, the directions of the three vectors <bold>f</bold><sub>i,j</sub> are taken as <italic>θ<sub>i</sub></italic>+π/2, <italic>θ<sub>i</sub></italic>−π/6, and <italic>θ<sub>i</sub></italic>+π/6. The vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002235.e008" xlink:type="simple"/></inline-formula> determine the periodicity of a given grid cell according to f<italic><sub>i</sub></italic> = 4π/(λ<sub>i</sub>3<sup>0.5</sup>) <xref ref-type="bibr" rid="pcbi.1002235-Blair1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Burgess1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1002235-Hasselmo2">[39]</xref>, where λ<sub>i</sub> controls the space between simulated firing fields. For the waves to interfere constructively and produce a grid pattern, the three phases relate as <italic>p<sub>i,1</sub></italic>+<italic>p<sub>i,2</sub></italic> = <italic>p<sub>i,3</sub></italic>.</p>
          <p>We produced a basis set of 400 grid cell-like functions, using all combinations of four orientations θ<sub>i</sub> (0, π/12, π/6, and π/4), four node spacings λ<sub>i</sub> (4/(3<italic>n</italic>) environment widths for integers n = 1–4), and 25 different spatial phases evenly sampling the 2D space of phases p<sub>i,1</sub> and p<sub>i,2</sub> each between 0 and 2π. We also included a constant function, for a total of 401 bases. Finally, we ensured that the basis functions were non-negative (directly representable with firing rates) by adding an appropriate constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002235.e009" xlink:type="simple"/></inline-formula>. For all basis sets used (tabular, place cell, and grid cells), the weights for each basis function were learned independently.</p>
        </sec>
        <sec id="s4c4">
          <title>Geodesic transformation</title>
          <p>To modify basis sets to respect the wall layout of a particular grid task, the Euclidean x–y coordinates for each state were transformed such that their pairwise distances approximately reflected geodesic distances (i.e. distances along paths that respect boundaries) in the gridworld. The basis functions were then evaluated at these transformed coordinates. Specifically, coordinates were transformed in a manner analogous to the ISOMAP algorithm <xref ref-type="bibr" rid="pcbi.1002235-Sargolini1">[54]</xref>. Floyd's Algorithm <xref ref-type="bibr" rid="pcbi.1002235-Floyd1">[88]</xref> was used to generate an M-by-M dissimilarity matrix, containing for each pair of states, the shortest-path distance (measured as the number of states) between them along the state adjacency graph. For the gridworlds shown in <xref ref-type="fig" rid="pcbi-1002235-g008">Figure 8</xref>, there are disconnected components on the state graph, which implies infinite geodesic distances between components and causes the next step of multidimensional scaling to be inestimable. To maintain the environment's integrity, we capped these infinite pairwise distances at their corresponding Euclidean distances.</p>
          <p>Next, we estimated a set of Euclidean coordinates (i.e., an x–y pair for each of the M states) whose Euclidean inter-state distances approximated the geodesic distance matrix. This was accomplished by applying non-classical multidimensional scaling (Matlab, mdscale) to the dissimilarity matrix, using Sammon's nonlinear stress criterion <xref ref-type="bibr" rid="pcbi.1002235-Sammon1">[89]</xref> as the objective function. Insofar as these new coordinates differ from the original geodesic coordinates for a state, they reflect the distorted geodesic geometry. Using this transformed set of x–y coordinates, we then reevaluated the grid cell-like and place cell-like basis sets using the same sets of parameters (phase, spacing, and orientation) as in the Euclidean cases. Note that we specify field size as a fraction of environment width, and this remapping may stretch the environment. In this case, we scaled bases as fractions of the maximum of environment width or height, thus producing a basis scaled appropriately for the transformed environment.</p>
          <p>We computed this transformation once for each environment, producing a static basis set over which to perform reinforcement learning. Realistically, the animal would have to learn the state transition function (i.e., the location of barriers) in order to compute the basis, and the firing fields would be expected to change as this state transition model was learned. However, since in our environments obstacles are sparse and observable from a distance, the true transition matrix (and the basis implied) should be entirely learned during the first trial in any of our environments.</p>
        </sec>
        <sec id="s4c5">
          <title>Ground truth</title>
          <p>Ground-truth value functions were computed for the optimal policy using dynamic programming over a tabular basis.</p>
        </sec>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002235-OKeefe1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name><name name-style="western"><surname>Dostrovsky</surname><given-names>J</given-names></name></person-group>             <year>1971</year>             <article-title>The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat.</article-title>             <source>Brain Res</source>             <volume>34</volume>             <fpage>171</fpage>             <lpage>175</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Hafting1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hafting</surname><given-names>T</given-names></name><name name-style="western"><surname>Fyhn</surname><given-names>M</given-names></name><name name-style="western"><surname>Molden</surname><given-names>S</given-names></name><name name-style="western"><surname>Moser</surname><given-names>MB</given-names></name><name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name></person-group>             <year>2005</year>             <article-title>Microstructure of a spatial map in the entorhinal cortex.</article-title>             <source>Nature</source>             <volume>436</volume>             <fpage>801</fpage>             <lpage>806</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Foster1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Foster</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Morris</surname><given-names>RG</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name></person-group>             <year>2000</year>             <article-title>A model of hippocampally dependent navigation, using the temporal difference learning rule.</article-title>             <source>Hippocampus</source>             <volume>10</volume>             <fpage>1</fpage>             <lpage>16</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Redish1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name><name name-style="western"><surname>Touretzky</surname><given-names>DS</given-names></name></person-group>             <year>1997</year>             <article-title>Cognitive maps beyond the hippocampus.</article-title>             <source>Hippocampus</source>             <volume>7</volume>             <fpage>15</fpage>             <lpage>35</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-McNaughton1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name><name name-style="western"><surname>Barnes</surname><given-names>CA</given-names></name><name name-style="western"><surname>Gerrard</surname><given-names>JL</given-names></name><name name-style="western"><surname>Gothard</surname><given-names>K</given-names></name><name name-style="western"><surname>Jung</surname><given-names>MW</given-names></name><etal/></person-group>             <year>1996</year>             <article-title>Deciphering the hippocampal polyglot: the hippocampus as a path integration system.</article-title>             <source>J Exp Biol</source>             <volume>199</volume>             <fpage>173</fpage>             <lpage>185</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Samsonovich1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Samsonovich</surname><given-names>A</given-names></name><name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name></person-group>             <year>1997</year>             <article-title>Path integration and cognitive mapping in a continuous attractor neural network model.</article-title>             <source>J Neurosci</source>             <volume>17</volume>             <fpage>5900</fpage>             <lpage>5920</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Redish2">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name><name name-style="western"><surname>Touretzky</surname><given-names>DS</given-names></name></person-group>             <year>1998</year>             <article-title>The role of the hippocampus in solving the Morris water maze.</article-title>             <source>Neural Comput</source>             <volume>10</volume>             <fpage>73</fpage>             <lpage>111</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Sutton1">
        <label>8</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sutton</surname><given-names>R</given-names></name><name name-style="western"><surname>Barto</surname><given-names>A</given-names></name></person-group>             <year>1998</year>             <source>Reinforcement learning: An introduction</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Houk1">
        <label>9</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Houk</surname><given-names>J</given-names></name><name name-style="western"><surname>Adams</surname><given-names>J</given-names></name><name name-style="western"><surname>Barto</surname><given-names>A</given-names></name></person-group>             <year>1995</year>             <article-title>A model of how the basal ganglia generate and use neural signals that predict reinforcement.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Houk</surname><given-names>J</given-names></name><name name-style="western"><surname>Davis</surname><given-names>J</given-names></name></person-group>             <source>Models of information processing in the basal ganglia</source>             <publisher-loc>Cambridge, , MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>249</fpage>             <lpage>270</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Schultz1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Montague</surname><given-names>PR</given-names></name></person-group>             <year>1997</year>             <article-title>A neural substrate of prediction and reward.</article-title>             <source>Science</source>             <volume>275</volume>             <fpage>1593</fpage>             <lpage>1599</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Doya1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name></person-group>             <year>2008</year>             <article-title>Modulators of decision making.</article-title>             <source>Nat Neurosci</source>             <volume>11</volume>             <fpage>410</fpage>             <lpage>416</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Blair1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Blair</surname><given-names>HT</given-names></name><name name-style="western"><surname>Welday</surname><given-names>AC</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>K</given-names></name></person-group>             <year>2007</year>             <article-title>Scale-invariant memory representations emerge from moire interference between grid fields that produce theta oscillations: a computational model.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>3211</fpage>             <lpage>3229</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Solstad1">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Solstad</surname><given-names>T</given-names></name><name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name><name name-style="western"><surname>Einevoll</surname><given-names>GT</given-names></name></person-group>             <year>2006</year>             <article-title>From grid cells to place cells: a mathematical model.</article-title>             <source>Hippocampus</source>             <volume>16</volume>             <fpage>1026</fpage>             <lpage>1031</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Mahadevan1">
        <label>14</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mahadevan</surname><given-names>S</given-names></name></person-group>             <year>2005</year>             <article-title>Proto-value functions: Developmental reinforcement learning.</article-title>             <source>Proceedings of the 22nd International Conference on Machine Learning; 7–11 August 2005; Bonn, Germany</source>             <fpage>553</fpage>             <lpage>560</lpage>             <comment>ICML 2005</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Mahadevan2">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mahadevan</surname><given-names>S</given-names></name><name name-style="western"><surname>Maggioni</surname><given-names>M</given-names></name></person-group>             <year>2006</year>             <article-title>Value Function Approximation with Diffusion Wavelets and Laplacian Eigenfunctions.</article-title>             <source>Adv Neural Inf Process Syst</source>             <volume>18</volume>             <fpage>843</fpage>             <lpage>850</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Dayan1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name></person-group>             <year>1993</year>             <article-title>Improving Generalization for Temporal Difference Learning: The Successor Representation.</article-title>             <source>Neural Comput</source>             <volume>5</volume>             <fpage>613</fpage>             <lpage>624</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Konidaris1">
        <label>17</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Konidaris</surname><given-names>G</given-names></name><name name-style="western"><surname>Osentoski</surname><given-names>S</given-names></name></person-group>             <year>2008</year>             <article-title>Value function approximation in reinforcement learning using the Fourier basis.</article-title>             <comment>Technical Report UM-CS-2008-19, Department of Computer Science, University of Massachusetts, Amherst</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Tenenbaum1">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tenenbaum</surname><given-names>JB</given-names></name><name name-style="western"><surname>de Silva</surname><given-names>V</given-names></name><name name-style="western"><surname>Langford</surname><given-names>JC</given-names></name></person-group>             <year>2000</year>             <article-title>A global geometric framework for nonlinear dimensionality reduction.</article-title>             <source>Science</source>             <volume>290</volume>             <fpage>2319</fpage>             <lpage>2323</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Dragoi1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dragoi</surname><given-names>G</given-names></name><name name-style="western"><surname>Harris</surname><given-names>KD</given-names></name><name name-style="western"><surname>Buzsaki</surname><given-names>G</given-names></name></person-group>             <year>2003</year>             <article-title>Place representation within hippocampal networks is modified by long-term potentiation.</article-title>             <source>Neuron</source>             <volume>39</volume>             <fpage>843</fpage>             <lpage>853</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-McNaughton2">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name><name name-style="western"><surname>Barnes</surname><given-names>CA</given-names></name><name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name></person-group>             <year>1983</year>             <article-title>The contributions of position, direction, and velocity to single unit activity in the hippocampus of freely-moving rats.</article-title>             <source>Exp Brain Res</source>             <volume>52</volume>             <fpage>41</fpage>             <lpage>49</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Mehta1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mehta</surname><given-names>MR</given-names></name><name name-style="western"><surname>Quirk</surname><given-names>MC</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>MA</given-names></name></person-group>             <year>2000</year>             <article-title>Experience-dependent asymmetric shape of hippocampal receptive fields.</article-title>             <source>Neuron</source>             <volume>25</volume>             <fpage>707</fpage>             <lpage>715</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-OKeefe2">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name><name name-style="western"><surname>Recce</surname><given-names>ML</given-names></name></person-group>             <year>1993</year>             <article-title>Phase relationship between hippocampal place units and the EEG theta rhythm.</article-title>             <source>Hippocampus</source>             <volume>3</volume>             <fpage>317</fpage>             <lpage>330</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Muller1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Muller</surname><given-names>RU</given-names></name><name name-style="western"><surname>Bostock</surname><given-names>E</given-names></name><name name-style="western"><surname>Taube</surname><given-names>JS</given-names></name><name name-style="western"><surname>Kubie</surname><given-names>JL</given-names></name></person-group>             <year>1994</year>             <article-title>On the directional firing properties of hippocampal place cells.</article-title>             <source>J Neurosci</source>             <volume>14</volume>             <fpage>7235</fpage>             <lpage>7251</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Derdikman1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Derdikman</surname><given-names>D</given-names></name><name name-style="western"><surname>Whitlock</surname><given-names>JR</given-names></name><name name-style="western"><surname>Tsao</surname><given-names>A</given-names></name><name name-style="western"><surname>Fyhn</surname><given-names>M</given-names></name><name name-style="western"><surname>Hafting</surname><given-names>T</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>Fragmentation of grid cell maps in a multicompartment environment.</article-title>             <source>Nat Neurosci</source>             <volume>12</volume>             <fpage>1325</fpage>             <lpage>1332</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Best1">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Best</surname><given-names>PJ</given-names></name><name name-style="western"><surname>White</surname><given-names>AM</given-names></name><name name-style="western"><surname>Minai</surname><given-names>A</given-names></name></person-group>             <year>2001</year>             <article-title>Spatial processing in the brain: the activity of hippocampal place cells.</article-title>             <source>Annu Rev Neurosci</source>             <volume>24</volume>             <fpage>459</fpage>             <lpage>486</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Muller2">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Muller</surname><given-names>RU</given-names></name><name name-style="western"><surname>Stead</surname><given-names>M</given-names></name><name name-style="western"><surname>Pach</surname><given-names>J</given-names></name></person-group>             <year>1996</year>             <article-title>The hippocampus as a cognitive graph.</article-title>             <source>J Gen Physiol</source>             <volume>107</volume>             <fpage>663</fpage>             <lpage>694</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Blum1">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Blum</surname><given-names>KI</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name></person-group>             <year>1996</year>             <article-title>A model of spatial map formation in the hippocampus of the rat.</article-title>             <source>Neural Comput</source>             <volume>8</volume>             <fpage>85</fpage>             <lpage>93</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Foster2">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Foster</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>MA</given-names></name></person-group>             <year>2006</year>             <article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state.</article-title>             <source>Nature</source>             <volume>440</volume>             <fpage>680</fpage>             <lpage>683</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Gerstner1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name></person-group>             <year>1997</year>             <article-title>Learning navigational maps through potentiation and modulation of hippocampal place cells.</article-title>             <source>J Comput Neurosci</source>             <volume>4</volume>             <fpage>79</fpage>             <lpage>94</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Kjelstrup1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kjelstrup</surname><given-names>KB</given-names></name><name name-style="western"><surname>Solstad</surname><given-names>T</given-names></name><name name-style="western"><surname>Brun</surname><given-names>VH</given-names></name><name name-style="western"><surname>Hafting</surname><given-names>T</given-names></name><name name-style="western"><surname>Leutgeb</surname><given-names>S</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Finite scale of spatial representation in the hippocampus.</article-title>             <source>Science</source>             <volume>321</volume>             <fpage>140</fpage>             <lpage>143</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Jung1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jung</surname><given-names>MW</given-names></name><name name-style="western"><surname>Wiener</surname><given-names>SI</given-names></name><name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name></person-group>             <year>1994</year>             <article-title>Comparison of spatial firing characteristics of units in dorsal and ventral hippocampus of the rat.</article-title>             <source>J Neurosci</source>             <volume>14</volume>             <fpage>7347</fpage>             <lpage>7356</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-OKeefe3">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name><name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name></person-group>             <year>1996</year>             <article-title>Geometric determinants of the place fields of hippocampal neurons.</article-title>             <source>Nature</source>             <volume>381</volume>             <fpage>425</fpage>             <lpage>428</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Brun1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brun</surname><given-names>VH</given-names></name><name name-style="western"><surname>Solstad</surname><given-names>T</given-names></name><name name-style="western"><surname>Kjelstrup</surname><given-names>KB</given-names></name><name name-style="western"><surname>Fyhn</surname><given-names>M</given-names></name><name name-style="western"><surname>Witter</surname><given-names>MP</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Progressive increase in grid scale from dorsal to ventral medial entorhinal cortex.</article-title>             <source>Hippocampus</source>             <volume>18</volume>             <fpage>1200</fpage>             <lpage>1212</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Barry1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Barry</surname><given-names>C</given-names></name><name name-style="western"><surname>Hayman</surname><given-names>R</given-names></name><name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name><name name-style="western"><surname>Jeffery</surname><given-names>KJ</given-names></name></person-group>             <year>2007</year>             <article-title>Experience-dependent rescaling of entorhinal grids.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <fpage>682</fpage>             <lpage>684</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Fuhs1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fuhs</surname><given-names>MC</given-names></name><name name-style="western"><surname>Touretzky</surname><given-names>DS</given-names></name></person-group>             <year>2006</year>             <article-title>A spin glass model of path integration in rat medial entorhinal cortex.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>4266</fpage>             <lpage>4276</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Burgess1">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name><name name-style="western"><surname>Barry</surname><given-names>C</given-names></name><name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name></person-group>             <year>2007</year>             <article-title>An oscillatory interference model of grid cell firing.</article-title>             <source>Hippocampus</source>             <volume>17</volume>             <fpage>801</fpage>             <lpage>812</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Fiete1">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fiete</surname><given-names>IR</given-names></name><name name-style="western"><surname>Burak</surname><given-names>Y</given-names></name><name name-style="western"><surname>Brookings</surname><given-names>T</given-names></name></person-group>             <year>2008</year>             <article-title>What grid cells convey about rat location.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>6858</fpage>             <lpage>6871</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Hasselmo1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group>             <year>2008</year>             <article-title>Grid cell mechanisms and function: contributions of entorhinal persistent spiking and phase resetting.</article-title>             <source>Hippocampus</source>             <volume>18</volume>             <fpage>1213</fpage>             <lpage>1229</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Hasselmo2">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hasselmo</surname><given-names>ME</given-names></name><name name-style="western"><surname>Giocomo</surname><given-names>LM</given-names></name><name name-style="western"><surname>Zilli</surname><given-names>EA</given-names></name></person-group>             <year>2007</year>             <article-title>Grid cell firing may arise from interference of theta frequency membrane potential oscillations in single neurons.</article-title>             <source>Hippocampus</source>             <volume>17</volume>             <fpage>1252</fpage>             <lpage>1271</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Hasselmo3">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hasselmo</surname><given-names>ME</given-names></name><name name-style="western"><surname>Brandon</surname><given-names>MP</given-names></name></person-group>             <year>2008</year>             <article-title>Linking cellular mechanisms to behavior: entorhinal persistent spiking and membrane potential oscillations may underlie path integration, grid cell firing, and episodic memory.</article-title>             <source>Neural Plast</source>             <volume>2008</volume>             <fpage>658323</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Mhatre1">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mhatre</surname><given-names>H</given-names></name><name name-style="western"><surname>Gorchetchnikov</surname><given-names>A</given-names></name><name name-style="western"><surname>Grossberg</surname><given-names>S</given-names></name></person-group>             <year>2010</year>             <article-title>Grid cell hexagonal patterns formed by fast self-organized learning within entorhinal cortex.</article-title>             <source>Hippocampus. </source>             <comment>E-pub ahead of print. doi:10.1002/hipo.20901</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Zilli1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zilli</surname><given-names>EA</given-names></name><name name-style="western"><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group>             <year>2010</year>             <article-title>Coupled noisy spiking neurons as velocity-controlled oscillators in a model of grid cell spatial firing.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>13850</fpage>             <lpage>13860</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Rolls1">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name><name name-style="western"><surname>Stringer</surname><given-names>SM</given-names></name><name name-style="western"><surname>Elliot</surname><given-names>T</given-names></name></person-group>             <year>2006</year>             <article-title>Entorhinal cortex grid cells can map to hippocampal place cells by competitive learning.</article-title>             <source>Network</source>             <volume>17</volume>             <fpage>447</fpage>             <lpage>465</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Franzius1">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Franzius</surname><given-names>M</given-names></name><name name-style="western"><surname>Vollgraf</surname><given-names>R</given-names></name><name name-style="western"><surname>Wiskott</surname><given-names>L</given-names></name></person-group>             <year>2007</year>             <article-title>From grids to places.</article-title>             <source>J Comput Neurosci</source>             <volume>22</volume>             <fpage>297</fpage>             <lpage>299</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Jeffery1">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jeffery</surname><given-names>KJ</given-names></name></person-group>             <year>2007</year>             <article-title>Self-localization and the entorhinal-hippocampal system.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>17</volume>             <fpage>684</fpage>             <lpage>691</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Molter1">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Molter</surname><given-names>C</given-names></name><name name-style="western"><surname>Yamaguchi</surname><given-names>Y</given-names></name></person-group>             <year>2008</year>             <article-title>Impact of temporal coding of presynaptic entorhinal cortex grid cells on the formation of hippocampal place fields.</article-title>             <source>Neural Netw</source>             <volume>21</volume>             <fpage>303</fpage>             <lpage>310</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-OKeefe4">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name><name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name></person-group>             <year>2005</year>             <article-title>Dual phase and rate coding in hippocampal place cells: theoretical significance and relationship to entorhinal grid cells.</article-title>             <source>Hippocampus</source>             <volume>15</volume>             <fpage>853</fpage>             <lpage>866</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Moser1">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name><name name-style="western"><surname>Kropff</surname><given-names>E</given-names></name><name name-style="western"><surname>Moser</surname><given-names>MB</given-names></name></person-group>             <year>2008</year>             <article-title>Place cells, grid cells, and the brain's spatial representation system.</article-title>             <source>Annu Rev Neurosci</source>             <volume>31</volume>             <fpage>69</fpage>             <lpage>89</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Suri1">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Suri</surname><given-names>RE</given-names></name><name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name></person-group>             <year>2001</year>             <article-title>Temporal difference model reproduces anticipatory neural activity.</article-title>             <source>Neural Comput</source>             <volume>13</volume>             <fpage>841</fpage>             <lpage>862</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Brown1">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brown</surname><given-names>MA</given-names></name><name name-style="western"><surname>Sharp</surname><given-names>PE</given-names></name></person-group>             <year>1995</year>             <article-title>Simulation of spatial learning in the Morris water maze by a neural network model of the hippocampal formation and nucleus accumbens.</article-title>             <source>Hippocampus</source>             <volume>5</volume>             <fpage>171</fpage>             <lpage>188</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Johnson1">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Johnson</surname><given-names>A</given-names></name><name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name></person-group>             <year>2005</year>             <article-title>Hippocampal replay contributes to within session learning in a temporal difference reinforcement learning model.</article-title>             <source>Neural Netw</source>             <volume>18</volume>             <fpage>1163</fpage>             <lpage>1171</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Fyhn1">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fyhn</surname><given-names>M</given-names></name><name name-style="western"><surname>Molden</surname><given-names>S</given-names></name><name name-style="western"><surname>Witter</surname><given-names>MP</given-names></name><name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name><name name-style="western"><surname>Moser</surname><given-names>MB</given-names></name></person-group>             <year>2004</year>             <article-title>Spatial representation in the entorhinal cortex.</article-title>             <source>Science</source>             <volume>305</volume>             <fpage>1258</fpage>             <lpage>1264</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Canto1">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Canto</surname><given-names>CB</given-names></name><name name-style="western"><surname>Wouterlood</surname><given-names>FG</given-names></name><name name-style="western"><surname>Witter</surname><given-names>MP</given-names></name></person-group>             <year>2008</year>             <article-title>What does the anatomical organization of the entorhinal cortex tell us?</article-title>             <source>Neural Plast</source>             <volume>2008</volume>             <fpage>381243</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Sargolini1">
        <label>54</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sargolini</surname><given-names>F</given-names></name><name name-style="western"><surname>Fyhn</surname><given-names>M</given-names></name><name name-style="western"><surname>Hafting</surname><given-names>T</given-names></name><name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name><name name-style="western"><surname>Witter</surname><given-names>MP</given-names></name><etal/></person-group>             <year>2006</year>             <article-title>Conjunctive representation of position, direction, and velocity in entorhinal cortex.</article-title>             <source>Science</source>             <volume>312</volume>             <fpage>758</fpage>             <lpage>762</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Finch1">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Finch</surname><given-names>DM</given-names></name><name name-style="western"><surname>Gigg</surname><given-names>J</given-names></name><name name-style="western"><surname>Tan</surname><given-names>AM</given-names></name><name name-style="western"><surname>Kosoyan</surname><given-names>OP</given-names></name></person-group>             <year>1995</year>             <article-title>Neurophysiology and neuropharmacology of projections from entorhinal cortex to striatum in the rat.</article-title>             <source>Brain Res</source>             <volume>670</volume>             <fpage>233</fpage>             <lpage>247</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Krayniak1">
        <label>56</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Krayniak</surname><given-names>PF</given-names></name><name name-style="western"><surname>Meibach</surname><given-names>RC</given-names></name><name name-style="western"><surname>Siegel</surname><given-names>A</given-names></name></person-group>             <year>1981</year>             <article-title>A projection from the entorhinal cortex to the nucleus accumbens in the rat.</article-title>             <source>Brain Res</source>             <volume>209</volume>             <fpage>427</fpage>             <lpage>431</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Totterdell1">
        <label>57</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Totterdell</surname><given-names>S</given-names></name><name name-style="western"><surname>Meredith</surname><given-names>GE</given-names></name></person-group>             <year>1997</year>             <article-title>Topographical organization of projections from the entorhinal cortex to the striatum of the rat.</article-title>             <source>Neuroscience</source>             <volume>78</volume>             <fpage>715</fpage>             <lpage>729</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Corbit1">
        <label>58</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Corbit</surname><given-names>LH</given-names></name><name name-style="western"><surname>Ostlund</surname><given-names>SB</given-names></name><name name-style="western"><surname>Balleine</surname><given-names>BW</given-names></name></person-group>             <year>2002</year>             <article-title>Sensitivity to instrumental contingency degradation is mediated by the entorhinal cortex and its efferents via the dorsal hippocampus.</article-title>             <source>J Neurosci</source>             <volume>22</volume>             <fpage>10976</fpage>             <lpage>10984</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Langston1">
        <label>59</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Langston</surname><given-names>RF</given-names></name><name name-style="western"><surname>Ainge</surname><given-names>JA</given-names></name><name name-style="western"><surname>Couey</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Canto</surname><given-names>CB</given-names></name><name name-style="western"><surname>Bjerknes</surname><given-names>TL</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Development of the spatial representation system in the rat.</article-title>             <source>Science</source>             <volume>328</volume>             <fpage>1576</fpage>             <lpage>1580</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Wills1">
        <label>60</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wills</surname><given-names>TJ</given-names></name><name name-style="western"><surname>Cacucci</surname><given-names>F</given-names></name><name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name><name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name></person-group>             <year>2010</year>             <article-title>Development of the hippocampal cognitive map in preweanling rats.</article-title>             <source>Science</source>             <volume>328</volume>             <fpage>1573</fpage>             <lpage>1576</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Ludvig1">
        <label>61</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ludvig</surname><given-names>EA</given-names></name><name name-style="western"><surname>Sutton</surname><given-names>RS</given-names></name><name name-style="western"><surname>Kehoe</surname><given-names>EJ</given-names></name></person-group>             <year>2008</year>             <article-title>Stimulus representation and the timing of reward-prediction errors in models of the dopamine system.</article-title>             <source>Neural Comput</source>             <volume>20</volume>             <fpage>3034</fpage>             <lpage>3054</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Barry2">
        <label>62</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Barry</surname><given-names>C</given-names></name><name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name></person-group>             <year>2007</year>             <article-title>Learning in a geometric model of place cell firing.</article-title>             <source>Hippocampus</source>             <volume>17</volume>             <fpage>786</fpage>             <lpage>800</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Hasselmo4">
        <label>63</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group>             <year>2007</year>             <article-title>Arc length coding by interference of theta frequency oscillations may underlie context-dependent hippocampal unit data and episodic memory function.</article-title>             <source>Learn Mem</source>             <volume>14</volume>             <fpage>782</fpage>             <lpage>794</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Skaggs1">
        <label>64</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Skaggs</surname><given-names>WE</given-names></name><name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name></person-group>             <year>1998</year>             <article-title>Spatial firing properties of hippocampal CA1 populations in an environment containing two visually identical regions.</article-title>             <source>J Neurosci</source>             <volume>18</volume>             <fpage>8455</fpage>             <lpage>8466</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Muller3">
        <label>65</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Muller</surname><given-names>RU</given-names></name><name name-style="western"><surname>Kubie</surname><given-names>JL</given-names></name></person-group>             <year>1987</year>             <article-title>The effects of changes in the environment on the spatial firing of hippocampal complex-spike cells.</article-title>             <source>J Neurosci</source>             <volume>7</volume>             <fpage>1951</fpage>             <lpage>1968</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Alvernhe1">
        <label>66</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Alvernhe</surname><given-names>A</given-names></name><name name-style="western"><surname>Save</surname><given-names>E</given-names></name><name name-style="western"><surname>Poucet</surname><given-names>B</given-names></name></person-group>             <year>2011</year>             <article-title>Local remapping of place cell firing in the Tolman detour task.</article-title>             <source>Eur J Neurosci</source>             <volume>33</volume>             <fpage>1696</fpage>             <lpage>1705</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Tolman1">
        <label>67</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tolman</surname><given-names>E</given-names></name></person-group>             <year>1932</year>             <source>Purposive Behaviors in Animals and Men</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Appleton-Century-Crofts</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Collett1">
        <label>68</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name><name name-style="western"><surname>Cartwright</surname><given-names>BA</given-names></name><name name-style="western"><surname>Smith</surname><given-names>BA</given-names></name></person-group>             <year>1986</year>             <article-title>Landmark learning and visuo-spatial memories in gerbils.</article-title>             <source>J Comp Physiol A</source>             <volume>158</volume>             <fpage>835</fpage>             <lpage>851</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Solstad2">
        <label>69</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Solstad</surname><given-names>T</given-names></name><name name-style="western"><surname>Boccara</surname><given-names>CN</given-names></name><name name-style="western"><surname>Kropff</surname><given-names>E</given-names></name><name name-style="western"><surname>Moser</surname><given-names>MB</given-names></name><name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name></person-group>             <year>2008</year>             <article-title>Representation of geometric borders in the entorhinal cortex.</article-title>             <source>Science</source>             <volume>322</volume>             <fpage>1865</fpage>             <lpage>1868</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Sharp1">
        <label>70</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sharp</surname><given-names>PE</given-names></name></person-group>             <year>1991</year>             <article-title>Computer-Simulation of Hippocampal Place Cells.</article-title>             <source>Psychobiology</source>             <volume>19</volume>             <fpage>103</fpage>             <lpage>115</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Sharp2">
        <label>71</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sharp</surname><given-names>PE</given-names></name><name name-style="western"><surname>Blair</surname><given-names>HT</given-names></name><name name-style="western"><surname>Brown</surname><given-names>M</given-names></name></person-group>             <year>1996</year>             <article-title>Neural network modeling of the hippocampal formation spatial signals and their possible role in navigation: a modular approach.</article-title>             <source>Hippocampus</source>             <volume>6</volume>             <fpage>720</fpage>             <lpage>734</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Redish3">
        <label>72</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name></person-group>             <year>1999</year>             <source>Beyond the cognitive map: From place cells to episodic memory</source>             <publisher-loc>Cambridge, , MA</publisher-loc>             <publisher-name>The MIT Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Gorchetchnikov1">
        <label>73</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gorchetchnikov</surname><given-names>A</given-names></name><name name-style="western"><surname>Grossberg</surname><given-names>S</given-names></name></person-group>             <year>2007</year>             <article-title>Space, time and learning in the hippocampus: how fine spatial and temporal scales are expanded into population codes for behavioral control.</article-title>             <source>Neural Netw</source>             <volume>20</volume>             <fpage>182</fpage>             <lpage>193</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Hasselmo5">
        <label>74</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group>             <year>2009</year>             <article-title>A model of episodic memory: mental time travel along encoded trajectories using grid cells.</article-title>             <source>Neurobiol Learn Mem</source>             <volume>92</volume>             <fpage>559</fpage>             <lpage>573</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-McNaughton3">
        <label>75</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name><name name-style="western"><surname>Battaglia</surname><given-names>FP</given-names></name><name name-style="western"><surname>Jensen</surname><given-names>O</given-names></name><name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name><name name-style="western"><surname>Moser</surname><given-names>MB</given-names></name></person-group>             <year>2006</year>             <article-title>Path integration and the neural basis of the ‘cognitive map’.</article-title>             <source>Nat Rev Neurosci</source>             <volume>7</volume>             <fpage>663</fpage>             <lpage>678</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Jeanblanc1">
        <label>76</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jeanblanc</surname><given-names>J</given-names></name><name name-style="western"><surname>Peterschmitt</surname><given-names>Y</given-names></name><name name-style="western"><surname>Hoeltzel</surname><given-names>A</given-names></name><name name-style="western"><surname>Louilot</surname><given-names>A</given-names></name></person-group>             <year>2004</year>             <article-title>Influence of the entorhinal cortex on accumbal and striatal dopaminergic responses in a latent inhibition paradigm.</article-title>             <source>Neuroscience</source>             <volume>128</volume>             <fpage>187</fpage>             <lpage>200</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Sutton2">
        <label>77</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sutton</surname><given-names>RS</given-names></name></person-group>             <year>1990</year>             <article-title>Integrated architectures for learning, planning, and reacting based on approximating dynamic programming.</article-title>             <source>Proceedings of the Seventh International Conference on Machine Learning; 21–23 June 1990; Austin, Texas</source>             <fpage>216</fpage>             <lpage>224</lpage>             <comment>ICML 1990</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Daw1">
        <label>78</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Daw</surname><given-names>N</given-names></name><name name-style="western"><surname>Niv</surname><given-names>Y</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name></person-group>             <year>2005</year>             <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control.</article-title>             <source>Nat Neurosci</source>             <volume>8</volume>             <fpage>1704</fpage>             <lpage>1711</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Johnson2">
        <label>79</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Johnson</surname><given-names>A</given-names></name><name name-style="western"><surname>van der Meer</surname><given-names>MA</given-names></name><name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name></person-group>             <year>2007</year>             <article-title>Integrating hippocampus and striatum in decision-making.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>17</volume>             <fpage>692</fpage>             <lpage>697</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Hasselmo6">
        <label>80</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group>             <year>2005</year>             <article-title>A model of prefrontal cortical mechanisms for goal-directed behavior.</article-title>             <source>J Cogn Neurosci</source>             <volume>17</volume>             <fpage>1115</fpage>             <lpage>1129</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Johnson3">
        <label>81</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Johnson</surname><given-names>A</given-names></name><name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name></person-group>             <year>2007</year>             <article-title>Neural ensembles in CA3 transiently encode paths forward of the animal at a decision point.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>12176</fpage>             <lpage>12189</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Doya2">
        <label>82</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name></person-group>             <year>1999</year>             <article-title>What are the computations of the cerebellum, the basal ganglia and the cerebral cortex?</article-title>             <source>Neural Netw</source>             <volume>12</volume>             <fpage>961</fpage>             <lpage>974</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Daw2">
        <label>83</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name><name name-style="western"><surname>Courville</surname><given-names>AC</given-names></name><name name-style="western"><surname>Touretzky</surname><given-names>DS</given-names></name></person-group>             <year>2006</year>             <article-title>Representation and timing in theories of the dopamine system.</article-title>             <source>Neural Comput</source>             <volume>18</volume>             <fpage>1637</fpage>             <lpage>1677</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Dayan2">
        <label>84</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name></person-group>             <year>2008</year>             <article-title>Decision theory, reinforcement learning, and the brain.</article-title>             <source>Cogn Affect Behav Neurosci</source>             <volume>8</volume>             <fpage>429</fpage>             <lpage>453</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Sutton3">
        <label>85</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sutton</surname><given-names>R</given-names></name></person-group>             <year>1988</year>             <article-title>Learning to predict by the methods of temporal differences.</article-title>             <source>Mach Learn</source>             <volume>3</volume>             <fpage>9</fpage>             <lpage>44</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-McClure1">
        <label>86</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>McClure</surname><given-names>S</given-names></name><name name-style="western"><surname>Daw</surname><given-names>N</given-names></name><name name-style="western"><surname>Montague</surname><given-names>P</given-names></name></person-group>             <year>2003</year>             <article-title>A computational substrate for incentive salience.</article-title>             <source>Trends Neurosci</source>             <volume>26</volume>             <fpage>423</fpage>             <lpage>428</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Fenton1">
        <label>87</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fenton</surname><given-names>AA</given-names></name><name name-style="western"><surname>Kao</surname><given-names>HY</given-names></name><name name-style="western"><surname>Neymotin</surname><given-names>SA</given-names></name><name name-style="western"><surname>Olypher</surname><given-names>A</given-names></name><name name-style="western"><surname>Vayntrub</surname><given-names>Y</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Unmasking the CA1 ensemble place code by exposures to small and large environments: more place cells and multiple, irregularly arranged, and expanded place fields in the larger space.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>11250</fpage>             <lpage>11262</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Floyd1">
        <label>88</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Floyd</surname><given-names>R</given-names></name></person-group>             <year>1962</year>             <article-title>Algorithm 97: Shortest path.</article-title>             <source>Commun ACM</source>             <volume>5</volume>             <fpage>345</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002235-Sammon1">
        <label>89</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sammon</surname><given-names>JW</given-names></name></person-group>             <year>1969</year>             <article-title>A Nonlinear Mapping for Data Structure Analysis.</article-title>             <source>IEEE Trans Comput</source>             <volume>18</volume>             <fpage>401</fpage>             <lpage>409</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>
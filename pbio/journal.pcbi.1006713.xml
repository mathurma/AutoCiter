<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-00525</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006713</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Learning and forgetting using reinforced Bayesian change detection</article-title>
<alt-title alt-title-type="running-head">Learning and forgetting using reinforced Bayesian change detection</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5810-086X</contrib-id>
<name name-style="western">
<surname>Moens</surname> <given-names>Vincent</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="fn" rid="currentaff001"><sup>¤</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Zénon</surname> <given-names>Alexandre</given-names></name>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>CoAction Lab, Institue of Neuroscience, Université Catholique de Louvain, Bruxelles, Belgium</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>INCIA, Université de Bordeaux, Bordeaux, France</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Friston</surname> <given-names>Karl J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University College London, UNITED KINGDOM</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="current-aff" id="currentaff001">
<label>¤</label>
<p>Current address: University of Louvain, 53, Avenue Mounier, COSY-B1.53.04, B-1200 Brussels, Belgium</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">vincent.moens@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>4</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="epub">
<day>17</day>
<month>4</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>4</issue>
<elocation-id>e1006713</elocation-id>
<history>
<date date-type="received">
<day>5</day>
<month>4</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>9</day>
<month>12</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Moens, Zénon</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006713"/>
<abstract>
<p>Agents living in volatile environments must be able to detect changes in contingencies while refraining to adapt to unexpected events that are caused by noise. In Reinforcement Learning (RL) frameworks, this requires learning rates that adapt to past reliability of the model. The observation that behavioural flexibility in animals tends to decrease following prolonged training in stable environment provides experimental evidence for such adaptive learning rates. However, in classical RL models, learning rate is either fixed or scheduled and can thus not adapt dynamically to environmental changes. Here, we propose a new Bayesian learning model, using variational inference, that achieves adaptive change detection by the use of Stabilized Forgetting, updating its current belief based on a mixture of fixed, initial priors and previous posterior beliefs. The weight given to these two sources is optimized alongside the other parameters, allowing the model to adapt dynamically to changes in environmental volatility and to unexpected observations. This approach is used to implement the “critic” of an actor-critic RL model, while the actor samples the resulting value distributions to choose which action to undertake. We show that our model can emulate different adaptation strategies to contingency changes, depending on its prior assumptions of environmental stability, and that model parameters can be fit to real data with high accuracy. The model also exhibits trade-offs between flexibility and computational costs that mirror those observed in real data. Overall, the proposed method provides a general framework to study learning flexibility and decision making in RL contexts.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>In stable contexts, animals and humans exhibit automatic behaviour that allows them to make fast decisions. However, these automatic processes exhibit a lack of flexibility when environmental contingencies change. In the present paper, we propose a model of behavioural automatization that is based on adaptive forgetting and that emulates these properties. The model builds an estimate of the stability of the environment and uses this estimate to adjust its learning rate and the balance between exploration and exploitation policies. The model performs Bayesian inference on latent variables that represent relevant environmental properties, such as reward functions, optimal policies or environment stability. From there, the model makes decisions in order to maximize long-term rewards, with a noise proportional to environmental uncertainty. This rich model encompasses many aspects of Reinforcement Learning (RL), such as Temporal Difference RL and counterfactual learning, and accounts for the reduced computational cost of automatic behaviour. Using simulations, we show that this model leads to interesting predictions about the efficiency with which subjects adapt to sudden change of contingencies after prolonged training.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>Actions de Recherche Concertee</institution>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Zenon</surname> <given-names>Alexandre</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>FSR - Brain back to Brussels</institution>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5810-086X</contrib-id>
<name name-style="western">
<surname>MOENS</surname> <given-names>Vincent</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution>Fondation Médicale Reine Elisabeth</institution>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Zenon</surname> <given-names>Alexandre</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was performed at the Institute of Neuroscience (IoNS) of the Université catholique de Louvain (Brussels, Belgium); it was supported by grants from the ARC (Actions de Recherche Concertées, Communauté Francaise de Belgique), from the Fondation Médicale Reine Elisabeth (FMRE), from the Fonds de la Recherche Scientifique (F.R.S.-FNRS) and from IdEx Bordeaux. A.Z. was a Senior Research Associate supported by INNOVIRIS and is currently 1st grade researcher for the french National Center for Scientific Research (CNRS). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="12"/>
<table-count count="3"/>
<page-count count="41"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-04-29</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The full code that was used to simulate, fit and plot data is available at: <ext-link ext-link-type="uri" xlink:href="https://figshare.com/s/21c266bd84b83f01c06b" xlink:type="simple">https://figshare.com/s/21c266bd84b83f01c06b</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Learning agents must be able to deal efficiently with surprising events when trying to represent the current state of the environment. Ideally, agents’ response to such events should depend on their belief about how likely the environment is to change. When expecting a steady environment, a surprising event should be considered as an accident and should not lead to updating previous beliefs. Conversely, if the agent assumes the environment is volatile, then a single unexpected event should trigger forgetting of past beliefs and relearning of the (presumably) new contingency. Importantly, assumptions about environmental volatility can also be learned from experience.</p>
<p>Here, we propose a general model that implements this adaptive behaviour using Bayesian inference. This model is divided in two parts: the critic which learns the environment and the actor that makes decision on the basis of the learned model of the environment.</p>
<p>The critic side of the model (called Hierarchical Adaptive Forgetting Variational Filter, HAFVF [<xref ref-type="bibr" rid="pcbi.1006713.ref001">1</xref>]) discriminates contingency changes from accidents on the basis of past environmental volatility, and adapts its learning accordingly. This learner is a special case of Stabilized Forgetting (SF) [<xref ref-type="bibr" rid="pcbi.1006713.ref002">2</xref>]: practically, learning is modulated by a forgetting factor that controls the relative influence of past data with respect to a fixed prior distribution reflecting the naive knowledge of the agent. At each time step, the goal of the learner is to infer whether the environment has changed or not. In the former case, she erases her memory of past events and resets her prior belief to her initial prior knowledge. In the latter, she can learn a new posterior belief of the environment structure based on her previous belief. The value of the forgetting factor encodes these two opposite behaviours: small values tend to bring parameters back to their original prior, whereas large values tend to keep previous posteriors in memory. The first novel contribution of our work lies in the fact that the posterior distribution of the forgetting factor depends on the estimated stability of past observations. The second and most crucial contribution lies in the hierarchical structure of this forgetting scheme: indeed, the posterior distribution of the forgetting factor is itself subject to a certain forgetting, learned in a similar manner. This leads to a 3-level hierarchical organization in which the bottom level learns to predict the environment, the intermediate level represents its volatility and the top level learns how likely the environment is to change its volatility. We show that this model implements a generalization of classical Q-learning algorithms.</p>
<p>The actor side of the model is framed as a full Drift-Diffusion Model of decision making [<xref ref-type="bibr" rid="pcbi.1006713.ref003">3</xref>] (Normal-Inverse-Gamma Diffusion Process; NIGDM) that samples from the value distributions inferred from the critic in order to select actions in proportion to their probability of being the most valued. We show that this approach predicts plausible results in terms of exploration-exploitation policy balance, reward rate, reaction times (RT) and cognitive cost of decision. Using simulated data, we also show that the model can uncover specific features of human behaviour in single and multi-stage environments. The whole model is outlined in Algorithm 8: the agent first selects an action given an (approximate) Q-sampling policy, which is temporally implemented as a Full DDM [<xref ref-type="bibr" rid="pcbi.1006713.ref003">3</xref>] with variable drift rate and accumulation noise, then learns based on the return of the action executed (reward <italic>r</italic>(<italic>s</italic><sub><italic>j</italic></sub>, <italic>a</italic><sub><italic>j</italic></sub>) and transition <italic>s</italic>′ = <italic>T</italic>(<italic>s</italic><sub><italic>j</italic></sub>, <italic>a</italic><sub><italic>j</italic></sub>)). Then, the critic updates its approximate posterior belief about the state of the environment <italic>q</italic><sub><italic>j</italic></sub> ≈ <italic>p</italic>.</p>
<p><bold>Algorithm 1</bold>: AC-HAFVF sketch <italic>a</italic> represents actions, <italic>r</italic> stands for rewards, <italic>s</italic> stands for state and <bold>x</bold> stands for observations. <italic>μ</italic><sup><italic>r</italic></sup> is the expected value of the reward. <italic>q</italic> represents the approximate posterior of the latent variable <bold>z</bold> and <bold><italic>θ</italic></bold><sub>0</sub> stands for the prior parameter values of the distribution of <bold>z</bold></p>
<p specific-use="line">1 <bold>for</bold> <italic>j</italic> = 1 <bold><italic>to</italic></bold> <italic>J</italic> <bold>do</bold></p>
<p specific-use="line">2  <bold>Actor</bold>: <italic>NIGDM</italic>  Line 8;</p>
<p specific-use="line">3  select <inline-formula id="pcbi.1006713.e001"><alternatives><graphic id="pcbi.1006713.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mrow><mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>∼</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mtext>arg</mml:mtext> <mml:mspace width="4pt"/><mml:mtext>max</mml:mtext></mml:mrow> <mml:mi mathvariant="bold">a</mml:mi></mml:msub> <mml:msup><mml:mi>μ</mml:mi> <mml:mi>r</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>;</p>
<p specific-use="line">4  Observe <bold>x</bold><sub><italic>j</italic></sub> = {<italic>r</italic>(<italic>s</italic><sub><italic>j</italic></sub>, <italic>a</italic><sub><italic>j</italic></sub>), <italic>s</italic><sub><italic>j</italic>+1</sub>};</p>
<p specific-use="line">5  </p>
<p specific-use="line">6  <bold>Critic</bold>: <italic>HAFVF</italic>  Line 8;</p>
<p specific-use="line">7  update <italic>q</italic><sub><italic>j</italic></sub>(<bold>z</bold>(<italic>s</italic><sub><italic>j</italic></sub>, <italic>a</italic><sub><italic>j</italic></sub>)) ≈ <italic>p</italic>(<bold>z</bold>(<italic>s</italic><sub><italic>j</italic></sub>, <italic>a</italic><sub><italic>j</italic></sub>)|<bold>x</bold><sub><italic>j</italic></sub>;<bold>x</bold><sub>&lt;<italic>j</italic></sub>, <bold><italic>θ</italic></bold><sub>0</sub>);</p>
<p specific-use="line">8 <bold>end</bold></p>
<p>We apply the proposed approach to Model-Free RL contexts (i.e. to agents limiting their knowledge of the environment to a set of reward functions) in an extensive manner. We explore in detail the application of our algorithm to Temporal Discounting RL, in which we study the possibility of learning the discounting factor as a latent variable of the model. We also highlight various methods for accounting for unobserved events in a changing environment. Finally, we show that the way our algorithm optimizes the exploration-exploitation balance is similar to Q-Value Sampling when using large DDM thresholds.</p>
<p>Importantly, the proposed approach is very general, and even though we apply it here only to Model-Free Reinforcement Learning, it could be also extended to Model-Based RL [<xref ref-type="bibr" rid="pcbi.1006713.ref004">4</xref>], where the agent models a state-action-state transition table together with the reward functions. Additionally, other machine-learning algorithms can also benefit from this approach [<xref ref-type="bibr" rid="pcbi.1006713.ref001">1</xref>].</p>
<p>The paper is structured as follows: first (Related work section) we review briefly the state of the art and place our work within the context of current literature. in the Methods section, we present the mathematical details of the model. We derive the analytical expressions of the learning rule, and frame them in a biological context. We then show how this learning scheme directly translates into a decision rule that constitutes a special case of the Sequential Sampling family of algorithms. In the Results section, we show various predictions of our model in terms of learning and decision making. More importantly, we show that despite its complexity, the model can be fitted to behavioural data. We conclude by reviewing the contributions of the present work, highlighting its limitations and putting it in a broader perspective.</p>
<sec id="sec002">
<title>Related work</title>
<p>The adaptation of learning to contingency changes and noise has numerous connections to various scientific fields from cognitive psychology to machine learning. A classical finding in behavioural neuroscience is that instrumental behaviours tend to be less and less flexible as subjects repeatedly receive positive reinforcement after selecting a certain action in a certain context, both in animals [<xref ref-type="bibr" rid="pcbi.1006713.ref005">5</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref008">8</xref>] and humans [<xref ref-type="bibr" rid="pcbi.1006713.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref013">13</xref>]. This suggests that biological agents indeed adapt their learning rate to inferred environmental stability: when the environment appears stable (e.g. after prolonged experience of a rewarded stimulus-response association), they show increased tendency to maintain their model of the environment unchanged despite reception of unexpected data.</p>
<p>Most studies on such automatization of behaviour have focused on action selection. However, weighting new evidence against previous belief is also a fundamental problem for perception and cognition [<xref ref-type="bibr" rid="pcbi.1006713.ref014">14</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref016">16</xref>]. Predictive coding [<xref ref-type="bibr" rid="pcbi.1006713.ref017">17</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref022">22</xref>] provides a rich, global, framework that has the potential to tackle this problem, but an explicit formulation of cognitive flexibility is still lacking. For example, whereas [<xref ref-type="bibr" rid="pcbi.1006713.ref022">22</xref>] provides an elegant Kalman-like Bayesian filter that learns the current state of the environment based on its past observations and predicts the effect of its actions, it assumes a stable environment and cannot, therefore, adapt dynamically to contingency changes. The Hierarchical Gaussian Filter (HGF) proposed by Mathys and colleagues [<xref ref-type="bibr" rid="pcbi.1006713.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref024">24</xref>] provides a mathematical framework that implements learning of a sensory input in a hierarchical manner, and that can account for the emergence of inflexibility in various situations. This model deals with the problem of flexibility (framed as expected “volatility”) by building a hierarchy of random variables: each of these variables is distributed with a Gaussian distribution with a mean equal to this variable at the trial before and the variance equal to a non-linear transform of the variable at superior level. Each level encodes the distribution of the volatility of the level below. Although it has shown its efficiency in numerous applications [<xref ref-type="bibr" rid="pcbi.1006713.ref025">25</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref030">30</xref>], a major limitation of this model, within the context of our present concern, is that While the HGF accommodates a dynamically varying volatility, it assumes that the precision of the likelihood at the lowest level is static. To understand why it is the case, one should first observe that in the HGF the variance at each level is the product of two factors: a first “tonic” component, which is constant throughout the experiment, and a “phasic” component that is time-varying and controlled by the level above. These terms recall the concepts of “expected” and “unexpected” uncertainty [<xref ref-type="bibr" rid="pcbi.1006713.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref032">32</xref>], and in the present paper, we will refer to these as variance (of the observation) and volatility (of the contingency). Now consider an experiment with two distinct successive signals, one with a low variance and one with a high variance. When fitted to this dataset, the HGF will consider the lower variance as the first tonic component, and all the extra variance in the second part of the signal will be assigned to the “phasic” part of the volatility, thus wrongfully considering noise of the signal as a change of contingency (see <xref ref-type="fig" rid="pcbi.1006713.g001">Fig 1</xref>). In summary, the HGF will have difficulties accounting for changes in the variance of the observations. Moreover, the HGF model cannot forget past experience after changes of contingency, but can only adapt its learning to the current contingency. This contrasts with the approach we propose, where the assessment of a change of contingency is made with the use of a reference, naive prior that plays the role of a “null hypothesis”. This way of making the learning process gravitate around a naive prior allows the model to actively forget past events and to eventually come back to a stable learning state even after very surprising events. These caveats limit the applicability of the HGF to a certain class of datasets in which contingency changes affect the mean rather than the variance of observations and in which the training set contains all possible future changes that the model may encounter at testing.</p>
<fig id="pcbi.1006713.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Fitting of HGF model on dataset with changing variance.</title>
<p>Two signals with a low (0.1) and high (1) variance were successively simulated for 200 trials each. A two-level HGF and the HAFVF were fitted to this simple dataset. <bold>A</bold>. The HGF considered the lower variance component as a “tonic” factor whereas all the additional variance of the second part of the signal was assigned to the “phasic” (time-varying) volatility component. This corresponded to a high second-level activation during the second phase of the experiment (<bold>B</bold>.) reflecting a low estimate of signal stability. The corresponding Maximum a Posteriori (MAP) estimate of the HAFVF had a much better variance estimate for both the first and second part of the experiment (<bold>A</bold>.), and, in contrast to the HGF, the stability measure (<bold>B</bold>.) decreased only at the time of the change of contingency. Shaded areas represent the 95% (approximate) posterior confidence interval of the mean. Green dots represent the value of the observations.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g001" xlink:type="simple"/>
</fig>
<p>As will be shown in detail below, in the model proposed in the present paper, volatility is not only a function of the variance of the observations: if a new observation falls close enough to previous estimates then the agent will refine its posterior estimate of the variance and will decrease its forgetting factor (i.e. will move its prior away from the fixed initial prior and closer to the learned posterior from the previous trial), but if the new observation is not likely given this posterior estimate, the forgetting factor will increase (i.e. will move closer to the fixed initial prior) and the model will tend to update to a novel state (because of the low precision of the initial prior). In the results of this manuscript, we show that our model outperforms the HGF in such situations.</p>
<p>In Machine Learning and in Statistics, too, the question of whether new unexpected data should be classified as outlier or environmental change is important [<xref ref-type="bibr" rid="pcbi.1006713.ref033">33</xref>]. This problem of “denoising” or “filtering” the data is ubiquitous in science, and usually relies on arbitrary assumptions about environmental stability. In signal processing and system identification, adaptive forgetting is a broad field where optimality is highly context (and prior)-dependant [<xref ref-type="bibr" rid="pcbi.1006713.ref002">2</xref>]. Bayesian Filtering (BF) [<xref ref-type="bibr" rid="pcbi.1006713.ref034">34</xref>], and in particular the Kalman Filter [<xref ref-type="bibr" rid="pcbi.1006713.ref035">35</xref>] often lack the necessary flexibility to model real-life signals that are, by nature, changing. One can discriminate two approaches to deal with this problem: whereas Particle Filtering (PF) [<xref ref-type="bibr" rid="pcbi.1006713.ref036">36</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref038">38</xref>] is computationally expensive, the SF family of algorithms [<xref ref-type="bibr" rid="pcbi.1006713.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref039">39</xref>], from which our model is a special case, usually has greater accuracy for a given amount of resources [<xref ref-type="bibr" rid="pcbi.1006713.ref036">36</xref>] (for more information, we refer to [<xref ref-type="bibr" rid="pcbi.1006713.ref035">35</xref>] where SF is reviewed). Most previous approaches in SF have used a truncated exponential prior [<xref ref-type="bibr" rid="pcbi.1006713.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref041">41</xref>] or a fixed, linear mixture prior to account for the stability of the process [<xref ref-type="bibr" rid="pcbi.1006713.ref037">37</xref>]. Our approach is innovative in this field in two ways: first, we use a Beta prior on the mixing coefficient (unusual but not unique [<xref ref-type="bibr" rid="pcbi.1006713.ref042">42</xref>]), and we adapt the posterior of this forgetting factor on the basis of past observations, the prior of this parameter and its own adaptive forgetting factor. Second, we introduce a hierarchy of forgetting that stabilizes the learning when the training length is long.</p>
<p>We therefore intend to focus our present research on the very question of flexibility. We will show how flexibility can be implemented in a Bayesian framework using an adaptive forgetting factor, and what prediction this framework makes when applied to learning and decision making in Model-Free paradigms.</p>
</sec>
</sec>
<sec id="sec003" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec004">
<title>Bayesian Q-learning and the problem of flexibility</title>
<p>Classical RL [<xref ref-type="bibr" rid="pcbi.1006713.ref043">43</xref>], or Bayesian RL [<xref ref-type="bibr" rid="pcbi.1006713.ref044">44</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref045">45</xref>] cannot discriminate learners that are more prone to believe in a contingency change from those who tend to disregard unexpected events and consider them as noise. To show this, we take the following example: let <italic>p</italic>(<italic>ρ</italic>|<italic>r</italic><sub>≤<italic>j</italic></sub>) = Beta(<italic>α</italic>, <italic>β</italic>) be the posterior probability at trial j of a binary reward <italic>r</italic><sub><italic>j</italic></sub> ∼ Bern(<italic>ρ</italic>) with prior probability <italic>ρ</italic> ∼ Beta(<italic>α</italic><sub>0</sub>, <italic>β</italic><sub>0</sub>). It can be shown that, at the trial <italic>j</italic> = <italic>v</italic><sub><italic>j</italic></sub> + <italic>u</italic><sub><italic>j</italic></sub>, where <italic>v</italic><sub><italic>j</italic></sub> is the number of successes and <italic>u</italic><sub><italic>j</italic></sub> the number of failures, the posterior probability parameters read {<italic>α</italic><sub><italic>j</italic></sub> = <italic>α</italic><sub>0</sub> + <italic>v</italic><sub><italic>j</italic></sub>, <italic>β</italic><sub><italic>j</italic></sub> = <italic>β</italic><sub>0</sub> + <italic>u</italic><sub><italic>j</italic></sub>}. This can be easily mapped to a classical RL algorithm if one considers that, at each update of <italic>v</italic> and <italic>u</italic>, the posterior expectation of <italic>ρ</italic> is updated by
<disp-formula id="pcbi.1006713.e002"><alternatives><graphic id="pcbi.1006713.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow/></mml:msub> <mml:mo>[</mml:mo> <mml:mrow><mml:mi>ρ</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mo>≤</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mi>v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula>
<disp-formula id="pcbi.1006713.e003"><alternatives><graphic id="pcbi.1006713.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e003" xlink:type="simple"/><mml:math display="block" id="M3"><mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>j</mml:mi></mml:mfrac> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow/></mml:msub> <mml:mo>[</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>]</mml:mo> <mml:mo>+</mml:mo> <mml:mfrac><mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mi>j</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula>
<disp-formula id="pcbi.1006713.e004"><alternatives><graphic id="pcbi.1006713.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mrow><mml:mo>=</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mo>[</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>]</mml:mo> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mo>[</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>]</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula>
<disp-formula id="pcbi.1006713.e005"><alternatives><graphic id="pcbi.1006713.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mrow><mml:mtext>where</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>η</mml:mi> <mml:mo>≜</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>j</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
which has the form of a classical myopic Q-learning algorithm with a decreasing learning rate.</p>
<p>The drawback of this fixed-schedule learning rate is that, if the number of observed successes outnumbers greatly the number of failures (<italic>v</italic> ≫ <italic>u</italic>) at the time of a contingency change in which failures become suddenly more frequent, the agent will need <italic>v</italic> − <italic>u</italic> + 1 failures to start considering that <italic>p</italic>(<italic>r</italic><sub><italic>j</italic></sub> = 0|<italic>r</italic><sub>≤<italic>j</italic></sub>) &gt; <italic>p</italic>(<italic>r</italic><sub><italic>j</italic></sub> = 1|<italic>r</italic><sub>≤<italic>j</italic></sub>). This behaviour is obviously sub-optimal in a changing environment, and Dearden [<xref ref-type="bibr" rid="pcbi.1006713.ref044">44</xref>] suggests adding a constant forgetting factor to the updates of the posterior, making therefore the agent progressively blind to past outcomes. Consider the case in which
<disp-formula id="pcbi.1006713.e006"><alternatives><graphic id="pcbi.1006713.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e006" xlink:type="simple"/><mml:math display="block" id="M6"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow/></mml:msub> <mml:mo>[</mml:mo> <mml:mrow><mml:mi>ρ</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mo>≤</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>w</mml:mi> <mml:msub><mml:mi>v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>w</mml:mi> <mml:msub><mml:mi>v</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>w</mml:mi> <mml:msub><mml:mi>u</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></disp-formula>
with <italic>w</italic> ∈ [0; 1] being the forgetting factor. We can easily see that, in the limit case of <italic>α</italic><sub>0</sub> = 0 and <italic>β</italic><sub>0</sub> = 0, <inline-formula id="pcbi.1006713.e007"><alternatives><graphic id="pcbi.1006713.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>β</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>→</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> as <italic>j</italic> → ∞. We can define <inline-formula id="pcbi.1006713.e008"><alternatives><graphic id="pcbi.1006713.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula> as the <italic>efficient memory</italic> of the agent, which provides a bound on the <italic>effective memory</italic>, represented by the total amount of trials taken into account so far (e.g. <italic>α</italic><sub><italic>j</italic></sub>+ <italic>β</italic><sub><italic>j</italic></sub> in the previous example). This produces an upper and lower bound to the variance of the posterior estimate of <italic>p</italic>(<italic>ρ</italic>|<italic>r</italic><sub>≤<italic>j</italic></sub>). This can be seen from the variance of the beta distribution <inline-formula id="pcbi.1006713.e009"><alternatives><graphic id="pcbi.1006713.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi> <mml:mi>a</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>ρ</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mo>≤</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>β</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>β</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>β</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> which is maximized when <italic>α</italic><sub><italic>j</italic></sub> = <italic>β</italic><sub><italic>j</italic></sub>, and minimized when either <italic>α</italic><sub><italic>j</italic></sub> = <italic>α</italic><sub>0</sub> or <italic>β</italic><sub><italic>j</italic></sub> = <italic>β</italic><sub>0</sub>. In a steady environment, agents with larger memory are advantaged since they can better estimate the variance of the observations. But when the environment changes, large memory becomes disadvantageous because it requires longer time to adapt to the new contingency. Here, we propose a natural solution to this problem by having the agent erase its memory when a new observation (or a series of observations) is unlikely given the past experience.</p>
</sec>
<sec id="sec005">
<title>General framework</title>
<p>Our framework is based on the following assumptions:</p>
<p><bold>Assumption 1</bold> <italic>The environment is fully Markovian: the probability of the current observation given all the past history is equal to the probability of this observation given the previous observation</italic>.</p>
<p><bold>Assumption 2</bold> <italic>At a given time point, all the observations (rewards, state transitions, etc.) are</italic> <italic>i</italic>.<italic>i</italic>.<italic>d</italic>. <italic>and follow a distribution p</italic>(<bold>x</bold>|<bold>z</bold>) <italic>that is issued from the exponential family and has a conjugate prior that also belongs to the exponential family p</italic>(<bold>z</bold>|<bold><italic>θ</italic></bold><sub>0</sub>).</p>
<p>For conciseness, the latent variables <bold>z</bold> (i.e. action value, transition probability etc.) and their prior <bold><italic>θ</italic></bold> will represent the natural parameters of the corresponding distributions in what follows.</p>
<p><bold>Assumption 3</bold> <italic>The agent builds a hierarchical model of the environment, where each of the distributions at the lower level (reward and state transitions) are independent, i.e. the reward distribution for one state-action cannot be predicted from the distribution of the other state-actions</italic>.</p>
<p><bold>Assumption 4</bold> <italic>The agent can only observe the effects of the action she performs</italic>.</p>
<p>Finally, an important assumption that will guide the development of the model is that the evolution of the environment is unpredictable (i.e. transition probabilities are uniformly distributed for all states of the environment) with the notable exception that it is more or less likely to stay in the same state than to switch to another state. Formally:</p>
<p><bold>Assumption 5</bold> <italic>Let</italic> <inline-formula id="pcbi.1006713.e010">
<alternatives>
<graphic id="pcbi.1006713.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e010" xlink:type="simple"/>
<mml:math display="inline" id="M10">
<mml:msubsup>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:msup>
<mml:mi>z</mml:mi>
<mml:mi>a</mml:mi>
</mml:msup>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>A</mml:mi>
</mml:msubsup>
</mml:math>
</alternatives>
</inline-formula> <italic>be a set of environment states, with A</italic> ≫ 0 <italic>and a, b, c</italic> ∈ {1, 2, …, <italic>A</italic>}, <italic>a</italic> ∉ {<italic>b</italic>, <italic>c</italic>}. <italic>We assume that the transition probabilities are uniformly distributed for b, c</italic> ∈ {1: <italic>A</italic>}<sub>¬<italic>a</italic></sub>, <italic>which reads</italic>:
<disp-formula id="pcbi.1006713.e011"><alternatives><graphic id="pcbi.1006713.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e011" xlink:type="simple"/><mml:math display="block" id="M11"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi>z</mml:mi> <mml:mi>b</mml:mi></mml:msup> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi>z</mml:mi> <mml:mi>a</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi>z</mml:mi> <mml:mi>c</mml:mi></mml:msup> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi>z</mml:mi> <mml:mi>a</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≠</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi>z</mml:mi> <mml:mi>a</mml:mi></mml:msup> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi>z</mml:mi> <mml:mi>a</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
Assumption 5 implies that any attempt to learn new transitions from state to state based on a uniform prior over these transitions will harm the performance of the predictive model, and the best strategy one could adopt is to learn the probability of staying in the same state and group the probabilities of changing to any other state together. Then, the only two transition probabilities to learn are:
<disp-formula id="pcbi.1006713.e012"><alternatives><graphic id="pcbi.1006713.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi>z</mml:mi> <mml:mi>b</mml:mi></mml:msup> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi>z</mml:mi> <mml:mi>a</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>for</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>b</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>a</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi>z</mml:mi> <mml:mi>a</mml:mi></mml:msup> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi>z</mml:mi> <mml:mi>a</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
This is what the “critic” part of the AC-HAFVF we propose achieves. Of course, the model could be improved by learning the other transition probabilities, if needed, but we leave this for future work (see for instance [<xref ref-type="bibr" rid="pcbi.1006713.ref035">35</xref>]).</p>
<sec id="sec006">
<title>Model specifications</title>
<p>We are interested in deriving the posterior probability of some datapoint-specific measure <italic>p</italic><sub><italic>j</italic></sub>(<bold>z</bold> ∣ <bold>x</bold><sub>≤<italic>j</italic></sub>, <bold><italic>θ</italic></bold><sub>0</sub>), where <italic>j</italic> indicates the point in time, given the past and current observations <bold>x</bold><sub>≤<italic>j</italic></sub> and some prior belief <bold><italic>θ</italic></bold><sub>0</sub>. Bayes theorem states that this is equal to
<disp-formula id="pcbi.1006713.e013"><alternatives><graphic id="pcbi.1006713.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e013" xlink:type="simple"/><mml:math display="block" id="M13"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>J</mml:mi></mml:msubsup> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msubsup><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>J</mml:mi></mml:msubsup> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula>
We now consider the case of a subject that observes the stream of data and updates her posterior belief on-line as data are gathered. According to Assumption 2, one can express the posterior of <bold>z</bold> given the current observation <italic>x</italic><sub><italic>j</italic></sub> <disp-formula id="pcbi.1006713.e014"><alternatives><graphic id="pcbi.1006713.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e014" xlink:type="simple"/><mml:math display="block" id="M14"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(6)</label></disp-formula>
It appears immediately that the prior <italic>p</italic>(<bold>z</bold>|<bold>x</bold><sub>&lt;<italic>j</italic></sub>) has the same form as the previous posterior, so that our posterior probability function can be easily estimated recursively using the last posterior estimate as a prior (yesterday’s posterior is today’s prior) until <italic>p</italic>(<bold>z</bold>|<bold><italic>θ</italic></bold><sub>0</sub>) is reached. Assumption 2 implies that the posterior <italic>p</italic>(<bold>z</bold>|<italic>x</italic><sub><italic>j</italic></sub>, <bold>x</bold><sub>&lt;<italic>j</italic></sub>) will be tractable: since <italic>p</italic>(<bold>x</bold>|<bold>z</bold>) is from the exponential family and has a conjugate prior <italic>p</italic>(<bold>z</bold>|<bold><italic>θ</italic></bold><sub>0</sub>), the posterior probability has the same form as the prior, and has a convenient expression:
<disp-formula id="pcbi.1006713.e015"><alternatives><graphic id="pcbi.1006713.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e015" xlink:type="simple"/><mml:math display="block" id="M15"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mo>[</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>j</mml:mi> <mml:mi>ξ</mml:mi></mml:msubsup></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>j</mml:mi> <mml:mi>η</mml:mi></mml:msubsup></mml:mtd></mml:mtr></mml:mtable> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:mo>[</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn> <mml:mi>ξ</mml:mi></mml:msubsup> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>j</mml:mi></mml:munderover> <mml:mi mathvariant="bold">T</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi> <mml:mn>0</mml:mn> <mml:mi>η</mml:mi></mml:msubsup> <mml:mo>+</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula>
where <bold>T</bold>(<italic>x</italic><sub><italic>i</italic></sub>) is the sufficient statistics of the <italic>i</italic><sup>th</sup> sample, and where we have made explicit the fact that <inline-formula id="pcbi.1006713.e016"><alternatives><graphic id="pcbi.1006713.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn> <mml:mi>ξ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mn>0</mml:mn> <mml:mi>η</mml:mi></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> can be partitioned in two parts, from which <inline-formula id="pcbi.1006713.e017"><alternatives><graphic id="pcbi.1006713.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mn>0</mml:mn> <mml:mi>η</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> represents the prior number of observations. Consequently, <inline-formula id="pcbi.1006713.e018"><alternatives><graphic id="pcbi.1006713.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>j</mml:mi> <mml:mi>η</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is equivalent to the effective memory introduced above.</p>
<p>This simple form of recursive posterior estimate suffers from the drawbacks we want to avoid, i.e. it does not forget past experience. Let us therefore assume that <bold>z</bold><sub><italic>j</italic></sub> can be different from <bold>z</bold><sub><italic>j</italic>−1</sub> with a given probability, which we first assume to be known. We introduce a two-component mixture prior where the previous posterior is weighted against the original prior belief:
<disp-formula id="pcbi.1006713.e019"><alternatives><graphic id="pcbi.1006713.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e019" xlink:type="simple"/><mml:math display="block" id="M19"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>;</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≜</mml:mo> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>w</mml:mi></mml:msup> <mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mi>Z</mml:mi> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mspace width="4.pt"/><mml:mtext>with</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>w</mml:mi> <mml:mo>∈</mml:mo> <mml:mo>[</mml:mo> <mml:mn>0</mml:mn> <mml:mo>;</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
The exponential weights on this prior mixture allow us to easily write its logarithmic form, but it still demands that we compute the normalizing constant <italic>Z</italic>(<italic>w</italic>, <bold>x</bold><sub>&lt;<italic>j</italic></sub>, <bold><italic>θ</italic></bold><sub>0</sub>) = ∫ <italic>p</italic>(<bold>z</bold>|<bold>x</bold><sub>&lt;<italic>j</italic></sub>)<sup><italic>w</italic></sup> <italic>p</italic>(<bold>z</bold>|<bold><italic>θ</italic></bold><sub>0</sub>)<sup>1−<italic>w</italic></sup> <italic>d</italic> <bold>z</bold>. This constant has, however, a closed-form if both the prior and the previous posterior are from the same distribution, issued from the exponential family.</p>
<p>In <xref ref-type="disp-formula" rid="pcbi.1006713.e019">Eq 8</xref>, we assumed that the forgetting factor was known. However, it is more likely that the learner will need to infer it from the data at hand. Putting a beta prior on this parameter, and under the assumption that the posterior probability factorizes (Mean-Field assumption), the joint probability at time <italic>j</italic> reads:
<disp-formula id="pcbi.1006713.e020"><alternatives><graphic id="pcbi.1006713.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e020" xlink:type="simple"/><mml:math display="block" id="M20"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>,</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>;</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>w</mml:mi></mml:msup> <mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mi>Z</mml:mi> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>;</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
where <italic>ϕ</italic><sub>0</sub> is the vector of the parameters of the beta prior of <italic>w</italic>. The model in <xref ref-type="disp-formula" rid="pcbi.1006713.e020">Eq 9</xref> is not conjugate, and the posterior is therefore not guaranteed to be tractable anymore.</p>
</sec>
</sec>
<sec id="sec007">
<title>Hierarchical filter</title>
<p>Let us now analyze the expected behaviour of an agent using a model similar to the one just described, in a steady environment: if all <inline-formula id="pcbi.1006713.e021"><alternatives><graphic id="pcbi.1006713.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>J</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> belong to the same, unknown distribution <italic>p</italic>(<bold>x</bold>|<bold>z</bold>), the value of <inline-formula id="pcbi.1006713.e022"><alternatives><graphic id="pcbi.1006713.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:msub><mml:mi>p</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>∣</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>≤</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> will progressively converge to its true value as the prior (or the previous posterior) over <italic>w</italic> will eventually put a lot of weight on the past experience (i.e. it favours high values of <italic>w</italic>), since the distribution from which <bold>x</bold> is drawn is stationary. We have shown that such models rapidly tend to an overconfident posterior over <italic>w</italic> [<xref ref-type="bibr" rid="pcbi.1006713.ref001">1</xref>]. In practice, when the previous posterior of <italic>w</italic> is confident on the value that <italic>w</italic> should take (i.e. has low variance), it tends to favor updates that reduce variance further, corresponding to values of <italic>p</italic><sub><italic>j</italic></sub>(<italic>w</italic>|<bold>x</bold><sub>≤<italic>j</italic></sub>) that match <italic>p</italic><sub><italic>j</italic>−1</sub>(<italic>w</italic>|<bold>x</bold><sub>&lt;<italic>j</italic></sub>), even if this means ignoring an observed mismatch between <italic>p</italic><sub><italic>j</italic>−1</sub>(<bold>z</bold>|<bold>x</bold><sub>&lt;<italic>j</italic></sub>) and <italic>p</italic><sub><italic>j</italic></sub>(<bold>z</bold>|<bold>x</bold><sub>≤<italic>j</italic></sub>). In order to deal with this issue, we enrich our model by introducing a third level in the hierarchy.</p>
<p>We re-define the prior over <italic>w</italic> as a two-component mixture of priors:
<disp-formula id="pcbi.1006713.e023"><alternatives><graphic id="pcbi.1006713.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e023" xlink:type="simple"/><mml:math display="block" id="M23"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>p</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>;</mml:mo> <mml:mi>b</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≜</mml:mo> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>b</mml:mi></mml:msup> <mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>b</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mi>Z</mml:mi> <mml:mo>(</mml:mo> <mml:mi>b</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
and the full joint probability has the form
<disp-formula id="pcbi.1006713.e024"><alternatives><graphic id="pcbi.1006713.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e024" xlink:type="simple"/><mml:math display="block" id="M24"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>,</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>b</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>;</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">β</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>w</mml:mi></mml:msup> <mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mi>Z</mml:mi> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>b</mml:mi></mml:msup> <mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>b</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mi>Z</mml:mi> <mml:mo>(</mml:mo> <mml:mi>b</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>b</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">β</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
This additional hierarchical level allows the model to forget <italic>w</italic> as a function of observed data (i.e. not at a fixed rate) providing it with the capacity to adapt the approximate posterior distribution over <italic>w</italic> with greater flexibility [<xref ref-type="bibr" rid="pcbi.1006713.ref001">1</xref>]. The latent variable <italic>b</italic> can be seen as a regulizer for <italic>p</italic><sub><italic>j</italic></sub>(<italic>w</italic> ∣ <bold>x</bold><sub>≤<italic>j</italic></sub>).</p>
<p>The prior parameters of the HAFVF and their interpretation is outlined in <xref ref-type="table" rid="pcbi.1006713.t001">Table 1</xref>.</p>
<table-wrap id="pcbi.1006713.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.t001</object-id>
<label>Table 1</label>
<caption>
<title>HAFVF prior parameters in the case of normally distributed variables.</title>
<p>Horizontal lines separate the various levels.</p>
</caption>
<alternatives>
<graphic id="pcbi.1006713.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">General identifier</th>
<th align="left">Parameter</th>
<th align="left">Domain</th>
<th align="left">Name</th>
<th align="left">Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="4"><bold><italic>θ</italic></bold><sub>0</sub></td>
<td align="left"><inline-formula id="pcbi.1006713.e025"><alternatives><graphic id="pcbi.1006713.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:msubsup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn><mml:mi>μ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula></td>
<td align="left"><inline-formula id="pcbi.1006713.e026"><alternatives><graphic id="pcbi.1006713.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mi mathvariant="double-struck">R</mml:mi></mml:math></alternatives></inline-formula></td>
<td align="left">Prior mean</td>
<td align="left">Expected value of the observations</td></tr>
<tr>
<td align="left" style="background-color:#BFBFBF"><inline-formula id="pcbi.1006713.e027"><alternatives><graphic id="pcbi.1006713.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:msubsup><mml:mi>κ</mml:mi><mml:mn>0</mml:mn><mml:mi>μ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula></td>
<td align="left" style="background-color:#BFBFBF"><inline-formula id="pcbi.1006713.e028"><alternatives><graphic id="pcbi.1006713.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:math></alternatives></inline-formula></td>
<td align="left" style="background-color:#BFBFBF">Prior number of observations (over <italic>μ</italic>)</td>
<td align="left" style="background-color:#BFBFBF">Importance of the prior belief of <italic>μ</italic></td></tr>
<tr>
<td align="left"><inline-formula id="pcbi.1006713.e029"><alternatives><graphic id="pcbi.1006713.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:msubsup><mml:mi>α</mml:mi><mml:mn>0</mml:mn><mml:mi>σ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula></td>
<td align="left"><inline-formula id="pcbi.1006713.e030"><alternatives><graphic id="pcbi.1006713.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:math></alternatives></inline-formula></td>
<td align="left">Gamma shape parameter</td>
<td align="left">Importance of the prior belief of <italic>σ</italic></td></tr>
<tr>
<td align="left" style="background-color:#BFBFBF"><inline-formula id="pcbi.1006713.e031"><alternatives><graphic id="pcbi.1006713.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:msubsup><mml:mi>β</mml:mi><mml:mn>0</mml:mn><mml:mi>σ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula></td>
<td align="left" style="background-color:#BFBFBF"><inline-formula id="pcbi.1006713.e032"><alternatives><graphic id="pcbi.1006713.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:math></alternatives></inline-formula></td>
<td align="left" style="background-color:#BFBFBF">Gamma rate parameter</td>
<td align="left" style="background-color:#BFBFBF">Sum of squared residuals</td></tr>
<tr>
<td align="left" rowspan="2"><italic>ϕ</italic><sub>0</sub></td>
<td align="left"><inline-formula id="pcbi.1006713.e033"><alternatives><graphic id="pcbi.1006713.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:msubsup><mml:mi>α</mml:mi><mml:mn>0</mml:mn><mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula></td>
<td align="left"><inline-formula id="pcbi.1006713.e034"><alternatives><graphic id="pcbi.1006713.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:math></alternatives></inline-formula></td>
<td align="left">Beta shape parameter</td>
<td align="left">Stability belief of {<italic>μ</italic>, <italic>σ</italic>}</td></tr>
<tr>
<td align="left" style="background-color:#BFBFBF"><inline-formula id="pcbi.1006713.e035"><alternatives><graphic id="pcbi.1006713.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:msubsup><mml:mi>β</mml:mi><mml:mn>0</mml:mn><mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula></td>
<td align="left" style="background-color:#BFBFBF"><inline-formula id="pcbi.1006713.e036"><alternatives><graphic id="pcbi.1006713.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:math></alternatives></inline-formula></td>
<td align="left" style="background-color:#BFBFBF">Beta shape parameter</td>
<td align="left" style="background-color:#BFBFBF">Volatility belief of {<italic>μ</italic>, <italic>σ</italic>}</td></tr>
<tr>
<td align="left" rowspan="2"><bold><italic>β</italic></bold><sub>0</sub></td>
<td align="left"><inline-formula id="pcbi.1006713.e037"><alternatives><graphic id="pcbi.1006713.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:msubsup><mml:mi>α</mml:mi><mml:mn>0</mml:mn><mml:mi>β</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula></td>
<td align="left"><inline-formula id="pcbi.1006713.e038"><alternatives><graphic id="pcbi.1006713.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:math></alternatives></inline-formula></td>
<td align="left">Beta shape parameter</td>
<td align="left">Stability belief of <italic>w</italic></td></tr>
<tr>
<td align="left" style="background-color:#BFBFBF"><inline-formula id="pcbi.1006713.e039"><alternatives><graphic id="pcbi.1006713.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:msubsup><mml:mi>β</mml:mi><mml:mn>0</mml:mn><mml:mi>β</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula></td>
<td align="left" style="background-color:#BFBFBF"><inline-formula id="pcbi.1006713.e040"><alternatives><graphic id="pcbi.1006713.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:math></alternatives></inline-formula></td>
<td align="left" style="background-color:#BFBFBF">Beta shape parameter</td>
<td align="left" style="background-color:#BFBFBF">Volatility belief of <italic>w</italic></td></tr></tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec008">
<title>Variational Inference</title>
<p>Eqs <xref ref-type="disp-formula" rid="pcbi.1006713.e014">6</xref>–<xref ref-type="disp-formula" rid="pcbi.1006713.e024">10</xref> involve the posterior probability distributions of the parameters given the previous observations. When these quantities have no closed-form formula, two classes of methods can be used to estimate them. Simulation-based algorithms [<xref ref-type="bibr" rid="pcbi.1006713.ref046">46</xref>] such as importance sampling, particle filtering or Markov Chain Monte Carlo, are asymptotically exact but computationally expensive, especially in the present case where the estimate has to be refined at each time step. The other class of methods, approximate inference [<xref ref-type="bibr" rid="pcbi.1006713.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref048">48</xref>], consists in formulating, for a model with parameters <bold>y</bold> and data <bold>x</bold>, an approximate posterior <italic>q</italic>(<bold>y</bold>), that we will use as a proxy to the true posterior <italic>p</italic>(<bold>y</bold>|<bold>x</bold>). Roughly, approximate inference can be partitioned into Expectation Propagation and Variational Bayes (VB) methods. Let us consider in more detail VB, as it is the core engine of our learning model. In VB, optimizing the approximate posterior amounts to computing a lower-bound to the log model evidence (ELBO) <inline-formula id="pcbi.1006713.e041"><alternatives><graphic id="pcbi.1006713.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:mrow><mml:mi mathvariant="script">L</mml:mi> <mml:mo>(</mml:mo> <mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo> <mml:mo>≤</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, whose distance from the true log model evidence can be reduced by gradient descent [<xref ref-type="bibr" rid="pcbi.1006713.ref049">49</xref>]. Hybrid methods, that combine sampling methods with approximate inference, also exist (e.g. Stochastic Gradient Variational Bayes [<xref ref-type="bibr" rid="pcbi.1006713.ref050">50</xref>] or Markov Chain Variational Inference [<xref ref-type="bibr" rid="pcbi.1006713.ref051">51</xref>]). With the use of refined approximate posterior distributions [<xref ref-type="bibr" rid="pcbi.1006713.ref052">52</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref054">54</xref>], they allow for highly accurate estimates of the true posterior with possibly complex, non-conjugate models.</p>
<p>We define a variational distribution over <bold>y</bold> with parameters <bold><italic>υ</italic></bold>: <italic>q</italic>(<bold>y</bold>|<bold><italic>υ</italic></bold>), which we will use as a proxy to the real, but unknown, posterior distribution <italic>p</italic>(<bold>y</bold>|<bold>x</bold>). The two distribution match exactly when their Kullback-Leibler divergences are equal to zero, i.e.
<disp-formula id="pcbi.1006713.e042"><alternatives><graphic id="pcbi.1006713.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e042" xlink:type="simple"/><mml:math display="block" id="M42"><mml:mrow><mml:mtable><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∥</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd columnalign="right"><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mo>⇔</mml:mo></mml:mtd><mml:mtd/><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∥</mml:mo><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd columnalign="right"><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mo>⇔</mml:mo></mml:mtd><mml:mtd/><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd columnalign="right"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives></disp-formula>
where we have omitted the approximate posterior parameters <bold><italic>υ</italic></bold> for sparsity of the expressions. Given some arbitrary constraints on <italic>q</italic>(<bold>y</bold>), we can choose (for mathematical convenience) to reduce <italic>D</italic><sub><italic>KL</italic></sub>[<italic>q</italic>(<bold>y</bold>)||<italic>p</italic>(<bold>y</bold>|<bold>x</bold>)] wrt <italic>q</italic>(<bold>y</bold>). Formally, this can be written as
<disp-formula id="pcbi.1006713.e043"><alternatives><graphic id="pcbi.1006713.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e043" xlink:type="simple"/><mml:math display="block" id="M43"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>q</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:munder><mml:mrow><mml:mtext>arg</mml:mtext> <mml:mspace width="4pt"/><mml:mtext>min</mml:mtext></mml:mrow> <mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:munder><mml:mspace width="4pt"/><mml:msub><mml:mi>D</mml:mi> <mml:mrow><mml:mi>K</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo> <mml:mo>∥</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:munder><mml:mrow><mml:mtext>arg</mml:mtext> <mml:mspace width="4pt"/><mml:mtext>min</mml:mtext></mml:mrow> <mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:munder> <mml:mo>∫</mml:mo> <mml:mi>q</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mfrac><mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:munder><mml:mrow><mml:mtext>arg</mml:mtext> <mml:mspace width="4pt"/><mml:mtext>min</mml:mtext></mml:mrow> <mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:munder> <mml:mo>∫</mml:mo> <mml:mi>q</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>-</mml:mo> <mml:mo>∫</mml:mo> <mml:mi>q</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
<p>We can now substitute log <italic>p</italic>(<bold>y</bold>|<bold>x</bold>) by its rhs in the log-Bayes formula
<disp-formula id="pcbi.1006713.e044"><alternatives><graphic id="pcbi.1006713.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e044" xlink:type="simple"/><mml:math display="block" id="M44"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>D</mml:mi> <mml:mrow><mml:mi>K</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">[</mml:mo> <mml:mi>q</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>∥</mml:mo> <mml:mi>p</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>|</mml:mo> <mml:mi>x</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo stretchy="false">]</mml:mo> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mi>q</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mrow><mml:mi>q</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>-</mml:mo> <mml:mo>∫</mml:mo> <mml:mi>q</mml:mi> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mo stretchy="false">(</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>-</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo stretchy="false">)</mml:mo> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mo>⇔</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mrow><mml:mi>p</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:munder accentunder="true"><mml:mrow><mml:mo>∫</mml:mo> <mml:mi>q</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>-</mml:mo> <mml:mo>∫</mml:mo> <mml:mi>q</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mrow><mml:mi>q</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold">y</mml:mi></mml:mrow> <mml:mo>︸</mml:mo></mml:munder> <mml:mrow><mml:mi mathvariant="script">L</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>q</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder> <mml:mo>+</mml:mo> <mml:msub><mml:mi>D</mml:mi> <mml:mrow><mml:mi>K</mml:mi> <mml:mi>L</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">[</mml:mo> <mml:mi>q</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>∥</mml:mo> <mml:mi>p</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo stretchy="false">]</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula></p>
<p>Because log <italic>p</italic>(<bold>x</bold>) does not depend on the model parameters, it is fixed for a given dataset. Therefore, as we maximize <inline-formula id="pcbi.1006713.e045"><alternatives><graphic id="pcbi.1006713.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:mrow><mml:mi mathvariant="script">L</mml:mi> <mml:mo>(</mml:mo> <mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1006713.e044">Eq 11</xref>, we decrease the divergence <italic>D</italic><sub><italic>KL</italic></sub>[<italic>q</italic>(<bold>y</bold>)||<italic>p</italic>(<bold>y</bold>|<bold>x</bold>)] between the approximate and the true posterior. When a maximum is reached, we can consider that (1) we have obtained the most accurate approximate posterior given our initial assumptions about <italic>q</italic>(<bold>y</bold>) and (2) <inline-formula id="pcbi.1006713.e046"><alternatives><graphic id="pcbi.1006713.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:mrow><mml:mi mathvariant="script">L</mml:mi> <mml:mo>(</mml:mo> <mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> provides a lower bound to log <italic>p</italic>(<bold>x</bold>). It should be noted here that the more <italic>q</italic>(<bold>y</bold>) is flexible, the closer we can hope to get from the true posterior, but this is generally at the expense of tractability and/or computational resources.</p>
<p>The ELBO in <xref ref-type="disp-formula" rid="pcbi.1006713.e044">Eq 11</xref> is the sum of the expected log joint probability and the entropy of the approximate posterior. In order for the former to be tractable, one must carefully choose the form of the approximate posterior. The Mean-field assumption we have made allows us to select, for each factor of the approximate posteriors, a distribution with the same form as their conjugate prior, which is the best possible configuration in this context [<xref ref-type="bibr" rid="pcbi.1006713.ref055">55</xref>].</p>
<p>Applying now this approach to <xref ref-type="disp-formula" rid="pcbi.1006713.e024">Eq 10</xref>, our spherical approximate posterior looks like:
<disp-formula id="pcbi.1006713.e047"><alternatives><graphic id="pcbi.1006713.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e047" xlink:type="simple"/><mml:math display="block" id="M47"><mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>,</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>b</mml:mi> <mml:mo>)</mml:mo> <mml:mo>≜</mml:mo> <mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>)</mml:mo> <mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:mi>ϕ</mml:mi> <mml:mo>)</mml:mo> <mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi>b</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold-italic">β</mml:mi> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></p>
<p>In addition, in order to recursively estimate the current posterior probability of the model parameters given the past, we make the natural approximation that the true previous posterior can be substituted by its variational approximation:
<disp-formula id="pcbi.1006713.e048"><alternatives><graphic id="pcbi.1006713.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e048" xlink:type="simple"/><mml:math display="block" id="M48"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:msub><mml:mi>q</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(12)</label></disp-formula>
and similarly for <italic>p</italic>(<italic>w</italic>|<bold>x</bold><sub>&lt;<italic>j</italic></sub>) and <italic>p</italic>(<italic>b</italic>|<bold>x</bold><sub>&lt;<italic>j</italic></sub>). The use of this distribution as a proxy to the posterior greatly simplifies the optimization of <italic>q</italic><sub><italic>j</italic></sub>(<bold>z</bold>, <italic>w</italic>, <italic>b</italic>).</p>
<p>The full, approximate joint probability distribution at time <italic>j</italic> therefore looks like
<disp-formula id="pcbi.1006713.e049"><alternatives><graphic id="pcbi.1006713.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e049" xlink:type="simple"/><mml:math display="block" id="M49"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>,</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>b</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>≈</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mfrac><mml:mrow><mml:msub><mml:mi>q</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>w</mml:mi></mml:msup> <mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mi>Z</mml:mi> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>q</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>b</mml:mi></mml:msup> <mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>b</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mi>Z</mml:mi> <mml:mo>(</mml:mo> <mml:mi>b</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mi>q</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>b</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>β</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <bold><italic>θ</italic></bold><sub><italic>j</italic>−1</sub>, <italic>ϕ</italic><sub><italic>j</italic>−1</sub> and <bold><italic>β</italic></bold><sub><italic>j</italic>−1</sub> are the variational parameters at the last trial for <bold>z</bold>, <italic>w</italic> and <italic>b</italic> respectively. A further advantage of the approximation made in <xref ref-type="disp-formula" rid="pcbi.1006713.e048">Eq 12</xref> is that the prior of <bold>z</bold> and w simplifies elegantly:
<disp-formula id="pcbi.1006713.e050"><alternatives><graphic id="pcbi.1006713.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e050" xlink:type="simple"/><mml:math display="block" id="M50"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>,</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>b</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>≈</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:mi>w</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>×</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1.em"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:mi>b</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>b</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>β</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula>
(see Appendix A for the full derivation).</p>
<p>A conjugate distribution for <italic>p</italic>(<italic>w</italic>) is hard to find. Šmìdl and Quinn [<xref ref-type="bibr" rid="pcbi.1006713.ref056">56</xref>] propose a uniform prior and a truncated exponential approximate posterior over <italic>w</italic>. They interpolate the normalizing constant between two fixed value of <italic>w</italic>, which allows them to perform closed-form updates of this parameter. Here, we chose <italic>p</italic>(<italic>w</italic>|<italic>ϕ</italic><sub>0</sub>) and <italic>q</italic>(<italic>w</italic>|<italic>ϕ</italic><sub><italic>j</italic></sub>) to be both beta distributions, a choice that does not impair our ability to perform closed-form updates of the variational parameters as we will see in the Update equation section.</p>
<p>In this model (see <xref ref-type="fig" rid="pcbi.1006713.g002">Fig 2</xref>), named the Hierarchical Adaptive Forgetting Variational Filter [<xref ref-type="bibr" rid="pcbi.1006713.ref001">1</xref>], specific prior configurations will bend the learning process to categorize surprising events either as contingency changes, or as accidents. In contrast with other models [<xref ref-type="bibr" rid="pcbi.1006713.ref057">57</xref>], <italic>w</italic> and <italic>b</italic> are represented with a rich probability distribution where both the expected values and variances have an impact on the model’s behaviour. For a given prior belief on <bold>z</bold>, a confident prior over <italic>w</italic>, centered on high values of this parameter, will lead to a lack of flexibility that would not be observed with a less confident prior, even if they have the same expectation.</p>
<fig id="pcbi.1006713.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Directed Acyclic Graph of the HAFVF model.</title>
<p>Plain circles represent observed variables, white circles represent latent variables and dots represents prior distribution parameters. Dashed circles and dashed arrows represent approximate posteriors and approximate posterior dependencies. A weighted prior latent node is highlighed.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g002" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec009">
<title>The critic: HAFVF as a reinforcement learning algorithm</title>
<p>Application of this scheme of learning to the RL case is straightforward, if one considers <inline-formula id="pcbi.1006713.e051"><alternatives><graphic id="pcbi.1006713.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>j</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>J</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> as being the observed rewards and <bold>z</bold> as the parameters of the distribution of these rewards. In the following, we will assume that the agent models a normally distributed state-action reward function <italic>x</italic><sub><italic>j</italic></sub> = <italic>r</italic>(<italic>s</italic>, <italic>a</italic>), from which she tries to estimate the posterior distribution natural parameters <bold>z</bold> ≜ <bold><italic>η</italic></bold>(<italic>μ</italic>(<italic>s</italic>, <italic>a</italic>), <italic>σ</italic>(<italic>s</italic>, <italic>a</italic>)) where <bold><italic>η</italic></bold>(⋅) is the natural parameter vector of the normal distribution. In this context, an intuitive choice for the prior (and the approximate posterior) of these parameters is a Normal Inverse-Gamma distribution (<inline-formula id="pcbi.1006713.e053"><alternatives><graphic id="pcbi.1006713.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e053" xlink:type="simple"/><mml:math display="inline" id="M53"><mml:msup><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mi mathvariant="script">G</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>): for the prior, we have
<disp-formula id="pcbi.1006713.e054"><alternatives><graphic id="pcbi.1006713.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e054" xlink:type="simple"/><mml:math display="block" id="M54"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mn>0</mml:mn> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mfrac><mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msubsup><mml:mi>κ</mml:mi> <mml:mn>0</mml:mn> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∼</mml:mo> <mml:msup><mml:mi mathvariant="script">G</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>α</mml:mi> <mml:mn>0</mml:mn> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mn>0</mml:mn> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
and the approximate posterior can be defined similarly with a normal component <inline-formula id="pcbi.1006713.e055"><alternatives><graphic id="pcbi.1006713.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e055" xlink:type="simple"/><mml:math display="inline" id="M55"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>j</mml:mi> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mfrac><mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msubsup><mml:mi>κ</mml:mi> <mml:mi>j</mml:mi> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and a gamma component <inline-formula id="pcbi.1006713.e056"><alternatives><graphic id="pcbi.1006713.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:mrow><mml:msup><mml:mi mathvariant="script">G</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>α</mml:mi> <mml:mi>j</mml:mi> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mi>j</mml:mi> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<sec id="sec010">
<title>Update equation</title>
<p>Even though the model is not formally conjugate, the use of a mixture of priors with exponential weights makes the variational update equations easy to implement for the first level. Let us first assert a few basic principles from the Mean-Field Variational Inference framework: it can be shown that, under the assumption that the approximate posterior factorizes in <italic>q</italic>(<italic>y</italic><sub>1</sub> <italic>y</italic><sub>2</sub>) = <italic>q</italic>(<italic>y</italic><sub>1</sub>)<italic>q</italic>(<italic>y</italic><sub>2</sub>), then the optimal distribution <italic>q</italic>*(<italic>y</italic><sub>1</sub>) given our current estimate of <italic>q</italic>(<italic>y</italic><sub>2</sub>) is given by
<disp-formula id="pcbi.1006713.e057"><alternatives><graphic id="pcbi.1006713.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e057" xlink:type="simple"/><mml:math display="block" id="M57"><mml:mrow><mml:msup><mml:mi>q</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mtext>exp</mml:mtext> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo> <mml:mo>-</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>Z</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives> <label>(14)</label></disp-formula>
where log <italic>Z</italic> is some log-normalizer that does not depend on <bold>y</bold>. <xref ref-type="disp-formula" rid="pcbi.1006713.e057">Eq 14</xref> states that each set of variational parameters can be updated independently given the current value of the others: this usually lead to an approach similar to EM [<xref ref-type="bibr" rid="pcbi.1006713.ref046">46</xref>], where one iterates through the updates of variational posterior successively until convergence.</p>
<p>Fortunately, thanks to the conjugate form of the lower level of the HAFVF, <xref ref-type="disp-formula" rid="pcbi.1006713.e057">Eq 14</xref> can be unpacked to a form that recalls <xref ref-type="disp-formula" rid="pcbi.1006713.e015">Eq 7</xref> where the update of the variational parameters of <bold>z</bold> reads:
<disp-formula id="pcbi.1006713.e058"><alternatives><graphic id="pcbi.1006713.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e058" xlink:type="simple"/><mml:math display="block" id="M58"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mo>[</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ϑ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>ξ</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">T</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>ϑ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>η</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives> <label>(15)</label></disp-formula>
where
<disp-formula id="pcbi.1006713.e059"><alternatives><graphic id="pcbi.1006713.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e059" xlink:type="simple"/><mml:math display="block" id="M59"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ϑ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>≜</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:mi>w</mml:mi> <mml:mo>]</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
is the weighted prior of <bold>z</bold> (see Appendix A). This update scheme can be mapped onto and be interpreted in terms of Q-learning [<xref ref-type="bibr" rid="pcbi.1006713.ref043">43</xref>] (see Appendix B). Again, <inline-formula id="pcbi.1006713.e060"><alternatives><graphic id="pcbi.1006713.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e060" xlink:type="simple"/><mml:math display="inline" id="M60"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>ϑ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>η</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> is the updated <italic>effective memory</italic> of the subject, which is bounded on the long term by the (approximate) <italic>efficient memory</italic> <inline-formula id="pcbi.1006713.e061"><alternatives><graphic id="pcbi.1006713.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e061" xlink:type="simple"/><mml:math display="inline" id="M61"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:mi>w</mml:mi> <mml:mo>]</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. One can indeed see that the actual efficient memory, which reads
<disp-formula id="pcbi.1006713.e062"><alternatives><graphic id="pcbi.1006713.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e062" xlink:type="simple"/><mml:math display="block" id="M62"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi></mml:mrow></mml:mfrac> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mfrac><mml:mrow><mml:msup><mml:mi>α</mml:mi> <mml:mi>ϕ</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:msup><mml:mi>β</mml:mi> <mml:mi>ϕ</mml:mi></mml:msup> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mi>b</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>b</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mtext>undefined</mml:mtext></mml:mtd> <mml:mtd columnalign="left"><mml:mtext>otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable> <mml:mo/></mml:mrow></mml:math></alternatives></disp-formula>
is undefined when <italic>b</italic> ≤ 1. To solve this issue, we used the first order Taylor approximation
<disp-formula id="pcbi.1006713.e063"><alternatives><graphic id="pcbi.1006713.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e063" xlink:type="simple"/><mml:math display="block" id="M63"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi></mml:mrow></mml:mfrac> <mml:mo>]</mml:mo> <mml:mo>≈</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:mi>w</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></disp-formula>
which is a biased but consistent estimator of the efficient memory, as it approaches its true value for large values of <italic>ϕ</italic>.</p>
<p>More specifically, for the approximate posterior of a single observation stream <inline-formula id="pcbi.1006713.e064"><alternatives><graphic id="pcbi.1006713.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e064" xlink:type="simple"/><mml:math display="inline" id="M64"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>J</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> with corresponding parameters <inline-formula id="pcbi.1006713.e065"><alternatives><graphic id="pcbi.1006713.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e065" xlink:type="simple"/><mml:math display="inline" id="M65"><mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>α</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, we can apply this principle easily, as the resulting distribution has the form of a <inline-formula id="pcbi.1006713.e066"><alternatives><graphic id="pcbi.1006713.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e066" xlink:type="simple"/><mml:math display="inline" id="M66"><mml:msup><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mi mathvariant="script">G</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> with parameters:
<disp-formula id="pcbi.1006713.e067"><alternatives><graphic id="pcbi.1006713.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e067" xlink:type="simple"/><mml:math display="block" id="M67"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msubsup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>κ</mml:mi> <mml:mrow><mml:mn>0</mml:mn></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mrow><mml:mn>0</mml:mn></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup></mml:mrow> <mml:msubsup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msubsup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msubsup><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>κ</mml:mi> <mml:mrow><mml:mn>0</mml:mn></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>α</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mi>σ</mml:mi></mml:msubsup></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msubsup><mml:mi>α</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>α</mml:mi> <mml:mrow><mml:mn>0</mml:mn></mml:mrow> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mi>j</mml:mi></mml:mrow> <mml:mi>σ</mml:mi></mml:msubsup></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msub><mml:mi>β</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mn>0</mml:mn></mml:mrow> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msub><mml:mi>κ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>j</mml:mi> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>κ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>j</mml:mi> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mn>0</mml:mn> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>j</mml:mi> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
where we have used <inline-formula id="pcbi.1006713.e068"><alternatives><graphic id="pcbi.1006713.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e068" xlink:type="simple"/><mml:math display="inline" id="M68"><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:mi>w</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>Deriving updates for the approximate posterior over the mixture weights <italic>w</italic> and <italic>b</italic> is more challenging, as the optimal approximate posterior in <xref ref-type="disp-formula" rid="pcbi.1006713.e057">Eq 14</xref> does not have the same form as the beta prior due to the non-conjugacy of the model. Fortunately, non-conjugate variational message passing (NCVMP) [<xref ref-type="bibr" rid="pcbi.1006713.ref058">58</xref>] can be used in this context. In short, NCVMP minimizes an approximate KL divergence in order to find the value of the approximate posterior parameters that maximize the ELBO. Although NCVMP convergence is not guaranteed, this issue can be somehow alleviated by damping of the updates (i.e. updating the variational parameters to a value lying in between the previous value they endorsed and the value computed using NCVMP, see [<xref ref-type="bibr" rid="pcbi.1006713.ref058">58</xref>] for more details). The need for a closed-form formula of the expected log-joint probability constitutes another obstacle for the naive implementation of NCVMP to the present problem: indeed, computing the expected value of the log-partition functions log <italic>Z</italic>(<italic>w</italic>) and log <italic>Z</italic>(<italic>b</italic>) involves a weighted sum of the past variational parameters <bold><italic>θ</italic></bold><sub><italic>j</italic>−1</sub> and the prior <bold><italic>θ</italic></bold><sub>0</sub>, which are known, with a weight <italic>w</italic>, which is unknown. Expectation of this expression given <italic>q</italic>(<italic>w</italic>) does not, in general, have an analytical expression. To solve this problem, we used the second order Taylor expansion around <inline-formula id="pcbi.1006713.e069"><alternatives><graphic id="pcbi.1006713.e069g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e069" xlink:type="simple"/><mml:math display="inline" id="M69"><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> (see Appendix A).</p>
<p>The derivation of the update equations of <italic>ϕ</italic> and <bold><italic>β</italic></bold> can be found in [<xref ref-type="bibr" rid="pcbi.1006713.ref001">1</xref>].</p>
</sec>
<sec id="sec011">
<title>Counterfactual learning</title>
<p>As an agent performs a series of choices in an environment, she must also keep track of the actions not chosen and update her belief accordingly: ideally, the variance of the approximate posterior of the reward function associated with a given action should increase when that action is not selected, to reflect the increased uncertainty about its outcome during the period when no outcome was observed. This requirement implies counterfactual learning capability [<xref ref-type="bibr" rid="pcbi.1006713.ref059">59</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref061">61</xref>].</p>
<p>Two options will be considered here: the first option consists in updating the approximate posterior parameters of the non-selected action at each time step with an update scheme that pulls the approximate posterior progressively towards the prior <bold><italic>θ</italic></bold><sub>0</sub>, with a speed that depends on <italic>w</italic>, i.e. as a function of the belief the agent has about environment stability. The second approach will consist in updating the approximate posterior of the actions only when they are actually selected, but accounting for past trials during which that action was not selected. The mathematical details of these approaches are detailed in Appendix C.</p>
</sec>
<sec id="sec012">
<title>Delayed updating</title>
<p>Even though the agent learns only actions that are selected, it can adapt its learning rate as a function of how distant in the past was the last time the action was selected. Formally, this approach considers that <italic>if</italic> the posterior probability had been updated at each time step and the forgetting factor <italic>w</italic> had been stable, <italic>then</italic> the impact of the observations <italic>n</italic> trials back in time would currently have an influence that would decrease geometrically with a rate <italic>ω</italic> ≜ <italic>w</italic><sup><italic>n</italic></sup>. We can then substitute the prior over <bold>z</bold> by:
<disp-formula id="pcbi.1006713.e071"><alternatives><graphic id="pcbi.1006713.e071g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e071" xlink:type="simple"/><mml:math display="block" id="M71"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi></mml:mrow> <mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>)</mml:mo> <mml:mo>≜</mml:mo></mml:mrow> <mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>ω</mml:mi></mml:msup> <mml:mi>p</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>ω</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mi>Z</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ω</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(17)</label></disp-formula>
which is identical to <xref ref-type="disp-formula" rid="pcbi.1006713.e019">Eq 8</xref> except that <italic>w</italic> has been substituted by <italic>ω</italic>.</p>
<p>We name this strategy <italic>Delayed Approximate Posterior Updating</italic>.</p>
</sec>
<sec id="sec013">
<title>Continuous updating</title>
<p>When an action is not selected, the agent can infer what value it would have had given the observed stability of the environment. In practice, this is done by updating the variational parameters of the selected <italic>and</italic> non-selected action using the observed reward for the former, and the expected reward and variance of this reward for the latter.</p>
<p>This approach can be beneficial for the agent in order to optimize her exploration/exploitation balance. In Appendix C.1, it is shown that if the agent has the prior belief that the reward variance is high, then the probability of exploring the non-chosen option will increase as the lag between the current trial and the last observation of the reward associated with this option increases.</p>
<p>This feature makes this approach intuitively more suited for exploration among multiple alternatives in changing environments, and we therefore selected it for the simulations achieved in this paper.</p>
</sec>
<sec id="sec014">
<title>Temporal difference learning</title>
<p>An important feature required for an efficient Model-Free RL algorithm is to be able to account for future rewards in order to make choices that might seem suboptimal to a myopic agent, but that make sense on the long run. This is especially useful when large rewards (or the avoidance of large punishments) can be expected in a near future.</p>
<p>In order to do this, one can simply sum the expected value of the next state to the current reward in order to perform the update of the reward distribution parameters. However, because the evolution of the environment is somehow chaotic, it is usually considered wiser to decay slightly the future rewards by a discount rate <italic>γ</italic>. This mechanism is in accordance with many empirical observations of animal behaviours [<xref ref-type="bibr" rid="pcbi.1006713.ref062">62</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref064">64</xref>], neurophysiological processes [<xref ref-type="bibr" rid="pcbi.1006713.ref065">65</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref067">67</xref>] and theories [<xref ref-type="bibr" rid="pcbi.1006713.ref068">68</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref070">70</xref>].</p>
<p>As the optimal value of <italic>γ</italic> is unknown to the agent, we can assume that she will try to estimate its posterior distribution from the data as she does for the mean and variance of the reward function. Appendix D shows how this can be implemented in the current context. An example of TD learning in a changing environment is given in the TD learning with the HAFVF section.</p>
<p>We now focus on the problem of decision making under the HAFVF.</p>
</sec>
</sec>
<sec id="sec015">
<title>The actor: Decision making under the HAFVF</title>
<sec id="sec016">
<title>Bayesian policy</title>
<p>In a stable environment where the distribution of the action values are known precisely, the optimal choice (i.e. the choice that will maximize reward on the long run) is the choice with the maximum expected value: indeed, it is easy to see that if <inline-formula id="pcbi.1006713.e072"><alternatives><graphic id="pcbi.1006713.e072g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e072" xlink:type="simple"/><mml:math display="inline" id="M72"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow/></mml:msub> <mml:mo>[</mml:mo> <mml:mi>r</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo> <mml:mo>&gt;</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow/></mml:msub> <mml:mo>[</mml:mo> <mml:mi>r</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, then <inline-formula id="pcbi.1006713.e073"><alternatives><graphic id="pcbi.1006713.e073g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e073" xlink:type="simple"/><mml:math display="inline" id="M73"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow/></mml:msub> <mml:mo>[</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>n</mml:mi></mml:msub> <mml:msub><mml:mi>r</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo> <mml:mo>&gt;</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow/></mml:msub> <mml:mo>[</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>n</mml:mi></mml:msub> <mml:msub><mml:mi>r</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> (here and for the next few paragraphs, we will restrict our analysis to the case of single stage tasks, and omit the <italic>s</italic> input in the reward function). However, in the context of a volatile environment, the agent has no certainty that the reward function has not changed since the last time she visited this state, and she has no precise estimate of the reward distribution. This should motivate her to devote part of her choices to exploration rather than exploitation. In a randomly changing environment, there is no general, optimal balance between the two, as there is no way to know how similar is the environment wrt the last trials. The best thing an agent can do is therefore to update her current policy wrt her current estimate of the uncertainty of the latent state of the environment.</p>
<p>Various policies have been proposed in order to use the Bayesian belief the agent has about its environment to make a decision that maximizes expected rewards in the long run. Here we will focus more particularly on Q-value sampling, or Q-sampling (QS) [<xref ref-type="bibr" rid="pcbi.1006713.ref071">71</xref>]. Note that we use the terminology Q-value sampling in accordance with Dearden [<xref ref-type="bibr" rid="pcbi.1006713.ref044">44</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref071">71</xref>], but one should recall that QS is virtually indistinguishable from Thompson sampling [<xref ref-type="bibr" rid="pcbi.1006713.ref072">72</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref073">73</xref>]. Our framework can also be connected to another algorithm used in the study of animal RL [<xref ref-type="bibr" rid="pcbi.1006713.ref074">74</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref075">75</xref>], based on the Value of Perfect Information (VPI) [<xref ref-type="bibr" rid="pcbi.1006713.ref044">44</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref076">76</xref>], which we describe in Appendix E.</p>
<p>QS [<xref ref-type="bibr" rid="pcbi.1006713.ref071">71</xref>] is an exploration policy based on the posterior predictive probability that an action value exceeds all the other actions available:
<disp-formula id="pcbi.1006713.e074"><alternatives><graphic id="pcbi.1006713.e074g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e074" xlink:type="simple"/><mml:math display="block" id="M74"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≜</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>=</mml:mo> <mml:munder><mml:mrow><mml:mtext>arg</mml:mtext> <mml:mspace width="4pt"/><mml:mtext>max</mml:mtext></mml:mrow> <mml:mi mathvariant="bold">a</mml:mi></mml:munder><mml:mspace width="4pt"/><mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:mi>p</mml:mi> <mml:mspace width="-0.166667em"/><mml:mo>(</mml:mo> <mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>&gt;</mml:mo> <mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>a</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mo>∀</mml:mo> <mml:msup><mml:mi>a</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>¬</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(18)</label></disp-formula>
The expectation of <xref ref-type="disp-formula" rid="pcbi.1006713.e074">Eq 18</xref> provides a clear policy to the agent. The QS approach is compelling in our case: in general, the learning algorithm we propose will produce a trial-wise posterior probability that should, most of the time, be easy to sample from.</p>
<p>In bandit tasks, the policy dictated by QS is optimal provided that the subject has an equal knowledge of all the options she has. If the environment is only partly and unequally explored, the value of some actions may be overestimated (or underestimated), in which case QS will fail to detect that exploration might be beneficial. QS can lead to the same policy in a context where two actions (<italic>a</italic><sub>1</sub> and <italic>a</italic><sub>2</sub>) have similar uncertainty associated with their reward distributions (<italic>σ</italic><sub>1</sub> = <italic>σ</italic><sub>2</sub>) but different means (<italic>μ</italic><sub>1</sub> &gt; <italic>μ</italic><sub>2</sub>), and in a context where one action has a much larger expected reward (<italic>μ</italic><sub>1</sub> ≫ <italic>μ</italic><sub>2</sub>) but also larger uncertainty (<italic>σ</italic><sub>1</sub> ≫ <italic>σ</italic><sub>2</sub>) (see [<xref ref-type="bibr" rid="pcbi.1006713.ref044">44</xref>] for an example). This can be sub-optimal, as the action with the larger uncertainty could lead to a higher (or lower) reward than expected: in this specific case, choosing the action with the largest expected reward should be even more encouraged due to the lack of of knowledge about its true reward distribution, which might be much higher than expected. A strategy to solve this problem is to give to each action value a bonus, the Value of Perfect Information, that reflects the expected information gain that will follow the selection of an action. This approach, and its relationship to our algorithm, is discussed in Appendix E.</p>
</sec>
<sec id="sec017">
<title>Q-sampling as a stochastic process</title>
<p>Let us get back to the case of QS, and consider an agent solving this problem using a gambler ruin strategy [<xref ref-type="bibr" rid="pcbi.1006713.ref077">77</xref>]. We assume that, in the case of a two-alternative forced choice task, this agent has equal initial expectations that either <italic>a</italic><sub>1</sub> or <italic>a</italic><sub>2</sub> will lead to the highest reward, represented by a start point <italic>z</italic><sub>0</sub> = <italic>ζ</italic>/2, where <italic>ζ</italic> will be described shortly. The gambler ruin process works as follows: this agent samples a value <inline-formula id="pcbi.1006713.e075"><alternatives><graphic id="pcbi.1006713.e075g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e075" xlink:type="simple"/><mml:math display="inline" id="M75"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mspace width="-0.166667em"/><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>∼</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and a value <inline-formula id="pcbi.1006713.e076"><alternatives><graphic id="pcbi.1006713.e076g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e076" xlink:type="simple"/><mml:math display="inline" id="M76"><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mspace width="-0.166667em"/><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∼</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and assess which one is higher. If <inline-formula id="pcbi.1006713.e077"><alternatives><graphic id="pcbi.1006713.e077g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e077" xlink:type="simple"/><mml:math display="inline" id="M77"><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mspace width="-0.166667em"/><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> beats <inline-formula id="pcbi.1006713.e078"><alternatives><graphic id="pcbi.1006713.e078g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e078" xlink:type="simple"/><mml:math display="inline" id="M78"><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mspace width="-0.166667em"/><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, she computes the number of wins of <italic>a</italic><sub>1</sub> until now as <italic>z</italic><sub>1</sub> = <italic>z</italic><sub>0</sub> + 1, and displaces her belief the other way (<italic>z</italic><sub>0</sub>−1) if <italic>a</italic><sub>2</sub> beats <italic>a</italic><sub>1</sub>. Then, she starts again and moves in the direction indicated by sign(<italic>r</italic>(<italic>a</italic><sub>1</sub>) − <italic>r</italic>(<italic>a</italic><sub>2</sub>)) until she reaches one of the two arbitrary thresholds situated at 0 or <italic>ζ</italic> that symbolize the two actions available. It is easy to see that the number of wins and losses generated by this procedure gives a Monte Carlo sample of <italic>p</italic>(<italic>r</italic>(<italic>a</italic><sub>1</sub>) &gt; <italic>r</italic>(<italic>a</italic><sub>2</sub>)|<bold>x</bold><sub>&lt;<italic>j</italic></sub>). We show in Appendix F.1 that this process tends to deteministically select the best option as the threshold grows.</p>
<p>So far, we have studied the gambler ruin problem as a discrete process. If the interval between the realization of two samples tends to 0, this accumulation of evidence can be approximated by a continuous stochastic process [<xref ref-type="bibr" rid="pcbi.1006713.ref077">77</xref>]. When the rewards are normally distributed, as in the present case, this results in a Wiener process, or Drift-Diffusion model (DDM, [<xref ref-type="bibr" rid="pcbi.1006713.ref078">78</xref>]), since the difference between two normally distributed random variables follows a normal distribution. This stochastic accumulation model has a displacement rate (drift) that is given by
<disp-formula id="pcbi.1006713.e079"><alternatives><graphic id="pcbi.1006713.e079g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e079" xlink:type="simple"/><mml:math display="block" id="M79"><mml:mrow><mml:mi>d</mml:mi> <mml:mfrac><mml:mi>z</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>+</mml:mo> <mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
see [<xref ref-type="bibr" rid="pcbi.1006713.ref079">79</xref>].</p>
<p>Crucially, it enjoys the same convergence property of selecting almost surely the best option for high thresholds (see Appendix F.2).</p>
</sec>
<sec id="sec018">
<title>Sequential Q-sampling as a Full-DDM model</title>
<p>This simple case of a fixed-parameters DDM, however, is not the one we have to deal with, as the agent does not know the true value of {<italic>μ</italic>(<italic>a</italic>), <italic>σ</italic><sup>2</sup>(<italic>a</italic>)}<sub><italic>a</italic>∈<bold>a</bold></sub>, but she can only approximate it based on her posterior estimate. Assuming that the approximate posterior over the latent mean and variance of the reward distribution is a <inline-formula id="pcbi.1006713.e080"><alternatives><graphic id="pcbi.1006713.e080g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e080" xlink:type="simple"/><mml:math display="inline" id="M80"><mml:msup><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mi mathvariant="script">G</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> distribution, and keeping the original statement <inline-formula id="pcbi.1006713.e081"><alternatives><graphic id="pcbi.1006713.e081g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e081" xlink:type="simple"/><mml:math display="inline" id="M81"><mml:mrow><mml:mi>d</mml:mi> <mml:mfrac><mml:mi>X</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, we have
<disp-formula id="pcbi.1006713.e082"><alternatives><graphic id="pcbi.1006713.e082g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e082" xlink:type="simple"/><mml:math display="block" id="M82"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>d</mml:mi> <mml:mfrac><mml:mi>X</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mover><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msubsup><mml:mover><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mover><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>where</mml:mtext> <mml:mspace width="4.pt"/></mml:mrow></mml:mtd> <mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msubsup><mml:mover><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd> <mml:mtd><mml:mo>∼</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>i</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>/</mml:mo> <mml:msubsup><mml:mi>κ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:msup><mml:mi mathvariant="script">G</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>α</mml:mi> <mml:mi>i</mml:mi> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mi>i</mml:mi> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="1.em"/></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4.pt"/><mml:mtext>for</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>2</mml:mn> <mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mo>⇔</mml:mo></mml:mtd> <mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mover><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd> <mml:mtd><mml:mo>∼</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mn>1</mml:mn> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mn>2</mml:mn> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>κ</mml:mi> <mml:mn>1</mml:mn> <mml:mi>μ</mml:mi></mml:msubsup></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>κ</mml:mi> <mml:mn>2</mml:mn> <mml:mi>μ</mml:mi></mml:msubsup></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd/></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="right"><mml:msubsup><mml:mover><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:msubsup></mml:mtd> <mml:mtd><mml:mo>∼</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="script">G</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>α</mml:mi> <mml:mn>1</mml:mn> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mn>1</mml:mn> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd/></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="right"><mml:msubsup><mml:mover><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mn>2</mml:mn></mml:msubsup></mml:mtd> <mml:mtd><mml:mo>∼</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="script">G</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>α</mml:mi> <mml:mn>2</mml:mn> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mn>2</mml:mn> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(19)</label></disp-formula>
and where, for the sake of sparsity of the notation, the indices are used to indicate the corresponding action-related variable.</p>
<p>To see how such evidence accumulation process evolves, one can discretize <xref ref-type="disp-formula" rid="pcbi.1006713.e082">Eq 19</xref>: this would be equivalent to sample at each time <italic>t</italic> a displacement
<disp-formula id="pcbi.1006713.e083"><alternatives><graphic id="pcbi.1006713.e083g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e083" xlink:type="simple"/><mml:math display="block" id="M83"><mml:mrow><mml:mo>Δ</mml:mo> <mml:mi>x</mml:mi> <mml:mo>=</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.166667em"/><mml:mover><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:msqrt><mml:mrow><mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msqrt> <mml:mspace width="0.166667em"/><mml:mover><mml:mrow><mml:mi>ς</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mspace width="0.166667em"/><mml:mi>ϵ</mml:mi></mml:mrow></mml:math></alternatives> <label>(20)</label></disp-formula>
where Δ<italic>x</italic> stands for <italic>x</italic><sub><italic>t</italic></sub> − <italic>x</italic><sub><italic>t</italic>−1</sub>. The drift <inline-formula id="pcbi.1006713.e084"><alternatives><graphic id="pcbi.1006713.e084g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e084" xlink:type="simple"/><mml:math display="inline" id="M84"><mml:mover><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover></mml:math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1006713.e083">Eq 20</xref> is sampled as the difference between two sampled means <inline-formula id="pcbi.1006713.e085"><alternatives><graphic id="pcbi.1006713.e085g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e085" xlink:type="simple"/><mml:math display="inline" id="M85"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mover><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and the squared noise <inline-formula id="pcbi.1006713.e086"><alternatives><graphic id="pcbi.1006713.e086g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e086" xlink:type="simple"/><mml:math display="inline" id="M86"><mml:msup><mml:mover><mml:mrow><mml:mi>ς</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msup></mml:math></alternatives></inline-formula> is sampled as the sum of the two sampled variances <inline-formula id="pcbi.1006713.e087"><alternatives><graphic id="pcbi.1006713.e087g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e087" xlink:type="simple"/><mml:math display="inline" id="M87"><mml:mrow><mml:msubsup><mml:mover><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mover><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. At each time step (or at each trial, quite similarly as we will show), the tuple of parameters <inline-formula id="pcbi.1006713.e088"><alternatives><graphic id="pcbi.1006713.e088g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e088" xlink:type="simple"/><mml:math display="inline" id="M88"><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mover><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msubsup><mml:mover><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mover><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is drawn from the current posterior distribution.</p>
<p>Hereafter, we will refer to this process as the Normal-Inverse-Gamma Diffusion Process, or <italic>NIGDM</italic>.</p>
</sec>
<sec id="sec019">
<title>NIGDM as an exploration rule</title>
<p>Importantly, and similarly to QS, this process has the desired property of selecting actions with a probability proportional to their probability of being the best option. This favours exploratory behaviour since, assuming equivalent expected rewards, actions that are associated with large reward uncertainty will tend to be selected more often. We show that the NIGDM behaves like QS in Appendix F.3. There, it is shown (Proposition 3) that, as the threshold grows, the NIGDM choice pattern resembles more and more the QS algorithm. For lower values of the threshold, this algorithm is less accurate than QS (see further discussion of the property of NIGDM for low thresholds in Appendix E).</p>
</sec>
<sec id="sec020">
<title>Cognitive cost optimization under the AC-HAFVF</title>
<p>Algorithm 2 summarizes the AC-HAFVF model. This model ties together a learning algorithm—that adapts how fast it forgets its past knowledge on the basis of its assessment of the stability of the environment—with a decision algorithm that makes full use of the posterior uncertainty of the reward distribution to balance exploration and exploitation.</p>
<p>Importantly, these algorithms make time and resource costs explicit: for instance, time constraints can make decisions less accurate, because they will require a lower decision threshold. <xref ref-type="fig" rid="pcbi.1006713.g003">Fig 3</xref> illustrates this interpretation of the AC-HAFVF by showing how accuracy and speed of the model vary as a function of the variance of the reward estimates: the cognitive cost of making a decision using the AC-HAFVF is high when the agent is uncertain about the reward mean (low <italic>κ</italic><sub><italic>j</italic></sub>) but has a low expectation of the variance (low <italic>β</italic><sub><italic>j</italic></sub>). In these situations, the choices were also more random, allowing the agent to explore the environment. Decisions are easier to make when the difference in mean rewards is clearer or when the rewards were more noisy.</p>
<fig id="pcbi.1006713.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Simulated policies for the AC-HAFVF as a function of reward variance <italic>β</italic><sub><italic>j</italic></sub> and number of effective observations <italic>κ</italic><sub><italic>j</italic></sub>, for a fixed value of posterior mean rewards (<italic>μ</italic><sub>1</sub> = −<italic>μ</italic><sub>2</sub> = 1), shape parameter <italic>α</italic><sub>1</sub> = <italic>α</italic><sub>2</sub> = 3 threshold <italic>ζ</italic> = 2, start point <italic>z</italic><sub>0</sub> = <italic>ζ</italic>/2 and <italic>τ</italic> = 0.</title>
<p><bold>A</bold>. Choices were more random for more noisy reward distributions (i.e. high values of <italic>β</italic><sub><italic>j</italic></sub>) and for mean estimates with a higher variance (i.e. with a lower number of observations <italic>κ</italic><sub><italic>j</italic></sub>). <bold>B</bold>. Decisions were faster when the difference of the means was clearer (high <italic>κ</italic><sub><italic>j</italic></sub>) and when the reward distributions was noisy (high <italic>β</italic>). Subjects were slower to decide what to do for noisy mean values but precise rewards, reflecting the high cognitive cost of the decision process in these situations.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g003" xlink:type="simple"/>
</fig>
<p>Besides the decision stage, the computational cost of the inference step can also be determined. To this end, one must first consider that the HAFVF updates the variational posterior using a natural gradient-based [<xref ref-type="bibr" rid="pcbi.1006713.ref080">80</xref>] approach with a Fisher preconditioning matrix [<xref ref-type="bibr" rid="pcbi.1006713.ref058">58</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref081">81</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref082">82</xref>]: the learner computes a gradient of the ELBO wrt the variational parameters, then moves in the direction of this gradient with a step length proportional to the posterior variance of the loss function. Because of this, the divergence between the true posterior probability <italic>p</italic>(<bold>z</bold>|<bold>x</bold><sub>≤<italic>j</italic></sub>) and the prior probability <italic>p</italic>(<bold>z</bold>) (i.e. the mixture of the default distribution and previous posterior) conditions directly the expected number of updates required for the approximate posterior to converge to a minimum <italic>D</italic><sub><italic>KL</italic></sub>[<italic>q</italic>||<italic>p</italic>] (see for instance [<xref ref-type="bibr" rid="pcbi.1006713.ref083">83</xref>]). Also, in a more frequentist perspective and at the between-trial time scale, convergence rate of the posterior probability towards the true (if any) model configuration is faster when the KL divergence between this posterior and the prior is small [<xref ref-type="bibr" rid="pcbi.1006713.ref084">84</xref>]: in other words, in a stable environment, a higher confidence in past experience will require less observations for the same rate of convergence, because it will tighten the distance between the prior and posterior at each time step.</p>
<p>These three aspects of computational cost (for decision, for within-trial inference and for across-trial inference) can justify the choice (or emergence) of lower flexible behaviours as they ultimately maximize the reward rate [<xref ref-type="bibr" rid="pcbi.1006713.ref074">74</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref085">85</xref>]: indeed, such strategies will lead in a stable environment to faster decisions, to faster inference at each time step and to a more stable and accurate posterior.</p>
<p><bold>Algorithm 2</bold>: AC-HAFVF. For simplicity, the NIGDM process has been discretized.</p>
<p specific-use="line"> <bold>input</bold>: prior belief {<bold><italic>θ</italic></bold><sub>0</sub>, <italic>ϕ</italic><sub>0</sub>, <bold><italic>β</italic></bold><sub>0</sub>}</p>
<p specific-use="line">1 <bold>for</bold> <italic>j</italic> = 1 <bold><italic>to</italic></bold> <italic>J</italic> <bold>do</bold></p>
<p specific-use="line">2  <bold>Actor</bold>: <italic>NIGDM</italic>;</p>
<p specific-use="line">  <bold>input</bold>: Start point <italic>z</italic><sub>0</sub>, threshold <italic>ζ</italic>, non-decision time <italic>τ</italic></p>
<p specific-use="line">3  <italic>k</italic> ← 0;</p>
<p specific-use="line">4  sample <inline-formula id="pcbi.1006713.e129"><alternatives><graphic id="pcbi.1006713.e129g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e129" xlink:type="simple"/><mml:math display="inline" id="M129"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi><mml:mi>μ</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>κ</mml:mi><mml:mi>i</mml:mi><mml:mi>μ</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="script">G</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mi>i</mml:mi><mml:mi>σ</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mi>i</mml:mi><mml:mi>σ</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> for <italic>i</italic> = {1, 2};</p>
<p specific-use="line">5  <bold>while</bold> 0 &lt; <italic>z</italic><sub><italic>k</italic></sub> &lt; <italic>ζ</italic> <bold>do</bold></p>
<p specific-use="line">6   <italic>k</italic> += 1;</p>
<p specific-use="line">7   sample <inline-formula id="pcbi.1006713.e130"><alternatives><graphic id="pcbi.1006713.e130g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e130" xlink:type="simple"/><mml:math display="inline" id="M130"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>;</p>
<p specific-use="line">8   move <italic>z</italic><sub><italic>k</italic></sub> += <italic>δ</italic><sub><italic>z</italic></sub>;</p>
<p specific-use="line">9  <bold>end</bold></p>
<p specific-use="line">10  select <inline-formula id="pcbi.1006713.e131"><alternatives><graphic id="pcbi.1006713.e131g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e131" xlink:type="simple"/><mml:math display="inline" id="M131"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>←</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mspace width="4pt"/><mml:mi>z</mml:mi><mml:mi>k</mml:mi><mml:mspace width="4pt"/><mml:mo>≥</mml:mo><mml:mi>ζ</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mn>2</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>otherwise</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>;</p>
<p specific-use="line">11  Get reward <italic>r</italic><sub><italic>j</italic></sub> = <italic>r</italic>(<italic>s</italic><sub><italic>j</italic></sub>, <italic>a</italic><sub><italic>j</italic></sub>), Observe transition <italic>s</italic><sub><italic>j</italic>+1</sub> = <italic>j</italic>(<italic>s</italic><sub><italic>j</italic></sub>, <italic>a</italic><sub><italic>j</italic></sub>);</p>
<p specific-use="line">12  </p>
<p specific-use="line">13  <bold>Critic</bold>: <italic>HAFVF</italic>;</p>
<p specific-use="line">14  <italic>ELBO</italic> ← −∞;</p>
<p specific-use="line">15  <bold>while</bold> |<italic>δ</italic><sub><italic>L</italic></sub>| ≤ 10<sup>−3</sup> <bold>do</bold></p>
<p specific-use="line">16   update <inline-formula id="pcbi.1006713.e132"><alternatives><graphic id="pcbi.1006713.e132g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e132" xlink:type="simple"/><mml:math display="inline" id="M132"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>arg</mml:mtext><mml:mspace width="4pt"/><mml:msub><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> using CVMP;</p>
<p specific-use="line">17   update {<italic>ϕ</italic><sub><italic>j</italic></sub>, <italic>β</italic><sub><italic>j</italic></sub>} using NCVMP;</p>
<p specific-use="line">18   <inline-formula id="pcbi.1006713.e133"><alternatives><graphic id="pcbi.1006713.e133g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e133" xlink:type="simple"/><mml:math display="inline" id="M133"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>←</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:mi>L</mml:mi><mml:mi>B</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>;</p>
<p specific-use="line">19   <inline-formula id="pcbi.1006713.e134"><alternatives><graphic id="pcbi.1006713.e134g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e134" xlink:type="simple"/><mml:math display="inline" id="M134"><mml:mrow><mml:mi>E</mml:mi><mml:mi>L</mml:mi><mml:mi>B</mml:mi><mml:mi>O</mml:mi><mml:mo>←</mml:mo><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>;</p>
<p specific-use="line">20  <bold>end</bold></p>
<p specific-use="line">21 <bold>end</bold></p>
</sec>
</sec>
<sec id="sec021">
<title>Fitting the AC-HAFVF</title>
<p>So far, we have provided all the necessary tools to simulate behavioural data using the AC-HAFVF. It is now necessary to show how to fit model parameters to an acquired dataset. We will first describe how this can be done in a Maximum Likelihood framework, before generalizing this method to Bayesian inference using variational methods.</p>
<p>The problem of fitting the AC-HAFVF to a dataset can be seen as a State-Space model fitting problem. We consider the following family of models:
<disp-formula id="pcbi.1006713.e089"><alternatives><graphic id="pcbi.1006713.e089g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e089" xlink:type="simple"/><mml:math display="block" id="M89"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd/><mml:mtd columnalign="right"><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:munder><mml:munder accentunder="true"><mml:mrow><mml:mi>f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>︸</mml:mo></mml:munder> <mml:mrow><mml:mi>H</mml:mi> <mml:mi>A</mml:mi> <mml:mi>F</mml:mi> <mml:mi>V</mml:mi> <mml:mi>F</mml:mi></mml:mrow></mml:munder></mml:mtd> <mml:mtd/></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="right"><mml:msub><mml:mi mathvariant="bold">y</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mtd> <mml:mtd><mml:mo>∼</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:munder><mml:munder accentunder="true"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mspace width="0.166667em"/><mml:mo>|</mml:mo> <mml:mspace width="0.166667em"/></mml:mrow> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:msub> <mml:mo>[</mml:mo> <mml:mi>W</mml:mi> <mml:mi>i</mml:mi> <mml:mi>e</mml:mi> <mml:mi>n</mml:mi> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>︸</mml:mo></mml:munder> <mml:mrow><mml:mi>N</mml:mi> <mml:mi>I</mml:mi> <mml:mi>G</mml:mi> <mml:mi>D</mml:mi> <mml:mi>M</mml:mi></mml:mrow></mml:munder></mml:mtd> <mml:mtd/></mml:mtr></mml:mtable></mml:mrow> <mml:mo/></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4.pt"/><mml:mtext>where</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">κ</mml:mi></mml:mrow> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mi>μ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">α</mml:mi></mml:mrow> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mi>σ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">β</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mi>J</mml:mi> <mml:mo>,</mml:mo> <mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4.pt"/><mml:mtext>and</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi mathvariant="bold">y</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mtext>t</mml:mtext> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mi>J</mml:mi> <mml:mo>,</mml:mo> <mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(21)</label></disp-formula>
and t<sub><italic>j</italic>,<italic>n</italic></sub> stands for the reaction time associated with the state-action pair (<italic>s</italic>, <italic>a</italic>) of the subject <italic>n</italic> at the trial <italic>j</italic>. Unlike many State-Space models, we have made the assumption in <xref ref-type="disp-formula" rid="pcbi.1006713.e089">Eq 21</xref> that the transition model <bold>Ω</bold><sub><italic>j</italic>,<italic>n</italic></sub> = <italic>f</italic>(<bold>Ω</bold><sub><italic>j</italic>−1,<italic>n</italic></sub>, <bold>Ω</bold><sub>0,<italic>n</italic></sub>, <bold>x</bold><sub><italic>j</italic>−1,<italic>n</italic></sub>) is entirely deterministic given the subject prior <bold>Ω</bold><sub>0,<italic>n</italic></sub> and the observations <bold>x</bold><sub>&lt;<italic>j</italic></sub>, which is in accordance with the model of decision making presented in the The actor: Decision making under the HAFVF section. Note that the Bayesian procedure we will adopt hereafter is formally identical to considering that the drift and noise are drawn according to the rules defined in the The actor: Decision making under the HAFVF section, making this model equivalent to:
<disp-formula id="pcbi.1006713.e090"><alternatives><graphic id="pcbi.1006713.e090g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e090" xlink:type="simple"/><mml:math display="block" id="M90"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi mathvariant="bold">y</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>∼</mml:mo> <mml:mi>W</mml:mi> <mml:mi>i</mml:mi> <mml:mi>e</mml:mi> <mml:mi>n</mml:mi> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mo>(</mml:mo> <mml:mover><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover><mml:mrow><mml:mi>ς</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover><mml:mrow><mml:mi>ς</mml:mi></mml:mrow> <mml:mo>∼</mml:mo></mml:mover></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>∼</mml:mo> <mml:mi>f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
<p>Quite importantly, we have made the assumption in <xref ref-type="disp-formula" rid="pcbi.1006713.e089">Eq 21</xref> that the threshold, the non-decision time and the start-point were fixed for each subject throughout the experiment. This is a strong assumption, that might be relaxed in practice. To simplify the analysis, and because it is not a mandatory feature of the model exposed above, we do not consider this possibility here and leave it for further developments.</p>
<p>We can now treat the problem of fitting the AC-HAFVF to behavioural data as two separate sub-problems: first, we will need to derive a differentiable function that, given an initial prior <bold>Ω</bold><sub>0,<italic>n</italic></sub> and a set of observations <bold>x</bold><sub><italic>n</italic></sub> produces a sequence <inline-formula id="pcbi.1006713.e091"><alternatives><graphic id="pcbi.1006713.e091g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e091" xlink:type="simple"/><mml:math display="inline" id="M91"><mml:mrow><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mi>n</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>J</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, and second (Maximum a Posteriori estimate of the AC-HAFVF section) a function that computes the probability of the observed behaviour given the current variational parameters.</p>
<sec id="sec022">
<title>Maximum a Posteriori estimate of the AC-HAFVF</title>
<p>The update equations described in the Update equation section enable us to generate a differentiable sequence of approximate posterior parameters <bold>Ω</bold><sub><italic>j</italic>,<italic>n</italic></sub> given some prior <bold>Ω</bold><sub>0,<italic>n</italic></sub> and a sequence of choices-rewards <bold>x</bold>. We can therefore reduce <xref ref-type="disp-formula" rid="pcbi.1006713.e089">Eq 21</xref> to a loss function of the form
<disp-formula id="pcbi.1006713.e092"><alternatives><graphic id="pcbi.1006713.e092g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e092" xlink:type="simple"/><mml:math display="block" id="M92"><mml:mrow><mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">y</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>≤</mml:mo> <mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>;</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
whose gradient wrt <bold>Ω</bold><sub>0,<italic>n</italic></sub> can be efficiently computed using the chain rule:
<disp-formula id="pcbi.1006713.e093"><alternatives><graphic id="pcbi.1006713.e093g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e093" xlink:type="simple"/><mml:math display="block" id="M93"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mo>∇</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msub> <mml:mspace width="-0.166667em"/><mml:mo>{</mml:mo> <mml:mrow><mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">y</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>;</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo> <mml:mo>=</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="2.em"/><mml:msub><mml:mo>∇</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msub><mml:msup><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mi>f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>≤</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:msub><mml:mo>∇</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msub> <mml:mspace width="-0.166667em"/><mml:mo>{</mml:mo> <mml:mrow><mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">y</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="2.em"/><mml:mspace width="4.pt"/><mml:mtext>where</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>≤</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Recall that <inline-formula id="pcbi.1006713.e094"><alternatives><graphic id="pcbi.1006713.e094g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e094" xlink:type="simple"/><mml:math display="inline" id="M94"><mml:mrow><mml:msub><mml:mo>∇</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msub> <mml:mspace width="-0.166667em"/><mml:msup><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mi>f</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>≤</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> is the jacobian (i.e. matrix of partial derivative) of <bold>Ω</bold><sub><italic>j</italic>,<italic>n</italic></sub> wrt each of the elements of <bold>Ω</bold><sub>0,<italic>n</italic></sub> that are optimized, and <inline-formula id="pcbi.1006713.e095"><alternatives><graphic id="pcbi.1006713.e095g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e095" xlink:type="simple"/><mml:math display="inline" id="M95"><mml:mrow><mml:msub><mml:mo>∇</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msub> <mml:mspace width="-0.166667em"/><mml:mo>{</mml:mo> <mml:mrow><mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">y</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ζ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:mi>n</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the gradient of the loss function (i.e. the NIGDM) wrt the output of <italic>f</italic>(⋅).</p>
<p>As the variational updates that lead to the evaluation of <bold>Ω</bold><sub><italic>j</italic>,<italic>n</italic></sub> are differentiable, the use of VB makes it possible to use automatic Differentiation to compute the Jacobian of <bold>Ω</bold><sub><italic>j</italic>,<italic>n</italic></sub> wrt <bold>Ω</bold><sub>0,<italic>n</italic></sub>.</p>
<p>The next step, is to derive the loss function log <italic>p</italic>(<bold>y</bold><sub><italic>j</italic>,<italic>n</italic></sub>|<bold>Ω</bold><sub><italic>j</italic>,<italic>n</italic></sub>, <italic>ζ</italic><sub><italic>n</italic></sub>, <italic>z</italic><sub>0</sub><sub><italic>n</italic></sub>, <italic>τ</italic><sub><italic>n</italic></sub>). In this log-probability density function, the local, trial-wise parameters
<disp-formula id="pcbi.1006713.e096"><alternatives><graphic id="pcbi.1006713.e096g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e096" xlink:type="simple"/><mml:math display="block" id="M96"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">χ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>≜</mml:mo> <mml:mo>{</mml:mo> <mml:msub><mml:mi>ξ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mspace width="-0.166667em"/><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mo>λ</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mspace width="-0.166667em"/><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives> <label>(22)</label></disp-formula>
have been marginalized out. This makes its evaluation hard to implement with conventional techniques. Variational methods can be used to retrieve an approximate Maximum A Posteriori (MAP) in these cases [<xref ref-type="bibr" rid="pcbi.1006713.ref086">86</xref>]. The method is detailed in Appendix G. Briefly, VB is used to compute a lower bound (<italic>ℓ</italic><sub><italic>j</italic>,<italic>n</italic></sub> ≤ log <italic>p</italic>(<bold>y</bold><sub><italic>j</italic>,<italic>n</italic></sub>|<bold>Ω</bold><sub><italic>j</italic>,<italic>n</italic></sub>, <italic>ζ</italic><sub><italic>n</italic></sub>, <italic>z</italic><sub>0</sub><sub><italic>n</italic></sub>, <italic>τ</italic><sub><italic>n</italic></sub>)) to the marginal posterior probability described above for each trial. Instead of optimizing each variational parameters independently, we optimize the parameters <bold><italic>ρ</italic></bold> of an inference network [<xref ref-type="bibr" rid="pcbi.1006713.ref087">87</xref>] that maps the current HAFVF approximate posterior parameters <bold>Ω</bold><sub><italic>j</italic>,<italic>n</italic></sub> and the data <bold>y</bold><sub><italic>j</italic>,<italic>n</italic></sub> to each trial-specific approximate posterior. This amortizes greatly the cost of the optimization (hence the name Amortized Variational Inference), as the nonlinear mapping (e.g. multilayered perceptron) <italic>h</italic>(<bold>y</bold><sub><italic>j</italic>,<italic>n</italic></sub>;<bold><italic>ρ</italic></bold>) can provide the approximate posterior parameters of any datapoint, even if it has not been observed yet. We chose <italic>q</italic><sub><bold><italic>ρ</italic></bold></sub>(<italic>χ</italic><sub><italic>j</italic>,<italic>n</italic></sub>|<bold>y</bold><sub><italic>j</italic>,<italic>n</italic></sub>) to be a multivariate Gaussian distribution, which leads to the following form of variational posterior:
<disp-formula id="pcbi.1006713.e097"><alternatives><graphic id="pcbi.1006713.e097g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e097" xlink:type="simple"/><mml:math display="block" id="M97"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>q</mml:mi> <mml:mi mathvariant="bold-italic">ρ</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">χ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold">y</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>≜</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">χ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mo>Σ</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">χ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>where</mml:mtext> <mml:mspace width="4.pt"/><mml:msup><mml:mi>μ</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">χ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>L</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">χ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msup></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>h</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">y</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>;</mml:mo> <mml:mi mathvariant="bold-italic">ρ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(23)</label></disp-formula>
and <inline-formula id="pcbi.1006713.e098"><alternatives><graphic id="pcbi.1006713.e098g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e098" xlink:type="simple"/><mml:math display="inline" id="M98"><mml:msup><mml:mi>L</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">χ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msup></mml:math></alternatives></inline-formula> is the lower Cholesky factor of <inline-formula id="pcbi.1006713.e099"><alternatives><graphic id="pcbi.1006713.e099g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e099" xlink:type="simple"/><mml:math display="inline" id="M99"><mml:msup><mml:mo>Σ</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">χ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msup></mml:math></alternatives></inline-formula>. Another consideration is that, in order to use the multivariate normal approximate posterior, the unbounded variances sample <inline-formula id="pcbi.1006713.e100"><alternatives><graphic id="pcbi.1006713.e100g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e100" xlink:type="simple"/><mml:math display="inline" id="M100"><mml:mrow><mml:msup><mml:mo>λ</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:mspace width="0.166667em"/><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> must be transformed to an unbounded space. We used the inverse softplus transform λ ≜ log(exp(⋅) − 1), as this function has a bounded gradient, in contrasts with the exponential mapping, which prevents numerical overflow. We found that this simple trick could regularize greatly the optimization process. However, this transformation of the normally distributed λ<sup>−1</sup>(⋅) variables requires us to correct the ELBO by the log-determinant of the Jacobian of the transform [<xref ref-type="bibr" rid="pcbi.1006713.ref054">54</xref>], which for the sofplus transform of <italic>x</italic> is simply <inline-formula id="pcbi.1006713.e101"><alternatives><graphic id="pcbi.1006713.e101g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e101" xlink:type="simple"/><mml:math display="inline" id="M101"><mml:mrow><mml:mrow><mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mo>|</mml:mo> <mml:mi>δ</mml:mi></mml:mrow> <mml:mfrac><mml:mrow><mml:mo>λ</mml:mo> <mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>δ</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:mfrac> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mtext>log</mml:mtext></mml:mrow> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mtext>exp</mml:mtext> <mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>The same transformation can be used for the parameters of <bold><italic>θ</italic></bold><sub>0</sub> that are required to be greater than 0 (i.e. all parameters except <italic>μ</italic><sub>0</sub>), which obviously do not require any log-Jacobian correction.</p>
<p>In <xref ref-type="disp-formula" rid="pcbi.1006713.e096">Eq 22</xref>, we have made explicit the fact that we used the three latent variables: the drift rate and the two action-specific noise parameters. This is due to the fact that, unfortunately, the distribution of the sum of two Inverse-Gamma distributed random variables does not have a closed form formula, making the use of single random variable <inline-formula id="pcbi.1006713.e102"><alternatives><graphic id="pcbi.1006713.e102g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e102" xlink:type="simple"/><mml:math display="inline" id="M102"><mml:mrow><mml:msubsup><mml:mi>ς</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> challenging, whereas it can be done easily for <italic>ξ</italic><sub><italic>j</italic>,<italic>n</italic></sub> = <italic>μ</italic><sub><italic>j</italic>,<italic>n</italic></sub>(<italic>a</italic><sub>1</sub>) − <italic>μ</italic><sub><italic>j</italic>,<italic>n</italic></sub>(<italic>a</italic><sub>2</sub>), which is normally distributed (see <xref ref-type="disp-formula" rid="pcbi.1006713.e082">Eq 19</xref>).</p>
<p>The final step to implement a MAP estimation algorithm is to set a prior for the parameters of the model. We used a simple L2 regularization scheme, which consists trivially in a normal prior <inline-formula id="pcbi.1006713.e103"><alternatives><graphic id="pcbi.1006713.e103g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e103" xlink:type="simple"/><mml:math display="inline" id="M103"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> over all parameters, mapped onto an unbounded space if needed.</p>
<p>Algorithm 3 shows how the full optimization proceeds.</p>
<p><bold>Algorithm 3</bold>: MAP estimate of AC-HAFVF parameters.</p>
<p specific-use="line"> <bold>input</bold>: Data <bold>x</bold> = {<italic>r</italic><sub><italic>j</italic>,<italic>n</italic></sub>, <bold>y</bold><sub><italic>j</italic>,<italic>n</italic></sub> for <italic>j</italic> = 1 <bold>to</bold> <italic>J</italic>, <italic>n</italic> = 1 <bold>to</bold> <italic>N</italic>}</p>
<p specific-use="line">1 <bold>initialize</bold> <bold>Ω</bold><sub><italic>n</italic></sub> = {<bold><italic>θ</italic></bold><sub>0</sub>, <italic>ϕ</italic><sub>0</sub>, <bold><italic>β</italic></bold><sub>0</sub>}<sub><italic>n</italic></sub> <bold>for</bold> <italic>n</italic> = 1 <bold>to</bold> <italic>N</italic> and IN<sup>§</sup> weights <bold><italic>ρ</italic></bold>;</p>
<p specific-use="line">2 <bold>repeat</bold></p>
<p specific-use="line">3  set <italic>L</italic> ← 0;</p>
<p specific-use="line">4  <bold>for</bold> <italic>n</italic> = 1 <bold><italic>to</italic></bold> <italic>N</italic> <bold>do</bold></p>
<p specific-use="line">5   Set <inline-formula id="pcbi.1006713.e135"><alternatives><graphic id="pcbi.1006713.e135g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e135" xlink:type="simple"/><mml:math display="inline" id="M135"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mo>∼</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">ρ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>;</p>
<p specific-use="line">6   <bold>for</bold> <italic>j</italic> = 1 <bold><italic>to</italic></bold> <italic>J</italic> <bold>do</bold></p>
<p specific-use="line">7    <bold>Learning Step</bold>: <italic>HAFVF</italic>;</p>
<p specific-use="line">8    Get <bold>Ω</bold><sub><italic>j</italic>,<italic>n</italic></sub> = <italic>f</italic>(<bold>Ω</bold><sub><italic>j</italic>−1,<italic>n</italic></sub>, <bold>Ω</bold><sub>0,<italic>n</italic></sub>, <bold>x</bold><sub><italic>j</italic>−1,<italic>n</italic></sub>)</p>
<p specific-use="line">9     and Jacobian wrt <bold>Ω</bold><sub>0,<italic>n</italic></sub>: <inline-formula id="pcbi.1006713.e136"><alternatives><graphic id="pcbi.1006713.e136g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e136" xlink:type="simple"/><mml:math display="inline" id="M136"><mml:mrow><mml:msub><mml:mo>∇</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mo>{</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>≤</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> using FAD*;</p>
<p specific-use="line">10    <bold>Decision Step</bold>: <italic>HAFVF</italic>;</p>
<p specific-use="line">11    Get ELBO <italic>ℓ</italic><sub><italic>j</italic>,<italic>n</italic></sub> of <inline-formula id="pcbi.1006713.e137"><alternatives><graphic id="pcbi.1006713.e137g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e137" xlink:type="simple"/><mml:math display="inline" id="M137"><mml:mrow><mml:mtext>log</mml:mtext><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext mathvariant="bold">y</mml:mtext><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:msub><mml:mn>0</mml:mn><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> using AVI<sup>†</sup>;</p>
<p specific-use="line">12     and corresponding gradient <inline-formula id="pcbi.1006713.e138"><alternatives><graphic id="pcbi.1006713.e138g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e138" xlink:type="simple"/><mml:math display="inline" id="M138"><mml:mrow><mml:msub><mml:mo>∇</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">ρ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>{</mml:mo><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> using RAD<sup>‡</sup>;</p>
<p specific-use="line">13    Increment <italic>L</italic> += <italic>ℓ</italic><sub><italic>j</italic>,<italic>n</italic></sub>;</p>
<p specific-use="line">14    Compute gradient wrt <bold>Ω</bold><sub>0,<italic>n</italic></sub> using the chain rule:</p>
<p specific-use="line">15     <inline-formula id="pcbi.1006713.e139"><alternatives><graphic id="pcbi.1006713.e139g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e139" xlink:type="simple"/><mml:math display="inline" id="M139"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mo>∼</mml:mo></mml:mover><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mo>+</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mo>∇</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mo>{</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>≤</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo><mml:msub><mml:mo>∇</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mo>{</mml:mo><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>;</p>
<p specific-use="line">16    Increment gradient of DDM and IN parameters</p>
<p specific-use="line">17     <inline-formula id="pcbi.1006713.e140"><alternatives><graphic id="pcbi.1006713.e140g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e140" xlink:type="simple"/><mml:math display="inline" id="M140"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mo>∼</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">ρ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mo>∇</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>{</mml:mo><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>;</p>
<p specific-use="line">18   <bold>end</bold></p>
<p specific-use="line">19   L2-norm regularization:</p>
<p specific-use="line">20    <inline-formula id="pcbi.1006713.e141"><alternatives><graphic id="pcbi.1006713.e141g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e141" xlink:type="simple"/><mml:math display="inline" id="M141"><mml:mrow><mml:mi>L</mml:mi><mml:mo>+</mml:mo><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>;</p>
<p specific-use="line">21    <inline-formula id="pcbi.1006713.e142"><alternatives><graphic id="pcbi.1006713.e142g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e142" xlink:type="simple"/><mml:math display="inline" id="M142"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mo>∼</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>;</p>
<p specific-use="line">22  <bold>end</bold></p>
<p specific-use="line">23  Perform gradient step <inline-formula id="pcbi.1006713.e143"><alternatives><graphic id="pcbi.1006713.e143g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e143" xlink:type="simple"/><mml:math display="inline" id="M143"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">ρ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mover><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mo>∼</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">ρ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> for a small <italic>η</italic>;</p>
<p specific-use="line">24 <bold>until</bold> <italic>Some convergence criterion is met</italic>;</p>
<p specific-use="line"><sup>§</sup> IN = Inference Network, * FAD = Forward Automatic Differenciation, <sup>†</sup> AVI = Amortized Variational Inference, <sup>‡</sup> RAD = Reverse Automatic Differentiation (i.e. backpropagation).</p>
</sec>
</sec>
</sec>
<sec id="sec023" sec-type="results">
<title>Results</title>
<p>We now present four simulated examples of the (AC-)HAFVF in various contexts. The first example compares the performance of the HAFVF to the HGF [<xref ref-type="bibr" rid="pcbi.1006713.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref024">24</xref>] in a simple contingency change scenario. The second example provides various case scenarios in a changing environment, illustrating the trade-off between flexibility and the precision of the predictions (Learning and flexibility assessment section), including cases where agents fail to adapt to contingency changes following prolonged training in a stable environment, as commonly observed in behavioural experiments [<xref ref-type="bibr" rid="pcbi.1006713.ref005">5</xref>]. The third example shows that the HAFVF can be efficiently fitted to a RL dataset using the method described in Fitting the AC-HAFVF section. The fourth and final example shows how this model behaves in multi-stage environments, and compares various implementations.</p>
<sec id="sec024">
<title>Adaptation to contingency changes and comparison with the HGF</title>
<p>In order to compare the performance of our model to the HGF, we generated a simple dataset consisting of a noisy square-wave signal of two periods of 200 trials, alternating between two normally distributed random variables (<inline-formula id="pcbi.1006713.e104"><alternatives><graphic id="pcbi.1006713.e104g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e104" xlink:type="simple"/><mml:math display="inline" id="M104"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>33</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006713.e105"><alternatives><graphic id="pcbi.1006713.e105g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e105" xlink:type="simple"/><mml:math display="inline" id="M105"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>33</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>). We fitted both a Gaussian HGF and the HAFVF to this simple dataset by finding the MAP parameter configuration for both models. The default configuration of the HGF was used, whereas in our case we put a normal hyperprior of <inline-formula id="pcbi.1006713.e106"><alternatives><graphic id="pcbi.1006713.e106g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e106" xlink:type="simple"/><mml:math display="inline" id="M106"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> on the parameters (with inverse softplus transform for parameters needing positive domains).</p>
<p>This fit constituted the first part of our experiment, which is displayed on the left part of <xref ref-type="fig" rid="pcbi.1006713.g004">Fig 4</xref>. We compared the quadratic approximations of the Maximum Log-model evidences [<xref ref-type="bibr" rid="pcbi.1006713.ref088">88</xref>] for both models, which for the HAFVF reads
<disp-formula id="pcbi.1006713.e107"><alternatives><graphic id="pcbi.1006713.e107g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e107" xlink:type="simple"/><mml:math display="block" id="M107"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">β</mml:mi> <mml:mn>0</mml:mn> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>∣</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>J</mml:mi></mml:munderover> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>w</mml:mi> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:msub><mml:mi>q</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">z</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1.em"/><mml:mo>-</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>Z</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>b</mml:mi> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:msub><mml:mi>q</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>b</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1.em"/><mml:mo>-</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>Z</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>b</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>q</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>b</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">β</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">β</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>M</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mn>2</mml:mn> <mml:mi>π</mml:mi> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:msup><mml:mrow><mml:mo>|</mml:mo> <mml:mo>-</mml:mo> <mml:mi>H</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic>H</italic> is the hessian of the log-joint at the mode and <italic>M</italic> is the number of parameters of the model. We found a value of -186.42 for HAVFV and -204.73 for the HGF, making the HAVFV a better model of the data, with a Bayes Factor [<xref ref-type="bibr" rid="pcbi.1006713.ref089">89</xref>] greater than 8 * 10<sup>7</sup>.</p>
<fig id="pcbi.1006713.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g004</object-id>
<label>Fig 4</label>
<caption>
<title>HAFVF and HGF performance on the same dataset.</title>
<p>Shaded areas represent the ±3 standard error interval. The two models were fitted to the first 400 trials, and then tested on the whole trace of observations. <bold>A</bold>. Observations, mean and standard error of the mean estimated by both models. <bold>B</bold>. The variance estimates show that the HAFVF adapted better to the variance in the first part of the experiment, reflected better the surprise at the contingency change and adapted successfully its estimate when the environment was highly stable. The HGF, on the contrary, rapidly degenerated its estimate of the variance, and did not show a significant trace of surprise when the contingency was altered. <bold>C</bold>. The value of the effective memory of the HAVFV is represented by the approximate posterior parameter <italic>κ</italic><sub><italic>μ</italic></sub>, and the maximum memory (efficient memory, see Bayesian Q-Learning and the problem of flexibility) allowed by the model at each trial.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g004" xlink:type="simple"/>
</fig>
<p>The second part of the experiment consisted in adding to this 400-trial signal a 1200-trial signal of input situated at <italic>y</italic> = 5. We evaluated for both models the quality of the fit obtained when using the parameter configurations resulting from the fit of the first part of the experiment (first 400 trials, or training dataset) (<xref ref-type="fig" rid="pcbi.1006713.g004">Fig 4</xref>, right part), on the remaining dataset (following 1200 trials, i.e. testing dataset). An optimal agent in such a situation should first account for the surprise associated with the sudden contingency change, and then progressively reduce its expected variance estimate to reflect the steadiness of the environment. We considered the capacity of both models to account for new data for a given parameter configuration as a measure of their flexibility. This test was motivated by the observation that a change detection algorithm has to be able to detect changes at test time that might be qualitatively different from changes at training time. A financial crisis is for instance an event that is in essence singular and unseen in the past (otherwise it would have been prevented). The algorithm should nevertheless be able to detect it efficiently.</p>
<p>The HGF was unable to exhibit the expected behaviour: it hardly adapted its estimated variance to the contingency change and did not adjust it significantly afterwards. This contrasted with the HAFVF, in which we observed initially an increase in the variance estimate at the point of contingency change (reflecting a high surprise), followed by progressively decreasing variance estimate, reflecting the adaptation of the model to the newly stable environment.</p>
<p>Together, these results are informative of the comparative performance of the two algorithms. The Maximum Log-model Evidence was larger for the HAFVF than for the HGF by several orders of magnitude, showing that our approach modelled better the data at hand than the HGF. Moreover, the lack of generalization of the HGF to a simple, new signal not used to fit the parameters, shows that this model tended to overfit the data, as can be seen from the estimated variance at the time of the contingency change.</p>
<p>Importantly, this capability of the HAFVF to account for unseen volatility changes did not need to be instructed through the selection of the model hyperparameters: it is a built in feature of the model.</p>
</sec>
<sec id="sec025">
<title>Learning and flexibility assessment</title>
<p>In the following datasets, we simulated the learning process of four hypothetical subjects differing in their prior distribution parameters <italic>ϕ</italic><sub>0</sub>, <bold><italic>β</italic></bold><sub>0</sub>, whereas we kept <bold><italic>θ</italic></bold><sub>0</sub> fixed for all of them (<xref ref-type="table" rid="pcbi.1006713.t002">Table 2</xref>). The choice of the subject parameters was made to generate limit and opposite cases of each expected behaviour. With these simulations, we aimed at showing how the prior belief on the two levels of forgetting conditioned the adaptation of the subject in case of contingency change (CC, <bold>Experiment 1</bold>) or isolated expected event (<bold>Experiment 2</bold>).</p>
<table-wrap id="pcbi.1006713.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.t002</object-id>
<label>Table 2</label>
<caption>
<title>This table summarizes the parameters of the beta prior of the two forgetting factors <italic>w</italic> and <italic>b</italic> used in the Learning and flexibility assessment section, as well as the initial prior over the mean and variance.</title>
<p>A low value of initial number of observations <italic>κ</italic><sub>0</sub> was used, in order to instruct learner to have a large prior variance over the value of the mean. Each subject will be referred by its expected memory at the lower and higher level (i.e. L = long, S = short memory). For instance, the subject number 3 (LS) is expected to have a long first-level memory, but a short second-level memory, which should make her more flexible than subject 2 (SL) after a long training, whom has a short first-level memory but a long second-level memory.</p>
</caption>
<alternatives>
<graphic id="pcbi.1006713.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.t002" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="left">Subjects</th>
<th align="center"><italic>μ</italic><sub>0</sub></th>
<th align="center"><italic>κ</italic><sub>0</sub></th>
<th align="center"><italic>α</italic><sub>0</sub></th>
<th align="center"><italic>β</italic><sub>0</sub></th>
<th align="center"><inline-formula id="pcbi.1006713.e144"><alternatives><graphic id="pcbi.1006713.e144g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e144" xlink:type="simple"/><mml:math display="inline" id="M144"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mrow/><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
<th align="center"><inline-formula id="pcbi.1006713.e145"><alternatives><graphic id="pcbi.1006713.e145g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e145" xlink:type="simple"/><mml:math display="inline" id="M145"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mrow/><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
<th align="center"><inline-formula id="pcbi.1006713.e146"><alternatives><graphic id="pcbi.1006713.e146g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e146" xlink:type="simple"/><mml:math display="inline" id="M146"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mrow/><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
<th align="center"><inline-formula id="pcbi.1006713.e147"><alternatives><graphic id="pcbi.1006713.e147g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e147" xlink:type="simple"/><mml:math display="inline" id="M147"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mrow/><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">(1)</td>
<td align="left">LL</td>
<td align="center" rowspan="4">0</td>
<td align="center" rowspan="4">0.1</td>
<td align="center" rowspan="4">1</td>
<td align="center" rowspan="4">1</td>
<td align="char" char=".">4.5</td>
<td align="char" char=".">0.5</td>
<td align="char" char=".">4.5</td>
<td align="char" char=".">0.5</td>
</tr>
<tr>
<td align="left">(2)</td>
<td align="left">SL</td>
<td align="char" char=".">0.5</td>
<td align="char" char=".">4.5</td>
<td align="char" char=".">4.5</td>
<td align="char" char=".">0.5</td>
</tr>
<tr>
<td align="left">(3)</td>
<td align="left">LS</td>
<td align="char" char=".">4.5</td>
<td align="char" char=".">0.5</td>
<td align="char" char=".">0.5</td>
<td align="char" char=".">4.5</td>
</tr>
<tr>
<td align="left">(4)</td>
<td align="left">SS</td>
<td align="char" char=".">0.5</td>
<td align="char" char=".">4.5</td>
<td align="char" char=".">0.5</td>
<td align="char" char=".">4.5</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>In both experiments, these agents were confronted with a stream of univariate random variables from which they had to learn the trial-wise posterior distribution of the mean and standard deviation.</p>
<p>In <bold>Experiment 1</bold>, we simulated the learning of these agents in a steady environment followed by an abrupt CC, occurring either after a long (900 trials) or a short (100 trials) training. The signal <bold>r</bold> = {<italic>r</italic><sub>1</sub>, <italic>r</italic><sub>2</sub>, …, <italic>r</italic><sub><italic>n</italic></sub>} was generated according to a Gaussian noise with mean <italic>μ</italic> = 3 before the CC and <italic>μ</italic> = −3 after the CC, and a constant standard deviation <italic>σ</italic> = 1. <xref ref-type="fig" rid="pcbi.1006713.g005">Fig 5</xref> summarizes the results of this first simulation. During the training phase, the subjects with a long memory on the first level learned the observation value faster than others. Conversely, the SS subject took a long time to learn the current distribution. More interesting is the behaviour of the four subjects after the CC. In order to see which strategy reflected best the data at hand, we computed the average of the ELBOs for each model. The winning agent was the Long-Short memory, irrespective of training duration, because it was better able to adapt its memory to the contingency.</p>
<fig id="pcbi.1006713.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g005</object-id>
<label>Fig 5</label>
<caption>
<title>HAFVF predictions after a CC.</title>
<p>Each column displays the results of a specific hyperparameter setting. The blue traces and subplots represent the learning in an experiment with a long training, the orange traces and subplots show learning during a short training experiment. <bold>A</bold>. The stream of observations in the two training cases are shown together with the average posterior expected value of the mean <inline-formula id="pcbi.1006713.e108"><alternatives><graphic id="pcbi.1006713.e108g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e108" xlink:type="simple"/><mml:math display="inline" id="M108"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>j</mml:mi> <mml:mi>μ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>. The box line width illustrates the ranking of the ELBO of each specific configuration for the dataset considered, with bolder borders corresponding to larger ELBOs. For both training conditions, the winning model (i.e. the model that best reflected the data) was the Long-Short memory model. This can be explained by the fact that the first two models trusted too much their initial knowledge after the CC, whereas the Short-Short learner was too cautious. <bold>B</bold>. Efficient memory (defined as <inline-formula id="pcbi.1006713.e109"><alternatives><graphic id="pcbi.1006713.e109g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e109" xlink:type="simple"/><mml:math display="inline" id="M109"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>q</mml:mi></mml:msub> <mml:mo>[</mml:mo> <mml:mo>·</mml:mo> <mml:mo>]</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>) for the first level (<inline-formula id="pcbi.1006713.e110"><alternatives><graphic id="pcbi.1006713.e110g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e110" xlink:type="simple"/><mml:math display="inline" id="M110"><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, plain line) and second level (<inline-formula id="pcbi.1006713.e111"><alternatives><graphic id="pcbi.1006713.e111g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e111" xlink:type="simple"/><mml:math display="inline" id="M111"><mml:mover accent="true"><mml:mi>b</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, dashed line).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g005" xlink:type="simple"/>
</fig>
<p>The two levels had a different impact on the flexibility of the subjects: the first level indicated how much a subject should trust his past experience when confronted with a new event, and the second level measured the stability of the first level. On the one hand, subjects with a low prior on first-level memory were too cautious about the stability of the environment (i.e. expected volatile environments) and failed to learn adequately the contingency at hand. On the other hand, after a long training, subjects with a high prior on second-level memory tended to over-trust environment stability, compared to subjects with a low prior on second level memory, impairing their adaptation after the CC.</p>
<p>The expected forgetting factors also shed light on the underlying learning process occurring in the four subjects: <inline-formula id="pcbi.1006713.e112"><alternatives><graphic id="pcbi.1006713.e112g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e112" xlink:type="simple"/><mml:math display="inline" id="M112"><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> grew or was steady until the CC for the four subjects, even for the SL subject which showed a rapid growth of <inline-formula id="pcbi.1006713.e113"><alternatives><graphic id="pcbi.1006713.e113g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e113" xlink:type="simple"/><mml:math display="inline" id="M113"><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> during the first trials, but failed to reduce it at the CC. In contrast, the LS subject did not exhibit this weakness, but rapidly reduced its expectation over the stability of the environment after the CC thanks to her pessimistic prior belief over <italic>b</italic>.</p>
<p>In <bold>Experiment 2</bold>, we simulated the effect of an isolated, unexpected event (<italic>r</italic><sub><italic>j</italic></sub> = −3) after long and short training with the same distribution as before. For both datasets, we focused our analysis on the value of the expected forgetting factors <inline-formula id="pcbi.1006713.e114"><alternatives><graphic id="pcbi.1006713.e114g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e114" xlink:type="simple"/><mml:math display="inline" id="M114"><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006713.e115"><alternatives><graphic id="pcbi.1006713.e115g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e115" xlink:type="simple"/><mml:math display="inline" id="M115"><mml:mover accent="true"><mml:mi>b</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, as well as the effective memory of the agents, represented by the parameter <italic>κ</italic><sup><italic>μ</italic></sup>. As noted earlier, the value of <inline-formula id="pcbi.1006713.e116"><alternatives><graphic id="pcbi.1006713.e116g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e116" xlink:type="simple"/><mml:math display="inline" id="M116"><mml:mover accent="true"><mml:mi>w</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> sets an upper bound (the efficient memory) on <italic>κ</italic><sup><italic>μ</italic></sup>, which represented the actual number of trials kept in memory up to the current trial.</p>
<p>
<xref ref-type="fig" rid="pcbi.1006713.g006">Fig 6</xref> illustrates the results of this experiment. Here, the flexible agents (with a low memory on either the first or second memory level, or both) were disadvantaged wrt the low flexibility agent (mostly LL). Indeed, following the occurrence of a highly unexpected observation, one can observe that the LS learner memory dropped after either long or short training. The LL learner, instead, was able to cushion the effect of this outlier, especially after a long training, making it the best learner of the four to learn these datasets (<xref ref-type="table" rid="pcbi.1006713.t003">Table 3</xref>).</p>
<fig id="pcbi.1006713.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g006</object-id>
<label>Fig 6</label>
<caption>
<title>HAFVF predictions after an isolated unexpected event.</title>
<p>The figure is similar to <xref ref-type="fig" rid="pcbi.1006713.g005">Fig 5</xref>. Here, the winning model was the one with a high memory on the first and second levels. The figure is structured as <xref ref-type="fig" rid="pcbi.1006713.g005">Fig 5</xref>, and we refer to this for a more detailed description.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g006" xlink:type="simple"/>
</fig>
<table-wrap id="pcbi.1006713.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.t003</object-id>
<label>Table 3</label>
<caption>
<title>Average ELBOs for Experiment 1 and 2.</title>
<p>Higher ELBOs stand for more probable models.</p>
</caption>
<alternatives>
<graphic id="pcbi.1006713.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.t003" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="center" colspan="4">Experiment 1</th>
<th align="center" colspan="4">Experiment 2</th>
</tr>
<tr>
<th align="center">Dataset</th>
<th align="center">LL</th>
<th align="center">SL</th>
<th align="center">LS</th>
<th align="center">SS</th>
<th align="center">LL</th>
<th align="center">SL</th>
<th align="center">LS</th>
<th align="center">SS</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1</td>
<td align="char" char=".">-1.719</td>
<td align="char" char=".">-1.657</td>
<td align="char" char=".">-1.62</td>
<td align="char" char=".">-1.863</td>
<td align="char" char=".">-1.459</td>
<td align="char" char=".">-1.652</td>
<td align="char" char=".">-1.501</td>
<td align="char" char=".">-1.863</td>
</tr>
<tr>
<td align="center">2</td>
<td align="char" char=".">-1.526</td>
<td align="char" char=".">-1.649</td>
<td align="char" char=".">-1.519</td>
<td align="char" char=".">-1.866</td>
<td align="char" char=".">-1.453</td>
<td align="char" char=".">-1.648</td>
<td align="char" char=".">-1.495</td>
<td align="char" char=".">-1.866</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec026">
<title>Fitting the HAFVF to a behavioural task</title>
<p>The model we propose has a large number of parameters, and overfitting could be an issue. To show that inference about the latent variables of the model depicted in the Fitting the AC-HAFVF section is possible, we simulated a dataset of 64 subjects performing a simple one-stage behavioural task, that consisted in trying to choose at each trial the action leading to the maximum reward. In any given trial <inline-formula id="pcbi.1006713.e117"><alternatives><graphic id="pcbi.1006713.e117g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e117" xlink:type="simple"/><mml:math display="inline" id="M117"><mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:mi>j</mml:mi> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mn>1000</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, the two possible actions (e.g. left or right button press) were associated to different, normally distributed, reward probabilities with a varying mean and a fixed standard deviation <inline-formula id="pcbi.1006713.e118"><alternatives><graphic id="pcbi.1006713.e118g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e118" xlink:type="simple"/><mml:math display="inline" id="M118"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>:</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> for the first action (<italic>a</italic><sub>1</sub>) the reward had a mean of 0 for the first 500 trials, then switched abruptly to + 2 for 100 trials and then to −2 for the rest of the experiment. The second action value was identically distributed but in the opposite order and with the opposite sign (<xref ref-type="fig" rid="pcbi.1006713.g007">Fig 7</xref>). This pattern was chosen in order to test the flexibility of each agent after an abrupt CC: after the first CC, an agent discarding completely exploration in favour of exploitation would miss the CC. The second and third CC tested how fast did the simulated agents adapt to the observed CC.</p>
<fig id="pcbi.1006713.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Simulated behavioral results.</title>
<p><bold>A</bold>. The values of the two available rewards are shown with the dotted lines. The average drift rate <italic>μ</italic><sub>1</sub> − <italic>μ</italic><sub>2</sub> is shown in plain lines for two selected simulated subjects <italic>n</italic><sub>1</sub> and <italic>n</italic><sub>2</sub>, and population average. Subject <italic>n</italic><sub>1</sub> was more flexible than subject <italic>n</italic><sub>2</sub> on both the first and the second level, making her more prone to adapt after the CCs, situated at trials 400, 500 and 600. This result is highlighted in the underlying zoomed box. <bold>B</bold>. The subjects’ expected variance (blue, log-valued) correlated negatively with the mean RT. The same correlation existed with the expected stability on the first level (orange, logit-valued), but not with the second level, which correlated positively with the average RT (green, logit-valued). Pearson correlation coefficient and respective p-values are shown in rounded boxes. <bold>C</bold>. Similarly, subjects with a higher expected variance and first-level stability had a lower average accuracy. Again, second-level memory expectation had the opposite effect.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g007" xlink:type="simple"/>
</fig>
<p>Individual prior parameters <inline-formula id="pcbi.1006713.e119"><alternatives><graphic id="pcbi.1006713.e119g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e119" xlink:type="simple"/><mml:math display="inline" id="M119"><mml:mrow><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>≜</mml:mo> <mml:mo>{</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mi mathvariant="script">G</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mspace width="4.pt"/><mml:mtext>prior</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mspace width="4.pt"/><mml:mtext>Beta</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>priors</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>ϕ</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">β</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and thresholds <italic>ζ</italic><sub><italic>n</italic></sub> were generated as follows: we first looked for the L2-regularized MAP estimates of these parameters that led to the maximum total reward:
<disp-formula id="pcbi.1006713.e120"><alternatives><graphic id="pcbi.1006713.e120g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e120" xlink:type="simple"/><mml:math display="block" id="M120"><mml:mrow><mml:msubsup><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mn>0</mml:mn> <mml:mo>*</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">ζ</mml:mi></mml:mrow> <mml:mo>*</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:munder><mml:mrow><mml:mtext>arg</mml:mtext> <mml:mspace width="4pt"/><mml:mtext>max</mml:mtext></mml:mrow> <mml:mrow><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mn>0</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>ζ</mml:mi></mml:mrow></mml:munder> <mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>J</mml:mi></mml:munderover> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:munder><mml:mrow><mml:mtext>arg</mml:mtext> <mml:mspace width="4pt"/><mml:mtext>max</mml:mtext></mml:mrow> <mml:msub><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:munder><mml:mspace width="4pt"/><mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">a</mml:mi> <mml:mrow><mml:mo>&lt;</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mo mathvariant="bold">Ω</mml:mo> <mml:mo>,</mml:mo> <mml:mi>ζ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mn>0</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>ζ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
using a Stochastic Gradient Variational Bayes (SGVB) [<xref ref-type="bibr" rid="pcbi.1006713.ref090">90</xref>] optimization scheme. With a negligible loss of generality, the prior mean <italic>μ</italic><sub>0</sub> was considered to be equal to 0 for all subjects for both the data generation and the fitting procedures. With a negligible loss of generality, the prior mean <italic>μ</italic><sub>0</sub> was considered to be equal to 0 for all subjects for both the data generation and the fitting procedures.</p>
<p>We then simulated individual priors centered around this value with a covariance matrix arbitrarily sampled as
<disp-formula id="pcbi.1006713.e121"><alternatives><graphic id="pcbi.1006713.e121g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e121" xlink:type="simple"/><mml:math display="block" id="M121"><mml:mrow><mml:msub><mml:mo>Σ</mml:mo> <mml:mrow><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo> <mml:mn>0</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mi>ζ</mml:mi></mml:mrow></mml:msub> <mml:mo>∼</mml:mo> <mml:msubsup><mml:mi mathvariant="script">W</mml:mi> <mml:mn>10</mml:mn> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>(</mml:mo> <mml:mo>[</mml:mo> <mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mo>⋯</mml:mo></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mn>1</mml:mn></mml:mtd> <mml:mtd/><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd> <mml:mtd/><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mo>⋯</mml:mo></mml:mtd> <mml:mtd><mml:mn>0</mml:mn></mml:mtd> <mml:mtd><mml:mrow><mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo>]</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1006713.e122"><alternatives><graphic id="pcbi.1006713.e122g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e122" xlink:type="simple"/><mml:math display="inline" id="M122"><mml:mrow><mml:msubsup><mml:mi mathvariant="script">W</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>·</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is an inverse-Wishart distribution with <italic>n</italic> degrees of freedom. This choice of prior lead to a large variability in the values of the AC-HAFVF parameters, except for the NIGDM threshold whose variance was set to a sufficiently low value (hence the 0.1 value in the prior scale matrix) to keep the learning performance high.</p>
<p>This method ensured that each and every parameter set was centered around an unknown optimal policy. This approach was motivated by the need to prevent strong constrains on the data generation pattern while keeping behaviour close to optimal, as might be expected from healthy population. The other DDM parameters, <italic>ν</italic><sub><italic>n</italic></sub> and <italic>τ</italic><sub><italic>n</italic></sub>, were generated according to a Gaussian distribution centered on 0 and 0.3, respectively. Simulated subjects with a performance lower than 70% were rejected and re-sampled to avoid irrelevant parameter patterns.</p>
<p>Learning was simulated according to the Continuous Learning strategy (see Counterfactual learning), because it was supposed to link more comprehensively the tendency to explore the environment with the choice of prior parameters <bold>Ω</bold><sub>0</sub>. Choices and RT where then generated according to the decision process described in the The actor: Decision making under the HAFVF section using the algorithm described by [<xref ref-type="bibr" rid="pcbi.1006713.ref091">91</xref>]. <xref ref-type="fig" rid="pcbi.1006713.g007">Fig 7</xref> shows two examples of the simulated behavioural data.</p>
<p>The behavioural results showed a clear tendency of subjects with large expected variance in action selection to act faster and less precisely than others. This follows directly from the structure of the NIGDM: larger variance of the drift-rate leads to faster but less precise policies. More interesting is the negative correlation between the expected stability and the reward-rate and average reaction time: this shows that the AC-HAFVF was able to encode a form of subject-wise computational complexity of the task. Indeed, large stability expectation leads subjects to trust more their past experience, thereby decreasing the expected reward variance after a long training, but it also leads to a lower capacity to adapt to CCs. For subjects with low expectation of stability, the second level memory was able to instruct the first-level to trust past experience when needed, as the positive correlation between accuracy and upper level memory shows.</p>
<sec id="sec027">
<title>Fitting results</title>
<p>The fit was achieved with the Adam [<xref ref-type="bibr" rid="pcbi.1006713.ref092">92</xref>] Stochastic Gradient Descent optimizer with parameters <italic>s</italic> = 0.005, <italic>β</italic><sub>1</sub> = 0.9, <italic>β</italic><sub>2</sub> = 0.99, where <italic>s</italic> decreased with a rate <inline-formula id="pcbi.1006713.e123"><alternatives><graphic id="pcbi.1006713.e123g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e123" xlink:type="simple"/><mml:math display="inline" id="M123"><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:mo>⌈</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>/</mml:mo> <mml:mn>1000</mml:mn></mml:mrow> <mml:mo>⌉</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> where <italic>i</italic> is the iteration number of the SGD optimizer. We used the following annealing procedure to avoid local minima: at each iteration, the whole set of parameters was sampled from a diagonal Gaussian distribution with covariance matrix 1/<italic>i</italic>. This simple manipulation greatly improved the convergence of the algorithm.</p>
<p>The MAP fit of the model is displayed in <xref ref-type="fig" rid="pcbi.1006713.g008">Fig 8</xref>. In general, the posterior estimates of the prior parameters were well correlated with their true value, except for the prior shape parameter <italic>α</italic><sub>0</sub>. This lack of correlation did not, however, harm much the fit of the variance (see below), showing that the model fit was able to accurately recover the expected prior variability of each subject, which depended on <italic>α</italic><sub>0</sub>. The NIGDM parameters were highly correlated with their original value.</p>
<fig id="pcbi.1006713.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Correlation between the true (x axis) and the posterior estimate (y axis) of the parameters of the prior distributions across subjects.</title>
<p>The first row displays the correlations between true value and estimated <bold><italic>θ</italic></bold><sub>0</sub>. The second row focuses on <italic>ϕ</italic><sub>0</sub> and <bold><italic>β</italic></bold><sub>0</sub>, whereas the third row shows the correlations for the NIGDM parameters (threshold, relative start-point and non-decision time). Correlation coefficients and associated p-value (with respect to the posterior expected value) are displayed in blue boxes. All parameters are displayed in the unbounded space they were generated from. Overall, all parameters correlated well with their true value, except for the <italic>α</italic><sub>0</sub>(<italic>a</italic>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g008" xlink:type="simple"/>
</fig>
<p>In order to evaluate the identifiability of our model, we performed the quadratic approximation to the posterior covariance of the fitted HAFVF parameters. The average result, displayed in <xref ref-type="fig" rid="pcbi.1006713.g009">Fig 9</xref>, shows that covariance between model parameters was low, except at the top level. This indicates that each of parameter had a distinguishable effect on the loss. The higher variance and covariance of the parameters <italic>α</italic><sup><italic>β</italic></sup> and <italic>β</italic><sup><italic>β</italic></sup> relates to the fact that the influence of these prior parameters vanishes as more and more data is observed, in accordance with the Bernstein-Von-Mises theorem. In practice, this means that <italic>α</italic><sup><italic>β</italic></sup> and <italic>β</italic><sup><italic>β</italic></sup> should not be given behavioural interpretation but should rather be viewed as regularizers of the model.</p>
<fig id="pcbi.1006713.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Average quadratic approximation to the posterior covariance of the HAFVF parameters at the mode.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g009" xlink:type="simple"/>
</fig>
<p>We also looked at how the true prior expected value of <italic>w</italic> and <italic>b</italic> and variance correlated with their estimate from the posterior distribution. All of these correlated well with their generative correspondent, with the notable exception of the expected value of the second-level memory <inline-formula id="pcbi.1006713.e124"><alternatives><graphic id="pcbi.1006713.e124g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e124" xlink:type="simple"/><mml:math display="inline" id="M124"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>q</mml:mi></mml:msub> <mml:mo>[</mml:mo> <mml:mi>b</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> (<xref ref-type="fig" rid="pcbi.1006713.g010">Fig 10</xref>). This confirms again the role of regulizer of <italic>b</italic> over <italic>w</italic>.</p>
<fig id="pcbi.1006713.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Correlation between true and expected values of the variances and forgetting factors.</title>
<p>All the fitted values (y axis) are derived from the expected value of <bold><italic>θ</italic></bold><sub>0</sub> (<bold>A</bold>., variance) and {<italic>ϕ</italic><sub>0</sub>, <bold><italic>β</italic></bold><sub>0</sub>} (<bold>B</bold>., forgetting factors) under the fitted approximate posterior distribution. Each dot represents a different subject. <bold>A</bold>. True (x-axis) to fit (y axis) correlation for the reward (blue) and mean reward (red) variance. Both expected values correlated well with their generative parameter, although the initial number of observations of the gamma prior <italic>α</italic><sub>0</sub> did not correlate well with its generative parameter. <bold>B</bold>. True (x-axis) to fit (y axis) correlation for the first (blue) and second (red) level expected forgetting factor.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g010" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec028">
<title>TD learning with the HAFVF</title>
<p>To study the TD learning described in the Temporal difference learning section, we built two similar Markov Decision Processes (MDP) which are described in <xref ref-type="fig" rid="pcbi.1006713.g011">Fig 11</xref>. In brief, they consist of 5 different states where the agent has to choose the best action in order to reach a reward (<italic>r</italic> = 5) delivered once a specific state has been reached (hereafter, we will use “rewarded state” and “rewarded state-action” interchangeably). The task consisted for the agent to learn the current best policy during a 1000-trial experiment where the contingency was fixed to the first MDP during the first 500 trials, and then switched abruptly to the second MDP during the second half of the experiment.</p>
<fig id="pcbi.1006713.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g011</object-id>
<label>Fig 11</label>
<caption>
<title>MDPs of experiment 1 (A) and 2 (B).</title>
<p>Rewarded states are displayed in green. Each action had a probability of 90% to lead to the end state indicated by the red and black arrows (respectively left and right action). The remaining 10% transition probabilities were evenly distributed among the other states. For clarity, the thick arrows show the optimal path the agent should aim to take during the two contingencies. Note that the only difference between experiment (i) and (ii) is the location of the rewarded state after the CC (state 2 for (i) and 5 for (ii)).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g011" xlink:type="simple"/>
</fig>
<p>The same prior was used for all subjects: the mean and variance prior was set to <italic>μ</italic><sub>0</sub> = 0, <italic>κ</italic><sub>0</sub> = 0.5, <italic>α</italic><sub>0</sub> = 3, <italic>β</italic><sub>0</sub> = 0.5. The forgetting factors shared the same flat prior <inline-formula id="pcbi.1006713.e125"><alternatives><graphic id="pcbi.1006713.e125g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e125" xlink:type="simple"/><mml:math display="inline" id="M125"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi> <mml:mn>0</mml:mn> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>b</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mn>0</mml:mn> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>b</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. The priors on the discounting factor were set to a high value <inline-formula id="pcbi.1006713.e126"><alternatives><graphic id="pcbi.1006713.e126g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e126" xlink:type="simple"/><mml:math display="inline" id="M126"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi> <mml:mn>0</mml:mn> <mml:mi>γ</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>9</mml:mn> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mn>0</mml:mn> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>b</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> in order to discourage myopic strategies. The policy prior (see Appendix D) was set to a high value (<italic>π</italic><sub>0</sub> = 5.) in order to limit the impact of initial choices on the computation of the state-action value.</p>
<p>Results are displayed in <xref ref-type="fig" rid="pcbi.1006713.g012">Fig 12</xref>. In both experiments, agents had a similar behaviour during the first phase of the experiment: they both learned well the first contingency by assigning an accurate value to each state-action pair in order to reach the rewarded state more often. As expected, after the contingency change, the agents in experiment (i) took a longer time to adapt than they took to learn the initial contingency, which can be seen from the steeper slope of the reward rate during the first half of the experiment wrt the second. This feature can only be observed if the agent weights its belief by some measure of certainty, which is not modelled in classical, non-Bayesian RL.</p>
<fig id="pcbi.1006713.g012" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006713.g012</object-id>
<label>Fig 12</label>
<caption>
<title>Behavioural results in the first (left of <xref ref-type="fig" rid="pcbi.1006713.g011">Fig 11</xref>) and second experiments (right of <xref ref-type="fig" rid="pcbi.1006713.g011">Fig 11</xref>).</title>
<p><bold>A</bold>. and <bold>B</bold>. Heat plot of the probability of visiting each state and selecting each action for the 64 agents simulated. (i) Agents progressively learned the first optimal actions (left action in state 3-4-5) during the first half of the experiment, then adapted their behaviour to the new contingency (right action in states 1-4-2). (ii) Similarly, in the second experiment, agents adapted their behaviour according to the new contingency (left action in 1-3-5). <bold>C</bold>. Efficient memory on the first and second level, and foreseeing capacity. Since the CC was less important in (ii) than in (i), because the left action in state 3 kept being rewarded, the expected value of <italic>w</italic> dropped less. The behaviour of the foreseeing capacity (<inline-formula id="pcbi.1006713.e127"><alternatives><graphic id="pcbi.1006713.e127g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e127" xlink:type="simple"/><mml:math display="inline" id="M127"><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>q</mml:mi></mml:msub> <mml:mo>[</mml:mo> <mml:mi>γ</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>) and, therefore, of the expected value of <italic>γ</italic>, is indicative of the effect that a CC had on this parameter: when the environment became less stable, <inline-formula id="pcbi.1006713.e128"><alternatives><graphic id="pcbi.1006713.e128g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e128" xlink:type="simple"/><mml:math display="inline" id="M128"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>q</mml:mi></mml:msub> <mml:mo>[</mml:mo> <mml:mi>γ</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> tended to <italic>increase</italic> which had the effect of increasing the impact of future states on the current value. <bold>D</bold>. (i) Reward rate dropped after the CC, whereas the RT increased. The fact that subjects made slower choices after the CC can be viewed as a mark of the increased task complexity caused by the re-learning phase. Along the same line, RT decreased again when the subjects were confident about the structure of the environment. (ii) The CC had also a lower impact on the reward rate and RT in experiment (ii).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.g012" xlink:type="simple"/>
</fig>
<p>In experiment (ii), the CC changes less the environment structure than the CC in experiment (i). The agents were able to take this difference into account: the value of the effective memories dropped less, and so did the reward rate.</p>
<p>An important feature observed in these two experiments is that the expected value of <italic>γ</italic> adapted efficiently to the contingency: although we used a prior skewed towards high values of <italic>γ</italic>, its value tended to be initially low as the agents had no knowledge of the various action values. Also, this value increased afterwards, reflecting a gain in predictive accuracy. The drop of <inline-formula id="pcbi.1006713.e070"><alternatives><graphic id="pcbi.1006713.e070g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e070" xlink:type="simple"/><mml:math display="inline" id="M70"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>q</mml:mi></mml:msub> <mml:mo>[</mml:mo> <mml:mi>w</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> had the effect of pushing <inline-formula id="pcbi.1006713.e052"><alternatives><graphic id="pcbi.1006713.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006713.e052" xlink:type="simple"/><mml:math display="inline" id="M52"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>q</mml:mi></mml:msub> <mml:mo>[</mml:mo> <mml:mi>γ</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> towards its prior, which in this case <italic>increased</italic> the posterior expectation of <italic>γ</italic>. At the same time, the uncertainty about <italic>γ</italic> increased, thereby enhancing the flexibility of this parameter.</p>
</sec>
</sec>
<sec id="sec029" sec-type="conclusions">
<title>Discussion</title>
<p>In this paper, we propose a new Bayesian Reinforcement Learning (RL) algorithm aimed at accounting for the adaptive flexibility of learning observed in animal and human subjects. This algorithm adapts continuously its learning rate to inferred environmental variability, and this adaptive learning rate is optimal under some assumptions about statistical properties of the environment. These assumptions take the form of prior distributions on the parameters of the latent and mixing weight variables. We illustrate different types of behaviour of the model when facing unexpected contingency changes by taking extreme case scenarios. These scenarios implemented four types of assumptions on the tendency of the environment to vary over time (first-level memory) and on the propensity of this environmental variability to change itself over time (second-level memory). This approach allowed us to reproduce the emergence of inflexible behaviour following prolonged experience of a stable environment, similar to empirical observations in animals. Indeed, it has long been known that extensive training leads to automatization of behaviour, called habits [<xref ref-type="bibr" rid="pcbi.1006713.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref093">93</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref096">96</xref>], or procedural “system 1” actor ([<xref ref-type="bibr" rid="pcbi.1006713.ref095">95</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref097">97</xref>]), which is characterized by a lack of flexibility (i.e. failure to adapt to contingency changes) and by reduction of computational costs, illustrated by the capacity to perform these behaviours concomitantly to other tasks [<xref ref-type="bibr" rid="pcbi.1006713.ref098">98</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref100">100</xref>]. These automatic types of behaviour are opposed to Goal-Directed behaviours ([<xref ref-type="bibr" rid="pcbi.1006713.ref099">99</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref101">101</xref>]) and share the common feature of being inflexible, either in terms of planning (for Model-Free RL for instance) or in terms of adaptation in general.</p>
<p>Regarding the actor part, we implemented a general, Bayesian decision-making algorithm that reflects in many ways the Full-DDM proposed by [<xref ref-type="bibr" rid="pcbi.1006713.ref003">3</xref>], as it samples the reward distribution associated to each action and selects at each time step the best option. These elementary decisions are integrated until a decision boundary is reached. Therefore, the actor maps the cognitive predictions of the critic onto specific behavioural outputs such as choice and reaction time (RT). Importantly, this kind of Bayesian evidence accumulation process for decision making is biologically plausible [<xref ref-type="bibr" rid="pcbi.1006713.ref102">102</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref103">103</xref>], well suited for decision making in RL [<xref ref-type="bibr" rid="pcbi.1006713.ref104">104</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref107">107</xref>] and makes predictions that are in accordance with physiological models of learning and decision making [<xref ref-type="bibr" rid="pcbi.1006713.ref108">108</xref>]. Other noteworthy attempts have been made to integrate sampling-based decision-making and RL [<xref ref-type="bibr" rid="pcbi.1006713.ref109">109</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref110">110</xref>] using the DDM. However, the present work is the first, to our knowledge, to frame the DDM as an optimal, Bayesian decision strategy to maximize long-term utility on the basis of value distributions inferred from a RL algorithm. We show that this RL-DDM association, and especially in the framework of the Full DDM [<xref ref-type="bibr" rid="pcbi.1006713.ref003">3</xref>], finds a grounded algorithmic justification in a Bayesian perspective, as the resulting policy mimics the one of an agent trying to infer the best decision given its posterior belief about the reward distribution.</p>
<p>Interestingly, under some slight modifications (i.e. assuming that the sampled rewards are not simulated but retrieved from the subject memory), it is similar to the model recently proposed by Bornstein et al. [<xref ref-type="bibr" rid="pcbi.1006713.ref111">111</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref112">112</xref>]. More specifically, while our decision making scheme used a heuristic based on the asymptotic property of MCMC, the scheme of decision making proposed by Bornstein and colleagues might recall other approximation techniques such as Approximate Bayesian Computation (ABC [<xref ref-type="bibr" rid="pcbi.1006713.ref113">113</xref>]). Following this approach, data samples are generated according to some defined rule, and only the samples that match the actual previous observations are kept in memory to approximate the posterior distribution or, in our case, to evaluate the option with the greatest reward. This simple trick in the decision making process keeps the stochastic nature of the accumulation process, while directly linking the level of evidence to items retrieved from memory.</p>
<p>The HAFVF also recalls the learning model proposed by Behrens and colleagues [<xref ref-type="bibr" rid="pcbi.1006713.ref032">32</xref>] who studied the variations of human learning rate in volatile environments and showed that activity in Anterior Cingulate Cortex reflected their model estimate of environmental volatility. The AC-HAFVF exhibits several differences with respect to this model: first, and crucially, it uses a Stabilized Forgetting framework to modify the belief that the agent has in the parameter values at each level, unlike Behrens et al. who used a purely forward model, similar in this sense to the HGF. Second, our model used Mean-field VB to make inference about the parameter values, allowing it to approximate the posterior distribution at low cost. The drawback of this approach, however, is that the AC-HAFVF presented here does not allow us to compute posterior covariance of their parameters at each trial, in contrast to Behrens and colleagues. Given these differences, it would interesting to compare how these various models of adaptation to volatility fit actual behavioural data and how well their parameters follow recorded neurobiological signals.</p>
<p>An important feature of the HAFVF is that it can account for unstructured changes of contingency. In other words, it allows the agent to learn anew the state of the environment even if the transition that leads to this state has never been experienced before. This is an important feature that contrasts with Kalman filters and Hidden Markov Models [<xref ref-type="bibr" rid="pcbi.1006713.ref001">1</xref>]. Both approaches have their pros and cons: learning state transition probabilities makes sense in environment that enjoy specific regularity conditions, but if the environment is chaotic, they can lead to poor adaptation performance. The approach we adopted here makes sense in situations in which one expects that the environment may change in an unstructured way, e.g. in which an environment that has remained stable for a long period of time may (suddenly or progressively) change in a random and hence unpredictable manner. An intermediate approach could however be developed [<xref ref-type="bibr" rid="pcbi.1006713.ref035">35</xref>].</p>
<p>One major advantage of our model is that its parameters are easily interpretable as reflecting hidden behavioural features such as trial-wise effective memory, prior and posterior expected stability, etc. We detail how model parameters can be fitted to data in order to recover these behavioural features at the trial, subject and population levels. This approach could be used, for instance, to cluster subjects in high-stability seeking and low-stability seeking sub-populations, and correlate these behaviours to health conditions, neurophysiological measures or training condition (stress, treatment etc.) We show that, for a simulated dataset, the fitted posterior distribution of the parameters correlate well with their original value. Moreover, each of the layers of the model (learning, first level memory and second level memory) have interesting behavioural correlates in terms of accuracy and RT. These results show that the model is identifiable and that there is a low redundancy in the various layers of the model. Also, different priors over the expected distribution of rewards and environment stability led also to different outcomes in terms of reward rate and RT: subjects whom assumed large environmental stability were likely to act faster, but also to be less flexible and to gain less on average, than subjects whom assumed high likelihood of contingency changes. The second-level memory had different effect, in the sense that large memory tended to be associated with flexible or inflexible behavior, depending on whether past experience corresponded to volatile or stable environment, respectively.</p>
<p>This finding also resonates with the habitual learning literature, in which decreased flexibility is also typically associated with short average RT, reflecting lower cognitive cost (see also [<xref ref-type="bibr" rid="pcbi.1006713.ref074">74</xref>]). However, in contrast to our approach, Keramati and colleagues suggest that adaptations to changes in volatility would rely on switching between two alternative decision strategies: an information-seeking goal-directed controller and a greedy habitual system. Habits would consist in bypassing computationally expensive inference steps in order to maximize reward rate when information gathering is too costly. The AC-HAFVF does not require to achieve model selection prior to making a decision: on the contrary, computational cost of the decision process is optimized automatically during learning and inference. For instance, VPI-guided evidence accumulation (see Appendix E) is achieved at a cost virtually identical of inference using a Q-value sampling strategy. Also, the switch from information-gathering to pure value-based selection strategy is natural when the posterior variance of the action values decreases, and the VPI vanishes as the average return becomes certain. Furthermore, using Q-value sampling only, we can see that the behaviour turns from being stochastic and explorative to being deterministic through training, again confirming that the learning and decision scheme we propose can account for the emergence of automatic behaviours. In turn, this could only happen if the environment is considered as stable by the agent. Further developments of the model could show how the threshold (e.g. [<xref ref-type="bibr" rid="pcbi.1006713.ref114">114</xref>]) and the start point (e.g. [<xref ref-type="bibr" rid="pcbi.1006713.ref115">115</xref>]) could be adapted to optimize the exploration policy and the cost of decisions.</p>
<p>Finally, we extended our work to MDP and multi-stages tasks. More than adding a mere reparameterization of TD learning, we propose a framework in which the time discount factor is considered by the agent as a latent variable: this opens the possibility of studying how animals and humans adapt their long-term / short-term return balance in different conditions of environmental variability. We show in the results that deep CC provoke a reset of the parameters, and lead subjects to erase their acquired knowledge of the posterior value of <italic>γ</italic>. We also show that this ability to adapt <italic>γ</italic> to the uncertainty of the environment can also be determinant at the beginning of the task, where nothing is known about the long term return of each action, and where individuals might benefit of a low expectation of <italic>γ</italic> that contrasts with the high expectation of subjects that have a deeper knowledge of the environment.</p>
<p>The present model is based on forgetting, which is an important feature in RL that should be differentiated from learning. In signal processing and related fields where online learning is required, learning can be seen as the capacity to build on previous knowledge (or assess a posterior probability distribution in a Bayesian context) to perform inference at the present step. Forgetting, on the contrary, is the capacity to erase the learning to come back at a naive, initial state of learning. The algorithm we propose learns a posterior belief of the data distribution and infers how likely this belief is to be valid in the next time step, on the basis of past environmental stability. This allows the algorithm to decide when and how much to forget its past belief in order to adapt to new contingencies. This feature sets our algorithm apart from previous proposals such as HGF, in which the naive prior looses its importance as learning goes on, and where the learner has no possibility of coming back to his initial knowledge. This lack of capacity to forget implies that the agent can be easily fooled by its past experience, whereas our model is more resistant in such cases, as its point of reference is fixed (which is the common feature of SF algorithms, see above). We have shown in the results that our model outperforms the HGF both in its fitting capability and its capacity to learn new observations with a given prior configuration. The AC-HAFVF should help to flexibly model learning in these contexts, and find correlates between physiological measures, such as dopaminergic signals [<xref ref-type="bibr" rid="pcbi.1006713.ref116">116</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref117">117</xref>], and precise model predictions in term of memory and flexibility.</p>
<p>The SF scheme we have used, where the previous posterior is compared with a naive prior to optimize the forgetting factor, is widely diffused in the signal processing community [<xref ref-type="bibr" rid="pcbi.1006713.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref035">35</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref118">118</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref119">119</xref>] and finds grounded mathematical justifications for error minimization in recursive Bayesian estimation [<xref ref-type="bibr" rid="pcbi.1006713.ref120">120</xref>]. However, it is the first time, to our knowledge, that this family of algorithms is applied to the study of RL in animals. We show that the two algorithms (RL and SF) share deep common features: for instance, the HAFVF and other similar algorithms ([<xref ref-type="bibr" rid="pcbi.1006713.ref057">57</xref>]) can be used with a naive prior <bold><italic>θ</italic></bold><sub>0</sub> set to 0, in which case the update equations reduce somehow to a classical Q-learning algorithm ([<xref ref-type="bibr" rid="pcbi.1006713.ref001">1</xref>] and Appendix B). Another interesting bound between the two fields emerges when the measure of the environment volatility is built hierarchically: an interesting consequence of the forgetting algorithm we propose is that, when observations are not made, the agent erases progressively its memory of past events. This leads to counterfactual learning schedule that favors exploration over exploitation at a rate dictated by the learned stability of the environment (see Appendix C for a development). Crucially, this updating scheme, and the consecutive exploration policy, flows directly from the hierarchical implementation of the SF scheme.</p>
<p>This work provides a tool to investigate learning rate adaptation in behaviour. Previous work has shown, for instance that the process of learning rate adaptation can be decomposed into various components that relate to different brain areas or networks [<xref ref-type="bibr" rid="pcbi.1006713.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref121">121</xref>]. Nassar and colleagues [<xref ref-type="bibr" rid="pcbi.1006713.ref122">122</xref>] have also looked at the impact of age on learning rate adaptation, and found that older subjects were more likely to have a narrow expectation of the variance of the data they were observing, impairing thereby their ability to detect true CC. The AC-HAFVF shares many similarities with the algorithm proposed by Nassar and McGuire: it is designed to detect how likely an observation is to be caused by an abrupt CC, and adapts its learning rate accordingly. Also, this detection of CC depends in both models not only on the first and second moment of the observations, but also on their prior average and variability. We think, however, that our model is more flexible and biologically plausible than the model of Nassar and McGuire for three reasons. First, it is fully Bayesian: when fitting the model, we do not fit an expected variance of the outcome observed, but a prior distribution on this variance. This important difference is likely to predict better the observed data, as the subjects performing an experiment have probably some prior uncertainty about the variability of the outcome they will witness. Second, we considered the steadiness of the environment as another Bayesian estimate, meaning that the subjects will have some confidence (and posterior distribution) in the fact that the environment has truly changed or not. Third, we believe that our model is more general (i.e. less <italic>ad hoc</italic>) than the model of Nassar, as the general form of <xref ref-type="disp-formula" rid="pcbi.1006713.e050">Eq 13</xref> encompasses many models that can be formulated using distributions issued from the exponential family. This includes behavioural models designed to evolve in multi-stage RL tasks, such as TD learning or Model-Based RL [<xref ref-type="bibr" rid="pcbi.1006713.ref123">123</xref>].</p>
<p>It is important to emphasize that the model we propose does not intend to be universal. In simple situations, fitting a classical Q-learning algorithm could lead to similar or even better predictions than those provided by our model. We think, however, that our model complexity makes it useful in situations where abrupt changes occur during the experiment, or where long sequences (several hundreds of trials) of data are acquired. The necessity to account for this adaptability could be determined by comparing the accuracy of the HAFVF model (i.e. the model evidence) to the one obtained from a simpler Bayesian Q-Learning algorithm without forgetting.</p>
<p>The richness and generality of the AC-HAFVF opens countless possibilities of future developments. The habitual/goal-directed duality has been widely framed in terms of Model-Free/Model-Based control separation (e.g. [<xref ref-type="bibr" rid="pcbi.1006713.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref096">96</xref>, <xref ref-type="bibr" rid="pcbi.1006713.ref124">124</xref>–<xref ref-type="bibr" rid="pcbi.1006713.ref128">128</xref>]). Although we do not model here a Model-Based learning algorithm, we think our work will ultimately help to discriminate various forms of inflexibility, and complete the whole picture of our understanding of human RL: in the usual Model-Free/Model-Based control duality, overconfidence in a Model-Free controller means that the subject will need to go through the same sequences of state-action transitions over and over to downweight actions situated early in a sequence. This contrasts with Model-Based control, which can immediately adapt its policy when an action situated far from the current state is devaluated [<xref ref-type="bibr" rid="pcbi.1006713.ref129">129</xref>]. The current implementation of the AC-HAFVF can model a lack of flexibility due to an overconfidence in the volatility of the environment, whereas adding a Model-Based component to the model might help to discriminate a lack of flexibility due to the overuse of a Model-Free strategy that characterizes the Model-Free/Model-Based paradigm. This balance could be learned and, in turn, be subject to forgetting. In short, implementation of Model-Based RL in an AC-HAFVF context might enrich greatly our understanding of how the balance between Model-Based and Model-Free RL works. This is certainly a development we intend to implement in the near future.</p>
<p>In conclusion, we provide a new Model-Free RL algorithm aimed at modelling behavioural adaptation to continuous and abrupt changes in the environment in a fully Bayesian way. We show that this model is flexible enough to reflect very different behavioural predictions in case of isolated unexpected events and prolonged change of contingencies. We also provide a biologically plausible decision making model that can be integrated elegantly in our learning algorithm, and completes elegantly the toolbox to simulate and fit datasets.</p>
</sec>
<sec id="sec030">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006713.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Normalizing constant of the exponential mixture prior distribution.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006713.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.s002" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>HAFVF update equations correspondence in classical RL.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006713.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.s003" xlink:type="simple">
<label>S3 Text</label>
<caption>
<title>Counterfactual learning update equations.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006713.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.s004" xlink:type="simple">
<label>S4 Text</label>
<caption>
<title>Discount factor inference.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006713.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.s005" xlink:type="simple">
<label>S5 Text</label>
<caption>
<title>VPI.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006713.s006" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.s006" xlink:type="simple">
<label>S6 Text</label>
<caption>
<title>NIGDM properties.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006713.s007" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006713.s007" xlink:type="simple">
<label>S7 Text</label>
<caption>
<title>Sampled drift optimisation.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank the Consortium des Équipements de Calcul Intensif (CECI) in Belgium for providing us with the computational resources that made possible the initial explorations that led to this manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006713.ref001">
<label>1</label>
<mixed-citation publication-type="other" xlink:type="simple">Moens V. The Hierarchical Adaptive Forgetting Variational Filter. Proceedings of the 35th international conference on Machine learning - ICML’18. 2018;.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>KULHAVÝ</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>ZARROP</surname> <given-names>MB</given-names></name>. <article-title>On a general concept of forgetting</article-title>. <source>International Journal of Control</source>. <year>1993</year>;<volume>58</volume>(<issue>4</issue>):<fpage>905</fpage>–<lpage>924</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/00207179308923034" xlink:type="simple">10.1080/00207179308923034</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Rouder</surname> <given-names>JN</given-names></name>. <article-title>Modeling Response Times for Two-Choice Decisions</article-title>. <source>Psychological Science</source>. <year>1998</year>;<volume>9</volume>(<issue>5</issue>):<fpage>347</fpage>–<lpage>356</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/1467-9280.00067" xlink:type="simple">10.1111/1467-9280.00067</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nature Neuroscience</source>. <year>2005</year>;<volume>8</volume>(<issue>12</issue>):<fpage>1704</fpage>–<lpage>1711</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1560" xlink:type="simple">10.1038/nn1560</ext-link></comment> <object-id pub-id-type="pmid">16286932</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dickinson</surname> <given-names>A</given-names></name>. <article-title>Actions and Habits: The Development of Behavioural Autonomy</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>. <year>1985</year>;<volume>308</volume>(<issue>1135</issue>):<fpage>67</fpage>–<lpage>78</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rstb.1985.0010" xlink:type="simple">10.1098/rstb.1985.0010</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dickinson</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Balleine</surname> <given-names>BW</given-names></name>, <name name-style="western"><surname>Watt</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Gonzalez</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Boakes</surname> <given-names>RA</given-names></name>. <article-title>Motivational control after extended instrumental training</article-title>. <source>Animal Learning &amp; Behavior</source>. <year>1995</year>;<volume>23</volume>(<issue>2</issue>):<fpage>197</fpage>–<lpage>206</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03199935" xlink:type="simple">10.3758/BF03199935</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yin</surname> <given-names>HH</given-names></name>, <name name-style="western"><surname>Knowlton</surname> <given-names>BJBJBJ</given-names></name>. <article-title>The role of the basal ganglia in habit formation</article-title>. <source>Nature reviews Neuroscience</source>. <year>2006</year>;<volume>7</volume>(<issue>6</issue>):<fpage>464</fpage>–<lpage>476</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn1919" xlink:type="simple">10.1038/nrn1919</ext-link></comment> <object-id pub-id-type="pmid">16715055</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hull</surname> <given-names>CL</given-names></name>. <article-title>Principles of Behavior: An Introduction to Behavior Theory</article-title>. In: <source>The Journal of Abnormal and Social Psychology</source>; <year>1943</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Seger</surname> <given-names>Ca</given-names></name>, <name name-style="western"><surname>Spiering</surname> <given-names>BJ</given-names></name>. <article-title>A critical review of habit learning and the Basal Ganglia</article-title>. <source>Frontiers in systems neuroscience</source>. <year>2011</year>;<volume>5</volume>(<issue>August</issue>):<fpage>66</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnsys.2011.00066" xlink:type="simple">10.3389/fnsys.2011.00066</ext-link></comment> <object-id pub-id-type="pmid">21909324</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dezfouli</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Balleine</surname> <given-names>BW</given-names></name>. <article-title>Habits, action sequences and reinforcement learning</article-title>. <source>European Journal of Neuroscience</source>. <year>2012</year>;<volume>35</volume>(<issue>7</issue>):<fpage>1036</fpage>–<lpage>1051</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1460-9568.2012.08050.x" xlink:type="simple">10.1111/j.1460-9568.2012.08050.x</ext-link></comment> <object-id pub-id-type="pmid">22487034</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gillan</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Otto</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Phelps</surname> <given-names>Ea</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>Model-based learning protects against forming habits</article-title>. <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source>. <year>2015</year>;<volume>15</volume>(<issue>3</issue>):<fpage>523</fpage>–<lpage>536</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13415-015-0347-6" xlink:type="simple">10.3758/s13415-015-0347-6</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Morris</surname> <given-names>LS</given-names></name>, <name name-style="western"><surname>Kundu</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dowell</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Mechelmans</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Favre</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Irvine</surname> <given-names>MA</given-names></name>, <etal>et al</etal>. <article-title>Fronto-striatal organization: Defining functional and microstructural substrates of behavioural flexibility</article-title>. <source>Cortex</source>. <year>2016</year>;<volume>74</volume>:<fpage>118</fpage>–<lpage>133</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cortex.2015.11.004" xlink:type="simple">10.1016/j.cortex.2015.11.004</ext-link></comment> <object-id pub-id-type="pmid">26673945</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Economides</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kurth-Nelson</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Lübbert</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Guitart-Masip</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Model-Based Reasoning in Humans Becomes Automatic with Training</article-title>. <source>PLoS Computational Biology</source>. <year>2015</year>;<volume>11</volume>(<issue>9</issue>):<fpage>1</fpage>–<lpage>19</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004463" xlink:type="simple">10.1371/journal.pcbi.1004463</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hélie</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Waldschmidt</surname> <given-names>JG</given-names></name>, <name name-style="western"><surname>Ashby</surname> <given-names>FG</given-names></name>. <article-title>Automaticity in rule-based and information-integration categorization</article-title>. <source>Attention, perception &amp; psychophysics</source>. <year>2010</year>;<volume>72</volume>(<issue>4</issue>):<fpage>1013</fpage>–<lpage>1031</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/APP.72.4.1013" xlink:type="simple">10.3758/APP.72.4.1013</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>MacLeod</surname> <given-names>CM</given-names></name>. <article-title>Half a century of research on the Stroop effect: An integrative review</article-title>. <source>Psychological Bulletin</source>. <year>1991</year>;<volume>109</volume>(<issue>2</issue>):<fpage>163</fpage>–<lpage>203</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-2909.109.2.163" xlink:type="simple">10.1037/0033-2909.109.2.163</ext-link></comment> <object-id pub-id-type="pmid">2034749</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Clark</surname> <given-names>A</given-names></name>. <article-title>Whatever next? Predictive brains, situated agents, and the future of cognitive science</article-title>. <source>The Behavioral and brain sciences</source>. <year>2013</year>;<volume>36</volume>(<issue>3</issue>):<fpage>181</fpage>–<lpage>204</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1017/S0140525X12000477" xlink:type="simple">10.1017/S0140525X12000477</ext-link></comment> <object-id pub-id-type="pmid">23663408</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kiebel</surname> <given-names>S</given-names></name>. <article-title>Predictive coding under the free-energy principle</article-title>. <source>Philosophical transactions of the Royal Society of London Series B, Biological sciences</source>. <year>2009</year>;<volume>364</volume>:<fpage>1211</fpage>–<lpage>1221</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rstb.2008.0300" xlink:type="simple">10.1098/rstb.2008.0300</ext-link></comment> <object-id pub-id-type="pmid">19528002</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hesselmann</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Sadaghiani</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Kleinschmidt</surname> <given-names>A</given-names></name>. <article-title>Predictive coding or evidence accumulation? False inference and neuronal fluctuations</article-title>. <source>PLoS ONE</source>. <year>2010</year>;<volume>5</volume>(<issue>3</issue>):<fpage>1</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0009926" xlink:type="simple">10.1371/journal.pone.0009926</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Computational psychiatry: the brain as a phantastic organ</article-title>. <source>The Lancet Psychiatry</source>. <year>2014</year>;<volume>1</volume>(<issue>2</issue>):<fpage>148</fpage>–<lpage>158</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S2215-0366(14)70275-5" xlink:type="simple">10.1016/S2215-0366(14)70275-5</ext-link></comment> <object-id pub-id-type="pmid">26360579</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mayrhauser</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Bergmann</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Crone</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kronbichler</surname> <given-names>M</given-names></name>. <article-title>Neural repetition suppression: evidence for perceptual expectation in object-selective regions</article-title>. <source>Frontiers in Human Neuroscience</source>. <year>2014</year>;<volume>8</volume>(<issue>April</issue>):<fpage>1</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2014.00225" xlink:type="simple">10.3389/fnhum.2014.00225</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Limongi</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Silva</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Góngora-Costa</surname> <given-names>B</given-names></name>. <article-title>Temporal prediction errors modulate task-switching performance</article-title>. <source>Frontiers in Psychology</source>. <year>2015</year>;<volume>6</volume>(<issue>August</issue>):<fpage>1</fpage>–<lpage>10</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2015.01185" xlink:type="simple">10.3389/fpsyg.2015.01185</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kneissler</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Drugowitsch</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Butz</surname> <given-names>MV</given-names></name>. <article-title>Simultaneous learning and filtering without delusions: a Bayes-optimal combination of Predictive Inference and Adaptive Filtering</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2015</year>;<volume>9</volume>(<issue>April</issue>):<fpage>1</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncom.2015.00047" xlink:type="simple">10.3389/fncom.2015.00047</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>. <article-title>A Bayesian foundation for individual learning under uncertainty</article-title>. <source>Frontiers in Human Neuroscience</source>. <year>2011</year>;<volume>5</volume>(<issue>May</issue>):<fpage>1</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2011.00039" xlink:type="simple">10.3389/fnhum.2011.00039</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mathys</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Lomakina</surname> <given-names>EI</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Iglesias</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Brodersen</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <etal>et al</etal>. <article-title>Uncertainty in perception and the Hierarchical Gaussian Filter</article-title>. <source>Frontiers in Human Neuroscience</source>. <year>2014</year>;<volume>8</volume>(<issue>November</issue>):<fpage>1</fpage>–<lpage>24</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2014.00825" xlink:type="simple">10.3389/fnhum.2014.00825</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Iglesias</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Brodersen</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Kasper</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Piccirelli</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>den Ouden</surname> <given-names>HEM</given-names></name>, <etal>et al</etal>. <article-title>Hierarchical Prediction Errors in Midbrain and Basal Forebrain during Sensory Learning</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>80</volume>(<issue>2</issue>):<fpage>519</fpage>–<lpage>530</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.09.009" xlink:type="simple">10.1016/j.neuron.2013.09.009</ext-link></comment> <object-id pub-id-type="pmid">24139048</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Vossel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bauer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <etal>et al</etal>. <article-title>Cholinergic stimulation enhances Bayesian belief updating in the deployment of spatial attention</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2014</year>;<volume>34</volume>(<issue>47</issue>):<fpage>15735</fpage>–<lpage>15742</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0091-14.2014" xlink:type="simple">10.1523/JNEUROSCI.0091-14.2014</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hauser</surname> <given-names>TU</given-names></name>, <name name-style="western"><surname>Iannaccone</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ball</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Brandeis</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Walitza</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Role of the Medial Prefrontal Cortex in Impaired Decision Making in Juvenile Attention-Deficit/Hyperactivity Disorder</article-title>. <source>JAMA Psychiatry</source>. <year>2014</year>;<volume>71</volume>(<issue>10</issue>):<fpage>1165</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1001/jamapsychiatry.2014.1093" xlink:type="simple">10.1001/jamapsychiatry.2014.1093</ext-link></comment> <object-id pub-id-type="pmid">25142296</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Diaconescu</surname> <given-names>AO</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Weber</surname> <given-names>LAE</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kasper</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Lomakina</surname> <given-names>EI</given-names></name>, <etal>et al</etal>. <article-title>Inferring on the Intentions of Others by Hierarchical Bayesian Learning</article-title>. <source>PLoS Computational Biology</source>. <year>2014</year>;<volume>10</volume>(<issue>9</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003810" xlink:type="simple">10.1371/journal.pcbi.1003810</ext-link></comment> <object-id pub-id-type="pmid">25187943</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schwartenbeck</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>FitzGerald</surname> <given-names>THB</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kronbichler</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>. <article-title>Evidence for surprise minimization over value maximization in choice behavior</article-title>. <source>Scientific Reports</source>. <year>2015</year>;<volume>5</volume>(<issue>1</issue>):<fpage>16575</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/srep16575" xlink:type="simple">10.1038/srep16575</ext-link></comment> <object-id pub-id-type="pmid">26564686</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brazil</surname> <given-names>IA</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Popma</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hoppenbrouwers</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Cohn</surname> <given-names>MD</given-names></name>. <article-title>Representational uncertainty in the brain during threat conditioning and the link with psychopathic traits</article-title>. <source>Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</source>. <year>2017</year>;(<issue>14</issue>):<fpage>1</fpage>–<lpage>7</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yu</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Uncertainty, neuromodulation, and attention</article-title>. <source>Neuron</source>. <year>2005</year>;<volume>46</volume>(<issue>4</issue>):<fpage>681</fpage>–<lpage>692</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2005.04.026" xlink:type="simple">10.1016/j.neuron.2005.04.026</ext-link></comment> <object-id pub-id-type="pmid">15944135</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Behrens</surname> <given-names>TEJ</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Walton</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MFS</given-names></name>. <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nature neuroscience</source>. <year>2007</year>;<volume>10</volume>(<issue>9</issue>):<fpage>1214</fpage>–<lpage>1221</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1954" xlink:type="simple">10.1038/nn1954</ext-link></comment> <object-id pub-id-type="pmid">17676057</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Doucet</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Johansen</surname> <given-names>AM</given-names></name>. <article-title>A Tutorial on Particle filtering and smoothing: Fiteen years later</article-title>. <source>The Oxford handbook of nonlinear filtering</source>. <year>2011</year>;(<issue>December 2008</issue>):<fpage>656</fpage>–<lpage>705</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref034">
<label>34</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Doucet</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>De Freitas</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Gordon</surname> <given-names>N</given-names></name>. <source>Sequential Monte Carlo Methods in Practice</source>. <publisher-name>Springer</publisher-name> <publisher-loc>New York</publisher-loc>. <year>2001</year>; p. <fpage>178</fpage>–<lpage>195</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1198/tech.2003.s23" xlink:type="simple">10.1198/tech.2003.s23</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref035">
<label>35</label>
<mixed-citation publication-type="other" xlink:type="simple">Azizi S, Quinn A. A data-driven forgetting factor for stabilized forgetting in approximate Bayesian filtering. In: 2015 26th Irish Signals and Systems Conference (ISSC). vol. 11855. IEEE; 2015. p. 1–6. Available from: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/document/7163747/" xlink:type="simple">http://ieeexplore.ieee.org/document/7163747/</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Smidl</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Quinn</surname> <given-names>A</given-names></name>. <article-title>Variational Bayesian Filtering</article-title>. <source>IEEE Transactions on Signal Processing</source>. <year>2008</year>;<volume>56</volume>(<issue>10</issue>):<fpage>5020</fpage>–<lpage>5030</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TSP.2008.928969" xlink:type="simple">10.1109/TSP.2008.928969</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref037">
<label>37</label>
<mixed-citation publication-type="other" xlink:type="simple">Smidl V, Gustafsson F. Bayesian estimation of forgetting factor in adaptive filtering and change detection. In: 2012 IEEE Statistical Signal Processing Workshop (SSP). 1. IEEE; 2012. p. 197–200. Available from: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/document/6319658/" xlink:type="simple">http://ieeexplore.ieee.org/document/6319658/</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Özkan</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Šmídl</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Saha</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lundquist</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Gustafsson</surname> <given-names>F</given-names></name>. <article-title>Marginalized adaptive particle filtering for nonlinear models with unknown time-varying noise parameters</article-title>. <source>Automatica</source>. <year>2013</year>;<volume>49</volume>(<issue>6</issue>):<fpage>1566</fpage>–<lpage>1575</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.automatica.2013.02.046" xlink:type="simple">10.1016/j.automatica.2013.02.046</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Laar</surname> <given-names>TVD</given-names></name>, <name name-style="western"><surname>Cox</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Diepen</surname> <given-names>AV</given-names></name>, <name name-style="western"><surname>Vries</surname> <given-names>BD</given-names></name>. <source>Variational Stabilized Linear Forgetting in State-Space Models</source>. <year>2017</year>;(<issue>Section II</issue>):<fpage>848</fpage>–<lpage>852</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Smidl</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Quinn</surname> <given-names>A</given-names></name>. <article-title>Mixture-based extension of the AR model and its recursive Bayesian identification</article-title>. <source>IEEE Transactions on Signal Processing</source>. <year>2005</year>;<volume>53</volume>(<issue>9</issue>):<fpage>3530</fpage>–<lpage>3542</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TSP.2005.853103" xlink:type="simple">10.1109/TSP.2005.853103</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Masegosa</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Nielsen</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Langseth</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Ramos-Lopez</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Salmeron</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Madsen</surname> <given-names>AL</given-names></name>. <article-title>Bayesian Models of Data Streams with Hierarchical Power Priors</article-title>. <source>International Conference on Machine Learning (ICM)</source>. <year>2017</year>;<volume>70</volume>:<fpage>2334</fpage>–<lpage>2343</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dedecius</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Hofman</surname> <given-names>R</given-names></name>. <article-title>Autoregressive model with partial forgetting within Rao-Blackwellized particle filter</article-title>. <source>Communications in Statistics: Simulation and Computation</source>. <year>2012</year>;<volume>41</volume>(<issue>5</issue>):<fpage>582</fpage>–<lpage>589</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/03610918.2011.598992" xlink:type="simple">10.1080/03610918.2011.598992</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>. <article-title>Introduction to Reinforcement Learning</article-title>. <source>Learning</source>. <year>1998</year>;<volume>4</volume>:<fpage>1</fpage>–<lpage>5</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref044">
<label>44</label>
<mixed-citation publication-type="other" xlink:type="simple">Dearden R, Friedman N, Russell S. Bayesian Q-Learning. In: American Association of Artificial Intelligence (AAAI)-98; 1998. p. 761–768.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref045">
<label>45</label>
<mixed-citation publication-type="other" xlink:type="simple">Dearden R, Dearden R, Friedman N, Friedman N, Andre D, Andre D. Model based Bayesian exploration. Proceedings of the fifteenth Conference on Uncertainty in Artificial Intelligence. 1999;(Howard 1966):150–159.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref046">
<label>46</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Bishop</surname> <given-names>CM</given-names></name>. <source>Pattern Recognition and Machine Learning</source>; <year>2006</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jaakkola</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>. <article-title>A variational approach to Bayesian logistic regression models and their extensions</article-title>. <source>Aistats</source>. <year>1996</year>;(<issue>AUGUST 2001</issue>).</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jaakkola</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>. <article-title>Bayesian parameter estimation via variational methods</article-title>. <source>Statistics And Computing</source>. <year>2000</year>;<volume>10</volume>(<issue>1</issue>):<fpage>25</fpage>–<lpage>37</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1023/A:1008932416310" xlink:type="simple">10.1023/A:1008932416310</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref049">
<label>49</label>
<mixed-citation publication-type="other" xlink:type="simple">Blei DM, Kucukelbir A, McAuliffe JD. Variational Inference: A Review for Statisticians. arXiv. 2016; p. 1–33.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Paisley</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Blei</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Jordan</surname> <given-names>M</given-names></name>. <article-title>Variational Bayesian Inference with Stochastic Search</article-title>. <source>Icml</source>. <year>2012</year>;(<issue>2000</issue>):<fpage>1367</fpage>–<lpage>1374</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref051">
<label>51</label>
<mixed-citation publication-type="other" xlink:type="simple">Salimans T, Kingma DP, Welling M. Markov Chain Monte Carlo and Variational Inference: Bridging the Gap. International Conference on Machine Learning. 2015;.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kingma</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Rezende</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Mohamed</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Welling</surname> <given-names>M</given-names></name>. <source>Semi-Supervised Learning with Deep Generative Models</source>. <year>2014</year>; p. <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref053">
<label>53</label>
<mixed-citation publication-type="other" xlink:type="simple">Ranganath R, Tran D, Blei DM. Hierarchical Variational Models. arXiv. 2014; p. 1–9.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref054">
<label>54</label>
<mixed-citation publication-type="other" xlink:type="simple">Rezende DJ, Mohamed S. Variational Inference with Normalizing Flows. Proceedings of the 32nd International Conference on Machine Learning. 2015;37:1530–1538.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Blei</surname> <given-names>DM</given-names></name>. <article-title>Variational Inference</article-title>. <source>CsPrincetonEdu</source>. <year>2002</year>; p. <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref056">
<label>56</label>
<mixed-citation publication-type="other" xlink:type="simple">V Smidl AQ. Bayesian estimation of non-stationary AR model parameters via an unknown forgetting factor. In: 3rd IEEE Signal Processing Education Workshop. 2004 IEEE 11th Digital Signal Processing Workshop, 2004. 6. IEEE; 2004. p. 221–225. Available from: <ext-link ext-link-type="uri" xlink:href="http://staff.utia.cas.cz/smidl/files/publ/taos04.pdfhttp://ieeexplore.ieee.org/document/1437946/" xlink:type="simple">http://staff.utia.cas.cz/smidl/files/publ/taos04.pdfhttp://ieeexplore.ieee.org/document/1437946/</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref057">
<label>57</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Smidl</surname> <given-names>V</given-names></name>. <source>The Variational Bayes Approach in Signal Processing</source>; <year>2004</year>. Available from: <ext-link ext-link-type="uri" xlink:href="http://staff.utia.cz/smidl/Public/Thesis-final.pdf" xlink:type="simple">http://staff.utia.cz/smidl/Public/Thesis-final.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Knowles</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Minka</surname> <given-names>TP</given-names></name>. <article-title>Non-conjugate variational message passing for multinomial and binary regression</article-title>. <source>Nips</source>. <year>2011</year>; p. <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bottou</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Peters</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ch</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Quiñonero-Candela</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Charles</surname> <given-names>DX</given-names></name>, <name name-style="western"><surname>Chickering</surname> <given-names>DM</given-names></name>, <etal>et al</etal>. <article-title>Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising</article-title>. <source>Journal of Machine Learning Research</source>. <year>2013</year>;<volume>14</volume>:<fpage>3207</fpage>–<lpage>3260</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref060">
<label>60</label>
<mixed-citation publication-type="other" xlink:type="simple">Foerster J, Farquhar G, Afouras T, Nardelli N, Whiteson S. Counterfactual Multi-Agent Policy Gradients. Arxiv. 2017; p. 1–12.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref061">
<label>61</label>
<mixed-citation publication-type="other" xlink:type="simple">Lawrence C, Sokolov A, Riezler S. Counterfactual Learning from Bandit Feedback under Deterministic Logging: A Case Study in Statistical Machine Translation. 2017;.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mischel</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Ebbesen</surname> <given-names>EB</given-names></name>, <name name-style="western"><surname>Raskoff Zeiss</surname> <given-names>A</given-names></name>. <article-title>Cognitive and attentional mechanisms in delay of gratification</article-title>. <source>Journal of Personality and Social Psychology</source>. <year>1972</year>;<volume>21</volume>(<issue>2</issue>):<fpage>204</fpage>–<lpage>218</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0032198" xlink:type="simple">10.1037/h0032198</ext-link></comment> <object-id pub-id-type="pmid">5010404</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Weatherly</surname> <given-names>JN</given-names></name>. <article-title>On several factors that control rates of discounting</article-title>. <source>Behavioural Processes</source>. <year>2014</year>;<volume>104</volume>:<fpage>84</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.beproc.2014.01.020" xlink:type="simple">10.1016/j.beproc.2014.01.020</ext-link></comment> <object-id pub-id-type="pmid">24487030</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Story</surname> <given-names>GW</given-names></name>, <name name-style="western"><surname>Vlaev</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Darzi</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Does temporal discounting explain unhealthy behavior? A systematic review and reinforcement learning perspective</article-title>. <source>Frontiers in behavioral neuroscience</source>. <year>2014</year>;<volume>8</volume>(<issue>March</issue>):<fpage>76</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnbeh.2014.00076" xlink:type="simple">10.3389/fnbeh.2014.00076</ext-link></comment> <object-id pub-id-type="pmid">24659960</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McClure</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Laibson</surname> <given-names>DI</given-names></name>, <name name-style="western"><surname>Loewenstein</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>Separate neural systems value immediate and delayed monetary rewards</article-title>. <source>Science (New York, NY)</source>. <year>2004</year>;<volume>306</volume>(<issue>5695</issue>):<fpage>503</fpage>–<lpage>507</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1100907" xlink:type="simple">10.1126/science.1100907</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Updating dopamine reward signals</article-title>. <source>Current opinion in neurobiology</source>. <year>2013</year>;<volume>23</volume>(<issue>2</issue>):<fpage>229</fpage>–<lpage>238</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2012.11.012" xlink:type="simple">10.1016/j.conb.2012.11.012</ext-link></comment> <object-id pub-id-type="pmid">23267662</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bermudez</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Timing in reward and decision processes</article-title>. <source>Philosophical transactions of the Royal Society of London Series B, Biological sciences</source>. <year>2014</year>;<volume>369</volume>(<issue>1637</issue>):<fpage>20120468</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rstb.2012.0468" xlink:type="simple">10.1098/rstb.2012.0468</ext-link></comment> <object-id pub-id-type="pmid">24446502</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref068">
<label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Takahashi</surname> <given-names>T</given-names></name>. <article-title>Loss of self-control in intertemporal choice may be attributable to logarithmic time-perception</article-title>. <source>Medical Hypotheses</source>. <year>2005</year>;<volume>65</volume>(<issue>4</issue>):<fpage>691</fpage>–<lpage>693</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.mehy.2005.04.040" xlink:type="simple">10.1016/j.mehy.2005.04.040</ext-link></comment> <object-id pub-id-type="pmid">15990243</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref069">
<label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Vincent</surname> <given-names>BT</given-names></name>. <article-title>Hierarchical Bayesian estimation and hypothesis testing for delay discounting tasks</article-title>. <source>Behavior Research Methods</source>. <year>2015</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13428-015-0672-2" xlink:type="simple">10.3758/s13428-015-0672-2</ext-link></comment> <object-id pub-id-type="pmid">26542975</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kurth-Nelson</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Bickel</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Redish</surname> <given-names>AD</given-names></name>. <article-title>A theoretical account of cognitive effects in delay discounting</article-title>. <source>European Journal of Neuroscience</source>. <year>2012</year>;<volume>35</volume>(<issue>7</issue>):<fpage>1052</fpage>–<lpage>1064</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1460-9568.2012.08058.x" xlink:type="simple">10.1111/j.1460-9568.2012.08058.x</ext-link></comment> <object-id pub-id-type="pmid">22487035</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref071">
<label>71</label>
<mixed-citation publication-type="other" xlink:type="simple">Wyatt J. Exploration and Inference in Learning From Reinforcement; 1998. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.era.lib.ed.ac.uk/handle/1842/532" xlink:type="simple">https://www.era.lib.ed.ac.uk/handle/1842/532</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref072">
<label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Thompson</surname> <given-names>WR</given-names></name>. <article-title>On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of Two Samples</article-title>. <source>Biometrika</source>. <year>1933</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/biomet/25.3-4.285" xlink:type="simple">10.1093/biomet/25.3-4.285</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kaufmann</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Korda</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Munos</surname> <given-names>R</given-names></name>. <article-title>Thompson Sampling: An Asymptotically Optimal Finite Time Analysis</article-title>. <source>International Conference on Algorithmic Learning Theory</source>. <year>2012</year>;(<issue>1</issue>):<fpage>199</fpage>–<lpage>213</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-3-642-34106-9_18" xlink:type="simple">10.1007/978-3-642-34106-9_18</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref074">
<label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Keramati</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dezfouli</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Piray</surname> <given-names>P</given-names></name>. <article-title>Speed/accuracy trade-off between the habitual and the goal-directed processes</article-title>. <source>PLoS computational biology</source>. <year>2011</year>;<volume>7</volume>(<issue>5</issue>):<fpage>e1002055</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002055" xlink:type="simple">10.1371/journal.pcbi.1002055</ext-link></comment> <object-id pub-id-type="pmid">21637741</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref075">
<label>75</label>
<mixed-citation publication-type="other" xlink:type="simple">Viejo G, Khamassi M, Brovelli A, Girard B. Modelling choice and reaction time during instrumental learning through the coordination of adaptive working memory and reinforcement learning. Fourth Symposium on Biology of Decision—Making (SBDM 2014). 2014;9(August).</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref076">
<label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mcallister</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Dziugaite</surname> <given-names>K</given-names></name>. <source>Bayesian Reinforcement Learning</source>. <year>2013</year>;<volume>35</volume>(<issue>March</issue>):<fpage>1</fpage>–<lpage>21</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref077">
<label>77</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Feller</surname> <given-names>W</given-names></name>. <source>An Introduction to Probability Theory and Its Applications</source>. <publisher-name>Wiley</publisher-name>. <year>1968</year>;<volume>2</volume>:<fpage>509</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref078">
<label>78</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name>. <article-title>A theory of memory retrieval</article-title>. <source>Psychological Review</source>. <year>1978</year>;<volume>85</volume>(<issue>2</issue>):<fpage>59</fpage>–<lpage>108</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.85.2.59" xlink:type="simple">10.1037/0033-295X.85.2.59</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref079">
<label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Smith</surname> <given-names>PL</given-names></name>. <article-title>Stochastic Dynamic Models of Response Time and Accuracy: A Foundational Primer</article-title>. <source>Journal of Mathematical Psychology</source>. <year>2000</year>;<volume>44</volume>(<issue>3</issue>):<fpage>408</fpage>–<lpage>463</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/jmps.1999.1260" xlink:type="simple">10.1006/jmps.1999.1260</ext-link></comment> <object-id pub-id-type="pmid">10973778</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref080">
<label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Amari</surname> <given-names>Si</given-names></name>. <article-title>Natural Gradient Works Efficiently in Learning</article-title>. <source>Neural Computation</source>. <year>1998</year>;<volume>10</volume>(<issue>2</issue>):<fpage>251</fpage>–<lpage>276</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089976698300017746" xlink:type="simple">10.1162/089976698300017746</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref081">
<label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sato</surname> <given-names>MA</given-names></name>. <article-title>Online Model Selection Based on the Variational Bayes</article-title>. <source>Neural Comput</source>. <year>2001</year>;<volume>13</volume>(<issue>7</issue>):<fpage>1649</fpage>–<lpage>1681</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089976601750265045" xlink:type="simple">10.1162/089976601750265045</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref082">
<label>82</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hoffman</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Blei</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Paisley</surname> <given-names>J</given-names></name>. <source>Stochastic Variational Inference</source>. <year>2012</year>;.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref083">
<label>83</label>
<mixed-citation publication-type="other" xlink:type="simple">Martens J. New insights and perspectives on the natural gradient method. 2014;.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref084">
<label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ghosal</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ghosh</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>van der Vaart</surname> <given-names>AW</given-names></name>. <article-title>Convergence rates of posterior distributions</article-title>. <source>The Annals of Statistics</source>. <year>2000</year>;<volume>28</volume>(<issue>2</issue>):<fpage>500</fpage>–<lpage>531</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1214/aos/1016218228" xlink:type="simple">10.1214/aos/1016218228</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref085">
<label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zenon</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Solopchuk</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Pezzulo</surname> <given-names>G</given-names></name>. <article-title>An information-theoretic perspective on the costs of cognition</article-title>. <source>bioRxiv</source>. <year>2018</year>; p. 208280. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/208280" xlink:type="simple">10.1101/208280</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref086">
<label>86</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Moens</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Zenon</surname> <given-names>A</given-names></name>. <article-title>Recurrent Auto-Encoding Drift Diffusion Model</article-title>. <source>bioRxiv</source>. <year>2018</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/220517" xlink:type="simple">10.1101/220517</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref087">
<label>87</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mnih</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Gregor</surname> <given-names>K</given-names></name>. <article-title>Neural Variational Inference and Learning in Belief Networks</article-title>. <source>ArXiv statML</source>. <year>2014</year>;<volume>32</volume>(<issue>October</issue>):<fpage>1</fpage>–<lpage>20</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref088">
<label>88</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Mattout</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Trujillo-Barreto</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Ashburner</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Penny</surname> <given-names>W</given-names></name>. <article-title>Variational free energy and the Laplace approximation</article-title>. <source>NeuroImage</source>. <year>2007</year>;<volume>34</volume>(<issue>1</issue>):<fpage>220</fpage>–<lpage>234</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2006.08.035" xlink:type="simple">10.1016/j.neuroimage.2006.08.035</ext-link></comment> <object-id pub-id-type="pmid">17055746</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref089">
<label>89</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>Trial-by-trial data analysis using computational models</article-title>. <source>Attention &amp; Performance XXIII</source>. <year>2011</year>; p. <fpage>1</fpage>–<lpage>26</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref090">
<label>90</label>
<mixed-citation publication-type="other" xlink:type="simple">Kingma DP, Welling M. Auto-Encoding Variational Bayes. 2013;.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref091">
<label>91</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Tuerlinckx</surname> <given-names>F</given-names></name>. <article-title>Estimating parameters of the diffusion model: Approaches to dealing with contaminant reaction times and parameter variability</article-title>. <source>Psychonomic Bulletin &amp; Review</source>. <year>2002</year>;<volume>9</volume>(<issue>3</issue>):<fpage>438</fpage>–<lpage>481</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03196302" xlink:type="simple">10.3758/BF03196302</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref092">
<label>92</label>
<mixed-citation publication-type="other" xlink:type="simple">Kingma DP, Ba JL. Adam: a Method for Stochastic Optimization. International Conference on Learning Representations 2015. 2015; p. 1–15.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref093">
<label>93</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dickinson</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Nicholas</surname> <given-names>DJ</given-names></name>. <article-title>Irrelevant incentive learning during instrumental conditioning: The role of the drive-reinforcer and response-reinforcer relationships</article-title>. <source>The Quarterly Journal of Experimental Psychology Section B</source>. <year>1983</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref094">
<label>94</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wood</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Ruenger</surname> <given-names>D</given-names></name>. <article-title>Psychology of Habit</article-title>. <source>Annual Review of Psychology</source>. <year>2015</year>;(<issue>September</issue>):<fpage>1</fpage>–<lpage>26</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref095">
<label>95</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Goal-directed control and its antipodes</article-title>. <source>Neural Networks</source>. <year>2009</year>;<volume>22</volume>(<issue>3</issue>):<fpage>213</fpage>–<lpage>219</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neunet.2009.03.004" xlink:type="simple">10.1016/j.neunet.2009.03.004</ext-link></comment> <object-id pub-id-type="pmid">19362448</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref096">
<label>96</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Goals and habits in the brain</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>80</volume>(<issue>2</issue>):<fpage>312</fpage>–<lpage>325</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.09.007" xlink:type="simple">10.1016/j.neuron.2013.09.007</ext-link></comment> <object-id pub-id-type="pmid">24139036</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref097">
<label>97</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Kahneman</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Frederick</surname> <given-names>S</given-names></name>. <chapter-title>Representativeness Revisited: Attribute Substitution in Intuitive Judgment</chapter-title>. In: <name name-style="western"><surname>Gilovich</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Griffin</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Kahneman</surname> <given-names>D</given-names></name>, editors. <source>Heuristics and Biases</source>. <publisher-name>Cambridge University Press</publisher-name>; <year>2001</year>. p. <fpage>49</fpage>–<lpage>81</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://ebooks.cambridge.org/ref/id/CBO9780511808098A012" xlink:type="simple">http://ebooks.cambridge.org/ref/id/CBO9780511808098A012</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref098">
<label>98</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schneider</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Shiffrin</surname> <given-names>RM</given-names></name>. <article-title>Controlled and Automatic Human Information Processing: I. Detection, Search, and Attention</article-title>. <source>Psychological Review</source>. <year>1977</year>;<volume>84</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.84.1.1" xlink:type="simple">10.1037/0033-295X.84.1.1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref099">
<label>99</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Moors</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>De Houwer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Houwer</surname> <given-names>JD</given-names></name>. <article-title>Automaticity: A Theoretical and Conceptual Analysis</article-title>. <source>Psychological Bulletin</source>. <year>2006</year>;<volume>132</volume>(<issue>2</issue>):<fpage>297</fpage>–<lpage>326</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-2909.132.2.297" xlink:type="simple">10.1037/0033-2909.132.2.297</ext-link></comment> <object-id pub-id-type="pmid">16536645</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref100">
<label>100</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ashby</surname> <given-names>FG</given-names></name>, <name name-style="western"><surname>Crossley</surname> <given-names>MJ</given-names></name>. <article-title>Automaticity and multiple memory systems</article-title>. <source>Wiley Interdisciplinary Reviews: Cognitive Science</source>. <year>2012</year>;<volume>3</volume>(<issue>3</issue>):<fpage>363</fpage>–<lpage>376</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/wcs.1172" xlink:type="simple">10.1002/wcs.1172</ext-link></comment> <object-id pub-id-type="pmid">26301468</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref101">
<label>101</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Waldschmidt</surname> <given-names>JG</given-names></name>, <name name-style="western"><surname>Ashby</surname> <given-names>FG</given-names></name>. <article-title>Cortical and striatal contributions to automaticity in information-integration categorization</article-title>. <source>NeuroImage</source>. <year>2011</year>;<volume>56</volume>(<issue>3</issue>):<fpage>1791</fpage>–<lpage>1802</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2011.02.011" xlink:type="simple">10.1016/j.neuroimage.2011.02.011</ext-link></comment> <object-id pub-id-type="pmid">21316475</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref102">
<label>102</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hanes</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Schall</surname> <given-names>JD</given-names></name>. <article-title>Neural control of voluntary movement initiation</article-title>. <source>Science</source>. <year>1996</year>;<volume>274</volume>(<issue>5286</issue>):<fpage>427</fpage>–<lpage>430</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.274.5286.427" xlink:type="simple">10.1126/science.274.5286.427</ext-link></comment> <object-id pub-id-type="pmid">8832893</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref103">
<label>103</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roitman</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>. <article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2002</year>;<volume>22</volume>(<issue>21</issue>):<fpage>9475</fpage>–<lpage>9489</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.22-21-09475.2002" xlink:type="simple">10.1523/JNEUROSCI.22-21-09475.2002</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref104">
<label>104</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Soltani</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>XJ</given-names></name>. <article-title>Synaptic computation underlying probabilistic inference</article-title>. <source>Nature Neuroscience</source>. <year>2010</year>;<volume>13</volume>(<issue>1</issue>):<fpage>112</fpage>–<lpage>119</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2450" xlink:type="simple">10.1038/nn.2450</ext-link></comment> <object-id pub-id-type="pmid">20010823</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref105">
<label>105</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gluth</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rieskamp</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Buchel</surname> <given-names>C</given-names></name>. <article-title>Deciding When to Decide: Time-Variant Sequential Sampling Models Explain the Emergence of Value-Based Decisions in the Human Brain</article-title>. <source>Journal of Neuroscience</source>. <year>2012</year>;<volume>32</volume>(<issue>31</issue>):<fpage>10686</fpage>–<lpage>10698</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0727-12.2012" xlink:type="simple">10.1523/JNEUROSCI.0727-12.2012</ext-link></comment> <object-id pub-id-type="pmid">22855817</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref106">
<label>106</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rombouts</surname> <given-names>JO</given-names></name>, <name name-style="western"><surname>Bohte</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Roelfsema</surname> <given-names>PR</given-names></name>. <article-title>Neurally Plausible Reinforcement Learning of Working Memory Tasks</article-title>. <source>Nips</source>. <year>2012</year>; p. <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref107">
<label>107</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kurzawa</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Summerfield</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Bogacz</surname> <given-names>R</given-names></name>. <article-title>Neural Circuits Trained with Standard Reinforcement Learning Can Accumulate Probabilistic Information during Decision Making</article-title>. <source>Neural Computation</source>. <year>2017</year>;<volume>29</volume>(<issue>2</issue>):<fpage>368</fpage>–<lpage>393</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/NECO_a_00917" xlink:type="simple">10.1162/NECO_a_00917</ext-link></comment> <object-id pub-id-type="pmid">27870610</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref108">
<label>108</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Smith</surname> <given-names>PL</given-names></name>, <name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name>. <chapter-title>Diffusion and Random Walk Processes</chapter-title>. In: <collab>Elsevier Ltd</collab>, editor. <source>International Encyclopedia of the Social &amp; Behavioral Sciences</source>. <volume>vol. 6</volume>. <publisher-name>Elsevier</publisher-name>; <year>2015</year>. p. <fpage>395</fpage>–<lpage>401</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.sciencedirect.com/science/article/pii/B0080430767006203http://linkinghub.elsevier.com/retrieve/pii/B9780080970868430370" xlink:type="simple">http://www.sciencedirect.com/science/article/pii/B0080430767006203http://linkinghub.elsevier.com/retrieve/pii/B9780080970868430370</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref109">
<label>109</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Gagne</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Nyhus</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Masters</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wiecki</surname> <given-names>TV</given-names></name>, <name name-style="western"><surname>Cavanagh</surname> <given-names>JF</given-names></name>, <etal>et al</etal>. <article-title>fMRI and EEG Predictors of Dynamic Decision Parameters during Human Reinforcement Learning</article-title>. <source>Journal of Neuroscience</source>. <year>2015</year>;<volume>35</volume>(<issue>2</issue>):<fpage>485</fpage>–<lpage>494</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2036-14.2015" xlink:type="simple">10.1523/JNEUROSCI.2036-14.2015</ext-link></comment> <object-id pub-id-type="pmid">25589744</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref110">
<label>110</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pedersen</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Biele</surname> <given-names>G</given-names></name>. <article-title>The drift diffusion model as the choice rule in reinforcement learning</article-title>. <source>Psychonomic Bulletin &amp; Review</source>. <year>2017</year>;<volume>24</volume>(<issue>4</issue>):<fpage>1234</fpage>–<lpage>1251</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13423-016-1199-y" xlink:type="simple">10.3758/s13423-016-1199-y</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref111">
<label>111</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bornstein</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Khaw</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Shohamy</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>Reminders of past choices bias decisions for reward in humans</article-title>. <source>Nature Communications</source>. <year>2017</year>;<volume>8</volume>(<issue>May 2015</issue>):<fpage>15958</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ncomms15958" xlink:type="simple">10.1038/ncomms15958</ext-link></comment> <object-id pub-id-type="pmid">28653668</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref112">
<label>112</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bornstein</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Norman</surname> <given-names>KA</given-names></name>. <article-title>Reinstated episodic context guides sampling-based decisions for reward</article-title>. <source>Nature Neuroscience</source>. <year>2017</year>;<volume>20</volume>(<issue>7</issue>):<fpage>997</fpage>–<lpage>1003</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4573" xlink:type="simple">10.1038/nn.4573</ext-link></comment> <object-id pub-id-type="pmid">28581478</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref113">
<label>113</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lintusaari</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gutmann</surname> <given-names>MU</given-names></name>, <name name-style="western"><surname>Dutta</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kaski</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Corander</surname> <given-names>J</given-names></name>. <article-title>Fundamentals and recent developments in approximate Bayesian computation</article-title>. <source>Systematic Biology</source>. <year>2017</year>;<volume>66</volume>(<issue>1</issue>):<fpage>e66</fpage>–<lpage>e82</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/sysbio/syw077" xlink:type="simple">10.1093/sysbio/syw077</ext-link></comment> <object-id pub-id-type="pmid">28175922</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref114">
<label>114</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cavanagh</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Wiecki</surname> <given-names>TV</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>MX</given-names></name>, <name name-style="western"><surname>Figueroa</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Samanta</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sherman</surname> <given-names>SJ</given-names></name>, <etal>et al</etal>. <article-title>Subthalamic nucleus stimulation reverses mediofrontal influence over decision threshold</article-title>. <source>Nature Neuroscience</source>. <year>2011</year>;<volume>14</volume>(<issue>11</issue>):<fpage>1462</fpage>–<lpage>1467</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2925" xlink:type="simple">10.1038/nn.2925</ext-link></comment> <object-id pub-id-type="pmid">21946325</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref115">
<label>115</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mulder</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Wagenmakers</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Boekel</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Forstmann</surname> <given-names>BU</given-names></name>. <article-title>Bias in the brain: a diffusion model analysis of prior probability and potential payoff</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2012</year>;<volume>32</volume>(<issue>7</issue>):<fpage>2335</fpage>–<lpage>2343</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.4156-11.2012" xlink:type="simple">10.1523/JNEUROSCI.4156-11.2012</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref116">
<label>116</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Morita</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kato</surname> <given-names>A</given-names></name>. <article-title>Striatal dopamine ramping may indicate flexible reinforcement learning with forgetting in the cortico-basal ganglia circuits</article-title>. <source>Frontiers in Neural Circuits</source>. <year>2014</year>;<volume>8</volume>(<issue>April</issue>):<fpage>1</fpage>–<lpage>15</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref117">
<label>117</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kato</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Morita</surname> <given-names>K</given-names></name>. <article-title>Forgetting in Reinforcement Learning Links Sustained Dopamine Signals to Motivation</article-title>. <source>PLoS Computational Biology</source>. <year>2016</year>;<volume>12</volume>(<issue>10</issue>):<fpage>1</fpage>–<lpage>41</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005145" xlink:type="simple">10.1371/journal.pcbi.1005145</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref118">
<label>118</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kulhavy</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Karny</surname> <given-names>M</given-names></name>. <article-title>Tracking of slowly varying parameters by directional forgetting</article-title>. <source>Preprints 9ih IFAC Congress</source>. <year>1984</year>;<volume>10</volume>:<fpage>178</fpage>–<lpage>183</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref119">
<label>119</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kulhavý</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kraus</surname> <given-names>FJ</given-names></name>. <article-title>On Duality of Exponential and Linear Forgetting</article-title>. <source>IFAC Proceedings Volumes</source>. <year>1996</year>;<volume>29</volume>(<issue>1</issue>):<fpage>5340</fpage>–<lpage>5345</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S1474-6670(17)58530-4" xlink:type="simple">10.1016/S1474-6670(17)58530-4</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref120">
<label>120</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kárný</surname> <given-names>M</given-names></name>. <article-title>Approximate Bayesian recursive estimation</article-title>. <source>Information Sciences</source>. <year>2014</year>;<volume>285</volume>(<issue>1</issue>):<fpage>100</fpage>–<lpage>111</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref121">
<label>121</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McGuire</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Nassar</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Kable</surname> <given-names>JW</given-names></name>. <article-title>Functionally Dissociable Influences on Learning Rate in a Dynamic Environment</article-title>. <source>Neuron</source>. <year>2014</year>;<volume>84</volume>(<issue>4</issue>):<fpage>870</fpage>–<lpage>881</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2014.10.013" xlink:type="simple">10.1016/j.neuron.2014.10.013</ext-link></comment> <object-id pub-id-type="pmid">25459409</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref122">
<label>122</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nassar</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Bruckner</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Heekeren</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Eppinger</surname> <given-names>B</given-names></name>. <article-title>Age differences in learning emerge from an insufficient representation of uncertainty in older adults</article-title>. <source>Nature Communications</source>. <year>2016</year>;<volume>7</volume>(<issue>May 2015</issue>):<fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref123">
<label>123</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Doll</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Simon</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>The ubiquity of model-based reinforcement learning</article-title>. <source>Current opinion in neurobiology</source>. <year>2012</year>;<volume>22</volume>(<issue>6</issue>):<fpage>1075</fpage>–<lpage>1081</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2012.08.003" xlink:type="simple">10.1016/j.conb.2012.08.003</ext-link></comment> <object-id pub-id-type="pmid">22959354</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref124">
<label>124</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Gershman</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Model-based influences on humans’ choices and striatal prediction errors</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>69</volume>(<issue>6</issue>):<fpage>1204</fpage>–<lpage>1215</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2011.02.027" xlink:type="simple">10.1016/j.neuron.2011.02.027</ext-link></comment> <object-id pub-id-type="pmid">21435563</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref125">
<label>125</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wunderlich</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Smittenaar</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Dopamine enhances model-based over model-free choice behavior</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>75</volume>(<issue>3</issue>):<fpage>418</fpage>–<lpage>424</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2012.03.042" xlink:type="simple">10.1016/j.neuron.2012.03.042</ext-link></comment> <object-id pub-id-type="pmid">22884326</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref126">
<label>126</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Otto</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Raio</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Chiang</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Phelps</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>Working-memory capacity protects model-based learning from stress</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2013</year>;<volume>110</volume>(<issue>52</issue>):<fpage>20941</fpage>–<lpage>20946</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1312011110" xlink:type="simple">10.1073/pnas.1312011110</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref127">
<label>127</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schad</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Jünger</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Sebold</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Garbusow</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bernhardt</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Javadi</surname> <given-names>AH</given-names></name>, <etal>et al</etal>. <article-title>Processing speed enhances model-based over model-free reinforcement learning in the presence of high working memory functioning</article-title>. <source>Frontiers in Psychology</source>. <year>2014</year>;<volume>5</volume>(<issue>December</issue>):<fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006713.ref128">
<label>128</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kool</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Gershman</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Cushman</surname> <given-names>FA</given-names></name>. <article-title>Cost-Benefit Arbitration Between Multiple Reinforcement-Learning Systems</article-title>. <source>Psychological Science</source>. <year>2017</year>; p. 095679761770828. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797617708288" xlink:type="simple">10.1177/0956797617708288</ext-link></comment> <object-id pub-id-type="pmid">28731839</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006713.ref129">
<label>129</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gläscher</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Doherty</surname> <given-names>JPO</given-names></name>, <name name-style="western"><surname>Gläscher</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Article States versus Rewards: Dissociable Neural Prediction Error Signals Underlying Model-Based and Model-Free Reinforcement Learning</article-title>. <source>Neuron</source>. <year>2010</year>;<volume>66</volume>(<issue>4</issue>):<fpage>585</fpage>–<lpage>595</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2010.04.016" xlink:type="simple">10.1016/j.neuron.2010.04.016</ext-link></comment> <object-id pub-id-type="pmid">20510862</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
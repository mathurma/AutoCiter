<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">09-PLCB-RA-0692R3</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000555</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology/Computational Neuroscience</subject><subject>Neuroscience/Sensory Systems</subject><subject>Computer Science/Natural and Synthetic Vision</subject><subject>Neuroscience/Natural and Synthetic Vision</subject></subj-group></article-categories><title-group><article-title>Robust Models for Optic Flow Coding in Natural Scenes Inspired by Insect Biology</article-title><alt-title alt-title-type="running-head">Bioinspired Velocity Detection</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Brinkworth</surname><given-names>Russell S. A.</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>O'Carroll</surname><given-names>David C.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
</contrib-group><aff id="aff1">          <addr-line>Discipline of Physiology, School of Molecular and Biomedical Science, The University of Adelaide, South Australia, Australia</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Graham</surname><given-names>Lyle J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">Université Paris Descartes, Centre National de la Recherche Scientifique, France</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">russell.brinkworth@adelaide.edu.au</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: RSB DCO. Performed the experiments: RSB. Analyzed the data: RSB. Contributed reagents/materials/analysis tools: RSB DCO. Wrote the paper: RSB DCO.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>11</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>6</day><month>11</month><year>2009</year></pub-date><volume>5</volume><issue>11</issue><elocation-id>e1000555</elocation-id><history>
<date date-type="received"><day>15</day><month>6</month><year>2009</year></date>
<date date-type="accepted"><day>2</day><month>10</month><year>2009</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2009</copyright-year><copyright-holder>Brinkworth, O'Carroll</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>The extraction of accurate self-motion information from the visual world is a difficult problem that has been solved very efficiently by biological organisms utilizing non-linear processing. Previous bio-inspired models for motion detection based on a correlation mechanism have been dogged by issues that arise from their sensitivity to undesired properties of the image, such as contrast, which vary widely between images. Here we present a model with multiple levels of non-linear dynamic adaptive components based directly on the known or suspected responses of neurons within the visual motion pathway of the fly brain. By testing the model under realistic high-dynamic range conditions we show that the addition of these elements makes the motion detection model robust across a large variety of images, velocities and accelerations. Furthermore the performance of the entire system is more than the incremental improvements offered by the individual components, indicating beneficial non-linear interactions between processing stages. The algorithms underlying the model can be implemented in either digital or analog hardware, including neuromorphic analog VLSI, but defy an analytical solution due to their dynamic non-linear operation. The successful application of this algorithm has applications in the development of miniature autonomous systems in defense and civilian roles, including robotics, miniature unmanned aerial vehicles and collision avoidance sensors.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>Building artificial vision systems that work robustly in a variety of environments has been difficult, with systems often only performing well under restricted conditions. In contrast, animal vision operates effectively under extremely variable situations. Many attempts to emulate biological vision have met with limited success, often because multiple seemingly appropriate approximations to neural coding resulted in a compromised system. We have constructed a full model for motion processing in the insect visual pathway incorporating known or suspected elements in as much detail as possible. We have found that it is only once all elements are present that the system performs robustly, with reduction or removal of elements dramatically limiting performance. The implementation of this new algorithm could provide a very useful and robust velocity estimator for artificial navigation systems.</p>
</abstract><funding-group><funding-statement>The project was supported by grants from the Australian Research Council (LP0667744 and DP0986683) and the US Air Force Office of Scientific Research (FA 9550-04-1-0294). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="14"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>The extraction of useful motion cues for navigation through visual scenes is technically challenging. While artificial systems struggle to solve this task in real time, insects with low-resolution eyes and small brains (less than a million neurons) <xref ref-type="bibr" rid="pcbi.1000555-Strausfeld1">[1]</xref> are able to avoid obstacles and successfully navigate through complex surrounds during high-speed flight <xref ref-type="bibr" rid="pcbi.1000555-Land1">[2]</xref>. This efficiency is inspiring for software engineers who struggle to achieve similar performance in artificial vision utilizing high resolution cameras, sophisticated software, and computers with hundreds of millions of transistors. Furthermore, insect vision has many unique features that lend it to useful applications. Despite inherently low resolution in even the best fly eyes <xref ref-type="bibr" rid="pcbi.1000555-Land2">[3]</xref> and visual processing that is simple and tractable enough for modeling, insects achieve spectacular flight control using passive visual sensors. Accurate models of such a system would allow replication of an insect's ability to discriminate visual scenes based on contrast, shadow, motion etc <xref ref-type="bibr" rid="pcbi.1000555-Srinivasan1">[4]</xref>.</p>
<p>Many insects are adept at high-speed aerial maneuvers based on visual cues, using motion vision for the detection of targets <xref ref-type="bibr" rid="pcbi.1000555-Olberg1">[5]</xref>, for visual odometry <xref ref-type="bibr" rid="pcbi.1000555-Srinivasan2">[6]</xref> and angular velocity estimation <xref ref-type="bibr" rid="pcbi.1000555-Egelhaaf1">[7]</xref>. Among insects dipteran flies stand out with highly acrobatic pursuit behavior at angular velocities of several thousand degrees per second <xref ref-type="bibr" rid="pcbi.1000555-Collett1">[8]</xref>, although these higher speeds likely exceed the useful coding range for motion sensitive neurons <xref ref-type="bibr" rid="pcbi.1000555-Kern1">[9]</xref>. Many species are also excellent hoverers, able to maintain a fixed position for extended periods of time. These extreme flight modes extend vision to the upper and lower limits of the temporal resolution described for insect higher order visual neurons <xref ref-type="bibr" rid="pcbi.1000555-OCarroll1">[10]</xref> and make them an ideal candidate to study motion vision, in particular the accuracy of wide-field angular velocity estimation.</p>
<sec id="s1a">
<title>Models For Motion Detection</title>
<p>There are four main classes of motion detection models, namely: (1) differential methods; (2) region-based matching; (3) phase-based and (4) energy-based techniques (for review see <xref ref-type="bibr" rid="pcbi.1000555-Barron1">[11]</xref>). All four consist of three basic components (pre-filtering, local motion estimation and integration over the field of view) but vary markedly in the approaches used to realize these steps.</p>
<sec id="s1a1">
<title>Differential</title>
<p>These methods including gradient-based models, determine velocity from spatiotemporal derivatives and models exist that employ both first <xref ref-type="bibr" rid="pcbi.1000555-Horn1">[12]</xref> and second order derivatives <xref ref-type="bibr" rid="pcbi.1000555-Nagel1">[13]</xref>. Despite producing reasonably accurate results under a number of realistic scenarios differential methods are sensitive to the type of numerical differentiation and spatiotemporal smoothing used, as ‘raw’ methods (without sufficient smoothing) can produce discontinuous results. Due to the differentiation they are also particularly susceptible to errors under noisy conditions <xref ref-type="bibr" rid="pcbi.1000555-Potters1">[14]</xref>.</p>
</sec><sec id="s1a2">
<title>Region or feature based matching</title>
<p>Such techniques normally involve maximizing a cross-correlation or minimizing a difference measure such as the RMS error <xref ref-type="bibr" rid="pcbi.1000555-Anandan1">[15]</xref>. These also include the use of probabilistic approaches, Kalman Filters <xref ref-type="bibr" rid="pcbi.1000555-Singh1">[16]</xref> and Monte Carlo localization <xref ref-type="bibr" rid="pcbi.1000555-Dellaert1">[17]</xref>, to generate and determine location on topological maps. The use of some modified neural networks to determine image velocity <xref ref-type="bibr" rid="pcbi.1000555-Botelho1">[18]</xref> can also be considered in this category. When accurate numerical differentiation can not be used due to noise, low frame counts or aliasing it is common for engineers to use region-based matching techniques. However these methods tend to only be accurate at high velocities and are less able to accurately estimate sub-pixel displacements. Although, unlike most other methods of velocity detection, the time required for reliable velocity estimation is generally much less and can be obtained in only 2–3 frames.</p>
</sec><sec id="s1a3">
<title>Phase-based</title>
<p>These techniques for determining image motion rely on the phase behavior of arrays of band-pass filters <xref ref-type="bibr" rid="pcbi.1000555-Fleet1">[19]</xref>. These filters decompose the input signal according to scale, speed and orientation. Operating in the complex domain phase-based techniques are in effect a differential technique operating on phase rather than amplitude, which has been shown to be more stable <xref ref-type="bibr" rid="pcbi.1000555-Fleet2">[20]</xref>. While such models have been shown to produce more accurate responses than others types of motion detection <xref ref-type="bibr" rid="pcbi.1000555-Barron1">[11]</xref> they can still suffer from noise and discontinuity limitations as with gradient-based models.</p>
</sec><sec id="s1a4">
<title>Energy- or frequency-based</title>
<p>Methods that use the output energy of velocity-tuned filters to estimate motion are in this category <xref ref-type="bibr" rid="pcbi.1000555-Heeger1">[21]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Heeger2">[22]</xref>. These techniques have rarely been used in practical applications as they tend to give outputs contingent on non-motion parameters of the image, can have non-trivial initial condition equations and some have underlying assumptions that are not often true (i.e. some assume the input stimulus is equivalent to white noise).</p>
</sec></sec><sec id="s1b">
<title>Biological Vision Uses Correlation-Based Motion Detection</title>
<p>It has been shown that certain energy-based methods are equivalent to correlation-based methods <xref ref-type="bibr" rid="pcbi.1000555-Adelson1">[23]</xref>. Given the problems with this class of motion detection it is perhaps surprising that correlation-based models appear to be the ubiquitous form of motion detection in biology. The correlation motion detector model <xref ref-type="bibr" rid="pcbi.1000555-Hassenstein1">[24]</xref> has been used to explain direction selective motion detection in a wide variety of insects, birds and mammals, including humans <xref ref-type="bibr" rid="pcbi.1000555-WolfOberhollenzer1">[25]</xref>–<xref ref-type="bibr" rid="pcbi.1000555-Clifford1">[27]</xref>. This model involves a non-linear correlation of adjacent spatial samples, with an asymmetric delay filter giving rise to direction selective responses within a local elementary motion detector or EMD <xref ref-type="bibr" rid="pcbi.1000555-Hassenstein1">[24]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Reichardt1">[28]</xref>. While the term “EMD” has been used in the context of numerous variant or alternative forms of local motion detector, in insects arrays of correlation-based EMDs are then summed by so-called lobula plate tangential cells (LPTCs) to provide measurements of wide-field optical flow or motion of specific targets <xref ref-type="bibr" rid="pcbi.1000555-Egelhaaf2">[29]</xref>. By analogy to insect EMDs, our subsequent use of this term thus specifically refers to EMDs based on a local correlation operation.</p>
<p>Two key questions arise from the observation that biological motion detectors are of the correlation class. Firstly, assuming biological vision has strong selective pressures to attain a robust and efficient system that is optimized for the task, what are the compelling advantages for this type of motion detector in the context for which they are used? Secondly, how does the biological system overcome the intrinsic problems with this type of motion detector?</p>
</sec><sec id="s1c">
<title>Possible Advantages of Motion Correlation</title>
<p>Detectors based on motion correlation have been shown to have significant advantages over gradient models <xref ref-type="bibr" rid="pcbi.1000555-Kennedy1">[30]</xref> where detector noise is problematic <xref ref-type="bibr" rid="pcbi.1000555-Potters1">[14]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Borst1">[31]</xref>, e.g. at low contrasts or luminance. Certain features of the correlation EMD make it an extremely useful primitive for biological motion processing, particularly its robustness to both temporal and spatial noise <xref ref-type="bibr" rid="pcbi.1000555-Haag1">[32]</xref>. However, such EMDs are also sensitive to non-motion-related parameters of visual stimuli, and do not by themselves give an unambiguous indication of angular velocity <xref ref-type="bibr" rid="pcbi.1000555-Dror1">[33]</xref>, which is at odds with the apparent ease with which insects analyze this parameter <xref ref-type="bibr" rid="pcbi.1000555-Srinivasan2">[6]</xref>. This is due in large part to the inherent sensitivity of correlation-based EMDs to contrast and spatial structure of local features within moving scenes. This leads to ambiguity in the local response as a function of angular velocity, a phenomenon we term ‘pattern noise’ <xref ref-type="bibr" rid="pcbi.1000555-Dror1">[33]</xref>. However previous work <xref ref-type="bibr" rid="pcbi.1000555-Shoemaker1">[34]</xref> has suggested that static and dynamic non-linearity associated with obvious components of physiological implementation of the model helps overcome some of the inherent limitations of the basic EMD.</p>
<p>One contributing factor in the ability of correlation based motion models to accurately encode angular velocity is the relative consistency of the spatial statistics of natural scenes, in spite of structural difference <xref ref-type="bibr" rid="pcbi.1000555-Dror1">[33]</xref>. Natural images tend to possess spatial power spectra with an approximate 1/<italic>f</italic><sup>2+u</sup> characteristic, where <italic>f</italic> is spatial frequency and u is small (i.e. a straight line on a log-log scale) <xref ref-type="bibr" rid="pcbi.1000555-Tolhurst1">[35]</xref>. In addition to similarity between different scenes this characteristic implies a self-similarity in natural imagery at different spatial scales, although residual differences in structure remain.</p>
<p>A recent electrophysiological breakthrough was made showing that unlike when using sinusoidal stimuli the LPTCs of insects shown natural images robustly encoded angular velocity independently of the contrast in the scene (see Figure 3B from <xref ref-type="bibr" rid="pcbi.1000555-Straw1">[36]</xref>), a characteristic not predicted by earlier models. This highlights the importance of testing biological motion detection, and models based upon it, under as ‘natural’ conditions as possible.</p>
<p>In this paper we provide an explanation for a controversy that has plagued visual science. How is it that biological motion detecting neurons can reliably encode angular velocity across different scenes when electrophysiological evidence shows that they use correlation-based EMDs? To do this we extend motion models, based directly on the well-studied LPTCs in the insect visual system <xref ref-type="bibr" rid="pcbi.1000555-Shoemaker1">[34]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Lindemann1">[37]</xref>, by inclusion of additional dynamic non-linear components that combine to provide a robust estimate for global angular velocity and thus account for hitherto poorly understood properties of the fly LPTCs. The inclusion of these non-linearities, while overcoming many of the problems with motion energy models, is only slightly more complex computationally than the raw EMD model and far more efficient than most other motion detection algorithms. Furthermore, the model works on ‘real-world’ luminance levels, rather than the 8-bit normalized images captured by most current digital systems, making it more easily implemental on low power custom imagers.</p>
</sec></sec><sec id="s2">
<title>Methods</title>
<sec id="s2a">
<title>High Dynamic Range Image Capture</title>
<p>Our primary purpose was to develop a model robust against the statistical variance between different scenes in nature, where luminance can vary by over 6 decades or more. In order to capture images for use as stimuli we therefore used a Nikon D-70 digital camera and panoramic tripod head attachment to obtain 14 panoramic images from a variety of urban and natural locations around Adelaide, South Australia in high dynamic range (HDR) format. Locations were selected to represent a range of luminance, contrast and spatial clutter conditions. Each panorama was obtained using a series of 12 overlapping panels saved in 16-bit NEF (raw) format (12-bits of actual dynamic range). Each panel was imaged at 3 different exposure levels (−2.0 and +2.0EV bracketing) in order to capture components of the scenes that exceeded the dynamic range of the camera sensor. We used PTGui (New House Internet Services BV) to stitch the 12 overlapping images together for each of the three different exposures into full 360 degree panoramas. For each panorama over-saturated pixels were discarded and local luminance was established using a linear gamma curve for the camera luminance values and cosine weightings depending on individual pixel values, i.e. low and high pixel values were assigned low weights while mid range pixels had high weights <xref ref-type="bibr" rid="pcbi.1000555-Debevec1">[38]</xref>. We combined the panoramas, with an offset depending on exposure, and converted them to floating point format (IEEE single precision standard) at 8000×1600 pixel resolution and full color using custom software written in LabView (National Instruments). Such high resolution was not needed for the detail, as insect optics are too coarse to make use of it, but rather to permit accurate simulation of slow image speeds. The full color HDR images are available for use by interested parties by contacting the authors.</p>
<p>Since the motion processing pathway of insects is known to be monochromatic <xref ref-type="bibr" rid="pcbi.1000555-Smakman1">[39]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Srinivasan3">[40]</xref> only the green channel was used as inputs to the motion detection model. All images used in this study, and the associated mean 1D row power spectra, and are shown in <xref ref-type="fig" rid="pcbi-1000555-g001">Figure 1</xref>. There was a larger roll-off in the higher frequency components of the images than would be expected from the non-idealities of the lens used, caused by stitching artifacts in the generation of the HDR panoramic images. The inevitable time delay between taking each of the panels resulted in small movements of the fine details in the scene (e.g. leaves) thus producing a low-pass effect. Furthermore, spatial corrections for the lens distortions and software alignment of the panels to produce panoramas may have reduced the detail in the overlapping panel sections. However, the frequency region in the pass-band of the insect LPTCs modeled in this work (&lt;1 cycle/degree) appeared unaffected by this smoothing.</p>
<fig id="pcbi-1000555-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000555.g001</object-id><label>Figure 1</label><caption>
<title>Panoramic input images.</title>
<p>(upper) The model used high-dynamic range inputs however they have been normalized, gamma corrected and reduced to 8-bits of dynamic range for reproduction here. Images are ranked from highest to lowest contrast based on the raw elementary motion detection contrast measure (C<sub>EMD</sub>: see text for details) and cover a wide range of different environments and lighting conditions. Real world brightness (Cd/m<sup>2</sup>) and contrast values are given in <xref ref-type="table" rid="pcbi-1000555-t001">Table 1</xref>. Only the green channel of the images (shown) was used as inputs to the model. (lower) Average 1D row power spectra of the 14 natural panoramic images used as inputs to the motion processing model. All have an approximately linear relationship between power and spatial frequency (on the logarithmic axis) common in natural scenes. The vertical offset (contrast) in the graphs varied almost 10dB between the different images. The roll-off at higher frequencies was caused by stitching artifacts and was outside the pass-band of the models used.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.g001" xlink:type="simple"/></fig></sec><sec id="s2b">
<title>Image Statistics</title>
<p><xref ref-type="table" rid="pcbi-1000555-t001">Table 1</xref> shows the brightness and contrast for the 14 images illustrated in <xref ref-type="fig" rid="pcbi-1000555-g001">Figure 1</xref>. Unlike in traditional imagery HDR images vary enormously in mean luminance. In order to compensate for this, and produce contrast metrics that were not dependant on image brightness, a crude global gain control was used (divide by mean luminance). Because image normalization is a major role of the biological photoreceptors this step was omitted in subsequent modeling. Additionally, since defining image contrast is so difficult for natural scenes, we used several different measures to quantify it (<xref ref-type="table" rid="pcbi-1000555-t001">Table 1</xref>), based either on the global image statistics, or taking into account the specific receptive field properties of local motion detection and the biological system it is intended to mimic <xref ref-type="bibr" rid="pcbi.1000555-Tadmor1">[41]</xref>.</p>
<table-wrap id="pcbi-1000555-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000555.t001</object-id><label>Table 1</label><caption>
<title>Image Statistics.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1000555-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.t001" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">Image</td>
<td align="left" colspan="1" rowspan="1">Luminance (Cd/m<sup>2</sup>)</td>
<td align="left" colspan="1" rowspan="1">C<sub>RMS</sub></td>
<td align="left" colspan="1" rowspan="1">C<sub>Row</sub></td>
<td align="left" colspan="1" rowspan="1">C<sub>Effective</sub></td>
<td align="left" colspan="1" rowspan="1">C<sub>EMD</sub></td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">A</td>
<td align="left" colspan="1" rowspan="1">1138</td>
<td align="left" colspan="1" rowspan="1">3.335</td>
<td align="left" colspan="1" rowspan="1">2.193</td>
<td align="left" colspan="1" rowspan="1">3.228</td>
<td align="left" colspan="1" rowspan="1">1.762</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">B</td>
<td align="left" colspan="1" rowspan="1">356</td>
<td align="left" colspan="1" rowspan="1">3.652</td>
<td align="left" colspan="1" rowspan="1">2.908</td>
<td align="left" colspan="1" rowspan="1">5.674</td>
<td align="left" colspan="1" rowspan="1">1.538</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">C</td>
<td align="left" colspan="1" rowspan="1">877</td>
<td align="left" colspan="1" rowspan="1">3.048</td>
<td align="left" colspan="1" rowspan="1">1.671</td>
<td align="left" colspan="1" rowspan="1">2.312</td>
<td align="left" colspan="1" rowspan="1">1.389</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">D</td>
<td align="left" colspan="1" rowspan="1">490</td>
<td align="left" colspan="1" rowspan="1">4.642</td>
<td align="left" colspan="1" rowspan="1">2.656</td>
<td align="left" colspan="1" rowspan="1">3.413</td>
<td align="left" colspan="1" rowspan="1">1.382</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">E</td>
<td align="left" colspan="1" rowspan="1">491</td>
<td align="left" colspan="1" rowspan="1">2.465</td>
<td align="left" colspan="1" rowspan="1">2.050</td>
<td align="left" colspan="1" rowspan="1">1.348</td>
<td align="left" colspan="1" rowspan="1">1.170</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">F</td>
<td align="left" colspan="1" rowspan="1">276</td>
<td align="left" colspan="1" rowspan="1">4.407</td>
<td align="left" colspan="1" rowspan="1">2.134</td>
<td align="left" colspan="1" rowspan="1">2.839</td>
<td align="left" colspan="1" rowspan="1">1.147</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">G</td>
<td align="left" colspan="1" rowspan="1">2715</td>
<td align="left" colspan="1" rowspan="1">1.455</td>
<td align="left" colspan="1" rowspan="1">1.666</td>
<td align="left" colspan="1" rowspan="1">1.686</td>
<td align="left" colspan="1" rowspan="1">1.072</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">H</td>
<td align="left" colspan="1" rowspan="1">1684</td>
<td align="left" colspan="1" rowspan="1">1.600</td>
<td align="left" colspan="1" rowspan="1">1.826</td>
<td align="left" colspan="1" rowspan="1">1.962</td>
<td align="left" colspan="1" rowspan="1">1.013</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">I</td>
<td align="left" colspan="1" rowspan="1">11648</td>
<td align="left" colspan="1" rowspan="1">0.930</td>
<td align="left" colspan="1" rowspan="1">1.341</td>
<td align="left" colspan="1" rowspan="1">0.662</td>
<td align="left" colspan="1" rowspan="1">0.681</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">J</td>
<td align="left" colspan="1" rowspan="1">3339</td>
<td align="left" colspan="1" rowspan="1">0.932</td>
<td align="left" colspan="1" rowspan="1">1.391</td>
<td align="left" colspan="1" rowspan="1">0.973</td>
<td align="left" colspan="1" rowspan="1">0.665</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">K</td>
<td align="left" colspan="1" rowspan="1">3901</td>
<td align="left" colspan="1" rowspan="1">1.140</td>
<td align="left" colspan="1" rowspan="1">1.448</td>
<td align="left" colspan="1" rowspan="1">1.277</td>
<td align="left" colspan="1" rowspan="1">0.644</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">L</td>
<td align="left" colspan="1" rowspan="1">5112</td>
<td align="left" colspan="1" rowspan="1">0.889</td>
<td align="left" colspan="1" rowspan="1">1.242</td>
<td align="left" colspan="1" rowspan="1">0.846</td>
<td align="left" colspan="1" rowspan="1">0.572</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">M</td>
<td align="left" colspan="1" rowspan="1">27993</td>
<td align="left" colspan="1" rowspan="1">0.731</td>
<td align="left" colspan="1" rowspan="1">1.034</td>
<td align="left" colspan="1" rowspan="1">0.686</td>
<td align="left" colspan="1" rowspan="1">0.520</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">N</td>
<td align="left" colspan="1" rowspan="1">9249</td>
<td align="left" colspan="1" rowspan="1">0.807</td>
<td align="left" colspan="1" rowspan="1">1.145</td>
<td align="left" colspan="1" rowspan="1">1.013</td>
<td align="left" colspan="1" rowspan="1">0.444</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Range</td>
<td align="left" colspan="1" rowspan="1">101</td>
<td align="left" colspan="1" rowspan="1">6.352</td>
<td align="left" colspan="1" rowspan="1">2.813</td>
<td align="left" colspan="1" rowspan="1">8.565</td>
<td align="left" colspan="1" rowspan="1">3.972</td>
</tr>
</tbody>
</table></alternatives></table-wrap>
<p>RMS Contrast (C<sub>RMS</sub>) is the global standard deviation divided by global mean. As a global measure it gives a simple to calculate estimate of the contrast in the whole image and makes no assumptions about directionality. However it can produce large values simply by virtue of the fact many images contain large, yet uniform, bright (e.g. sky) and dark (e.g. ground) sections that do not necessarily produce strong local motion cues during horizontal (yaw) motion.</p>
<p>Row Contrast (C<sub>Row</sub>) is the square root of the mean 1D row power spectra. Since the neurons we were mimicking are selective for horizontal (yaw) motion having an estimate bias in this direction was appropriate. However this measurement weighted all spatial frequencies equally, a situation that resulted in more influence being given to higher spatial frequencies (fine detail) than in either the biological system or our model of it.</p>
<p>Effective Row Contrast (C<sub>Effective</sub>) is the square root of the y-intercept in the line of best fit for the mean 1D row power spectra between 0.01 and 0.5 cycles/degree (on a log-log scale) to match the observed spatial coding range for insect vision. Note that 0.5 cycles/degree is the Niquist limit for hoverfly spatial sampling, which is approximately 1 degree separation between pixels <xref ref-type="bibr" rid="pcbi.1000555-Straw2">[42]</xref>, while field of view of 100 degrees or more are not uncommon in fly LPTCs <xref ref-type="bibr" rid="pcbi.1000555-Krapp1">[43]</xref>. This measure took advantage of the linear (on a log scale) relationship between image power and frequency in natural images and also the optical limitations (spatial sampling) of the system. While this is a more insect-biased contrast measurement than either of the previous two metrics it was still essentially based on low order image statistics.</p>
<p>EMD Contrast (C<sub>EMD</sub>) is the square root of the response of a basic motion correlator model. The images were blurred and optically sampled as for motion detection (section 3.2), then passed through a basic unelaborated EMD model at a single speed, below the velocity maximum of the system. The size of the response to this raw EMD model gave an estimate of image contrast that took into account the exact conditions experienced by the motion detection model. Since the images were high dynamic range, image normalization (division by global mean) was performed so this measure of contrast was only influenced by the structure within the environment and not the absolute luminance of the image.</p>
<p>Comparison of the differences in contrast by these four measures confirms we achieved our objective in obtaining a set of images that should provide an enormous range in responses for a classical motion energy model tuned to similar spatial sampling. Also, while the different contrast metrics did show some differences they produced similar results, with the average correlation (r<sup>2</sup>) between the C<sub>EMD</sub> measure and the other three approximately 0.7. Note that recent electrophysiological work using a comparable set of images (but low dynamic range) did show that neurons in the brain of the fly were able to robustly detect angular velocity independent of the scene <xref ref-type="bibr" rid="pcbi.1000555-Straw1">[36]</xref>.</p>
<p>The row contrast measurement (C<sub>Row</sub>) gave the smallest range of estimates for image contrast. This was due to the fact it was more heavily biased towards high spatial frequencies than the other measures and frequencies above 5–6 cycles/degree were likely to be influenced by lens distortion and stitching artifacts, hence reducing the contrast of the images. This limitation was addressed when using effective row contrast (C<sub>Effective</sub>) by logarithmically weighting the spatial frequency (i.e. more weight to lower frequencies) and limiting it to details larger than 0.5 cycles/degree where distortions were minimal.</p>
</sec><sec id="s2c">
<title>Motion Detection Model</title>
<p>The motion detector used in this paper, shown in <xref ref-type="fig" rid="pcbi-1000555-g002">Figure 2</xref>, was, at its core, based on the Hassenstein-Reichardt Correlator <xref ref-type="bibr" rid="pcbi.1000555-Hassenstein1">[24]</xref>. However we added a number of elaborations (<xref ref-type="fig" rid="pcbi-1000555-g002">Figure 2B</xref>) to help overcome the limitations of this class of model. This more robust model took into account a number of the processing steps known, or presumed, to exist in the fly visual system and is described in the <xref ref-type="sec" rid="s3">results</xref>. All stages of the model were simulated using Matlab (MathWorks).</p>
<fig id="pcbi-1000555-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000555.g002</object-id><label>Figure 2</label><caption>
<title>Motion processing model.</title>
<p>A) Schematic of a basic correlator elementary motion detector (EMD) used as the fundamental motion detection algorithm in this paper. B) Diagrammatic representation of the fully elaborated motion processing model used in this study. C) Legend describing the symbolic representations used in B). Each stage of the model represents the processing occurring on a pixel-wise basis within the insect visual system. Connections between near-by processing columns (nearest or next-nearest neighbors) in the 2D network occur between stages, mostly in the form of spatial high-pass filtering, with the only global stage a final spatial summation at the start of stage 5. Each stage is further divided into smaller processing steps involving operations such as 1st order low-pass filtering, centre-surround antagonism, non-linear gains or divisive feedback. Further detail is presented in the text.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.g002" xlink:type="simple"/></fig><sec id="s2c1">
<title>Optics</title>
<p>The optical model used to blur and sample the panoramas was based the resolution and optical quality of the fly visual system <xref ref-type="bibr" rid="pcbi.1000555-Smakman1">[39]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Straw2">[42]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Stavenga1">[44]</xref> and pilot simulations. However, a fixed resolution and optical blur was selected rather than using settings that varied across the image as with the natural compound eye. Images were first blurred with a 2D Gaussian to simulate the optical properties of the lens (Δρ = 1.4 degrees, full width at half maximum) prior to hexagonally sampling the image as per the photoreceptor spacing in the eye (Δφ = 1 degree, horizontal spacing between adjacent pixels).</p>
</sec><sec id="s2c2">
<title>EMD</title>
<p>Each model incorporated a basic correlational elementary motion detector (EMD) <xref ref-type="bibr" rid="pcbi.1000555-Egelhaaf3">[45]</xref> with the minimum processing required to generate motion sensitive outputs. In this model a delayed version of the output from one detector is multiplied with the (non-delayed) output of an adjoining detector. The elimination of flicker and the generation of a response in the opposite direction was achieved by subtracting two mirror symmetric units. Comparisons were made between pixels centered on the current spatial location and the nearest and next-nearest neighbors. These comparisons were then weighted for directionality and position <xref ref-type="bibr" rid="pcbi.1000555-vanHateren1">[46]</xref> before combining to produce a motion vector for horizontal motion (corresponds to yaw rotation for a panoramic image). Earlier modeling of ‘basic’ EMDs (e.g. <xref ref-type="bibr" rid="pcbi.1000555-Harris1">[47]</xref>) employed first order low-pass filters with time constants in the order of 35 ms. In our model the delay element was achieved by cascading three first order low-pass filters, all with the same cut-off frequency (f<sub>c</sub> = 12 Hz), and an additional fixed time delay of 2 ms. This set of parameters was chosen as it gave a biologically realistic transfer function with a small delay before a smooth rapid rising phase and a longer falling phase (approximately log-normal response). The value used produced an optimum at approximately 100 degrees/s, in line with neurobiological recordings from fly motion sensitive neurons viewing similar natural images <xref ref-type="bibr" rid="pcbi.1000555-Straw1">[36]</xref>, and corresponded to a temporal cut-off frequency around 5.5 Hz, similar to that found using sine wave stimuli in flies <xref ref-type="bibr" rid="pcbi.1000555-Harris2">[48]</xref>.</p>
</sec></sec><sec id="s2d">
<title>Model Analysis</title>
<p>We tested the model under a range of velocities (6 points per decade) from 0.01 degrees/s to 1000 degrees/s by rotating the panoramic input images within the virtual environment. Although our modeling used discrete time we utilized a high sample rate relative to the time constants of biological vision in order to approximate continuous time processing. The sample rate of the simulation was 1 kHz for all rotation speeds below 200 degrees/s and 5 kHz for all rotations above 200 degrees/s. The working angular velocity range of the model was below 100 degrees/s, with faster rotations producing increasingly smaller responses. Thus all analysis was limited to the range 0.1 degrees/s to 100 degrees/s. We employed linear sub-pixel interpolation during the simulated yaw rotations to ensure an accurate simulation of smooth motion at low velocities.</p>
<p>In order to avoid ‘neural after-images’ the initial conditions were set to the mean luminance of the image. Simulations were run for 1050 ms to allow sufficient time for the system to reach steady state. All analysis was based on the average response of the last 50ms.</p>
<p>Two parameters were calculated to quantify the output of the model at each angular velocity in terms of image invariance.</p>
<p>Coefficient of Variation (CV) was defined as the standard deviation of the response of all images at a given rotational speed divided by the mean of the responses and is shown in equation 1. This parameter was used to show variation (ambiguity) in model responses to different images at a specific angular velocity. Lower coefficients of variation meant less variability and a more reproducible result across different images. However, having a low CV does not automatically make a system a good velocity discriminator. Overlapping horizontal lines will have a low CV but will produce the same output value for a range of velocities, making it impossible to distinguish between different image speeds.<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.e001" xlink:type="simple"/><label>(1)</label></disp-formula>Where CV<italic><sub>i</sub></italic> is the coefficient of variation at point <italic>i</italic>, σ is the standard deviation of the image responses, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000555.e002" xlink:type="simple"/></inline-formula> is the mean of the model responses to the images and <italic>i</italic> is the test velocity. CV is expressed as a percentage in the text.</p>
<p>Z Score was defined as the difference in the means at the two consecutive velocities divided by the sum of the two consecutive standard deviations then scaled for the number of samples per decade (i.e. local slope divided by local variability) and is shown in equation 2. Unlike CV this parameter represents the ability of the system to discriminate between velocities. A higher Z score meant that the ability to determine the difference between velocities was greater.<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.e003" xlink:type="simple"/><label>(2)</label></disp-formula>Where Z<italic><sub>i</sub></italic> is the Z score at point <italic>i</italic>, <italic>ppd</italic> is the number of test points per decade (in this case 6), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000555.e004" xlink:type="simple"/></inline-formula> is the mean of the model responses to the images, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000555.e005" xlink:type="simple"/></inline-formula> is the standard deviation of the image responses, <italic>i</italic> is the test velocity and <italic>i</italic>−1 is the previous test velocity.</p>
<p>All results are given in the form mean±95% confidence interval unless otherwise stated. Global CV or Z score statistics were calculated as the average over the range 0.1 to 100 degrees/s. This range was chosen as the maximum closely matches the optimal point seen in biological motion detecting neurons <xref ref-type="bibr" rid="pcbi.1000555-Straw1">[36]</xref> and the minimum is within the accuracy of the animation method used to simulate image motion (linear interpolation). However the model parameters could be altered to create a different coding range if desired.</p>
</sec></sec><sec id="s3">
<title>Results/Discussion</title>
<p>Being one of the most extensively studied systems in neurobiology the fly motion system <xref ref-type="bibr" rid="pcbi.1000555-Egelhaaf1">[7]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Egelhaaf3">[45]</xref> was used as the base line for all variables (such as time constants, gain factors etc) in the model where available. Where such data did not exist, or was ambiguous, a best estimate was used that was consistent with typical values found in other neuronal systems. In such cases a small amount of parameter optimization was used to ensure accurate coding was not compromised. It was not unusual to find a parameter could take a range of values without having a significant impact on angular velocity coding, i.e. the system was not critically dependant on the exact values used.</p>
<sec id="s3a">
<title>Motion Detection Model</title>
<p>Each stage of the model depicted in <xref ref-type="fig" rid="pcbi-1000555-g002">Figure 2B</xref> was built up sequentially in order to investigate the contribution of each stage to reliable angular velocity encoding. The response of the model to each of the 14 images, and the effect of adding each of the processing stages into the chain, is shown in <xref ref-type="fig" rid="pcbi-1000555-g003">Figure 3</xref>. As with all correlation-based EMD models the system produced ambiguous responses, with the same signal value for two different velocities either side of an optimum. However in practice this limitation could be overcome by using the system only within the coding range (i.e. below the optimum).</p>
<fig id="pcbi-1000555-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000555.g003</object-id><label>Figure 3</label><caption>
<title>Model responses after various processing stages.</title>
<p>A) Steady-state responses, integrated over the entire image, of the model to all 14 input images over the range of velocities tested after inclusion of various modeling stages as depicted in <xref ref-type="fig" rid="pcbi-1000555-g002">Figure 2</xref>. Lines are color coded to the images as shown in <xref ref-type="fig" rid="pcbi-1000555-g001">Figure 1</xref>. B) Summary statistics of model performance after each stage of processing. All data are given as mean of responses over the range 0.1–100 degrees/s. Error bars represent 95% confidence intervals. The inclusion of each of the stages improved the ability of the model to reliably encode velocity by reducing the variability in the response between images. Σ illustrated that the responses were summed over all space, EMD stands for correlational elementary motion detector and was the fundamental motion estimation operation. For a detailed description of the processing of each stage, and the exact effects on velocity consistency between images, see main text.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.g003" xlink:type="simple"/></fig><sec id="s3a1">
<title>Basic EMD</title>
<p>Consistent with Dror et al <xref ref-type="bibr" rid="pcbi.1000555-Dror1">[33]</xref> the basic EMD model (Raw) gave broadly similar shaped angular velocity tuning curves over the range tested and peaking at around 100 degrees/s, but with huge variance in the response gain as a function of angular velocity (CV = 121±1.17% and Z score = 0.408±0.063 in the range 0.1 to 100 degrees/s). Hence making it completely unusable as an angular velocity estimator as the response at any one angular velocity was vastly different for each image.</p>
</sec><sec id="s3a2">
<title>Stage 1 – phototransduction</title>
<p>This stage was a model to account for the non-linearities in blowfly phototransduction, and was based on our modified version <xref ref-type="bibr" rid="pcbi.1000555-Mah1">[49]</xref> of a parametric model initially proposed by van Hateren and Snippe <xref ref-type="bibr" rid="pcbi.1000555-vanHateren2">[50]</xref>. This included dynamic pixel-wise control of several parameters: gain, the corner frequency of a low pass temporal filter, dynamic gamma correction and a saturating non-linearity (Naka- Rushton transform). These all resulted in a useful dynamic range compression by increasing the gain of dark sections of the image while simultaneously and independently reducing the gain in higher luminance sections. This processing has been shown to be functionally equivalent to that found in primate cone receptors <xref ref-type="bibr" rid="pcbi.1000555-vanHateren3">[51]</xref> and also facilitates the detection of small targets in clutter <xref ref-type="bibr" rid="pcbi.1000555-Brinkworth1">[52]</xref>. All parameters were set to those found in our previous photoreceptor recordings <xref ref-type="bibr" rid="pcbi.1000555-Mah1">[49]</xref>.</p>
<p>The inclusion of the biomimetic photoreceptor processing improved the performance of the model by over 600% compared to that from the unelaborated (raw) EMD model. However the performance of the system as a reliable angular velocity estimator was still quite low. Coefficient of variation (21.9±1.22%) and Z score (2.96±0.495) values showed the variation between scenes still represented a significant portion of the entire response. The addition of this stage moved the model from what has been previously only attempted using normalized low dynamic range images <xref ref-type="bibr" rid="pcbi.1000555-Shoemaker1">[34]</xref> into a form that could be used under real-world luminance inputs with no pre-conditioning.</p>
</sec><sec id="s3a3">
<title>Stage 2 – spatial-temporal redundancy reduction</title>
<p>This stage was designed to account for additional processing by the second-order neurons, lamina monopolar cells (LMCs) in flies, which are analogous to bipolar cells in mammalian eyes <xref ref-type="bibr" rid="pcbi.1000555-Laughlin1">[53]</xref>. They remove redundancy in both space and time in an information theoretic optimal way based on the local light level <xref ref-type="bibr" rid="pcbi.1000555-vanHateren4">[54]</xref>. Processing steps included variable (higher cut-off in areas of higher luminance) and relaxed first-order high-pass filtering (permitting some DC component of the signal to be propagated) in both space and time depending on light levels <xref ref-type="bibr" rid="pcbi.1000555-Juusola1">[55]</xref> and a saturating non-linearity (tanh; see equation 3). The sign inversion seen in neurophysiological recordings from these cells was not included as it had no impact on the performance of the system <xref ref-type="bibr" rid="pcbi.1000555-Laughlin2">[56]</xref>. Similarly neural superposition was not included as it would have served no purpose. Neural superposition involves the combination of a number of (in the case of the hover-fly 6) independent samples of the same point in space to reduce noise <xref ref-type="bibr" rid="pcbi.1000555-Kirschfeld1">[57]</xref>. Since this simulation had essentially no detector or model noise (or none that would be influenced by this) it was excluded.</p>
<p>In the case of implementing spatial high-pass filtering the ‘surround’ was defined as the response from the neighboring 6 pixels on the hexagonal grid. These signals were inverted, attenuated, delayed and smoothed (proposed operation of the amacrine cells in the biological system) before combining with the signal from the centre pixel <xref ref-type="bibr" rid="pcbi.1000555-James1">[58]</xref>. Where possible the changes in filtering due to luminance conditions were based on previously published recordings from fly LMCs <xref ref-type="bibr" rid="pcbi.1000555-Dubs1">[59]</xref>.<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.e006" xlink:type="simple"/><label>(3)</label></disp-formula>Where y(x) is the output signal limited to the range ±1 (designed to mimic the limited bandwidth in a physical system) and G is the input gain.</p>
<p>The inclusion of LMC-like processing after the addition of stage 1 to the raw EMD model produced minor but mixed results. There was a non-significant 28% increase in the average Z score, meaning the ability to distinguish between velocities was slightly improved. However it also caused a 10% (not significant) increase in CV, resulting in slightly more variability in the responses produced by the difference scenes. Thus the LMC processing provided little extra benefit in this configuration. This is itself was surprising since the processing of the LMC (spatial-temporal high-pass filtering) has been considered an important element in the pre-processing of motion detectors based on EMDs <xref ref-type="bibr" rid="pcbi.1000555-Dror1">[33]</xref>. However, this model for LMC processing does not fully capture all the non-linear components of LMC operation and it is likely missing sections play an important role in this, or other, visual tasks.</p>
<p>While it is clear that photoreceptors must be on the motion processing pathway there remains debate about subsequent neuronal stages with proponents both for <xref ref-type="bibr" rid="pcbi.1000555-Douglass1">[60]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Rister1">[61]</xref> and against <xref ref-type="bibr" rid="pcbi.1000555-Coombe1">[62]</xref> the inclusion of LMCs on the motion pathway. We decided to keep the LMCs in the model as the processing (high-pass spatial-temporal filtering) was theoretically beneficial to both motion processing and optimizing information transmission in limited bandwidths. However, we also performed tests with this stage removed to determine the actual effect the LMC model had on the reliability of angular velocity coding (below).</p>
</sec><sec id="s3a4">
<title>Stage 3 – local motion estimation</title>
<p>This stage incorporated hypothetical elaborations to the core EMD. These elaborations were additional stronger spatial high-pass filtering (nearest and next-nearest neighbors on the 2D image plane), for which there is some anatomical evidence <xref ref-type="bibr" rid="pcbi.1000555-Strausfeld2">[63]</xref>, as well as additional saturating non-linearities (as per equation 3) after the multiplication (correlation) between the delayed and undelayed spatially separated pixels. The basis for this saturation was that biological neurons have a limited bandwidth, so expansive non-linearities (such as multiplication) must be bounded. Soft saturation, such as that produced by a tanh function, is commonly seen in biological sensory systems and has been proposed by others to exist in the motion pathway <xref ref-type="bibr" rid="pcbi.1000555-Egelhaaf4">[64]</xref> in order to account for certain contrast tuning properties of LPTCs <xref ref-type="bibr" rid="pcbi.1000555-RiveraAlvidrez1">[65]</xref>. Unfortunately recordings from the insect medulla region, the second optic lobe neuropil and the region believed to contain the EMD-like processing, are difficult and rare <xref ref-type="bibr" rid="pcbi.1000555-Osorio1">[66]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Osorio2">[67]</xref> due to the relative difficulty in obtaining stable recordings <xref ref-type="bibr" rid="pcbi.1000555-Honegger1">[68]</xref>, so the gain was estimated to provide a good compromise between utilizing the available bandwidth and producing saturating responses.</p>
<p>The inclusion of the saturating non-linearities and further spatial high-pass filtering had little beneficial effect on either the average CV (9% reduction) or Z score (2% reduction) within the operating range (&lt;100 degrees/s). However it did increase the rate of roll-off and the similarity between images at high speeds (<xref ref-type="fig" rid="pcbi-1000555-g003">Figure 3A</xref>). Damping in this section of the velocity curve has been shown to be important from a control systems point of view in reducing potential instability in the system during periods of very high rotational velocities <xref ref-type="bibr" rid="pcbi.1000555-Warzecha1">[69]</xref>.</p>
</sec><sec id="s3a5">
<title>Stage 4 – local motion adaptation</title>
<p>This stage was a novel model for local motion-dependent gain reduction (local motion adaptation) as observed in the rotational motion sensitive neurons in the fly visual system <xref ref-type="bibr" rid="pcbi.1000555-Maddess1">[70]</xref>. The motion adaptation was implemented via divisive feedback of a spatial-temporal low-pass filtered version of the local motion signal (nearest and next-nearest neighbors on the 2D image plane). This feed-forward gain control was made direction independent, as shown in biology <xref ref-type="bibr" rid="pcbi.1000555-Harris3">[71]</xref>, by the addition of a full-wave rectifier on the input to the low-pass filters. This motion gain control permitted a form of predictive coding where the gain in regions of high motion-energy (clutter) was reduced and the signal amplified in regions of low clutter. The basic premise was to increase the statistical independence of local motion signals by reducing their co-variance, hence increasing the information content in the global signal. Unlike the motion control used in our previous modeling <xref ref-type="bibr" rid="pcbi.1000555-Shoemaker1">[34]</xref> this new type of adaptation did not act as a contrast normalization stage. Hence the model retained one of the most curious recent findings in the fly that can not be accounted for by the work of Shoemaker et al. While images of different contrast produce similar outputs in LPTCs artificially reducing the contrast of images results in a reduction of the responses, but the responses are still similar across the different images <xref ref-type="bibr" rid="pcbi.1000555-Straw1">[36]</xref>. Other processing stages included were a static saturating non-linearity (tanh; 2<sup>nd</sup> last block in stage 4 of <xref ref-type="fig" rid="pcbi-1000555-g002">Figure 2B</xref>) and a compressive non-linearity shown in equation 4 (last block in stage 4 of <xref ref-type="fig" rid="pcbi-1000555-g002">Figure 2B</xref>).<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.e007" xlink:type="simple"/><label>(4)</label></disp-formula>Where <italic>y(x)</italic> is the compressed output of the local motion gain control stage, <italic>x</italic> is the local motion estimation after the local gain control and saturating non-linearity and <italic>p</italic> is the power used to compress the response range (i.e. boost the response to low speed rotation relative to that of high speed rotation). The nominal value for <italic>p</italic> was 0.5. This value was chosen in order to partially correct for the square-like expansion caused by the multiplication in the EMD stage and to produced a signal that was log-linear over most of the signaling range, another unexpected neurophysiological finding by Straw et al <xref ref-type="bibr" rid="pcbi.1000555-Straw1">[36]</xref>. Since <italic>p</italic>&lt;1 it was necessary to use the modulus of the local motion signal to produce real results. The directionality of the result was maintained by the use of the <italic>sign</italic> function that produced −1 if <italic>x</italic>&lt;0 and 1 if <italic>x</italic>&gt;0.</p>
<p>This processing had little effect on the average Z score (2% increase), but did reduce the average CV (48% reduction) and decrease the required output bandwidth by boosting the response to low velocities while suppressing high velocities. So while in a noise free simulation, such as that presented here, there was no real improvement in the ability to accurately encode velocities this stage will have implication in real-world implementations where noise and limited bandwidth are important considerations. It is also important to note that in previous modeling the inclusion of ‘local motion gain control’, either on its own or in tandem with other processing, constantly made angular velocity coding worse <xref ref-type="bibr" rid="pcbi.1000555-Shoemaker1">[34]</xref>.</p>
</sec><sec id="s3a6">
<title>Stage 5 – large-field integration</title>
<p>This stage was a representation of the processing performed by the LPTCs in flies and was the summation of all stage 4 outputs and represented the first, and only, global calculation in the model. The low number of global calculations means that it is easier to construct physical models, such as aVLSI <xref ref-type="bibr" rid="pcbi.1000555-Shoemaker1">[34]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-OCarroll2">[72]</xref> or FPGA implementations. Note that this is the first stage for which there is evidence of global integration in the biological system. This stage included a non-linear spatial correction factor <xref ref-type="bibr" rid="pcbi.1000555-Borst2">[73]</xref> designed to account for the fact that not all EMDs will be activated by a given natural scene at any instant. This was followed by a final saturating non-linearity (tanh; equation 3). This stage did not contain additional global components of motion adaptation such as the famous ‘waterfall effect’, which are a known feature of biological visual systems <xref ref-type="bibr" rid="pcbi.1000555-Srinivasan4">[74]</xref>. In the absence of a clear role for these phenomena in velocity coding they may add an unnecessary level of complexity to artificial systems required to estimate actual rather than relative angular velocity.</p>
<p>Adding this final stage to the rest of the processing chain had a marked positive improvement on both the CV (25% reduction) and the Z score (93% increase), making the model much more robust. However, it should be noted that the improvement of the model response after the inclusion of stage 5 was not solely due to the performance of that stage but rather the accumulated actions of each of the preceding stages. The replacement of the photoreceptor model for a standard normalization operation (divide by image mean), while still maintaining all other operations, reduced the average Z score from 7.28±1.62 (mean±95% confidence interval) to 1.42±0.42. The removal of stage 2 from the complete model caused the average Z score to drop by over 40% to 4.35±0.77, despite this stage having had no significant effect when added after stage 1 in the absence of other elaborations. These findings highlight the importance of looking at the performance of the system as a whole rather than the individual components of the model.</p>
</sec></sec><sec id="s3b">
<title>Effect of Optical Sampling</title>
<p>The response of the modeling showed that the inclusion of bioinspired processing components could, in tandem, produce reliable angular velocity coding of visual inputs. However it was important to determine the requirements of this approach from an optical sampling view-point. In order to test the robustness of angular velocity coding for different spatial sample rates, we ran the full model for a range of possible constant sampling optical configurations. The spatial baseline used was the hoverfly (<italic>Eristalis tenax</italic>), where resolution (Δφ) is maximally about 1 degree but can drop off to almost 2 degrees in the periphery <xref ref-type="bibr" rid="pcbi.1000555-Straw2">[42]</xref>. Other types of flies can have even less resolution, e.g. Land <xref ref-type="bibr" rid="pcbi.1000555-Land3">[75]</xref> reports 2.8 degree resolution in house flies (<italic>Musca domestica</italic>) and as low as 5.8 degrees in fruit flies (<italic>Drosophila melanogaster</italic>). Furthermore acceptance angles (Δρ), which can be approximated by a Gaussian blur with a full width at half maximum of 1.4 degrees (standard deviation of 0.59 degrees) in hoverflies <xref ref-type="bibr" rid="pcbi.1000555-Stavenga1">[44]</xref>, can be as large as 2.6 degrees in bees <xref ref-type="bibr" rid="pcbi.1000555-Laughlin3">[76]</xref> and even 4 degrees in dark adapted locusts <xref ref-type="bibr" rid="pcbi.1000555-Williams1">[77]</xref>.</p>
<p>The results of varying Δρ and Δφ are shown in <xref ref-type="fig" rid="pcbi-1000555-g004">Figure 4</xref> and at no time did we attempt to mimic the variable resolution found to exist across the biological compound eye. In all cases the optimum condition (producing the largest average Z score) was a Δφ of 2 degrees with a Δρ of 2.8 degrees. When Δρ was kept constant at 2.8 degrees (<xref ref-type="fig" rid="pcbi-1000555-g004">Figure 4a</xref>) all tested values of Δφ resulted in significantly lower Z scores than the case of 2 degree sampling, except for 1.26 degrees (p&lt;0.05). However this solution came at the expense of increased computational effort, with 2.5 times more samples (and hence processing power) required to realize it.</p>
<fig id="pcbi-1000555-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000555.g004</object-id><label>Figure 4</label><caption>
<title>Effect of image blur and spatial sampling on velocity discrimination.</title>
<p>A) the optical blur (Δρ) was a constant 2D Gaussian of 2.8 degrees (full width at half maximum) and the spatial sampling rate (Δφ) was varied. B) The spatial sampling was set to 2 degrees (180 pixels in horizontal dimension) and the optical blur varied. C) The optical blur was fixed at 1.4 times larger than the spatial sampling rate, which was varied. The circles show, in order, the Z score between each of the 19 tested speeds between 0.1 and 100degrees/s inclusive (equally spaced on a log scale, i.e. 18 intervals). The columns and error bars show mean Z scores and standard errors of the mean respectively. In each case it was found that the maximal Z score (i.e. best discrimination between velocities) was with a spatial sampling of 2 degrees and an optical blur of 2.8 degrees.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.g004" xlink:type="simple"/></fig>
<p>At a fixed Δφ the location of the optimal angular velocity (corresponding to the largest Z scores) can be shifted to higher velocities by increasing Δρ. In this system it was found that there was no significant difference in the reliability of angular velocity coding when using Δρ of 2.8, 3.53 and 4.44 degrees and with no difference in the number of calculations required to produce these results (assuming the blur was not performed by software convolution of an over sampled system, in which case smaller blur would be less computationally expensive) then the selection of blur would depend only on the application, with systems with larger blurs tuned for higher velocities.</p>
<p>By keeping the Δρ/Δφ equal to 1.4 (<xref ref-type="fig" rid="pcbi-1000555-g004">Figure 4c</xref>) it was possible to show that the system performance was not significantly different over a range of spatial sampling values (1.26–2.52 degrees). As with the constant sampling case increasing the absolute blur moved the optimal point to higher velocities. However in our model computational time increased between these limits by a factor of 4. In computation, as in biology, greater efficiency might thus make lower spatial sampling rates more desirable.</p>
<p>Overall the optical model found to produce the most accurate angular velocity coding was achieved using a Δφ of 2 degrees and a Δρ of 2.8 degrees. While the spatial sampling rate is lower than that found in the majority of insects the blur to sampling rate ratio (Δρ/Δφ ) of 1.4 is the same as that seen in bees <xref ref-type="bibr" rid="pcbi.1000555-Laughlin3">[76]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-vanHateren5">[78]</xref> and flies <xref ref-type="bibr" rid="pcbi.1000555-Straw2">[42]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Stavenga1">[44]</xref>; a ratio that has been predicted as optimal in an information-theoretical sense <xref ref-type="bibr" rid="pcbi.1000555-Snyder1">[79]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Snyder2">[80]</xref>. In comparison experiments in primates have shown that the detection of high temporal frequency stimuli is governed by the relatively low resolution magnocellular pathway <xref ref-type="bibr" rid="pcbi.1000555-Merigan1">[81]</xref>. Furthermore, throughout the animal kingdom, ranging from invertebrates to vertebrates including humans, the mechanisms underlying motion detection can be attributed to correlational EMD-like processing <xref ref-type="bibr" rid="pcbi.1000555-Borst3">[82]</xref>. Thus there is substantial evidence for a common strategy of low-resolution motion vision in many biological systems.</p>
<p>The reason that the optimum spatial sampling rate is so low is because the system was tested under both natural and urban images. Natural scenes have a fractal pattern (self-similarity at different scales) that means, in general, more information can be gained by increasing the resolution of the image. In contrast urban scenes (such as indoor locations) have a high degree of spatial redundancy (such as uniformly painted walls), where increasing the resolution provides little increase to the overall information gained. Since the EMD is a motion energy model it relies on information change between pixels, if there is little information change there is little energy and hence a small motion signal. Thus increasing the resolution had little or no effect on the velocity consistency of the natural scenes, as they all tended to scale together, but it did cause the urban scenes to produce relatively smaller responses. Hence the ideal spatial resolution of a system may be dependant on the mix of urban and natural environments it needs to operate in. This finding is in direct opposition to the current trends in cameras and computer vision towards support for systems with higher spatial resolution.</p>
<p>Unlike in most traditional artificial systems the optimum condition for this system was not a sharply focused image. This is because, due to the low spatial resolution, the system needed to detect sub-pixel motion in order to reliably encode slow velocities. If there were no optical overlap between pixels this would not be possible. However with overlap it was possible to detect small motion changes both within a given pixel and also in the neighboring pixels. Conversely, too much optical blur made the differences between the pixels too small, hence reducing the independence of each sample and resulting in less accurate angular velocity detection.</p>
</sec><sec id="s3c">
<title>Varying Model Parameters</title>
<p>Although it is possible to elicit a motion response by stimulating only two adjacent receptors (see <xref ref-type="fig" rid="pcbi-1000555-g002">Figure 2A</xref>) integration over a larger area reduces phase dependant pattern noise <xref ref-type="bibr" rid="pcbi.1000555-Dror1">[33]</xref>. The optimum integration size will be task-dependent. For the special case simulated in this paper of ‘pure yaw’ (e.g. as needs to be compensated for by a hovering fly) complete elimination of pattern noise in the time domain can be achieved by sampling across the full 360 degrees of the horizontal visual field. However, what additional spatial summation is required to reduce variability due to differences in spatiotemporal contrast over the vertical extent of the field of view? To address this, we varied the number of vertical rows averaged in stage 5 to investigate the degree to which spatial integration across a larger receptive field influenced angular velocity coding. In this case, we used the fully elaborated model (i.e. all stages), with 2 degree spatial sampling and 2.8 degree optical blur as previous experiments had suggested this to be an optimum optical design due to its compromise between Z score and computational efficiency (section 3.2). All conditions involved a central row around the horizon and an equal number of rows evenly spaced above and below the centre up to a maximum of 72 degrees (29 rows due to hexagonal sampling and the inability to use the outer most rows). The results are shown in <xref ref-type="fig" rid="pcbi-1000555-g005">Figure 5</xref>. The maximal average Z score was obtained by using 25 rows, however due to the logarithmic shape of the curve using any number of rows greater than 7 produced results within 10% of the full resolution.</p>
<fig id="pcbi-1000555-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000555.g005</object-id><label>Figure 5</label><caption>
<title>Effect of varying the vertical rows in global summation stage on velocity discrimination.</title>
<p>A) The number of rows used in the global summation (stage 5 in <xref ref-type="fig" rid="pcbi-1000555-g002">Figure 2</xref>) was varied. In each case a row centered on the horizon was used and other rows were equally separated both above and below the horizon. Little improvement is gained by averaging more than 7 rows together. B) Only 3 rows were used in the calculation but the separation of the rows from the centre was varied. The optimal separation of rows occurred at approximately 21 degrees, i.e. rows at +21, 0 and −21 degrees with reference to the horizon. Due to the large amount of image similarity in the vertical dimension separations less than this resulted in samples that were not distinct enough to assist with velocity estimation. Values were calculated as the mean Z score across all velocity intervals used, error bars represent one standard error of the mean.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.g005" xlink:type="simple"/></fig>
<p>The effect of varying the slope of the curve and point of maximal response is shown in <xref ref-type="fig" rid="pcbi-1000555-g006">Figure 6</xref>. The slope of the model can be modified to fit the desired scope of velocities for a given application. Using a smaller range (i.e. greater response gain as a function of angular velocity) made the system more robust against noise, which is more likely to be a problem at low speeds or where the output bandwidth is limited. However in a noise free simulation there was little or no benefit in reducing the working range. The average Z score was 6.77±1.16, 7.53±1.62 and 7.15±1.59 (mean±95% confidence interval) for slope parameters of 0.3, 0.5 and 0.75 respectively.</p>
<fig id="pcbi-1000555-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000555.g006</object-id><label>Figure 6</label><caption>
<title>Effect of varying the working range and velocity optima.</title>
<p>Average model responses for all 14 natural images. The model can be configured to detect different velocity ranges and to have a peak response at different velocities. Error bars represent one standard deviation. A) The slope refers to the exponent of a power function implemented at the end of stage 4. Despite the clear reduction in response amplitude at the higher slope value there was no significant difference in Z score between a slope of 0.3 and 0.75 in the range 0.01–1 degrees/s (paired t-test, p&gt;0.05). This finding is most likely due to the lack of noise in the model and would change in any real-world implementation. B) The peak response of the model is a function of the (3rd order) delay filter implemented in the Hassenstein-Reichardt detector (stage 3). Using a slower delay filter shifts the maximum response point to lower velocities and increases the rate of roll-off outside the pass-band. In the case of the slowest delay filter used the response is inverted (aliased) at very high velocities.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.g006" xlink:type="simple"/></fig>
<p>The maximum (optimal) angular velocity of the system could be changed depending on the requirements of the system (<xref ref-type="fig" rid="pcbi-1000555-g006">Figure 6b</xref>). In all cases the variation between images was much greater outside the working range (above the optimum angular velocity). This is because the variability within individual images (pattern noise) increased with angular velocity and with a decreasing response to the true angular velocity the signal became swamped with noise.</p>
</sec><sec id="s3d">
<title>Dynamic Stimuli</title>
<p>In all of the test conditions described in the paper to date the image angular velocity was constant and the motion detection model was given sufficient time to reach steady-state before the results were taken. However this is not a realistic situation for a motion sensor that would typically be required to produce a reliable response under dynamic conditions. In order to test the model under conditions of variable angular velocity and acceleration a 20 second stimulus was constructed that consisted of variable width periods of constantly (in the log domain) increasing and decreasing angular velocity. The exact waveform, and the model response, is shown in <xref ref-type="fig" rid="pcbi-1000555-g007">Figure 7</xref>. With the median of the coefficient of variation being 7.28% the model showed little variation in response to the different scenes, even under rapid accelerations (±844 degrees/s<sup>2</sup>). In fact the median coefficient of variation under constant conditions over the same rotational velocities (100−0.5 degrees/s) was 6.91%, indicating a decrease in performance reliability of less than 5.5% under dynamic conditions where the model was not permitted to reach stead-state.</p>
<fig id="pcbi-1000555-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000555.g007</object-id><label>Figure 7</label><caption>
<title>Response of the motion detection model to dynamic stimuli.</title>
<p>The time domain response of the model to all images as tested under velocity ramps of different slopes. Image assignments and line coloring is the same as <xref ref-type="fig" rid="pcbi-1000555-g001">Figure 1</xref>. Despite the relatively large, and variable, accelerations involved the motion model produces very consistent responses for the different images. Aliasing (reversal of signaled direction) can be seen when the stimulus changes from decreasing to increasing velocity under the high acceleration.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.g007" xlink:type="simple"/></fig>
<p>Despite the system only being tested under positive angular velocities there were situations when the model produced negative results indicating that the model got the direction of motion wrong. This aliasing occurred at low velocities following high velocities and at the point where the stimulus went from decreasing to increasing rotational velocities. Moreover, it was more prevalent under larger accelerations. Despite not being explicitly included in the motion model (see section 3.1 stage 5) this result is somewhat analogous to the waterfall effect where after the rapid removal of a large motion stimulus motion detecting neurons tend to hyperpolarize.</p>
<p>Although flies are capable of extreme angular accelerations during saccades, much larger than the 844 degrees/s<sup>2</sup> tested here, <xref ref-type="bibr" rid="pcbi.1000555-Schilstra1">[83]</xref> it is not clear that the visual system is used for coding under such situations. Some authors (e.g. <xref ref-type="bibr" rid="pcbi.1000555-Warzecha1">[69]</xref>) have made the point that the visual motion response may be deliberately damped to avoid sensitivity to such events in order to avoid instability in the optomotor response, in lieu of a mechanism for saccadic suppression (as in primate vision) otherwise required. Other sensory systems likely play a role in encoding high-speed acceleration (e.g. halteres) and the visual motion pathway seems deliberately tuned to low speeds in flies (see <xref ref-type="bibr" rid="pcbi.1000555-OCarroll3">[84]</xref>).</p>
</sec><sec id="s3e">
<title>Horizontal Field of View</title>
<p>In all previously described results the full 360 degrees of horizontal visual space was integrated in order to remove the dependence of the result on the part of the image being analyzed (pattern noise). Although it can be reduced by integrating over smaller areas <xref ref-type="bibr" rid="pcbi.1000555-Harrison1">[85]</xref> using a fully panoramic field of view has been show to be the only way to eliminate the periodic responses dependant on image statistics <xref ref-type="bibr" rid="pcbi.1000555-Rajesh1">[86]</xref>. Behavioral experiments in the fly have shown that they are sensitive to the contrast and orientation of patterns at the level of individual receptor pairs (i.e. single EMDs) <xref ref-type="bibr" rid="pcbi.1000555-Reichardt2">[87]</xref> or when they cover a larger (non-panoramic) area of space <xref ref-type="bibr" rid="pcbi.1000555-Reichardt3">[88]</xref>. While not realistic for the output of a single neuron <xref ref-type="bibr" rid="pcbi.1000555-Nordstrm1">[89]</xref> the outputs of populations of motion sensitive LPTCs combine to give an almost complete panoramic view, as evidenced by the output of neck motor neurons <xref ref-type="bibr" rid="pcbi.1000555-Huston1">[90]</xref>, thus minimising pattern noise by means of spatial integration <xref ref-type="bibr" rid="pcbi.1000555-Reichardt2">[87]</xref>. In addition to integrating over wider fields of view incorporating saturation and other non-linear processing elements predicted to exist in the biological motion processing pathway can modify and reduce pattern noise when a limited field of view is used <xref ref-type="bibr" rid="pcbi.1000555-Dror1">[33]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Rajesh2">[91]</xref>.</p>
<p>In order to investigate the role of horizontal field of view on the temporal response of the system we reduced the field of view of the model to 20 degrees of visual space in both the raw (but normalized for image brightness) and fully elaborated models. Under such conditions there were two important sources of variability to consider, that between images (inter-image, as already reported) and that within images (intra-image, i.e. the time domain variability of the system in response to a constant input). The responses of the model to a constant velocity of 50 degree/s are shown in <xref ref-type="fig" rid="pcbi-1000555-g008">Figure 8</xref>. With the limited spatial integration and most basic EMD model the average coefficient of variation within images over a full rotation was 66.3±27.1% (mean±standard deviation) and the variation between the 14 image means was 46.6%. Thus showing the response was not a constant indicator of individual image velocity, or a good inter-image velocity estimator. Increasing the field of view to 360 degrees dramatically reduced the intra-image variation to 0.82±0.44%, however as expected it had no effect on the intra-image variation. Using the full model with the limited field of view resulted in an intra-image variation of 23.9±5.1%, reduced compared to the case with the spatially limited raw model but not to the same extent as with the panoramic view. The inter-image variation in this case was 11.7%, much improved over both raw cases. Finally, the full model with full 360 degree field of view produced both the smallest intra-image (0.48±0.14%) and inter-image (2.2%) variations. The difference in the inter-image variations between the full and limited field of view tests was due to both the reduced saturation (in the spatially limited case) and the different weighting factors in the non-linear global summation stage.</p>
<fig id="pcbi-1000555-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000555.g008</object-id><label>Figure 8</label><caption>
<title>Temporal response of spatially restricted basic and elaborated models.</title>
<p>Image appeared over a content grey background at time −400ms. Due to adaptive elements in the early visual processing an appearance artifact is visible in the elaborated models. Images were kept stationary until time 0 when the velocity stepped up to 50 degrees/s. In addition to the raw correlator elementary motion detector (<xref ref-type="fig" rid="pcbi-1000555-g002">Figure 2A</xref>) the basic model also included a normalization factor for the image brightness. The vertical scales for the model settings are different in each case in order to show the full variations under each condition. The variation in the time domain response (pattern noise) when the model had only a 20 degree field of view (FoV) was much larger than when averaged over the full 360 degrees of visual space. Furthermore, the inclusion of the model elaborations reduced not only the variations between images but also the pattern noise within individual images, even in the absence of a large field of view. Inset shows a close-up of the model response to the velocity step (shown as dotted gray line). Even at the very high acceleration induced by this stimulus the model maintains a similar response profile for all images tested. Image assignments and line coloring is the same as <xref ref-type="fig" rid="pcbi-1000555-g001">Figure 1</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000555.g008" xlink:type="simple"/></fig></sec><sec id="s3f">
<title>Conclusion</title>
<p>By constructing a model for motion detection based on elements known, or suspected, to be present in the biological system we have shown that accurate and robust detection of global motion can be achieved using a system with very low resolution based on relatively simple mathematical operations. The key to the operation of the model was the way multiple non-linear elements interacted to produce an estimate of angular velocity that was independent of the scene it was viewing. Moreover, the performance of the system as a whole was greater than the linear addition of the individual components taken in isolation.</p>
<p>While we have based our model on parameters derived from physiological analysis of the fly motion pathway the model may also be applicable to data from other species. In previous work Ibbotson described ‘velocity tuned’ (VT) neurons in the honeybee that appear to differ from our model and fly neurons in having monotonic responses to very high speeds (1000 degrees/s) and apparently less dependent on spatial period of square-wave patterns <xref ref-type="bibr" rid="pcbi.1000555-Ibbotson1">[92]</xref>. While a degree of pattern invariance may result from the adaptive nature of our model, the apparent lack of response roll-off in the Ibbotson data is more difficult to reconcile with the fly data. Interestingly, however, because the bee spatial optimum is much lower than in flies (coarser spatial sampling) and the temporal optima much higher (shorter delay) <xref ref-type="bibr" rid="pcbi.1000555-OCarroll3">[84]</xref>, the useful “coding range” (as referred to in our model description) is predicted to be shifted to 10 times that in flies (see <xref ref-type="bibr" rid="pcbi.1000555-Dror2">[93]</xref>), where velocity optima for natural scenes are already 200 degrees/s <xref ref-type="bibr" rid="pcbi.1000555-Straw1">[36]</xref>. Since the Ibbotson data set only explored velocities below 1000 degrees/s it is thus likely that patterns were not animated at high enough velocities to see the response roll-off predicted by a correlation-based model (including our fully elaborated model).</p>
<p>There is strong evidence that the fly motion pathway processes negative and positive contrasts separately <xref ref-type="bibr" rid="pcbi.1000555-Harris1">[47]</xref>. However, the motion model described here does not incorporate any kind of ‘contrast asymmetry’. Although several authors have explored whether the motion pathway is fed by separate ‘on’ and ‘off’ pathways (e.g. <xref ref-type="bibr" rid="pcbi.1000555-Egelhaaf5">[94]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Riehle1">[95]</xref>), no studies have yet provided conclusive results. Recently we have shown that the separation between ‘on’ and ‘off’ pathways can be a useful primitive in target detection <xref ref-type="bibr" rid="pcbi.1000555-Wiederman1">[96]</xref>,<xref ref-type="bibr" rid="pcbi.1000555-Wiederman2">[97]</xref>. While others have shown that contrast separation can be used as a pre-processing stage in a different type of EMD-based model <xref ref-type="bibr" rid="pcbi.1000555-Franceschini1">[98]</xref> the current model shows it is not a necessity for the accurate detection of wide field angular velocity using correlation-based EMDs.</p>
<p>There is a significant push to reduce the complexity of bio-inspired algorithms so they will run in real-time on modern computer platforms <xref ref-type="bibr" rid="pcbi.1000555-Bayerl1">[99]</xref>. The complexity of the model described in this paper may be too much to realize in a real-time application based on a single serial CPU. However its highly parallel nature and low resolution make it an ideal candidate for implementation in either a FPGA or GPGPU <xref ref-type="bibr" rid="pcbi.1000555-NVIDIA1">[100]</xref> based platform. Furthermore reduced versions have already been produced in analog VLSI <xref ref-type="bibr" rid="pcbi.1000555-Brinkworth2">[101]</xref> and may be suitable for serial digital systems as well <xref ref-type="bibr" rid="pcbi.1000555-OCarroll4">[102]</xref> where frame rates in excess of 100Hz have already been achieved using standard consumer-level computers. It is also important to note that the computational complexity of an EMD based system can be orders of magnitude less than alternative schemes for computing local velocity vectors in optic flow analysis (e.g. <xref ref-type="bibr" rid="pcbi.1000555-Lucas1">[103]</xref>).</p>
</sec></sec></body>
<back><ref-list>
<title>References</title>
<ref id="pcbi.1000555-Strausfeld1"><label>1</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Strausfeld</surname><given-names>N</given-names></name>
</person-group>             <year>1976</year>             <source>Some Quantitative Aspects of the Fly's Brain. Atlas of an Insect</source>             <publisher-loc>Berlin</publisher-loc>             <publisher-name>Springer-Verlag</publisher-name>             <fpage>49</fpage>             <lpage>56</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Land1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Land</surname><given-names>MF</given-names></name>
<name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name>
</person-group>             <year>1974</year>             <article-title>Chasing behaviour of houseflies.</article-title>             <source>J Comp Physiol A</source>             <volume>156</volume>             <fpage>525</fpage>             <lpage>538</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Land2"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Land</surname><given-names>MF</given-names></name>
<name name-style="western"><surname>Eckert</surname><given-names>HM</given-names></name>
</person-group>             <year>1985</year>             <article-title>Maps of the acute zones of fly eyes.</article-title>             <source>J Comp Physiol A</source>             <volume>156</volume>             <fpage>525</fpage>             <lpage>538</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Srinivasan1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Srinivasan</surname><given-names>MV</given-names></name>
<name name-style="western"><surname>Zhang</surname><given-names>SW</given-names></name>
<name name-style="western"><surname>Lehrer</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name>
</person-group>             <year>1996</year>             <article-title>Honeybee navigation en route to the goal: Visual flight control and odometry.</article-title>             <source>J Exp Biol</source>             <volume>199</volume>             <fpage>237</fpage>             <lpage>244</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Olberg1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Olberg</surname><given-names>RM</given-names></name>
<name name-style="western"><surname>Worthington</surname><given-names>AH</given-names></name>
<name name-style="western"><surname>R</surname><given-names>VK</given-names></name>
</person-group>             <year>2000</year>             <article-title>Prey pursuit and interception in dragonflies.</article-title>             <source>J Comp Physiol A</source>             <volume>186</volume>             <fpage>155</fpage>             <lpage>162</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Srinivasan2"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Srinivasan</surname><given-names>MV</given-names></name>
<name name-style="western"><surname>Zhang</surname><given-names>SW</given-names></name>
<name name-style="western"><surname>Altwein</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Tautz</surname><given-names>J</given-names></name>
</person-group>             <year>2000</year>             <article-title>Honeybee navigation: Nature and calibration of the “odometer”.</article-title>             <source>Science</source>             <volume>287</volume>             <fpage>851</fpage>             <lpage>853</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Egelhaaf1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Egelhaaf</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Borst</surname><given-names>A</given-names></name>
</person-group>             <year>1993</year>             <article-title>A look into the cockpit of the fly - visual orientation, algorithms, and identified neurons.</article-title>             <source>J Neurosci</source>             <volume>13</volume>             <fpage>4563</fpage>             <lpage>4574</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Collett1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Collett</surname><given-names>TS</given-names></name>
<name name-style="western"><surname>Land</surname><given-names>MF</given-names></name>
</person-group>             <year>1975</year>             <article-title>Visual control of flight behaviour in the hoverfly, <italic>Syritta pipiens L</italic>.</article-title>             <source>J Comp Physiol A</source>             <volume>99</volume>             <fpage>1</fpage>             <lpage>66</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Kern1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kern</surname><given-names>R</given-names></name>
<name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Michaelis</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Lindemann</surname><given-names>JP</given-names></name>
<name name-style="western"><surname>Egelhaaf</surname><given-names>M</given-names></name>
</person-group>             <year>2005</year>             <article-title>Function of a fly motion-sensitive neuron matches eye movements during free flight.</article-title>             <source>PLoS Biol</source>             <volume>3</volume>             <fpage>e171</fpage>          </element-citation></ref>
<ref id="pcbi.1000555-OCarroll1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>
<name name-style="western"><surname>Bidwell</surname><given-names>NJ</given-names></name>
<name name-style="western"><surname>Harris</surname><given-names>RA</given-names></name>
</person-group>             <year>1997</year>             <article-title>Spatio-temporal properties of motion detectors matched to low image velocities in hovering insects.</article-title>             <source>Vision Res</source>             <volume>37</volume>             <fpage>3427</fpage>             <lpage>3439</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Barron1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Barron</surname><given-names>JL</given-names></name>
<name name-style="western"><surname>Fleet</surname><given-names>DJ</given-names></name>
<name name-style="western"><surname>Beauchemin</surname><given-names>SS</given-names></name>
</person-group>             <year>1994</year>             <article-title>Performance of optical-flow techniques.</article-title>             <source>IJCV</source>             <volume>12</volume>             <fpage>43</fpage>             <lpage>77</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Horn1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Horn</surname><given-names>BKP</given-names></name>
<name name-style="western"><surname>Schunck</surname><given-names>BG</given-names></name>
</person-group>             <year>1981</year>             <article-title>Determining optical-flow.</article-title>             <source>Artif Intell</source>             <volume>17</volume>             <fpage>185</fpage>             <lpage>203</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Nagel1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nagel</surname><given-names>HH</given-names></name>
</person-group>             <year>1987</year>             <article-title>On the estimation of optical-flow - Relations between different approaches and some new results.</article-title>             <source>Artif Intell</source>             <volume>33</volume>             <fpage>299</fpage>             <lpage>324</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Potters1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Potters</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name>
</person-group>             <year>1994</year>             <article-title>Statistical-mechanics and visual signal-processing.</article-title>             <source>Journal de Physique</source>             <volume>4</volume>             <fpage>1755</fpage>             <lpage>1775</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Anandan1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Anandan</surname><given-names>P</given-names></name>
</person-group>             <year>1989</year>             <article-title>A computational framework and an algorithm for the measurement of visual-motion.</article-title>             <source>IJCV</source>             <volume>2</volume>             <fpage>283</fpage>             <lpage>310</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Singh1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Singh</surname><given-names>A</given-names></name>
</person-group>             <year>1992</year>             <article-title>Incremental estimation of image flow using a Kalman filter.</article-title>             <source>JVCIR</source>             <volume>3</volume>             <fpage>39</fpage>             <lpage>57</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Dellaert1"><label>17</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dellaert</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Fox</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Burgard</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Thrun</surname><given-names>S</given-names></name>
</person-group>             <year>1999</year>             <article-title>Monte Carlo localization for mobile robots.</article-title>             <fpage>1322</fpage>             <lpage>1328</lpage>             <comment>ICRA '99: IEEE International Conference on Robotics and Automation, Vols 1–4, Proceedings</comment>          </element-citation></ref>
<ref id="pcbi.1000555-Botelho1"><label>18</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Botelho</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Correa</surname><given-names>UB</given-names></name>
<name name-style="western"><surname>Lautenschlager</surname><given-names>WI</given-names></name>
</person-group>             <year>2006</year>             <article-title>Vision-Based Motion Detection Using C-NLPCA Approach.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>de Paulo Canuto</surname><given-names>AM</given-names></name>
<name name-style="western"><surname>de Souto</surname><given-names>MCP</given-names></name>
</person-group>             <publisher-loc>Brazil</publisher-loc>             <publisher-name>Ribeirão Preto</publisher-name>             <fpage>37</fpage>             <lpage>42</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Fleet1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fleet</surname><given-names>DJ</given-names></name>
<name name-style="western"><surname>Jepson</surname><given-names>AD</given-names></name>
</person-group>             <year>1990</year>             <article-title>Computation of component image velocity from local phase information.</article-title>             <source>IJCV</source>             <volume>5</volume>             <fpage>77</fpage>             <lpage>104</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Fleet2"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fleet</surname><given-names>DJ</given-names></name>
<name name-style="western"><surname>Jepson</surname><given-names>AD</given-names></name>
</person-group>             <year>1993</year>             <article-title>Stability of phase information.</article-title>             <source>TPAMI</source>             <volume>15</volume>             <fpage>1253</fpage>             <lpage>1268</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Heeger1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name>
</person-group>             <year>1987</year>             <article-title>Optical-flow using spatiotemporal filters.</article-title>             <source>IJCV</source>             <volume>1</volume>             <fpage>279</fpage>             <lpage>302</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Heeger2"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name>
</person-group>             <year>1987</year>             <article-title>Model for the extraction of image flow.</article-title>             <source>JOSA</source>             <volume>4</volume>             <fpage>1455</fpage>             <lpage>1471</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Adelson1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Adelson</surname><given-names>EH</given-names></name>
<name name-style="western"><surname>Bergen</surname><given-names>JR</given-names></name>
</person-group>             <year>1985</year>             <article-title>Spatiotemporal energy models for the perception of motion.</article-title>             <source>JOSA</source>             <volume>2</volume>             <fpage>284</fpage>             <lpage>299</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Hassenstein1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hassenstein</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Reichardt</surname><given-names>W</given-names></name>
</person-group>             <year>1956</year>             <article-title>Systemtheoretische analyse der Zeit-, Reihenfolgen-, und Vorseichenauswertung bei der Berwegungsperzeption des Rüsselkäfers Chlorophanus.</article-title>             <source>Zeitschrift für Naturforschung</source>             <volume>11b</volume>             <fpage>513</fpage>             <lpage>524</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-WolfOberhollenzer1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wolf-Oberhollenzer</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Kirschfeld</surname><given-names>K</given-names></name>
</person-group>             <year>1994</year>             <article-title>Motion sensitivity in the nucleus of the basal optic root of the pigeon.</article-title>             <source>J Neurophysiol</source>             <volume>71</volume>             <fpage>1559</fpage>             <lpage>1573</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Vansanten1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Vansanten</surname><given-names>JPH</given-names></name>
<name name-style="western"><surname>Sperling</surname><given-names>G</given-names></name>
</person-group>             <year>1984</year>             <article-title>Temporal covariance model of human motion perception.</article-title>             <source>Journal of the Optical Society of America a-Optics Image Science and Vision</source>             <volume>1</volume>             <fpage>451</fpage>             <lpage>473</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Clifford1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Clifford</surname><given-names>CWG</given-names></name>
<name name-style="western"><surname>Ibbotson</surname><given-names>MR</given-names></name>
</person-group>             <year>2003</year>             <article-title>Fundamental mechanisms of visual motion detection: models, cells and functions.</article-title>             <source>Progress in Neurobiology</source>             <volume>68</volume>             <fpage>409</fpage>             <lpage>437</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Reichardt1"><label>28</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reichardt</surname><given-names>W</given-names></name>
</person-group>             <year>1961</year>             <article-title>Autocorrelation, a Principle for the Evaluation of Sensory Information by the Central Nervous System.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Rosenblith</surname><given-names>WA</given-names></name>
</person-group>             <source>Principles of Sensory Communications</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>John Wiley</publisher-name>             <fpage>303</fpage>             <lpage>317</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Egelhaaf2"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Egelhaaf</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Borst</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Reichardt</surname><given-names>W</given-names></name>
</person-group>             <year>1989</year>             <article-title>Computational structure of a biological motion-detection system as revealed by local detector analysis in the fly's nervous-system.</article-title>             <source>JOSA</source>             <volume>6</volume>             <fpage>1070</fpage>             <lpage>1087</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Kennedy1"><label>30</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kennedy</surname><given-names>HL</given-names></name>
</person-group>             <year>2007</year>             <source>Gradient Operators for the Determination of Optical Flow</source>             <publisher-loc>Glenelg, Australia.</publisher-loc>             <fpage>346</fpage>             <lpage>351</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Borst1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Borst</surname><given-names>A</given-names></name>
</person-group>             <year>2007</year>             <article-title>Correlation versus gradient type motion detectors: the pros and cons.</article-title>             <source>Philos Trans R Soc Lond B: Biol Sci</source>             <volume>362</volume>             <fpage>369</fpage>             <lpage>374</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Haag1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Haag</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Denk</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Borst</surname><given-names>A</given-names></name>
</person-group>             <year>2004</year>             <article-title>Fly motion vision is based on Reichardt detectors regardless of the signal-to-noise ratio.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>101</volume>             <fpage>16333</fpage>             <lpage>16338</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Dror1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dror</surname><given-names>RO</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>
</person-group>             <year>2001</year>             <article-title>Accuracy of velocity estimation by Reichardt correlators.</article-title>             <source>Journal of the Optical Society of America A: Optics, Image Science &amp; Vision</source>             <volume>18</volume>             <fpage>241</fpage>             <lpage>252</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Shoemaker1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Shoemaker</surname><given-names>PA</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Straw</surname><given-names>AD</given-names></name>
</person-group>             <year>2005</year>             <article-title>Velocity constancy and models for wide-field motion detection in insects.</article-title>             <source>Biol Cybern</source>             <volume>93</volume>             <fpage>275</fpage>             <lpage>287</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Tolhurst1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name>
<name name-style="western"><surname>Tadmor</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Chao</surname><given-names>T</given-names></name>
</person-group>             <year>1992</year>             <article-title>Amplitude spectra of natural images.</article-title>             <source>OPO</source>             <volume>12</volume>             <fpage>229</fpage>             <lpage>232</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Straw1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Straw</surname><given-names>AD</given-names></name>
<name name-style="western"><surname>Rainsford</surname><given-names>T</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
</person-group>             <year>2008</year>             <article-title>Contrast sensitivity of insect motion detectors to natural images.</article-title>             <source>Journal of Vision</source>             <volume>8</volume>             <fpage>1</fpage>             <lpage>9</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Lindemann1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lindemann</surname><given-names>JP</given-names></name>
<name name-style="western"><surname>Kern</surname><given-names>R</given-names></name>
<name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Ritter</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Egelhaaf</surname><given-names>M</given-names></name>
</person-group>             <year>2005</year>             <article-title>On the Computations Analyzing Natural Optic Flow: Quantitative Model Analysis of the Blowfly Motion Vision Pathway.</article-title>             <source>J Neurosci</source>             <volume>25</volume>             <fpage>6435</fpage>             <lpage>6448</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Debevec1"><label>38</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Debevec</surname><given-names>PE</given-names></name>
<name name-style="western"><surname>Malik</surname><given-names>J</given-names></name>
</person-group>             <year>1997</year>             <source>Recovering High Dynamic Range Radiance Maps from Photographs</source>             <publisher-loc>Los Angeles, CA,, USA.</publisher-loc>             <fpage>369</fpage>             <lpage>378</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Smakman1"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Smakman</surname><given-names>JG</given-names></name>
<name name-style="western"><surname>Stavenga</surname><given-names>DG</given-names></name>
</person-group>             <year>1986</year>             <article-title>Spectral sensitivity of blowfly photoreceptors: dependence on waveguide effects and pigment concentration.</article-title>             <source>Vision Research</source>             <volume>26</volume>             <fpage>1019</fpage>             <lpage>1025</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Srinivasan3"><label>40</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Srinivasan</surname><given-names>MV</given-names></name>
<name name-style="western"><surname>Guy</surname><given-names>RG</given-names></name>
</person-group>             <year>1990</year>             <article-title>Spectral properties of movement perception in the dronefly Eristalis.</article-title>             <source>J Comp Physiol A</source>             <volume>166</volume>             <fpage>287</fpage>             <lpage>295</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Tadmor1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tadmor</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name>
</person-group>             <year>2000</year>             <article-title>Calculating the contrasts that retinal ganglion cells and LGN neurones encounter in natural scenes.</article-title>             <source>Vision Res</source>             <volume>40</volume>             <fpage>3145</fpage>             <lpage>3157</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Straw2"><label>42</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Straw</surname><given-names>AD</given-names></name>
<name name-style="western"><surname>Warrant</surname><given-names>EJ</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
</person-group>             <year>2006</year>             <article-title>A ‘bright zone’ in male hoverfly (Eristalis tenax) eyes and associated faster motion detection and increased contrast sensitivity.</article-title>             <source>J Exp Biol</source>             <volume>209</volume>             <fpage>4339</fpage>             <lpage>4354</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Krapp1"><label>43</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Krapp</surname><given-names>HG</given-names></name>
<name name-style="western"><surname>Hengstenberg</surname><given-names>R</given-names></name>
</person-group>             <year>1996</year>             <article-title>Estimation of self-motion by optic flow processing in single visual interneurons.</article-title>             <source>Nature</source>             <volume>384</volume>             <fpage>463</fpage>             <lpage>466</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Stavenga1"><label>44</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stavenga</surname><given-names>DG</given-names></name>
</person-group>             <year>2003</year>             <article-title>Angular and spectral sensitivity of fly photoreceptors. I. Integrated facet lens and rhabdomere optics.</article-title>             <source>J Comp Physiol A</source>             <volume>189</volume>             <fpage>1</fpage>             <lpage>17</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Egelhaaf3"><label>45</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Egelhaaf</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Kern</surname><given-names>R</given-names></name>
</person-group>             <year>2002</year>             <article-title>Vision in flying insects.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>12</volume>             <fpage>699</fpage>             <lpage>706</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-vanHateren1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name>
</person-group>             <year>1990</year>             <article-title>Directional tuning curves elementary movement detectors and the estimation of the direction of visual movement.</article-title>             <source>Vision Res</source>             <volume>30</volume>             <fpage>603</fpage>             <lpage>614</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Harris1"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Harris</surname><given-names>RA</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
</person-group>             <year>2002</year>             <article-title>Afterimages in fly motion vision.</article-title>             <source>Vision Res</source>             <volume>42</volume>             <fpage>1701</fpage>             <lpage>1714</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Harris2"><label>48</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Harris</surname><given-names>RA</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>
</person-group>             <year>1999</year>             <article-title>Adaptation and the temporal filter of fly motion detectors.</article-title>             <source>Vision Res</source>             <volume>39</volume>             <fpage>2603</fpage>             <lpage>2613</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Mah1"><label>49</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mah</surname><given-names>EL</given-names></name>
<name name-style="western"><surname>Brinkworth</surname><given-names>RSA</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
</person-group>             <year>2008</year>             <article-title>Implementation of an elaborated neuromorphic model of a biological photoreceptor.</article-title>             <source>Biol Cybern</source>             <volume>98</volume>             <fpage>357</fpage>             <lpage>369</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-vanHateren2"><label>50</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Snippe</surname><given-names>HP</given-names></name>
</person-group>             <year>2001</year>             <article-title>Information Theoretical Evaluation of Parametric Models of Gain Control in Blowfly Photoreceptor Cells.</article-title>             <source>Vision Res</source>             <volume>41</volume>             <fpage>1851</fpage>             <lpage>1865</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-vanHateren3"><label>51</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Snippe</surname><given-names>HP</given-names></name>
</person-group>             <year>2006</year>             <article-title>Phototransduction in primate cones and blowfly photoreceptors: different mechanisms, different algorithms, similar response.</article-title>             <source>J Comp Physiol A</source>             <volume>192</volume>             <fpage>187</fpage>             <lpage>197</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Brinkworth1"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Brinkworth</surname><given-names>RSA</given-names></name>
<name name-style="western"><surname>Mah</surname><given-names>EL</given-names></name>
<name name-style="western"><surname>Gray</surname><given-names>JP</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
</person-group>             <year>2008</year>             <article-title>Photoreceptor Processing Improves Salience Facilitating Small Target Detection In Cluttered Scenes.</article-title>             <source>Journal of Vision</source>             <volume>8</volume>             <fpage>1</fpage>             <lpage>17</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Laughlin1"><label>53</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>
<name name-style="western"><surname>Hardie</surname><given-names>RC</given-names></name>
</person-group>             <year>1978</year>             <article-title>Common strategies for light adaptation in the peripheral visual systems of fly and dragonfly.</article-title>             <source>J Comp Physiol</source>             <volume>128</volume>             <fpage>319</fpage>             <lpage>340</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-vanHateren4"><label>54</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name>
</person-group>             <year>1992</year>             <article-title>A theory of maximizing sensory information.</article-title>             <source>Biol Cybern</source>             <volume>68</volume>             <fpage>68</fpage>             <lpage>70</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Juusola1"><label>55</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Juusola</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Uusitalo</surname><given-names>RO</given-names></name>
<name name-style="western"><surname>Weckstrom</surname><given-names>M</given-names></name>
</person-group>             <year>1995</year>             <article-title>Transfer of Graded Potentials at the Photoreceptor Interneuron Synapse.</article-title>             <source>J Gen Physiol</source>             <volume>105</volume>             <fpage>117</fpage>             <lpage>148</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Laughlin2"><label>56</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>
<name name-style="western"><surname>Osorio</surname><given-names>D</given-names></name>
</person-group>             <year>1989</year>             <article-title>Mechanisms for neural signal enhncement in the blowfly compound eye.</article-title>             <source>J Exp Biol</source>             <volume>144</volume>             <fpage>113</fpage>             <lpage>146</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Kirschfeld1"><label>57</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kirschfeld</surname><given-names>K</given-names></name>
</person-group>             <year>1971</year>             <article-title>[Uptake and processing of optic data in the complex eye of insects].</article-title>             <source>Naturwissenschaften</source>             <volume>58</volume>             <fpage>201</fpage>             <lpage>209</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-James1"><label>58</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>James</surname><given-names>AC</given-names></name>
</person-group>             <year>1992</year>             <article-title>Nonlinear operator network models of processing in the fly lamina.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Pinter</surname><given-names>RB</given-names></name>
<name name-style="western"><surname>Nabet</surname><given-names>B</given-names></name>
</person-group>             <source>Nonlinear vision: Determination of neural receptive fields, function, and networks</source>             <publisher-loc>London</publisher-loc>             <publisher-name>CRC Press</publisher-name>             <fpage>39</fpage>             <lpage>73</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Dubs1"><label>59</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dubs</surname><given-names>A</given-names></name>
</person-group>             <year>1982</year>             <article-title>The spatial intergration of signals in the retina and lamina of the fly compound eye under different conditions of luminance.</article-title>             <source>J Comp Physiol A</source>             <volume>146</volume>             <fpage>321</fpage>             <lpage>343</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Douglass1"><label>60</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Douglass</surname><given-names>JK</given-names></name>
<name name-style="western"><surname>Strausfeld</surname><given-names>NJ</given-names></name>
</person-group>             <year>1995</year>             <article-title>Visual motion detection circuits in flies: peripheral motion computation by identified small-field retinotopic neurons.</article-title>             <source>J Neurosci</source>             <volume>15</volume>             <fpage>5596</fpage>             <lpage>5611</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Rister1"><label>61</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rister</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Pauls</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Schnell</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Ting</surname><given-names>CY</given-names></name>
<name name-style="western"><surname>Lee</surname><given-names>CH</given-names></name>
<etal/></person-group>             <year>2007</year>             <article-title>Dissection of the peripheral motion channel in the visual system of Drosophila melanogaster.</article-title>             <source>Neuron</source>             <volume>56</volume>             <fpage>155</fpage>             <lpage>170</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Coombe1"><label>62</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Coombe</surname><given-names>PE</given-names></name>
<name name-style="western"><surname>Srinivasan</surname><given-names>MV</given-names></name>
<name name-style="western"><surname>Guy</surname><given-names>RG</given-names></name>
</person-group>             <year>1989</year>             <article-title>Are the large monopolar cells of the insect lamina on the optomotor pathway.</article-title>             <source>J Comp Physiol A</source>             <volume>166</volume>             <fpage>23</fpage>             <lpage>35</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Strausfeld2"><label>63</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Strausfeld</surname><given-names>NJ</given-names></name>
<name name-style="western"><surname>Lee</surname><given-names>JK</given-names></name>
</person-group>             <year>1991</year>             <article-title>Neuronal basis for parallel visual processing in the fly.</article-title>             <source>Visual Neurosci</source>             <volume>7</volume>             <fpage>13</fpage>             <lpage>33</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Egelhaaf4"><label>64</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Egelhaaf</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Borst</surname><given-names>A</given-names></name>
</person-group>             <year>1989</year>             <article-title>Transient and steady-state response properties of movement detectors.</article-title>             <source>JOSA</source>             <volume>6</volume>             <fpage>116</fpage>             <lpage>127</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-RiveraAlvidrez1"><label>65</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rivera-Alvidrez</surname><given-names>Z</given-names></name>
<name name-style="western"><surname>Higgins</surname><given-names>CM</given-names></name>
</person-group>             <year>2005</year>             <source>Contrast saturation in a neuronally-based model of elementary motion detection</source>             <publisher-name>Elsevier Science Bv</publisher-name>             <fpage>173</fpage>             <lpage>179</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Osorio1"><label>66</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Osorio</surname><given-names>D</given-names></name>
</person-group>             <year>1987</year>             <article-title>The temporal properties of nonlinear, transient cells in the locust medulla.</article-title>             <source>J Comp Physiol A</source>             <volume>161</volume>             <fpage>431</fpage>             <lpage>440</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Osorio2"><label>67</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Osorio</surname><given-names>D</given-names></name>
</person-group>             <year>1991</year>             <article-title>Mechanisms of early visual processing in the medulla of the locust optic lobe - how self-inhibition, spatial-pooling, and signal rectification contribute to the properties of transient cells.</article-title>             <source>Visual Neurosci</source>             <volume>7</volume>             <fpage>345</fpage>             <lpage>355</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Honegger1"><label>68</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Honegger</surname><given-names>HW</given-names></name>
</person-group>             <year>1980</year>             <article-title>Receptive-fields of sustained medulla neurons in crickets.</article-title>             <source>J Comp Physiol</source>             <volume>136</volume>             <fpage>191</fpage>             <lpage>201</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Warzecha1"><label>69</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Warzecha</surname><given-names>AK</given-names></name>
<name name-style="western"><surname>Egelhaaf</surname><given-names>M</given-names></name>
</person-group>             <year>1996</year>             <article-title>Intrinsic properties of biological motion detectors prevent the optomotor control system from getting unstable.</article-title>             <source>Philos Trans R Soc Lond, Ser B: Biol Sci</source>             <volume>351</volume>             <fpage>1579</fpage>             <lpage>1591</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Maddess1"><label>70</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Maddess</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>
</person-group>             <year>1985</year>             <article-title>Adaptation of the motion- sensitive neuron H1 is generated locally and governed by contrast frequency.</article-title>             <source>Proc R Soc Lond, Ser B: Biol Sci</source>             <volume>225</volume>             <fpage>251</fpage>             <lpage>275</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Harris3"><label>71</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Harris</surname><given-names>RA</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>
</person-group>             <year>2000</year>             <article-title>Contrast gain reduction in fly motion adaptation.</article-title>             <source>Neuron</source>             <volume>28</volume>             <fpage>595</fpage>             <lpage>606</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-OCarroll2"><label>72</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Shoemaker</surname><given-names>PA</given-names></name>
<name name-style="western"><surname>Brinkworth</surname><given-names>RSA</given-names></name>
</person-group>             <year>2007</year>             <article-title>Bioinspired optical rotation sensor.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Al-Sarawi</surname><given-names>SF</given-names></name>
</person-group>             <source>Smart Structures, Devices, and Systems III</source>             <publisher-loc>Adelaide, Australia.</publisher-loc> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">641416</size>           </element-citation></ref>
<ref id="pcbi.1000555-Borst2"><label>73</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Borst</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Egelhaaf</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Haag</surname><given-names>J</given-names></name>
</person-group>             <year>1995</year>             <article-title>Mechanisms of dendritic integration underlying gain control in fly motion-sensitive neurons.</article-title>             <source>J Comput Neurosci</source>             <volume>2</volume>             <fpage>5</fpage>             <lpage>18</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Srinivasan4"><label>74</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Srinivasan</surname><given-names>MV</given-names></name>
<name name-style="western"><surname>Dvorak</surname><given-names>DR</given-names></name>
</person-group>             <year>1979</year>             <article-title>The waterfall illusion in an insect visual system.</article-title>             <source>Vision Res</source>             <volume>19</volume>             <fpage>1435</fpage>             <lpage>1437</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Land3"><label>75</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Land</surname><given-names>MF</given-names></name>
</person-group>             <year>1997</year>             <article-title>Visual acuity in insects.</article-title>             <source>Annu Rev Entomol</source>             <volume>42</volume>             <fpage>147</fpage>             <lpage>177</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Laughlin3"><label>76</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>
<name name-style="western"><surname>Horridge</surname><given-names>GA</given-names></name>
</person-group>             <year>1971</year>             <article-title>Angular sensitivity of the retinula cells of dark-adapted worker bee.</article-title>             <source>J Comp Physiol A</source>             <volume>74</volume>             <fpage>329</fpage>             <lpage>335</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Williams1"><label>77</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Williams</surname><given-names>DS</given-names></name>
</person-group>             <year>1983</year>             <article-title>changes of photoreceptor performance associated with the daily turnover of photoreceptor membrane in locusts.</article-title>             <source>J Comp Physiol</source>             <volume>150</volume>             <fpage>509</fpage>             <lpage>519</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-vanHateren5"><label>78</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Srinivasan</surname><given-names>MV</given-names></name>
<name name-style="western"><surname>Wait</surname><given-names>PB</given-names></name>
</person-group>             <year>1990</year>             <article-title>Pattern recognition in bees: orientation discrimination.</article-title>             <source>J Comp Physiol A</source>             <volume>167</volume>             <fpage>649</fpage>             <lpage>654</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Snyder1"><label>79</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Snyder</surname><given-names>AW</given-names></name>
</person-group>             <year>1977</year>             <article-title>Acuity of compound eyes: Physical limitations and design.</article-title>             <source>J Comp Physiol A</source>             <volume>116</volume>             <fpage>161</fpage>             <lpage>182</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Snyder2"><label>80</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Snyder</surname><given-names>AW</given-names></name>
<name name-style="western"><surname>Stavenga</surname><given-names>DG</given-names></name>
<name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>
</person-group>             <year>1977</year>             <article-title>Spatial Information Capacity of Compound Eyes.</article-title>             <source>J Comp Physiol A</source>             <volume>116</volume>             <fpage>183</fpage>             <lpage>207</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Merigan1"><label>81</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Merigan</surname><given-names>WH</given-names></name>
<name name-style="western"><surname>Katz</surname><given-names>LM</given-names></name>
<name name-style="western"><surname>Maunsell</surname><given-names>JHR</given-names></name>
</person-group>             <year>1991</year>             <article-title>The effects of parvocellular lateral geniculate lesions on the acuity and contrast sensitivity of macaque monkeys.</article-title>             <source>J Neurosci</source>             <volume>11</volume>             <fpage>994</fpage>             <lpage>1001</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Borst3"><label>82</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Borst</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Egelhaaf</surname><given-names>M</given-names></name>
</person-group>             <year>1989</year>             <article-title>Principles of visual-motion detection.</article-title>             <source>Trends Neurosci</source>             <volume>12</volume>             <fpage>297</fpage>             <lpage>306</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Schilstra1"><label>83</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Schilstra</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Van Hateren</surname><given-names>JH</given-names></name>
</person-group>             <year>1999</year>             <article-title>Blowfly flight and optic flow I. Thorax kinematics and flight dynamics.</article-title>             <source>J Exp Biol</source>             <volume>202</volume>             <fpage>1481</fpage>             <lpage>1490</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-OCarroll3"><label>84</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Bidwell</surname><given-names>NJ</given-names></name>
<name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>
<name name-style="western"><surname>Warrant</surname><given-names>EJ</given-names></name>
</person-group>             <year>1996</year>             <article-title>Insect motion detectors matched to visual ecology.</article-title>             <source>Nature</source>             <volume>382</volume>             <fpage>63</fpage>             <lpage>66</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Harrison1"><label>85</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Harrison</surname><given-names>RR</given-names></name>
<name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>
</person-group>             <year>2000</year>             <article-title>Robust analog VSLI Reichardt motion sensor.</article-title>             <source>Analog integrated circuits and signal processing</source>             <volume>24</volume>             <fpage>213</fpage>             <lpage>239</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Rajesh1"><label>86</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rajesh</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Straw</surname><given-names>A</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Abbott</surname><given-names>D</given-names></name>
</person-group>             <year>2005</year>             <article-title>Effect of spatial sampling on pattern noise in insect-based motion detection.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Al-Sarawi</surname><given-names>SF</given-names></name>
</person-group>             <source>Proceedings SPIE.</source>             <publisher-loc>Australia.</publisher-loc>             <fpage>811</fpage>             <lpage>825</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Reichardt2"><label>87</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reichardt</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Egelhaaf</surname><given-names>M</given-names></name>
</person-group>             <year>1988</year>             <article-title>Properties of individual-movement detectors as derived from behavioral-experiments on the visual-system of the fly.</article-title>             <source>Biol Cybern</source>             <volume>58</volume>             <fpage>287</fpage>             <lpage>294</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Reichardt3"><label>88</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reichardt</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Guo</surname><given-names>AK</given-names></name>
</person-group>             <year>1986</year>             <article-title>Elementary pattern discrimination (behavioural experiments with the fly Musca domestica).</article-title>             <source>Biol Cybern</source>             <volume>53</volume>             <fpage>284</fpage>             <lpage>306</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Nordstrm1"><label>89</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nordström</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Barnett</surname><given-names>PD</given-names></name>
<name name-style="western"><surname>Moyer de Miguel</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Brinkworth</surname><given-names>RSA</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
</person-group>             <year>2008</year>             <article-title>Sexual dimorphism in the hoverfly motion vision pathway.</article-title>             <source>Curr Biol</source>             <volume>18</volume>             <fpage>661</fpage>             <lpage>667</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Huston1"><label>90</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Huston</surname><given-names>SJ</given-names></name>
<name name-style="western"><surname>Krapp</surname><given-names>HG</given-names></name>
</person-group>             <year>2008</year>             <article-title>Visuomotor Transformation in the Fly Gaze Stabilization System.</article-title>             <source>PLoS Biol</source>             <volume>6</volume>             <fpage>1468</fpage>             <lpage>1478</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Rajesh2"><label>91</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rajesh</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Rainsford</surname><given-names>TJ</given-names></name>
<name name-style="western"><surname>Brinkworth</surname><given-names>RSA</given-names></name>
<name name-style="western"><surname>Abbott</surname><given-names>D</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
</person-group>             <year>2007</year>             <source>Implementation of saturation for modeling pattern noise using naturalistic stimuli. Proceedings SPIE</source>             <publisher-loc>Adelaide, Australia.</publisher-loc> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">641424</size>           </element-citation></ref>
<ref id="pcbi.1000555-Ibbotson1"><label>92</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ibbotson</surname><given-names>MR</given-names></name>
</person-group>             <year>2001</year>             <article-title>Evidence for velocity-tuned motion-sensitive descending neurons in the honeybee.</article-title>             <source>Proc R Soc Lond, Ser B: Biol Sci</source>             <volume>268</volume>             <fpage>2195</fpage>             <lpage>2201</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Dror2"><label>93</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dror</surname><given-names>RO</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>
</person-group>             <year>2000</year>             <article-title>The role of natural image statistics in biological motion estimation.</article-title>             <source>Springer Lecture Notes in Computer Science</source>             <volume>181</volume>             <fpage>492</fpage>             <lpage>501</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Egelhaaf5"><label>94</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Egelhaaf</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Borst</surname><given-names>A</given-names></name>
</person-group>             <year>1992</year>             <article-title>Are there separate on and off channels in fly motion vision.</article-title>             <source>Visual Neurosci</source>             <volume>8</volume>             <fpage>151</fpage>             <lpage>164</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Riehle1"><label>95</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Riehle</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Franceschini</surname><given-names>N</given-names></name>
</person-group>             <year>1984</year>             <article-title>Motion detection in flies - parametric control over on-off pathways.</article-title>             <source>Exp Brain Res</source>             <volume>54</volume>             <fpage>390</fpage>             <lpage>394</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Wiederman1"><label>96</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wiederman</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Brinkworth</surname><given-names>RSA</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
</person-group>             <year>2009</year>             <article-title>Performance of a Bio-Inspired Model for the Robust Detection of Moving Targets in High Dynamic Range Natural Scenes.</article-title>             <source>JCTN</source>             <comment>in press: acceptance date 8-1-09</comment>          </element-citation></ref>
<ref id="pcbi.1000555-Wiederman2"><label>97</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wiederman</surname><given-names>SD</given-names></name>
<name name-style="western"><surname>Shoemaker</surname><given-names>PA</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
</person-group>             <year>2008</year>             <article-title>A model for the detection of moving targets in visual clutter inspired by insect physiology.</article-title>             <source>PLoS ONE</source>             <volume>3</volume>             <fpage>e2784</fpage>          </element-citation></ref>
<ref id="pcbi.1000555-Franceschini1"><label>98</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Franceschini</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Pichon</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Blanes</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Brady</surname><given-names>JM</given-names></name>
</person-group>             <year>1992</year>             <article-title>From Insect Vision to Robot Vision.</article-title>             <source>Philos Trans R Soc Lond, Ser B: Biol Sci</source>             <volume>337</volume>             <fpage>283</fpage>             <lpage>294</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Bayerl1"><label>99</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bayerl</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Neumann</surname><given-names>H</given-names></name>
</person-group>             <year>2007</year>             <article-title>A Fast Biologically Inspired Algorithm for Recurrent Motion Estimation.</article-title>             <source>TPAMI</source>             <volume>29</volume>             <fpage>246</fpage>             <lpage>260</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-NVIDIA1"><label>100</label><element-citation publication-type="journal" xlink:type="simple">             <collab xlink:type="simple">NVIDIA</collab>             <year>2008</year>             <article-title>What is CUDA</article-title>          </element-citation></ref>
<ref id="pcbi.1000555-Brinkworth2"><label>101</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Brinkworth</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Shoemaker</surname><given-names>P</given-names></name>
<name name-style="western"><surname>O'Carroll</surname><given-names>D</given-names></name>
</person-group>             <year>2009</year>             <article-title>Characterization of a Neuromorphic Motion Detection Chip Based On Insect Visual System.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Palaniswami</surname><given-names>MS</given-names></name>
</person-group>             <source>ISSNIP</source>             <publisher-loc>Melbourne, Australia.</publisher-loc>          </element-citation></ref>
<ref id="pcbi.1000555-OCarroll4"><label>102</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>O'Carroll</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Brinkworth</surname><given-names>RSA</given-names></name>
</person-group>             <year>2008</year>             <article-title>Biomimetic &amp; Bio-Inspired Motion Detectors Based on Insect Vision.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Viollett</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Ruffier</surname><given-names>F</given-names></name>
</person-group>             <publisher-loc>Nics, France.</publisher-loc>             <fpage>1</fpage>             <lpage>2</lpage>          </element-citation></ref>
<ref id="pcbi.1000555-Lucas1"><label>103</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lucas</surname><given-names>BD</given-names></name>
<name name-style="western"><surname>Kanade</surname><given-names>T</given-names></name>
</person-group>             <year>1981</year>             <article-title>An iterative image registration technique with an application to stereo vision.</article-title>             <fpage>674</fpage>             <lpage>679</lpage>             <comment>Proceedings 7th Joint Conference on Artificial Intelligence. Vancouver, Canada</comment>          </element-citation></ref>
</ref-list>

</back>
</article>
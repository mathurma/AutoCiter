<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-12-00684</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003182</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subject>Developmental neuroscience</subject><subject>Neural homeostasis</subject><subject>Sensory systems</subject></subj-group></subj-group><subj-group><subject>Systems biology</subject></subj-group><subj-group><subject>Theoretical biology</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>Sparse Coding Models Can Exhibit Decreasing Sparseness while Learning Sparse Codes for Natural Images</article-title>
<alt-title alt-title-type="running-head">Sparseness and V1 Development</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Zylberberg</surname><given-names>Joel</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>DeWeese</surname><given-names>Michael Robert</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Department of Physics, University of California, Berkeley, Berkeley, California, United States of America</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Redwood Center for Theoretical Neuroscience, University of California, Berkeley, Berkeley, California, United States of America</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>Helen Wills Neuroscience Institute, University of California, Berkeley, Berkeley, California, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Indiana University, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">deweese@berkeley.edu</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: JZ. Performed the experiments: JZ. Analyzed the data: JZ. Wrote the paper: JZ MRD.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>8</month><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>29</day><month>8</month><year>2013</year></pub-date>
<volume>9</volume>
<issue>8</issue>
<elocation-id>e1003182</elocation-id>
<history>
<date date-type="received"><day>30</day><month>4</month><year>2012</year></date>
<date date-type="accepted"><day>3</day><month>7</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Zylberberg, DeWeese</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>The sparse coding hypothesis has enjoyed much success in predicting response properties of simple cells in primary visual cortex (V1) based solely on the statistics of natural scenes. In typical sparse coding models, model neuron activities and receptive fields are optimized to accurately represent input stimuli using the least amount of neural activity. As these networks develop to represent a given class of stimulus, the receptive fields are refined so that they capture the most important stimulus features. Intuitively, this is expected to result in sparser network activity over time. Recent experiments, however, show that stimulus-evoked activity in ferret V1 becomes <italic>less</italic> sparse during development, presenting an apparent challenge to the sparse coding hypothesis. Here we demonstrate that some sparse coding models, such as those employing homeostatic mechanisms on neural firing rates, can exhibit decreasing sparseness during learning, while still achieving good agreement with mature V1 receptive field shapes and a reasonably sparse mature network state. We conclude that observed developmental trends do not rule out sparseness as a principle of neural coding <italic>per se</italic>: a mature network can perform sparse coding even if sparseness decreases somewhat during development. To make comparisons between model and physiological receptive fields, we introduce a new nonparametric method for comparing receptive field shapes using image registration techniques.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>The popular sparse coding theory posits that the receptive fields of visual cortical neurons maximize the efficiency of the neural representation of natural images. Models implementing this idea typically minimize a combination of the error in reconstructing natural images from neural activities, and the average level of activity in the model neurons. In simulations, these models are presented with natural images and the RFs then develop so as to increase representation efficiency. After a long developmental period, the model RFs typically agree well with those observed experimentally in visual cortex. Since the models seek to minimize (for a given level of reconstruction error) the neural activity levels, the average levels of neural activity might be expected to decrease as the models develop. In the developing mammalian cortex, visual RFs are also modified during development, so the sparse coding hypothesis might appear to suggest that activity levels should decrease during development. Recent experiments with young ferrets show the opposite trend: mature animals tend to have more active visual cortices. Herein, we demonstrate that, depending on the models' initial conditions, some sparse coding models can exhibit increasing activity levels while learning the same types of RFs that are observed in visual cortex: the developmental data do not preclude sparse coding.</p>
</abstract>
<funding-group><funding-statement>This work was supported by an international student research fellowship from the Howard Hughes Medical Institute (to JZ). MRD gratefully acknowledges support from the McKnight Foundation, the James S. McDonnell Foundation, the Hellman Family Faculty Fund, the Mary Elizabeth Rennie Endowment for Epilepsy Research, and the National Science Foundation through Grant No. IIS-1219199. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="10"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>A central question in systems neuroscience is whether optimization principles can account for the architecture and physiology of the nervous system. One candidate principle is sparse coding (SC), which posits that neurons encode input stimuli <italic>efficiently</italic>: stimuli should be encoded with maximum fidelity while simultaneously using the smallest possible amount of neural activity <xref ref-type="bibr" rid="pcbi.1003182-Rehn1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Simoncelli1">[2]</xref>. Much evidence suggests that primary visual cortex (V1) forms sparse representations of visual stimuli <xref ref-type="bibr" rid="pcbi.1003182-Rehn1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Olshausen1">[3]</xref>–<xref ref-type="bibr" rid="pcbi.1003182-Baddeley1">[7]</xref>. For example, when trained with natural scenes, SC models have been shown to learn the same types of receptive fields (RFs) as are exhibited by simple cells in macaque primary visual cortex (V1) <xref ref-type="bibr" rid="pcbi.1003182-Rehn1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Olshausen2">[8]</xref>.</p>
<p>Throughout this paper, we make reference to the notion of “sparseness”. Intuitively, sparseness is related to there being either a small subset of neurons active at any time (population sparseness), or to each neuron being active only a small fraction of the time (lifetime sparseness) <xref ref-type="bibr" rid="pcbi.1003182-Willmore1">[9]</xref>. In the <xref ref-type="sec" rid="s4">Methods</xref> section, we define the precise notions of sparseness that we use in this paper.</p>
<p>In further support of the SC hypothesis, measurements of the firing rates of V1 neurons in response to videos of natural scenes show that those rates are low, and that the firing rate distributions are sharply peaked near zero <xref ref-type="bibr" rid="pcbi.1003182-Baddeley1">[7]</xref>. Similarly, cell-attached recordings in auditory cortex show highly sparse levels of activity <xref ref-type="bibr" rid="pcbi.1003182-Hromdka1">[10]</xref>. Conversely, other experimenters <xref ref-type="bibr" rid="pcbi.1003182-Tolhurst1">[11]</xref> have observed non-sparse (dense) neuronal activity in visual cortex, although the boundary between “sparse” and “dense” activity is open to interpretation and thus it is unclear how sparse the activity must be in order to confirm the SC hypothesis <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref>. Importantly, however, it has been observed that stimulating larger portions of the visual field leads to sparser, and less correlated, V1 neuronal responses <xref ref-type="bibr" rid="pcbi.1003182-Vinje1">[4]</xref>–<xref ref-type="bibr" rid="pcbi.1003182-Haider1">[6]</xref>. It has been suggested that this effect arises because of inhibitory recurrent connections between excitatory cells, mediated by the appropriate interneurons <xref ref-type="bibr" rid="pcbi.1003182-Haider1">[6]</xref>.</p>
<p>In simulating the development of a sparse coding model, one typically <xref ref-type="bibr" rid="pcbi.1003182-Rehn1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Olshausen1">[3]</xref> initializes the receptive fields with random white noise — so as to not bias the shapes of the RFs learned by the network — and then presents the network with natural images, in response to which the RFs get modified. As the model (<italic>e.g.</italic>, <xref ref-type="bibr" rid="pcbi.1003182-Rehn1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Olshausen1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Bell1">[13]</xref>) modifies itself in response to the stimuli, neurons gradually learn features that allow for a better encoding of the stimuli, so the sparseness is expected to increase over time. This point was emphasized in recent work <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref>. Physiology experiments, however, show something different in the developing visual cortex. Recently, Berkes and colleagues measured multi-unit V1 activity in awake young ferrets viewing natural movies, and found that, as the animals matured, their stimulus-driven V1 activity became <italic>less</italic> sparse <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Berkes2">[15]</xref> (<xref ref-type="fig" rid="pcbi-1003182-g001">Fig. 1</xref>).</p>
<fig id="pcbi-1003182-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003182.g001</object-id><label>Figure 1</label><caption>
<title>V1 developmental data appear to challenge the canonical sparse coding models.</title>
<p>Multi-unit activity in primary visual cortex (V1) of awake young ferrets watching natural movies shows decreasing sparseness over time. The sparseness metrics shown in this figure are defined in the results section of this paper, and the data are courtesy of Pietro Berkes <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Berkes2">[15]</xref>. The plot has a logarithmic horizontal axis. For contrast, one expects that, in sparse coding models, the sparseness should increase over time. This point was emphasized in recent work <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref>. In this paper, we show that, in sparse coding models sparseness can actually decrease during the learning process, so the data shown here cannot rule out sparse coding as a theory of sensory coding.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003182.g001" position="float" xlink:type="simple"/></fig>
<p>The above discussion hints at a major source of confusion in this area of research. In particular, sparseness is discussed as both a relative measure (<italic>i.e.</italic>: “Is network A sparser than network B?”), and as an absolute descriptor (<italic>i.e.</italic>: “Is network A sparse?”). In this paper, we will first study relative measures of sparseness, and observe how these measures change as a result of development in our recently published SAILnet model <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref>; do they increase, or decrease over time? The absolute sparseness values of the final (mature) networks – which vary between 0 (not sparse), and 1 (maximally sparse) – will be used to infer whether the final network is sparse at all. This mirrors the way that Berkes and colleagues discussed sparseness in the developing ferret.</p>
<p>The ferret sparseness-over-time data appears to contradict the SC hypothesis. At the same time, that hypothesis has otherwise been quite successful in explaining some key features of peripheral sensory systems. It is therefore natural to ask whether sparse coding models necessarily <italic>must</italic> exhibit increasing sparseness in order to learn V1-like receptive fields and perform sparse coding in the mature state. In this work, we focus primarily on a recently published variant of sparse coding called SAILnet <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref> in which homeostasis regulates the neuronal firing rates while synaptically local plasticity rules modify the network structure, leading to V1-like receptive field formation. We will demonstrate that, depending on the initial conditions of the simulation, SAILnet can exhibit either increasing, or decreasing sparseness, while learning RFs that are in quantitatively good agreement with those observed in V1, and having a reasonably sparse final state. The choices of parameter values in the model determine the equilibrium state to which the network ultimately converges. If the initial conditions are <italic>even sparser</italic> than this equilibrium point, sparseness will decrease during development, and yet the final state can still be sparse in an absolute sense.</p>
<p>We will also see that, for appropriately chosen initial conditions, the same can be true of the canonical SparseNet model of Olshausen and Field <xref ref-type="bibr" rid="pcbi.1003182-Olshausen1">[3]</xref>. Thus, the apparent contradiction between the ferret developmental sparseness data, and SC models <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref> does not necessarily mean that SC is implausible as a theory for sensory computation. Later in this paper, we discuss plausible alternatives for sensory coding other than SC models.</p>
</sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Overview of the Sparse and Independent Local network (SAILnet) model</title>
<p>Since this paper focuses primarily on our SAILnet model (<xref ref-type="fig" rid="pcbi-1003182-g002">Fig. 2</xref>), we will now provide a brief overview that model, which is described in detail elsewhere <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref> and summarized in the <xref ref-type="sec" rid="s4">Methods</xref> section. The model consists of a network of leaky integrate-and-fire (LIF) neurons, which receive feed-forward input from image pixels, in a rough approximation of the thalamic input to V1. The neurons inhibit each other via recurrent inhibitory connections, the strengths of which are learned so as to reduce correlations amongst the units, consistent with recent physiology experiments <xref ref-type="bibr" rid="pcbi.1003182-Vinje1">[4]</xref>–<xref ref-type="bibr" rid="pcbi.1003182-Haider1">[6]</xref>. We note that one can modify SAILnet so that interneurons mediate the inhibition between excitatory cells so as to satisfy Dale's law (E-I Net; <xref ref-type="bibr" rid="pcbi.1003182-King1">[16]</xref>).</p>
<fig id="pcbi-1003182-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003182.g002</object-id><label>Figure 2</label><caption>
<title>SAILnet architecture.</title>
<p>In our model, described in detail elsewhere <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref>, leaky integrate-and-fire neurons receive inputs from pixels in whitened natural images, in a rough approximation of the thalamic input to V1. Inhibitory recurrent connections between neurons, shown in red, act to decorrelate the neuronal activities. The neurons have variable firing thresholds, which are varied by the neurons so as to maintain a desired long-term-average firing rate.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003182.g002" position="float" xlink:type="simple"/></fig>
<p>The neurons' firing thresholds are modified over time so as to maintain a target lifetime-average firing rate. For our LIF neurons, this is similar to synaptic rescaling, which has been proposed as a mechanism to stabilize correlation-based learning schemes <xref ref-type="bibr" rid="pcbi.1003182-Abbott1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Marder1">[18]</xref>, and has been observed in physiology experiments <xref ref-type="bibr" rid="pcbi.1003182-Abbott1">[17]</xref>. Alternatively, the variable firing threshold can be thought of in terms of a modifiable intrinsic neuronal excitability, another well-known homeostatic mechanism <xref ref-type="bibr" rid="pcbi.1003182-Turrigiano1">[19]</xref>.</p>
<p>Finally, the feed-forward weights are learned by the network, so that the neuronal activities form an optimal linear generative model of the input stimulus, subject to the constraints imposed by limited firing rates and minimal correlations. The derivation of our learning rules from this objective function is presented in <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref>. All information needed for the model's plasticity rules is available locally at the synapse being modified — updates depend only on the pre- and post-synaptic activity levels.</p>
</sec><sec id="s2b">
<title>SAILnet activity can become less sparse during receptive field formation, much like ferret V1 development</title>
<p>To study the change in sparseness over time, we ran SAILnet simulations, starting with randomized feed-forward weights, recurrent connection strengths, and firing thresholds that were initialized with Gaussian-distributed white noise. At different times during the development process, we recorded the simulated neuronal activity in response to randomly selected batches of natural images. Following a recent experimental study <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref>, we computed from these network activities three sparseness measures, which are discussed in more detail in the <xref ref-type="sec" rid="s4">Methods</xref> section. Each of these measures varies between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e001" xlink:type="simple"/></inline-formula> (not sparse at all) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e002" xlink:type="simple"/></inline-formula> (as sparse as possible).</p>
<p>The first of these, the “activity sparseness,” <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e003" xlink:type="simple"/></inline-formula>, measures the fraction of units that are <italic>inactive</italic> in response to a given stimulus, averaged over different stimuli. If this quantity is near 1, then only a small subset of units responds to each stimulus. If every unit is active in response to every stimulus, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e004" xlink:type="simple"/></inline-formula>.</p>
<p>The “population sparseness” <xref ref-type="bibr" rid="pcbi.1003182-Vinje2">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Treves1">[20]</xref>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e005" xlink:type="simple"/></inline-formula>, measures the degree to which the population response to a given stimulus is restricted to a small subset of the population, averaged over all stimuli. If only a small number of units have large activities in response to a given stimulus, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e006" xlink:type="simple"/></inline-formula> will be near <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e007" xlink:type="simple"/></inline-formula>, even if many units have small but non-zero activities. By contrast, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e008" xlink:type="simple"/></inline-formula> would be small in that case, because there are not many completely inactive units. If the units all respond equally to every stimulus, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e009" xlink:type="simple"/></inline-formula>. For the same level of representation error, the formation of efficient representations demands relatively high values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e010" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e011" xlink:type="simple"/></inline-formula>, such that only a small fraction of the available neural resources are utilized in representing each image.</p>
<p>Finally, the “lifetime sparseness” <xref ref-type="bibr" rid="pcbi.1003182-Vinje2">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Treves1">[20]</xref> measures how much the responses of individual units tend to be concentrated over a small subset of stimuli, averaged over units. If the units respond very selectively, so that they have strong responses to a small number of stimuli, and weak responses to most stimuli, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e012" xlink:type="simple"/></inline-formula> will be near 1. Conversely, if each unit responds equally to all stimuli, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e013" xlink:type="simple"/></inline-formula>.</p>
<p>Intuitively, all of these measures are somewhat related (although, see <xref ref-type="bibr" rid="pcbi.1003182-Willmore1">[9]</xref> for notable exceptions). At the same time, when it comes to the efficiency of the neural representation, the more relevant quantities are the activity sparseness and the population sparseness, which both have to do with the fraction of neural resources used to represent each image <xref ref-type="bibr" rid="pcbi.1003182-Willmore1">[9]</xref>. Furthermore, the values of “lifetime” sparseness one obtains will vary with the time scale over which one performs the measurement. As such, it is a somewhat more ambiguous quantity than are the activity and population sparseness measures. Despite these issues, we include results for the lifetime sparseness for our model in keeping with the experimental study <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref> that motivated this theoretical project.</p>
<p>In order to further facilitate meaningful comparison with the experiment of Berkes and colleagues, we mimicked a multi-unit activity measurement by randomly grouping together sets of 8 SAILnet neurons, whose activities were then summed to form a multi-unit response. These “multi-unit” activities were used for computing our sparseness measures. This procedure yielded results (<xref ref-type="fig" rid="pcbi-1003182-g003">Fig. 3</xref>) that were qualitatively similar to the single-unit sparseness measures (not shown), but with larger changes in sparseness values. A direct quantitative comparison between our model multi-unit sparseness data and the ferret data is difficult because it is not clear how best to estimate the relevant number of neurons to group together, or even whether all groupings should have the same number of neurons. Furthermore, in the ferret data, the neurons grouped together are physically nearby, which means that, due to retinotopic and orientation maps in V1, they will have similar receptive fields. The SAILnet model has no such notion of spatial organization and our random grouping of cells misses that aspect of the ferret experiment.</p>
<fig id="pcbi-1003182-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003182.g003</object-id><label>Figure 3</label><caption>
<title>SAILnet multi-unit activity can become less sparse during receptive field formation.</title>
<p>A SAILnet simulation was performed in which the RFs, firing thresholds, and recurrent connection strengths were initialized with random numbers (see <xref ref-type="sec" rid="s4">Methods</xref> section for details). (<bold>A</bold>) These initial RFs are shown for 196 randomly selected model neurons. Each box on the grid shows the RF of one neuron, with white corresponding to positive pixel values, and black corresponding to negative ones. (<bold>B</bold>) After training with natural images, these same SAILnet neurons have oriented, localized RFs. (<bold>C</bold>) All three of our “multi-unit” sparseness measures decrease during the training period, as has been observed in the visual cortex of maturing ferrets <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref>. We made similar observations when we made measurements of single-neuron sparseness values (data not shown).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003182.g003" position="float" xlink:type="simple"/></fig>
<p>In <xref ref-type="fig" rid="pcbi-1003182-g003">Fig. 3</xref>, we show a random subset of 196 (out of the 250 total) receptive fields of SAILnet neurons both before and after the network is trained with natural scenes. We also show the evolution of our multi-unit sparseness measures during that training process. Contrary to the idea that sparse coding models must show strictly increasing sparseness during learning <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref>, our SAILnet model can display <italic>decreasing</italic> sparseness by all three measures while it is learning localized and oriented receptive fields. We will later show that the popular SparseNet model of Olshausen and Field <xref ref-type="bibr" rid="pcbi.1003182-Olshausen1">[3]</xref> can also exhibit decreasing sparseness over time.</p>
<p>The time course of the sparseness measures depends on the learning rates (parameter modification step sizes), with smaller learning rates leading to slower changes in sparseness measures, as expected (data not shown). The depth of the observed “undershoot” also depends on the initial conditions and the learning rates. The specific activity sparseness values (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e014" xlink:type="simple"/></inline-formula>) depend on the chosen threshold: higher thresholds lead to higher sparseness values.</p>
<p>The receptive fields learned by the model, while displaying decreasing sparseness, are in good quantitative agreement with a measured corpus of 250 macaque monkey V1 simple cell receptive fields, as we will demonstrate in the section on comparisons of receptive field shapes.</p>
<p>The model discussed in this section and shown in <xref ref-type="fig" rid="pcbi-1003182-g003">Fig. 3</xref> has relatively high firing thresholds and a relatively large amount of lateral inhibition in the initial state. Those properties lead to highly sparse firing. As the network learns, the homeostatic firing rate regulation reduces the thresholds and then inhibitory connections are modified by their own plasticity rules (see <xref ref-type="sec" rid="s4">Methods</xref> section for details). These have the effect of reducing the model's sparseness over time. For contrast, in the next section we will consider a model that is identical to the one presented here, but with the following modifications to the initial conditions: the firing thresholds are initialized at smaller values and there is initially less lateral inhibition.</p>
</sec><sec id="s2c">
<title>For less sparse initial conditions, SAILnet multi-unit activity becomes sparser during receptive field formation</title>
<p>We find that SAILnet does not <italic>require</italic> sparseness to decrease over time; rather, it is <italic>compatible</italic> with decreasing sparseness. To demonstrate this point, we repeated our SAILnet simulations and sparseness measurements with different initial conditions (see <xref ref-type="sec" rid="s4">Methods</xref> section for details). As discussed in the previous section, these initial conditions have lower firing thresholds and less lateral inhibition than in the model shown in <xref ref-type="fig" rid="pcbi-1003182-g003">Fig. 3</xref>.</p>
<p>In this case, the relatively low firing thresholds and relatively small amount of lateral inhibition lead to the initial network state being less sparse than the final (equilibrium) state, so sparseness increases over time (<xref ref-type="fig" rid="pcbi-1003182-g004">Fig. 4</xref>).</p>
<fig id="pcbi-1003182-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003182.g004</object-id><label>Figure 4</label><caption>
<title>For less sparse initial conditions, SAILnet multi-unit sparseness measures increase during training.</title>
<p>A SAILnet simulation was performed in which the RFs were initially randomized, and the recurrent inhibitory connection strengths and firing thresholds were initialized with random numbers that were smaller than for the simulation described in <xref ref-type="fig" rid="pcbi-1003182-g003">Fig. 3</xref> (see <xref ref-type="sec" rid="s4">Methods</xref> section for details). (<bold>A</bold>) The initial RFs are shown for 196 randomly selected model neurons. As in <xref ref-type="fig" rid="pcbi-1003182-g003">Fig. 3</xref>, each box on the grid depicts the RF of one neuron, with lighter tones corresponding to positive pixel values, and darker tones corresponding to negative values. (<bold>B</bold>) After training with natural images, these same SAILnet neurons have oriented, localized RFs. (<bold>C</bold>) All three of our multi-unit sparseness measures increase during the training period. Aside from the initial conditions, the network used to generate these data was identical to the one from <xref ref-type="fig" rid="pcbi-1003182-g003">Fig. 3</xref>: both networks have the same learning rates, the same number of neurons, the same target mean firing rate, and are trained on the same database of whitened natural images.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003182.g004" position="float" xlink:type="simple"/></fig>
<p>Similar to <xref ref-type="fig" rid="pcbi-1003182-g003">Fig. 3</xref>, in <xref ref-type="fig" rid="pcbi-1003182-g004">Fig. 4</xref> we show a random subset of 196 neuronal receptive fields both before and after the training procedure and, as we demonstrate below, those RF shapes are in quantitative agreement with those measured in macaque V1.</p>
<p>We emphasize that, compared to the model discussed in <xref ref-type="fig" rid="pcbi-1003182-g003">Fig. 3</xref>, which exhibited increasing sparseness, the model discussed here (and in <xref ref-type="fig" rid="pcbi-1003182-g004">Fig. 4</xref>) differs only in the initial conditions; all other parameters were the same for the two models. Consequently, after a long training period, over which the effects of the initial conditions gradually disappear, these two models have very similar final sparseness levels and receptive fields. For the models studied in this paper (<xref ref-type="fig" rid="pcbi-1003182-g003">Figs. 3</xref> and <xref ref-type="fig" rid="pcbi-1003182-g004">4</xref>), the final multi-unit sparseness values (after the final training batch) are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e015" xlink:type="simple"/></inline-formula> for the model in which sparseness increases over time (<xref ref-type="fig" rid="pcbi-1003182-g004">Fig. 4</xref>), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e016" xlink:type="simple"/></inline-formula> for the model in which sparseness decreases over time.</p>
</sec><sec id="s2d">
<title>Theoretical models besides SAILnet can also display both increasing and decreasing sparseness over time</title>
<p>While our SAILnet model <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref> and a recent extension that obeys Dale's law <xref ref-type="bibr" rid="pcbi.1003182-King1">[16]</xref> are more biophysically realistic than previous sparse coding models, the increasing or decreasing sparseness over time we describe above (<xref ref-type="fig" rid="pcbi-1003182-g003">Figs. 3</xref> and <xref ref-type="fig" rid="pcbi-1003182-g004">4</xref>) is not unique to SAILnet.</p>
<p>To explore this issue more fully, we return to the canonical SparseNet model of Olshausen and Field <xref ref-type="bibr" rid="pcbi.1003182-Olshausen1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Olshausen3">[21]</xref>. We first note that, as in SAILnet, the “equilibrium” sparseness level in SparseNet is determined by a free parameter in the model (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e017" xlink:type="simple"/></inline-formula> in <xref ref-type="bibr" rid="pcbi.1003182-Olshausen1">[3]</xref>). Furthermore, in the SparseNet model, there is a homeostatic mechanism that adjusts the magnitudes of the feed-forward weights so as to keep the units' activities near some pre-defined set point. Similar to SAILnet, this process is not instantaneous.</p>
<p>In what follows, we use the SparseNet code of Olshausen and Field <xref ref-type="bibr" rid="pcbi.1003182-Olshausen1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Olshausen3">[21]</xref> “out of the box,” without modifying any parameters except the initialization of the basis functions — these are analogous to the feed-forward weights, or receptive fields, of SAILnet units.</p>
<p>We begin by initializing these basis functions with Gaussian white noise of variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e018" xlink:type="simple"/></inline-formula>, so that the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e019" xlink:type="simple"/></inline-formula> bases have <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e020" xlink:type="simple"/></inline-formula> norms of approximately <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e021" xlink:type="simple"/></inline-formula>. In this case, sparseness increases over time (<xref ref-type="fig" rid="pcbi-1003182-g005">Fig. 5a</xref>) and the basis amplitudes decrease: the mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e022" xlink:type="simple"/></inline-formula> norm of these bases is approximately 0.5 once the model converges, after the training period.</p>
<fig id="pcbi-1003182-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003182.g005</object-id><label>Figure 5</label><caption>
<title>SparseNet can also display either increasing or decreasing sparseness during learning.</title>
<p>To check that our conclusions apply to other models besides SAILnet, we performed simulations with the publicly available SparseNet code of Olshausen and Field <xref ref-type="bibr" rid="pcbi.1003182-Olshausen1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Olshausen3">[21]</xref>. (<bold>A</bold>) When the basis functions are initialized with large-amplitude white noise (see text for details), the sparseness increases over time contrary to the ferret data shown in <xref ref-type="fig" rid="pcbi-1003182-g001">Fig. 1</xref>. (<bold>B</bold>) However, when the bases are initialized with small-amplitude white noise, the sparseness decreases over time.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003182.g005" position="float" xlink:type="simple"/></fig>
<p>These changes can be understood by recalling that, during inference — where the activities of the units are determined in response to a given image — the activities are chosen to minimize the following cost function: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e023" xlink:type="simple"/></inline-formula>. The error, as in SAILnet, is the sum over pixels of the squared error of the difference between the image and a linear generative model formed by multiplying each unit's activity by its basis function. Thus, if the basis has a small magnitude, then large activations are needed in order to form a decent linear generative model. However, these large activations are punished by the “activities” term in the cost function. As a result, some of the units that add only a modest improvement to the representation are turned off, or nearly so. If the basis has a large magnitude, then only small activations are needed to form the linear generative model, and these small activations are less strongly penalized than are large activations. As a result, the activation can be more distributed over the network when the filters have large magnitudes. To summarize: large basis function magnitudes lead to less sparse network activity and the basis magnitudes are modified with a non-zero timescale.</p>
<p>Putting all of this together, if we initialize the bases with Gaussian white noise of variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e024" xlink:type="simple"/></inline-formula>, so that they initially have <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e025" xlink:type="simple"/></inline-formula> norms in the neighborhood of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e026" xlink:type="simple"/></inline-formula>, then the basis norms increase over time during training. After this model converges, the mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e027" xlink:type="simple"/></inline-formula> norm of the bases is again around 0.5. Consequently, the sparseness decreases over time (<xref ref-type="fig" rid="pcbi-1003182-g005">Fig. 5b</xref>).</p>
<p>As in SAILnet, one way to understand these trends is to recall that the model parameters dictate the final “equilibrium” state of the model, but the initial conditions can be chosen independently of the final state. As such, initial conditions can be chosen to be either more or less sparse than the equilibrium condition, leading to sparseness either decreasing or increasing over time.</p>
</sec><sec id="s2e">
<title>Comparing SAILnet receptive fields to those observed in macaque V1</title>
<p>In many theoretical studies (<italic>e.g.</italic>, <xref ref-type="bibr" rid="pcbi.1003182-Rehn1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Carlson1">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Puerta1">[23]</xref>), one learns a sparse coding dictionary for natural stimuli, then compares the shapes of the resultant basis functions to the shapes of the physiologically measured receptive fields.</p>
<p>Typically, this comparison is either done by eye (as in <xref ref-type="bibr" rid="pcbi.1003182-Carlson1">[22]</xref>), or by fitting both the model RFs and the experimentally measured ones to some parameterized shape functions, and then comparing (again, typically by eye) the distributions of the resultant shape parameters for both the model and the data <xref ref-type="bibr" rid="pcbi.1003182-Rehn1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Puerta1">[23]</xref>. More rigorously, one can quantitatively compare the distributions of these shape parameters (Rehn, Warland, and Sommer, CoSyNe 2008 abstract) between the model and the experimental data, although that method fails if one has too few RFs with which to perform the comparison.</p>
<p>The by-eye comparisons are not very quantitative, even if they first involve fitting parameterized shape models, and any fitting of parameterized shape models is vulnerable to failures of the shape function: any RFs whose shapes are not well described by the parameterized function will yield nonsense best fit parameter values.</p>
<p>To get around these difficulties, we introduce a novel method for directly comparing the shapes of theoretical and experimental receptive fields, using image registration. In this technique, we assume that receptive fields may differ by a translation, rotation, and/or global size rescaling, yet still have the same shape. For example, consider an equilateral triangle within a bounding box. A shifted, rotated, and resized version of that shape is still an equilateral triangle.</p>
<p>We apply this intuition to the comparison between our model receptive fields, and a set of 250 macaque V1 receptive fields courtesy of D. Ringach. We do this by taking each experimentally measured V1 receptive field and then for each model RF we find the combination of translation, rotation, and overall rescaling that gives the best match between the experimental and transformed-model RF. We quantify the match by the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e028" xlink:type="simple"/></inline-formula> value (square of the correlation coefficient) between the pixel values of the model and the experimental RF. Choosing the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e029" xlink:type="simple"/></inline-formula>-maximizing RF is similar to seeking the model RF that can account for the largest fraction of the variance of the experimental RF, but allows for an overall multiplicative constant in front of the model RF. Specifically, the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e030" xlink:type="simple"/></inline-formula> value tells us the fraction of the experimental RF variance that could be explained by a linear function of the best model RF (<italic>i.e.</italic>, possibly including an additive constant to all pixel values and an overall amplitude change).</p>
<p>Once we have done this for all model RFs, we take the one whose best transform yields the largest <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e031" xlink:type="simple"/></inline-formula> and take that as the best-fit model RF for the given experimental RF. In this way, we answer the question: Once we account for possible translations, rotations, and size rescalings, how much of the variance in the experimental RF pixel values can be accounted for by the library of model RFs? <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e032" xlink:type="simple"/></inline-formula> values near <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e033" xlink:type="simple"/></inline-formula> indicate that the experimental RF is reproduced perfectly by the theoretical model, while values near <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e034" xlink:type="simple"/></inline-formula> indicate that it is not. We then repeat this procedure for all of the RFs in the experimental dataset, yielding one <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e035" xlink:type="simple"/></inline-formula> value per experimental RF. Below, we discuss the averages over these <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e036" xlink:type="simple"/></inline-formula> values.</p>
<p>Looking at the macaque RFs in <xref ref-type="fig" rid="pcbi-1003182-g006">Fig. 6A</xref>, it is clear that the region of support of the RF is often smaller than the size of the image window over which the RF is measured, and any noise outside of the region of support (or within it, for that matter) will be unaccounted for by the image registration process, thus lowering the apparent goodness-of-fit. To attempt to quantify this level of noise and to give a solid benchmark with which to assess our experiment-vs.-model comparison, we repeat the image registration fitting described above, but instead of using model RFs as comparators, we compare each experimental RF against the corpus of <italic>other experimental RFs</italic>. In other words, we do a leave-one-out analysis where we try to fit each macaque RF and, for that fit, we take the 249 other macaque RFs and pretend that they are “model” RFs. We then find the largest <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e037" xlink:type="simple"/></inline-formula> value possible for the best transformation of each of the 249 comparison RFs and use that number to quantify how well we could realistically expect to fit the macaque RF. We term this maximal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e038" xlink:type="simple"/></inline-formula> value for the macaque-to-macaque comparison the fraction of variance in the data that is “explainable” by our image-registration technique (although not necessarily captured by the dictionary of shapes learned by our sparse coding model).</p>
<fig id="pcbi-1003182-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003182.g006</object-id><label>Figure 6</label><caption>
<title>Registration-based receptive field comparisons show a quantitative match between SAILnet and macaque V1 RF shapes.</title>
<p>(<bold>A</bold>) For illustration purposes, we show 100 of the 250 macaque V1 receptive fields (courtesy of D. Ringach) against which we compared our SAILnet model neuronal RFs. To estimate the fraction of the variance in the pixel values of these RFs that could realistically be explained, we performed registration-based RF fitting for each macaque RF, using <italic>all other macaque RFs</italic> as comparators. The best-fit matches to the RFs in panel <bold>A</bold> are shown in panel <bold>B</bold>, and the distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e039" xlink:type="simple"/></inline-formula> values obtained with the macaque-vs-macaque fitting shows that, on average, approximately <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e040" xlink:type="simple"/></inline-formula> of the variance in the macaque RF pixel values can be explained by other macaque RFs (<bold>E</bold>). For the SAILnet model that experienced increasing sparseness during training, the best-fit RF matches are shown in panel <bold>C</bold>, and the distribution of corresponding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e041" xlink:type="simple"/></inline-formula> values shows that, on average, approximately <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e042" xlink:type="simple"/></inline-formula> of the variance in the macaque RFs can be explained by these SAILnet model neuronal RFs (<bold>E</bold>). Similarly, for the SAILnet model that experienced decreasing sparseness during training (<bold>D</bold>), approximately <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e043" xlink:type="simple"/></inline-formula> of the variance in the macaque RFs can be explained by model neuronal RFs. For both of the SAILnet networks shown (<bold>C,D</bold>), there are a few macaque RFs for which the image registration fails completely. We include these in our goodness-of-fit statistics; they correspond to the cells with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e044" xlink:type="simple"/></inline-formula> values near zero. There is no clear trend in the shapes of macaque RFs that cause this failure. For either increasing, or decreasing sparseness during training, the model neuronal RFs can, on average, account for approximately <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e045" xlink:type="simple"/></inline-formula> of the explainable variance in the measured macaque RFs. The error bars on the bars in panel (<bold>E</bold>) correspond to the standard deviation of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e046" xlink:type="simple"/></inline-formula> values over the sample of experimental RFs. There is a statistically significant, although small in magnitude, difference between the quality with which the macaque RFs fit each other (<bold>E</bold>), and the quality with which either model fits the data (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e047" xlink:type="simple"/></inline-formula> for either model, using a paired t test; n = 250). There is no statistically significant difference between the quality with which the two models fit the macaque RFs (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e048" xlink:type="simple"/></inline-formula>, paired t test; n = 250).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003182.g006" position="float" xlink:type="simple"/></fig>
<p>In using this technique to estimate the noise level, we essentially assume that the RF shapes are repeated in the experimental data (which one can see in <xref ref-type="fig" rid="pcbi-1003182-g006">Fig. 6</xref>), and use that intuition to ask, “How much of the data variance is due to noise rather than the RF properties themselves?”</p>
<p>In <xref ref-type="fig" rid="pcbi-1003182-g006">Fig. 6</xref>, we show the experimental RFs, the best-transformed (translation, rotation, and overall size rescaling) model RFs learned with either increasing or decreasing sparseness values, and the quantitative comparisons between the RF shapes (average <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e049" xlink:type="simple"/></inline-formula> values for how well the macaque RFs can be explained by the model RFs).</p>
<p>The macaque-to-macaque comparisons (<xref ref-type="fig" rid="pcbi-1003182-g006">Fig. 6E</xref>) show that, on average, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e050" xlink:type="simple"/></inline-formula> of the variance in the RF pixel values can be explained using other RFs from the macaque V1 dataset. We term this the “explainable” variance and it sets an upper bound on how well we could expect our model RFs to match the macaque RFs. For comparison, the model RFs account for, on average, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e051" xlink:type="simple"/></inline-formula> of the variance in the RF pixel values, regardless of whether the learning of those RFs was accompanied with either increasing or decreasing sparseness. The difference between the average explained variance for the two different models (those of <xref ref-type="fig" rid="pcbi-1003182-g003">Figs. 3</xref> and <xref ref-type="fig" rid="pcbi-1003182-g004">4</xref>) is not statistically significant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e052" xlink:type="simple"/></inline-formula>, paired t test; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e053" xlink:type="simple"/></inline-formula>), while the differences between each of the model's mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e054" xlink:type="simple"/></inline-formula> values and that of the macaque-vs-macaque comparison are statistically significant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e055" xlink:type="simple"/></inline-formula>, paired t test; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e056" xlink:type="simple"/></inline-formula>).</p>
<p>Because the model RFs can explain an average of roughly <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e057" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e058" xlink:type="simple"/></inline-formula>) of the explainable variance in the RF data, regardless of whether the model experienced increasing or decreasing sparseness during training, we conclude that the model RFs are in quantitatively good agreement with the experimental RFs, independent of whether the learning of shapes was accompanied with increasing or decreasing sparseness.</p>
<p>Generally, larger networks have a greater diversity of receptive field shapes (this can be easily seen by comparing the RFs shown in this paper to those in <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref>), and will thus tend to perform better in our image-registration comparisons. The networks studied in this paper were relatively small, in order to allow us to study the evolution of networks with many different initial conditions. Thus, we expect that even better model-to-experiment RF matches are possible if one were to study larger networks. On the other hand, the macaque V1 database to which we compared our model contains only 250 receptive fields, so a “fair” comparison to a larger simulated network would require more experimental data, or the selection of a random subset of the simulated RFs.</p>
<p>Our quantitative non-parametric RF comparison method could be used to compare many different theories to experimental data, and thus to ascertain which ones provide the best fit. That comparison is beyond the scope of this paper.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<sec id="s3a">
<title>Main contributions of this work</title>
<p>We have demonstrated that a computational model (SAILnet <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref>) can learn V1-like receptive fields while simultaneously exhibiting either a <italic>decrease</italic>, or an <italic>increase</italic>, in the sparseness of neuronal activities. In both cases, the sparseness of the final (mature) network state is high enough to be reasonably considered “sparse.” We further showed that these same trends in sparseness over time can be achieved with the less biophysically realistic SparseNet model, despite the fact that it does not incorporate the same form of homeostasis as SAILnet.</p>
<p>In order to quantify the similarity between experimentally measured V1 receptive fields and the receptive fields learned by our SAILnet model, we have further introduced a novel non-parametric RF comparison tool based on image registration techniques.</p>
<p>Since sparseness can decrease during development, with the mature network state still performing sparse coding, the type of active sparseness maximization disproven by recent experiments <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref> is not necessary to produce observed V1 receptive field shapes, nor is it required to learn a sparse representation of natural scenes. The trends in sparseness over time can be so strongly affected by the initial conditions of the network that those trends are not very informative about the objective function being optimized. Thus, developmental data, such as those shown in <xref ref-type="fig" rid="pcbi-1003182-g001">Fig. 1</xref>, cannot strictly rule out the general notion that V1 simple cell receptive fields develop so as to form sparse, efficient, representations of natural scenes.</p>
</sec><sec id="s3b">
<title>Is it fair to compare the sparseness trends experienced by developing animals with those exhibited by sparse coding models?</title>
<p>One possibility that requires consideration is that the sparseness data of Berkes and colleagues <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref> should not be compared at all with theoretical models when assessing the hypothesis that V1 performs sparse coding. Recall that the sparse coding models criticized by Berkes and colleagues showed increasing sparseness <italic>during receptive field formation</italic>, and that their claim was that, since the ferret data instead showed decreasing sparseness <italic>during development</italic>, the sparse coding models do not provide a good description of V1.</p>
<p>In order for this comparison to be “fair,” one must ensure that receptive fields undergo significant change during the developmental period over which Berkes and colleagues measured sparseness. Indeed, other experimenters have observed that the orientation and direction selectivity of the neurons in ferret V1 increase <xref ref-type="bibr" rid="pcbi.1003182-White1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Li1">[25]</xref> during the same developmental period over which Berkes and colleagues observed decreasing sparseness levels, and that the mature state of the visual cortex for both ferrets and cats is sensitive to visual experiences in this period <xref ref-type="bibr" rid="pcbi.1003182-Li1">[25]</xref>–<xref ref-type="bibr" rid="pcbi.1003182-Cynader1">[28]</xref>. Combining these observations, we note that sparseness in ferret V1 seems to decrease while the visual cortical maps and receptive fields are being refined by experience, in apparent contradiction to the SC hypothesis. The largest contribution of this paper is to resolve that apparent contradiction.</p>
<p>Of course, there could always be other reasons — beyond the scope of this paper — why the developmental data fail to be relevant to the sparse coding hypothesis. We leave that question for future work.</p>
<p>For the sake of completeness, we note that Rochefort and colleagues have observed that <italic>spontaneous</italic> slow-wave activity in the anesthetized mouse visual cortex becomes sparser immediately after eye-opening <xref ref-type="bibr" rid="pcbi.1003182-Rochefort1">[29]</xref>. At first glance, this might appear to contradict the ferret data of Berkes and colleagues <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref>. However, since the ferret data is stimulus-evoked activity and the mouse data is spontaneous activity, it is not clear that a comparison between these datasets is meaningful. Because the spontaneous activity is not very easily related to the sparse coding hypothesis, which does not have much to say about activity in the absence of sensory input, we have focused on the ferret data (stimulus-evoked activity) in this paper.</p>
</sec><sec id="s3c">
<title>Prior work on homeostasis and learning</title>
<p>We are not the first to propose that homeostasis might underlay experience-dependent modification of the nervous system. Indeed, Marder and others have strongly and persuasively argued that neural systems might have a desired operating point such that when perturbed they use homeostatic mechanisms to return to that desired functional state <xref ref-type="bibr" rid="pcbi.1003182-Marder1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003182-Turrigiano1">[19]</xref>. Moreover, Miller and others have shown that homeostatic activity regulation can facilitate learning in model-neuronal systems <xref ref-type="bibr" rid="pcbi.1003182-Perrinet1">[30]</xref>–<xref ref-type="bibr" rid="pcbi.1003182-Sullivan1">[32]</xref>.</p>
<p>Finally, recent work by Perrinet <xref ref-type="bibr" rid="pcbi.1003182-Perrinet1">[30]</xref> also used homeostatic activity regulation in learning sparse codes, so that model may also show either increasing or decreasing sparseness over time, for appropriately chosen initial conditions.</p>
</sec><sec id="s3d">
<title>Concluding remarks</title>
<p>We have demonstrated that the mature network state can perform sparse coding regardless of whether learning is accompanied by an increase or decrease in sparseness. At the same time, sparse coding is not the only principle that has been proposed in order to understand V1 function. Of particular interest in this regard is a recent study by Berkes and colleagues <xref ref-type="bibr" rid="pcbi.1003182-Berkes2">[15]</xref>. In that work, the authors showed that both stimulus-evoked and spontaneous (in the absence of any stimulus) activity in V1 became more similar as the animals aged, suggesting that V1 might be learning a Bayesian prior on the statistics of the environment. They further observed that part of this change in activity distributions came about due to increases in the correlations between V1 neurons with age. This observation is contrary to the redundancy reduction arguments often used to support efficient coding models, such as traditional sparse coding models and SAILnet. Thus, there is some evidence that sparse coding may not be the best theory of V1 function, and that others, such as that advanced in <xref ref-type="bibr" rid="pcbi.1003182-Berkes2">[15]</xref>, may be better in some regards. Moreover, it is not clear how the sparse coding hypothesis could account for many of the properties of V1 complex cells despite its success for simple cells, and differences in the level of activity between awake and anesthetized V1 may pose additional challenges for sparse coding models. However, sparse coding models have successfully accounted for the shapes of V1 simple cell receptive fields, while the Bayesian-type optimality models have yet to do so. There is thus much room for further advances in our understanding of sensory coding, and measurements that can rule out theoretical models are key to that advancement. Our results show that the decrease in sparseness during development, which has been argued to rule out sparse coding in V1 <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref>, is not, on its own, sufficient to make that claim.</p>
</sec></sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<sec id="s4a">
<title>Sparseness measures used in this work</title>
<p>There are many different ways to measure sparseness. In this work, we follow the experimental study of Berkes and colleagues <xref ref-type="bibr" rid="pcbi.1003182-Berkes1">[14]</xref> and use the following three measures.</p>
<p>First, the “activity sparseness” (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e059" xlink:type="simple"/></inline-formula>), which is the fraction of units inactive in response to any given stimulus:<disp-formula id="pcbi.1003182.e060"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003182.e060" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e061" xlink:type="simple"/></inline-formula> is the number of units whose activities rose above some threshold number of spikes in response to the stimulus, and N is the total number of units for which data were recorded. We set the threshold to 4 spikes for the multi-unit sparseness data shown herein. We performed this measurement by averaging over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e062" xlink:type="simple"/></inline-formula> different input stimuli. The activity sparseness <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e063" xlink:type="simple"/></inline-formula> is very similar to the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e064" xlink:type="simple"/></inline-formula> norm – which is actually a pseudo-norm – of the unit activities; low <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e065" xlink:type="simple"/></inline-formula> norms correspond to high <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e066" xlink:type="simple"/></inline-formula> values.</p>
<p>In addition, we recorded two other sparseness measures, originally due to Treves <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e067" xlink:type="simple"/></inline-formula> Rolls <xref ref-type="bibr" rid="pcbi.1003182-Treves1">[20]</xref> (TR), and subsequently modified by Vinje <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e068" xlink:type="simple"/></inline-formula> Gallant <xref ref-type="bibr" rid="pcbi.1003182-Vinje2">[5]</xref>. First, let us consider what we will call the “TR population sparseness” measure <xref ref-type="bibr" rid="pcbi.1003182-Berkes2">[15]</xref>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e069" xlink:type="simple"/></inline-formula>,<disp-formula id="pcbi.1003182.e070"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003182.e070" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e071" xlink:type="simple"/></inline-formula> is the activity of unit <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e072" xlink:type="simple"/></inline-formula>. Note that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e073" xlink:type="simple"/></inline-formula> is assessed in response to a single image, although for our purposes, we will average this measure over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e074" xlink:type="simple"/></inline-formula> different image stimuli, to infer the average TR population sparseness. Similarly, we will define the “TR lifetime” sparseness of a given unit, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e075" xlink:type="simple"/></inline-formula>, the same way (<xref ref-type="disp-formula" rid="pcbi.1003182.e070">Eq. 2</xref>), but with the replacement that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e076" xlink:type="simple"/></inline-formula> represents the unit's activity in response to a given image <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e077" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e078" xlink:type="simple"/></inline-formula> will be the number of different image stimuli (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e079" xlink:type="simple"/></inline-formula>) for which activities are recorded. Similar to the TR population sparseness <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e080" xlink:type="simple"/></inline-formula>, we will average these values over the entire population for our measurement.</p>
</sec><sec id="s4b">
<title>SAILnet model details</title>
<p>The SAILnet model <xref ref-type="bibr" rid="pcbi.1003182-Zylberberg1">[12]</xref> consists of a network of leaky integrate-and-fire neurons that receive feed-forward input from image pixels (a rough approximation of the thalamic input to V1), and inhibit each other through recurrent connections. The feed-forward weight from pixel <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e081" xlink:type="simple"/></inline-formula> (with value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e082" xlink:type="simple"/></inline-formula>) to neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e083" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e084" xlink:type="simple"/></inline-formula>) and the inhibitory recurrent connections between neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e085" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e086" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e087" xlink:type="simple"/></inline-formula>) are learned by the network. In response to a given image, neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e088" xlink:type="simple"/></inline-formula> emits some number <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e089" xlink:type="simple"/></inline-formula> of spikes, which can be zero. Homeostasis, enforced via modifiable firing thresholds <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e090" xlink:type="simple"/></inline-formula> forces the neurons to all have the same lifetime-average firing rate of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e091" xlink:type="simple"/></inline-formula> spikes per image. After the image presentation, the network parameters are updated via<disp-formula id="pcbi.1003182.e092"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003182.e092" xlink:type="simple"/><label>(3)</label></disp-formula>where the (positive) constants <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e093" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e094" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e095" xlink:type="simple"/></inline-formula> define the rates at which the parameters are learned. In order for them to remain inhibitory, after each update, the recurrent connections are rectified so that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e096" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4c">
<title>SAILnet simulation details</title>
<p>For all simulations shown herein, the feed-forward weights <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e097" xlink:type="simple"/></inline-formula> were initialized with Gaussian white noise, and the learning rates were set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e098" xlink:type="simple"/></inline-formula>. We used <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e099" xlink:type="simple"/></inline-formula> neurons which viewed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e100" xlink:type="simple"/></inline-formula> pixel image patches, hence the neuronal representation was approximately critically sampled (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e101" xlink:type="simple"/></inline-formula> overcomplete) with respect to the number of pixels. The target firing rate was set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e102" xlink:type="simple"/></inline-formula> spikes per neuron per image in all cases. In all cases, the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e103" xlink:type="simple"/></inline-formula> norm of the feed-forwards weights to each neuron was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e104" xlink:type="simple"/></inline-formula> in the initial condition.</p>
<p>For the data shown in <xref ref-type="fig" rid="pcbi-1003182-g004">Fig. 4</xref>, the initial recurrent connection strengths <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e105" xlink:type="simple"/></inline-formula> were drawn randomly from a normal (Gaussian) distribution with zero mean and unit variance, the firing thresholds <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e106" xlink:type="simple"/></inline-formula> were initialized to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e107" xlink:type="simple"/></inline-formula>, and the model neuronal activity became more sparse during training.</p>
<p>For the results shown in <xref ref-type="fig" rid="pcbi-1003182-g003">Fig. 3</xref>, the initial recurrent connection strengths were drawn randomly from a lognormal distribution (the negative of their logarithms were drawn from a normal distribution with zero mean and unit variance), the firing thresholds were drawn uniformly over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e108" xlink:type="simple"/></inline-formula>, and the model neuronal activity became less sparse during training.</p>
<p>We note that in all cases, the specific shape of the sparseness vs. time plot depends on the choice of initial conditions. However, for a large class of initial conditions, the sparseness will decrease over time, and for another large class of initial conditions, it will increase (data not shown). Thus, our qualitative conclusion is not particularly sensitive to the exact numerical values described above.</p>
</sec><sec id="s4d">
<title>SparseNet simulation details</title>
<p>The SparseNet results were generated using code publicly distributed by Bruno Olshausen (<ext-link ext-link-type="uri" xlink:href="http://redwood.berkeley.edu/bruno/sparsenet/" xlink:type="simple">http://redwood.berkeley.edu/bruno/sparsenet/</ext-link>). The code was used “out of the box”, without modifying the parameter values. For the data shown in <xref ref-type="fig" rid="pcbi-1003182-g005">Fig. 5a</xref>, then bases (matrix A in the code) was initialized with Gaussian white noise of variance 1. For the data shown in <xref ref-type="fig" rid="pcbi-1003182-g005">Fig. 5b</xref>, matrix A was initialized with Gaussian white noise of variance 0.01.</p>
<p>In both cases, 256 units were used, and the model was trained on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e109" xlink:type="simple"/></inline-formula> pixel image patches: the model is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e110" xlink:type="simple"/></inline-formula> overcomplete with respect to the number of input pixels.</p>
</sec><sec id="s4e">
<title>Registration-based RF comparisons</title>
<p>To perform the quantitative comparison of receptive field shapes, we used the image registration tool in MatLab <xref ref-type="bibr" rid="pcbi.1003182-MATLAB1">[33]</xref>. This package allowed us to quickly and easily compute the optimum combination of translation, rotation, and stretch – called a “similarity” transform in MatLab – to match each physiology RF with an RF from the appropriate comparison class (either model data or other experimentally measured RFs). For the optimizer, we used the “monomodal” option.</p>
<p>Our data consists of 250 Macaque V1 receptive fields, measured using reverse-correlation methods in the lab of Dario Ringach <xref ref-type="bibr" rid="pcbi.1003182-Ringach1">[34]</xref>. These data are either <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e111" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e112" xlink:type="simple"/></inline-formula>, or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e113" xlink:type="simple"/></inline-formula> pixel images, showing the extent to which the neuron responds to each pixel. In order to standardize these data for the comparison, and because many of the RFs occupy only a tiny fraction of the image, we pre-process those RFs that are larger than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e114" xlink:type="simple"/></inline-formula> pixels, as follows. First, we find the peak absolute pixel value in the image – nominally, this is somewhere in the region of support of the “real” RF –, and we cut out a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e115" xlink:type="simple"/></inline-formula> pixel region surrounding that peak. We then perform our image registration fitting on these standard-sized RFs.</p>
<p>For each macaque RF, we performed an exhaustive search over all model RFs, wherein we found the best similarity transform to match each model RF to the macaque RF, then took the best-matching model RF (with the appropriate best similarity transform), as the fit. The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e116" xlink:type="simple"/></inline-formula> value between this best-fit transformed-model RF and the data RF was used to quantify the goodness of fit.</p>
<p>To generate a benchmark to assess how good a “good” <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e117" xlink:type="simple"/></inline-formula> value is for this problem, we repeated our fitting process, but instead of fitting the data to SAILnet model RFs, we fit each macaque RF with the corpus of <italic>other</italic> macaque RFs. In so doing, we could estimate the fraction of data variance that could be explained in a best-case scenario.</p>
<p>The ratio between these numbers – the data-vs.-model <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e118" xlink:type="simple"/></inline-formula> value and the data-vs.-data <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003182.e119" xlink:type="simple"/></inline-formula> value – gives us an estimate of the fraction of explainable variance that is captured by the model.</p>
</sec></sec></body>
<back>
<ack>
<p>The authors thank Pietro Berkes for sharing the ferret V1 developmental data points and Dario Ringach for providing the macaque V1 receptive field data. The authors are grateful for helpful comments from Fritz Sommer.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003182-Rehn1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rehn</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sommer</surname><given-names>FT</given-names></name> (<year>2007</year>) <article-title>A network that uses few active neurones to code visual input predicts the diverse shapes of cortical receptive fields</article-title>. <source>J Comput Neurosci</source> <volume>22</volume>: <fpage>135</fpage>–<lpage>146</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Simoncelli1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simoncelli</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Olshausen</surname><given-names>B</given-names></name> (<year>2001</year>) <article-title>Natural image statistics and neural representation</article-title>. <source>Annu Rev Neurosci</source> <volume>24</volume>: <fpage>1193</fpage>–<lpage>1216</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Olshausen1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>1996</year>) <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source> <volume>381</volume>: <fpage>607</fpage>–<lpage>609</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Vinje1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vinje</surname><given-names>WE</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2002</year>) <article-title>Natural stimulation of the nonclassical receptive field increases information transmission efficiency in V1</article-title>. <source>J Neurosci</source> <volume>22</volume>: <fpage>2904</fpage>–<lpage>2915</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Vinje2"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vinje</surname><given-names>WE</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2000</year>) <article-title>Sparse coding and decorrelation in primary visual cortex during natural vision</article-title>. <source>Science</source> <volume>287</volume>: <fpage>1273</fpage>–<lpage>1276</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Haider1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haider</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Krause</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Duque</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Yu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Touryan</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Synaptic and network mechanisms of sparse and reliable visual cortical activity during nonclassical receptive field stimulation</article-title>. <source>Neuron</source> <volume>65</volume>: <fpage>107</fpage>–<lpage>121</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Baddeley1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baddeley</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name>, <name name-style="western"><surname>Booth</surname><given-names>MCA</given-names></name>, <name name-style="western"><surname>Sengpiel</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Freeman</surname><given-names>T</given-names></name>, <etal>et al</etal>. (<year>1997</year>) <article-title>Responses of neurons in primary and inferior temporal visual cortices</article-title>. <source>Proc R Soc Lon B</source> <volume>264</volume>: <fpage>1775</fpage>–<lpage>1783</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Olshausen2"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Cadieu</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>Warland</surname><given-names>DK</given-names></name> (<year>2009</year>) <article-title>Learning real and complex overcomplete representations from the statistics of natural images</article-title>. <source>Proc SPIE</source> <volume>7446</volume>: <fpage>74460S-1</fpage>–<lpage>74460S-11</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Willmore1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Willmore</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Tolhurst</surname><given-names>D</given-names></name> (<year>2001</year>) <article-title>Characterizing the sparseness of neural codes</article-title>. <source>Network: Comput Neural Syst</source> <volume>12</volume>: <fpage>255</fpage>–<lpage>270</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Hromdka1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hromádka</surname><given-names>T</given-names></name>, <name name-style="western"><surname>DeWeese</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Zador</surname><given-names>AM</given-names></name> (<year>2008</year>) <article-title>Sparse representation of sounds in the unanesthetized auditory cortex</article-title>. <source>PLoS Biol</source> <volume>6</volume>: <fpage>124</fpage>–<lpage>137</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Tolhurst1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Smyth</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Thompson</surname><given-names>ID</given-names></name> (<year>2009</year>) <article-title>The sparseness of neuronal responses in ferret primary visual cortex</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>2355</fpage>–<lpage>2370</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Zylberberg1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zylberberg</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Murphy</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>DeWeese</surname><given-names>MR</given-names></name> (<year>2011</year>) <article-title>A sparse coding model with synaptically local plasticity and spiking neurons can account for the diverse shapes of V1 simple cell receptive fields</article-title>. <source>PLoS Comp Biol</source> <volume>7</volume>: <fpage>e1002250-1</fpage>–<lpage>e1002250-12</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Bell1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>1997</year>) <article-title>The “independent components” of natural scenes are edge filters</article-title>. <source>Vision Res</source> <volume>37</volume>: <fpage>3327</fpage>–<lpage>3328</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Berkes1"><label>14</label>
<mixed-citation publication-type="other" xlink:type="simple">Berkes P, White BL, Fiser J (2009) No evidence for active sparsification in the visual cortex. In: Bengio Y, Schuurmans D, Lafferty JD, Williams CKI, Culotta A, editors. Advances in Neural Information Processing Systems 22, San Mateo: Morgan Kaufmann. pp. 108–116.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Berkes2"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Orbán</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Lengyel</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Fiser</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment</article-title>. <source>Science</source> <volume>331</volume>: <fpage>83</fpage>–<lpage>87</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-King1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>King</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Zylberberg</surname><given-names>J</given-names></name>, <name name-style="western"><surname>DeWeese</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Inhibitory interneurons decorrelate excitatory cells to drive sparse code formation in a spiking model of v1</article-title>. <source>J Neurosci</source> <volume>33</volume>: <fpage>5475</fpage>–<lpage>5485</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Abbott1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abbott</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Nelson</surname><given-names>S</given-names></name> (<year>2000</year>) <article-title>Synaptic plasticity: taming the beast</article-title>. <source>Nat Neurosci</source> <volume>3</volume>: <fpage>1178</fpage>–<lpage>1183</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Marder1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marder</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Goaillard</surname><given-names>J</given-names></name> (<year>2006</year>) <article-title>Variability, compensation and homeostasis in neuron and network function</article-title>. <source>Nat Rev Neurosci</source> <volume>7</volume>: <fpage>563</fpage>–<lpage>574</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Turrigiano1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Turrigiano</surname><given-names>G</given-names></name> (<year>2011</year>) <article-title>Too many cooks? intrinsic and synaptic homeostatic mechanisms in cortical circuit refinement</article-title>. <source>Annu Rev Neurosci</source> <volume>34</volume>: <fpage>89</fpage>–<lpage>103</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Treves1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name> (<year>1991</year>) <article-title>What determines the capacity of autoassociative memories in the brain?</article-title> <source>Network: Comput Neural Syst</source> <volume>2</volume>: <fpage>371</fpage>–<lpage>397</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Olshausen3"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>1997</year>) <article-title>Sparse coding with an overcomplete basis set: a strategy employed by V1?</article-title> <source>Vision Res</source> <volume>37</volume>: <fpage>3311</fpage>–<lpage>3325</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Carlson1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carlson</surname><given-names>NL</given-names></name>, <name name-style="western"><surname>Ming</surname><given-names>VL</given-names></name>, <name name-style="western"><surname>DeWeese</surname><given-names>MR</given-names></name> (<year>2012</year>) <article-title>Sparse codes for speech predict spectrotemporal receptive fields in the inferior colliculus</article-title>. <source>PLoS Comput Biol</source> <volume>8</volume>: <fpage>e1002594</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Puerta1"><label>23</label>
<mixed-citation publication-type="other" xlink:type="simple">Puerta G, Bornschein J, Lücke J (2010) The maximal causes of natural scenes are edge filters. In: Lafferty J, Williams CKI, Shawe-Taylor J, Zemel R, Culotta A, editors. Advances in Neural Information Processing 23, San Mateo: Morgan Kaufmann. pp. 1939–1947.</mixed-citation>
</ref>
<ref id="pcbi.1003182-White1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>White</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Fitzpatrick</surname><given-names>D</given-names></name> (<year>2007</year>) <article-title>Vision and cortical map development</article-title>. <source>Neuron</source> <volume>56</volume>: <fpage>327</fpage>–<lpage>338</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Li1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Fitzpatrick</surname><given-names>D</given-names></name>, <name name-style="western"><surname>White</surname><given-names>L</given-names></name> (<year>2006</year>) <article-title>The development of direction selectivity in ferret visual cortex depends on early visual experience</article-title>. <source>Nat Neurosci</source> <volume>9</volume>: <fpage>676</fpage>–<lpage>681</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Imbert1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Imbert</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Buisseret</surname><given-names>P</given-names></name> (<year>1975</year>) <article-title>Receptive field characteristics and plastic properties of visual cortical cells in kittens reared with or without visual experience</article-title>. <source>Exp Brain Res</source> <volume>22</volume>: <fpage>25</fpage>–<lpage>36</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Fagiolini1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fagiolini</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Pizzorusso</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Berardi</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Domenici</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Maffei</surname><given-names>L</given-names></name> (<year>1994</year>) <article-title>Functional postnatal development of the rat primary visual cortex and the role of visual experience: Dark rearing and monocular deprivation</article-title>. <source>Vision Res</source> <volume>34</volume>: <fpage>709</fpage>–<lpage>720</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Cynader1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cynader</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Berman</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Hein</surname><given-names>A</given-names></name> (<year>1973</year>) <article-title>Cats reared in stroboscopic illumination: effects on receptive fields in visual cortex</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>70</volume>: <fpage>1353</fpage>–<lpage>1354</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Rochefort1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rochefort</surname><given-names>NL</given-names></name>, <name name-style="western"><surname>Garaschuk</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Milos</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Narushima</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Marandi</surname><given-names>N</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Sparsification of neuronal activity in the visual cortex at eye-opening</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>106</volume>: <fpage>15049</fpage>–<lpage>15054</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Perrinet1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perrinet</surname><given-names>L</given-names></name> (<year>2010</year>) <article-title>Role of homeostasis in learning sparse representations</article-title>. <source>Neural Comput</source> <volume>22</volume>: <fpage>1812</fpage>–<lpage>1836</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Miller1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Mackay</surname><given-names>D</given-names></name> (<year>1994</year>) <article-title>The role of constraints in hebbian learning</article-title>. <source>Neural Comput</source> <volume>6</volume>: <fpage>100</fpage>–<lpage>126</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Sullivan1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sullivan</surname><given-names>T</given-names></name>, <name name-style="western"><surname>de Sa</surname><given-names>V</given-names></name> (<year>2006</year>) <article-title>Homeostatic synaptic scaling in self-organizing maps</article-title>. <source>Neural Netw</source> <volume>19</volume>: <fpage>734</fpage>–<lpage>743</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003182-MATLAB1"><label>33</label>
<mixed-citation publication-type="other" xlink:type="simple">MATLAB (2012) version R2012a. Natick, Massachusetts: The MathWorks Inc.</mixed-citation>
</ref>
<ref id="pcbi.1003182-Ringach1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ringach</surname><given-names>D</given-names></name> (<year>2002</year>) <article-title>Spatial structure and asymmetry of simple-cell receptive fields in macaque primary visual cortex</article-title>. <source>J Neurophysiol</source> <volume>88</volume>: <fpage>455</fpage>–<lpage>463</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
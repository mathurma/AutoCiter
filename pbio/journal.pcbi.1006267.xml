<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006267</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-00936</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject><subj-group><subject>Agent-based modeling</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Systems science</subject><subj-group><subject>Agent-based modeling</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Systems science</subject><subj-group><subject>Agent-based modeling</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Thermodynamics</subject><subj-group><subject>Free energy</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Locus coeruleus</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Locus coeruleus</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Cerebral cortex</subject><subj-group><subject>Frontal lobe</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Cerebral cortex</subject><subj-group><subject>Frontal lobe</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Locus Coeruleus tracking of prediction errors optimises cognitive flexibility: An Active Inference model</article-title>
<alt-title alt-title-type="running-head">An active inference model of Locus Coeruleus function</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8585-3763</contrib-id>
<name name-style="western">
<surname>Sales</surname>
<given-names>Anna C.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7984-8909</contrib-id>
<name name-style="western">
<surname>Friston</surname>
<given-names>Karl J.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5396-3108</contrib-id>
<name name-style="western">
<surname>Jones</surname>
<given-names>Matthew W.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0345-0456</contrib-id>
<name name-style="western">
<surname>Pickering</surname>
<given-names>Anthony E.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Moran</surname>
<given-names>Rosalyn J.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>School of Physiology, Pharmacology and Neuroscience, University of Bristol, Bristol, United Kingdom</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Wellcome Trust Centre for Neuroimaging, UCL, London, United Kingdom</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Anaesthesia, Pain and Critical Care Sciences, Translational Health Sciences, Bristol Medical School, University of Bristol, Bristol, United Kingdom</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Department of Neuroimaging, Institute of Psychiatry, Psychology &amp; Neuroscience, King's College London, United Kingdom</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Gershman</surname>
<given-names>Samuel J.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Harvard University, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">anna.sales@bristol.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>4</day>
<month>1</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<month>1</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>1</issue>
<elocation-id>e1006267</elocation-id>
<history>
<date date-type="received">
<day>4</day>
<month>6</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>24</day>
<month>10</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Sales et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006267"/>
<abstract>
<p>The locus coeruleus (LC) in the pons is the major source of noradrenaline (NA) in the brain. Two modes of LC firing have been associated with distinct cognitive states: changes in tonic rates of firing are correlated with global levels of arousal and behavioural flexibility, whilst phasic LC responses are evoked by salient stimuli. Here, we unify these two modes of firing by modelling the response of the LC as a correlate of a prediction error when inferring states for action planning under Active Inference (AI). We simulate a classic Go/No-go reward learning task and a three-arm ‘explore/exploit’ task and show that, if LC activity is considered to reflect the magnitude of high level ‘state-action’ prediction errors, then both tonic and phasic modes of firing are emergent features of belief updating. We also demonstrate that when contingencies change, AI agents can update their internal models more quickly by feeding back this state-action prediction error–reflected in LC firing and noradrenaline release–to optimise learning rate, enabling large adjustments over short timescales. We propose that such prediction errors are mediated by cortico-LC connections, whilst ascending input from LC to cortex modulates belief updating in anterior cingulate cortex (ACC). In short, we characterise the LC/ NA system within a general theory of brain function. In doing so, we show that contrasting, behaviour-dependent firing patterns are an emergent property of the LC that translates state-action prediction errors into an optimal balance between plasticity and stability.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>The brain uses sensory information to build internal models and make predictions about the world. When errors of prediction occur, models must be updated to ensure desired outcomes are still achieved. Neuromodulator chemicals provide a possible pathway for triggering such changes in brain state. One such neuromodulator, noradrenaline, originates predominantly from a cluster of neurons in the brainstem—the locus coeruleus (LC)—and plays a key role in behaviour, for instance, in determining the balance between exploiting or exploring the environment. Here we use Active Inference (AI), a mathematical model of perception and action, to formally describe LC function. We propose that LC activity is triggered by errors in prediction and that the subsequent release of noradrenaline alters the rate of learning about the environment. Biologically, this describes an LC-cortex feedback loop promoting behavioural flexibility in times of uncertainty. We model LC output as a simulated animal performs two tasks known to elicit archetypal responses. We find that experimentally observed ‘phasic’ and ‘tonic’ patterns of LC activity emerge naturally, and that modulation of learning rates improves task performance. This provides a simple, unified computational account of noradrenergic computational function within a general model of behaviour.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100010269</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>108899/Z/15/Z</award-id>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>088373/Z/09/A</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0345-0456</contrib-id>
<name name-style="western">
<surname>Pickering</surname>
<given-names>Anthony E.</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>088130/Z/09/Z</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7984-8909</contrib-id>
<name name-style="western">
<surname>Friston</surname>
<given-names>Karl J.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>ACS is supported by the Wellcome Trust PhD programme in Neural Dynamics: from synapses to systems in health and disease at the University of Bristol (ref. 108899/Z/15/Z). KJF is funded by a Wellcome Trust Principal Research Fellowship (ref: 088130/Z/09/Z). AEP is funded by a Wellcome Trust Senior Clinical Fellowship (ref. 088373/Z/09/A). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="0"/>
<page-count count="24"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-01-16</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All data was generated using MATLAB code which is freely available via the public GitHub repository <ext-link ext-link-type="uri" xlink:href="https://github.com/AnnaCSales/ActiveInference" xlink:type="simple">https://github.com/AnnaCSales/ActiveInference</ext-link>. This code is a modified version of general Active Inference implementations which are also freely available at the public repository: <ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/software/spm12/" xlink:type="simple">https://www.fil.ion.ucl.ac.uk/spm/software/spm12/</ext-link></meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The locus coeruleus (LC) is the major source of noradrenaline (NA) in the brain, projecting to most territories from the frontal cortex to the distal spinal cord. Changes in LC firing have been associated with behavioural changes, most notably the switch from ‘exploiting’ to ‘exploring’ the environment, and the facilitation of appropriate responses to salient stimuli [<xref ref-type="bibr" rid="pcbi.1006267.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref002">2</xref>].</p>
<p>Tonic LC activity is correlated with global levels of arousal and behavioural flexibility, where firing rates increase with rising levels of alertness [<xref ref-type="bibr" rid="pcbi.1006267.ref001">1</xref>]. At the extreme, high rates of tonic firing have been causally related to behavioural variability and stochastic decision making [<xref ref-type="bibr" rid="pcbi.1006267.ref003">3</xref>]. This ‘tonic mode’ has previously been modelled as a response to factors such as declining utility in a task [<xref ref-type="bibr" rid="pcbi.1006267.ref004">4</xref>] or ‘unexpected uncertainties’ [<xref ref-type="bibr" rid="pcbi.1006267.ref005">5</xref>], triggering behavioural variability and a switch from ‘exploiting’ a known resource to ‘exploring’ for a new resource.</p>
<p>The LC also fires in short, high frequency bursts. Such phasic activity occurs in animals in response to behaviourally relevant salient stimuli [<xref ref-type="bibr" rid="pcbi.1006267.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1006267.ref008">8</xref>]. This phasic response has been described as a ‘network interrupt’ or ‘reset’, which facilitates a shift to shorter-term behavioural planning [<xref ref-type="bibr" rid="pcbi.1006267.ref009">9</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref010">10</xref>]. Activating stimuli are those which have an established behavioural significance; for instance, signalling the location of food or the presence of a predator. They may also include stimuli that are highly unexpected [<xref ref-type="bibr" rid="pcbi.1006267.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref011">11</xref>]–although the phasic response will habituate rapidly to novelty alone in the absence of behavioural salience [<xref ref-type="bibr" rid="pcbi.1006267.ref012">12</xref>].</p>
<p>A series of studies has provided evidence of further nuance to phasic LC responses. Similar to the well-known dopaminergic response, as an animal learns a cue-reward relationship, phasic LC responses will transfer from temporal alignment with an unconditioned stimuli (US) to a predictive, conditioned stimuli (CS+)[<xref ref-type="bibr" rid="pcbi.1006267.ref013">13</xref>]. Additionally, rarer stimuli, or those predicting a large reward, elicit a stronger LC response [<xref ref-type="bibr" rid="pcbi.1006267.ref006">6</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref008">8</xref>]. In contrast if predictive cues are delivered consecutively, the size of the response appears to decrease [<xref ref-type="bibr" rid="pcbi.1006267.ref006">6</xref>]. The rich array of factors affecting the nature of the phasic response suggests that LC activation is linked to both facilitation of behavioural response and to internal representations of uncertainties and probabilities.</p>
<p>Despite the increasing body of knowledge about the impact of the LC on behaviour, a comprehensive computational account remains elusive–in contrast to the more developed account of other neuromodulators; most notably dopamine, which has been interpreted as a signal of reward prediction error. In particular, existing modelling approaches have generally tackled the tonic and phasic firing responses of the LC as separate modes with distinct functional significance, triggered by different circumstances [<xref ref-type="bibr" rid="pcbi.1006267.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref005">5</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref009">9</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref010">10</xref>].</p>
<p>Here, we propose that a critical computational role of the LC-NA system is to react to high level ‘state-action’ prediction errors upstream of the LC and cause appropriate flexibility in belief updating via feedback projections to cortex. In brief, our account of noradrenergic activity is based on the fact that the degree of belief updating reflects volatility in the environment and can therefore inform the optimal rate of evidence accumulation and plasticity. The ‘state-action’ prediction error considered in this work is the ‘Bayesian surprise’ or change in probabilistic beliefs before and after observing some outcome. We develop these ideas as neural correlates of discrete updates and action planning under the formalism of Active Inference (AI). AI offers an effective mathematical framework for such modelling, unifying inferences on states and action planning and providing a detailed description of beliefs at each step of a behavioural task [<xref ref-type="bibr" rid="pcbi.1006267.ref014">14</xref>–<xref ref-type="bibr" rid="pcbi.1006267.ref017">17</xref>]. In taking this formal approach, our description of the LC is integrated into a general theory of the brain function and uses constructs that underwrite the normal cycle of perceptual inference and action selection. This contrasts with previous LC modelling approaches, which have invoked the separate monitoring of statistical quantities (such as unexpected uncertainty) outside of the action selection cycle [<xref ref-type="bibr" rid="pcbi.1006267.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref005">5</xref>].</p>
<p>In the following we apply AI to simulate the updating of beliefs about states of the world–and actions–as a synthetic agent engages with two scenarios (a Go/No-go task with reversal and an ‘explore/exploit’ task) that elicit archetypal LC responses. Using this approach, we show that the ‘state-action prediction error’ offers an effective predictor of LC firing over both long (tonic) and short (phasic) timescales, without the need to invoke switches between distinct modes. Furthermore, we described how the signal may be broadcast back to cortex to affect appropriate updates to internal models of the environment. This links the error via the LC to model flexibility–bringing two key concepts of the LC together: ‘explore-exploit’ and ‘network reset’. It also produces behavioural changes that agree with experimental knowledge of animal behaviours under noradrenergic manipulation. Finally, the simulations produce realistic LC firing patterns that could, in principle, be used to model empirical responses.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Models</title>
<sec id="sec003">
<title>Brief overview of Active Inference</title>
<p>Active Inference is a theory of behaviour that has previously been mapped to putative neural implementations [<xref ref-type="bibr" rid="pcbi.1006267.ref014">14</xref>]. The basic premise of AI is that to stay in states compatible with survival, an agent must create and update a generative model of the world [<xref ref-type="bibr" rid="pcbi.1006267.ref014">14</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref018">18</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref019">19</xref>]. To do this effectively the agent represents the true structure of the world with an internal model that is a good approximation of how its sensations are generated. (Note that in this paper, we often use the term ‘model’ to refer to the agent’s beliefs about states and actions in the world. Technically, these beliefs are posterior probability distributions, which require a generative model to exist).</p>
<p>The generative model encompasses a set of discrete states and transition patterns that probabilistically capture all the agent’s beliefs about the world and likely outcomes under different actions. The model is formulated as a Partially Observable Markov Decision Process (POMDP), under which the agent must infer its current state, make predictions about the outcome of actions in the future and make postdictions about the landscape it has just traversed. In this context the word ‘state’ refers to a combination of features relevant to the agent, including its location and the cognitive context of that location; i.e., states of the world that matter for its behaviour.</p>
<p>To optimise this model, the agent constantly seeks to minimise variational free energy. This free energy is a mathematical proxy for the difference between the agent’s generative model and a ‘perfect’ or ‘true’ model of the world, and thus must be continually updated for the agent to survive. Estimates of the free energy can be obtained over time by comparing predictions from the generative model with the results of actions in the real world, for instance, by checking whether an action produces the expected sensory feedback. Using this information from the real world, the agent minimises free energy in two ways: by adjusting the parameters of the generative model itself, and by picking actions that it believes will be associated with the lowest free energy. This allows the agent to both optimise the model and change its action plans. Updating proceeds in cycles, with each round of model updates accompanied by predictions that are then checked by selecting and executing an action–in turn allowing a new round of updates (<xref ref-type="fig" rid="pcbi.1006267.g001">Fig 1</xref>).</p>
<fig id="pcbi.1006267.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006267.g001</object-id>
<label>Fig 1</label>
<caption>
<title>A quasi-mathematical description of the framework of Active Inference (based on [<xref ref-type="bibr" rid="pcbi.1006267.ref014">14</xref>]).</title>
<p>The flow chart on the right shows the sequence of updates occurring over a single trial consisting of time-steps t = 1….T.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.g001" xlink:type="simple"/>
</fig>
<p>This framework means that each round of updates combines perceptual inference with action selection. Mathematically, this takes the form of a series of iterative updates to parameters that are repeated until convergence. Specifically, each new observation from the environment enables posterior beliefs about states to be updated via iterating expressions that minimise free energy. Similar iterative updates are then applied to posterior beliefs about competing policies and precision parameters (step 4 of <xref ref-type="fig" rid="pcbi.1006267.g002">Fig 2</xref>). Finally, the updated beliefs are used to select an action which in turn generates a new observation (step 5 of <xref ref-type="fig" rid="pcbi.1006267.g002">Fig 2</xref>). It is this machinery that we will map to LC/NA firing and function. A derivation of the Active Inference framework is provided in Appendix 1; <xref ref-type="supplementary-material" rid="pcbi.1006267.s003">S1 Fig</xref> shows hierarchical dependencies within the model. Appendix 2 also gives an overview of the implementation in code.</p>
<fig id="pcbi.1006267.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006267.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Mathematical outline of the framework of Active Inference.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.g002" xlink:type="simple"/>
</fig>
<p>There are two more subtleties that should be noted in this brief description. Firstly, the requirement to minimise free energy in action selection means that actions are driven by twin goals–the future attainment of states that the agent holds valuable (utility), as well as the attainment of information when performing an action (epistemic value). Formally, these describe the path integral of free energy expected under competing policies (see [<xref ref-type="bibr" rid="pcbi.1006267.ref014">14</xref>] and Appendix 1). Thus, agents that act to minimise free energy will end up where they hoped to, while resolving uncertainty about their environment. If policies do not differ in their ability to resolve uncertainty (i.e. no policy will harvest more information) then utility will drive policy selection. It has already been established that this particular cost function explores and exploits in a predictable and mathematically well-defined manner, depending on the relative utility of outcomes and on the uncertainty with which the agent views its environment [<xref ref-type="bibr" rid="pcbi.1006267.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1006267.ref017">17</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref020">20</xref>].</p>
<p>The second important component is the timespan covered by inferences. The agent continually updates its understanding of the past, the present and the future. This means that observations in the present can be used to update inferences on states that occurred in the past–in this way, past events continue to be useful for belief updating long after they occurred. This is just a formalisation of our ability to postdict (e.g., “I started in this context, even if I didn't know at the time”). Equally, the agent’s knowledge of the world is used to form predictions at future times (e.g., “These are the outcomes I expect under this policy”). The agent not only attempts to use events that have already happened to minimise free energy, but also tries to select actions and inferences which it believes will minimise free energy of future observations.</p>
</sec>
<sec id="sec004">
<title>A Bayesian model average drives action selection</title>
<p>As outlined in Figs <xref ref-type="fig" rid="pcbi.1006267.g001">1</xref> and <xref ref-type="fig" rid="pcbi.1006267.g002">2</xref>, the generative model comprises probability distributions over states, sequences of actions, precision (confidence in predictions) and observations. At each time step, the agent updates its beliefs about these probability distributions over states, actions and precision by minimising free energy.</p>
<p>Once all updates have been completed the agent combines all of its inferences to produce a Bayesian Model Average (BMA) of states under possible actions. This can be considered as a summary of everything the agent knows about its place in the world–an overall ‘map’ of the states it believes it occupied in the past, the state it occupies now and the states it believes it will occupy in the future. The distribution implicitly includes action planning that is informed by inferences about events in the past. The Bayesian Model Average is then used by the agent to select an action, as described in <xref ref-type="fig" rid="pcbi.1006267.g002">Fig 2</xref>. The action causes a transition to a new state, which generates an observation from the environment.</p>
</sec>
<sec id="sec005">
<title>State-action prediction errors as a driver of LC activity</title>
<p>Any large change in the state-action heatmap between time steps represents a <italic>state-action prediction error</italic>. These errors indicate that the agent’s beliefs about its past and future states have changed substantially after receiving a fresh observation. Such prediction errors indicate that the agent’s model of the world–including its plan for actions–must change. This may either be because an unexpected stimulus has occurred, requiring an abrupt change in behaviour, or because observations over longer timescales are consistently demonstrating that key components of the model (for example, the observation likelihood (<bold><italic>A</italic></bold>) and state transition (<bold><italic>B</italic></bold>) matrices) are no longer fit for purpose. Crucially, errors originating from both situations are reflected in the state-action prediction error. We propose that they are a driver of LC activity.</p>
<p>The BMA is estimated for each time point within the task (indexed by <italic>τ</italic>) and takes the form of a weighted sum over state probabilities (states are weighted by the probability of each policy predicting that state at the given time). To estimate the state-action prediction error during a task, we take the Kullback-Leibler divergence between Bayesian Model Average (BMA) distributions at successive time steps. Mathematically, this reflects the degree of belief updating induced by each new observation. It is often known as a relative entropy, information gain or Bayesian surprise. The following expressions describe the BMA (upper equation) and the state-action prediction error (lower):
<disp-formula id="pcbi.1006267.e001">
<alternatives>
<graphic id="pcbi.1006267.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006267.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">τ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">π</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1006267.e002">
<alternatives>
<graphic id="pcbi.1006267.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006267.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mi>S</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>||</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">]</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Here, <bold><italic>S</italic></bold><sub><italic>τ</italic></sub> is the BMA over states for time <italic>τ</italic> within the task, while <inline-formula id="pcbi.1006267.e003"><alternatives><graphic id="pcbi.1006267.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006267.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is the vector of probabilities for states at time <italic>τ</italic> under policy <italic>p</italic>, which has a probability <bold><italic>π</italic></bold><sub><bold><italic>p</italic></bold></sub>. In the expression for state-action prediction error, superscripts (either <italic>t</italic> or <italic>t</italic> − 1) refer to the time at which the estimate is calculated.</p>
<p>Prediction errors over shorter timescales (i.e. between actions, during the iterative cycle of belief updating) are an integral feature of AI. The state-action prediction error, in contrast, represents a global error: it is expressed over the timescale of a behavioural epoch as a <italic>response</italic> to the outcome of belief updating that facilitates action selection.</p>
<p>In the implementation, the state-action prediction error is calculated immediately after the BMA over states, as shown in <xref ref-type="fig" rid="pcbi.1006267.g003">Fig 3</xref>.</p>
<fig id="pcbi.1006267.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006267.g003</object-id>
<label>Fig 3</label>
<caption>
<title>The cycle of updates under Active Inference, expanded to show the calculation of the state- action prediction error and the application of model decay.</title>
<p>Left: non-mathematical ‘cartoon’ explanation of the cycle of updates. Right: more detailed update cycle, to be compared with the version shown in <xref ref-type="fig" rid="pcbi.1006267.g001">Fig 1</xref>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.g003" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec006">
<title>LC feedback: Flexible model learning promoted by state-action prediction errors</title>
<p>Why might it be useful for the LC to respond to state-action prediction errors? We suggest that one important function is that such errors require a specific modulation of distributed cortical activity encoding representations of the structure of the environment, particularly in frontal cortex. This modulation would boost the flexibility of internal representations (where our matrices would be formed by connected cell assemblies in frontal cortex) and increase their responsiveness to recent observations. In vivo, this may be mediated by the release of noradrenaline from LC projections to the frontal cortex occurring in response to state-action prediction errors.</p>
<p>The need for flexible model updating is directly relevant to a related challenge for Active Inference models; namely, the rate at which the agent’s experience is assimilated into its model. Addressing this issue provides a pathway for modelling the effect of LC activation and closes the feedback loop between brainstem and cortex. So what computational role does NA have in facilitating adaptive flexibility?</p>
<p>Under AI, the agent’s model of the world is encoded by a set of probability distributions that keep track of the mappings between states and outcomes, and between states occupied at sequential time points. These mappings are encoded by Dirichlet distributions, the parameters of which are incremented with each instance of a particular mapping the agent experiences (as shown in step 6, <xref ref-type="fig" rid="pcbi.1006267.g002">Fig 2</xref> and Appendix 1) [<xref ref-type="bibr" rid="pcbi.1006267.ref014">14</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref020">20</xref>]. However, difficulties arise when environmental contingencies change, because the gradual accumulation of concentration parameters is essentially unlimited. Accumulated experience can come to dominate the agent’s model, with new information having little effect on the agent’s decisions. This occurs because the generative model does not allow for fluctuations in probability transitions, i.e. environmental volatility. This issue can be finessed by adding a volatility or decay factor (<italic>α)</italic>, which effectively endows the generative model with the capacity to ‘forget’ experiences in the past that are not relevant if environmental contingencies change.</p>
<p>This introduces a modification to the update equations shown in <xref ref-type="fig" rid="pcbi.1006267.g002">Fig 2</xref>, of the form:
<disp-formula id="pcbi.1006267.e004">
<alternatives>
<graphic id="pcbi.1006267.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006267.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi><mml:mspace width="0.25em"/><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mo>:</mml:mo><mml:mspace width="0.12em"/><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1006267.e005">
<alternatives>
<graphic id="pcbi.1006267.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006267.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mspace width="0.25em"/><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mo>:</mml:mo><mml:mspace width="0.12em"/><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Where <bold><italic>d</italic></bold> and <italic>d</italic> are the updated and existing beliefs respectively. In the original update, the <bold><italic>d</italic></bold> vector (which describes the agent’s prior about its state at t = 1) is simply incremented by adding the agent’s beliefs about the state it occupied at t = 1. This update is then applied after each trial. In the new version, the same increment occurs, but with a ‘decay’ of the values in d that is controlled by <italic>α</italic>. The same modification is made to the updates for <bold><italic>a</italic></bold> and <bold><italic>b</italic></bold> (the updated forms are given explicitly in Appendix 1).</p>
<p>In the context of reversal learning, this is not a trivial adjustment but a crucial addition to the generative model which enables AI agents to adapt flexibly. However, the level at which to set the decay term poses a further challenge: if the decay is too big, the model is too flexible and will be dominated by its most recent experiences (as all the other terms will have decayed). If the decay is too small concentration parameters may accumulate too slowly, rendering the model too stable.</p>
<p>There are several ways one can optimise this ‘forgetting’ in volatility models. One could equip the Markov decision process with a further hierarchical level modelling fluctuations from trial to trial–as in the hierarchical Gaussian filter [<xref ref-type="bibr" rid="pcbi.1006267.ref021">21</xref>]. A simpler (and biologically parsimonious) solution is to link the decay factor to recent values of state-action prediction error via the LC. In other words, equip the agent with the prior that if belief updating is greater than expected, environmental contingencies have become more volatile.</p>
<p>This produces flexibility in model learning when state-action prediction error is high (low α) but maintains model stability when state-action prediction error is low (high α). We have modelled this feedback using a simple logistic function to convert the error into a value for <italic>α</italic>:
<disp-formula id="pcbi.1006267.e006">
<alternatives>
<graphic id="pcbi.1006267.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006267.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
</disp-formula>
where <italic>SAPE</italic> is the state-action prediction error seen during the trial (in tasks with more than one prediction error per trial, the maximum error is used), k is a gradient and <italic>m</italic> is a mean (i.e., expected) value. In all simulations presented below, <italic>α</italic><sub><italic>min</italic></sub> = 2, <italic>α</italic><sub><italic>max</italic></sub> = 32, k = 8, and <italic>m</italic> was set one standard deviation above the mean error value encountered in 100 trials of each task with α = 16.</p>
<p>Under this scheme, a brief but large state-action prediction error ‘boosts’ the impact of a recent experience upon the agent’s model of the world. This occurs by temporarily increasing the attrition of existing, experience dependent parameters encoding environmental contingencies. Crucially, this causes recent actions and observations to have a greater effect on the Dirichlet distributions than they would otherwise. If errors then decrease, the model stabilises again. However, if actions consistently produce large state-action prediction errors then the underlying model parameters will gradually lose their structure–equivalent to the flattening of probability distributions that form the agent’s model—leading to greater variability in action selection. This ‘flat’ model does not need to track volatility separately: we instead incorporate LC/NA directly into the decision-making loop.</p>
<p>General MATLAB code implementing Active Inference can be found at <ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/software/spm12/" xlink:type="simple">https://www.fil.ion.ucl.ac.uk/spm/software/spm12/</ext-link> (in the folder toolbox/DEM). Code from this toolbox was modified to perform the simulations described in this paper; examples are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/AnnaCSales/ActiveInference" xlink:type="simple">https://github.com/AnnaCSales/ActiveInference</ext-link>.</p>
</sec>
</sec>
<sec id="sec007" sec-type="results">
<title>Results</title>
<p>The simulations reported in this paper suggest that behavioural contexts that produce large state-action prediction errors are also those that produce archetypal LC responses in experimental environments. Below, we describe the emergence of phasic and tonic activity in two tasks as a response to changes in state-action prediction error. We initially present results without the LC feedback (model decay) in place before showing how both simulations are improved by modelling the LC as a link between state-action prediction errors and model decay / volatility.</p>
<sec id="sec008">
<title>State-action prediction errors display tonic and phasic patterns of response</title>
<sec id="sec009">
<title>Go/no-go task</title>
<p>A simple go/no-go task modelled under AI is shown in <xref ref-type="fig" rid="pcbi.1006267.g004">Fig 4</xref>. In this task, the agent (depicted as a rat) starts in a ‘ready’ state—location 1—and must move to location 2 to receive a cue. When the cue is received the agent may either move back to location 1 or seek a reward at location 3. The agent has a strong preference for receiving the reward but an aversion to moving to location 3 and remaining unrewarded. This is represented in the task by a notional ramp which forces the agent to expend physical effort in seeking the reward. There are six available states, which between them describe the different combinations of features relevant to the agent during the task. Learning is mediated through updates to the <bold>A</bold> and <bold>D</bold> matrices, which encode likelihood mappings between hidden states of the world and outcomes–and prior beliefs about initial states.</p>
<fig id="pcbi.1006267.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006267.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Simple go/no-go task modelled under AI.</title>
<p>(a) Structure of the task (see main text) (b)-(d) The state-action heatmap showing inferences on the agent’s state over a rare ‘Go!’ trial. Large updates are required at t = 2, after the animal receives the ‘go’ cue which forces it to update its action plans and state inferences. This update is proposed to cause a large, time specific input into LC, which causes a sudden phasic burst of LC activity. The lower part of the <italic>Fig</italic> shows the full modelling of the go/no-go task, with components as described in <xref ref-type="fig" rid="pcbi.1006267.g001">Fig 1</xref>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.g004" xlink:type="simple"/>
</fig>
<p>At each time point, the agent’s beliefs are summarised in the Bayesian Model Average, represented graphically as a state-action heatmap. The heatmap shows how the likelihood of different states evolves over time as evidence accumulates and beliefs are updated. <xref ref-type="fig" rid="pcbi.1006267.g004">Fig 4(B)</xref> shows a representation of the agent’s beliefs about states at the beginning of a new trial in which the ‘go’ cue is heard. The agent is ‘well trained’; that is, it has an accurate understanding of the relationship between the cue and the availability of the reward, and of the fact that the ‘go’ cue is rare (here, the cue probability is 10%). In our modelling, we trained the synthetic rat by running the simulation for 750 trials. We then used the learnt priors as the starting point for the ‘well trained’ case.</p>
<p>Given its knowledge of the task, the agent begins with a strong belief that it is beginning the trial in state 2 (in which a reward will not be available). It also makes predictions for the states it believes it will occupy later in the trial: at t = 2, it believes it is likely to occupy state 4 –corresponding to the occurrence of the ‘no-go’ cue, but also entertains a slight possibility that the ‘go’ cue might still appear. The agent is much less certain in its predictions for t = 3, but still holds a higher probability that it will end up in one of the unrewarded end states.</p>
<p>At the next time point (at t = 2, <xref ref-type="fig" rid="pcbi.1006267.g004">Fig 4(C)</xref>), the agent updates its state-action heatmap, making new inferences on the probabilities of different states in the past, present and future, based on its most recent observations. If it has received the rare ‘go’ cue, it will have to update its predictions for its state at the end of the task, in addition to altering its inferences about the state in which it started at t = 1 (a process of postdiction about past states based on new information). The agent therefore has to make a large, sudden update to its BMA heatmap at t = 2. By t = 3 (<xref ref-type="fig" rid="pcbi.1006267.g004">Fig 4(D)</xref>), the agent has received the reward as predicted, and knows with certainty where it is and where it has been. Only small updates are required to its estimates at this point.</p>
<p>Simulated state-action prediction errors during this task are shown in <xref ref-type="fig" rid="pcbi.1006267.g005">Fig 5</xref>. In this simulation the state-action prediction error does not modulate learning and the decay parameter <italic>α</italic> has been set to a fixed value (<italic>α = 16)</italic>. During the task, an agent who is well trained shows large peaks of state-action prediction error when the reward-predicting cue is presented, resulting in phasic activity in the LC as seen experimentally [<xref ref-type="bibr" rid="pcbi.1006267.ref006">6</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref022">22</xref>]. The underlying reason for this error is a large, quick shift in action planning, from the (more likely) ‘No-go’ outcome to the rare ‘Go’ situation.</p>
<fig id="pcbi.1006267.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006267.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Plot of state-action prediction error, simulated LC spiking and behaviour during 100 trials of the go/no-go task, (for agents with a fixed value of model decay parameter <italic>α</italic> not linked to state-action prediction error).</title>
<p>Each point within the task is assumed to last 1s and is associated with a single state-action prediction error. In (a) the raw prediction error is extracted for t = 2, when the animal receives a cue (this is the error between t = 1 and t = 2) and t = 3 when the animal receives feedback on its response to the cue (the error between t = 2 and t = 3). Because the prediction error explicitly evaluates differences between update cycles, there is no error available for the first time point. Each trial has therefore been collapsed to two time points, each lasting 1 second. In (a) the occurrence of the ‘go’ cue causes strong peaks in prediction error. This is converted into a simulated LC firing rate in (b). To visualise LC firing, a firing probability <italic>p</italic> is calculated for each second using the state-action prediction error (SAPE) as the input into a logistic function, so that <inline-formula id="pcbi.1006267.e007"><alternatives><graphic id="pcbi.1006267.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006267.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula> where <italic>k</italic> = 8, and <italic>m</italic> is as above. Each second was then further split into 0.1s bins, during which the unit generated a single spike with probability <italic>p</italic>. This gives a physiologically reasonable [<xref ref-type="bibr" rid="pcbi.1006267.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref022">22</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref023">23</xref>] maximum firing rate of 10hz if <italic>p</italic> = 1. This is converted into a simulated LC firing rate in (b), showing phasic LC activation when the ‘go’ cue is heard. Plot (c) is a graphical representation of behaviour during the task at times t = 2 and t = 3 for each trial, in which the position of the coloured block describes the agent’s location and the colour shows the agent’s observation after moving.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec010">
<title>‘Explore / Exploit’ task</title>
<p>We also modelled a task designed to offer the agent a choice between exploiting a known resource or exploring for new sources of reward (depicted in <xref ref-type="fig" rid="pcbi.1006267.g006">Fig 6</xref>). On every trial in this task the agent searches for a reward in one of three arms. In one arm, the probability of finding a reward is high (90%), whilst in the others the probability is low (10%). The probabilities are held constant for a set number of trials, during which time the agent accumulates beliefs about the likelihood of finding a reward in each location. Typically, once the agent has been rewarded in one location numerous times it will build a strong prior probability on the availability of a reward in that location (reflected in updates to elements of the <bold>B</bold> matrix). In the example shown in <xref ref-type="fig" rid="pcbi.1006267.g006">Fig 6</xref> the agent begins by exploring the arms until it has seen a reward in arm 1, after which it continues to visit this location. After a set number of trials, the location of the high probability arm is shifted. When this happens, the agent’s established model of the world no longer provides an accurate explanation of its experiences. As expected rewards fail to materialise, state-action prediction errors arise. Under our model, this causes an increasing tonic rate of LC activity whilst new priors are learnt and behaviour changes.</p>
<fig id="pcbi.1006267.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006267.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Modelling a 3-arm explore/exploit task under Active Inference.</title>
<p>(a) shows the mathematical structure of the task. There are seven states, including one neutral starting point and 3 arm locations which can be combined with either a reward / no reward. There are 7 observations; here these have a 1-to-1 mapping to states (<bold>A</bold> matrix). Actions 1–4 simply move the agent to locations 1–4 respectively. The probability of obtaining a reward in a given arm (p<sub>2</sub> for action 2, above) is held static for a fixed number of trials, with one arm granting a reward with a 90% probability and the others with 10% probability. This is then switched, so that the agent must adjust its priors and its behaviour. (b) shows the state-action prediction errors and simulated LC responses over a typical run of 100 trials for an agent with a fixed (<italic>α</italic> = 16) value of the model decay parameter.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.g006" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec011">
<title>Flexibility in model learning improves task performance and enables reversal learning</title>
<p>We now turn to simulations in which the state-action prediction error is linked–via LC activity—to the model decay parameter. When this link is introduced there are improvements in performance in the simulations of both the Go/no-go and explore/exploit tasks (Figs <xref ref-type="fig" rid="pcbi.1006267.g007">7</xref> and <xref ref-type="fig" rid="pcbi.1006267.g008">8</xref>).</p>
<fig id="pcbi.1006267.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006267.g007</object-id>
<label>Fig 7</label>
<caption>
<title>The explore/exploit task simulated with fixed and flexible values of model decay.</title>
<p>(a) and (b) show the behavioural output from the explore/exploit task for agents with a fixed <italic>α</italic> parameter, specifically <italic>α</italic> = 32 (slow model decay) or <italic>α</italic> = 2 (fast model decay). The agent with <italic>α</italic> = 2 is hyperflexible in its behaviour and changes its strategy after single failed trials. In contrast, the <italic>α</italic> = 32 agent is inflexible and persists in seeking reward in the same location despite multiple failed trials. (c) and (d) show the outcome of simulations involving fixed <italic>α</italic> agents contrasted with the performance of an agent with a flexible value of <italic>α</italic> set by the state-action prediction error. Each simulation consisted of 150 trials in which the location of the high probability arm changed either every 15 or every 50 trials. The simulation was repeated 50 times. (c) and (d) show the average reward obtained in bins of 20 trials (shaded errors show standard error of the mean), alongside the mean total reward gained by each agent (error bars show S.E.M.;***P&lt;0.0001, one way ANOVA followed by Tukey posthoc test). The less stable/more stable environments favour the <italic>α</italic> = 2 / <italic>α</italic> = 32 agent respectively: however, the flexible agent is able to perform as well (or better) in both scenarios. In (e) the location of the reward changes after random intervals, and the flexible agent clearly outperforms both of the fixed- <italic>α</italic> agents.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.g007" xlink:type="simple"/>
</fig>
<fig id="pcbi.1006267.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006267.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Reversal learning during the go/no-go task.</title>
<p>(a)–(c) show the performance of an agent with a value of model decay determined by state-action prediction error during a reversal of cues in the go/no-go task. The agent begins with a well-trained understanding (via 750 trials of training) that cue 2 indicates that a reward is available. At trial 35 (t = 70) the cue/context relationship is reversed, and the agent must now learn that cue 1 indicates the ‘Go’ context. This initially causes numerous unsuccessful trials, violating the learnt model and producing high prediction errors (a). Note that prediction errors are initially elevated at both timepoints in each trial because both the previously rare cue and the subsequent lack of reward are unexpected. These prediction errors result in a lowering in the parameter decay factor (b), which in turn flattens the agent’s priors causing more variability in behaviour. Eventually the agent learns the new contingencies and the model stabilises, with the re-emergence of phasic bursts of LC activity on ‘Go’ trials (a, c). From trial 125 onwards, the peak of phasic activity begins to transition towards the presentation of the cue rather than the reward. Plot (d) is a graphical representation of behaviour during the task at times t = 2 and t = 3 for each trial, in which the position of the coloured block describes the agent’s location and the colour shows the agent’s observation after moving. (e) shows performance over 50 repeats of the reversal learning task shown in (a), for agents with a fixed or flexible value of α. All agents begin with a near optimal d’ value (measured over bins of 20 trials). However, only the agent with α determined by the state-action prediction error is able to return to optimal levels of performance within the 300 trials shown. (f) and (g) show characteristics of the mean prediction error response to ‘go’ and ‘no-cue’ cues during the static (non-reversed) task as reward and probability parameters are varied, for agents with a flexible value of α((f) ***P&lt;0.0001; one-way ANOVA between different c values, followed by Tukey posthoc test, (g) ** P&lt;0.001, ***P&lt;0.0001; two tailed Student’s t-test between go/no go contexts for fixed cue probabilities, one way ANOVA followed by Tukey posthoc test for ‘go’ peaks with different cue probabilities).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.g008" xlink:type="simple"/>
</fig>
<p>In the explore/exploit task, the dynamic modulation of model building allows state-action prediction errors to reduce more quickly when the rat is settled into the ‘exploit’ mode of harvesting a reward in a reliable location, promoting model stability. When the reward is no longer available, errors mount and the increase in model decay causes the agent to make more explorative choices. This contrasts with the same task simulated with fixed values of <italic>α</italic> (<xref ref-type="fig" rid="pcbi.1006267.g007">Fig 7(A) and 7(B)</xref>): when the model is hyper-flexible (<italic>α = 2)</italic>, the agent often switches behavioural strategy after a single failed trial; when the model is inflexible, the agent takes a large number of trials to visit a new location (<italic>α = 2)</italic>. The highly flexible agent performs well when the structure of the environment is volatile (<xref ref-type="fig" rid="pcbi.1006267.g007">Fig 7C</xref>). In this context, even small errors may reasonably indicate that the underlying rules of the task have changed, and the agent’s rapid shifts in strategy yields rewards. Over multiple simulations the flexible agent obtains a significantly higher total reward than the inflexible agent (averages over 50 simulations of 150 trials each with rules as shown in <xref ref-type="fig" rid="pcbi.1006267.g007">Fig 7</xref>). Conversely, the inflexible agent obtains significantly more overall reward when the environment is more stable (5(d)). <xref ref-type="fig" rid="pcbi.1006267.g007">Fig 7(C) and 7(D)</xref> also show the performance of an agent with a dynamic <italic>α</italic> with a value determined by the state-action prediction error, ranging between <italic>α = 2</italic> and <italic>α = 32</italic>. This agent performs as well as, or better than, the fixed <italic>α</italic> agents in both contexts, responding with a rapid changes to its model (and resulting behaviour) when errors are high for a sustained period, but stabilising when errors decrease. This agent also outperforms both fixed <italic>α</italic> agents when the arm locations change after random intervals (<xref ref-type="fig" rid="pcbi.1006267.g007">Fig 7(D)</xref>). A full plot of state-action prediction errors, simulated LC firing and behavioural output for the explore/exploit task with the flexible <italic>α</italic> agent is also shown in <xref ref-type="supplementary-material" rid="pcbi.1006267.s004">S2 Fig</xref>.</p>
<p>The Go/No-Go task was also simulated during a reversal of cue meanings (<xref ref-type="fig" rid="pcbi.1006267.g008">Fig 8</xref>). As expected, the well-trained agent begins the session by showing a phasic response in state-action prediction error / LC firing in response to the ‘Go’ cue (cue 1). At trial 35, the meaning of the two cues switches so that the ‘Go’ context is predicted by cue 2. At the reversal, state-action prediction errors cannot be resolved and LC firing switches to a higher tonic level. During this period, model updating–and behaviour—becomes more flexible and the new rules of the task are learnt. Eventually the high levels of tonic activity fall away and phasic responses to the new ‘Go’ cue re-emerge; coupled with a lower level of tonic activity. This mirrors the pattern of LC firing recorded in monkeys during the same task [<xref ref-type="bibr" rid="pcbi.1006267.ref022">22</xref>]. Note that after the reversal, phasic responses emerge initially in response to the reward itself, then to both the cue and reward, and finally only in response to the cue. Over multiple trials of the reversal, only the agent with a flexible <italic>α</italic> linked to state-action prediction error is able to learn the new contingencies and return to optimum performance levels (<xref ref-type="fig" rid="pcbi.1006267.g008">Fig 8(E)</xref>, for which the reversal was repeated 50 times).</p>
<p>The characteristics of the state-action prediction error for this agent were then examined in more detail (<xref ref-type="fig" rid="pcbi.1006267.g008">Fig 8(F) and 8(G)</xref>). 2000 trials were run of the go/no-go task in which the cue meanings were held constant (no reversal), and the agent started each trial with ‘well-trained’ priors obtained through 750 trials of training, as above. We find that the size of the state-action prediction error–the proposed input into the LC—changes in ways that are consistent with experimentally reported LC activation (see discussion below). As shown in <xref ref-type="fig" rid="pcbi.1006267.g008">Fig 8</xref>, the size of the phasic peak in state-action prediction error is larger for rarer ‘go’ stimuli (<xref ref-type="fig" rid="pcbi.1006267.g008">Fig 8(G)</xref>, in which ‘G’ = go cues, ‘NG’ = no go cues). When the probability of the ‘go’ cue is held fixed, the resulting peak increases as the reward becomes more valuable to the agent (represented by the value held in the agent’s c matrix, <xref ref-type="fig" rid="pcbi.1006267.g008">Fig 8(F)</xref>). Finally, when consecutive ‘go’ trials occur, the second peak is reduced in size (mean reduction of 12.9%±1.4%, see <xref ref-type="supplementary-material" rid="pcbi.1006267.s005">S3 Fig</xref>).</p>
<p>As expected, when the ‘go’ cues are rare (e.g. p(g) = 10%) the state-action prediction error response to the ‘go’ cue is significantly larger than the response to the ‘no-go’ cue. Interestingly, this is still true when the cues occur with equal probability (p(go) = 50%), and when the ‘go’ cue is slightly more probable (p(go) = 55%, <xref ref-type="fig" rid="pcbi.1006267.g008">Fig 8G</xref>).</p>
<p>Many of these response characteristics are also present in agents with a fixed <italic>α</italic> and are an inherent feature of the state-action prediction error (see <xref ref-type="supplementary-material" rid="pcbi.1006267.s005">S3 Fig</xref>). However only the agent with flexible <italic>α</italic> displays <italic>both</italic> the correct profile of prediction error responses and the ability to learn the reversal of contingencies shown above.</p>
<p>A full plot of state-action prediction errors, simulated LC firing and behavioural output for the static go/no-go task for the flexible <italic>α</italic> agent is shown in <xref ref-type="supplementary-material" rid="pcbi.1006267.s004">S2 Fig</xref>.</p>
</sec>
</sec>
<sec id="sec012" sec-type="conclusions">
<title>Discussion</title>
<p>We propose that the LC fulfils a crucial role, linking state-action prediction errors (or Bayesian surprise) during the planning of actions to model decay–a form of learning rate. Using this approach, we have reproduced the following experimentally observed LC characteristics:</p>
<list list-type="bullet">
<list-item><p>Phasic responses during a Go/No-Go paradigm as described experimentally in [<xref ref-type="bibr" rid="pcbi.1006267.ref006">6</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref013">13</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref022">22</xref>]. Here, cues predicting a reward (for which the animal must perform an action) elicit clear phasic LC responses, which stand out against a background of lower overall tonic activity.</p></list-item>
<list-item><p>A more general link between the ‘exploration’ mode of behaviour and high tonic levels of LC activity. Whilst direct measurements of LC activity during explore-exploit paradigms are lacking, the link is strongly suggested by indirect experimental evidence. For instance, Tervo et al [<xref ref-type="bibr" rid="pcbi.1006267.ref003">3</xref>] demonstrated highly variable behavioural choices in rats when the activity of LC units projecting to ACC was held artificially high via optogenetic manipulation. Other studies have also demonstrated [<xref ref-type="bibr" rid="pcbi.1006267.ref024">24</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref025">25</xref>] that an increase in pupil size (a correlate of LC activity) occurs in parallel with behavioural flexibility and task disengagement.</p></list-item>
</list>
<p>We also reproduce more subtle characteristics of state-action prediction error responses. Simulations of the go/no-go task demonstrate a progression of phasic responses during the learning period that parallels the development of responses reported in a similar go/no-go task in rats [<xref ref-type="bibr" rid="pcbi.1006267.ref013">13</xref>], in which phasic responses occur initially for the reward alone, then for both the cue and reward, and finally, only for the cue itself. Additionally, during the go/no-go task the model reproduces the following empirical results:</p>
<list list-type="bullet">
<list-item><p>a reduction in the size of the phasic state-action prediction error when ‘go’ cues were presented consecutively, as reported for an identical go/no-go task [<xref ref-type="bibr" rid="pcbi.1006267.ref006">6</xref>];</p></list-item>
<list-item><p>an increase in response size when target ‘go’ cues are rarer [<xref ref-type="bibr" rid="pcbi.1006267.ref006">6</xref>];</p></list-item>
<list-item><p>a larger response to ‘go’ cues than to ‘no-go’ cues when the two are equally probable [<xref ref-type="bibr" rid="pcbi.1006267.ref006">6</xref>]. The model further predicts that the larger response to the ‘go’ cue will persist even when this cue is slightly <italic>more</italic> probable than the ‘no-go’ cue (up to 55%—see <xref ref-type="fig" rid="pcbi.1006267.g008">Fig 8</xref> and <xref ref-type="supplementary-material" rid="pcbi.1006267.s005">S3 Fig</xref>) and that the responses will equalise or reverse as the probability of the ‘go’ cue increases further;</p></list-item>
<list-item><p>a larger state-action prediction error response to the ‘go’ cue when the cue predicts a greater reward (when the probability of the cue is fixed; see <xref ref-type="fig" rid="pcbi.1006267.g008">Fig 8F</xref>), in line with results reported in monkeys in similar contexts [<xref ref-type="bibr" rid="pcbi.1006267.ref008">8</xref>].</p></list-item>
</list>
<p>The results above for both the go/no-go and explore/exploit tasks suggest that the LC should be phasically active when a strongly predicted reward is absent (for example, the unrewarded trials in <xref ref-type="fig" rid="pcbi.1006267.g006">Fig 6</xref>). This is in conflict with the results of a similar go/no-go task [<xref ref-type="bibr" rid="pcbi.1006267.ref013">13</xref>], which reported no LC activation when predicted rewards were omitted. However, another study–using pupil dilation as a measure of LC response–observed an increase in pupil size upon presentation of rewards that were either significantly higher or lower than expected [<xref ref-type="bibr" rid="pcbi.1006267.ref026">26</xref>], as predicted here.</p>
<p>We also note that Nassar et al. [<xref ref-type="bibr" rid="pcbi.1006267.ref027">27</xref>], have shown that pupil linked arousal systems are intimately linked to assessments of environmental instabilities and were predictive of the influence of new data on subsequent inferences. This is entirely complementary to the model presented above, in which the same principles are successfully applied to demonstrate realistic responses in both the go/no-go and explore/exploit tasks.</p>
<p>We do not address in detail the timing of phasic LC activation relative to cues and actions. However, under the model the LC is activated in response to the completed updating of beliefs. This updating is an iterative process that, in real life, may take a variable amount of time–in contrast to the selection of action which occurs automatically based on the probability distributions produced. This is consistent with empirical results showing that the activation of the LC is more tightly locked to action than to preceding cues (see, for instance [<xref ref-type="bibr" rid="pcbi.1006267.ref013">13</xref>]). A detailed examination of the interplay between LC activation, cued-actions and levels of motivation (including responses to ‘stop’ signals, as explored in [<xref ref-type="bibr" rid="pcbi.1006267.ref028">28</xref>]) are also outside the scope of the tasks described here but present important avenues for future modelling.</p>
<sec id="sec013">
<title>Neurobiology</title>
<p>In previous Active Inference literature the calculation of Bayesian Model Averages has been mapped to the dorsal prefrontal cortex [<xref ref-type="bibr" rid="pcbi.1006267.ref014">14</xref>]. This is one of the frontal regions known to send projections to LC [<xref ref-type="bibr" rid="pcbi.1006267.ref029">29</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref030">30</xref>] and is a candidate for the calculation of state-action prediction error (although we accept that without further experimental work such anatomical attributions are largely speculative). Experimental evidence for a neural representation of a distinct prediction error based on states, rather than rewards, has also been found in dorsal regions of the frontal cortex in a human MRI study [<xref ref-type="bibr" rid="pcbi.1006267.ref031">31</xref>].</p>
<p>Turning to the LC-prefrontal connections and the modulation of model updating, converging experimental evidence suggests that working models of the environment are reflected by ACC activity. Activity in the ACC has been shown to correlate to many factors relevant to the maintenance of a generative model, including reward magnitude and probability (for review see [<xref ref-type="bibr" rid="pcbi.1006267.ref032">32</xref>]), estimation of the value of action sequences and subsequent prediction errors [<xref ref-type="bibr" rid="pcbi.1006267.ref033">33</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref034">34</xref>] and the value of switching behavioural strategies [<xref ref-type="bibr" rid="pcbi.1006267.ref035">35</xref>]. Marked changes in activity in ACC have been observed at times thought to coincide with significant model updating and occur in parallel with explorative behaviour–an event that has been directly linked to increased input from locus coeruleus [<xref ref-type="bibr" rid="pcbi.1006267.ref003">3</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref036">36</xref>]. Similarly, a direct ACC/ LC connection has also been found in response to task conflicts [<xref ref-type="bibr" rid="pcbi.1006267.ref037">37</xref>]. ACC activity is also correlated with learning rate during times of volatility, such that when the statistics of the environment change, more recent observations are weighted more heavily in preference to historical information [<xref ref-type="bibr" rid="pcbi.1006267.ref038">38</xref>]. This evidence provides a solid foundation for the hypothesis that the LC modulates learning rate by governing model updating via ACC. Specifically, we propose that the release of noradrenaline would cause a temporary increase in the susceptibility of model-holding networks to new information. At a cellular level, this would lead to NA effectively breaking and reshaping connections amongst cell assemblies.</p>
<p>In vitro investigation of the cellular effects of noradrenaline provides support for this idea, indicating that noradrenaline may suppress intrinsic connectivity of cortical neurons, causing a relative enhancement of afferent input [<xref ref-type="bibr" rid="pcbi.1006267.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref039">39</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref040">40</xref>]. Sara [<xref ref-type="bibr" rid="pcbi.1006267.ref041">41</xref>] and Harley [<xref ref-type="bibr" rid="pcbi.1006267.ref042">42</xref>] also suggest that LC spiking synchronises oscillations at theta and gamma frequencies, allowing effective transfer of information between brain regions during periods of LC activity. This may allow enhanced updating of existing models with more recent observations. A role for the LC in prioritising recent observations during times of environmental volatility has been explicitly suggested experimentally [<xref ref-type="bibr" rid="pcbi.1006267.ref043">43</xref>] and is supported by evidence regarding the critical role of LC activation in reversal learning, e.g. [<xref ref-type="bibr" rid="pcbi.1006267.ref044">44</xref>].</p>
<p>We note that if the LC is indeed responding to state-action prediction errors, model updating is likely not the only functionality it has. For instance, LC activation has been experimentally linked to the potentiation of memory formation [<xref ref-type="bibr" rid="pcbi.1006267.ref041">41</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref045">45</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref046">46</xref>], analgesic effects [<xref ref-type="bibr" rid="pcbi.1006267.ref047">47</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref048">48</xref>] and changes to sensory perception for stimuli occurring at the time of LC activation [<xref ref-type="bibr" rid="pcbi.1006267.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref049">49</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref050">50</xref>]. These are all reasonable responses to a large state-action prediction error: the increase in gain on sensory input may ensure that salient stimuli are more easily detectable in the future, whilst enhanced formation of memory might ensure that mappings between salient stimuli and states are remembered over longer timeframes. Similarly, the temporary suppression of pain may facilitate urgent physical responses to important stimuli (for instance, allowing action in response to a stimulus indicating the presence of a predator). The possibility that the LC has the capacity to provide a differentiated response to state-action prediction error is supported by recent work indicating that existence of distinct subunits with preferred targets producing different functional effects [<xref ref-type="bibr" rid="pcbi.1006267.ref048">48</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref051">51</xref>–<xref ref-type="bibr" rid="pcbi.1006267.ref053">53</xref>].</p>
</sec>
<sec id="sec014">
<title>Relationship to existing models of LC function</title>
<p>The ideas described above are not a radical departure from existing models of LC function–but use the theory of active inference to integrate similar concepts into a general theory of brain function, without invoking the need for monitoring of ad-hoc statistical quantities.</p>
<p>The adaptive gain theory proposed by Aston Jones and Cohen [<xref ref-type="bibr" rid="pcbi.1006267.ref004">4</xref>] proposes that the LC responds to ongoing assessments of utility in OFC and ACC by altering the global ‘gain’ of the brain (the responsivity of individual units). Phasic activation produces a widespread increase in gain which enables a more efficient behavioural response following a task-related decision; however, when the utility of a task decreases, the LC switches to a tonic mode which favours task disengagement and a switch from ‘exploit’ to ‘explore’.</p>
<p>The mechanism we have described reproduces many elements of the adaptive gain theory, with the important exception that different LC firing patterns promoting explorative or exploitative behaviour are an emergent property of the model rather than a dichotomy imposed by design. Since the probability assigned to individual policies is explicitly dependent on their utility (in combination with their epistemic value) a large state-action prediction error will ultimately reflect changes in the availability of policies which lead to high utility outcomes. This may be a positive change, as is the case when a cue indicates that a ‘Go’ policy will secure a reward, or a negative change, when rewards are no longer available in the explore/exploit task. This link is demonstrated in <xref ref-type="fig" rid="pcbi.1006267.g006">Fig 6</xref> for the explore/exploit task, where increases in state-action prediction error / LC firing occur in tandom with abrupt changes in the agent's assessment of a given policy's utility. Both the LC response, and the underlying cause (state-action prediction error), show a shift between ‘phasic’ and ‘tonic’ modes (although it is entirely possible that coupling mechanisms within the LC also act to exaggerate the shift and cause the LC to fire in a more starkly bi-modal fashion, as suggested by computational modelling of the LC [<xref ref-type="bibr" rid="pcbi.1006267.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref054">54</xref>]). As described above, a short prediction error will act to heighten the response to a salient cue over the short term, whilst a large, sustained prediction error–occurring in parallel with declining utility in a task–will act to make behaviour more exploratory.</p>
<p>Yu and Dayan have proposed an alternative model where tonic noradrenaline is a signal of ‘unexpected uncertainty’, when large changes in environment produce observations which strongly violate expectations [<xref ref-type="bibr" rid="pcbi.1006267.ref005">5</xref>]. This is described as a ‘global model failure signal’ and leads to enhancement of bottom-up sensory information. We have focused on a similar ‘model failure’ signal which allows larger changes to learning about the structure of the model itself–but using the inferences of states within AI as our driver, avoiding explicit tracking of the statistics of ‘unexpected uncertainty’. Rather, we compute model failure in terms of ‘everyday’ errors in predicted actions and sensations. Our model is also in line with the ‘network reset’ theory proposed by Bouret et al, in which LC phasic activation promotes rapid re-organisation of neural networks to accomplish shifts in behavioural mode [<xref ref-type="bibr" rid="pcbi.1006267.ref010">10</xref>], see also [<xref ref-type="bibr" rid="pcbi.1006267.ref009">9</xref>]. Large changes in configuration of the state-action heatmap alongside the updates to internal models above would similarly constitute network re-organisations with the result of changing behaviour. Importantly, state-action updates precede action selection, placing LC activation after decision making / classification of stimuli, but before the behavioural response. This order of events is in keeping with experimental evidence showing that LC responses do indeed consistently precede behavioural responses [<xref ref-type="bibr" rid="pcbi.1006267.ref013">13</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref055">55</xref>]. This also parallels the ‘neural interrupt’ model of phasic noradrenaline proposed by Dayan and Yu [<xref ref-type="bibr" rid="pcbi.1006267.ref056">56</xref>], in which uncertainties over states within a task are signalled by phasic bursts of noradrenaline, causing an interrupt signal during which new states can be adopted.</p>
<p>More recently Parr et al have described an alternative active inference-based model of noradrenaline in decision making [<xref ref-type="bibr" rid="pcbi.1006267.ref057">57</xref>]. Under this model, noradrenaline and acetylcholine are related to the precision assigned to beliefs about outcomes and beliefs about state transitions. That is, the agent assigns a different weight to any inferences made using the <bold>A</bold> matrix (modulated by release of acetylcholine) or the <bold>B</bold> matrix (modulated by noradrenaline) in its updates. This approach captures some of the interplay between environmental uncertainty and release of noradrenaline. Our formulation also speaks to these uncertainties–without the need to introduce new volatility parameters, or to segregate cholinergic / noradrenergic response into separate modulators of likelihood and transition (i.e., <bold>A</bold> and <bold>B</bold> matrices). Both approaches target the coding of contingencies in terms of connectivity (i.e., probability matrices). Parr et al consider the optimisation of the precision of contingencies. Conversely, we consider the optimisation of precision from the point of view of optimal learning rates. In other words, the confidence or precision of beliefs about outcomes likelihoods and state transitions can itself be optimised based on inference (about states) or learning (about parameters) in the generative model.</p>
<p>The key contribution of the current work is to link inference to the precision of beliefs about parameters via learning. This addresses the issue of how model parameters are learned and updated and allows an AI agent to make substantial changes to the architecture of its model in times when environmental rules have shifted. The ensuing behaviour produces the archetypal phasic-tonic shifts in LC dynamics, and links LC responses to the outcome of decision on stimuli, as suggested by in-vivo recordings; summaries of which can be found in [<xref ref-type="bibr" rid="pcbi.1006267.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006267.ref011">11</xref>].</p>
<p>The difference between these two applications of Active Inference illustrates a broader point about the way in which the theory is used to describe neuromodulation. Current versions of Active Inference have conceived of neuromodulatory systems as reflections of precision, altering the weights assigned to components of the agent’s model <italic>during</italic> a continuous cycle of updates. This underlying modulation is capable of drastically altering the inferences the agent makes about likely states and actions. Here we have offered a different view, in which noradrenaline is proposed to respond to the <italic>outcome</italic> of an update cycle. This enables us to endow an active inference agent with a noradrenergic response which relates activity in the locus coeruleus to the outcome of decisions and to subsequent changes to action planning. These responses are then linked back to changes in the underlying structure of the agent’s model–again outside of the cycle of inferences. Placing such responses above the update cycle moves them closer to the level of action selection and allows us to reproduce many aspects of LC dynamics observed empirically.</p>
<p>Once validated through experimental work, models of this type can provide insight into symptoms of disorders which have been linked to LC dysfunction. For example, attention deficit hyperactivity disorder (ADHD), which is characterised by inattention and hyperactivity, has been associated with elevated tonic LC activity [<xref ref-type="bibr" rid="pcbi.1006267.ref001">1</xref>]. Under our model, high tonic firing rates would cause a persistently high ‘model decay’. This would cause similar outcomes to those demonstrated for the hyper-flexible explore/exploit agent (<xref ref-type="fig" rid="pcbi.1006267.g007">Fig 7</xref>), which cannot build a stable structured model of the environment and reacts to even minor violations of predictions by changing its behavioural strategy. Pharmacological interventions which lower tonic LC firing rates may ameliorate symptoms by allowing structured models to emerge, guiding appropriate phasic responses and producing more focused behavioural strategies.</p>
<p>Several lines of future work are available to test components of the state-action prediction error / LC theory. Firstly, a clearer understanding of the drivers of LC responses could be pursued through in-vivo recordings in PFC, ACC and LC. This would help to confirm if calculations of state-action prediction error (or utility/estimation uncertainty, under other theories) originate in frontal cortex, rather than being calculated in the LC itself or elsewhere. Simultaneous recordings with high temporal resolution in-vivo will also help to delineate cause and effect in frontal cortex/LC interactions and will complement the accumulating data from human fMRI / pupillometry. Specific details of the above theory could then be tested; for example, in comparing the predictions for an LC driven purely by consideration of utility or estimation uncertainty, rather than by a state-prediction error as prescribed by Free Energy-based estimates. In-vivo recordings during the two tasks described here could also be examined for the characteristic patterns. For instance, in the pattern of LC firing predicted for the explore/exploit task, the above modelling shows a sudden transition to a higher tonic level of activity during a change in the environmental statistics, and a much slower decay of activity occurring as rules stabilise. Triggering or blocking such patterns of firing during task performance would be particularly revealing regarding the proposed role of the LC.</p>
<p>Finally, we have not addressed the role of other neuromodulators that have related effects on behaviour. Whilst dopamine is explicitly included in Active Inference models as a precision parameter, other neuromodulators (e.g. serotonin) do not yet have a clear place within the model. Understanding the interplay between these systems will be crucial for placing LC activity in context—and will enable the explanatory power of Active Inference to be fully harnessed.</p>
</sec>
</sec>
<sec id="sec015">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006267.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.s001" xlink:type="simple">
<label>S1 Appendix</label>
<caption>
<title>Derivations of Active Inference update equations and expressions for state-action prediction errors and model decay.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006267.s002" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.s002" xlink:type="simple">
<label>S2 Appendix</label>
<caption>
<title>‘Pseudocode’ overview of the implementation of the Active Inference model.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006267.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.s003" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Bayesian dependency graph showing the overall generative model employed during decision making.</title>
<p>First the free energy and expected free energy of policies is evaluated. Next these serve as priors on the probability of a policy, which in turn leads to a selected action, state transitions and outcomes. In Appendix 1 we provide a full description of the model.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006267.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.s004" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Full plots of state-action prediction error, behaviour and simulated LC firing in tasks performed by the agent with a flexible <italic>α</italic>.</title>
<p>(a) shows the performance of the agent in the go/no-go task. The prediction error output is similar in form to the output from the task played by the agent with <italic>α</italic> = 16 in <xref ref-type="fig" rid="pcbi.1006267.g005">Fig 5</xref>, except for the more pronounced reduction in the size of the state-action prediction error peaks in response to consecutive cues. (b) shows the performance during the explore/exploit task with the same parameters as in <xref ref-type="fig" rid="pcbi.1006267.g007">Fig 7(A) and 7(B)</xref>, that is, a with changes in the location of the high probability arm (p = 0.7) every 50 trials.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006267.s005" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006267.s005" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Characteristics of state-action prediction error peak responses during the no-go trial for different fixed <italic>α</italic> agents.</title>
<p>All plots show averages over 2000 trials. (a) shows the changes in prediction error peak responses during either ‘go’ (marked ‘G’) cues or ‘no-go’ (marked ‘NG’) cues. All agents display a larger ‘go’ response for rarer cues. Additionally, responses for ‘go’ cues are consistently larger than those for ‘no-go’ cues when the ‘go’ is more probable than, or equally probable as, the ‘no-go’ cue. This effect persists up to a ‘go’ probability of 55%. When the probability of the cue is increased further, the peaks are equal in size or reversed. (b) shows the effect of changing the reward size. As in <xref ref-type="fig" rid="pcbi.1006267.g008">Fig 8</xref>, all agents display a larger state-action prediction error response when the reward is larger. (c) shows the reduction in peak size caused by presenting ‘go’ cues consecutively. This reduction is greater for the more flexible (lower <italic>α</italic>) agents, reflecting the larger changes to the agent’s model caused by the consecutive ‘go’ cues.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1006267.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berridge</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Waterhouse</surname> <given-names>BD</given-names></name>. <article-title>The locus coeruleus–noradrenergic system: modulation of behavioral state and state-dependent cognitive processes</article-title>. <source>Brain Res Rev</source>. <year>2003</year>;<volume>42</volume>(<issue>1</issue>):<fpage>33</fpage>–<lpage>84</lpage>. <object-id pub-id-type="pmid">12668290</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Foote</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Bloom</surname> <given-names>FE</given-names></name>, <name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>. <article-title>Nucleus locus ceruleus: new evidence of anatomical and physiological specificity</article-title>. <source>Physiol Rev</source>. <year>1983</year> <month>Jul</month>;<volume>63</volume>(<issue>3</issue>):<fpage>844</fpage>–<lpage>914</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/physrev.1983.63.3.844" xlink:type="simple">10.1152/physrev.1983.63.3.844</ext-link></comment> <object-id pub-id-type="pmid">6308694</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tervo</surname> <given-names>DGR</given-names></name>, <name name-style="western"><surname>Proskurin</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Manakov</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kabra</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Vollmer</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Branson</surname> <given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Behavioral variability through stochastic choice and its gating by anterior cingulate cortex</article-title>. <source>Cell</source>. <year>2014</year>;<volume>159</volume>(<issue>1</issue>):<fpage>21</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cell.2014.08.037" xlink:type="simple">10.1016/j.cell.2014.08.037</ext-link></comment> <object-id pub-id-type="pmid">25259917</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>AN INTEGRATIVE THEORY OF LOCUS COERULEUS-NOREPINEPHRINE FUNCTION: Adaptive Gain and Optimal Performance</article-title>. <source>Annu Rev Neurosci</source>. <year>2005</year> <month>Jul</month> <day>21</day>;<volume>28</volume>(<issue>1</issue>):<fpage>403</fpage>–<lpage>50</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006267.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yu</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Expected and unexpected uncertainty: ACh and NE in the neocortex</article-title>. <source>Adv neural Inf Process</source> …. <year>2003</year>;<volume>15</volume>:<fpage>157</fpage>–<lpage>64</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006267.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rajkowski</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kubiak</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Alexinsky</surname> <given-names>T</given-names></name>. <article-title>Locus Coeruleus Neurons in Monkey Are Selectively Activated by Attended Cues in a Vigilance Task</article-title>. <source>J Neurosci</source>. <year>1994</year>;<volume>14</volume>(<issue>7</issue>):<fpage>4467</fpage>–<lpage>4460</lpage>. <object-id pub-id-type="pmid">8027789</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Bloom</surname> <given-names>FE</given-names></name>. <article-title>Norepinephrine-containing locus coeruleus neurons in behaving rats exhibit pronounced responses to non-noxious environmental stimuli</article-title>. <source>J Neurosci</source>. 1981/08/01. <year>1981</year>;<volume>1</volume>(<issue>8</issue>):<fpage>887</fpage>–<lpage>900</lpage>. <object-id pub-id-type="pmid">7346593</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bouret</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Richmond</surname> <given-names>BJ</given-names></name>. <article-title>Sensitivity of Locus Ceruleus Neurons to Reward Value for Goal-Directed Actions</article-title>. <source>J Neurosci</source>. <year>2015</year>;<volume>35</volume>(<issue>9</issue>):<fpage>4005</fpage>–<lpage>14</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.4553-14.2015" xlink:type="simple">10.1523/JNEUROSCI.4553-14.2015</ext-link></comment> <object-id pub-id-type="pmid">25740528</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>AJ</given-names></name>. <article-title>Phasic norepinephrine: A neural interrupt signal for unexpected events</article-title>. <source>Netw Comput Neural Syst December</source>. <year>2006</year>;<volume>17</volume>(<issue>4</issue>):<fpage>335</fpage>–<lpage>50</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006267.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bouret</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sara</surname> <given-names>SJ</given-names></name>. <article-title>Network reset: A simplified overarching theory of locus coeruleus noradrenaline function</article-title>. Vol. <volume>28</volume>, <source>Trends in Neurosciences</source>. <year>2005</year>. p. <fpage>574</fpage>–<lpage>82</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2005.09.002" xlink:type="simple">10.1016/j.tins.2005.09.002</ext-link></comment> <object-id pub-id-type="pmid">16165227</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nieuwenhuis</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>Decision making, the P3, and the locus coeruleus—norepinephrine system</article-title>. <source>Psychol Bull</source>. <year>2005</year>;<volume>131</volume>(<issue>4</issue>):<fpage>510</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-2909.131.4.510" xlink:type="simple">10.1037/0033-2909.131.4.510</ext-link></comment> <object-id pub-id-type="pmid">16060800</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Bloom</surname> <given-names>FE</given-names></name>. <article-title>Activity of norepinephrine-containing locus coeruleus neurons in behaving rats anticipates fluctuations in the sleep-waking cycle</article-title>. <source>J Neurosci</source>. <year>1981</year> <month>Aug</month>;<volume>1</volume>(<issue>8</issue>):<fpage>876</fpage>–<lpage>86</lpage>. <object-id pub-id-type="pmid">7346592</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bouret</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sara</surname> <given-names>SJ</given-names></name>. <article-title>Reward expectation, orientation of attention and locus coeruleus-medial frontal cortex interplay during learning</article-title>. <source>Eur J Neurosci</source>. <year>2004</year> <month>Aug</month> <day>1</day>;<volume>20</volume>(<issue>3</issue>):<fpage>791</fpage>–<lpage>802</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1460-9568.2004.03526.x" xlink:type="simple">10.1111/j.1460-9568.2004.03526.x</ext-link></comment> <object-id pub-id-type="pmid">15255989</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>FitzGerald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Schwartenbeck</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Pezzulo</surname> <given-names>G</given-names></name>. <article-title>Active Inference: A Process Theory</article-title>. <source>Neural Comput</source>. <year>2017</year> <month>Jan</month>;<volume>29</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>49</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/NECO_a_00912" xlink:type="simple">10.1162/NECO_a_00912</ext-link></comment> <object-id pub-id-type="pmid">27870614</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Schwartenbeck</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Fitzgerald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Moutoussis</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>The anatomy of choice: active inference and agency</article-title>. <source>Front Hum Neurosci</source>. <year>2013</year>;<volume>7</volume>(<month>September</month>):<fpage>598</fpage>.</mixed-citation></ref>
<ref id="pcbi.1006267.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwartenbeck</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>FitzGerald</surname> <given-names>THB</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kronbichler</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>. <article-title>Evidence for surprise minimization over value maximization in choice behavior</article-title>. <source>Sci Rep</source>. <year>2015</year> <month>Nov</month> <day>13</day>;<volume>5</volume>:<fpage>16575</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/srep16575" xlink:type="simple">10.1038/srep16575</ext-link></comment> <object-id pub-id-type="pmid">26564686</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwartenbeck</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>FitzGerald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>. <article-title>Exploration, novelty, surprise, and free energy minimization</article-title>. <source>Front Psychol</source>. <year>2013</year>;<volume>4</volume>:<fpage>710</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2013.00710" xlink:type="simple">10.3389/fpsyg.2013.00710</ext-link></comment> <object-id pub-id-type="pmid">24109469</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Ognibene</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fitzgerald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Pezzulo</surname> <given-names>G</given-names></name>. <article-title>Cognitive Neuroscience Active inference and epistemic value</article-title>. <source>Cogn Neurosci</source>. <year>2015</year>;</mixed-citation></ref>
<ref id="pcbi.1006267.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Schwartenbeck</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>FitzGerald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Moutoussis</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>The anatomy of choice: dopamine and decision-making</article-title>. <source>Phil Trans R Soc B</source>. <year>2014</year>;<volume>369</volume>(<issue>1655</issue>):<fpage>20130481</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rstb.2013.0481" xlink:type="simple">10.1098/rstb.2013.0481</ext-link></comment> <object-id pub-id-type="pmid">25267823</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Fitzgerald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Schwartenbeck</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>O ‘doherty</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Pezzulo</surname> <given-names>G</given-names></name>. <article-title>Active inference and learning</article-title>. <source>Neurosci Biobehav Rev</source>. <year>2016</year>;<volume>68</volume>:<fpage>862</fpage>–<lpage>79</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neubiorev.2016.06.022" xlink:type="simple">10.1016/j.neubiorev.2016.06.022</ext-link></comment> <object-id pub-id-type="pmid">27375276</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>. <article-title>A Bayesian foundation for individual learning under uncertainty</article-title>. <source>Front Hum Neurosci</source>. <year>2011</year>;<volume>5</volume>:<fpage>39</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2011.00039" xlink:type="simple">10.3389/fnhum.2011.00039</ext-link></comment> <object-id pub-id-type="pmid">21629826</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rajkowski</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kubiak</surname> <given-names>P</given-names></name>. <article-title>Conditioned responses of monkey locus coeruleus neurons anticipate acquisition of discriminative behavior in a vigilance task</article-title>. <source>Neuroscience</source>. <year>1997</year>;<volume>80</volume>(<issue>3</issue>):<fpage>697</fpage>–<lpage>715</lpage>. <object-id pub-id-type="pmid">9276487</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Foote</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Bloom</surname> <given-names>FE</given-names></name>. <article-title>Impulse activity of locus coeruleus neurons in awake rats and monkeys is a function of sensory stimulation and arousal</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1980</year> <month>May</month> <day>1</day>;<volume>77</volume>(<issue>5</issue>):<fpage>3033</fpage>–<lpage>7</lpage>. <object-id pub-id-type="pmid">6771765</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gilzenrat</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Nieuwenhuis</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Jepma</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>Pupil diameter tracks changes in control state predicted by the adaptive gain theory of locus coeruleus function</article-title>. <source>Cogn Affect Behav Neurosci</source>. <year>2010</year> <month>Jun</month>;<volume>10</volume>(<issue>2</issue>):<fpage>252</fpage>–<lpage>69</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/CABN.10.2.252" xlink:type="simple">10.3758/CABN.10.2.252</ext-link></comment> <object-id pub-id-type="pmid">20498349</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jepma</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Nieuwenhuis</surname> <given-names>S</given-names></name>. <article-title>Pupil Diameter Predicts Changes in the Exploration?Exploitation Trade-off: Evidence for the Adaptive Gain Theory</article-title>. <source>J Cogn Neurosci</source>. <year>2011</year> <month>Jul</month> <day>10</day>;<volume>23</volume>(<issue>7</issue>):<fpage>1587</fpage>–<lpage>96</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn.2010.21548" xlink:type="simple">10.1162/jocn.2010.21548</ext-link></comment> <object-id pub-id-type="pmid">20666595</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Preuschoff</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>BM</surname> <given-names>‘t Hart</given-names></name>, <name name-style="western"><surname>Einhauser</surname> <given-names>W</given-names></name>. <article-title>Pupil dilation signals surprise: evidence for noradrenaline’s role in decision making</article-title>. <source>Front Neurosci</source>. <year>2011</year> <month>Sep</month> <day>30</day>;<volume>5</volume>:<fpage>115</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnins.2011.00115" xlink:type="simple">10.3389/fnins.2011.00115</ext-link></comment> <object-id pub-id-type="pmid">21994487</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nassar</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Rumsey</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Parikh</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Heasly</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>. <article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title>. <source>Nat Neurosci</source>. <year>2012</year> <month>Jul</month> <day>3</day>;<volume>15</volume>(<issue>7</issue>):<fpage>1040</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3130" xlink:type="simple">10.1038/nn.3130</ext-link></comment> <object-id pub-id-type="pmid">22660479</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kalwani</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Joshi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>. <article-title>Phasic activation of individual neurons in the locus ceruleus/subceruleus complex of monkeys reflects rewarded decisions to go but not stop</article-title>. <source>J Neurosci</source>. <year>2014</year> <month>Oct</month> <day>8</day>;<volume>34</volume>(<issue>41</issue>):<fpage>13656</fpage>–<lpage>69</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2566-14.2014" xlink:type="simple">10.1523/JNEUROSCI.2566-14.2014</ext-link></comment> <object-id pub-id-type="pmid">25297093</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Arnsten</surname> <given-names>AF</given-names></name>, <name name-style="western"><surname>Goldman-Rakic</surname> <given-names>PS</given-names></name>. <article-title>Selective prefrontal cortical projections to the region of the locus coeruleus and raphe nuclei in the rhesus monkey</article-title>. <source>Brain Res</source>. <year>1984</year> <month>Jul</month> <day>23</day>;<volume>306</volume>(<issue>1–2</issue>):<fpage>9</fpage>–<lpage>18</lpage>. <object-id pub-id-type="pmid">6466989</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jodo</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Chiang</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>. <article-title>Potent excitatory influence of prefrontal cortex activity on noradrenergic locus coeruleus neurons</article-title>. <source>Neuroscience</source>. <year>1998</year> <month>Mar</month>;<volume>83</volume>(<issue>1</issue>):<fpage>63</fpage>–<lpage>79</lpage>. <object-id pub-id-type="pmid">9466399</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gläscher</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>. <article-title>States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning</article-title>. <source>Neuron</source>. <year>2010</year> <month>May</month> <day>27</day>;<volume>66</volume>(<issue>4</issue>):<fpage>585</fpage>–<lpage>95</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2010.04.016" xlink:type="simple">10.1016/j.neuron.2010.04.016</ext-link></comment> <object-id pub-id-type="pmid">20510862</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rushworth</surname> <given-names>MFS</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>TEJ</given-names></name>. <article-title>Choice, uncertainty and value in prefrontal and cingulate cortex</article-title>. <source>Nat Neurosci</source>. <year>2008</year> <month>Apr</month> <day>26</day>;<volume>11</volume>(<issue>4</issue>):<fpage>389</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn2066" xlink:type="simple">10.1038/nn2066</ext-link></comment> <object-id pub-id-type="pmid">18368045</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Matsumoto</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Matsumoto</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Abe</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>K</given-names></name>. <article-title>Medial prefrontal cell activity signaling prediction errors of action values</article-title>. <source>Nat Neurosci</source>. <year>2007</year> <month>May</month> <day>22</day>;<volume>10</volume>(<issue>5</issue>):<fpage>647</fpage>–<lpage>56</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1890" xlink:type="simple">10.1038/nn1890</ext-link></comment> <object-id pub-id-type="pmid">17450137</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holroyd</surname> <given-names>CB</given-names></name>, <name name-style="western"><surname>Yeung</surname> <given-names>N</given-names></name>. <article-title>Motivation of extended behaviors by anterior cingulate cortex</article-title>. <source>Trends Cogn Sci</source>. <year>2011</year>;<volume>16</volume>:<fpage>121</fpage>–<lpage>7</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006267.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hayden</surname> <given-names>BY</given-names></name>, <name name-style="western"><surname>Pearson</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Platt</surname> <given-names>ML</given-names></name>. <article-title>Neuronal basis of sequential foraging decisions in a patchy environment</article-title>. <source>Nat Neurosci</source>. <year>2011</year> <month>Jul</month> <day>5</day>;<volume>14</volume>(<issue>7</issue>):<fpage>933</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2856" xlink:type="simple">10.1038/nn.2856</ext-link></comment> <object-id pub-id-type="pmid">21642973</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Karlsson</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Tervo</surname> <given-names>DGR</given-names></name>, <name name-style="western"><surname>Karpova</surname> <given-names>AY</given-names></name>. <article-title>Network Resets in Medial Prefrontal Cortex Mark the Onset of Behavioral Uncertainty</article-title>. <source>Science</source> (80-). <year>2012</year>;<volume>338</volume>(<issue>6103</issue>):<fpage>135</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006267.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ebitz</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Platt</surname> <given-names>ML</given-names></name>. <article-title>Neuronal activity in primate dorsal anterior cingulate cortex signals task conflict and predicts adjustments in pupil-linked arousal</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>85</volume>(<issue>3</issue>):<fpage>628</fpage>–<lpage>40</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2014.12.053" xlink:type="simple">10.1016/j.neuron.2014.12.053</ext-link></comment> <object-id pub-id-type="pmid">25654259</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Behrens</surname> <given-names>TEJ</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Walton</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MFS</given-names></name>. <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source>. <year>2007</year> <month>Sep</month> <day>5</day>;<volume>10</volume>(<issue>9</issue>):<fpage>1214</fpage>–<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1954" xlink:type="simple">10.1038/nn1954</ext-link></comment> <object-id pub-id-type="pmid">17676057</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hasselmo</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Linster</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Patil</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Cekic</surname> <given-names>M</given-names></name>. <article-title>Noradrenergic Suppression of Synaptic Transmission May Influence Cortical Signal-to-Noise Ratio</article-title>. <source>J Neurophysiol</source>. <year>1997</year> <month>Jun</month>;<volume>77</volume>(<issue>6</issue>):<fpage>3326</fpage>–<lpage>39</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1997.77.6.3326" xlink:type="simple">10.1152/jn.1997.77.6.3326</ext-link></comment> <object-id pub-id-type="pmid">9212278</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref040"><label>40</label><mixed-citation publication-type="other" xlink:type="simple">Kobayashi M, Imamura K, Sugai T, Onoda N, Yamamoto M, Komai S, et al. Selective suppression of horizontal propagation in rat visual cortex by norepinephrine.</mixed-citation></ref>
<ref id="pcbi.1006267.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sara</surname> <given-names>SJ</given-names></name>, J. S. <article-title>Locus Coeruleus in time with the making of memories</article-title>. <source>Curr Opin Neurobiol</source>. <year>2015</year> <month>Dec</month>;<volume>35</volume>:<fpage>87</fpage>–<lpage>94</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2015.07.004" xlink:type="simple">10.1016/j.conb.2015.07.004</ext-link></comment> <object-id pub-id-type="pmid">26241632</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Walling</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>RAM</given-names></name>, <name name-style="western"><surname>Milway</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Earle</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Harley</surname> <given-names>CW</given-names></name>. <article-title>Selective tuning of hippocampal oscillations by phasic locus coeruleus activation in awake male rats</article-title>. <source>Hippocampus</source>. <year>2011</year> <source>Nov</source>;<volume>21</volume>(<issue>11</issue>):<fpage>1250</fpage>–<lpage>62</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hipo.20816" xlink:type="simple">10.1002/hipo.20816</ext-link></comment> <object-id pub-id-type="pmid">20865739</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nassar</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Rumsey</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Parikh</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Heasly</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>. <article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title>. <source>Nat Neurosci</source>. <year>2012</year>;</mixed-citation></ref>
<ref id="pcbi.1006267.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rorabaugh</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Chalermpalanupap</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Botz-Zapp</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Fu</surname> <given-names>VM</given-names></name>, <name name-style="western"><surname>Lembeck</surname> <given-names>NA</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>RM</given-names></name>, <etal>et al</etal>. <article-title>Chemogenetic locus coeruleus activation restores reversal learning in a rat model of Alzheimer’s disease</article-title>. <source>Brain</source>. <year>2017</year> <month>Nov</month> <day>1</day>;<volume>140</volume>(<issue>11</issue>):<fpage>3023</fpage>–<lpage>38</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/brain/awx232" xlink:type="simple">10.1093/brain/awx232</ext-link></comment> <object-id pub-id-type="pmid">29053824</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Takeuchi</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Duszkiewicz</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Sonneborn</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Spooner</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Yamasaki</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Watanabe</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Locus coeruleus and dopaminergic consolidation of everyday memory Studies of memory for over a century</article-title>. <source>Nature</source>. <year>2016</year>;<volume>537</volume>:<fpage>5</fpage>–<lpage>7</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006267.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wagatsuma</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Okuyama</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sun</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Abe</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Tonegawa</surname> <given-names>S</given-names></name>. <article-title>Locus coeruleus input to hippocampal CA3 drives single-trial learning of a novel context</article-title>. <source>Proc Natl Acad Sci</source>. <year>2018</year> <month>Jan</month> <day>9</day>;<volume>115</volume>(<issue>2</issue>):<fpage>E310</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1714082115" xlink:type="simple">10.1073/pnas.1714082115</ext-link></comment> <object-id pub-id-type="pmid">29279390</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hickey</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Fyson</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Watson</surname> <given-names>TC</given-names></name>, <name name-style="western"><surname>Perrins</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Hewinson</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Optoactivation of locus ceruleus neurons evokes bidirectional changes in thermal nociception in rats</article-title>. <source>J Neurosci</source>. <year>2014</year>;<volume>34</volume>(<issue>12</issue>):<fpage>4148</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.4835-13.2014" xlink:type="simple">10.1523/JNEUROSCI.4835-13.2014</ext-link></comment> <object-id pub-id-type="pmid">24647936</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hirschberg</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Randall</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kremer</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Pickering</surname> <given-names>AE</given-names></name>. <article-title>Functional dichotomy in spinal- vs prefrontal-projecting locus coeruleus modules splits descending noradrenergic analgesia from ascending aversion and anxiety in rats</article-title>. <source>Elife</source>. <year>2017</year> <month>Oct</month> <day>13</day>;<volume>6</volume>.</mixed-citation></ref>
<ref id="pcbi.1006267.ref049"><label>49</label><mixed-citation publication-type="other" xlink:type="simple">Raquel A, Martins O, Froemke RC. Coordinated forms of noradrenergic plasticity in the locus coeruleus and primary auditory cortex.</mixed-citation></ref>
<ref id="pcbi.1006267.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hurley</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Devilbiss</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Waterhouse</surname> <given-names>B</given-names></name>. <article-title>A matter of focus: monoaminergic modulation of stimulus coding in mammalian sensory networks</article-title>. <source>Curr Opin Neurobiol</source>. <year>2004</year> <month>Aug</month> <day>1</day>;<volume>14</volume>(<issue>4</issue>):<fpage>488</fpage>–<lpage>95</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2004.06.007" xlink:type="simple">10.1016/j.conb.2004.06.007</ext-link></comment> <object-id pub-id-type="pmid">15321070</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kebschull</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Garcia Da Silva</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Reid</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Peikon</surname> <given-names>ID</given-names></name>, <name name-style="western"><surname>Albeanu</surname> <given-names>DF</given-names></name>, <name name-style="western"><surname>Zador Correspondence</surname> <given-names>AM</given-names></name>, <etal>et al</etal>. <article-title>High-Throughput Mapping of Single-Neuron Projections by Sequencing of Barcoded RNA NeuroResource High-Throughput Mapping of Single-Neuron Projections by Sequencing of Barcoded RNA</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>91</volume>:<fpage>975</fpage>–<lpage>87</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2016.07.036" xlink:type="simple">10.1016/j.neuron.2016.07.036</ext-link></comment> <object-id pub-id-type="pmid">27545715</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chandler</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Gao</surname> <given-names>W-J</given-names></name>, <name name-style="western"><surname>Waterhouse</surname> <given-names>BD</given-names></name>. <article-title>Heterogeneous organization of the locus coeruleus projections to prefrontal and motor cortices</article-title>. <source>Proc Natl Acad Sci</source>. <year>2014</year> <month>May</month> <day>6</day>;<volume>111</volume>(<issue>18</issue>):<fpage>6816</fpage>–<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1320827111" xlink:type="simple">10.1073/pnas.1320827111</ext-link></comment> <object-id pub-id-type="pmid">24753596</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Uematsu</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Tan</surname> <given-names>BZ</given-names></name>, <name name-style="western"><surname>Ycu</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Cuevas</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Koivumaa</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Junyent</surname> <given-names>F</given-names></name>, <etal>et al</etal>. <article-title>Modular organization of the brainstem noradrenaline system coordinates opposing learning states</article-title>. <source>Nat Neurosci</source>. <year>2017</year> <month>Sep</month> <day>18</day>;</mixed-citation></ref>
<ref id="pcbi.1006267.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Usher</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Servan-Schreiber</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Rajkowski</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>. <article-title>The Role of Locus Coeruleus in the Regulation of Cognitive Performance</article-title>. <source>Science</source> (80-). <year>1999</year>;<volume>283</volume>(<fpage>5401</fpage>).</mixed-citation></ref>
<ref id="pcbi.1006267.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Clayton</surname> <given-names>EC</given-names></name>, <name name-style="western"><surname>Rajkowski</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>. <article-title>Phasic Activation of Monkey Locus Ceruleus Neurons by Simple Decisions in a Forced-Choice Task</article-title>. <source>J Neurosci</source>. <year>2004</year> <month>Nov</month> <day>3</day>;<volume>24</volume>(<issue>44</issue>):<fpage>9914</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2446-04.2004" xlink:type="simple">10.1523/JNEUROSCI.2446-04.2004</ext-link></comment> <object-id pub-id-type="pmid">15525776</object-id></mixed-citation></ref>
<ref id="pcbi.1006267.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>AJ</given-names></name>. <article-title>Phasic norepinephrine: A neural interrupt signal for unexpected events</article-title>. <source>Netw Comput Neural Syst</source>. <year>2006</year> <month>Jan</month> <day>18</day>;<volume>17</volume>(<issue>4</issue>):<fpage>335</fpage>–<lpage>50</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006267.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Parr</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Uncertainty, epistemics and active inference</article-title>. <source>J R Soc Interface</source>. <year>2017</year> <month>Nov</month> <day>1</day>;<volume>14</volume>(<issue>136</issue>):<fpage>20170376</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rsif.2017.0376" xlink:type="simple">10.1098/rsif.2017.0376</ext-link></comment> <object-id pub-id-type="pmid">29167370</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
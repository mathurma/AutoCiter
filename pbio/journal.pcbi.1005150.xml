<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-16-00857</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005150</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject><subj-group><subject>Neuroanatomy</subject><subj-group><subject>Neural pathways</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject><subj-group><subject>Neuroanatomy</subject><subj-group><subject>Neural pathways</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroanatomy</subject><subj-group><subject>Neural pathways</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical noise</subject><subj-group><subject>Gaussian noise</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Signal processing</subject><subj-group><subject>Signal to noise ratio</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Ocular system</subject><subj-group><subject>Ocular anatomy</subject><subj-group><subject>Retina</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Ocular system</subject><subj-group><subject>Ocular anatomy</subject><subj-group><subject>Retina</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Information theory</subject><subj-group><subject>Source coding</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>How Do Efficient Coding Strategies Depend on Origins of Noise in Neural Circuits?</article-title>
<alt-title alt-title-type="running-head">How Efficient Coding Depends on Origins of Noise</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2572-8861</contrib-id>
<name name-style="western">
<surname>Brinkman</surname> <given-names>Braden A. W.</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Weber</surname> <given-names>Alison I.</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1052-2609</contrib-id>
<name name-style="western">
<surname>Rieke</surname> <given-names>Fred</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="fn" rid="econtrib001"><sup>‡</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Shea-Brown</surname> <given-names>Eric</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="fn" rid="econtrib001"><sup>‡</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Department of Applied Mathematics, University of Washington, Seattle, Washington, United States of America</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Physiology and Biophysics, University of Washington, Seattle, Washington, United States of America</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Graduate Program in Neuroscience, University of Washington, Seattle, Washington, United States of America</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>Howard Hughes Medical Institute, University of Washington, Seattle, Washington, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Beck</surname> <given-names>Jeff</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Duke University, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con">
<p><list list-type="simple"><list-item><p><bold>Conceived and designed the experiments:</bold> BAWB AIW FR ESB.</p></list-item> <list-item><p><bold>Performed the experiments:</bold> BAWB AIW.</p></list-item> <list-item><p><bold>Analyzed the data:</bold> BAWB AIW FR ESB.</p></list-item> <list-item><p><bold>Contributed reagents/materials/analysis tools:</bold> BAWB AIW.</p></list-item> <list-item><p><bold>Wrote the paper:</bold> BAWB AIW FR ESB.</p></list-item></list></p>
</fn>
<fn fn-type="other" id="econtrib001">
<p>‡FR and ESB also contributed equally to this work.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">bradenb@uw.edu</email> (BAWB); <email xlink:type="simple">aiweber@uw.edu</email> (AIW)</corresp>
</author-notes>
<pub-date pub-type="collection">
<month>10</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="epub">
<day>14</day>
<month>10</month>
<year>2016</year>
</pub-date>
<volume>12</volume>
<issue>10</issue>
<elocation-id>e1005150</elocation-id>
<history>
<date date-type="received">
<day>26</day>
<month>5</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>16</day>
<month>9</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Brinkman et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005150"/>
<abstract>
<p>Neural circuits reliably encode and transmit signals despite the presence of noise at multiple stages of processing. The efficient coding hypothesis, a guiding principle in computational neuroscience, suggests that a neuron or population of neurons allocates its limited range of responses as efficiently as possible to best encode inputs while mitigating the effects of noise. Previous work on this question relies on specific assumptions about where noise enters a circuit, limiting the generality of the resulting conclusions. Here we systematically investigate how noise introduced at different stages of neural processing impacts optimal coding strategies. Using simulations and a flexible analytical approach, we show how these strategies depend on the strength of each noise source, revealing under what conditions the different noise sources have competing or complementary effects. We draw two primary conclusions: (1) differences in encoding strategies between sensory systems—or even adaptational changes in encoding properties within a given system—may be produced by changes in the structure or location of neural noise, and (2) characterization of both circuit nonlinearities as well as noise are necessary to evaluate whether a circuit is performing efficiently.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>For decades the efficient coding hypothesis has been a guiding principle in determining how neural systems can most efficiently represent their inputs. However, conclusions about whether neural circuits are performing optimally depend on assumptions about the noise sources encountered by neural signals as they are transmitted. Here, we provide a coherent picture of how optimal encoding strategies depend on noise strength, type, location, and correlations. Our results reveal that nonlinearities that are efficient if noise enters the circuit in one location may be inefficient if noise actually enters in a different location. This offers new explanations for why different sensory circuits, or even a given circuit under different environmental conditions, might have different encoding properties.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>CRCNS-DMS-120827</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Shea-Brown</surname> <given-names>Eric</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>DGE-1256082</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Weber</surname> <given-names>Alison I.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000011</institution-id>
<institution>Howard Hughes Medical Institute</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1052-2609</contrib-id>
<name name-style="western">
<surname>Rieke</surname> <given-names>Fred</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution>Raymond and Beverly Sackler Scholars Program in Integrative Biophysics</institution>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2572-8861</contrib-id>
<name name-style="western">
<surname>Brinkman</surname> <given-names>Braden A. W.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award005">
<funding-source>
<institution>ARCS foundation</institution>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Weber</surname> <given-names>Alison I.</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>Support was provided by the National Science Foundation (<ext-link ext-link-type="uri" xlink:href="http://www.nsf.gov/" xlink:type="simple">http://www.nsf.gov/</ext-link>) via CRCNS-DMS-120827 and a Graduate Research Fellowship (Grant No. DGE-1256082 to AIW), by the Raymond and Beverly Sackler Scholars Program in Integrative Biophysics at the University of Washington (<ext-link ext-link-type="uri" xlink:href="http://depts.washington.edu/sacklers/" xlink:type="simple">http://depts.washington.edu/sacklers/</ext-link>) (BAWB), by the ARCS Foundation, Seattle Chapter (<ext-link ext-link-type="uri" xlink:href="https://www.arcsfoundation.org/seattle/" xlink:type="simple">https://www.arcsfoundation.org/seattle/</ext-link>) (AIW), and by the Howard Hughes Medical Institute (<ext-link ext-link-type="uri" xlink:href="http://www.hhmi.org/" xlink:type="simple">http://www.hhmi.org/</ext-link>) (FR). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="4"/>
<page-count count="34"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Code used in this study is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/bradenbrinkman/optimalencoders" xlink:type="simple">https://github.com/bradenbrinkman/optimalencoders</ext-link>. Parameters used in simulations are contained within the paper.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Our sensory systems encode information about the external environment and transmit this information to higher brain areas with remarkable fidelity, despite a number of sources of noise that corrupt the incoming signal. Noise—variability in neural responses that masks the relevant signal—can arise from the external inputs to the nervous system (e.g., in stochastic arrival of photons at the retina, which follow Poisson statistics) and from properties intrinsic to the nervous system, such as variability in channel gating, vesicle release, and neurotransmitter diffusion (reviewed in [<xref ref-type="bibr" rid="pcbi.1005150.ref001">1</xref>]). This noise places fundamental limits on the accuracy with which information can be encoded by a cell or population [<xref ref-type="bibr" rid="pcbi.1005150.ref002">2</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref005">5</xref>]. An equally important consideration, however, is that noise dictates which processing strategies adopted by the nervous system will be most effective in transmitting signal relative to noise.</p>
<p>Efficient coding theory has been an important principle in the study of neuroscience for over half a century, and a number of studies have found that neural circuits can encode and transmit as much useful information as possible given physical and physiological constraints [<xref ref-type="bibr" rid="pcbi.1005150.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref013">13</xref>]. Foundational work by Laughlin successfully predicted the function by which an interneuron in the blowfly eye transformed its inputs [<xref ref-type="bibr" rid="pcbi.1005150.ref007">7</xref>]. This and other early work prompted a myriad of studies that considered how neurons could make the most efficient use of their output range in a variety of systems and stimulus conditions [<xref ref-type="bibr" rid="pcbi.1005150.ref014">14</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref019">19</xref>]. Efficient coding theory has played an important role in how we interpret biological systems. However, one cannot know how efficiently a neuron or population is encoding its inputs without understanding the sources of noise present in the system. Several previous studies have recognized noise as an important factor in determining optimal computations [<xref ref-type="bibr" rid="pcbi.1005150.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref021">21</xref>]. These and related studies of efficient coding often make strong assumptions about the location of noise in the system in question, and these assumptions are typically not based on direct measurements of the underlying noise sources. For example, noise is often assumed to arise at the output stage and follow Poisson statistics. Yet experimental evidence has shown that spike generation itself is near-deterministic, implying that most noise observed in a neuron’s responses is inherited from earlier processing stages [<xref ref-type="bibr" rid="pcbi.1005150.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref024">24</xref>]. Indeed, several different sources of noise may contribute to response variability, and the relative contributions of these noise sources can change under different environmental and stimulus conditions [<xref ref-type="bibr" rid="pcbi.1005150.ref025">25</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref027">27</xref>]. Importantly, the results of efficient coding analyses depend on the assumptions made about the locations of noise in the system in question, but there has been to date no systematic study of the implications that different noise sources have for efficient coding strategies. In particular, identifying failures of efficient coding theory—i.e., neural computations that do not optimally transform inputs—necessitates a broad understanding of how different sources of noise alter efficient coding predictions.</p>
<p>Here, we consider how the optimal encoding strategies of neurons depend on the location of noise in a neural circuit. We focus on the coding strategies of single neurons or pairs of neurons in feedforward circuits as simple cases with physiologically relevant applications. Indeed, early sensory systems often encode stimuli in a small number of parallel channels, including in vision [<xref ref-type="bibr" rid="pcbi.1005150.ref028">28</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref030">30</xref>], audition [<xref ref-type="bibr" rid="pcbi.1005150.ref031">31</xref>], chemosensation [<xref ref-type="bibr" rid="pcbi.1005150.ref032">32</xref>], thermosensation [<xref ref-type="bibr" rid="pcbi.1005150.ref033">33</xref>], and somatosensation [<xref ref-type="bibr" rid="pcbi.1005150.ref034">34</xref>]. We build a model that incorporates several different sources of noise, relaxing many of the assumptions of previously studied models, including the shape of the function by which a neuron transforms its inputs to outputs. We determine the varied, and often competing, effects that different noise sources have on efficient coding strategies and how these strategies depend on the location, magnitude, and correlations of noise across neurons. Much of the efficient coding literature is impacted by these results. For example, Laughlin’s predictions assume that downstream noise is identical for all responses; when this is not true, a different processing strategy will be optimal. Other recent work, considering such questions as when it is advantageous to have diverse encoding properties in a population and when sparse firing is beneficial, bears reinterpretation in light of these results [<xref ref-type="bibr" rid="pcbi.1005150.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref035">35</xref>]. Our work demonstrates that understanding the sources of noise in a neural circuit is critical to interpreting circuit function.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<p>Our goal is to understand how diverse noise sources shape a neural circuit’s optimal encoding strategies. We determine the optimal nonlinearities using two complementary approaches. First, we take variational derivatives of the mean squared error (MSE) between the true input and a linear estimate of the input to derive a system of equations for the exact optimal nonlinearities. We constrain the output of the nonlinearities to fall within a fixed range to reflect the limited dynamic range of neurons, but aside from this, we make no assumptions about the shape of the nonlinearities. Second, we simulate the model by parametrizing the nonlinearities and numerically determining the parameter values of the nonlinearity that best encode the stimulus. With this approach, we can use more complex measures of coding fidelity, such as mutual information (MI), as our criterion for optimality (see <xref ref-type="sec" rid="sec020">Methods</xref> for details).</p>
<p>We first describe a feedforward neural circuit model that incorporates three potential sources of noise. We then describe how a single pathway should allocate its response range to optimally encode its inputs, showing that optimal strategies depend strongly on where noise enters the circuit. Finally, we extend our model to include two parallel pathways, reflecting a common architecture in sensory systems. We consider how dual pathways should parcellate the range of inputs, namely the factors that determine to what extent they should encode overlapping regions of the input distribution and whether they should have the same or different response polarities.</p>
<sec id="sec003">
<title>Circuit model</title>
<p>The model is schematized in <xref ref-type="fig" rid="pcbi.1005150.g001">Fig 1</xref>, and is detailed below. We constructed this model with retinal circuitry in mind, though the model could be reinterpreted to represent other primarily feedforward early sensory systems, or even small segments of cortical circuitry. We begin with a simple feature of neural circuits that captures a ubiquitous encoding transformation: a nonlinear conversion of inputs to outputs. Nonlinear processing arises from several biological processes, such as dendritic integration, vesicle release at the synapse, and spike generation [<xref ref-type="bibr" rid="pcbi.1005150.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref037">37</xref>]. Such nonlinearities appear in most neural coding models (such as the commonly used linear-nonlinear-poisson (LNP) models or generalized linear models [<xref ref-type="bibr" rid="pcbi.1005150.ref038">38</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref040">40</xref>]). Although there are likely several sites with some level of nonlinear processing in the retinal circuitry, there is a single dominant nonlinearity at most light levels which can be localized to the output synapse of the bipolar cells [<xref ref-type="bibr" rid="pcbi.1005150.ref041">41</xref>]. Our goal is to determine the shape of the nonlinearity in this model that most faithfully encodes a distribution of inputs—i.e., the optimal encoding strategy. Indeed, in the retina, the shape of this nonlinearity has been shown to adapt under different stimulus conditions, suggesting that this adaptation might serve to improve encoding of visual stimuli as environmental conditions (and hence noise) change [<xref ref-type="bibr" rid="pcbi.1005150.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref042">42</xref>].</p>
<fig id="pcbi.1005150.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Model of neural encoding with three sources of noise.</title>
<p><bold>A:</bold> Model schematic for a single pathway. An input <italic>s</italic> is directly corrupted by some noise <italic>η</italic>, and then transformed nonlinearly by <italic>f</italic>(⋅). The nonlinear processing stage sets the mean of a scaled Poisson response with variance equal to <italic>κ</italic> times the mean response. This response is corrupted by additional additive downstream noise <italic>ζ</italic> to give a total response <italic>r</italic>. <bold>B:</bold> Transformed stimulus distribution at each stage of the model. <bold>C:</bold> Model schematic for two parallel pathways. Noise upstream and downstream of the nonlinearity may be correlated across neurons. For schematic purposes, we have drawn all signal processing steps as though they are contained within a single neuron, but each pathway could more generally represent signal processing spread out across multiple neurons.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.g001" xlink:type="simple"/>
</fig>
<p>The pathway receives an input signal or stimulus <italic>s</italic>, which is drawn from the standard normal distribution. Generally, an individual value of <italic>s</italic> can represent any deviation from the mean stimulus value, and the full distribution of <italic>s</italic> represents the set of inputs that might be encountered over some time window in which the circuit is able to adapt. In the context of the retinal circuitry, <italic>s</italic> can be understood as the contrast of a small region, or pixel, of the visual stimulus. The contrast in this pixel might be positive or negative relative to the ambient illumination level. The full distribution of <italic>s</italic> would then represent the distribution of contrasts encountered by this bipolar cell as the eye explores a particular scene. (We use Gaussian distributions here for simplicity in analytical computations, though similar results are obtained in simulations with skewed stimulus distributions, similar to the distributions of pixel contrast of natural scenes [<xref ref-type="bibr" rid="pcbi.1005150.ref043">43</xref>].) We assume the distribution of <italic>s</italic> is fixed in time. If properties of the signal distribution varied randomly in time (for example, if the variance of possible signals the circuit receives fluctuates between integration times), over long times the circuit would see an effectively broader distribution due to this extra variability. Conversely, if the particular visual scene being viewed or other environmental conditions change suddenly, the input distribution as a whole (for example, the range of contrasts, corresponding to the width of the input distribution) also changes suddenly. Therefore we expect the shape of the optimal nonlinearity to adapt to this new set of signal and noise distributions. We do not model the adaptation process itself; our results for the optimal nonlinearity correspond to the end result of the adaptation process in this interpretation.</p>
<p>We incorporate three independent sources of noise, located before, during, and after the nonlinear processing stage (<xref ref-type="fig" rid="pcbi.1005150.g001">Fig 1A and 1B</xref>). The input stimulus is first corrupted by upstream noise <italic>η</italic>. This noise source represents various forms of sensory noise that corrupt signals entering the circuit. This might include noise in the incoming stimulus itself or noise in photoreceptors. The strength of this noise source is governed by its variance, <inline-formula id="pcbi.1005150.e001"><alternatives><graphic id="pcbi.1005150.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>. The signal plus noise (<xref ref-type="fig" rid="pcbi.1005150.g001">Fig 1B</xref>, purple) is then passed through a nonlinearity <italic>f</italic>(⋅), which sets the mean of a scaled Poisson process with a quantal size <italic>κ</italic>. The magnitude of <italic>κ</italic> determines the contribution of this noise source, with large values of <italic>κ</italic> corresponding to high noise. This noise source captures quantal variations in response, such as synaptic vesicle release, which can be a significant source of noise at the bipolar cell to ganglion cell synapse [<xref ref-type="bibr" rid="pcbi.1005150.ref026">26</xref>]. Finally, the scaled Poisson response is corrupted by downstream noise <italic>ζ</italic> (with variance <inline-formula id="pcbi.1005150.e002"><alternatives><graphic id="pcbi.1005150.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>) to obtain the output response (<xref ref-type="fig" rid="pcbi.1005150.g001">Fig 1B</xref>, green). This source of noise captures any variability introduced after the nonlinearity, such as noise in a postsynaptic target. In the retina, this downstream noise captures noise intrinsic to a retinal ganglion cell, and the final output of the model is the current recorded in a ganglion cell. If the sources of upstream and downstream noise are independent (e.g., photoreceptor noise and retinal ganglion cell channel noise, respectively), then the two kinds of noise will be uncorrelated in a feedforward circuit like we model here. Lateral input from other channels, which we do not consider, could potentially introduce dependence between upstream and downstream noise. Feedback connections operating on timescales within a single-integration window could also potentially introduce correlations between additive upstream and downstream noises. However, while such connections could be important in cortical circuits, they are not significant in the sensory circuits that inspired this model, so we assume independent upstream and downstream noise in this work. For further biological interpretation of the model, see <xref ref-type="sec" rid="sec016">Discussion</xref>.</p>
<p>We begin by studying a model of a single pathway. We then consider how two pathways operating in parallel ought to divide the stimulus space to most efficiently code inputs. These models are constructed of two parallel pathways of the single pathway motif (<xref ref-type="fig" rid="pcbi.1005150.g001">Fig 1C</xref>), with the addition that noise may be correlated across both pathways. The study of two parallel channels is motivated by the fact that a particular area of visual space is typically encoded by paired ON and OFF channels with otherwise similar functional properties, but similar parallel processing occurs throughout early sensory systems and in some cortical areas [<xref ref-type="bibr" rid="pcbi.1005150.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref032">32</xref>]. We will return to further discussion of parallel pathways in the second half of the Results.</p>
</sec>
<sec id="sec004">
<title>Optimal coding strategies for single pathways</title>
<p>We begin with the case of a single pathway. For simplicity, we start with cases in which one of the three noise sources dominates over the others. Considering cases in which a single noise source dominates isolates the distinct effects of each noise source on the optimal nonlinearity. We then show that these same effects govern how the three noise sources compete in setting the optimal nonlinearity when they are all of comparable magnitude.</p>
<sec id="sec005">
<title>Upstream noise decreases slope of optimal nonlinearity to encode broader range of inputs</title>
<p>In <xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref>, we plot the optimal nonlinearities for cases in which one of the noise sources dominates the others. For each noise source, we show results for small, intermediate, and large values of the signal-to-noise ratio (SNR) of model responses. Importantly, the SNR is matched within columns of <xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref>, allowing for a direct comparison of the effects of different noise sources. We present both analytical results (dashed lines) for optimal nonlinearities constrained only by the assumption of fixed dynamic range, and results using parametrized nonlinearities of a sigmoidal form (solid lines). We show only optimal “ON” nonlinearities (nonlinearities that increase response strength as stimulus strength increases) in this section for simplicity; the mirror-image “OFF” nonlinearities (which decrease response strength as stimulus strength increases) are mathematically equivalent and result in identical values of MSE or MI.</p>
<fig id="pcbi.1005150.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Optimal nonlinearities when one noise source dominates, found by minimizing the mean squared error (MSE) of a linear estimator.</title>
<p>Each row shows three separate cases in which a single source of noise dominates. The dominant noise source is indicated by the highlighted source in the circuit schematics left of each row. The overall level of noise is quantified by the signal-to-noise ratio (SNR), which is fixed in each column. The SNR is largest in the leftmost column and smallest in the rightmost column; i.e., the strength of the <italic>noise</italic> increases toward the right. The shape of the optimal nonlinearity changes markedly depending on which noise source dominates the circuit, <italic>even when the overall signal-to-noise ratio of model responses is the same</italic>. Analytical results (dashed colored lines) and simulations with sigmoidal nonlinearities (solid lines) are shown. The stimulus distribution (dashed gray curve) is also shown for reference. Shaded regions encompass nonlinearities that perform within 1% of the minimum mean squared error of the optimal sigmoidal nonlinearity. The SNR is computed as the variance of the signal (the variance, across all inputs, of the average response to a given input) divided by the variance of the noise (the average variance in responses to a given input); see <xref ref-type="sec" rid="sec020">Methods</xref>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.g002" xlink:type="simple"/>
</fig>
<p>We begin with the case in which the upstream noise dominates (<xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref>, top row). The optimal nonlinearities are centered around the most likely stimulus and have progressively lower slopes for greater upstream noise variance. Upstream noise is added directly to the stimulus and hence cannot be removed by any nonlinear transformation. The optimal strategy in this case is to ensure that the limited range of outputs is used to encode the entire range of inputs. Increasing upstream noise effectively broadens the input distribution, and decreasing the slope of the nonlinearity compensates for this broadening. Quantitatively, we find that the effect of upstream noise is captured entirely by normalizing the inputs (stimulus plus upstream noise) by their standard deviation <inline-formula id="pcbi.1005150.e003"><alternatives><graphic id="pcbi.1005150.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mo>(</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> (see <xref ref-type="sec" rid="sec020">Methods</xref>). In other words, nonlinearities are simply scaled versions of each other that overlay entirely when normalized by the effective range of inputs (stimulus plus noise) they receive.</p>
<p>It is instructive to see the responses produced by both optimal and suboptimal nonlinearities to clarify this intuition (<xref ref-type="fig" rid="pcbi.1005150.g003">Fig 3</xref>). A suboptimal nonlinearity (<xref ref-type="fig" rid="pcbi.1005150.g003">Fig 3B</xref>) has a relatively steep slope, which results in a large number of inputs producing either maximal or minimal responses. As a result, the response distribution shows peaks near the edges of the response range. The optimal nonlinearity (<xref ref-type="fig" rid="pcbi.1005150.g003">Fig 3A</xref>) has a shallower slope which prevents saturation of the outputs.</p>
<fig id="pcbi.1005150.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Responses produced by optimal (left column) and suboptimal (right column) nonlinearities.</title>
<p>Each row shows a different set of noise conditions in which a single source of noise is dominant (i.e., upstream noise dominates in panels <bold>A</bold> and <bold>B</bold>, Poisson noise in <bold>C</bold> and <bold>D</bold>, and downstream noise in <bold>E</bold> and <bold>F</bold>). Markers show 1,000 points randomly selected from the stimulus distribution (bottom subpanels) and the corresponding responses that are produced by the nonlinearity (solid line). Different nonlinearities produce very different response distributions (left subpanels). These particular suboptimal nonlinearities are chosen for illustrative purposes, to highlight qualitative features of the optimal nonlinearities.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.g003" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec006">
<title>Poisson noise shifts the optimal nonlinearity so that low-noise responses encode most likely stimuli</title>
<p>We next isolate the effect of the scaled Poisson noise, by considering the case where its magnitude dominates the other noise sources (<xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref>, middle row). Increasing <italic>κ</italic> increases the slope of the optimal nonlinearity and shifts it off-center. The scaled Poisson noise has variance proportional to the mean response. Thus, stimuli that elicit the weakest responses also generate the lowest noise. The offset of the optimal nonlinearity associates the least noisy range of outputs, near the base of the nonlinearity, with the most probable stimuli.</p>
<p>A suboptimal nonlinearity (<xref ref-type="fig" rid="pcbi.1005150.g003">Fig 3D</xref>) maps a significant proportion of inputs to medium and high responses, which are noisy. Conversely, the optimal nonlinearity (<xref ref-type="fig" rid="pcbi.1005150.g003">Fig 3C</xref>) maps a large proportion of inputs to lower response values, including many to 0, which has no associated Poisson noise. This comes at the cost of compressing many stimuli to the same response value, but in terms of decoding error is more than compensated for by decreased levels of noise.</p>
<p>We chose to model this source of noise as following Poisson statistics, as several lines of evidence suggest that vesicle release at synapses in the retina is well-described as Poissonian [<xref ref-type="bibr" rid="pcbi.1005150.ref044">44</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref045">45</xref>]. However, we also tested to what extent the results here depend on this particular assumption. We investigated how optimal nonlinearities change for two additional types of noise that might be associated with the nonlinear stage: (1) multiplicative Gaussian noise, where the variance is proportional to the output of the nonlinearity, and (2) vesicle release that follows a binomial distribution, where the output of the nonlinearity determines the probability of release. In both cases (and for both criteria for optimality, MSE and MI), results are qualitatively similar to those presented here (see <xref ref-type="supplementary-material" rid="pcbi.1005150.s001">S1 Fig</xref>). The trends were necessarily identical for the Poisson and multiplicative Gaussian noises, which both have variances proportional to the nonlinearity. For a linear stimulus estimator, as used in this work, the MSE depends only on the mean and covariances of the nonlinear-stage noise—higher order statistics do not affect the shape of the optimal nonlinearity determined by minimizing the MSE. Hence, any circuit in which the mean and variances of the response are proportional to the nonlinearity will yield the same optimal nonlinearities.</p>
</sec>
<sec id="sec007">
<title>Downstream noise steepens slopes to improve discriminability of responses</title>
<p>Finally, we study the case where the downstream noise dominates other noise sources (<xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref>, bottom row). Here, the optimal nonlinearity remains centered for a range of noise strengths but becomes markedly steeper as the variance of downstream noise increases. Steepening the slope amplifies changes in the response with respect to the stimulus, while leaving the downstream noise unchanged. The result is a greater signal-to-noise ratio for those stimuli that fall near the midpoint of the nonlinearity. Placing the nonlinearity in the center of the stimulus distribution ensures that the most likely stimuli will be the most discriminable. This differs from the case of upstream noise, where the slope becomes less steep as noise increases. Unlike upstream noise, which corrupts the stimulus directly, the signal and downstream noise can be differentially amplified to improve the SNR.</p>
<p>The optimal nonlinearity for large downstream noise (<xref ref-type="fig" rid="pcbi.1005150.g003">Fig 3E</xref>) has a steep slope. Responses corresponding to stimuli above versus below the mean can be clearly distinguished from the response distribution. This improved discriminability comes at the cost of encoding a smaller range of inputs, but this is compensated for by the improved discriminability for inputs that fall within the range encoded by the nonlinearity. A suboptimal nonlinearity (<xref ref-type="fig" rid="pcbi.1005150.g003">Fig 3F</xref>), on the other hand, results in relatively poor discrimination of a broader range of inputs: small differences in inputs lead to small differences in outputs, which are overcome by the downstream noise. If the downstream noise is much larger than the typical response sizes, the nonlinearity essentially becomes an all-or-nothing response; i.e., the downstream noise is so large that the response can only provide information about whether or not the stimulus is greater or less than the mean. Some of this effect can be seen in the example shown in <xref ref-type="fig" rid="pcbi.1005150.g003">Fig 3E</xref>, with the response distribution becoming bimodal.</p>
<p>To ensure that our results are not dependent on our criterion for optimality (i.e., minimizing the mean squared error of a linear estimator), we also used simulations to find the optimal nonlinearities that maximize the mutual information between stimulus and response (see <xref ref-type="sec" rid="sec020">Methods</xref> for details). Nonlinearities that maximize the MI show the same trends as those that minimize MSE (<xref ref-type="supplementary-material" rid="pcbi.1005150.s002">S2 Fig</xref>; compare to <xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref>).</p>
</sec>
<sec id="sec008">
<title>Noise sources compete to shape the nonlinearity</title>
<p>The results in <xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref> demonstrate that optimal nonlinearities have very different shapes when different noise sources dominate, even if they have the same overall “strength” (i.e., induce the same SNR). In particular, upstream and downstream noise have opposite effects on the optimal nonlinearity, even though they are both Gaussian and additive at their source.</p>
<p>We now show that the same trends occur when there are multiple noise sources of comparable strengths. In this case the optimal nonlinearities lie between the solutions shown above and change smoothly as the noise parameters are varied. <xref ref-type="fig" rid="pcbi.1005150.g004">Fig 4</xref> takes three cuts through the (<italic>σ</italic><sub>up</sub>, <italic>κ</italic>, <italic>σ</italic><sub>down</sub>) parameter space and shows how the optimal nonlinearity changes as one moves in a particular direction. Once again, we see that different noise sources often have opposite effects on features of the optimal nonlinearity. This highlights the importance of considering model assumptions about where noise enters in a circuit. When trying to determine whether a given circuit is operating optimally, one can arrive at opposite conclusions depending on where noise is assumed to be present. This is an important point given that there are many different ways in which noise is commonly incorporated into neural models (e.g., Poisson noise in the nonlinearity or additive Gaussian noise) and these assumptions are not frequently based on knowledge of noise location in the corresponding biological circuit.</p>
<fig id="pcbi.1005150.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Optimal nonlinearities for cuts through parameter space.</title>
<p><bold>A:</bold> Schematic showing regions of 3-dimensional parameter space: <italic>σ</italic><sub>up</sub> (purple), <italic>σ</italic><sub>down</sub> (green), and <italic>κ</italic> (blue). Insets show the optimal nonlinearity corresponding to the like-colored point, along with the stimulus distribution (dashed gray curves). <bold>B:</bold> Slope of the optimal nonlinearity as each parameter is varied along the corresponding dashed axis in <bold>A</bold>. <bold>C:</bold> Offsets plotted in the same manner as <bold>B</bold>. Slopes and offsets are obtained from the exact solutions of the model.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.g004" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec009">
<title>Optimal coding strategies for parallel pathways</title>
<p>Information in many sensory systems is encoded in parallel pathways. In vision, for example, inputs are encoded by both ON cells and OFF cells. In audition, an incoming stimulus is encoded in many parallel channels, each encoding a particular frequency band. Allowing for multiple parallel channels raises fundamental questions about how these resources should be allocated: should multiple channels have the same or different response polarities? Should an input be encoded in multiple channels redundantly, or should different channels specialize in encoding a particular range of inputs? To understand these tradeoffs, we solved our model for the optimal nonlinearities for a pair of parallel pathways, the simplest case in which these questions can be investigated. Indeed, in many cases, a small number of sensory neurons are responsible for carrying the relevant signal [<xref ref-type="bibr" rid="pcbi.1005150.ref046">46</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref049">49</xref>].</p>
<p>Our circuit model for multiple pathways comprises parallel copies of the single pathway model (<xref ref-type="fig" rid="pcbi.1005150.g001">Fig 1C</xref>), with the additional detail that both upstream and downstream noise may be correlated across pathways. We show below that the sign and strength of these correlations can strongly affect optimal encoding strategies. To focus on the effects of noise on optimal encoding strategies, we added complexity to the noise structure, while making significant simplifications in the stimulus structure. In particular, we assume that both channels receive the same stimulus. Correlated but non-identical stimuli in the two channels would likely affect optimal encoding strategies, but we did not explore this possibility and leave it as a direction for future inquiry.</p>
<p>We discuss the parallel pathway results in the following order: first, we discuss the possible pairs of nonlinearities, which are richer than the single-pathway case. We then discuss the functional effects that each of the parameters, or in some cases combinations of parameters, has on the shapes of the nonlinearities, with a focus on which parameter regimes favor highly overlapping versus minimally overlapping encoding of inputs (hereafter referred to as “overlapping” and “non-overlapping”). Finally, we discuss factors that determine whether a circuit should encode inputs with channels of opposite polarity versus channels of the same polarity.</p>
<sec id="sec010">
<title>Multiple optimal coding strategies exist—“ON-OFF” and “ON-ON” pairs</title>
<p>Similar to the single pathway case above, solving the model reveals that each nonlinearity may be of the ON or OFF type, allowing for four combinations of pairs: ON-ON, ON-OFF, OFF-ON, and OFF-OFF. Note that we did not make assumptions about the shape of the optimal nonlinearities, other than restricting the output range. In particular, we did not explicitly impose monotonicity of the nonlinearities, though this may be a consequence of our choice of linear stimulus estimator. Non-monotonic nonlinearities have been proposed to serve a variety of computational functions [<xref ref-type="bibr" rid="pcbi.1005150.ref050">50</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref056">56</xref>], and understanding under what conditions they are optimal is an interesting and important direction for future studies; here we focus on the monotonic nonlinearities obtained from our analytic approach.</p>
<p>The ON-ON and OFF-OFF pairs are related by symmetry of the model and are equivalent, as are the ON-OFF and OFF-ON pairs. However, the ON-OFF and ON-ON pairs are <italic>not</italic> equivalent and have different decoding error (MSE) (similar to Ref. [<xref ref-type="bibr" rid="pcbi.1005150.ref056">56</xref>]). All ON-OFF pairs are anti-symmetric (<italic>f</italic><sub>1</sub>(<italic>z</italic>) = <italic>f</italic><sub>2</sub>(− <italic>z</italic>)), with varying degrees of overlap between nonlinearities (<xref ref-type="fig" rid="pcbi.1005150.g005">Fig 5A</xref>). However, ON-ON nonlinearities split into separate subclasses: identical ON-ON pairs are two copies of the same nonlinearity, <italic>f</italic><sub>1</sub>(<italic>z</italic>) = <italic>f</italic><sub>2</sub>(<italic>z</italic>) and hence overlap entirely, while non-identical ON-ON pairs split their thresholds and overlap only in the tails, similar to the configurations considered in several recent studies [<xref ref-type="bibr" rid="pcbi.1005150.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref056">56</xref>]. For some noise conditions, identical and non-identical ON-ON pairs are co-existing analytical solutions of the model; the MSE of the two solutions need not be equal. The non-identical subclass only exists when the circuit can lower the MSE by splitting the thresholds. The situation is simpler for ON-OFF pairs, for which we only observe a single solution for each noise condition.</p>
<fig id="pcbi.1005150.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Optimal nonlinearities for a circuit with two parallel pathways, found by minimizing mean squared error (MSE) of a linear estimator.</title>
<p><bold>A:</bold> Optimal nonlinearities for circuits in which pathways are of opposite polarity. Each row corresponds to a case in which one particular noise source is dominant. The dominant noise source is indicated by the highlighted source in the schematics at the center of the figure. As in <xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref>, solid curves are the optimal sigmoidal nonlinearities and colored dashed curves are optimal nonlinearities obtained analytically. The gray dashed curves represent the stimulus distribution. Shaded regions represent the range of sigmoidal nonlinearities that perform within 1% of the mean squared error of the optimal sigmoidal nonlinearities. <bold>B:</bold> Same as <bold>A</bold> but for pathways of the same polarity. We address the relative coding efficiency of the different polarities in the section “Globally optimal strategies.”</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.g005" xlink:type="simple"/>
</fig>
<p>We first present results for both ON-OFF and ON-ON classes of solutions, showing how different noise sources shape optimal nonlinearities in a circuit with two parallel channels. The qualitative effects of each noise source are consistent across ON-OFF and ON-ON architectures. We then show which parameter determines whether same polarity or opposite polarity solutions are globally optimal.</p>
</sec>
<sec id="sec011">
<title>Highly correlated inputs favor non-overlapping encoding, uncorrelated inputs favor overlapping encoding</title>
<p>To fully understand how the nonlinearity pairs change when a given noise source dominates responses, we need to be precise about what we mean when we say upstream noise or downstream noise dominates. The overall impacts of the noise sources are not simply the variances <inline-formula id="pcbi.1005150.e004"><alternatives><graphic id="pcbi.1005150.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005150.e005"><alternatives><graphic id="pcbi.1005150.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> but are also influenced by the degree of correlation between the noise sources across pathways, <italic>ρ</italic><sub>up</sub> and <italic>ρ</italic><sub>down</sub>. As we will make clear, these correlations dictate the effective noise level, i.e., the extent to which noise interferes with signal decoding (see [<xref ref-type="bibr" rid="pcbi.1005150.ref002">2</xref>] for relevant discussion of noise correlations).</p>
<p>We find that upstream noise parameters (both variance and correlations) determine the degree to which optimal nonlinearities overlap, encoding some inputs in both channels. This is true regardless of whether nonlinearities in the two pathways are of the same polarity (“ON-ON”) or opposite polarities (“ON-OFF”). We can gain insight into this result by first considering the effects of the two upstream noise terms (<inline-formula id="pcbi.1005150.e006"><alternatives><graphic id="pcbi.1005150.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <italic>ρ</italic><sub>up</sub>) individually. First, consider the effects of changing the magnitude of upstream noise if it is uncorrelated across channels. If the magnitude of noise is small (small <inline-formula id="pcbi.1005150.e007"><alternatives><graphic id="pcbi.1005150.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>), one channel can reliably encode a stimulus, and the most favorable strategy is for each pathway to encode a different range of inputs. This allows the largest range of inputs to be encoded. If <inline-formula id="pcbi.1005150.e008"><alternatives><graphic id="pcbi.1005150.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> is large, however, it is beneficial to redundantly encode the input in both channels, as averaging can be used to better recover the stimulus, given that the noise is not (positively) correlated.</p>
<p>Now consider the effects of varying amounts of noise correlations, <italic>ρ</italic><sub>up</sub>, for a fixed noise magnitude. Weak upstream noise correlations (<italic>ρ</italic><sub>up</sub> ≈ 0) mean that averaging can be beneficial, as the noise is independent in each channel. This favors overlapping encoding. Strong noise correlations (<italic>ρ</italic><sub>up</sub> ≲ 1), on the other hand, result in coherent shifts of the stimulus in both pathways, making it difficult to distinguish what part of the input is signal and what part of the input is noise. Encoding highly correlated inputs (including highly correlated noise) with two overlapping nonlinearities offers no advantage over encoding with a single nonlinearity. The better strategy, then, is to use each pathway to encode a different range of inputs, maximizing coverage of the input space.</p>
<p>It turns out that these changes can be wholly captured by the correlation coefficient of the <italic>total inputs</italic> (stimulus plus noise) to each channel,
<disp-formula id="pcbi.1005150.e009"><alternatives><graphic id="pcbi.1005150.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e009" xlink:type="simple"/><mml:math display="block" id="M9"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msub> <mml:mo>≡</mml:mo> <mml:mfrac><mml:mrow><mml:mo>⟨</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:msqrt><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
i.e., <inline-formula id="pcbi.1005150.e010"><alternatives><graphic id="pcbi.1005150.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <italic>ρ</italic><sub>up</sub> do not independently control the degree of overlap of the nonlinearities. Analytical calculations (see <xref ref-type="sec" rid="sec020">Methods</xref>) show that when the input to the nonlinearities is rescaled by its standard deviation (<inline-formula id="pcbi.1005150.e011"><alternatives><graphic id="pcbi.1005150.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:math></alternatives></inline-formula>, as in the single cell case), the dependence on <italic>σ</italic><sub>s</sub>, <italic>σ</italic><sub>up</sub>, and <italic>ρ</italic><sub>up</sub> enters only through the effective parameter combination <italic>ρ</italic><sub>eff</sub>.</p>
<p>In summary, when inputs (stimulus plus noise) to parallel channels are uncorrelated, having each channel cover overlapping regions of the input space provides two distinct estimates of the stimulus. These estimates are combined to produce a better overall estimate, so encoding the stimulus in both channels is favorable. When inputs are highly correlated or when noise is low, the circuit cannot achieve better performance by encoding the input in two overlapping channels than it can with a single channel, so it is best to have each nonlinearity cover a different range of inputs to encode as large a range of stimuli as possible.</p>
</sec>
<sec id="sec012">
<title>Poisson variability biases both channels to encode most frequent stimuli</title>
<p>Increasing the Poisson strength <italic>κ</italic> has opposite effects for ON-OFF versus ON-ON pairs (<xref ref-type="fig" rid="pcbi.1005150.g005">Fig 5</xref>, center row) in terms of the degree of overlap in encoding. For ON-OFF pairs, increasing <italic>κ</italic> pushes the nonlinearities apart, while for ON-ON pairs increasing <italic>κ</italic> pulls nonlinearities back together. However, both of these effects are manifestations of the principle that the most reliable responses should encode the most likely stimuli, just as in the single-pathway case. Because the variance of responses due to Poisson variability is lowest near the base of the nonlinearity, increasing <italic>κ</italic> biases the base of the nonlinearities to be positioned near the peak of the stimulus distribution. For ON-OFF nonlinearities, this effectively pushes the nonlinearities apart, while ON-ON nonlinearities are drawn back together. In both ON-OFF and ON-ON pairs, the slope of the nonlinearities increases to improve discriminability of inputs, as in the single-pathway case.</p>
</sec>
<sec id="sec013">
<title>Downstream noise variance steepens nonlinearities</title>
<p>High downstream noise steepens the nonlinearities and drives the center of the nonlinearity back towards the most likely inputs (<xref ref-type="fig" rid="pcbi.1005150.g005">Fig 5</xref>, bottom row). However, even for large noise, nonlinearities may have varying degrees of overlap, depending on the values of <italic>κ</italic> or <italic>ρ</italic><sub>eff</sub>. As such, the downstream noise does not have a significant influence on the degree of overlap of the encoding strategies.</p>
<p>As in the case of a single pathway, results obtained by maximizing the mutual information are qualitatively similar to those obtained by minimizing the mean squared error of a linear estimator (<xref ref-type="supplementary-material" rid="pcbi.1005150.s003">S3 Fig</xref>; compare to <xref ref-type="fig" rid="pcbi.1005150.g005">Fig 5</xref>).</p>
</sec>
<sec id="sec014">
<title>Competition between noise sources</title>
<p>To study the competition between noise sources when there is not a clear dominant source, we sweep along cuts in the (<italic>ρ</italic><sub>eff</sub>, <italic>κ</italic>, <italic>σ</italic><sub>down</sub>) parameter space, similar to <xref ref-type="fig" rid="pcbi.1005150.g004">Fig 4</xref>. Here, however, we focus on how the <italic>rescaled</italic> slopes and offsets change under different noise conditions. As described above, after rescaling by the standard deviation of the input (<inline-formula id="pcbi.1005150.e012"><alternatives><graphic id="pcbi.1005150.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:math></alternatives></inline-formula>), the effects of the three stimulus and upstream noise parameters can be combined into a single parameter <italic>ρ</italic><sub>eff</sub> that determines the shape of the optimal nonlinearity. We focus on the rescaled slopes (slope multiplied by <inline-formula id="pcbi.1005150.e013"><alternatives><graphic id="pcbi.1005150.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:math></alternatives></inline-formula>) and rescaled offsets (offset divided by <inline-formula id="pcbi.1005150.e014"><alternatives><graphic id="pcbi.1005150.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:math></alternatives></inline-formula>) in order to present the effects of the single parameter <italic>ρ</italic><sub>eff</sub>. The Poisson strength <italic>κ</italic> and the downstream noise standard deviation <italic>σ</italic><sub>down</sub> have similar effects on the paired nonlinearities as they do in the case of a single pathway. Poisson noise increases the slope (<xref ref-type="fig" rid="pcbi.1005150.g006">Fig 6B</xref>, middle subpanel) and shifts the nonlinearities off-center (<xref ref-type="fig" rid="pcbi.1005150.g006">Fig 6C</xref>, middle subpanel). Downstream noise also steepens the slope (<xref ref-type="fig" rid="pcbi.1005150.g006">Fig 6B</xref>, right subpanel) and centers the nonlinearities (<xref ref-type="fig" rid="pcbi.1005150.g006">Fig 6C</xref>, right subpanel). The total input correlation <italic>ρ</italic><sub>eff</sub> has relatively little effect on the rescaled slope (<xref ref-type="fig" rid="pcbi.1005150.g006">Fig 6B</xref>, left subpanel), but significantly impacts the offset (<xref ref-type="fig" rid="pcbi.1005150.g006">Fig 6C</xref>, left subpanel). The separation of the offsets of the ON-OFF nonlinearities (solid lines) increases as <italic>ρ</italic><sub>eff</sub> increases towards 1, reflecting an increase in the degree of non-overlapping encoding. Under most noise conditions, the two ON-ON nonlinearities (dashed lines) are identical and hence encode inputs redundantly; however, as <italic>ρ</italic><sub>eff</sub> approaches 1, the offsets split, switching from the identical ON-ON subclass to the non-identical ON-ON subclass. For nonlinearities of the same polarity, this splitting is in competition with both the scaled Poisson noise and the downstream noise, which bias the base of the nonlinearities back towards the center of the stimulus distribution (compare dashed lines in subpanels across <xref ref-type="fig" rid="pcbi.1005150.g006">Fig 6</xref>). If <italic>ρ</italic><sub>eff</sub> is not large enough, as is the case for the cuts along the <italic>κ</italic> and <italic>σ</italic><sub>down</sub> dimensions in <xref ref-type="fig" rid="pcbi.1005150.g006">Fig 6</xref>, no splitting occurs. Splitting of ON-ON nonlinearities only occurs for a narrow range of <italic>ρ</italic><sub>eff</sub> between 0.9 − 1.0; this range shrinks as the strength of the Poisson or downstream noise grow. For zero Poisson and downstream noise, the range is consistent with the model of [<xref ref-type="bibr" rid="pcbi.1005150.ref021">21</xref>].</p>
<fig id="pcbi.1005150.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Optimal ON-OFF or ON-ON nonlinearities for slices through parameter space.</title>
<p><bold>A:</bold> Schematics showing regions of the effective 3-dimensional parameter space: total input correlation <italic>ρ</italic><sub>eff</sub> (purple), scaled Poisson strength <italic>κ</italic> (blue), and downstream noise standard deviation <italic>σ</italic><sub>down</sub> (green). Insets show the optimal nonlinearity corresponding to the like-colored point. Top schematic: optimal ON-OFF nonlinearities, bottom: optimal ON-ON nonlinearities. <bold>B:</bold> Slopes of the optimal nonlinearities (rescaled by <inline-formula id="pcbi.1005150.e015"><alternatives><graphic id="pcbi.1005150.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:math></alternatives></inline-formula>) for ON-OFF (solid) and ON-ON (dashed) solutions as each parameter is varied along the corresponding dashed axis in <bold>A</bold>. <bold>C:</bold> Offsets (rescaled by <inline-formula id="pcbi.1005150.e016"><alternatives><graphic id="pcbi.1005150.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>) plotted in the same manner as <bold>B</bold>. Insets in the <italic>ρ</italic><sub>eff</sub> plots are zoomed in to resolve the splitting of the identical ON-ON solution into the non-identical ON-ON solution. Rescaled slopes and offsets are obtained from numerical solutions of the analytic model; see <xref ref-type="sec" rid="sec020">Methods</xref> for details about rescaling.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.g006" xlink:type="simple"/>
</fig>
<p>These plots demonstrate that, as in the single pathway case, the different noise sources are often in direct conflict with each other and result in qualitatively different nonlinearities. Furthermore, the effects of upstream noise correlations differ from those of downstream noise correlations, further described below.</p>
</sec>
<sec id="sec015">
<title>Globally optimal strategies: Downstream noise determines polarity of nonlinearities</title>
<p>So far, we have investigated how different noise regimes shape the ON-OFF and ON-ON nonlinearities, without regard to which strategy is the globally optimal solution. We find that downstream noise correlations primarily determine the relative efficiency of ON-OFF nonlinearities compared to ON-ON nonlinearities.</p>
<p>
<xref ref-type="fig" rid="pcbi.1005150.g007">Fig 7</xref> maps out the optimal strategy in each region of parameter space for an exemplary value of <italic>κ</italic>, with different values of <italic>ρ</italic><sub>eff</sub> for each panel. Green points indicate that the ON-OFF strategy is optimal, while purple or blue points indicate that identical ON-ON or non-identical ON-ON strategies, respectively, are optimal. The size of the dots indicates the percent difference in MSE between the globally optimal solution and the best solution of a different type (e.g., if ON-OFF is optimal, percent difference between the optimal ON-OFF solution, and the best possible ON-ON solution).</p>
<fig id="pcbi.1005150.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Dependence of solution polarity on noise parameters.</title>
<p>Each panel shows the optimal solution type (indicated by color) as a function of <italic>σ</italic><sub>down</sub> and <italic>ρ</italic><sub>down</sub> for a particular value of <italic>ρ</italic><sub>eff</sub>. Dot size indicates the percent decrease in MSE between the globally optimal solution and the best solution of a different type (ON-ON where ON-OFF is optimal, and ON-OFF where ON-ON is optimal). Dots show results from numerical solution of integral equations for the exact nonlinearities; black lines show analytic predictions for boundaries at which ON-ON and ON-OFF solutions are equally optimal. The parameter <italic>κ</italic> has relatively little influence on the qualitative features of this plot, so for simplicity, we only show cases where <italic>κ</italic> = 1.0. The crossover from identical to non-identical ON-ON solutions occurs between <italic>ρ</italic><sub>eff</sub> ≈ 0.9 − 1.0; strong downstream noise or Poisson strength reduces the range over which splitting occurs. The rescaled nonlinearities and globally optimal strategy depend only on the parameters <italic>ρ</italic><sub>eff</sub>, <italic>κ</italic>, <italic>σ</italic><sub>down</sub> and <italic>ρ</italic><sub>down</sub>; the dependence on <italic>σ</italic><sub>s</sub>, <italic>σ</italic><sub>up</sub>, and <italic>ρ</italic><sub>up</sub> enters only through <italic>ρ</italic><sub>eff</sub>. See <xref ref-type="sec" rid="sec020">Methods</xref> for details.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.g007" xlink:type="simple"/>
</fig>
<p>We see that downstream noise correlations impact the relative mean squared error of ON-OFF versus ON-ON encoding strategies: ON-OFF pairs are generally optimal when the downstream noise is positively correlated across pathways, while ON-ON pairs are generally optimal when downstream noise is negatively correlated across pathways. The transitions can be most easily understood by considering the behavior of the optimal linear readout of the stimulus for each strategy. This readout is a <italic>difference</italic> of the total responses for ON-OFF pairs, while it is a (weighted) <italic>sum</italic> of the total responses for ON-ON pairs. Thus, ON-OFF pairs result in a subtraction of the downstream noise, while ON-ON pairs add the downstream noise. It is therefore favorable to encode with an ON-OFF pair when downstream noise is positively correlated and with an ON-ON pair when downstream noise is negatively correlated. Although the intuition is clearer for the linear readout, this picture also holds when MI is maximized (see <xref ref-type="supplementary-material" rid="pcbi.1005150.s002">S2</xref> and <xref ref-type="supplementary-material" rid="pcbi.1005150.s003">S3</xref> Figs).</p>
<p>The exact values of downstream noise variance and correlations at which the transition from ON-OFF to ON-ON strategies being optimal depends on the upstream and scaled Poisson noise. The strength <italic>κ</italic> adjusts the height of the transition boundaries: increasing <italic>κ</italic> tends to increase the range of downstream noise strength and correlations for which ON-OFF is optimal, while taking <italic>κ</italic> → 0 shifts the boundary curve down until the transition occurs at <italic>ρ</italic><sub>down</sub> = 0 for all <italic>σ</italic><sub>down</sub>.</p>
</sec>
</sec>
</sec>
<sec id="sec016" sec-type="conclusions">
<title>Discussion</title>
<p>While the efficient coding hypothesis has been an important principle in understanding neural coding, our results demonstrate that proper interpretation of a neural circuit’s efficiency depends on the nature and location of noise; a nonlinearity that is efficient if noise enters at one location in the circuit may be inefficient if the noise actually enters in a different location.</p>
<p>Several previous studies have investigated how architecture or cell type impacts efficient coding strategies [<xref ref-type="bibr" rid="pcbi.1005150.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref056">56</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref058">58</xref>]. While these models also include noise, assumptions about the location and strength of noise, as well as the allowed shapes of the nonlinearities, are more restrictive than our approach, and are not intended to systematically investigate the effects of disparate noise sources on coding strategies. Many similar questions can be answered using our model, and thus our work complements these studies by providing a broader, unifying picture of the interplay between noise and circuit architecture or cell types, while highlighting how different assumptions about noise could alter the conclusions or interpretation of previous work.</p>
<sec id="sec017">
<title>Implications for efficient coding in biological circuits</title>
<p>Noise in neural circuits arises from a variety of sources, both internal and external to the nervous system (reviewed in [<xref ref-type="bibr" rid="pcbi.1005150.ref001">1</xref>]). Noise is present in sensory inputs, such as fluctuations in photon arrival rate at the retina, which follow Poisson statistics, or variability in odorant molecule arrival at olfactory receptors due to random diffusion and the turbulent nature of odor plumes. Noise also arises within the nervous system due to several biophysical processes, such as sensory transduction cascades, channel opening, synaptic vesicle release, and neurotransmitter diffusion.</p>
<p>Past work has focused on two complementary, but distinct aspects of neural coding: 1) how noise limits coding fidelity, and 2) how circuits should efficiently encode inputs in the presence of such noise. Much of the work to date has focused on the first aspect, investigating how noise places fundamental limits on information transfer and coding fidelity for fixed neural coding strategies (e.g., tuning curves) [<xref ref-type="bibr" rid="pcbi.1005150.ref002">2</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref005">5</xref>]. Examples include studying how noise correlations lead to ambiguous separation of neural responses [<xref ref-type="bibr" rid="pcbi.1005150.ref002">2</xref>] and which correlation structures maximally inhibit coding performance [<xref ref-type="bibr" rid="pcbi.1005150.ref005">5</xref>].</p>
<p>The second perspective dates back to the pioneering work of [<xref ref-type="bibr" rid="pcbi.1005150.ref006">6</xref>] and [<xref ref-type="bibr" rid="pcbi.1005150.ref007">7</xref>]. These early works primarily considered how efficient codes are affected by constraints on neural responses, such as limited dynamic range. Recent studies have built upon these foundational studies, investigating further questions such as how circuit architecture shapes optimal neural codes [<xref ref-type="bibr" rid="pcbi.1005150.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref056">56</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref058">58</xref>]. However, this body of work has not systematically studied how efficient coding strategies depend on assumptions made about the nature of noise in a circuit.</p>
<p>Previous work has shown that the amount of noise in a circuit can qualitatively change optimal coding strategies [<xref ref-type="bibr" rid="pcbi.1005150.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref059">59</xref>]. We also find that noise strength can be an important factor in determining efficient coding strategies. A 5- to 10-fold decrease in the signal-to-noise ratio produces dramatic qualitative changes in the optimal nonlinearities (<xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref>), and those changes depend on noise location. The SNR values used in our study correspond to a range of SNR values commonly observed in responses of neurons in early sensory systems [<xref ref-type="bibr" rid="pcbi.1005150.ref060">60</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref061">61</xref>], suggesting that this result could be observed in biological circuits. Our analysis goes beyond considerations of noise strength to reveal how efficient coding strategies change depending on where noise arises in a circuit, showing that different noise sources often having competing effects. Other work in the context of decision making has similarly shown that the location of noise can impact the optimal architecture of a network, thus demonstrating that noise location in a circuit is important not only for signal transmission but also for computation [<xref ref-type="bibr" rid="pcbi.1005150.ref062">62</xref>]. Knowledge of both noise strength and where noise arises is therefore crucial for determining whether a neural circuit is encoding efficiently or not. Notably, even when the SNR of the circuit outputs is the same, the optimal nonlinearity can be very different depending on the location of the dominant noise source.</p>
<p>The locations of different noise sources have perhaps been most clearly elucidated in the retina. Several studies have investigated noise within the photoreceptors, and in some cases have even implicated certain elements within the transduction cascade [<xref ref-type="bibr" rid="pcbi.1005150.ref061">61</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref063">63</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref064">64</xref>]. Additional noise arises at the photoreceptor to bipolar cell synapse, where stochastic fluctuations in vesicle release obscure the signal [<xref ref-type="bibr" rid="pcbi.1005150.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref065">65</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref067">67</xref>]. It has also been suggested that noise downstream of this synapse contributes a significant amount of the total noise observed in the ganglion cells, with some studies pointing to the bipolar cell to ganglion cell synapse specifically [<xref ref-type="bibr" rid="pcbi.1005150.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref067">67</xref>].</p>
<p>Several pieces of evidence show that the relative contributions of different noise sources can change under different conditions as a circuit adapts. For example, in starlight or similar conditions, external noise due to variability in photon arrival dominates noise in rod photoreceptors and the downstream retinal circuitry [<xref ref-type="bibr" rid="pcbi.1005150.ref061">61</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref068">68</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref070">70</xref>]. As light levels increase, noise in the circuits reading out the photoreceptor signals—particularly at the synapse between cone bipolar cells and ganglion cells—can play a more prominent role [<xref ref-type="bibr" rid="pcbi.1005150.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref067">67</xref>]. Moreover, even in cases where the magnitude of a given noise source remains unchanged, adaptation can engage different nonlinearities throughout the circuit, shifting the location of the dominant nonlinearity and thereby effectively changing the location of the noise sources relative to the circuit nonlinearity. The fact that noise strength and nonlinearity location in neural circuits is subject to change under different conditions underscores the importance of understanding how these circuit features shape optimal encoding strategies.</p>
<p>In the retina, it has been observed that the nonlinearity at the cone bipolar to ganglion cell synapse can change dramatically depending on ambient illumination. Under daylight viewing conditions, this synapse exhibits strong rectification. Yet under dimmer viewing conditions, this synapse is nearly linear [<xref ref-type="bibr" rid="pcbi.1005150.ref042">42</xref>]. The functional role of this change is unclear, though the fact that noise sources are known to change under different levels of illumination points to a possible answer. If the dominant source of noise shifts from external sources to sources within downstream circuitry with increasing light level, as suggested by the evidence in [<xref ref-type="bibr" rid="pcbi.1005150.ref042">42</xref>], our results indicate that the circuit indeed ought to operate more nonlinearly at higher light levels. Furthermore, it is known that the strength of correlations not only varies between different types of retinal ganglion cells [<xref ref-type="bibr" rid="pcbi.1005150.ref071">71</xref>], but these correlations may be stimulus dependent [<xref ref-type="bibr" rid="pcbi.1005150.ref072">72</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref073">73</xref>]. Based on our results for paired nonlinearities, we predict that types of neurons that receive highly correlated input will have nonlinearities with small overlap, while cells that receive uncorrelated input will have highly overlapping nonlinearities. Fully understanding this adaptation, and adaptations in other systems, will require further elucidation of the noise sources in the circuit.</p>
</sec>
<sec id="sec018">
<title>Reinterpretation of other efficient coding studies</title>
<p>Understanding how different aspects of circuit architecture shape efficient coding strategies has been a recent area of interest [<xref ref-type="bibr" rid="pcbi.1005150.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1005150.ref056">56</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref058">58</xref>]. However, a systematic study of the effects of noise was not the goal of these works, and so the properties of the noise in these studies has been limited, bound by specific assumptions on noise strength and location, and the allowed shapes of nonlinearities. As a result, while there is some overlap in the conclusions of these studies, the differences in assumptions about the noise and nonlinearities also lead to some apparent disagreement. Fortunately, we can investigate many similar questions within our model, and thereby complement the results of these previous studies and enrich our understanding of the role of circuit architecture and function. We briefly discuss the connections that other published studies have to the work presented here, focusing on studies with questions that can be most directly investigated as special cases of our model.</p>
<p>Early work by Laughlin suggested a simple solution for how a single neuron can maximize the amount of information transmitted: a neuron should utilize all response levels with equal frequency, thereby maximizing the response entropy [<xref ref-type="bibr" rid="pcbi.1005150.ref007">7</xref>]. Laughlin found that an interneuron in the compound eye of the blowfly transforms its inputs according to this principle. More recent work investigated nonlinearities in salamander and macaque retinal ganglion cells, predicting that optimal nonlinearities should be steep with moderate thresholds [<xref ref-type="bibr" rid="pcbi.1005150.ref035">35</xref>]. Experimental measurements of nonlinearities in ganglion cells were found to be near-optimal based on these predictions. Although both of these studies (along with many others) predict that neurons are efficiently encoding their inputs, assumptions about noise are not well-constrained by experiment. (In one case, the model assumes very low noise of equal magnitude for all output levels, while in the other all noise is at the level of the nonlinearity output.) As our work shows, one can arrive at different—even opposite—conclusions depending on where noise is assumed to enter the circuit. Without experimentally determining the sources of noise in each circuit, it is impossible to determine whether that circuit is performing optimally.</p>
<p>Going beyond single neurons or pathways, several recent studies have investigated the benefits of using multiple channels to encode stimuli and assigning different roles to each of those channels depending on circuit inputs. For example, Gjorgjieva and colleagues investigated when it is beneficial to encode inputs with multiple neurons of the same polarity versus encoding inputs with neurons of different polarity [<xref ref-type="bibr" rid="pcbi.1005150.ref056">56</xref>]. They conclude that ON-ON and ON-OFF circuits generally produce the same amount of mutual information, with ON-OFF circuits doing so more efficiently per spike. Our results provide a broader context in which we can interpret their findings, showing that when additive downstream noise (which was not included in their model) is anti-correlated, encoding with same polarity neurons can become a more favorable solution. Another recent study investigated under what conditions it is beneficial for multiple neurons of the same polarity to have the same threshold and when it is beneficial to split thresholds [<xref ref-type="bibr" rid="pcbi.1005150.ref021">21</xref>]. In particular, [<xref ref-type="bibr" rid="pcbi.1005150.ref021">21</xref>] find that nonlinearities split when the strength of upstream noise is weak. Our results are consistent with this finding and again broaden our understanding of why this splitting occurs: by incorporating correlations, we show that it is not simply the amount of noise that determines splitting, but the combination of noise strength and noise correlations. This identifies additional possibilities for testing these efficient coding predictions, by looking not just for cells that receive noisy input with similar magnitudes, but by looking for types of cells that receive correlated versus uncorrelated input and determining the degree of overlap of their nonlinearities.</p>
</sec>
<sec id="sec019">
<title>Conclusion</title>
<p>We find that even in relatively simple circuit models, assumptions about the location and strength of multiple noise sources in neural circuits strongly impact conclusions about optimal encoding. In particular, different relative strengths of noise upstream, downstream, or associated with nonlinear processing of signals yield different optimal coding strategies, even if the overall signal-to-noise ratio is the same. Furthermore, correlations between noise sources across multiple channels alter the degree to which optimal channels encode overlapping portions of the signal distribution, as well as the overall polarity of the channels. On the other hand, different combinations of noise sources can also yield very similar nonlinearities. Consequently, measurements of noise at various locations in neural circuits are necessary to verify or refute ideas about efficient coding and to more broadly understand the strategies by which neurons mitigate the effects of unwanted variability in neural computations.</p>
</sec>
</sec>
<sec id="sec020" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec021">
<title>Model details</title>
<p>Our model is schematized in <xref ref-type="fig" rid="pcbi.1005150.g001">Fig 1</xref>. Biophysical interpretation is discussed in detail in the Results and Discussion. We model the input to the circuit as a signal or stimulus <italic>s</italic> that comes from a distribution of possible inputs within a short integration time window, and hence is a random variable in our model. Before this input can be encoded by the circuit, it is corrupted by noise <italic>η</italic>, which we also take to be a random variable. The circuit then encodes total signal <italic>s</italic> + <italic>η</italic> by nonlinearly transforming it, <italic>f</italic>(<italic>s</italic> + <italic>η</italic>). This transformed signal sets the mean of a variable circuit response. That is, the circuit does not respond deterministically, but stochastically. We do not take this stochastic response to be spiking, due to the fact that spike generation has been shown to be repeatable, attributing variability in spiking to other sources [<xref ref-type="bibr" rid="pcbi.1005150.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1005150.ref024">24</xref>]. Instead, inspired by quantal neurotransmitter release, which results in post-synaptic potentials of integer multiples of a fixed minimum size, we model the stochastic response as a scaled Poisson distribution: responses come in integer multiples of a minimum non-zero response size <italic>κ</italic>, with an overall mean response <italic>f</italic>(<italic>s</italic> + <italic>η</italic>), conditioned on the total input, <italic>s</italic> + <italic>η</italic>. This stochastic response is then corrupted by downstream noise <italic>ζ</italic>, which we also take to be a random variable. The total response <italic>r</italic> of a single-path circuit is thus
<disp-formula id="pcbi.1005150.e017"><alternatives><graphic id="pcbi.1005150.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e017" xlink:type="simple"/><mml:math display="block" id="M17"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:mi>m</mml:mi> <mml:mo>+</mml:mo> <mml:mi>ζ</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
where <italic>m</italic> is a Poisson-distributed random variable with mean <italic>κ</italic><sup> − 1</sup> <italic>f</italic>(<italic>s</italic> + <italic>η</italic>), such that the mean of <italic>κm</italic> is <italic>f</italic>(<italic>s</italic> + <italic>η</italic>). Our circuit model thus has three sources of intrinsic variability: the additive noise sources (<italic>η</italic> and <italic>ζ</italic>) and the stochastic scaled-Poisson response.</p>
<p>We assume the statistics of the signal and noise are held fixed over a time window long enough that the circuit can adapt its nonlinearity to the full distribution of signal and noise. That is, in a small integration time window <italic>Δt</italic>, the channel receives a draw from the signal and noise distributions to produce a response. Thus, we model the signal <italic>s</italic> and noises <italic>η</italic>, <italic>ζ</italic>, and the scaled Poisson responses as random variables rather than stochastic processes.</p>
<p>In this work, we assume the distribution of possible inputs to be Gaussian with fixed variance <inline-formula id="pcbi.1005150.e018"><alternatives><graphic id="pcbi.1005150.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>; without loss of generality we can take the mean to be zero (i.e., the signal represents variations relative to a mean background). We assume the upstream and downstream noise to be Gaussian with mean 0 and variances <inline-formula id="pcbi.1005150.e019"><alternatives><graphic id="pcbi.1005150.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005150.e020"><alternatives><graphic id="pcbi.1005150.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>, respectively. The assumption of Gaussian distributions for the input and noise is not a restriction of the model, but a choice we make to simplify our analyses and because we expect physiologically relevant noise sources to share many of the properties of a Gaussian distribution. Even in cases where the input distribution is not Gaussian, pre-processing of inputs can remove heavy tails and lead to more Gaussian-like input distributions. It has been shown that stimulus filtering in the retina indeed has this effect [<xref ref-type="bibr" rid="pcbi.1005150.ref074">74</xref>].</p>
<p>An additional scenario to consider is the possibility that the signal properties, such as the variances, could themselves be random. We might then wonder how this would impact the predicted nonlinearities. As a “trial” of our model is a single draw from the stimulus and noise distributions, there is no well-defined variance on a <italic>single</italic> trial. A changing variance on every trial would be equivalent to starting with a broader noise distribution of fixed variance. We can thus interpret the stimulus distribution we use in the study to be the effective distribution after trial-by-trial variations in variance have already been taken into account. The results for a signal of constant variance can thus be adapted, qualitatively, to the case of random trial-by-trial variance by increasing the stimulus variance in order to mimic the impact that trial-by-trial changes in variance have on the shape of the nonlinearity.</p>
</sec>
<sec id="sec022">
<title>Two methods for determining the optimal nonlinearities</title>
<p>In order to understand how noise properties and location impact efficient coding strategies, we seek the nonlinearity that best encoded the input distribution for a variety of noise conditions. We primarily consider the mean squared error (MSE) of a linear estimator of the stimulus, as outlined below, as our criterion of optimality. This is not the only possible optimality criterion, so to check the effects that other criteria might have, we also consider maximizing the mutual information (MI) between stimulus and response. MI provides a measure of coding fidelity that is free from assumptions about how information is read out from responses. However, MI is difficult to evaluate analytically for all but the simplest models. Indeed, for our model, deriving exact analytic equations for the optimal nonlinearities using MI is intractable. We turn to simulations in this case.</p>
<p>We determine the nonlinearities obtained by minimizing the MSE using two complementary methods. First, we take variational derivatives of the MSE with respect to the nonlinearities themselves to derive a set of exact equations for the optimal nonlinearities, free from any assumptions about their shape or functional form, as described below. The only constraints we apply are that the nonlinearity must be non-negative and saturate at a value of 1. (The choice of saturation level is arbitrary and does not affect the results.) Applying such constraints are non-trivial—in most variational problems constraints enforce an equality, but in our method we are enforcing an inequality, discussed in the next section. Using this analytic approach, we minimize the assumptions we make about the nonlinearities and obtain insights into the behavior of the model that are otherwise inaccessible.</p>
<p>Second, we parametrize the nonlinearities as sigmoidal or piecewise linear curves with two parameters that control the slope and offset. We simulate the model, sweeping over the slope and offset parameters (<xref ref-type="fig" rid="pcbi.1005150.g008">Fig 8A</xref>) until we find the parameter set that minimizes the MSE of the linear readout. This parametric approach makes strong assumptions about the form of the nonlinearity but also has distinct advantages. Simulations allow us to test to what extent our conclusions about the shape (i.e., slope and offset) of the optimal nonlinearity depend on its specific functional form. For example, we find from our analytical calculations that optimal nonlinearities are roughly piecewise linear (<xref ref-type="fig" rid="pcbi.1005150.g008">Fig 8C</xref>), but one might expect biophysical constraints to restrict neurons to having smooth nonlinearities. For this reason, we also test sigmoidal shaped nonlinearities, a smooth approximation of the piecewise linear solutions that emerge from the nonparametric analytical approach, and use simulations to find the optimal parameters. We find the results with sigmoidal nonlinearities qualitatively very similar to the analytical solution (<xref ref-type="fig" rid="pcbi.1005150.g008">Fig 8C</xref>).</p>
<fig id="pcbi.1005150.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Complementary methods for determining the optimal nonlinearity.</title>
<p><bold>A:</bold> We use simulations to find the sigmoidal nonlinearity that minimizes the mean squared error (MSE) of a linear readout of the stimulus. We sweep over multiple possible slope and offset combinations to find the optimal nonlinearity. MSE is given in units of the stimulus variance, <inline-formula id="pcbi.1005150.e021"><alternatives><graphic id="pcbi.1005150.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>. <bold>B:</bold> Using the same method as <bold>A</bold>, we maximize the mutual information (MI) between stimulus and responses. MI is given in units of bits. <bold>C:</bold> Optimal sigmoidal nonlinearities (blue and purple curves) found from simulations versus the optimal nonlinearity determined by solving the model analytically (gray curve). The analytical solution is determined non-parametrically, and was not chosen to be piecewise linear. All nonlinearities are qualitatively similar, regardless of the criterion for optimality or constraints on the functional form of the nonlinearity.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.g008" xlink:type="simple"/>
</fig>
<p>Parametric simulations have the additional advantage of allowing tests of more complex criteria for optimality than the MSE, such as maximizing the mutual information (MI) between the stimulus and responses, which we cannot compute analytically. Using simulations with parametrized nonlinearities, we are able to find the nonlinearity that maximizes MI (<xref ref-type="fig" rid="pcbi.1005150.g008">Fig 8B</xref>). We have verified that optimal nonlinearities found by maximizing MI are qualitatively similar to those found by minimizing the MSE of a linear readout (<xref ref-type="fig" rid="pcbi.1005150.g008">Fig 8C</xref> shows one example). For simplicity, throughout the main text of this paper we focus on results for minimizing MSE, but present results from maximizing MI in a few cases for comparison.</p>
</sec>
<sec id="sec023">
<title>Variational approach</title>
<sec id="sec024">
<title>Single pathway</title>
<p>We first evaluate how well a single pathway encodes the signal <italic>s</italic> using the mean squared error (MSE) between the true signal <italic>s</italic> and an estimate of the signal, <italic>s</italic><sub>est</sub>, computed from the responses:
<disp-formula id="pcbi.1005150.e022"><alternatives><graphic id="pcbi.1005150.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e022" xlink:type="simple"/><mml:math display="block" id="M22"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>χ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:msub><mml:mfenced close="⟩" open="⟨" separators=""><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>est</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mfenced> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where the average is taken over all possible inputs and all possible responses (or, equivalently, all possible inputs and all possible configurations of intrinsic circuit variability). We choose as our signal-estimator a linear function of the response:
<disp-formula id="pcbi.1005150.e023"><alternatives><graphic id="pcbi.1005150.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e023" xlink:type="simple"/><mml:math display="block" id="M23"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mtext>est</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>D</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:mi>D</mml:mi> <mml:mi>r</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
The parameter <italic>D</italic> is a “decoding weight” that sets the scale between the signal estimate and the responses. It can be shown that minimizing <italic>χ</italic><sup>2</sup> with respect to the parameter <italic>D</italic><sub>0</sub> yields <italic>D</italic><sub>0</sub> = −<italic>D</italic>〈<italic>r</italic>〉, so the estimator may be written
<disp-formula id="pcbi.1005150.e024"><alternatives><graphic id="pcbi.1005150.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e024" xlink:type="simple"/><mml:math display="block" id="M24"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mtext>est</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mi>D</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>r</mml:mi> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
<p>For the linear estimator, the expression for the MSE yields
<disp-formula id="pcbi.1005150.e025"><alternatives><graphic id="pcbi.1005150.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e025" xlink:type="simple"/><mml:math display="block" id="M25"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>χ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>D</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>s</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msup><mml:mi>D</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>var</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
where the averages 〈…〉 are taken over the stimulus and noise distributions: <italic>s</italic>, <italic>η</italic>, <italic>ζ</italic> (averages over the scaled-Poisson variable have been evaluated completely). This expression for the MSE is a function of the decoding weight <italic>D</italic> and a functional of the nonlinearity <italic>f</italic>(<italic>z</italic>). To find the most efficient coding strategy for a fixed set of noise parameters <inline-formula id="pcbi.1005150.e026"><alternatives><graphic id="pcbi.1005150.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, <italic>κ</italic>, and <inline-formula id="pcbi.1005150.e027"><alternatives><graphic id="pcbi.1005150.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>, we must minimize <italic>χ</italic><sup>2</sup> with respect to <italic>both</italic> the decoding weight <italic>D</italic> (which gives the “optimal linear estimator”) and the nonlinearity <italic>f</italic>(<italic>z</italic>).</p>
<p>We can minimize <italic>χ</italic><sup>2</sup> with respect to the decoding weight <italic>D</italic> by taking a partial derivative and setting it equal to zero, yielding
<disp-formula id="pcbi.1005150.e028"><alternatives><graphic id="pcbi.1005150.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e028" xlink:type="simple"/><mml:math display="block" id="M28"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>D</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:mi>κ</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>var</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>s</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula></p>
<p>To determine the optimal nonlinearity, subject to the constraints 0 ≤ <italic>f</italic>(<italic>z</italic>) ≤ 1, we take a variational derivative of the MSE with respect to the nonlinearity itself. The constraints can be formally applied using a continuous version of the Karush–Kuhn–Tucker (KKT) conditions, an extension of the method of Lagrange multipliers to inequality constraints. This allows us to free ourselves from <italic>all</italic> assumptions about the shape of the nonlinearity outside of the limited dynamic range we impose. For Gaussian stimuli and upstream noise of respective variances <inline-formula id="pcbi.1005150.e029"><alternatives><graphic id="pcbi.1005150.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005150.e030"><alternatives><graphic id="pcbi.1005150.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>, the resulting equation for <italic>f</italic>(<italic>z</italic>) is
<disp-formula id="pcbi.1005150.e031"><alternatives><graphic id="pcbi.1005150.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>Ξ</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mfrac><mml:mi>z</mml:mi> <mml:mi>D</mml:mi></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>κ</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
where <italic>Ξ</italic>(<italic>x</italic>) = 0 if <italic>x</italic> &lt; 0, 1 if <italic>x</italic> &gt; 1, and <italic>x</italic> if 0 ≤ <italic>x</italic> ≤ 1; this imposes the constraints on the solution. From <xref ref-type="disp-formula" rid="pcbi.1005150.e031">Eq (7)</xref>, we read off that the optimal single-pathway nonlinearity is a piecewise linear function (i.e., the nonlinearity is of the form <italic>mz</italic> + <italic>b</italic> for <italic>z</italic><sub>0</sub> &lt; <italic>z</italic> &lt; <italic>z</italic><sub>1</sub>, and is 0 for <italic>z</italic> &lt; <italic>z</italic><sub>0</sub> and 1 for <italic>z</italic> &gt; <italic>z</italic><sub>1</sub>). It is important to reiterate that, other than the limited dynamic range, we did not impose any assumptions (such as monotonicity) on the nonlinearity. All that remains is to self-consistently determine the constants <italic>D</italic> and 〈<italic>f</italic>(<italic>s</italic> + <italic>η</italic>)〉. Rather than solve directly for these constants, it is convenient to write the nonlinearity as
<disp-formula id="pcbi.1005150.e032"><alternatives><graphic id="pcbi.1005150.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e032" xlink:type="simple"/><mml:math display="block" id="M32"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>Ξ</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mrow><mml:mi>z</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
and solve for the constants <italic>z</italic><sub>0</sub> and <italic>z</italic><sub>1</sub>, which are defined by <inline-formula id="pcbi.1005150.e033"><alternatives><graphic id="pcbi.1005150.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mrow><mml:mi>f</mml:mi> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>z</mml:mi> <mml:mn>0</mml:mn> <mml:mo>+</mml:mo></mml:msubsup> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005150.e034"><alternatives><graphic id="pcbi.1005150.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mrow><mml:mi>f</mml:mi> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>z</mml:mi> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo></mml:msubsup> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. This yields the relations <inline-formula id="pcbi.1005150.e035"><alternatives><graphic id="pcbi.1005150.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mi>D</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>/</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and <italic>z</italic><sub>0</sub> = (<italic>z</italic><sub>1</sub> − <italic>z</italic><sub>0</sub>)(<italic>κ</italic>/2 − 〈<italic>f</italic>(<italic>s</italic> + <italic>η</italic>)〉). Using these relations and <xref ref-type="disp-formula" rid="pcbi.1005150.e032">Eq (8)</xref> to compute the expectations appearing in <xref ref-type="disp-formula" rid="pcbi.1005150.e028">Eq (6)</xref> yields a set of transcendental equations for <italic>z</italic><sub>1</sub> and <italic>z</italic><sub>0</sub> that can be solved numerically for any values of the noise parameters <inline-formula id="pcbi.1005150.e036"><alternatives><graphic id="pcbi.1005150.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005150.e037"><alternatives><graphic id="pcbi.1005150.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>, <italic>κ</italic> and <inline-formula id="pcbi.1005150.e038"><alternatives><graphic id="pcbi.1005150.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>. The expectation integrals 〈…〉 over <italic>s</italic> and <italic>η</italic> can be non-dimensionalized by a change of variables that shows that <inline-formula id="pcbi.1005150.e039"><alternatives><graphic id="pcbi.1005150.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:msub><mml:mi>x</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005150.e040"><alternatives><graphic id="pcbi.1005150.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:msub><mml:mi>x</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, for rescaled inputs <italic>x</italic><sub>1</sub> and <italic>x</italic><sub>0</sub> that depend only on <italic>κ</italic> and <inline-formula id="pcbi.1005150.e041"><alternatives><graphic id="pcbi.1005150.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>. Following this result, we set <inline-formula id="pcbi.1005150.e042"><alternatives><graphic id="pcbi.1005150.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:mrow><mml:mi>z</mml:mi> <mml:mo>=</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:mi>x</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1005150.e031">Eq (7)</xref>. The resulting coefficient of <italic>x</italic> is <inline-formula id="pcbi.1005150.e043"><alternatives><graphic id="pcbi.1005150.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>/</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:mo>/</mml:mo> <mml:mi>D</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Non-dimensionalizing the expectation values in <xref ref-type="disp-formula" rid="pcbi.1005150.e028">Eq (6)</xref> reveals that this parameter combination only depends on the non-dimensionalized expectation integrals, and so <italic>f</italic>(<italic>z</italic>) normalizes the input <italic>z</italic> by the standard deviation of <italic>z</italic>. As a result, the rescaled nonlinearity <inline-formula id="pcbi.1005150.e044"><alternatives><graphic id="pcbi.1005150.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is independent of <inline-formula id="pcbi.1005150.e045"><alternatives><graphic id="pcbi.1005150.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005150.e046"><alternatives><graphic id="pcbi.1005150.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>.</p>
</sec>
<sec id="sec025">
<title>Two pathways</title>
<p>Our model of a two-pathway circuit encoding a common signal input builds on two copies of the single-pathway circuit. Both paths receive the same input signal <italic>s</italic>, which is then corrupted by noise upstream of the encoding nonlinearity. The corrupting noise is not the same in each pathway, but may be correlated. Thus, the total input to pathway 1 is <italic>s</italic> + <italic>η</italic><sub>1</sub> and the total input to pathway 2 is <italic>s</italic> + <italic>η</italic><sub>2</sub>. Each pathway then encodes its input by nonlinearly transforming it, <italic>f</italic><sub>1</sub>(<italic>s</italic> + <italic>η</italic><sub>1</sub>) and <italic>f</italic><sub>2</sub>(<italic>s</italic> + <italic>η</italic><sub>2</sub>). The transformed signals set the mean of the scaled-Poisson noise in each path. The stochastic responses of each path are conditionally independent of each other. That is, correlations in the stochastic responses are only due to correlations in the inputs to the two pathways, not due to any intrinsic correlation. Finally, these stochastic responses are each corrupted by noise downstream of the encoding nonlinearity. The noise is not the same in each pathway, but may be correlated across pathways.</p>
<p>The responses for each pathway may be formulated mathematically as
<disp-formula id="pcbi.1005150.e047"><alternatives><graphic id="pcbi.1005150.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e047" xlink:type="simple"/><mml:math display="block" id="M47"><mml:msub><mml:mi>r</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:msub><mml:mi>m</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ζ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo></mml:math></alternatives> <label>(9)</label></disp-formula> <disp-formula id="pcbi.1005150.e048"><alternatives><graphic id="pcbi.1005150.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e048" xlink:type="simple"/><mml:math display="block" id="M48"><mml:msub><mml:mi>r</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:msub><mml:mi>m</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ζ</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo></mml:math></alternatives> <label>(10)</label></disp-formula>
where <italic>m</italic><sub>1</sub> and <italic>m</italic><sub>2</sub> are Poisson-distributed integers with (conditional) means <italic>κ</italic><sup>−1</sup> <italic>f</italic><sub>1</sub>(<italic>s</italic> + <italic>η</italic><sub>1</sub>) and <italic>κ</italic><sup>−1</sup> <italic>f</italic><sub>2</sub>(<italic>s</italic> + <italic>η</italic><sub>2</sub>), respectively. As in the single-pathway model, we assume there is a distribution of inputs <italic>s</italic> that we model as a zero-mean Gaussian with variance <inline-formula id="pcbi.1005150.e049"><alternatives><graphic id="pcbi.1005150.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e049" xlink:type="simple"/><mml:math display="inline" id="M49"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>. As the upstream noise is correlated, <italic>η</italic><sub>1</sub> and <italic>η</italic><sub>2</sub> follow a joint-distribution that we take to be a zero-mean Gaussian with equal variances <inline-formula id="pcbi.1005150.e050"><alternatives><graphic id="pcbi.1005150.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e050" xlink:type="simple"/><mml:math display="inline" id="M50"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> in each pathway and correlation coefficient <italic>ρ</italic><sub>up</sub>. Similarly, we model the downstream noise as a zero-mean bivariate Gaussian with variance <inline-formula id="pcbi.1005150.e051"><alternatives><graphic id="pcbi.1005150.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> in both pathways and correlation coefficient <italic>ρ</italic><sub>down</sub>. The rationales for choosing Gaussian distributions are the same as in the single-pathway model. The choice of equal upstream or downstream noise variance in each channel simplifies the analysis; unequal variances are tractable but offer little additional insight, so we do not discuss this case in this work.</p>
<p>As in the single-path case, we determine the optimal choices of nonlinearities by minimizing the mean-squared-error between the input to the circuit and an estimate computed from the responses of each pathway. We estimate the signal using a weighted sum of the responses,
<disp-formula id="pcbi.1005150.e052"><alternatives><graphic id="pcbi.1005150.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e052" xlink:type="simple"/><mml:math display="block" id="M52"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mtext>est</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>D</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
(The constant shift <italic>D</italic><sub>0</sub> has been decomposed into the optimal choice, <italic>D</italic><sub>0</sub> = −<italic>D</italic><sub>1</sub>〈<italic>r</italic><sub>1</sub>〉 − <italic>D</italic><sub>2</sub>〈<italic>r</italic><sub>2</sub>〉.) The MSE for this choice of decoder works out to
<disp-formula id="pcbi.1005150.e053"><alternatives><graphic id="pcbi.1005150.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e053" xlink:type="simple"/><mml:math display="block" id="M53"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msup><mml:mi>χ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>s</mml:mi> <mml:msub><mml:mi>f</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:msub><mml:mi>D</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>s</mml:mi> <mml:msub><mml:mi>f</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:msubsup><mml:mi>D</mml:mi> <mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>var</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:msubsup><mml:mi>D</mml:mi> <mml:mn>2</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>var</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:mn>2</mml:mn> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>D</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mtext>cov</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>;</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
averages in this expression are taken over the stimulus <italic>s</italic>, and the joint distributions of <italic>η</italic><sub>1</sub> and <italic>η</italic><sub>2</sub>; averages over <italic>ζ</italic><sub>1</sub> and <italic>ζ</italic><sub>2</sub> have been performed, yielding terms depending on the variance (<inline-formula id="pcbi.1005150.e054"><alternatives><graphic id="pcbi.1005150.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e054" xlink:type="simple"/><mml:math display="inline" id="M54"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>) and correlation (<italic>ρ</italic><sub>down</sub>) of the downstream noise. Taking regular derivatives with respect to the decoding weights <italic>D</italic><sub>1</sub> and <italic>D</italic><sub>2</sub> and variational derivatives with respect to <italic>f</italic><sub>1</sub>(<italic>z</italic>) and <italic>f</italic><sub>2</sub>(<italic>z</italic>) yields a coupled set of integral equations for the optimal weights and nonlinearities (subject again to the constraints 0 ≤ <italic>f</italic><sub>1</sub>(<italic>z</italic>) ≤ 1 and 0 ≤ <italic>f</italic><sub>2</sub>(<italic>z</italic>) ≤ 1). To simplify the resulting equations, we present them here in rescaled form, defining the rescaled nonlinearities <inline-formula id="pcbi.1005150.e055"><alternatives><graphic id="pcbi.1005150.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e055" xlink:type="simple"/><mml:math display="inline" id="M55"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005150.e056"><alternatives><graphic id="pcbi.1005150.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi>f</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, as well as the rescaled decoder weights <inline-formula id="pcbi.1005150.e057"><alternatives><graphic id="pcbi.1005150.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e057" xlink:type="simple"/><mml:math display="inline" id="M57"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:msub><mml:mi>D</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>/</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005150.e058"><alternatives><graphic id="pcbi.1005150.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e058" xlink:type="simple"/><mml:math display="inline" id="M58"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:msub><mml:mi>D</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>/</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. This reflects that, as in the single-pathway case, the optimal nonlinearities rescale inputs by the total input standard deviation <inline-formula id="pcbi.1005150.e059"><alternatives><graphic id="pcbi.1005150.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e059" xlink:type="simple"/><mml:math display="inline" id="M59"><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:math></alternatives></inline-formula>. The equations for the rescaled decoder weights and nonlinearities are
<disp-formula id="pcbi.1005150.e060"><alternatives><graphic id="pcbi.1005150.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e060" xlink:type="simple"/><mml:math display="block" id="M60"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:mi>κ</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>var</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mo>+</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:mtext>cov</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:msub></mml:mfenced> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>y</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula> <disp-formula id="pcbi.1005150.e061"><alternatives><graphic id="pcbi.1005150.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e061" xlink:type="simple"/><mml:math display="block" id="M61"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:mi>κ</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>var</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mo>+</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:mtext>cov</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:msub></mml:mfenced> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>y</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula> <disp-formula id="pcbi.1005150.e062"><alternatives><graphic id="pcbi.1005150.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e062" xlink:type="simple"/><mml:math display="block" id="M62"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>Ξ</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mi>x</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>κ</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub></mml:mfrac> <mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>y</mml:mi> <mml:mspace width="3.33333pt"/><mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>y</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msub> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:msup> <mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>y</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula> <disp-formula id="pcbi.1005150.e063"><alternatives><graphic id="pcbi.1005150.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e063" xlink:type="simple"/><mml:math display="block" id="M63"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>Ξ</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mi>x</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>κ</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub></mml:mfrac> <mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>y</mml:mi> <mml:mspace width="3.33333pt"/><mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>y</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msub> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:msup> <mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>y</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
where again Ξ(<italic>x</italic>) = 0 if <italic>x</italic> &lt; 0, 1 if <italic>x</italic> &gt; 1, and <italic>x</italic> if 0 ≤ <italic>x</italic> ≤ 1. Here, the averages 〈…〉 involving single nonlinearities are integrals with respect to a standard normal distribution weight, <inline-formula id="pcbi.1005150.e064"><alternatives><graphic id="pcbi.1005150.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e064" xlink:type="simple"/><mml:math display="inline" id="M64"><mml:mrow><mml:mo form="prefix">exp</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:msup><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>/</mml:mo> <mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>; e.g.,
<disp-formula id="pcbi.1005150.e065"><alternatives><graphic id="pcbi.1005150.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e065" xlink:type="simple"/><mml:math display="block" id="M65"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>y</mml:mi> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>y</mml:mi> <mml:mspace width="3.33333pt"/><mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:msup><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup> <mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:msqrt></mml:mfrac> <mml:mi>y</mml:mi> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>y</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
The covariance between <inline-formula id="pcbi.1005150.e066"><alternatives><graphic id="pcbi.1005150.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e066" xlink:type="simple"/><mml:math display="inline" id="M66"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005150.e067"><alternatives><graphic id="pcbi.1005150.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e067" xlink:type="simple"/><mml:math display="inline" id="M67"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005150.e068"><alternatives><graphic id="pcbi.1005150.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e068" xlink:type="simple"/><mml:math display="inline" id="M68"><mml:mrow><mml:mtext>cov</mml:mtext> <mml:mo>[</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, is defined as
<disp-formula id="pcbi.1005150.e069"><alternatives><graphic id="pcbi.1005150.e069g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e069" xlink:type="simple"/><mml:math display="block" id="M69"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>cov</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where
<disp-formula id="pcbi.1005150.e070"><alternatives><graphic id="pcbi.1005150.e070g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e070" xlink:type="simple"/><mml:math display="block" id="M70"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:msub><mml:mi>y</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mi>d</mml:mi> <mml:msub><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mspace width="3.33333pt"/><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mfrac><mml:mrow><mml:msubsup><mml:mi>y</mml:mi> <mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>y</mml:mi> <mml:mn>2</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msub> <mml:msub><mml:mi>y</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:msub><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:msup> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula>
The effective upstream noise correlation coefficient is defined by <xref ref-type="disp-formula" rid="pcbi.1005150.e009">Eq (1)</xref> in the main text, and represents the total effective correlation between the inputs <italic>s</italic> + <italic>η</italic><sub>1</sub> and <italic>s</italic> + <italic>η</italic><sub>2</sub>; i.e., the perfectly correlated inputs to the two pathways (the two copies of <italic>s</italic>) are corrupted by noise, thereby reducing the overall correlation of the inputs to the two channels.</p>
<p>Unlike the single-pathway case, the equations for the paired-pathway nonlinearities are coupled nonlinear integral equations that must, in general, be solved numerically. Two special cases can be solved by hand: <italic>ρ</italic><sub>eff</sub> = 0, in which the inputs to two pathways are effectively uncorrelated (requiring large, negatively correlated upstream noise) and the equations decouple, yielding two copies of the single-pathway nonlinearity. The second case is <italic>ρ</italic><sub>eff</sub> = 1, for which the inputs to the two channels are perfectly correlated (either due to the lack of upstream noise or because upstream noise is perfectly correlated between the two channels). In this case, the Gaussian integral kernels in Eqs <xref ref-type="disp-formula" rid="pcbi.1005150.e062">(15)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005150.e063">(16)</xref> reduce to delta functions, yielding two coupled functional equations for the nonlinearities that can be solved to show the optimal nonlinearities are piecewise linear. The resulting pair of nonlinearities may have the same polarity of responses to stimuli, which we call “ON-ON” or “OFF-OFF” pairs (by analogy to ON and OFF cells in the retina) or opposite polarity responses to stimuli, which we dub “ON-OFF” or “OFF-ON” pairs.</p>
</sec>
<sec id="sec026">
<title>Numerical solution of the coupled integral equations for the paired nonlinearities</title>
<p>To solve the paired nonlinearities in general, we formulate Eqs <xref ref-type="disp-formula" rid="pcbi.1005150.e060">(13)</xref>–<xref ref-type="disp-formula" rid="pcbi.1005150.e063">(16)</xref> as fixed points of the set of iterated mappings
<disp-formula id="pcbi.1005150.e071"><alternatives><graphic id="pcbi.1005150.e071g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e071" xlink:type="simple"/><mml:math display="block" id="M71"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mi>κ</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>var</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>y</mml:mi> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mtext>cov</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:msub></mml:mfenced> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>y</mml:mi> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msubsup><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mfenced close=")" open="(" separators=""><mml:mi>κ</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>var</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mo>-</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mtext>cov</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>out</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:msub></mml:mfenced> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(18)</label></disp-formula> <disp-formula id="pcbi.1005150.e072"><alternatives><graphic id="pcbi.1005150.e072g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e072" xlink:type="simple"/><mml:math display="block" id="M72"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mi>κ</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>var</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>y</mml:mi> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mtext>cov</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:msub></mml:mfenced> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>y</mml:mi> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msubsup><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mfenced close=")" open="(" separators=""><mml:mi>κ</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>var</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mo>-</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mtext>cov</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:msub></mml:mfenced> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(19)</label></disp-formula> <disp-formula id="pcbi.1005150.e073"><alternatives><graphic id="pcbi.1005150.e073g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e073" xlink:type="simple"/><mml:math display="block" id="M73"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>Ξ</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mi>x</mml:mi> <mml:msubsup><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>κ</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:msubsup><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:msubsup><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac> <mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mo>⟨</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mspace width="-14.22636pt"/><mml:mi>d</mml:mi> <mml:mi>y</mml:mi> <mml:mspace width="3.33333pt"/><mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:msup><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup> <mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:msqrt></mml:mfrac> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mfenced close=")" open="(" separators=""><mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:mi>y</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msub> <mml:mi>x</mml:mi></mml:mfenced></mml:mfenced></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(20)</label></disp-formula> <disp-formula id="pcbi.1005150.e074"><alternatives><graphic id="pcbi.1005150.e074g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e074" xlink:type="simple"/><mml:math display="block" id="M74"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>Ξ</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mi>x</mml:mi> <mml:msubsup><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>κ</mml:mi> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:msubsup><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:msubsup><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac> <mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mo>⟨</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mspace width="-14.22636pt"/><mml:mi>d</mml:mi> <mml:mi>y</mml:mi> <mml:mspace width="3.33333pt"/><mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:msup><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup> <mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:msqrt></mml:mfrac> <mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mfenced close=")" open="(" separators=""><mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt> <mml:mi>y</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msub> <mml:mi>x</mml:mi></mml:mfenced></mml:mfenced></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(21)</label></disp-formula>
We formally solved the linear set of eqs <xref ref-type="disp-formula" rid="pcbi.1005150.e060">(13)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005150.e061">(14)</xref> for the rescaled decoding weights to write down Eqs <xref ref-type="disp-formula" rid="pcbi.1005150.e071">(18)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005150.e072">(19)</xref>. We have also changed variables in the integrals to move all dependence on <italic>ρ</italic><sub>eff</sub> into the nonlinearities. This is necessary for numerical stability when <italic>ρ</italic><sub>eff</sub> is close to 1.</p>
<p>Though we have written the above equations in rescaled form for notational simplicity, the code was written in the original, unrescaled form, so we revert to that notation when describing the algorithm below.</p>
<p>The idea of this set of iterative mappings is to make initial guesses for <inline-formula id="pcbi.1005150.e075"><alternatives><graphic id="pcbi.1005150.e075g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e075" xlink:type="simple"/><mml:math display="inline" id="M75"><mml:msubsup><mml:mi>D</mml:mi> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005150.e076"><alternatives><graphic id="pcbi.1005150.e076g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e076" xlink:type="simple"/><mml:math display="inline" id="M76"><mml:msubsup><mml:mi>D</mml:mi> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005150.e077"><alternatives><graphic id="pcbi.1005150.e077g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e077" xlink:type="simple"/><mml:math display="inline" id="M77"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi> <mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1005150.e078"><alternatives><graphic id="pcbi.1005150.e078g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e078" xlink:type="simple"/><mml:math display="inline" id="M78"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi> <mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, and use Eqs <xref ref-type="disp-formula" rid="pcbi.1005150.e071">(18)</xref>–<xref ref-type="disp-formula" rid="pcbi.1005150.e074">(21)</xref> to update the guesses until
<disp-formula id="pcbi.1005150.e079"><alternatives><graphic id="pcbi.1005150.e079g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e079" xlink:type="simple"/><mml:math display="block" id="M79"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfenced close="|" open="|" separators=""><mml:msubsup><mml:mi>D</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>D</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mfenced> <mml:mo>&lt;</mml:mo> <mml:mi>ϵ</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula> <disp-formula id="pcbi.1005150.e080"><alternatives><graphic id="pcbi.1005150.e080g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e080" xlink:type="simple"/><mml:math display="block" id="M80"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfenced close="|" open="|" separators=""><mml:msubsup><mml:mi>f</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>f</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mo>&lt;</mml:mo> <mml:mi>ϵ</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
for an absolute tolerance <italic>ϵ</italic> = 10<sup>−4</sup>, for every point <italic>z</italic>. This is a form of Picard iteration for finding the fixed points of iterated maps. It is difficult to prove convergence of this scheme, so we resort to solving the equations for multiple initial guesses and showing that they consistently converge to the same solutions. ON-OFF solutions can be found by making initial guess <italic>D</italic><sub>1</sub> &gt; 0, <italic>D</italic><sub>2</sub> &lt; 0, while ON-ON solutions can be found by making initial guess <italic>D</italic><sub>1</sub> &gt; 0, <italic>D</italic><sub>2</sub> &gt; 0. Our initial guesses are Gaussian random variables centered at ±1, with a standard deviation of 0.5.</p>
<p>Eqs <xref ref-type="disp-formula" rid="pcbi.1005150.e062">(15)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005150.e063">(16)</xref> constrain the form of the nonlinearities, which allows us to consider a restricted set of initial guesses. Because the integral kernel has unit area and the nonlinearities are restricted to the range [0, 1], the integral term in Eqs <xref ref-type="disp-formula" rid="pcbi.1005150.e073">(20)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005150.e074">(21)</xref> is also within the range [0, 1]. For initial guesses for the nonlinearities, we discretize the input values <italic>z</italic>, and for each input value we choose a uniform random value for the integral term in Eqs <xref ref-type="disp-formula" rid="pcbi.1005150.e073">(20)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005150.e074">(21)</xref>. The initial guess is also thresholded so that it satisfies the constraint <inline-formula id="pcbi.1005150.e081"><alternatives><graphic id="pcbi.1005150.e081g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e081" xlink:type="simple"/><mml:math display="inline" id="M81"><mml:mrow><mml:mn>0</mml:mn> <mml:mo>≤</mml:mo> <mml:msubsup><mml:mi>f</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≤</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>For each class of ON-OFF or ON-ON initial conditions, we use 20 different initial random seeds. The initial conditions for different seeds generally converge to the same solutions. Some rare exceptions occur: occasionally, an ON-ON or ON-OFF initial guess may find the opposite class of solution. For parameter regimes in which the MSE of identical and non-identical ON-ON solutions is very close, ON-ON guesses may result in either solution.</p>
<p>During the iterative computations, the discretized nonlinearities are fit with splines for use in numerically computing the various integrals. Single variable integrals are performed using a Gauss-Legendre quadrature scheme, while double-integrals are evaluated using Monte Carlo sampling.</p>
<p>For the parameter values used in the numerical solution of the integral equations, see the “Parameter values used in figures” section, below.</p>
</sec>
</sec>
<sec id="sec027">
<title>Model simulations</title>
<p>Analytic calculations allow us to exactly determine the nonlinearities that minimize the MSE of a linear readout, without making any assumptions about the shape of the nonlinearity. However, it is possible that certain physiological properties might constrain the shape of the nonlinearity (to be smooth, for example). It is also possible that another criterion for optimality (instead of minimizing MSE of a linear readout) might yield different results. To test these possibilities, we turned to simulations.</p>
<sec id="sec028">
<title>Minimizing MSE for different nonlinearity shapes</title>
<p>We first tested the dependence of our results on the shape of the nonlinearity. Throughout the paper, we show results for logistic nonlinearities of the form:
<disp-formula id="pcbi.1005150.e082"><alternatives><graphic id="pcbi.1005150.e082g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e082" xlink:type="simple"/><mml:math display="block" id="M82"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mo form="prefix">exp</mml:mo> <mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mi>ν</mml:mi> <mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>-</mml:mo> <mml:mi>ϕ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(22)</label></disp-formula>
where <italic>ν</italic> is a slope parameter and <italic>ϕ</italic> is an offset parameter. (Remember that we constrain the range of our nonlinearities to be between 0 and 1 to mimic physiological constraints that result in thresholding and saturating nonlinearities.) This particular form was chosen due to its smoothness (in contrast to the optimal nonlinearities found from analytic calculations) and because it can be characterized by just two parameters. For a given set of noise conditions, we drew randomly from the stimulus distribution and simulated responses that would be produced by a nonlinearity with slope parameter <italic>ν</italic> and offset <italic>ϕ</italic>. We then found the decoding weight(s) <italic>D</italic>, estimated the stimulus, and calculated the MSE. The number of draws required from the stimulus distribution to produce an accurate estimate varied widely depending on the noise parameters (with noisier conditions requiring more draws to accurately estimate the MSE). We generally used about 10 million draws from the stimulus distribution and averaged the results of 5–10 repetitions of this procedure to obtain our results. Comparison with analytical calculations verified the accuracy of our estimates. By completing this procedure for a number of different possible parameters for the nonlinearity, sweeping over a broad range of slope and offset values, we determined the parameters that minimized the MSE. These results are shown throughout the paper for comparison to the analytic solutions. The two classes are in broad agreement.</p>
</sec>
<sec id="sec029">
<title>Maximizing mutual information</title>
<p>Simulations also allowed us to test the dependence of our results on the criterion for optimality. As a second criterion, we chose to maximize the mutual information:
<disp-formula id="pcbi.1005150.e083"><alternatives><graphic id="pcbi.1005150.e083g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e083" xlink:type="simple"/><mml:math display="block" id="M83"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>M</mml:mi> <mml:mi>I</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>S</mml:mi> <mml:mo>;</mml:mo> <mml:mi>R</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>H</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>R</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>H</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:mi>R</mml:mi> <mml:mo>|</mml:mo> <mml:mi>S</mml:mi></mml:mfenced> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(23)</label></disp-formula>
where <italic>S</italic> denotes the stimulus and <italic>R</italic> denotes the response. The (differential) entropy <italic>H</italic> is given by:
<disp-formula id="pcbi.1005150.e084"><alternatives><graphic id="pcbi.1005150.e084g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e084" xlink:type="simple"/><mml:math display="block" id="M84"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>H</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>X</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>x</mml:mi> <mml:mspace width="3.33333pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mo form="prefix">log</mml:mo> <mml:mn>2</mml:mn></mml:msub> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(24)</label></disp-formula>
where <italic>p</italic>(<italic>x</italic>) denotes the probability density function of <italic>x</italic>. In order to estimate entropy, we used the binless estimator outlined by Victor in [<xref ref-type="bibr" rid="pcbi.1005150.ref075">75</xref>]. Briefly, this strategy relies on calculating nearest neighbor distances between points to estimate the distribution <italic>p</italic>(<italic>x</italic>); shorter distances indicate a higher density of points and greater <italic>p</italic>(<italic>x</italic>). The binless entropy estimate is given by:
<disp-formula id="pcbi.1005150.e085"><alternatives><graphic id="pcbi.1005150.e085g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e085" xlink:type="simple"/><mml:math display="block" id="M85"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>H</mml:mi> <mml:mrow><mml:mtext>diff</mml:mtext></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>X</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:msub><mml:mo form="prefix">log</mml:mo> <mml:mn>2</mml:mn></mml:msub> <mml:mfenced close="]" open="[" separators=""><mml:mfrac><mml:mrow><mml:msub><mml:mi>S</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:mi>M</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mfenced></mml:mrow> <mml:mi>d</mml:mi></mml:mfrac></mml:mfenced> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>γ</mml:mi> <mml:mrow><mml:mo form="prefix">ln</mml:mo> <mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>d</mml:mi> <mml:mi>M</mml:mi></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:msub><mml:mo form="prefix">log</mml:mo> <mml:mn>2</mml:mn></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>λ</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(25)</label></disp-formula> <italic>d</italic> is the dimensionality of the distribution for which entropy is being estimated (in our case, the number of pathways), <italic>M</italic> is the number of samples, and <italic>λ</italic><sub><italic>j</italic></sub> is the Euclidean distance to the nearest neighbor of sample <italic>j</italic>. <italic>S</italic><sub><italic>d</italic></sub> is the area of a unit <italic>d</italic>-dimensional spherical surface (<italic>S</italic><sub>1</sub> = 2, <italic>S</italic><sub>2</sub> = 2<italic>π</italic>). <italic>γ</italic> is the Euler-Mascheroni constant. See [<xref ref-type="bibr" rid="pcbi.1005150.ref075">75</xref>] for further details. As with estimating the MSE, the number of draws from the stimulus distribution required for convergence was based on the value of the noise parameters. Generally, about 10,000 draws from the stimulus distribution were taken to estimate <italic>H</italic>(<italic>R</italic>). For each of those stimulus values, about 10,000–100,000 responses were simulated (on different “trials,” the same stimulus presented repeatedly yields different responses due to noise) to estimate <italic>H</italic>(<italic>R</italic>|<italic>S</italic>). Results of about 10 repetitions were averaged to obtain the final MI estimate.</p>
<p>The binless method requires that no two samples be identical, which can pose problems in certain conditions. For example, if <italic>κ</italic> is nonzero such that the output of the nonlinearity is discretized into a certain number of bins and downstream noise is zero or very small, many responses are likely to be identical to numerical precision. In these cases, a more standard binned method was used to estimate entropy:
<disp-formula id="pcbi.1005150.e086"><alternatives><graphic id="pcbi.1005150.e086g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e086" xlink:type="simple"/><mml:math display="block" id="M86"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>H</mml:mi> <mml:mrow><mml:mtext>diff</mml:mtext></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>X</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:mo>-</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mo form="prefix">log</mml:mo> <mml:mn>2</mml:mn></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>w</mml:mi></mml:mfrac></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(26)</label></disp-formula>
where <italic>w</italic> is the bin width. Similar numbers of draws from the stimulus distribution were used as were used with the binless estimator. Generally, MI estimates converged when ∼50 bins were used.</p>
<p>Several test cases were used to verify that the binless and binned approaches yielded consistent estimates of the mutual information. MI estimates were additionally verified by comparing the estimates produced by these methods to particular cases in which the response distribution can be calculated analytically, enabling accurate numerical computation of the mutual information. Two cases were tested analytically. In both cases, the only source of noise is the downstream noise. The noise entropy <italic>H</italic>(<italic>R</italic>|<italic>S</italic>) is then equivalent for all <italic>S</italic> and the second term in <xref ref-type="disp-formula" rid="pcbi.1005150.e083">Eq (23)</xref> is simply the entropy of the downstream noise distribution, <inline-formula id="pcbi.1005150.e087"><alternatives><graphic id="pcbi.1005150.e087g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e087" xlink:type="simple"/><mml:math display="inline" id="M87"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:msub><mml:mo form="prefix">log</mml:mo> <mml:mn>2</mml:mn></mml:msub> <mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mi>π</mml:mi> <mml:mi>e</mml:mi> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. The nonlinearity thus only affects the response entropy <italic>H</italic>(<italic>R</italic>). The first of the two nonlinearities considered was the cumulative distribution function of the stimulus distribution; the output of the nonlinearity is then a uniform distribution on [0, 1]. The response distribution is this uniform distribution convolved with the downstream noise distribution, giving
<disp-formula id="pcbi.1005150.e088"><alternatives><graphic id="pcbi.1005150.e088g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e088" xlink:type="simple"/><mml:math display="block" id="M88"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>r</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mtext>erf</mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mi>r</mml:mi> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:msub><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mfenced> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mtext>erf</mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mrow><mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:msub><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1005150.e089"><alternatives><graphic id="pcbi.1005150.e089g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e089" xlink:type="simple"/><mml:math display="inline" id="M89"><mml:mrow><mml:mtext>erf</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn> <mml:msup><mml:mi>π</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>x</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mspace width="3.33333pt"/><mml:mo form="prefix">exp</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:msup><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the error function. The second nonlinearity tested was a piecewise-linear nonlinearity, <inline-formula id="pcbi.1005150.e090"><alternatives><graphic id="pcbi.1005150.e090g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e090" xlink:type="simple"/><mml:math display="inline" id="M90"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>Ξ</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. The response distribution can be computed exactly, but the expression is moderately lengthy, so it is omitted here. In both cases, numerical evaluation of <italic>H</italic>(<italic>R</italic>) can be done by direct numerical integration of <italic>p</italic>(<italic>r</italic>)log<sub>2</sub> <italic>p</italic>(<italic>r</italic>).</p>
<p>Optimal nonlinearities obtained by maximizing the mutual information were in broad agreement with those found by minimizing the mean squared error, as observed in <xref ref-type="supplementary-material" rid="pcbi.1005150.s002">S2 Fig</xref> (compared to <xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref>) and <xref ref-type="supplementary-material" rid="pcbi.1005150.s003">S3 Fig</xref> (compared to <xref ref-type="fig" rid="pcbi.1005150.g005">Fig 5</xref>).</p>
</sec>
<sec id="sec030">
<title>Signal-to-noise ratio</title>
<p>For a single channel, we define the signal-to-noise ratio (SNR) used in <xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref> as
<disp-formula id="pcbi.1005150.e091"><alternatives><graphic id="pcbi.1005150.e091g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e091" xlink:type="simple"/><mml:math display="block" id="M91"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtext>SNR</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow> <mml:mo>[</mml:mo> <mml:mrow><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>]</mml:mo></mml:mrow> </mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mrow> <mml:mo>[</mml:mo> <mml:mrow><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>]</mml:mo></mml:mrow> </mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(27)</label></disp-formula>
where the innermost expectation (numerator) and variance (denominator) are taken over all responses <italic>r</italic> = <italic>κm</italic> + <italic>ζ</italic>, conditioned on the stimulus. The outer variance (numerator) and expectation (denominator) are then taken over the stimulus distribution. In terms of integrals over the rescaled nonlinearities defined above, the SNR may be written
<disp-formula id="pcbi.1005150.e092"><alternatives><graphic id="pcbi.1005150.e092g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e092" xlink:type="simple"/><mml:math display="block" id="M92"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>SNR</mml:mtext> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mo>⟨</mml:mo> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:mrow><mml:mrow><mml:mo>⟨</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(28)</label></disp-formula>
The covariance-like term <inline-formula id="pcbi.1005150.e093"><alternatives><graphic id="pcbi.1005150.e093g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e093" xlink:type="simple"/><mml:math display="inline" id="M93"><mml:mrow><mml:mo>〈</mml:mo> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> has the same form as <xref ref-type="disp-formula" rid="pcbi.1005150.e070">Eq (17)</xref>, evaluated with <inline-formula id="pcbi.1005150.e094"><alternatives><graphic id="pcbi.1005150.e094g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e094" xlink:type="simple"/><mml:math display="inline" id="M94"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. It is not an actual covariance; it results from averaging <inline-formula id="pcbi.1005150.e095"><alternatives><graphic id="pcbi.1005150.e095g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e095" xlink:type="simple"/><mml:math display="inline" id="M95"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>η</mml:mi></mml:msub> <mml:msup><mml:mrow><mml:mo>[</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:mi>η</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> over the stimulus, using the fact we can rewrite this term as <inline-formula id="pcbi.1005150.e096"><alternatives><graphic id="pcbi.1005150.e096g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e096" xlink:type="simple"/><mml:math display="inline" id="M96"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:msub><mml:mi>η</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:msub> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:msub><mml:mi>η</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:msub> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, for two independent random variables <italic>η</italic><sub>1</sub> and <italic>η</italic><sub>2</sub>.</p>
</sec>
</sec>
<sec id="sec031">
<title>Parameter values used in figures</title>
<p>For all results, the stimulus is drawn from the standard normal distribution, and nonlinearity outputs are constrained to fall between 0 and 1.</p>
<p>For the simulations presented in this work, we swept over the parameters listed in <xref ref-type="table" rid="pcbi.1005150.t001">Table 1</xref>. We chose a lower value of <italic>σ</italic><sub>down</sub> = 0.1 rather than 0 to limit the number of parameter sets for which all noise sources in the model were zero, as these sets frequently do not converge within a reasonable amount of time. Because our code is written in terms of the unrescaled nonlinearities, we swept over <italic>ρ</italic><sub>eff</sub> by fixing <italic>σ</italic><sub>s</sub> = 1 and <italic>σ</italic><sub>up</sub> = 2 and sweeping over the upstream noise correlation coefficient <italic>ρ</italic><sub>up</sub> = {− 0.25, 0.0625, 0.3750, 0.6875, 1.0}. We swept over a much finer range of <italic>ρ</italic><sub>up</sub> between 0.875 and 1 to resolve the splitting seen in <xref ref-type="fig" rid="pcbi.1005150.g006">Fig 6</xref>. For these cases, we only used one initial seed to speed up computation.</p>
<table-wrap id="pcbi.1005150.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.t001</object-id>
<label>Table 1</label>
<caption>
<title>Parameter values used in numerical solutions of the coupled integral equations determining the optimal nonlinearities <italic>f</italic><sub>1</sub>(<italic>z</italic>) and <italic>f</italic><sub>2</sub>(<italic>z</italic>).</title>
</caption>
<alternatives>
<graphic id="pcbi.1005150.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<tbody>
<tr>
<td align="center"><italic>ρ</italic><sub>eff</sub></td>
<td align="center">0, 0.25, 0.5, 0.75, 1.0</td>
</tr>
<tr>
<td align="center"><italic>κ</italic></td>
<td align="center">0, 0.25, 0.5, 0.75, 1.0</td>
</tr>
<tr>
<td align="center"><italic>σ</italic><sub>down</sub></td>
<td align="center">0.1, 0.25, 0.5, 0.75, 1.0</td>
</tr>
<tr>
<td align="center"><italic>ρ</italic><sub>down</sub></td>
<td align="center">-1.0, -0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1.0</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>The upstream noise variance must be larger than the stimulus variance in order to achieve <italic>ρ</italic><sub>eff</sub> = 0. As the rescaled nonlinearities only depend on the <italic>ρ</italic><sub>eff</sub>, <italic>κ</italic>, <italic>σ</italic><sub>down</sub> and <italic>ρ</italic><sub>down</sub>, this choice only affects the absolute values of the MSE, which do depend on the ratio between <italic>σ</italic><sub>s</sub> and <italic>σ</italic><sub>up</sub>. Despite the dependence of the MSE on <italic>σ</italic><sub>s</sub> and <italic>σ</italic><sub>up</sub>, changing these parameters does not change which solutions are optimal for a fixed set of <italic>ρ</italic><sub>eff</sub>, <italic>κ</italic>, <italic>σ</italic><sub>down</sub> and <italic>ρ</italic><sub>down</sub>. This is because, for the optimal nonlinearities, the MSE works out to (in terms of the rescaled nonlinearities and decoding weights)
<disp-formula id="pcbi.1005150.e097"><alternatives><graphic id="pcbi.1005150.e097g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e097" xlink:type="simple"/><mml:math display="block" id="M97"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>χ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mfenced close="]" open="[" separators=""><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow/><mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>⟨</mml:mo><mml:mi>y</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>⟩</mml:mo> <mml:mo>+</mml:mo></mml:mrow> <mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>y</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow></mml:mfenced></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
The term <inline-formula id="pcbi.1005150.e098"><alternatives><graphic id="pcbi.1005150.e098g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e098" xlink:type="simple"/><mml:math display="inline" id="M98"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>〈</mml:mo> <mml:mi>y</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>〉</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>〈</mml:mo> <mml:mi>y</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is always positive because the decoding weights and averages always have the same sign. For fixed parameter values, it is only this term that varies between ON-OFF and ON-ON pairs. As the rescaled quantities only depend on <inline-formula id="pcbi.1005150.e099"><alternatives><graphic id="pcbi.1005150.e099g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e099" xlink:type="simple"/><mml:math display="inline" id="M99"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi> <mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mspace width="3.33333pt"/><mml:mi>κ</mml:mi> <mml:mo>,</mml:mo> <mml:mspace width="3.33333pt"/><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>down</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and <italic>ρ</italic><sub>down</sub> (for equal noise variances in each pathway), the exact values of <inline-formula id="pcbi.1005150.e100"><alternatives><graphic id="pcbi.1005150.e100g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e100" xlink:type="simple"/><mml:math display="inline" id="M100"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005150.e101"><alternatives><graphic id="pcbi.1005150.e101g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e101" xlink:type="simple"/><mml:math display="inline" id="M101"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> do not determine which class of solutions is optimal except through <italic>ρ</italic><sub>eff</sub>. However, because the values of <inline-formula id="pcbi.1005150.e102"><alternatives><graphic id="pcbi.1005150.e102g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e102" xlink:type="simple"/><mml:math display="inline" id="M102"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005150.e103"><alternatives><graphic id="pcbi.1005150.e103g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005150.e103" xlink:type="simple"/><mml:math display="inline" id="M103"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>up</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> do affect the overall MSE, the optimal solution may not perform significantly better than “nearby” sub-optimal nonlinearities; e.g., there may be a wide range of nonlinearities that give MSE within 1–5% of the optimal nonlinearity when the upstream noise variance is large. See Figs <xref ref-type="fig" rid="pcbi.1005150.g002">2</xref> and <xref ref-type="fig" rid="pcbi.1005150.g005">5</xref> in Results.</p>
<p>Similarly, the percentage difference in MSE between ON-OFF versus ON-ON strategies can vary depending on the size of <italic>σ</italic><sub>s</sub> and <italic>σ</italic><sub>up</sub>. <xref ref-type="fig" rid="pcbi.1005150.g007">Fig 7</xref> shows differences of up to 20% for <italic>σ</italic><sub>s</sub> = 1.0 and <italic>σ</italic><sub>up</sub> = 1.0 (we use a smaller value of <italic>σ</italic><sub>up</sub> here to show that the percent differences in MSE can be significiant; the default value of <italic>σ</italic><sub>up</sub> = 2.0 yields percent differences in MSE of up to about 5%).</p>
<p>For <xref ref-type="fig" rid="pcbi.1005150.g008">Fig 8</xref> (comparison of methods for determining the optimal nonlinearity), the parameters used were: <italic>σ</italic><sub>up</sub> = 0.2, <italic>κ</italic> = 10<sup>-3</sup>, and <italic>σ</italic><sub>down</sub> = 0.2.</p>
<p>For <xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref> (single pathway optimal nonlinearities) the parameters are listed in <xref ref-type="table" rid="pcbi.1005150.t002">Table 2</xref>; parameters for <xref ref-type="fig" rid="pcbi.1005150.g003">Fig 3</xref> (comparison of optimal and suboptimal nonlinearities) are listed in <xref ref-type="table" rid="pcbi.1005150.t003">Table 3</xref>; parameters for <xref ref-type="fig" rid="pcbi.1005150.g005">Fig 5</xref> (parallel pathway optimal nonlinearities) are listed in <xref ref-type="table" rid="pcbi.1005150.t004">Table 4</xref>.</p>
<table-wrap id="pcbi.1005150.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.t002</object-id>
<label>Table 2</label>
<caption>
<title>Parameters used to generate data shown in <xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref> (single pathway optimal nonlinearities).</title>
</caption>
<alternatives>
<graphic id="pcbi.1005150.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.t002" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" colspan="2"/>
<th align="center">low noise<break/>SNR = 5</th>
<th align="center">medium noise<break/>SNR = 1</th>
<th align="center">high noise<break/>SNR = 0.1</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" rowspan="3"><bold>upstream noise dominant</bold></td>
<td align="center"><italic>σ</italic><sub>up</sub></td>
<td align="center">0.375</td>
<td align="center">0.92</td>
<td align="center">3.1</td>
</tr>
<tr>
<td align="center"><italic>κ</italic></td>
<td align="center">10<sup>-3</sup></td>
<td align="center">10<sup>-3</sup></td>
<td align="center">10<sup>-3</sup></td>
</tr>
<tr>
<td align="center"><italic>σ</italic><sub>down</sub></td>
<td align="center">0.05</td>
<td align="center">0.05</td>
<td align="center">0.05</td>
</tr>
<tr>
<td align="center" rowspan="3"><bold>Poisson noise dominant</bold></td>
<td align="center"><italic>σ</italic><sub>up</sub></td>
<td align="center">0.05</td>
<td align="center">0.05</td>
<td align="center">0.05</td>
</tr>
<tr>
<td align="center"><italic>κ</italic></td>
<td align="center">0.0395</td>
<td align="center">0.5</td>
<td align="center">6.6</td>
</tr>
<tr>
<td align="center"><italic>σ</italic><sub>down</sub></td>
<td align="center">0.05</td>
<td align="center">0.05</td>
<td align="center">0.05</td>
</tr>
<tr>
<td align="center" rowspan="3"><bold>downstream noise dominant</bold></td>
<td align="center"><italic>σ</italic><sub>up</sub></td>
<td align="center">0.05</td>
<td align="center">0.05</td>
<td align="center">0.05</td>
</tr>
<tr>
<td align="center"><italic>κ</italic></td>
<td align="center">10<sup>-3</sup></td>
<td align="center">10<sup>-3</sup></td>
<td align="center">10<sup>-3</sup></td>
</tr>
<tr>
<td align="center"><italic>σ</italic><sub>down</sub></td>
<td align="center">0.135</td>
<td align="center">0.4175</td>
<td align="center">1.54</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="pcbi.1005150.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.t003</object-id>
<label>Table 3</label>
<caption>
<title>Parameters used to generate data shown in <xref ref-type="fig" rid="pcbi.1005150.g003">Fig 3</xref> (comparison of optimal and suboptimal nonlinearities).</title>
</caption>
<alternatives>
<graphic id="pcbi.1005150.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.t003" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<tbody>
<tr>
<td align="center" rowspan="3"><bold>upstream noise dominant</bold></td>
<td align="center"><italic>σ</italic><sub>up</sub></td>
<td align="center">0.8</td>
</tr>
<tr>
<td align="center"><italic>κ</italic></td>
<td align="center">0</td>
</tr>
<tr>
<td align="center"><italic>σ</italic><sub>down</sub></td>
<td align="center">0.005</td>
</tr>
<tr>
<td align="center" rowspan="3"><bold>Poisson noise dominant</bold></td>
<td align="center"><italic>σ</italic><sub>up</sub></td>
<td align="center">0</td>
</tr>
<tr>
<td align="center"><italic>κ</italic></td>
<td align="center">0.2</td>
</tr>
<tr>
<td align="center"><italic>σ</italic><sub>down</sub></td>
<td align="center">0.005</td>
</tr>
<tr>
<td align="center" rowspan="3"><bold>downstream noise dominant</bold></td>
<td align="center"><italic>σ</italic><sub>up</sub></td>
<td align="center">0.05</td>
</tr>
<tr>
<td align="center"><italic>κ</italic></td>
<td align="center">0</td>
</tr>
<tr>
<td align="center"><italic>σ</italic><sub>down</sub></td>
<td align="center">0.3</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="pcbi.1005150.t004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005150.t004</object-id>
<label>Table 4</label>
<caption>
<title>Parameters used to generate data shown in <xref ref-type="fig" rid="pcbi.1005150.g005">Fig 5</xref> (parallel pathway optimal nonlinearities).</title>
</caption>
<alternatives>
<graphic id="pcbi.1005150.t004g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.t004" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" colspan="2"/>
<th align="center">low noise</th>
<th align="center">high noise</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" rowspan="5"><bold>upstream noise dominant</bold></td>
<td align="center"><italic>σ</italic><sub>up</sub></td>
<td align="center">0.85</td>
<td align="center">0.85</td>
</tr>
<tr>
<td align="center"><italic>ρ</italic><sub>up</sub></td>
<td align="center">0.9762</td>
<td align="center">-0.9073</td>
</tr>
<tr>
<td align="center"><italic>κ</italic></td>
<td align="center">0.1</td>
<td align="center">0.1</td>
</tr>
<tr>
<td align="center"><italic>σ</italic><sub>down</sub></td>
<td align="center">0.1</td>
<td align="center">0.1</td>
</tr>
<tr>
<td align="center"><italic>ρ</italic><sub>down</sub></td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center" rowspan="5"><bold>Poisson noise dominant</bold></td>
<td align="center"><italic>σ</italic><sub>up</sub></td>
<td align="center">0.25</td>
<td align="center">0.25</td>
</tr>
<tr>
<td align="center"><italic>ρ</italic><sub>up</sub></td>
<td align="center">-0.7</td>
<td align="center">-0.7</td>
</tr>
<tr>
<td align="center"><italic>κ</italic></td>
<td align="center">0.25</td>
<td align="center">0.9</td>
</tr>
<tr>
<td align="center"><italic>σ</italic><sub>down</sub></td>
<td align="center">0.1</td>
<td align="center">0.1</td>
</tr>
<tr>
<td align="center"><italic>ρ</italic><sub>down</sub></td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center" rowspan="5"><bold>downstream noise dominant</bold></td>
<td align="center"><italic>σ</italic><sub>up</sub></td>
<td align="center">0.25</td>
<td align="center">0.25</td>
</tr>
<tr>
<td align="center"><italic>ρ</italic><sub>up</sub></td>
<td align="center">-0.7</td>
<td align="center">-0.7</td>
</tr>
<tr>
<td align="center"><italic>κ</italic></td>
<td align="center">0.1</td>
<td align="center">0.1</td>
</tr>
<tr>
<td align="center"><italic>σ</italic><sub>down</sub></td>
<td align="center">0.25</td>
<td align="center">0.9</td>
</tr>
<tr>
<td align="center"><italic>ρ</italic><sub>down</sub></td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
</sec>
<sec id="sec032">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1005150.s001" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Optimal nonlinearities for different choice of noise at nonlinearity output stage.</title>
<p>As the amount of noise associated with the nonlinear processing stage increases, optimal nonlinearities steepen regardless of detailed statistical structure of this noise. We compared Poisson, multiplicative Gaussian, and binomial noise sources. Poisson noise was parameterized as described in the manuscript. Multiplicative Gaussian noise was drawn from a Gaussian distribution with mean zero and variance equal to the nonlinearity output multiplied by a parameter controlling noise strength. This noise was then added to the output of the nonlinearity. Noise strengths in the Poisson and multiplicative Gaussian plots are directly comparable in the sense that the corresponding lines have identical variance at each response level. Binomial noise was generated by drawing from a binomial distribution, with the number of “events” (analogous to the number of available vesicles) determining the noise level (where a greater number of events results in lower noise) and probability of success of each event given by the output of the nonlinearity, ranging from 0 to 1. We then found optimal nonlinearities through simulations that maximize the mutual information (as described in <xref ref-type="sec" rid="sec020">Methods</xref>). For each of these types of noise, the optimal nonlinearity steepens as noise is increased (dark blue to light blue lines).</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005150.s002" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Optimal nonlinearities for a single pathway when one noise source dominates, found by maximizing mutual information (MI).</title>
<p>Same as <xref ref-type="fig" rid="pcbi.1005150.g002">Fig 2</xref>, except that mutual information is maximized. Optimal nonlinearities found by maximizing MI are generally steeper than those found by minimizing the MSE of a linear estimator, but qualitative trends are the same. Nonlinearities are only shown for the two larger SNR values, as it was difficult to obtain reliable estimates of the mutual information for SNR = 0.1.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005150.s003" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005150.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Optimal nonlinearities for a circuit with two parallel pathways, found by maximizing mutual information (MI).</title>
<p>As in <xref ref-type="fig" rid="pcbi.1005150.g005">Fig 5</xref>, solid lines represent the optimal logistic nonlinearities (for opposite polarities in panel <bold>A</bold> and the same polarities in panel <bold>B</bold>), and shaded regions indicate the region that contains solutions within 1% of the maximum MI. For reference, dashed lines show analytic results obtained by minimizing the MSE of a linear estimator (identical to those in <xref ref-type="fig" rid="pcbi.1005150.g005">Fig 5</xref>). Optimal nonlinearities found by maximizing MI are steeper (as in <xref ref-type="supplementary-material" rid="pcbi.1005150.s002">S2 Fig</xref>), and additionally tend more towards independence in the two channels. However, qualitative trends are the same regardless of the specific criterion for optimization.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Greg Schwartz, Greg Field, Ben Strowbridge, and Julijana Gjorgjieva for helpful feedback on the manuscript. This work was facilitated though the use of advanced computational, storage, and networking infrastructure provided by the Hyak supercomputer system at the University of Washington.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005150.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Faisal</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Selen</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>D</given-names></name>. <article-title>Noise in the nervous system</article-title>. <source>Nat Rev Neurosci</source>. <year>2008</year>;<volume>9</volume>(<issue>4</issue>):<fpage>292</fpage>–<lpage>303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2258" xlink:type="simple">10.1038/nrn2258</ext-link></comment> <object-id pub-id-type="pmid">18319728</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Averbeck</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Neural correlations, population coding and computation</article-title>. <source>Nature reviews Neuroscience</source>. <year>2006</year>;<volume>7</volume>(<issue>5</issue>):<fpage>358</fpage>–<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn1888" xlink:type="simple">10.1038/nrn1888</ext-link></comment> <object-id pub-id-type="pmid">16760916</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>The effect of correlated variability on the accuracy of a population code</article-title>. <source>Neural computation</source>. <year>1999</year>;<volume>11</volume>(<issue>1</issue>):<fpage>91</fpage>–<lpage>101</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976699300016827" xlink:type="simple">10.1162/089976699300016827</ext-link></comment> <object-id pub-id-type="pmid">9950724</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ecker</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Berens</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Tolias</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Bethge</surname> <given-names>M</given-names></name>. <article-title>The Effect of Noise Correlations in Populations of Diversely Tuned Neurons</article-title>. <source>Journal of Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>40</issue>):<fpage>14272</fpage>–<lpage>14283</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2539-11.2011" xlink:type="simple">10.1523/JNEUROSCI.2539-11.2011</ext-link></comment> <object-id pub-id-type="pmid">21976512</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Moreno-Bote</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kanitscheider</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Pitkow</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Information-limiting correlations</article-title>. <source>Nature Neuroscience</source>. <year>2014</year>;<volume>17</volume>(<issue>10</issue>):<fpage>1410</fpage>–<lpage>1417</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3807" xlink:type="simple">10.1038/nn.3807</ext-link></comment> <object-id pub-id-type="pmid">25195105</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref006">
<label>6</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Barlow</surname> <given-names>H</given-names></name>. <chapter-title>Possible Principles Underlying the Transformations of Sensory Messages</chapter-title>. In: <name name-style="western"><surname>Rosenblith</surname> <given-names>WA</given-names></name>, editor. <source>Sensory Communication</source>. <publisher-name>MIT Press</publisher-name>; <year>1961</year>. p. <fpage>217</fpage>–<lpage>234</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.trin.cam.ac.uk/horacebarlow/21.pdf" xlink:type="simple">http://www.trin.cam.ac.uk/horacebarlow/21.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005150.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Laughlin</surname> <given-names>S</given-names></name>. <article-title>A Simple Coding Procedure Enhances a Neuron’s Information Capacity</article-title>. <source>Z Naturforsch</source>. <year>1981</year>;<volume>36c</volume>:<fpage>910</fpage>–<lpage>912</lpage>. <object-id pub-id-type="pmid">7303823</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Atick</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Redlich</surname> <given-names>A</given-names></name>. <article-title>Towards a Theory of Early Visual Processing</article-title>. <source>Neural Comput</source>. <year>1990</year>;<volume>2</volume>(<issue>3</issue>):<fpage>308</fpage>–<lpage>320</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.1990.2.3.308" xlink:type="simple">10.1162/neco.1990.2.3.308</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Owen</surname> <given-names>WG</given-names></name>. <article-title>Temporal filtering in retinal bipolar cells. Elements of an optimal computation?</article-title> <source>Biophysical Journal</source>. <year>1990</year>;<volume>58</volume>(<issue>5</issue>):<fpage>1227</fpage>–<lpage>1233</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0006-3495(90)82463-2" xlink:type="simple">10.1016/S0006-3495(90)82463-2</ext-link></comment> <object-id pub-id-type="pmid">2291942</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref010">
<label>10</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Owen</surname> <given-names>WG</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <chapter-title>Optimal Filtering in the Salamander Retina</chapter-title>. In: <name name-style="western"><surname>Lippmann</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Moody</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Touretzky</surname> <given-names>DS</given-names></name>, editors. <source>Advances in Neural Information Processing Systems 3</source>. <publisher-name>Morgan-Kaufmann</publisher-name>; <year>1991</year>. p. <fpage>377</fpage>–<lpage>383</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/433-optimal-filtering-in-the-salamander-retina.pdf" xlink:type="simple">http://papers.nips.cc/paper/433-optimal-filtering-in-the-salamander-retina.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005150.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Atick</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Redlich</surname> <given-names>A</given-names></name>. <article-title>What Does the Retina Know about Natural Scenes?</article-title> <source>Neural Comput</source>. <year>1992</year>;<volume>210</volume>:<fpage>196</fpage>–<lpage>210</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.1992.4.2.196" xlink:type="simple">10.1162/neco.1992.4.2.196</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van Hateren</surname> <given-names>JH</given-names></name>. <article-title>Theoretical predictions of spatiotemporal receptive fields of fly LMCs, and experimental validation</article-title>. <source>Journal of Comparative Physiology A</source>. <year>1992</year>;<volume>171</volume>(<issue>2</issue>):<fpage>157</fpage>–<lpage>170</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00188924" xlink:type="simple">10.1007/BF00188924</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref013">
<label>13</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Warland</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>de Ruyter van Steveninck</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <source>Spikes: Exploring the Neural Code</source>. <publisher-loc>Cambridge, MA, USA</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>1999</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005150.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Srinivasan</surname> <given-names>MV</given-names></name>, <name name-style="western"><surname>Laughlin</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Dubs</surname> <given-names>A</given-names></name>. <article-title>Predictive Coding: A Fresh View of Inhibition in the Retina</article-title>. <source>Proceedings of the Royal Society of London B: Biological Sciences</source>. <year>1982</year>;<volume>216</volume>(<issue>1205</issue>):<fpage>427</fpage>–<lpage>459</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rspb.1982.0085" xlink:type="simple">10.1098/rspb.1982.0085</ext-link></comment> <object-id pub-id-type="pmid">6129637</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hateren</surname> <given-names>J</given-names></name>. <article-title>A THEORY OF MAXIMIZING SENSORY INFORMATION</article-title>. <source>Biological Cybernetics</source>. <year>1992</year>;<volume>68</volume>(<issue>1</issue>):<fpage>23</fpage>–<lpage>29</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00203134" xlink:type="simple">10.1007/BF00203134</ext-link></comment> <object-id pub-id-type="pmid">1486129</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Atick</surname> <given-names>J</given-names></name>. <article-title>Could information theory provide an ecological theory of sensory processing?</article-title> <source>Network: Computation in neural systems</source>. <year>1992</year>;. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3109/0954898X.2011.638888" xlink:type="simple">10.3109/0954898X.2011.638888</ext-link></comment> <object-id pub-id-type="pmid">22149669</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nadal</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Parga</surname> <given-names>N</given-names></name>. <article-title>Nonlinear neurons in the low-noise limit: a factorial code maximizes information transfer</article-title>. <source>Network: Computation in neural systems</source>. <year>1994</year>; p. <fpage>1</fpage>–<lpage>19</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/0954-898X_5_4_008" xlink:type="simple">10.1088/0954-898X_5_4_008</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brenner</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Steveninck</surname> <given-names>RV</given-names></name>. <article-title>Adaptive Rescaling Maximizes Information Transmission</article-title>. <source>Neuron</source>. <year>2000</year>;<volume>26</volume>:<fpage>695</fpage>–<lpage>702</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0896-6273(00)81205-2" xlink:type="simple">10.1016/S0896-6273(00)81205-2</ext-link></comment> <object-id pub-id-type="pmid">10896164</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fairhall</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Lewen</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>de Ruyter Van Steveninck</surname> <given-names>R</given-names></name>. <article-title>Efficiency and ambiguity in an adaptive neural code</article-title>. <source>Nature</source>. <year>2001</year>;<volume>412</volume>(<issue>6849</issue>):<fpage>787</fpage>–<lpage>92</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/35090500" xlink:type="simple">10.1038/35090500</ext-link></comment> <object-id pub-id-type="pmid">11518957</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref020">
<label>20</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Karklin</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>E</given-names></name>. <source>Efficient coding of natural images with a population of noisy linear-nonlinear neurons</source>. In: <publisher-name>NIPS</publisher-name>. <publisher-loc>Granada, Spain</publisher-loc>; <year>2011</year>. p. <fpage>1</fpage>–<lpage>9</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2011_0616.pdf" xlink:type="simple">http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2011_0616.pdf</ext-link>. <object-id pub-id-type="pmid">26273180</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kastner</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Baccus</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sharpee</surname> <given-names>T</given-names></name>. <article-title>Critical and maximally informative encoding between neural populations in the retina</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2015</year>;<volume>112</volume>(<issue>8</issue>):<fpage>2533</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1418092112" xlink:type="simple">10.1073/pnas.1418092112</ext-link></comment> <object-id pub-id-type="pmid">25675497</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bryant</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Segundo</surname> <given-names>J</given-names></name>. <article-title>Spike initiation by transmembrane current: a white-noise analysis</article-title>. <source>J Physiol</source>. <year>1976</year>;<volume>260</volume>:<fpage>279</fpage>–<lpage>314</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.1976.sp011516" xlink:type="simple">10.1113/jphysiol.1976.sp011516</ext-link></comment> <object-id pub-id-type="pmid">978519</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mainen</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>T</given-names></name>. <article-title>Reliability of spike timing in neocortical neurons</article-title>. <source>Science</source>. <year>1995</year>;<volume>268</volume>(<issue>5216</issue>):<fpage>1503</fpage>–<lpage>1506</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.7770778" xlink:type="simple">10.1126/science.7770778</ext-link></comment> <object-id pub-id-type="pmid">7770778</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Murphy</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>. <article-title>Network variability limits stimulus-evoked spike timing precision in retinal ganglion cells</article-title>. <source>Neuron</source>. <year>2006</year>;<volume>52</volume>(<issue>3</issue>):<fpage>511</fpage>–<lpage>24</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2006.09.014" xlink:type="simple">10.1016/j.neuron.2006.09.014</ext-link></comment> <object-id pub-id-type="pmid">17088216</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dunn</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>. <article-title>The impact of photoreceptor noise on retinal gain controls</article-title>. <source>Current opinion in neurobiology</source>. <year>2006</year>;<volume>16</volume>(<issue>4</issue>):<fpage>363</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2006.06.013" xlink:type="simple">10.1016/j.conb.2006.06.013</ext-link></comment> <object-id pub-id-type="pmid">16837189</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Freed</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Liang</surname> <given-names>Z</given-names></name>. <article-title>Synaptic noise is an information bottleneck in the inner retina during dynamic visual stimulation</article-title>. <source>The Journal of Physiology</source>. <year>2014</year>;<volume>592</volume>(<issue>Pt 4</issue>):<fpage>635</fpage>–<lpage>51</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.2013.265744" xlink:type="simple">10.1113/jphysiol.2013.265744</ext-link></comment> <object-id pub-id-type="pmid">24297850</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fuchs</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Glowatzki</surname> <given-names>E</given-names></name>. <article-title>Synaptic studies inform the functional diversity of cochlear afferents</article-title>. <source>Hearing research</source>. <year>2015</year>; p. <fpage>1</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.heares.2015.09.007" xlink:type="simple">10.1016/j.heares.2015.09.007</ext-link></comment> <object-id pub-id-type="pmid">26403507</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chichilnisky</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Kalmar</surname> <given-names>RS</given-names></name>. <article-title>Functional asymmetries in ON and OFF ganglion cells of primate retina</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2002</year>;<volume>22</volume>(<issue>7</issue>):<fpage>2737</fpage>–<lpage>47</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/20026215" xlink:type="simple">20026215</ext-link></comment> <object-id pub-id-type="pmid">11923439</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zaghloul</surname> <given-names>Ka</given-names></name>, <name name-style="western"><surname>Boahen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Demb</surname> <given-names>JB</given-names></name>. <article-title>Different circuits for ON and OFF retinal ganglion cells cause different contrast sensitivities</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2003</year>;<volume>23</volume>(<issue>7</issue>):<fpage>2645</fpage>–<lpage>54</lpage>. <object-id pub-id-type="pmid">12684450</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Burkhardt</surname> <given-names>Da</given-names></name>. <article-title>Contrast processing by ON and OFF bipolar cells</article-title>. <source>Visual neuroscience</source>. <year>2011</year>;<volume>28</volume>(<issue>1</issue>):<fpage>69</fpage>–<lpage>75</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S0952523810000313" xlink:type="simple">10.1017/S0952523810000313</ext-link></comment> <object-id pub-id-type="pmid">21092350</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Scholl</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gao</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Wehr</surname> <given-names>M</given-names></name>. <article-title>Nonoverlapping Sets of Synapses Drive On Responses and Off Responses in Auditory Cortex</article-title>. <source>Neuron</source>. <year>2010</year>;<volume>65</volume>(<issue>3</issue>):<fpage>412</fpage>–<lpage>421</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2010.01.020" xlink:type="simple">10.1016/j.neuron.2010.01.020</ext-link></comment> <object-id pub-id-type="pmid">20159453</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chalasani</surname> <given-names>SH</given-names></name>, <name name-style="western"><surname>Chronis</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Tsunozaki</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gray</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Ramot</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Goodman</surname> <given-names>MB</given-names></name>, <etal>et al</etal>. <article-title>Dissecting a circuit for olfactory behaviour in Caenorhabditis elegans</article-title>. <source>Nature</source>. <year>2007</year>;<volume>450</volume>(<issue>7166</issue>):<fpage>63</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature06292" xlink:type="simple">10.1038/nature06292</ext-link></comment> <object-id pub-id-type="pmid">17972877</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gallio</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ofstad</surname> <given-names>TA</given-names></name>, <name name-style="western"><surname>Macpherson</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Zuker</surname> <given-names>CS</given-names></name>. <article-title>The Coding of Temperature in the <italic>Drosophila</italic> Brain</article-title>. <source>Cell</source>. <year>2011</year>;<volume>144</volume>(<issue>4</issue>):<fpage>614</fpage>–<lpage>624</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cell.2011.01.028" xlink:type="simple">10.1016/j.cell.2011.01.028</ext-link></comment> <object-id pub-id-type="pmid">21335241</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref034">
<label>34</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Hsiao</surname> <given-names>SS</given-names></name>. <chapter-title>Similarities between touch and vision</chapter-title>. In: <name name-style="western"><surname>Morley</surname> <given-names>JW</given-names></name>, editor. <source>Neural Aspects in Tactile Sensation. vol. 127 of Advances in Psychology</source>. <publisher-name>North-Holland</publisher-name>; <year>1998</year>. p. <fpage>131</fpage>–<lpage>165</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.sciencedirect.com/science/article/pii/S0166411598800666" xlink:type="simple">http://www.sciencedirect.com/science/article/pii/S0166411598800666</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0166-4115(98)80066-6" xlink:type="simple">10.1016/S0166-4115(98)80066-6</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pitkow</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Meister</surname> <given-names>M</given-names></name>. <article-title>Decorrelation and efficient coding by retinal ganglion cells</article-title>. <source>Nat Neurosci</source>. <year>2012</year>;<volume>15</volume>(<issue>4</issue>):<fpage>628</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3064" xlink:type="simple">10.1038/nn.3064</ext-link></comment> <object-id pub-id-type="pmid">22406548</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Barrett</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Crill</surname> <given-names>W</given-names></name>. <article-title>Influence of dendritic location and membrane properties on the effectiveness of synapses on cat motoneurones</article-title>. <source>The Journal of physiology</source>. <year>1974</year>; p. <fpage>325</fpage>–<lpage>345</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.1974.sp010571" xlink:type="simple">10.1113/jphysiol.1974.sp010571</ext-link></comment> <object-id pub-id-type="pmid">4413861</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Augustine</surname> <given-names>G</given-names></name>. <article-title>Calcium entry and transmitter release at voltage-clamped nerve terminals of squid</article-title>. <source>The Journal of physiology</source>. <year>1985</year>; p. <fpage>163</fpage>–<lpage>181</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.1985.sp015819" xlink:type="simple">10.1113/jphysiol.1985.sp015819</ext-link></comment> <object-id pub-id-type="pmid">2865362</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref038">
<label>38</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>. <source>Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems</source>. <publisher-name>The MIT Press</publisher-name>; <year>2005</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005150.ref039">
<label>39</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Simoncelli</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Pillow</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>O</given-names></name>. <chapter-title>Characterization of Neural Responses with Stochastic Stimuli</chapter-title>. In: <name name-style="western"><surname>Gazzaniga</surname> <given-names>M</given-names></name>, editor. <source>The Cognitive Neurosciences</source>. <edition>3rd ed</edition>. <publisher-name>MIT Press</publisher-name>; <year>2004</year>. p. <fpage>327</fpage>–<lpage>338</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005150.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pillow</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shlens</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sher</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Litke</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Chichilnisky</surname> <given-names>E</given-names></name>, <etal>et al</etal>. <article-title>Spatio-temporal correlations and visual signalling in a complete neuronal population</article-title>. <source>Nature</source>. <year>2008</year>;<volume>454</volume>(<issue>7207</issue>):<fpage>995</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07140" xlink:type="simple">10.1038/nature07140</ext-link></comment> <object-id pub-id-type="pmid">18650810</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schwartz</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>. <article-title>Perspectives on: Information and coding in mammalian sensory physiology: Nonlinear spatial encoding by retinal ganglion cells: when 1 + 1 != 2</article-title>. <source>The Journal of General Physiology</source>. <year>2011</year>;<volume>138</volume>(<issue>3</issue>):<fpage>283</fpage>–<lpage>290</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1085/jgp.201110629" xlink:type="simple">10.1085/jgp.201110629</ext-link></comment> <object-id pub-id-type="pmid">21875977</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Grimes</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>. <article-title>The synaptic and circuit mechanisms underlying a change in spatial encoding in the retina</article-title>. <source>Neuron</source>. <year>2014</year>;<volume>82</volume>(<issue>2</issue>):<fpage>460</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.02.037" xlink:type="simple">10.1016/j.neuron.2014.02.037</ext-link></comment> <object-id pub-id-type="pmid">24742466</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ruderman</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>Statistics of Natural Images: Scaling in the Woods</article-title>. <source>PRL</source>. <year>1994</year>;<volume>73</volume>(<issue>6</issue>):<fpage>814</fpage>–<lpage>817</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.73.814" xlink:type="simple">10.1103/PhysRevLett.73.814</ext-link></comment> <object-id pub-id-type="pmid">10057546</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Freed</surname> <given-names>MA</given-names></name>. <article-title>Rate of Quantal Excitation to a Retinal Ganglion Cell Evoked by Sensory Input</article-title>. <source>Journal of Neurophysiology</source>. <year>2000</year>;<volume>83</volume>(<issue>5</issue>):<fpage>2956</fpage>–<lpage>2966</lpage>. <object-id pub-id-type="pmid">10805691</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Choi</surname> <given-names>SY</given-names></name>, <name name-style="western"><surname>Borghuis</surname> <given-names>BG</given-names></name>, <name name-style="western"><surname>Borghuis</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Rea</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Levitan</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Sterling</surname> <given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Encoding light intensity by the cone photoreceptor synapse</article-title>. <source>Neuron</source>. <year>2005</year>;<volume>48</volume>(<issue>4</issue>):<fpage>555</fpage>–<lpage>62</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2005.09.011" xlink:type="simple">10.1016/j.neuron.2005.09.011</ext-link></comment> <object-id pub-id-type="pmid">16301173</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Barlow</surname> <given-names>H</given-names></name>. <article-title>Single units and cognition: a neurone doctrine for perceptual psychology</article-title>. <source>Perception</source>. <year>1972</year>;<volume>1</volume>(<issue>October</issue>):<fpage>371</fpage>–<lpage>394</lpage>. <object-id pub-id-type="pmid">4377168</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ochoa</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Torebjörk</surname> <given-names>E</given-names></name>. <article-title>Sensations evoked by intraneural microstimulation of single mechanoreceptor units innervating the human hand</article-title>. <source>The Journal of physiology</source>. <year>1983</year>;<volume>342</volume>:<fpage>633</fpage>–<lpage>54</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.1983.sp014873" xlink:type="simple">10.1113/jphysiol.1983.sp014873</ext-link></comment> <object-id pub-id-type="pmid">6631752</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Field</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Sampath</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>. <article-title>RETINAL PROCESSING NEAR ABSOLUTE THRESHOLD: From Behavior to Mechanism</article-title>. <source>Annual Review of Physiology</source>. <year>2005</year>;<volume>67</volume>(<issue>1</issue>):<fpage>491</fpage>–<lpage>514</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.physiol.67.031103.151256" xlink:type="simple">10.1146/annurev.physiol.67.031103.151256</ext-link></comment> <object-id pub-id-type="pmid">15709967</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sincich</surname> <given-names>LC</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Tiruveedhula</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Horton</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Roorda</surname> <given-names>A</given-names></name>. <article-title>Resolving single cone inputs to visual receptive fields</article-title>. <source>Nature neuroscience</source>. <year>2009</year>;<volume>12</volume>(<issue>8</issue>):<fpage>967</fpage>–<lpage>969</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2352" xlink:type="simple">10.1038/nn.2352</ext-link></comment> <object-id pub-id-type="pmid">19561602</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Crespi</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Lazzizzera</surname> <given-names>I</given-names></name>. <article-title>Storage capacity and dynamics of nonmonotonic networks</article-title>. <source>ESANN’1999 proceedings—European Symposium on Artificial Neural Networks</source>. <year>1999</year>; p. <fpage>393</fpage>–<lpage>398</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005150.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Peirce</surname> <given-names>JW</given-names></name>. <article-title>The potential importance of saturating and supersaturating contrast response functions in visual cortex</article-title>. <source>Journal of Vision</source>. <year>2007</year>;<volume>7</volume>(<issue>6</issue>):<fpage>13</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/7.6.13" xlink:type="simple">10.1167/7.6.13</ext-link></comment> <object-id pub-id-type="pmid">17685796</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sadagopan</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>X</given-names></name>. <article-title>Level Invariant Representation of Sounds by Populations of Neurons in Primary Auditory Cortex</article-title>. <source>The Journal of Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>13</issue>):<fpage>3415</fpage>–<lpage>3426</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2743-07.2008" xlink:type="simple">10.1523/JNEUROSCI.2743-07.2008</ext-link></comment> <object-id pub-id-type="pmid">18367608</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Watkins</surname> <given-names>PV</given-names></name>, <name name-style="western"><surname>Barbour</surname> <given-names>DL</given-names></name>. <article-title>Specialized neuronal adaptation for preserving input sensitivity</article-title>. <source>Nat Neurosci</source>. <year>2008</year>;<volume>11</volume>(<issue>11</issue>):<fpage>1259</fpage>–<lpage>1261</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2201" xlink:type="simple">10.1038/nn.2201</ext-link></comment> <object-id pub-id-type="pmid">18820690</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>May</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Zhaoping</surname> <given-names>L</given-names></name>. <article-title>The potential roles of saturating and supersaturating contrast-response functions in conjunction detection: Reply to Peirce</article-title>. <source>Journal of Vision</source>. <year>2013</year>;<volume>13</volume>(<issue>4</issue>):<fpage>22</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/13.4.22" xlink:type="simple">10.1167/13.4.22</ext-link></comment> <object-id pub-id-type="pmid">23538142</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Peirce</surname> <given-names>JW</given-names></name>. <article-title>Nonlinear response functions can still be used to build conjunction detectors: Reply to May and Zhaoping</article-title>. <source>Journal of Vision</source>. <year>2013</year>;<volume>13</volume>(<issue>4</issue>):<fpage>23</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/13.4.23" xlink:type="simple">10.1167/13.4.23</ext-link></comment> <object-id pub-id-type="pmid">23538143</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gjorgjieva</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Meister</surname> <given-names>M</given-names></name>. <article-title>Benefits of pathway splitting in sensory coding</article-title>. <source>J Neurosci</source>. <year>2014</year>;<volume>34</volume>(<issue>36</issue>):<fpage>12127</fpage>–<lpage>44</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1032-14.2014" xlink:type="simple">10.1523/JNEUROSCI.1032-14.2014</ext-link></comment> <object-id pub-id-type="pmid">25186757</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref057">
<label>57</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Wang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Stocker</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>D</given-names></name>. <chapter-title>Optimal Neural Tuning Curves for Arbitrary Stimulus Distributions: Discrimax, Infomax and Minimum L_p Loss</chapter-title>. In: <name name-style="western"><surname>Pereira</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Burges</surname> <given-names>CJC</given-names></name>, <name name-style="western"><surname>Bottou</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Weinberger</surname> <given-names>KQ</given-names></name>, editors. <source>Advances in Neural Information Processing Systems 25</source>. <publisher-name>Curran Associates, Inc</publisher-name>.; <year>2012</year>. p. <fpage>2168</fpage>–<lpage>2176</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/4783-optimal-neural-tuning-curves-for-arbitrary-stimulus-distributions-discrimax-infomax-and-minimum-l_p-loss.pdf" xlink:type="simple">http://papers.nips.cc/paper/4783-optimal-neural-tuning-curves-for-arbitrary-stimulus-distributions-discrimax-infomax-and-minimum-l_p-loss.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005150.ref058">
<label>58</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Wang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Stocker</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>D</given-names></name>. <chapter-title>Optimal Neural Population Codes for High-dimensional Stimulus Variables</chapter-title>. In: <name name-style="western"><surname>Burges</surname> <given-names>CJC</given-names></name>, <name name-style="western"><surname>Bottou</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Welling</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ghahramani</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Weinberger</surname> <given-names>KQ</given-names></name>, editors. <source>Advances in Neural Information Processing Systems 26</source>. <publisher-name>Curran Associates, Inc</publisher-name>.; <year>2013</year>. p. <fpage>297</fpage>–<lpage>305</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/4994-optimal-neural-population-codes-for-high-dimensional-stimulus-variables.pdf" xlink:type="simple">http://papers.nips.cc/paper/4994-optimal-neural-population-codes-for-high-dimensional-stimulus-variables.pdf</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005150.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Butts</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Goldman</surname> <given-names>M</given-names></name>. <article-title>Tuning curves, neuronal variability, and sensory coding</article-title>. <source>PLoS biology</source>. <year>2006</year>;<volume>4</volume>(<issue>4</issue>):<fpage>639</fpage>–<lpage>646</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0040092" xlink:type="simple">10.1371/journal.pbio.0040092</ext-link></comment> <object-id pub-id-type="pmid">16529529</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Bodnar</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>Naturalistic stimuli increase the rate and efficiency of information transmission by primary auditory afferents</article-title>. <source>Proc R Soc B</source>. <year>1995</year>;<volume>262</volume>(<issue>1365</issue>):<fpage>259</fpage>–<lpage>265</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rspb.1995.0204" xlink:type="simple">10.1098/rspb.1995.0204</ext-link></comment> <object-id pub-id-type="pmid">8587884</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schneeweis</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Schnapf</surname> <given-names>J</given-names></name>. <article-title>Noise and light adaptation in rods of the macaque monkey</article-title>. <source>Visual neuroscience</source>. <year>2000</year>;<volume>17</volume>(<issue>5</issue>):<fpage>659</fpage>–<lpage>666</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S0952523800175017" xlink:type="simple">10.1017/S0952523800175017</ext-link></comment> <object-id pub-id-type="pmid">11153647</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Miller</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Katz</surname> <given-names>DB</given-names></name>. <article-title>Accuracy and response-time distributions for decision-making: Linear perfect integrators versus nonlinear attractor-based neural circuits</article-title>. <source>Journal of Computational Neuroscience</source>. <year>2013</year>;<volume>35</volume>(<issue>3</issue>):<fpage>261</fpage>–<lpage>294</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-013-0452-x" xlink:type="simple">10.1007/s10827-013-0452-x</ext-link></comment> <object-id pub-id-type="pmid">23608921</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ala-Laurila</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Greschner</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Chichilnisky</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>. <article-title>Cone photoreceptor contributions to noise and correlations in the retinal output</article-title>. <source>Nature Neuroscience</source>. <year>2011</year>;<volume>14</volume>(<issue>10</issue>):<fpage>1309</fpage>–<lpage>1316</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2927" xlink:type="simple">10.1038/nn.2927</ext-link></comment> <object-id pub-id-type="pmid">21926983</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Angueyra</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>. <article-title>Origin and effect of phototransduction noise in primate cone photoreceptors</article-title>. <source>Nat Neurosci</source>. <year>2013</year>;<volume>16</volume>(<issue>11</issue>):<fpage>1692</fpage>–<lpage>700</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3534" xlink:type="simple">10.1038/nn.3534</ext-link></comment> <object-id pub-id-type="pmid">24097042</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rao</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Buchsbaum</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Sterling</surname> <given-names>P</given-names></name>. <article-title>Rate of quantal transmitter release at the mammalian rod synapse</article-title>. <source>Biophysical journal</source>. <year>1994</year>;<volume>67</volume>(<issue>1</issue>):<fpage>57</fpage>–<lpage>63</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0006-3495(94)80454-0" xlink:type="simple">10.1016/S0006-3495(94)80454-0</ext-link></comment> <object-id pub-id-type="pmid">7919023</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schein</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ahmad</surname> <given-names>KM</given-names></name>. <article-title>Efficiency of synaptic transmission of single-photon events from rod photoreceptor to rod bipolar dendrite</article-title>. <source>Biophysical journal</source>. <year>2006</year>;<volume>91</volume>(<issue>9</issue>):<fpage>3257</fpage>–<lpage>67</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1529/biophysj.106.091744" xlink:type="simple">10.1529/biophysj.106.091744</ext-link></comment> <object-id pub-id-type="pmid">16920838</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Borghuis</surname> <given-names>BG</given-names></name>, <name name-style="western"><surname>Sterling</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>RG</given-names></name>. <article-title>Loss of sensitivity in an analog neural circuit</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2009</year>;<volume>29</volume>(<issue>10</issue>):<fpage>3045</fpage>–<lpage>58</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5071-08.2009" xlink:type="simple">10.1523/JNEUROSCI.5071-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19279241</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref068">
<label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Donner</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Firsov</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Govardovskii</surname> <given-names>V</given-names></name>. <article-title>The frequency of isomerization-like’dark’ events in rhodopsin and porphyropsin rods of the bull-frog retina</article-title>. <source>J Physiol</source>. <year>1990</year>; p. <fpage>673</fpage>–<lpage>692</lpage>. <object-id pub-id-type="pmid">2231428</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref069">
<label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dunn</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Doan</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sampath</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>. <article-title>Controlling the gain of rod-mediated signals in the Mammalian retina</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>. <year>2006</year>;<volume>26</volume>(<issue>15</issue>):<fpage>3959</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5148-05.2006" xlink:type="simple">10.1523/JNEUROSCI.5148-05.2006</ext-link></comment> <object-id pub-id-type="pmid">16611812</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ala-Laurila</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>. <article-title>Coincidence detection of single-photon responses in the inner retina at the sensitivity limit of vision</article-title>. <source>Curr Biol</source>. <year>2014</year>;<volume>24</volume>(<issue>24</issue>):<fpage>2888</fpage>–<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2014.10.028" xlink:type="simple">10.1016/j.cub.2014.10.028</ext-link></comment> <object-id pub-id-type="pmid">25454583</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref071">
<label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Greschner</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Shlens</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bakolitsa</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Gauthier</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Jepson</surname> <given-names>LH</given-names></name>, <etal>et al</etal>. <article-title>Correlated firing among major ganglion cell types in primate retina</article-title>. <source>The Journal of Physiology</source>. <year>2011</year>;<volume>589</volume>(<issue>1</issue>):<fpage>75</fpage>–<lpage>86</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.2010.193888" xlink:type="simple">10.1113/jphysiol.2010.193888</ext-link></comment> <object-id pub-id-type="pmid">20921200</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref072">
<label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zylberberg</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Cafaro</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Shea-Brown</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>. <article-title>Direction-Selective Circuits Shape Noise to Ensure a Precise Population Code</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>89</volume>(<issue>2</issue>):<fpage>369</fpage>–<lpage>383</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2015.11.019" xlink:type="simple">10.1016/j.neuron.2015.11.019</ext-link></comment> <object-id pub-id-type="pmid">26796691</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Franke</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Fiscella</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sevelev</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Roska</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Hierlemann</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Azeredo da Silveira</surname> <given-names>R</given-names></name>. <article-title>Structures of Neural Correlation and How They Favor Coding</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>89</volume>(<issue>2</issue>):<fpage>409</fpage>–<lpage>422</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2015.12.037" xlink:type="simple">10.1016/j.neuron.2015.12.037</ext-link></comment> <object-id pub-id-type="pmid">26796692</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref074">
<label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Barreiro</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Gjorgjieva</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rieke</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Shea-Brown</surname> <given-names>E</given-names></name>. <article-title>When do microcircuits produce beyond-pairwise correlations?</article-title> <source>Frontiers in computational neuroscience</source>. <year>2014</year>;<volume>8</volume>(<issue>February</issue>):<fpage>10</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2014.00010" xlink:type="simple">10.3389/fncom.2014.00010</ext-link></comment> <object-id pub-id-type="pmid">24567715</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005150.ref075">
<label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Victor</surname> <given-names>J</given-names></name>. <article-title>Binless strategies for estimation of information from neural data</article-title>. <source>Physical Review E</source>. <year>2002</year>;<volume>66</volume>(<issue>5</issue>):<fpage>051903</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.66.051903" xlink:type="simple">10.1103/PhysRevE.66.051903</ext-link></comment> <object-id pub-id-type="pmid">12513519</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
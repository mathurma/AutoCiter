<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">09-PLCB-RA-0948R2</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000697</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology/Computational Neuroscience</subject><subject>Neuroscience/Sensory Systems</subject><subject>Neuroscience/Psychology</subject><subject>Neuroscience/Experimental Psychology</subject><subject>Neuroscience/Natural and Synthetic Vision</subject></subj-group></article-categories><title-group><article-title>Within- and Cross-Modal Distance Information Disambiguate Visual Size-Change Perception</article-title><alt-title alt-title-type="running-head">Distance Disambiguates Size-Change Perception</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Battaglia</surname><given-names>Peter W.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Di Luca</surname><given-names>Massimiliano</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Ernst</surname><given-names>Marc O.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Schrater</surname><given-names>Paul R.</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Machulla</surname><given-names>Tonja</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Kersten</surname><given-names>Daniel</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>Brain and Cognitive Sciences and Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Max Planck Institute for Biological Cybernetics, Tübingen, Germany</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Department of Psychology, University of Minnesota, Minneapolis, Minnesota, United States of America</addr-line>       </aff><aff id="aff4"><label>4</label><addr-line>Department of Computer Science, University of Minnesota, Minneapolis, Minnesota, United States of America</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Maloney</surname><given-names>Laurence T.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">New York University, United States of America</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">pbatt@mit.edu</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: PWB MDL MOE PRS TM DK. Performed the experiments: PWB MDL TM. Analyzed the data: PWB MDL. Contributed reagents/materials/analysis tools: MOE. Wrote the paper: PWB MDL MOE PRS.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>3</month><year>2010</year></pub-date><pub-date pub-type="epub"><day>5</day><month>3</month><year>2010</year></pub-date><volume>6</volume><issue>3</issue><elocation-id>e1000697</elocation-id><history>
<date date-type="received"><day>10</day><month>8</month><year>2009</year></date>
<date date-type="accepted"><day>30</day><month>1</month><year>2010</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2010</copyright-year><copyright-holder>Battaglia et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>Perception is fundamentally underconstrained because different combinations of object properties can generate the same sensory information. To disambiguate sensory information into estimates of scene properties, our brains incorporate prior knowledge and additional “auxiliary” (i.e., not directly relevant to desired scene property) sensory information to constrain perceptual interpretations. For example, knowing the distance to an object helps in perceiving its size. The literature contains few demonstrations of the use of prior knowledge and auxiliary information in combined visual and haptic disambiguation and almost no examination of haptic disambiguation of vision beyond “bistable” stimuli. Previous studies have reported humans integrate multiple unambiguous sensations to perceive single, continuous object properties, like size or position. Here we test whether humans use visual and haptic information, individually and jointly, to disambiguate size from distance. We presented participants with a ball moving in depth with a changing diameter. Because no unambiguous distance information is available under monocular viewing, participants rely on prior assumptions about the ball's distance to disambiguate their -size percept. Presenting auxiliary binocular and/or haptic distance information augments participants' prior distance assumptions and improves their size judgment accuracy—though binocular cues were trusted more than haptic. Our results suggest both visual and haptic distance information disambiguate size perception, and we interpret these results in the context of probabilistic perceptual reasoning.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>To perceive your surroundings your brain must distinguish between different possible scenes, each of which is more or less likely. In order to disambiguate interpretations that are equally likely given sensory input, the brain aggregates multiple sensations to form an interpretation of the world consistent with each. For instance, when you judge the size of an object you are viewing, its distance influences its image size that projects to your eyes. To estimate its true size, your brain must use extra information to disambiguate whether it is a small, near object, or large, far object. If you touch the object your brain could use the felt distance to scale the apparent size of the object. Cognitive scientists do not fully understand the computations that make perceptual disambiguation possible. Here we investigate how people disambiguate an object's size from its distance by measuring participants' size judgments when we provide different types of distance sensations. We find that distance sensations provided by viewing objects with both eyes open, and by touching the object, are both effective for disambiguating its size. We provide a general probabilistic framework to explain these results, which provides a unifying account of sensory fusion in the presence of ambiguity.</p>
</abstract><funding-group><funding-statement>This work was supported by a University of Minnesota Doctoral Dissertation Fellowship, EU grant 27141 “ImmerSence”, SFB 550-A11, ONR N 00014-07-1-0937 and the Max Planck Society. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="10"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>For well over a century <xref ref-type="bibr" rid="pcbi.1000697-Fechner1">[1]</xref>,<xref ref-type="bibr" rid="pcbi.1000697-Hering1">[2]</xref> psychologists have considered the question of how the brain uses visual angle sensations to make judgments of an object's size, overcoming the confounding effect of its distance - but the topic remains unsettled. Holway and Boring <xref ref-type="bibr" rid="pcbi.1000697-Holway1">[3]</xref> found that when strong sensations of an object's distance were made available, human size matching performance at different distances was high, but when distance sensations were removed human perception of an object's size was erroneously dominated its visual angle. Epstein et al. <xref ref-type="bibr" rid="pcbi.1000697-Epstein1">[4]</xref> surveyed literature regarding the “size-distance invariance hypothesis” <xref ref-type="bibr" rid="pcbi.1000697-Kilpatrick1">[5]</xref>, which holds that retinal visual angle constrains perception of an object's size and distance such that their ratio holds a constant value (e.g. doubling an object's physical distance while hold its retinal image size constant causes its perceived size to double), and concluded the size-distance invariance hypothesis was subject to a variety of failures. Several studies attributed participants' mistaken size perceptions <xref ref-type="bibr" rid="pcbi.1000697-Epstein1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Gogel1">[6]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Brenner1">[12]</xref> to misjudgments of physical distance, while others point out that specific experimental design choices and task demands contribute to reported failures of size constancy <xref ref-type="bibr" rid="pcbi.1000697-Kaufman1">[13]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Gogel3">[16]</xref>. Recently Combe and Wexler <xref ref-type="bibr" rid="pcbi.1000697-Combe1">[17]</xref> reported that size constancy is stronger when the relative distance between observer and object varies due to observer motion, than when due to object motion. Such findings highlight the unsettled state of current empirical knowledge about human size and distance perception, which is exacerbated by the absence of a unified theoretical account for normative size/distance perception.</p>
<p>We hypothesize that the brain makes size inferences by incorporating multiple sensations based on knowledge of their generative relationship with physical environment properties, and that failures like inaccuracy and systematic biases are due to poverty, unreliability, and/or mistrust, of observed sensations. Our experiments tackle the issue of how the brain incorporates distance information, in particular binocular and haptic (touch), to jointly perceive of how an object's size is changing. Size-change perception, which surprisingly has not been studied in the size/distance perception literature, bears close similarity to static size perception because size-change judgments based on retinal image size are ambiguous if information about the object's motion-in-depth is unknown. However when auxiliary sensations indicating motion-in-depth are available, an observer may rule out size-change/motion combinations that are inconsistent with the auxiliary sensations, and unambiguously infer whether the object is inflating or deflating. We predicted that despite the inherent novelty of the stimuli (i.e. objects do not typically change in size while moving in depth), participants' abilities to discriminate whether an object inflated or deflated would depend on the availability and quality of information about its motion-in-depth. Because binocular and haptic sensations provide information about depth, we predicted that they would each be incorporated for improving size-change judgments. Thus our study answers two key questions: 1) Does the brain use distance-change information for size-change perception? 2) What are the roles of binocular and haptic distance-change information?</p>
<p>Our size-change discrimination task (<xref ref-type="fig" rid="pcbi-1000697-g001">Figure 1</xref>) presented participants with an object that either inflated or deflated while simultaneously either approaching or receding, and asked them to discriminate whether it inflated or deflated (<xref ref-type="fig" rid="pcbi-1000697-g002">Figure 2</xref>). Most static size perception tasks use matching paradigms, and our task was advantageous because it allowed us to present a single stimulus per trial, and avoid issues regarding relative comparison of pairs of stimuli. We provided participants with different types of auxiliary motion-in-depth information, binocular <xref ref-type="bibr" rid="pcbi.1000697-Holway1">[3]</xref>,<xref ref-type="bibr" rid="pcbi.1000697-Gogel3">[16]</xref>,<xref ref-type="bibr" rid="pcbi.1000697-Combe1">[17]</xref> and haptic <xref ref-type="bibr" rid="pcbi.1000697-vanBeers1">[18]</xref>,<xref ref-type="bibr" rid="pcbi.1000697-Bross1">[19]</xref>, both in isolation and simultaneously, and examined their inflation/deflation judgments to evaluate how auxiliary distance information influenced perceived size-change. Evidence for the use of binocular and haptic distance information in size-change perception has not been reported, and previous studies of cue integration <xref ref-type="bibr" rid="pcbi.1000697-Ernst1">[20]</xref> suggest the brain combines haptic and binocular information in proportion to its reliability to jointly improve spatial perception.</p>
<fig id="pcbi-1000697-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000697.g001</object-id><label>Figure 1</label><caption>
<title>Experimental apparatus.</title>
<p>Participants viewed a mirror that reflected the stimulus image from a monitor suspended overhead, such that the image depicted objects located in front of the participants. Participants viewed the mirror through Stereographics stereo glasses that allowed the computer to present stimuli independently to one, or both, eyes. Binocular depth stimuli were achieved by presented different images to each eye that simulated the appropriate stereo disparity. Beneath the mirror, participants' fingertips were attached to a PHANToM (Sensable Technologies) robot arm that allowed the computer to apply forces to the finger simulating rigid surfaces and objects.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000697.g001" xlink:type="simple"/></fig><fig id="pcbi-1000697-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000697.g002</object-id><label>Figure 2</label><caption>
<title>Experiment 1 predictions and data format.</title>
<p>A–B: Trial parameters and predictions. The figure depicts the combinations of size- and distance-rates used in different trials, and hypothetical predictions. The x- and y-axes represent the rates of change of a ball's physical size and distance, respectively. Each quadrant corresponds to one combination of approaching/receding and inflating/deflating. Each black dot indicates a pair of distance- and size-change rates presented as a trial during the experiment (each trial was repeated 10 times). The trials' rates were chosen so they fell into 3 distance-direction groups (colored line lines), approaching (blue), receding (red), and intermediate (green). The diagonal, dashed line in A and B is a discrimination boundary representing size- and distance-rate combinations that would result in zero image size-change. The vertical dotted line in A and B is a discrimination boundary representing zero physical size-change. An observer who relies fully on the ball's changing image size, (e.g. the “ambiguous” H−/B− cue condition), would judge the ball to be “inflating” for trials to the right of the discrimination boundary (shaded region of Panel A), and make errors for stimuli that fall in the triangular hatched regions. An observer who correctly uses the distance cue(s) (e.g. the “unambiguous” H+/B+ condition) would completely disambiguate size and distance and make “inflating” size judgments (shaded region of Panel B). C–D: Psychometric functions for H−/B− (C) and H+/B+ (D) distance-cue conditions (participant 5). Each graph depicts the proportion of trials judged “inflating” in the approaching (blue), intermediate (green), and receding (red) distance-direction groups, for participant 5. The x-axis represents size-change rate (mm/s) and the y-axis represents the percent of trials judged “inflating”. The ‘X's represent actual data and the curves represent best-fit psychometric functions (cumulative Gaussian). The horizontal gray lines represent points at which the ball would be judged as “inflating” 50% of the time. The vertical colored dashed lines indicate the size-change rates that correspond to zero image size-change for each distance-change direction condition (the intersections of the diagonal dashed line with the colored lines in Box A). E–F: 3D psychometric functions for H−/B− (C) and H+/B+ (D) distance-cue conditions (participant 5). The surface plots depict participant 5's choice probabilities for the H−/B− and H+/B+ conditions. The x-axis represents size-change rate, the y-axis represents distance-change rate, and the z-axis represents the percentage of trials in which the participant judged the ball as “inflating”. The curves are schematic, they represent the average psychometric function estimates across the three distance-cue conditions, interpolated so that the PSEs lay on the discrimination boundary. The colored lines overlaid on the surfaces are similar to those in boxes C–D. This figure shows the relationship between the psychometric functions in boxes C–D and the participant's associated “inflating” size judgments shown in boxes A–B. The heavy black dotted line corresponds to the confusion (white-gray boundary in boxes A–B).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000697.g002" xlink:type="simple"/></fig>
<p>We found that when distance-change information was absent, participants' size-change judgments closely matched object's image size-change. However, when we provided participants with auxiliary distance-change sensations, participants incorporated this additional information to form more accurate size percepts that were consistent with both monocular <italic>and</italic> auxiliary sensations. Moreover when both binocular and haptic information was presented, most participants showed greater disambiguation of size than when either was presented in isolation. These results suggest size-change perception uses knowledge of how multi-modal size and distance sensations are related to interpret the scene. We interpret these findings in the framework of probabilistic perceptual inference, in which available sensations are combined according to their relationship to scene properties and their respective reliabilities <xref ref-type="bibr" rid="pcbi.1000697-Knill1">[21]</xref>,<xref ref-type="bibr" rid="pcbi.1000697-Knill2">[22]</xref>.</p>
</sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Experiment 1: Distance disambiguation for size perception</title>
<p>Experiment 1 contained four <italic>distance-cue conditions</italic> (H−/B−, H+/B−, H−/B+, H+/B+) that provided the four possible combinations of the presence (+) or absence (−) of haptic (H) and binocular (B) cues to the ball's distance-change. Haptic cues include proprioceptive and pressure information generated by the ball's movement in depth, and binocular cues include vergence and relative retinal disparity information that gives direct information about the ball's trajectory (see <xref ref-type="sec" rid="s4">Methods</xref> and <xref ref-type="supplementary-material" rid="pcbi.1000697.s001">Text S1</xref>). <xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2A–B</xref> show grids on which we plot the ball's size- and distance-change rates for all stimuli (black dots). The diagonal dashed line divides the stimuli into those in which the ball's <italic>image size</italic> increases (lower-right) versus decreases (upper-left) in size, and the vertical dotted line divides the stimuli into those in which ball's <italic>physical size</italic> inflates (right) versus deflates (left).</p>
<p>Our specific analysis and results are as follows. We separated balls' distance-change rates into three <italic>distance-direction</italic> groups: <italic>receding</italic>, <italic>intermediate</italic>, and <italic>approaching</italic> (colored lines, <xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2A–B</xref>). For each group we fit individual psychometric functions (cumulative Gaussian), where the height of the function at a particular size-change rate indicates the percentage of trials the participant judged “inflating”. <xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2C–D</xref> depict the results for one participant corresponding to the distance-direction group in <xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2A–B</xref>. <xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2E–F</xref> illustrates the relationship between the psychometric function fits and the shaded regions in <xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2A–B</xref>. Within each distance-cue condition, we found each psychometric function's 50% point, and fit a line between these points. We termed these best-fit lines participants' <italic>discrimination boundaries</italic> between “inflating” and “deflating” responses, and interpreted them as measures of participants' <italic>confusion</italic>. Specifically, we computed the best-fit slope with respect to distance-change rate (y-axis), and normalized it into a <italic>confusion ratio</italic>. A confusion ratio of 1 meant the participant discriminated inflation from deflation depending exclusively on the sign of the image size-change rate, which corresponded to the locus of physical distance- and size-change rates that produced an image-change rate of 0 (diagonal line, <xref ref-type="fig" rid="pcbi-1000697-g002">Figure 2A</xref>). A confusion ratio of 0 meant the participant discriminated inflation from deflation depending on the sign of the physical size-change rate (vertical line, <xref ref-type="fig" rid="pcbi-1000697-g002">Figure 2B</xref>). Simply put, when a participant's discrimination judgments were independent of the nuisance distance property they did not confuse distance-change for size change (zero confusion), and when their discrimination judgments were dependent on the nuisance distance property they confused distance-change with size change (confusion of 1). Our “confusion ratio” is related to the Brunswick and Thouless ratios, which apply to static size matching tasks <xref ref-type="bibr" rid="pcbi.1000697-Hershenson1">[23]</xref>. Notably, those ratios scale inversely to ours: they take values of 1 when participants comparison size judgments match the standard stimulus size (confusion of 0), and 0 when the comparison size judgment matches the image size (confusion of 1).</p>
<p>In the trials that contained no distance cues (H−/B−), we predicted participants would rely on prior assumptions that the ball tends to stay still (or move slowly). This is a sort of motion analog to the “specific distance tendency” <xref ref-type="bibr" rid="pcbi.1000697-Gogel2">[10]</xref>. Slow movement priors have previously been reported for 2D motion perception <xref ref-type="bibr" rid="pcbi.1000697-Weiss1">[24]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Stocker1">[26]</xref> and others <xref ref-type="bibr" rid="pcbi.1000697-Wexler1">[27]</xref> find similar priors in 3D <xref ref-type="bibr" rid="pcbi.1000697-Wexler2">[28]</xref>. Assuming slow, or no, movement would bias participants to attribute increasing image size largely to inflation and in turn lead them to judge stimuli with increasing image sizes as “inflating” (shaded grey in <xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2A–B</xref>). All participants display precisely this pattern; <xref ref-type="fig" rid="pcbi-1000697-g003">Figure 3</xref> (top-left box) shows the specific pattern for a typical participant (5) in the H−/B− condition, and <xref ref-type="fig" rid="pcbi-1000697-g004">Figure 4</xref> summarizes all participants (white bars). The evidence suggests that participants used prior assumptions that objects tend to stay at rest to disambiguate the scene. But because the ball was often approaching or receding, these often-incorrect prior assumptions led to erroneous perceptual size judgments. However, if we had allowed participants to decide whether the ball was changing size or changing distance, they may have preferred changing distance in some cases - it may be that the role of the prior is guided by the task's demands.</p>
<fig id="pcbi-1000697-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000697.g003</object-id><label>Figure 3</label><caption>
<title>Experiment 1 discrimination boundaries (participant 5).</title>
<p>This figure depicts participant 5's discrimination boundaries in all distance-cue conditions, on the same axes as in <xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2A–B</xref>. Each box is a single distance-cue condition (indicated by “H*/B*” on left side of each box). The colored lines are the same as those depicted in <xref ref-type="fig" rid="pcbi-1000697-g002">Figure 2</xref>. Gray regions represent size- and distance-change combinations predicted to be judged “inflating” more than 50% of the time by discrimination boundary fit to participants' PSEs; white regions represent combinations predicted to be judged “deflating” more than 50% of the time.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000697.g003" xlink:type="simple"/></fig><fig id="pcbi-1000697-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000697.g004</object-id><label>Figure 4</label><caption>
<title>Experiment 1 size-change confusion.</title>
<p>The figure depicts the size-change confusion for each participant, and the group mean. Each bar is a single distance-cue condition's size-change confusion, with 1 MADC error bars (can be interpreted similarly to standard error, see Data Analysis). The distance-cue condition is indicated by the bar's shading and referenced in the legend. The horizontal dashed line indicates the predicted confusion for an observer that relies exclusively on the image size-change cue to make physical size-change judgments; this is why the H−/B− condition bars, in which only image size-change cues were available, all overlap the horizontal dashed line.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000697.g004" xlink:type="simple"/></fig>
<p>In those conditions that contained auxiliary distance-change cues (H+/B−, H−/B+, H+/B+), we predicted participants would perceive trials with increasing image size as “inflating” (shaded regions in <xref ref-type="fig" rid="pcbi-1000697-g002">Figure 2B</xref>) only when the ball's movement in depth could not account for the changing image size; in other words, the participant will not perceive a rapidly approaching ball as inflating if the image size is only increasing a small amount. Likewise, when the ball's image size was decreasing, we predicted participants would perceive the ball as deflating only when the recession rate was not great enough to account for the image size change. All participants exhibited this pattern when the auxiliary binocular cue was present (H−/B+ and H+/B+), and 7 of 10 also showed size disambiguation when the haptic cue alone was present (H+/B−); again, <xref ref-type="fig" rid="pcbi-1000697-g003">Figure 3</xref> (bottom-left, and right boxes) shows the specific pattern for a typical participant (5) in the H+/B−, H−/B+, and H+/B+ conditions, and <xref ref-type="fig" rid="pcbi-1000697-g004">Figure 4</xref> summarizes all participants (grey bars). These results indicate that participants disambiguate the scene using both haptic and binocular distance-change cues, by augmenting their prior assumptions to make more accurate inflation discriminations.</p>
<p><xref ref-type="fig" rid="pcbi-1000697-g004">Figure 4</xref> presents confusion for all participants in all distance-change conditions. A two-way, repeated-measures ANOVA found a significant reduction of confusion across participants for both haptic (F(1, 9) = 17.42, p&lt;0.005) and binocular (F(1, 9) = 212.5, p&lt;0.0001) distance-change cues, and no significant interaction (F≈0, p&gt;0.05) (though the fact that the binocular cue almost fully disambiguated the inflation/deflation rate for most participants means any interaction effect would be masked by the ceiling).</p>
<p>Our results indicate participants use binocular distance-change cues significantly more than haptic cues for disambiguating the scene and improving physical size judgments (H+/B− vs. H−/B+ conditions compared in a paired sign test, p&lt;0.002). Previous cue combination studies <xref ref-type="bibr" rid="pcbi.1000697-Ernst1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Ernst2">[29]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Shams1">[38]</xref> have demonstrated integration of cues in proportion to their relative reliabilities. If each auxiliary cue, binocular and haptic, was trusted by the observer to provide information about the ball's distance-change, we hypothesized that their disparate explaining-away effects were due to the binocular cues' greater reliability over the haptic cues'. We examined whether Experiment 1's binocular/haptic discrepancy was due to differences in haptic and binocular cue reliabilities in Experiment 2.</p>
</sec><sec id="s2b">
<title>Experiment 2: Distance-change cue reliability</title>
<p>We measured the haptic and binocular cues' noise (see <xref ref-type="bibr" rid="pcbi.1000697-Ernst3">[39]</xref>) to determine whether differences in their respective reliabilities could explain their discrepant effects on disambiguating the balls' inflation/deflation rates in Experiment 1. Participants observed two moving balls sequentially, and judged which ball moved faster, in a two-interval forced choice (2IFC) discrimination task. Experiment 2 used binocular and haptic cues in different conditions, so we could measure their respective reliabilities in isolation. The ball's movements were always restricted to the depth axis (with slight fronto-parallel oscillation described in the <xref ref-type="sec" rid="s4">Methods</xref>) as in Experiment 1, and also spanned the same speed range as Experiment 1. In the haptic condition, the ball was not visible during the stimulus interval; in the binocular condition the ball was visible and its image size changed under accurate perspective projection (see <xref ref-type="sec" rid="s4">Methods</xref> for details).</p>
<p>Our results show that with the exception of one participant, the haptic and binocular cue reliabilities do not explain their differential uses in Experiment 1. <xref ref-type="fig" rid="pcbi-1000697-g005">Figure 5</xref> shows the haptic and binocular distance-change noise magnitudes for each participant, where each pair of bars represents the haptic and binocular noise magnitudes (standard deviation) for a participant. Qualitatively it is clear that the binocular and haptic noises have comparable magnitudes. By comparing the set of bootstrap-resampled binocular and haptic noise magnitudes, we can perform a hypothesis test of the prediction that the binocular noise is less than the haptic noise. All participants fail this test (p&gt;0.05), except participant 9 (p&lt;0.05). Thus, differences in cue reliabilities cannot explain Experiment 1's discrepant use of binocular and haptic cues to reduce confusion. This effect is consistent with the observer trusting the binocular cue more greatly than the haptic, thus integrating less of the haptic cue information.</p>
<fig id="pcbi-1000697-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000697.g005</object-id><label>Figure 5</label><caption>
<title>Experiment 2 distance cue noise standard deviations.</title>
<p>The figure depicts the inverse-reliability of the haptic and binocular distance-change cues for each participant, and pooled across all participants. Each bar represents the standard deviation of the noise that corrupts a distance-change cue, with 1 MADC error bars (see Data Analysis). The haptic cue is indicated by the light bars, the binocular cue by the dark bars.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000697.g005" xlink:type="simple"/></fig></sec></sec><sec id="s3">
<title>Discussion</title>
<p>Our study finds that humans use within- (binocular) and cross-modal (haptic) distance-change sensations to disambiguate otherwise ambiguous monocular image size sensations, resulting in more accurate judgments of object size. Binocular distance-change cues influenced participants' size judgments more strongly than haptic cues. When both modalities' distance-change cues were presented simultaneously, nine of ten participants' physical size judgments were virtually confusion-free.</p>
<p>In order to use the distance-change to improve size-change judgments, the brain must use generative knowledge of how an object's physical size and distance cause monocular image size- and distance-change cues to alleviate the confounding effects of physical distance-change. Such knowledge may be abstractly represented (the laws of physics) or encoded in a more applied manner (a look-up table relating size, distance, and image cues). This is consistent with a core feature of Bayesian reasoning termed <italic>explaining-away</italic> <xref ref-type="bibr" rid="pcbi.1000697-Pearl1">[40]</xref>. Knowledge about the relationships between world properties and sensations provides perceptual inference processes with a common representation for integrating prior knowledge with sensory evidence, and probabilistically “solving for” scene properties based on sensations. Bayesian reasoning as a framework for interpreting perceptual behavior has attracted considerable attention because it provides a principled theoretical framework for describing the brain's recovery of scene properties from sensations <xref ref-type="bibr" rid="pcbi.1000697-Knill2">[22]</xref>,<xref ref-type="bibr" rid="pcbi.1000697-Kersten1">[41]</xref> and has allowed quantitative confirmation that humans exhibit near-optimal perceptual performance across many tasks <xref ref-type="bibr" rid="pcbi.1000697-Ernst1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Knill2">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Ernst2">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Battaglia1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Knill3">[35]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Shams1">[38]</xref>. Various studies have found that when humans judge single scene properties that produce multiple pieces of sensory information, or <italic>cues</italic> (<xref ref-type="fig" rid="pcbi-1000697-g006">Figure 6A</xref>), they average the cues in proportion to their reliability <xref ref-type="bibr" rid="pcbi.1000697-Yuille1">[25]</xref>, which is the Bayes'-prescribed perceptual strategy. Others report <xref ref-type="bibr" rid="pcbi.1000697-Mamassian1">[42]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Adams1">[44]</xref> perceptual “discounting”, in which prior knowledge is used to disambiguate otherwise ambiguous sensory cues, which requires knowledge of the generative relationship between a cue and the scene properties that cause it.</p>
<fig id="pcbi-1000697-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000697.g006</object-id><label>Figure 6</label><caption>
<title>Bayesian inference: from discounting to explaining-away.</title>
<p>Perception is characterized by two complementary processes: 1.) The “generative process” determines how scene properties, such as an object's physical size and distance, cause the observer's sensations, such as monocular image cues, binocular, and haptic information, and 2.) The scene “inference process” characterizes the observer's use of generative and prior knowledge to recover local scene properties. The generative process can be summarized by a conditional likelihood <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000697.e001" xlink:type="simple"/></inline-formula>, the inference process by the posterior probability distribution, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000697.e002" xlink:type="simple"/></inline-formula>. Bayes' rule dictates how each process relates: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000697.e003" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000697.e004" xlink:type="simple"/></inline-formula> represents the prior probability distribution over scene properties. In the figures above, scene properties are represented by white nodes, and cues are represented by gray nodes. In our experiment, the desired property was the physical ball size, the nuisance property was the physical ball distance, the ambiguous cue was the monocular image size cue, and the auxiliary cue was provided by the binocular and haptic distance cues. A.) Discounting inference: a desired property influences a single cue, which is ambiguous due to the confounding influence of a nuisance property. The single ambiguous cue can be used to estimate the desired scene property that caused it by discounting the effect of the nuisance property using prior knowledge about it. The conditional relationships (arrows) in Box A specify that Bayes' rule can be factored such that:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000697.e005" xlink:type="simple"/></disp-formula>B.) Explaining-away inference: similar structure to discounting, but involves additional, auxiliary cues. By using the auxiliary cue to “explain-away” the influence the nuisance property has on the ambiguous cue, the desired property can be unambiguously inferred. Bayes' rule specifies inferring the desired property as:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000697.e006" xlink:type="simple"/></disp-formula>The ambiguous and auxiliary cues can be factored because they are conditionally independent given the nuisance property.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000697.g006" xlink:type="simple"/></fig>
<p>Our study examines a more complex situation (<xref ref-type="fig" rid="pcbi-1000697-g006">Figure 6B</xref>) where, unlike discounting <xref ref-type="bibr" rid="pcbi.1000697-Mamassian1">[42]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Adams1">[44]</xref> (<xref ref-type="fig" rid="pcbi-1000697-g006">Figure 6A</xref>), correct inference of the <italic>desired</italic> scene property (physical size-change) requires an inference strategy that exploits generative knowledge of the relationships between <italic>multiple</italic> scene properties (physical size-change and physical distance-change) and <italic>multiple</italic> sensations (retinal image size-change, binocular and haptic distance-change cues). No single sensation alone, retinal image size-change or distance-change cue, constrains the physical size-change inference uniquely due to the confounding influence of <italic>nuisance</italic> scene properties – properties that affect sensations but do not contribute to the judgment - in this case, physical distance-change (<xref ref-type="fig" rid="pcbi-1000697-g006">Figure 6B</xref>). Because the nuisance property (physical distance) confounds the direct cue (retinal image size-change) to the desired property (physical size-change), incorporating <italic>auxiliary</italic> cues (distance-change sensations) can explain-away the influence of the nuisance physical distance-change and allow unambiguous judgments of physical size-change.</p>
<p>Explaining-away can characterize other perceptual tasks in which multiple scene properties influence multiple cues in the manner depicted by <xref ref-type="fig" rid="pcbi-1000697-g006">Figure 6B</xref>; for example, estimating surface reflectance from sensed lightness despite the confounding influence of illumination <xref ref-type="bibr" rid="pcbi.1000697-Adelson1">[45]</xref>, estimating object shape from image contours despite the confounding influence of pose, and the general class of “perceptual constancy” effects. Also explaining-away is a general Bayesian perspective on a specialized concept <xref ref-type="bibr" rid="pcbi.1000697-Maloney1">[46]</xref> termed “cue promotion” - in which a relative cue (like stereoscopic disparity) is able to be incorporated into perceptual judgments (promoted) only because a second, auxiliary cue (like depth from vergence) provides information to make it an absolute cue. Many unimodal perceptual phenomena are characteristic of explaining-away <xref ref-type="bibr" rid="pcbi.1000697-Holway1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Knill4">[47]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Landy3">[48]</xref>. Multimodal perceptual explaining-away is less documented, but explaining-away in bistable percepts has been reported <xref ref-type="bibr" rid="pcbi.1000697-Sekuler1">[49]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Wexler3">[52]</xref> as well as in continuous percepts <xref ref-type="bibr" rid="pcbi.1000697-Battaglia2">[53]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-MacNeilage1">[54]</xref>. Our results extend previous reports of explaining-away to include continuous, multimodal scene property judgments <xref ref-type="bibr" rid="pcbi.1000697-Knill4">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Blake1">[50]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-James1">[51]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Battaglia2">[53]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Kersten2">[55]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Bloj1">[56]</xref>.</p>
<p>Explaining-away is only appropriate when the auxiliary cues are dependent on scene properties that influence cues to the desired scene property. This typically occurs when the nuisance variable causes the auxiliary cue. There is evidence suggesting that non-visual sensory cues are integrated less efficiently than their reliabilities afford <xref ref-type="bibr" rid="pcbi.1000697-Battaglia1">[33]</xref> or in a less committed, reversible manner <xref ref-type="bibr" rid="pcbi.1000697-Ernst3">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Hillis2">[57]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Bresciani1">[58]</xref>, and some have attributed lack of cue integration to weak conditional dependency between cues and world properties <xref ref-type="bibr" rid="pcbi.1000697-Landy1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1000697-Bresciani1">[58]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Sato1">[62]</xref>. <italic>Reliability</italic> reflects the quality of a cue; if the sensory signal is corrupted by noise the reliability decreases. <italic>Trust</italic> reflects the degree to which the observer believes the cue is related to the desired scene property; there may be other scene properties that influence the auxiliary cue which diminishes the cue's diagnosticity for the desired scene property. In cases in which all auxiliary cues are trusted equally, they should be integrated in proportion to their relative reliabilities only. However, if trust in the auxiliary cues is unequally distributed they should integrated in proportion to the relative reliabilities <italic>and</italic> their trust.</p>
<p>Previous studies that tested multisensory disambiguation of bistable stimuli reported mixed results <xref ref-type="bibr" rid="pcbi.1000697-Blake1">[50]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-James1">[51]</xref>. It is possible that these different findings are due to non-visual cues being trusted less due to their frequent independence from visual cues. Alternatively the mixed results may be due to variable cue reliabilities <xref ref-type="bibr" rid="pcbi.1000697-Jacobs1">[63]</xref>, for instance when visual cues to a bistable stimulus's structure vary in relative reliability compared with tactile cues, tactile cues may influence perceived structure in proportion to their reliability. Our experiment was sensitive to partial disambiguation, because participants discriminated percepts that lied on a continuous axis (rate of distance-change), which may reconcile previous mixed results by demonstrating the graded roles of auxiliary cue information. We found different effects of individual haptic and visual cues, and strongest influence when both were present, which argues for the reliability-weighted integration of that information.</p>
<p>One potential reason that binocular distance-change cues were more useful than haptic cues for disambiguating size perception in our experiment may be that the haptic cue is more weakly coupled with the image cue than the binocular cue, perhaps reflecting the causal structure of the world. In decoupled situations, in which different world properties influence different cues independently, it is inappropriate to combine cues. For instance, in natural settings binocular depth and monocular image size cues are transmitted to the eyes by the same light patterns, thus are usually highly dependent. Because, sensory channels for visual and haptic information differ, and there are many situations in which the felt position of an object differs from its visual position, like manipulating a tool, playing with a yo-yo, or touching an object that is occluded by a nearer object. In our experiment the haptic cue was somewhat atypical, because we forced the fingertip to always be positioned at the <italic>center</italic> of the ball, not the edge, so the size-change would not be directly measurable by radial pressure toward or away from the ball's center. It is plausible that this atypicality degraded participants' belief that haptic and visual cues were caused by the same object. Recent reports of visual-auditory cue integration have found causality-modulated cue integration <xref ref-type="bibr" rid="pcbi.1000697-Roach1">[59]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Sato1">[62]</xref>, and it may explain why the haptic cue is trusted less for disambiguation compared with the disparity cue in our experiment.</p>
<p>Another possibility derives from the brain's algorithm used to compute the size-change rate. Per Rushton and Wann (<xref ref-type="bibr" rid="pcbi.1000697-Rushton1">[64]</xref>, <xref ref-type="fig" rid="pcbi-1000697-g001">Figure 1</xref> caption), the B+ conditions allow the possibility of estimating the size-change rate without explicitly estimating the distance-change rate (by computing the ratio between image-size-change and binocular vergence angle-change rates, which causes the explicit distance-change rate terms to cancel). This means that a potential source of noise in the B+ conditions, incurred during estimation of the distance-change rate, would be removed, allowing higher fidelity disambiguation of the size-change rate in those conditions. If this were the case, Experiment 2 may have overestimated the effect of noise in Experiment 1's B+ conditions depending on how noise enters the system: if noise only corrupts the brain's estimates of binocular vergence angle-change rates, then Experiment 2's binocular noise estimates are valid. However, if noise additionally corrupts the ability to make binocular distance-change judgments, then Experiment 2's binocular noise estimates would be overestimates of the true noise afflicting Experiment 1's B+ conditions. This logic may be moot if the distance-change is used to drive oculomotor vergence dynamics (i.e. tracking in depth) because in that case the noisy distance-change rate would influence the binocular vergence-change rate. Either way, in order to apply the ratio algorithm <xref ref-type="bibr" rid="pcbi.1000697-Rushton1">[64]</xref> for computing size-change still requires the brain to understand the generative relationships among size, distance, and the image and binocular sensory cues, which does not diminish our findings.</p>
<p>One future challenge is directly assessing what prior assumptions the perceptual system has about the world, and how reliability and trust in various cues are learned <xref ref-type="bibr" rid="pcbi.1000697-Jacobs1">[63]</xref>. With quantitative estimates of prior assumptions, one can predict how reliable auxiliary cues must be and how much they should be trusted, to override conflicting priors. Other studies <xref ref-type="bibr" rid="pcbi.1000697-Kilpatrick1">[5]</xref> refer to a “specific distance tendency” in which participants assume objects appear at a canonical distance. In the 2D motion perception domain and <xref ref-type="bibr" rid="pcbi.1000697-Weiss1">[24]</xref>,<xref ref-type="bibr" rid="pcbi.1000697-Stocker1">[26]</xref> each reported that humans exhibit strong prior preferences for “slow and smooth” movement, and our study suggests participants assume objects move slowly in 3D, but a stronger direct test of 3D motion priors requires quantitative predictions. Measuring prior knowledge directly is difficult, but developing indirect methods is an important topic of recent and continuing research <xref ref-type="bibr" rid="pcbi.1000697-Stocker1">[26]</xref>.</p>
<p>Our results indicate that the brain uses multisensory distance-change cues to improve perceptual size-change disambiguation. Haptic and binocular distance-change cues are both effective, binocular more than haptic, which is not explained by their relative reliabilities, but is consistent with causal cue integration models <xref ref-type="bibr" rid="pcbi.1000697-Krding1">[61]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Sato1">[62]</xref>. Our findings support the view that perceptual processing employs knowledge of the sensory generative process to infer scene properties and disambiguate competing interpretations.</p>
</sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<sec id="s4a">
<title>Ethics statement</title>
<p>Experiments were undertaken with the understanding and written consent of each subject, with the approval of the Ethik-Kommission der Medizinischen Fakultät und am Universitätsklinikum Tübingen, and in compliance with national legislation and the Code of Ethical Principles for Medical Research Involving Human Subjects of the World Medical Association (Declaration of Helsinki).</p>
</sec><sec id="s4b">
<title>Participants</title>
<p>11 right-handed participants (ages 18 to 35) with normal/corrected-to-normal vision (Snellen-equivalent of 20/25 or better) and normal stereopsis (60 s of arc or better - Stereotest circles; Stereo Optical, Chicago) were recruited from MPI Tuebingen's Subject Database and compensated 8 €/h. All participants completed both Experiments 1 and 2, with the exception of one who was excluded from reported results because her responses indicated she did not follow the experimenters' instructions.</p>
</sec><sec id="s4c">
<title>Apparatus</title>
<p>Participants sat in a virtual workbench that presented both graphical and haptic stimuli (<xref ref-type="fig" rid="pcbi-1000697-g001">Figure 1</xref>; see <xref ref-type="bibr" rid="pcbi.1000697-Ernst1">[20]</xref> for details). Participants' heads were stabilized with a chin-and-forehead rest 45 deg forward. Visual stimuli were presented on a monitor (21″ GDM-F500R SONY, 38.2×29.8 cm, resolution of 1280×1024 pixels, refresh rate 100 Hz) whose center was 50 cm from the eyes reflected on a first-surface mirror, and whose top was tilted 22 deg backwards from the fronto-parallel plane. Binocular stimuli were presented through CrystalEyes TM (StereoGraphics) liquid-crystal shutter glasses which allowed different images to be presented to each eye. Haptic stimuli were presented using a Premium PHANToM force-feedback device (SensAble Technologies), to which the index finger was attached by a thimble and elastic band, allowing six degrees of freedom movements. The 3D fingertip position was monitored continuously, and the computer applied simulated normal forces when the tip reached the positions of the virtual haptic objects. The apparatus was calibrated to spatially align the visual and haptic stimuli, simulating a single scene.</p>
</sec><sec id="s4d">
<title>General procedure</title>
<p>There were two experiments, <italic>1. Distance cue disambiguation for size perception</italic> and <italic>2. Distance cue reliability</italic>, that each contained <italic>haptic</italic> and <italic>binocular</italic> distance cues. At the start of each trial, a 35 mm diameter red ball was placed between 443 mm and 455 mm from the observer (4.4–4.5 deg visual angle). In trials containing a binocular distance cue, the ball was presented binocularly to the observer's two eyes, rendered to simulate an interocular distance of 58 mm. The participant signaled he or she was ready to begin the trial by reaching and contacting the ball with the index finger (attached to the PHANToM device). Once contact was made, the PHANToM device applied forces to the fingertip to guide it to the center of the ball.</p>
<p>At this point the experimental phase of the trial began: the ball began moving in depth with respect to the participant, while simultaneously changing in size, for a duration of 1000 ms. If the trial contained a haptic distance cue, as the ball moved appropriate forces were applied to the fingertip to maintain its position at the center of the ball; otherwise no forces were applied to the fingertip once the ball began to move and participants typically held their fingertips at a roughly constant position. The ball also slightly oscillated in the observer's fronto-parallel plane following a sinusoidal displacement (with amplitude between 5.0 and 15.0 mm) in a random direction and at a random frequency (between 0.35 and 0.5 Hz). This was intended to both decrease the similarity of the visual and haptic trajectories across trials, increase their perceptual fusion, as well as obviate local edge motion information as a direct indicator of image size-change.</p>
<p>Although fixation was not precisely controlled or monitored, our experience and observations of participants suggested they fixated the ball in monocular and binocular conditions. Also, our stimuli were constructed to eliminate two potential sources of size-change information from binocular cues. One source is “Da Vinci” stereopsis, which refers to depth information that results from points on the object that are visible in only one eye due to object self-occlusion. This cue requires identifying object points without correspondences between the eyes. Because the ball has no horizontal luminance/color contrast, Da Vinci stereopsis was eliminated as a cue to size-change. A second potential source of binocular size-change information was disparities due to the ball's oscillation. For a ball in the mid-sagittal plane there are no binocular disparity cues to size change. We determined that the slight oscillatory movements the balls made out of the mid-sagittal plane created sub-threshold (undetectable) relative disparity cues to ball size. See <xref ref-type="supplementary-material" rid="pcbi.1000697.s001">Text S1l</xref> for an in-depth examination and schematic of the binocular cue. Lastly, accommodation was a potential cue, uncontrolled except that the screen depth was fixed.</p>
<p>After 1000 ms, the ball disappeared. In Experiment 1, only a single stimulus interval was presented. In the Experiment 2, two stimulus intervals were presented; following the first interval a new ball appeared and the second interval proceeded just as the first. Once the stimulus interval(s) were finished, two buttons appeared on the left side of the scene and participants were instructed to press the button that corresponded to his or her judgment of the scene. The trial ended once the button was pressed, and the subsequent trial began immediately.</p>
<p>In Experiment 1 the buttons were labeled “inflating” and “deflating”, and the participant pressed the button corresponding to his or her perception of the ball's physical size change. We interpreted participants' choices as their discriminations of the ball's absolute size-change rate.</p>
<p>In Experiment 2, each trial was designed as two-interval forced-choice (2IFC). In every trial, both balls moved in the same direction with respect to the participant (approaching/receding), but their speeds were different relative to each other. Also, the balls never changed in size (equivalent to 0 mm/s size-change rate in the main experiment). In haptic trials, the ball disappeared from view as soon as it began to move. Following the two intervals participants were instructed to press one button among two choices, labeled “1st” and “2nd”, indicating which interval contained the faster ball.</p>
</sec><sec id="s4e">
<title>Design specifics</title>
<sec id="s4e1">
<title>Experiment 1</title>
<p>Four distance-change cue conditions were run, distinguished by the type(s) of distance cues that were presented: no-haptic/no-binocular (H−/B−), haptic/no-binocular (H+/B−), no-haptic/binocular (H−/B+), and haptic/binocular (H+/B+). The haptic and binocular distance cues are described above in the General Procedure subsection; each provided a compelling sensation of the ball's changing distance.</p>
<p>The ball's movement rate was selected from between −104.0 and 104.0 mm/s, where a negative velocity corresponds to the ball moving toward the observer and a positive velocity corresponds to the ball moving away, in the line of sight of the participant. Specifically, we used 3 pedestal distance-change rates, {−71.5, 0.0, 71.5 mm/s}, and varied the distance-change around these pedestal values by adding satellite values {−32.5, −26.0, −19.5, −13.0, −6.5, 0.0, 6.5, 13.0, 19.5, 26.0, 32.5 mm/s}, for a total of 33 possible distance-change values. The ball spanned 7.7 deg visual angle at its nearest/largest state and 2.5 deg at its farthest/smallest.</p>
<p>Concurrent with the ball's distance change, its size changed at a rate selected from between −11.0 to 11.0 mm/s, where negative rates correspond to the ball deflating and positive rates correspond to the ball inflating. For each pedestal distance-change, we paired each of the satellite distance-change values with a particular size-change rate from the set {−11.0, −8.8, −6.6, −4.4, −2.2, 0.0, 2.2, 4.4, 6.6, 8.8, 11.0 mm/s}. The pedestal distance-change rates defined which <italic>distance-direction group</italic> (approaching, receding, intermediate; indicated by the line colors in <xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2C–F</xref>) the trial belonged to. In total there were 33 unique distance and size-change rate pairs, each repeated 10 times. <xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2A–B</xref> plots all unique distance- and size-change rate combinations (black dots) as 2D coordinates.</p>
</sec><sec id="s4e2">
<title>Experiment 2</title>
<p>Two conditions were run, haptic and binocular. The experiment was 2IFC and the two intervals were called the standard and comparison, the order in which they were presented was randomly selected before each trial. For each distance-cue condition, two standard distance-change rates were used, {−55.0, 55.0 mm/s}. The comparison distance-change rates differed from the standard by a value from the set {−54.0, −36.0, −18.0, 0.0, 18.0, 36.0, 54.0 mm/s}. Each possible standard and comparison pair was repeated 14 times.</p>
</sec></sec><sec id="s4f">
<title>Data analysis</title>
<p>All confidence intervals were estimated by nonparametric bootstrapping <xref ref-type="bibr" rid="pcbi.1000697-Efron1">[65]</xref>, comparable to those used by <xref ref-type="bibr" rid="pcbi.1000697-Wichmann1">[66]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Wichmann2">[67]</xref>. Error bars on some figures were computed using the “median absolute deviations with finite sample correction factors” (MADC) from the LIBRA Robust Statistics toolbox for Matlab <xref ref-type="bibr" rid="pcbi.1000697-Verboven1">[68]</xref>. MADC approximates standard deviation estimates of the mean of the sample for normally-distributed data, but it is more robust for skewed and kurtotic distributions.</p>
<sec id="s4f1">
<title>Experiment 1</title>
<p>Maximum-likelihood estimation (MLE) was used to fit participants' size-change discrimination performance with psychometric functions (robust cumulative normal functions, see <xref ref-type="bibr" rid="pcbi.1000697-Wichmann1">[66]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Wichmann2">[67]</xref>) with size-change rate on the abscissa and frequency of responding “inflating” on the ordinate. The Point of Subjective Equality (PSE) was the 50% point on the fitted psychometric functions (horizontal gray lines in <xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2C–D</xref>). Across distance-change directions, <italic>approaching</italic>, <italic>intermediate</italic>, and <italic>receding</italic>, we maximum-likelihood-fit <italic>discrimination boundary</italic> lines to the PSEs to separate ‘inflating’ from ‘deflating’ responses (<xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2E–F</xref>). The free parameters for estimating discrimination boundaries were slope and intercept (with respect to the distance-change axis). Because all error bars were estimated by bootstrapped resampling, if the linear fits were poor models this was represented as increased error bar magnitudes.</p>
<p>We defined the <italic>confusion</italic> as the slope of the discrimination boundary with respect to the distance-change axis; confusion of 1 corresponds to the image-only discrimination boundary (<xref ref-type="fig" rid="pcbi-1000697-g002">Figure 2A–B</xref> diagonal dashed line), while confusion of 0 corresponds to the veridical size-change discrimination (<xref ref-type="fig" rid="pcbi-1000697-g002">Figures 2A–B</xref> vertical dotted line).</p>
</sec><sec id="s4f2">
<title>Experiment 2</title>
<p>We MLE-fit discrimination performance with robust cumulative normal functions <xref ref-type="bibr" rid="pcbi.1000697-Wichmann1">[66]</xref>–<xref ref-type="bibr" rid="pcbi.1000697-Wichmann2">[67]</xref> and interpreted the fitted just-noticeable-difference (JND) as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000697.e007" xlink:type="simple"/></inline-formula> times the standard deviation of the noise which corrupted a single distance-change cue <xref ref-type="bibr" rid="pcbi.1000697-Ernst3">[39]</xref>. Each single-cue standard deviation, which we refer to as noise, was an estimate of how reliable each distance-change cue was (reliability is inversely proportional to the noise's variance).</p>
</sec></sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1000697.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000697.s001" xlink:type="simple"><label>Text S1</label><caption>
<p>Details regarding the binocular stimuli presented to participants.</p>
<p>(0.24 MB PDF)</p>
</caption></supplementary-material>
</sec></body>
<back>
<ack>
<p>We thank our anonymous reviewers for their helpful comments.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1000697-Fechner1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fechner</surname><given-names>GT</given-names></name>
</person-group>             <year>1860</year>             <article-title>Elemente der Psychophysik, II.</article-title>          </element-citation></ref>
<ref id="pcbi.1000697-Hering1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hering</surname></name>
</person-group>             <year>1861</year>             <article-title>Beitriige zur Physiologie, I.</article-title>          </element-citation></ref>
<ref id="pcbi.1000697-Holway1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Holway</surname><given-names>AH</given-names></name>
<name name-style="western"><surname>Boring</surname><given-names>EG</given-names></name>
</person-group>             <year>1941</year>             <article-title>Determinants of apparent visual size with distance variant.</article-title>             <source>Am J Psyc</source>             <volume>54(1)</volume>             <fpage>21</fpage>             <lpage>37</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Epstein1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Epstein</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Park</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Casey</surname><given-names>A</given-names></name>
</person-group>             <year>1961</year>             <article-title>The current status of the size-distance hypothesis.</article-title>             <source>Psyc Bull</source>             <volume>58</volume>             <fpage>491</fpage>             <lpage>514</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Kilpatrick1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kilpatrick</surname><given-names>FP</given-names></name>
<name name-style="western"><surname>Ittelson</surname><given-names>WH</given-names></name>
</person-group>             <year>1953</year>             <article-title>The size-distance invariance hypothesis.</article-title>             <source>Psyc Rev</source>             <volume>60(4)</volume>             <fpage>223</fpage>             <lpage>231</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Gogel1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gogel</surname><given-names>WC</given-names></name>
<name name-style="western"><surname>Wist</surname><given-names>ER</given-names></name>
<name name-style="western"><surname>Harker</surname><given-names>GS</given-names></name>
</person-group>             <year>1963</year>             <article-title>A test of the invariance of the ration of perceived size to perceived distance.</article-title>             <source>Am J Psyc</source>             <volume>76</volume>             <fpage>537</fpage>             <lpage>553</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Ono1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ono</surname><given-names>H</given-names></name>
</person-group>             <year>1966</year>             <article-title>Distal and proximal size under reduced and non-reduced viewing conditions.</article-title>             <source>Am J Psyc</source>             <volume>79(2)</volume>             <fpage>234</fpage>             <lpage>241</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Heinemann1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Heinemann</surname><given-names>EG</given-names></name>
<name name-style="western"><surname>Nachmias</surname><given-names>J</given-names></name>
</person-group>             <year>1965</year>             <article-title>Accommodation as a cue to distance.</article-title>             <source>Am J Psyc</source>             <volume>78(1)</volume>             <fpage>139</fpage>             <lpage>142</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Gruber1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gruber</surname><given-names>HE</given-names></name>
<name name-style="western"><surname>Dinnerstein</surname><given-names>AJ</given-names></name>
</person-group>             <year>1965</year>             <article-title>The role of knowledge in distance-perception.</article-title>             <source>Am J Psyc</source>             <volume>78(4)</volume>             <fpage>575</fpage>             <lpage>581</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Gogel2"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gogel</surname><given-names>WC</given-names></name>
<name name-style="western"><surname>Tietz</surname><given-names>JD</given-names></name>
</person-group>             <year>1973</year>             <article-title>Absolute motion parallax and the specific distance tendency.</article-title>             <source>Perc Psyc</source>             <volume>13</volume>             <fpage>284</fpage>             <lpage>292</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Ono2"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ono</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Muter</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Mitson</surname><given-names>L</given-names></name>
</person-group>             <year>1974</year>             <article-title>Size-distance paradox with accommodative micropsia.</article-title>             <source>Perc Psyc</source>             <volume>15</volume>             <fpage>301</fpage>             <lpage>307</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Brenner1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Brenner</surname><given-names>E</given-names></name>
<name name-style="western"><surname>van Damme</surname><given-names>WJ</given-names></name>
</person-group>             <year>1999</year>             <article-title>Perceived distance, shape and size.</article-title>             <source>Vis Res</source>             <volume>39(5)</volume>             <fpage>975</fpage>             <lpage>986</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Kaufman1"><label>13</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kaufman</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Rock</surname><given-names>I</given-names></name>
</person-group>             <year>1989</year>             <article-title>The moon illusion thirty years later.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Hershenson</surname><given-names>M</given-names></name>
</person-group>             <source>The moon illusion</source>             <publisher-name>Erlbaum</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000697-Blessing1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Blessing</surname><given-names>WW</given-names></name>
<name name-style="western"><surname>Landauer</surname><given-names>AA</given-names></name>
<name name-style="western"><surname>Coltheart</surname><given-names>M</given-names></name>
</person-group>             <year>1967</year>             <article-title>The effect of false perspective cues on distance- and size-judgments: an examination of the invariance hypothesis.</article-title>             <source>Am J Psyc</source>             <volume>80(2)</volume>             <fpage>250</fpage>             <lpage>256</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-MonWilliams1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mon-Williams</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Tresilian</surname><given-names>JR</given-names></name>
</person-group>             <year>1999</year>             <article-title>A review of some recent studies on the extra-retinal contribution to distance perception.</article-title>             <source>Perception</source>             <volume>28</volume>             <fpage>167</fpage>             <lpage>181</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Gogel3"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gogel</surname><given-names>WC</given-names></name>
</person-group>             <year>1972</year>             <article-title>Scalar perceptions with binocular cues of distance.</article-title>             <source>Am J Psyc</source>             <volume>84(4)</volume>             <fpage>477</fpage>             <lpage>498</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Combe1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Combe</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Wexler</surname><given-names>M</given-names></name>
</person-group>             <year>2009</year>             <article-title>Observer movement and size constancy.</article-title>             <source>Psych Sci</source>             <comment>in press</comment>          </element-citation></ref>
<ref id="pcbi.1000697-vanBeers1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Beers</surname><given-names>RJ</given-names></name>
<name name-style="western"><surname>Sittig</surname><given-names>AC</given-names></name>
<name name-style="western"><surname>Gon</surname><given-names>JJ</given-names></name>
</person-group>             <year>1999</year>             <article-title>Integration of proprioceptive and visual position-information: An experimentally supported model.</article-title>             <source>J Neurophys</source>             <volume>81</volume>             <fpage>1355</fpage>             <lpage>1364</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Bross1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bross</surname><given-names>M</given-names></name>
</person-group>             <year>2000</year>             <article-title>Emmert's law in the dark: active and passive proprioceptive effects on positive visual afterimages.</article-title>             <source>Perception</source>             <volume>29</volume>             <fpage>1385</fpage>             <lpage>1391</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Ernst1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ernst</surname><given-names>MO</given-names></name>
<name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name>
</person-group>             <year>2002</year>             <article-title>Humans integrate visual and haptic information in a statistically optimal fashion.</article-title>             <source>Nature</source>             <volume>415</volume>             <fpage>429</fpage>             <lpage>433</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Knill1"><label>21</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Knill</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Richards</surname><given-names>W</given-names></name>
</person-group>             <year>1996</year>             <source>Perception as Bayesian inference</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000697-Knill2"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Knill</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name>
</person-group>             <year>2004</year>             <article-title>The Bayesian brain: The role of uncertainty in neural coding and computation for perception and action.</article-title>             <source>Tr Neuro</source>             <volume>27(12)</volume>             <fpage>712</fpage>             <lpage>719</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Hershenson1"><label>23</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hershenson</surname><given-names>ME</given-names></name>
</person-group>             <year>1998</year>             <source>Visual Space Perception: A Primer</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press, 1998</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000697-Weiss1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Weiss</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>
<name name-style="western"><surname>Adelson</surname><given-names>EH</given-names></name>
</person-group>             <year>2002</year>             <article-title>Motion illusions as optimal percepts.</article-title>             <source>Natu Neuro</source>             <volume>5(6)</volume>             <fpage>598</fpage>             <lpage>604</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Yuille1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Yuille</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Grzywacz</surname><given-names>N</given-names></name>
</person-group>             <year>1988</year>             <article-title>A computational theory for the perception of coherent visual motion.</article-title>             <source>Nature</source>             <volume>333</volume>             <fpage>71</fpage>             <lpage>74</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Stocker1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stocker</surname><given-names>AA</given-names></name>
<name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>
</person-group>             <year>2006</year>             <article-title>Noise characteristics and prior expectations in human visual speed perception.</article-title>             <source>Natu Neuro</source>             <volume>9(4)</volume>             <fpage>578</fpage>             <lpage>585</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Wexler1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wexler</surname><given-names>M</given-names></name>
</person-group>             <year>2003</year>             <article-title>Voluntary head movement and allocentric perception of space.</article-title>             <source>Psyc Sci</source>             <volume>14</volume>             <fpage>340</fpage>             <lpage>346</lpage>             <comment>t studies on the extra-retinal contribution to distance perception. Perception 28: 167–1</comment>          </element-citation></ref>
<ref id="pcbi.1000697-Wexler2"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wexler</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Lamouret</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Droulez</surname><given-names>J</given-names></name>
</person-group>             <year>2001a</year>             <article-title>The stationarity hypothesis: an allocentric criterion in visual perception.</article-title>             <source>Vis Res</source>             <volume>41</volume>             <fpage>3023</fpage>             <lpage>3037</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Ernst2"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ernst</surname><given-names>MO</given-names></name>
<name name-style="western"><surname>Bülthoff</surname><given-names>HH</given-names></name>
</person-group>             <year>2004</year>             <article-title>Merging the senses into a robust percept.</article-title>             <source>Tr Cogn Scie</source>             <volume>8(4)</volume>             <fpage>162</fpage>             <lpage>169</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Johnston1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Johnston</surname><given-names>EB</given-names></name>
<name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
<name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>
</person-group>             <year>1994</year>             <article-title>Integration of stereopsis and motion shape cues.</article-title>             <source>Vis Res</source>             <volume>34</volume>             <fpage>2259</fpage>             <lpage>2275</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Landy1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>
<name name-style="western"><surname>Maloney</surname><given-names>LT</given-names></name>
<name name-style="western"><surname>Johnston</surname><given-names>EB</given-names></name>
<name name-style="western"><surname>Young</surname><given-names>M</given-names></name>
</person-group>             <year>1995</year>             <article-title>Measurement and modeling of depth cue combination: In defense of weak fusion.</article-title>             <source>Vis Res</source>             <volume>35</volume>             <fpage>389</fpage>             <lpage>412</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Landy2"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>
<name name-style="western"><surname>Kojima</surname><given-names>H</given-names></name>
</person-group>             <year>2001</year>             <article-title>Ideal cue combination for localizing texture-defined edges.</article-title>             <source>JOSA A</source>             <volume>18</volume>             <fpage>2307</fpage>             <lpage>2320</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Battaglia1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Battaglia</surname><given-names>PW</given-names></name>
<name name-style="western"><surname>Jacobs</surname><given-names>RA</given-names></name>
<name name-style="western"><surname>Aslin</surname><given-names>RN</given-names></name>
</person-group>             <year>2003</year>             <article-title>Bayesian integration of visual and auditory signals for spatial localization.</article-title>             <source>JOSA</source>             <volume>20(7)</volume>             <fpage>1391</fpage>             <lpage>1397</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Gepshtein1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gepshtein</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name>
</person-group>             <year>2003</year>             <article-title>Viewing geometry determines how vision and haptics combine in size perception.</article-title>             <source>Curr Biol</source>             <volume>13(6)</volume>             <fpage>483</fpage>             <lpage>488</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Knill3"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Knill</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Saunders</surname><given-names>JA</given-names></name>
</person-group>             <year>2003</year>             <article-title>Do humans optimally integrate stereo and texture information for judgments of surface slant?</article-title>             <source>Vis Res</source>             <volume>43</volume>             <fpage>2539</fpage>             <lpage>2558</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Alais1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Alais</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Burr</surname><given-names>D</given-names></name>
</person-group>             <year>2004</year>             <article-title>The ventriloquist effect results from near optimal crossmodal integration.</article-title>             <source>Curr Biol</source>             <volume>14</volume>             <fpage>257</fpage>             <lpage>262</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Hillis1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hillis</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Watt</surname><given-names>SJ</given-names></name>
<name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>
<name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name>
</person-group>             <year>2004</year>             <article-title>Slant from texture and disparity cues: optimal cue combination.</article-title>             <source>J Vis</source>             <volume>4</volume>             <fpage>967</fpage>             <lpage>992</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Shams1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Shams</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Ma</surname><given-names>WJ</given-names></name>
<name name-style="western"><surname>Beierholm</surname><given-names>U</given-names></name>
</person-group>             <year>2005</year>             <article-title>Sound-induced flash illusion as an optimal percept.</article-title>             <source>Neuroreport</source>             <volume>16(17)</volume>             <fpage>1923</fpage>             <lpage>7</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Ernst3"><label>39</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ernst</surname><given-names>MO</given-names></name>
</person-group>             <year>2005</year>             <article-title>A Bayesian view on multimodal cue integration.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Knoblich</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Grosjean</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Thornton</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Shiffrar</surname><given-names>M</given-names></name>
</person-group>             <source>Perception of the human body from the inside out</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Oxford University Press</publisher-name>             <fpage>105</fpage>             <lpage>131</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Pearl1"><label>40</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pearl</surname><given-names>J</given-names></name>
</person-group>             <year>1988</year>             <source>Probabilistic reasoning in intelligent systems: Networks of plausible inference</source>             <publisher-loc>San Mateo, CA</publisher-loc>             <publisher-name>Morgan Kaufmann</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000697-Kersten1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kersten</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Mamassian</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Yuille</surname><given-names>A</given-names></name>
</person-group>             <year>2004</year>             <article-title>Object perception as Bayesian inference.</article-title>             <source>Ann Rev Psyc</source>             <volume>55</volume>             <fpage>271</fpage>             <lpage>304</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Mamassian1"><label>42</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mamassian</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Goutcher</surname><given-names>R</given-names></name>
</person-group>             <year>2001</year>             <article-title>Prior knowledge on the illumination position.</article-title>             <source>Cogn</source>             <volume>81</volume>             <fpage>B1</fpage>             <lpage>B9</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Mamassian2"><label>43</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mamassian</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>
</person-group>             <year>2001</year>             <article-title>Interaction of visual prior constraints.</article-title>             <source>Vis Res</source>             <volume>41</volume>             <fpage>2653</fpage>             <lpage>2668</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Adams1"><label>44</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Adams</surname><given-names>WJ</given-names></name>
<name name-style="western"><surname>Graf</surname><given-names>EW</given-names></name>
<name name-style="western"><surname>Ernst</surname><given-names>MO</given-names></name>
</person-group>             <year>2004</year>             <article-title>Experience can change the ‘light-from-above’ prior.</article-title>             <source>Natu Neuro</source>             <volume>7(10)</volume>             <fpage>1057</fpage>             <lpage>1058</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Adelson1"><label>45</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Adelson</surname><given-names>HE</given-names></name>
</person-group>             <year>2000</year>             <article-title>Lightness Perception and lightness illusions.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Gazzaniga</surname><given-names>M</given-names></name>
</person-group>             <source>The New Cognitive Neurosciences, 2nd Ed</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>339</fpage>             <lpage>351</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Maloney1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Maloney</surname><given-names>LT</given-names></name>
<name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>
</person-group>             <year>1989</year>             <article-title>A statistical framework for robust fusion of depth information. In: Pearlman WA, editor. Visual Communications and Image Processing IV.</article-title>             <source>Proc SPIE</source>             <volume>1199</volume>             <fpage>1154</fpage>             <lpage>1163</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Knill4"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Knill</surname><given-names>DC</given-names></name>
<name name-style="western"><surname>Kersten</surname><given-names>DJ</given-names></name>
</person-group>             <year>1991</year>             <article-title>Apparent surface curvature affects lightness perception.</article-title>             <source>Nature</source>             <volume>351</volume>             <fpage>228</fpage>             <lpage>230</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Landy3"><label>48</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>
<name name-style="western"><surname>Brenner</surname><given-names>E</given-names></name>
</person-group>             <year>2001</year>             <article-title>Motion-disparity interaction and the scaling of stereoscopic disparity.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Harris</surname><given-names>LR</given-names></name>
<name name-style="western"><surname>Jenkin</surname><given-names>MR</given-names></name>
</person-group>             <source>Vision and Attention</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Springer Verlag</publisher-name>             <fpage>129</fpage>             <lpage>151</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Sekuler1"><label>49</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sekuler</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Sekuler</surname><given-names>AB</given-names></name>
<name name-style="western"><surname>Lau</surname><given-names>R</given-names></name>
</person-group>             <year>1997</year>             <source>Nature</source>             <volume>385</volume>             <fpage>308</fpage>          </element-citation></ref>
<ref id="pcbi.1000697-Blake1"><label>50</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Blake</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Sobel</surname><given-names>KV</given-names></name>
<name name-style="western"><surname>James</surname><given-names>TW</given-names></name>
</person-group>             <year>2004</year>             <article-title>Neural synergy between kinetic vision and touch.</article-title>             <source>Psyc Sci</source>             <volume>15</volume>             <fpage>397</fpage>             <lpage>402</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-James1"><label>51</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>James</surname><given-names>TW</given-names></name>
<name name-style="western"><surname>Blake</surname><given-names>R</given-names></name>
</person-group>             <year>2004</year>             <article-title>Perceiving object motion using vision and touch.</article-title>             <source>Cogn, Affe, Behav Neuro</source>             <volume>4(2)</volume>             <fpage>201</fpage>             <lpage>207</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Wexler3"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wexler</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Panerai</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Lamouret</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Droulez</surname><given-names>J</given-names></name>
</person-group>             <year>2001b</year>             <article-title>Self-motion and the perception of stationary objects.</article-title>             <source>Nature</source>             <volume>409</volume>             <fpage>85</fpage>             <lpage>88</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Battaglia2"><label>53</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Battaglia</surname><given-names>PW</given-names></name>
<name name-style="western"><surname>Schrater</surname><given-names>PR</given-names></name>
<name name-style="western"><surname>Kersten</surname><given-names>DJ</given-names></name>
</person-group>             <year>2005</year>             <article-title>Auxiliary object knowledge influences visually-guided interception behavior.</article-title>             <source>Proc 2nd Symp App Perc Graph Visu, ACM Int Conf Proc Series</source>             <volume>95</volume>             <fpage>145</fpage>             <lpage>152</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-MacNeilage1"><label>54</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>MacNeilage</surname><given-names>PR</given-names></name>
<name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name>
<name name-style="western"><surname>Berger</surname><given-names>DR</given-names></name>
<name name-style="western"><surname>Bülthoff</surname><given-names>HH</given-names></name>
</person-group>             <year>2007</year>             <article-title>A Bayesian model of the disambiguation of gravitoinertial force by visual cues.</article-title>             <source>Exp Brain Res</source>             <volume>179(2)</volume>             <fpage>263</fpage>             <lpage>290</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Kersten2"><label>55</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kersten</surname><given-names>DJ</given-names></name>
<name name-style="western"><surname>Mamassian</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Knill</surname><given-names>DC</given-names></name>
</person-group>             <year>1997</year>             <article-title>Moving cast shadows induce apparent motion in depth.</article-title>             <source>Perception</source>             <volume>26(2)</volume>             <fpage>171</fpage>             <lpage>192</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Bloj1"><label>56</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bloj</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Kersten</surname><given-names>DJ</given-names></name>
<name name-style="western"><surname>Hurlbert</surname><given-names>AC</given-names></name>
</person-group>             <year>1999</year>             <article-title>3D shape perception influences colour perception via mutual illumination.</article-title>             <source>Nature</source>             <volume>402</volume>             <fpage>877</fpage>             <lpage>879</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Hillis2"><label>57</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hillis</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Ernst</surname><given-names>MO</given-names></name>
<name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name>
<name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>
</person-group>             <year>2002</year>             <article-title>Combining sensory information: Mandatory fusion within but not between senses.</article-title>             <source>Science</source>             <volume>22(11)</volume>             <fpage>1627</fpage>             <lpage>1630</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Bresciani1"><label>58</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bresciani</surname><given-names>JP</given-names></name>
<name name-style="western"><surname>Dammeier</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Ernst</surname><given-names>MO</given-names></name>
</person-group>             <year>2006</year>             <article-title>Vision and touch are automatically integrated for the perception of sequences of events.</article-title>             <source>J Vis</source>             <volume>6(5)</volume>             <fpage>554</fpage>             <lpage>564</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Roach1"><label>59</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Roach</surname><given-names>NW</given-names></name>
<name name-style="western"><surname>Heron</surname><given-names>J</given-names></name>
<name name-style="western"><surname>McGraw</surname><given-names>PV</given-names></name>
</person-group>             <year>2006</year>             <article-title>Resolving multisensory conflict: a strategy for balancing the costs and benefits of audio-visual integration.</article-title>             <source>Proc Biol Sci</source>             <volume>273(1598)</volume>             <fpage>2159</fpage>             <lpage>2168</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Ernst4"><label>60</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ernst</surname><given-names>MO</given-names></name>
</person-group>             <year>2007</year>             <article-title>Learning to integrate arbitrary signals from vision and touch.</article-title>             <source>J Vis </source>             <volume>7(5:7)</volume>             <fpage>1</fpage>             <lpage>14</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Krding1"><label>61</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Körding</surname><given-names>KP</given-names></name>
<name name-style="western"><surname>Beierholm</surname><given-names>U</given-names></name>
<name name-style="western"><surname>Ma</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Quartz</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Tenenbaum</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Shams</surname><given-names>L</given-names></name>
</person-group>             <year>2007</year>             <article-title>Causal inference in cue combination.</article-title>             <source>PLOSOne</source>             <volume>2(9)</volume>             <fpage>e943</fpage>          </element-citation></ref>
<ref id="pcbi.1000697-Sato1"><label>62</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sato</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Toyoizumi</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Aihara</surname><given-names>K</given-names></name>
</person-group>             <year>2007</year>             <article-title>Bayesian inference explains perception of unity and ventriloquism aftereffect: identification of common sources of audiovisual stimuli.</article-title>             <source>Neur Comp</source>             <volume>19(12)</volume>             <fpage>3335</fpage>             <lpage>3355</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Jacobs1"><label>63</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Jacobs</surname><given-names>RA</given-names></name>
</person-group>             <year>2002</year>             <article-title>What determines visual cue reliability?</article-title>             <source>Tr Cogn Sci</source>             <volume>6</volume>             <fpage>345</fpage>             <lpage>350</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Rushton1"><label>64</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rushton</surname><given-names>SK</given-names></name>
<name name-style="western"><surname>Wann</surname><given-names>JP</given-names></name>
</person-group>             <year>1999</year>             <article-title>Weighted combination of size and disparity: a computational model for timing a ball catch.</article-title>             <source>Nat Neuro</source>             <volume>2</volume>             <fpage>186</fpage>             <lpage>190</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Efron1"><label>65</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Efron</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Tibshirani</surname><given-names>RJ</given-names></name>
</person-group>             <year>1993</year>             <source>An Introduction to the Bootstrap</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Chapman &amp; Hall</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000697-Wichmann1"><label>66</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wichmann</surname><given-names>FA</given-names></name>
<name name-style="western"><surname>Hill</surname><given-names>NJ</given-names></name>
</person-group>             <year>2001a</year>             <article-title>The psychometric function: I. Fitting, sampling and goodness-of-fit.</article-title>             <source>Perc Psyc</source>             <volume>63(8)</volume>             <fpage>1293</fpage>             <lpage>1313</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Wichmann2"><label>67</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wichmann</surname><given-names>FA</given-names></name>
<name name-style="western"><surname>Hill</surname><given-names>NJ</given-names></name>
</person-group>             <year>2001b</year>             <article-title>The psychometric function: II. Bootstrap-based confidence intervals and sampling.</article-title>             <source>Perc Psyc</source>             <volume>63(8)</volume>             <fpage>1314</fpage>             <lpage>1329</lpage>          </element-citation></ref>
<ref id="pcbi.1000697-Verboven1"><label>68</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Verboven</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Hubert</surname><given-names>M</given-names></name>
</person-group>             <year>2005</year>             <article-title>LIBRA: a MATLAB Library for Robust Analysis.</article-title>             <source>Chem Inte Labo Syst</source>             <volume>75</volume>             <fpage>127</fpage>             <lpage>136</lpage>          </element-citation></ref>
</ref-list>

</back>
</article>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006580</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-00324</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Human performance</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Human performance</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Fourier analysis</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Genetics</subject><subj-group><subject>Genetic interference</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Beyond Bouma's window: How to explain global aspects of crowding?</article-title>
<alt-title alt-title-type="running-head">Beyond Bouma's window: How to explain global aspects of crowding?</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5120-9750</contrib-id>
<name name-style="western">
<surname>Doerig</surname>
<given-names>Adrien</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Bornet</surname>
<given-names>Alban</given-names>
</name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Rosenholtz</surname>
<given-names>Ruth</given-names>
</name>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Francis</surname>
<given-names>Gregory</given-names>
</name>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Clarke</surname>
<given-names>Aaron M.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Herzog</surname>
<given-names>Michael H.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Laboratory of Psychophysics, Brain Mind Institute, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Department of Brain and Cognitive Sciences, Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA, United States of America</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Department of Psychological Sciences, Purdue University, West Lafayette, IN, United States of America</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Laboratory of Computational Vision, Psychology Department, Bilkent University, Ankara, Turkey</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Einhäuser</surname>
<given-names>Wolfgang</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Technische Universitat Chemnitz, GERMANY</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">adrien.doerig@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>10</day>
<month>5</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<month>5</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>5</issue>
<elocation-id>e1006580</elocation-id>
<history>
<date date-type="received">
<day>29</day>
<month>3</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>4</day>
<month>10</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Doerig et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006580"/>
<abstract>
<p>In crowding, perception of an object deteriorates in the presence of nearby elements. Although crowding is a ubiquitous phenomenon, since elements are rarely seen in isolation, to date there exists no consensus on how to model it. Previous experiments showed that the global configuration of the entire stimulus must be taken into account. These findings rule out simple pooling or substitution models and favor models sensitive to global spatial aspects. In order to investigate how to incorporate global aspects into models, we tested a large number of models with a database of forty stimuli tailored for the global aspects of crowding. Our results show that incorporating grouping like components strongly improves model performance.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Visual crowding highlights interactions between elements in the visual field. For example, an object is more difficult to recognize if it is presented in clutter. Crowding is one of the most fundamental aspects of vision, playing crucial roles in object recognition, reading and visual perception in general, and is therefore an essential tool to understand how the visual system encodes information based on its retinal input. Hence, classic models of crowding have focused only on local interactions between neighboring visual elements. However, abundant experimental evidence argues against local processing, suggesting that the global configuration of visual elements strongly modulates crowding. Here, we tested all available models of crowding that are able to capture global processing across the entire visual field. We tested 12 models including the Texture Tiling Model, a Deep Convolutional Neural Network and the LAMINART neural network with large scale computer simulations. We found that models incorporating a grouping component are best suited to explain the data. Our results suggest that in order to understand vision in general, mid-level, contextual processing is inevitable.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001711</institution-id>
<institution>Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung</institution>
</institution-wrap>
</funding-source>
<award-id>176153</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5120-9750</contrib-id>
<name name-style="western">
<surname>Doerig</surname>
<given-names>Adrien</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100007601</institution-id>
<institution>Horizon 2020</institution>
</institution-wrap>
</funding-source>
<award-id>720270</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Bornet</surname>
<given-names>Alban</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>Adrien Doerig was supported by the Swiss National Science Foundation grant n.176153 “Basics of visual processing: from elements to figures”. Alban Bornet was supported by the European Union's Horizon 2020 Framework Programme for Research and Innovation under the Specific Grant Agreements No. 720270 (Human Brain Project SGA1) and No. 785907 (Human Brain Project SGA2). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="15"/>
<table-count count="0"/>
<page-count count="28"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-05-22</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All behavioral data comes from previously published work and may be found in the papers mentioned in the text. The full model results are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/adriendoerig/beyond-boumas-window-results" xlink:type="simple">https://github.com/adriendoerig/beyond-boumas-window-results</ext-link>. All the code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/adriendoerig/beyond-boumas-window-code" xlink:type="simple">https://github.com/adriendoerig/beyond-boumas-window-code</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>When an element is presented in the presence of nearby elements or clutter, it becomes harder to perceive, a well-known effect called crowding. One of the main characteristics of crowding is that the element itself is not invisible, contrary to contrast- and backward-masking; rather its features appear jumbled and distorted (<xref ref-type="fig" rid="pcbi.1006580.g001">Fig 1</xref>). Crowding is a ubiquitous phenomenon because elements are rarely encountered in isolation in everyday situations (<xref ref-type="fig" rid="pcbi.1006580.g001">Fig 1C</xref>). Thus, understanding crowding is crucial for understanding vision in general.</p>
<fig id="pcbi.1006580.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Crowding.</title>
<p><bold>a.</bold> In crowding, the perception of a target element deteriorates in the presence of nearby elements. When fixating the left cross, the target letter V on the right is hard to identify because of the nearby flankers. <bold>b.</bold> The task is easier than in (a), because the flankers are further away from the target letter V. Bouma’s law states that crowding occurs only when flankers are sufficiently close to the target, within the so-called Bouma’s window. <bold>c.</bold> Crowding is a ubiquitous phenomenon since elements are rarely seen in isolation. For example, when fixating the central red dot, the child on the left is easier to detect because it is not surrounded by nearby flankers, as is the child on the right.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g001" xlink:type="simple"/>
</fig>
<p>For about half a century, the consensus was that flankers interfere with a target element only when placed within a spatially restricted window around the target, the so-called Bouma law (<xref ref-type="fig" rid="pcbi.1006580.g001">Fig 1B</xref>; [<xref ref-type="bibr" rid="pcbi.1006580.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1006580.ref004">4</xref>]):
<disp-formula id="pcbi.1006580.e001">
<alternatives>
<graphic id="pcbi.1006580.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006580.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">z</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">B</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mo>’</mml:mo><mml:mi mathvariant="normal">s</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mo>≈</mml:mo><mml:mn>0.5</mml:mn><mml:mi mathvariant="normal">*</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Classic models of crowding proposed that early visual areas, such as V1, process the features of stimuli with high precision. Crowding occurs when neural signals are pooled along the visual hierarchy, e.g., when V2 neurons pool neural signals from V1 neurons [<xref ref-type="bibr" rid="pcbi.1006580.ref005">5</xref>]. Hence, in line with classic hierarchical feedforward processing (<xref ref-type="fig" rid="pcbi.1006580.g002">Fig 2A</xref>), crowding may be seen as a natural consequence of object recognition in the visual system. For example, a hypothetical neuron coding for a square might respond to signals from neurons coding for the lines making up the square. In order to achieve translational invariance, the square neuron is sensitive to lines all over its receptive field and pools this information in order to decide whether a square is present. According to this logic, crowding occurs when elements that do not belong to the same object are pooled. In this sense, crowding is an unwanted by-product of object recognition and, for this reason, a bottleneck of vision (for reviews, see [<xref ref-type="bibr" rid="pcbi.1006580.ref002">2</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref006">6</xref>]). Other models have proposed that performance in crowding deteriorates because features of the target are substituted for features of the flanking elements [<xref ref-type="bibr" rid="pcbi.1006580.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref007">7</xref>]. As mentioned, all these models are local in the sense that crowding is determined by nearby elements only. Based on these two lines of thought, pooling and substitution, researchers have suggested that with more flankers performance deteriorates because more irrelevant features are pooled or substituted.</p>
<fig id="pcbi.1006580.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g002</object-id>
<label>Fig 2</label>
<caption>
<title/>
<p><bold>a. Standard view of visual processing.</bold> First, edges are detected by low-level neurons with small receptive fields. Higher level neurons pool signals from lower level neurons in a hierarchical, feedforward manner, creating higher level representations of objects by combining low-level features [<xref ref-type="bibr" rid="pcbi.1006580.ref025">25</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref026">26</xref>]. For example, two low-level edge detectors may be combined to create a “corner” representation. Four such corner detectors can be assembled to create a rectangle representation. Receptive field size naturally increases along this pathway since, for example, a rectangle covers larger parts of the visual field than the lines making up the rectangle. <bold>b. Uncrowding.</bold> Observers performed a vernier discrimination task. The y-axis shows the threshold for which observers correctly discriminate the vernier offset in 75% of trials (so performance is good when the threshold is low). First, only a vernier is presented, an easy task (performance for this condition is shown as the dashed horizontal line). Then, a flanking square is added making the task much more difficult (leftmost stimulus). This is a classic crowding effect. Importantly, adding more flanking squares improved performance gradually, i.e., performance improved the more squares are presented [<xref ref-type="bibr" rid="pcbi.1006580.ref019">19</xref>]. We call this effect uncrowding. <bold>c. The global configuration</bold> of the entire stimulus determines crowding. Performance is strongly affected by elements far away from the target as shown in these examples [<xref ref-type="bibr" rid="pcbi.1006580.ref015">15</xref>]. <bold>d. Performance is not determined by local interactions only</bold>. In this display, fine-grained vernier acuity of about 200” depends on elements as far away as 8.5 degrees—a difference of two orders of magnitude, extending far beyond Bouma’s window.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g002" xlink:type="simple"/>
</fig>
<p>The understanding of crowding has largely changed in the last decade. For example, it has been shown that detailed information can survive crowding [<xref ref-type="bibr" rid="pcbi.1006580.ref008">8</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref009">9</xref>]. Crowding occurs in the fovea and is not restricted to the periphery, contrary to earlier proposals [<xref ref-type="bibr" rid="pcbi.1006580.ref010">10</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref011">11</xref>]. Most importantly for the present discussion, performance depends on elements far beyond Bouma’s window. For example, in supercrowding, elements outside of Bouma’s window decrease performance beyond the decrement arising from elements within the window [<xref ref-type="bibr" rid="pcbi.1006580.ref012">12</xref>]. Surprisingly, adding flankers can even reduce crowding, and such uncrowding effects can depend on elements outside of Bouma’s window (<xref ref-type="fig" rid="pcbi.1006580.g002">Fig 2</xref>; [<xref ref-type="bibr" rid="pcbi.1006580.ref010">10</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1006580.ref017">17</xref>], review: [<xref ref-type="bibr" rid="pcbi.1006580.ref018">18</xref>]). For example, observers performed a vernier discrimination task. When a surrounding square was added to the vernier, the task became much more difficult: a classic crowding effect. However, adding more flanking squares improved performance gradually, i.e., performance improved the more squares were presented ([<xref ref-type="bibr" rid="pcbi.1006580.ref019">19</xref>]; <xref ref-type="fig" rid="pcbi.1006580.g002">Fig 2B</xref>). The entire line of squares extends over 17 degrees in the right visual field, while the single vernier offset threshold is less than 200” (<xref ref-type="fig" rid="pcbi.1006580.g002">Fig 2D</xref>). Hence, performance is not exclusively determined by local interactions: fine-grained vernier acuity in the range of about 200” depends on elements as far away as 8.5 degrees—a ratio of two orders of magnitude, extending far beyond Bouma’s window. Moreover, performance depends on the overall configuration [<xref ref-type="bibr" rid="pcbi.1006580.ref020">20</xref>]. For example, in three-by-seven displays of squares and stars (<xref ref-type="fig" rid="pcbi.1006580.g002">Fig 2C</xref>), a shift of the central row changes performance strongly (<xref ref-type="fig" rid="pcbi.1006580.g002">Fig 2C</xref>, 4<sup>th</sup> and 5<sup>th</sup> configurations). Similar effects were found with stimuli other than verniers [<xref ref-type="bibr" rid="pcbi.1006580.ref021">21</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref022">22</xref>], as well as in auditory [<xref ref-type="bibr" rid="pcbi.1006580.ref023">23</xref>] and haptic crowding [<xref ref-type="bibr" rid="pcbi.1006580.ref024">24</xref>].</p>
<p>Because they cannot produce long-range effects, local models cannot explain the global aspects of crowding. Here, we tested which global models, integrating information across large parts of the visual field, can explain global effects on crowding (see <xref ref-type="fig" rid="pcbi.1006580.g003">Fig 3</xref> for a list). We also tested the most prominent local models to verify our hypothesis that local models are inadequate to explain global aspects of crowding.</p>
<fig id="pcbi.1006580.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Tested models and their characteristics.</title>
<p>Models may integrate information locally or globally, and the interference mechanism may be pooling, substitution, or other. Models are feed-forward or recurrent, and may or may not compute grouping-like aspects of the stimulus. The aim of the current work is to investigate which models can explain the global effects of crowding.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g003" xlink:type="simple"/>
</fig>
<p>The models that we tested differ with respect to four criteria:</p>
<p>Spatial extent: Local vs. Global. In a local model, elements far from the target do not exert any effects on the target. By contrast, in a global model, any element in the visual field may potentially interfere with target processing.</p>
<sec id="sec002">
<title>Mechanism of interference: Pooling, substitution, or other?</title>
<p>Organisation: Feed-forward (features at a given level are only affected by lower level features) vs. recurrent processing (features at a given level can be affected by lower or higher level features).</p>
<p>Grouping component: Does the model incorporate a grouping component? Certain models explicitly compute grouping-like aspects by determining which low-level elements should belong to the same higher level group. Only elements within a group interfere with each other.</p>
</sec>
</sec>
<sec id="sec003" sec-type="materials|methods">
<title>Methods</title>
<p>To test the models, we used human data from previous work exploring the crowding/uncrowding phenomena [<xref ref-type="bibr" rid="pcbi.1006580.ref010">10</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref011">11</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref015">15</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref017">17</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref019">19</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref020">20</xref>]. The stimulus database comprises 40 different stimuli belonging to 11 different categories: circles, Gestalts, hexagons, irregular1, irregular2, lines, octagons, patternIrregular, patternStars, squares and stars. An example of each category is shown in <xref ref-type="fig" rid="pcbi.1006580.g004">Fig 4</xref>. Behavioral results can be found in the original papers (listed in <xref ref-type="fig" rid="pcbi.1006580.g014">Fig 14</xref>). In each category, we have the vernier target alone, plus crowding and uncrowding configurations. All the stimuli are shown in <xref ref-type="fig" rid="pcbi.1006580.g014">Fig 14</xref> and behavioural results can be found in the original papers. With a few exceptions (see details in the results section), we ran each model on all stimuli. For some models, we could not use the entire database because computation time was too long (deep convolutional networks, LAMINART, Texture Tiling Model), or because the model was not adapted to accommodate certain kinds of stimuli (Population Coding). Human and model results are summarized in the discussion (Figs <xref ref-type="fig" rid="pcbi.1006580.g014">14</xref> &amp; <xref ref-type="fig" rid="pcbi.1006580.g015">15</xref>). All the code we used is available online at <ext-link ext-link-type="uri" xlink:href="https://github.com/adriendoerig/beyond-boumas-window-code" xlink:type="simple">https://github.com/adriendoerig/beyond-boumas-window-code</ext-link>. All the results can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/adriendoerig/beyond-boumas-window-results" xlink:type="simple">https://github.com/adriendoerig/beyond-boumas-window-results</ext-link>.</p>
<fig id="pcbi.1006580.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Stimulus categories.</title>
<p>We used 40 different stimuli from 11 different categories. The task was always to report the offset direction of the central vernier. This figure shows one example from each category. The stimulus database is tailored to test for global effects such as uncrowding. Human data was taken from previous work [<xref ref-type="bibr" rid="pcbi.1006580.ref010">10</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref011">11</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref015">15</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref017">17</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref019">19</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref020">20</xref>]. Human and model results are summarized in the discussion (<xref ref-type="fig" rid="pcbi.1006580.g014">Fig 14</xref> shows the results for all stimuli and models).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g004" xlink:type="simple"/>
</fig>
<p>There are two fundamentally different approaches to measure model performance. First, a linking hypothesis may be used to relate model output to performance (both are scalar numbers). For example, template matching computes how similar the model output is to the target image. If they are similar, performance is good. The second, textural approach is used to quantify performance in textural models. The idea is that peripheral vision is ambiguous because information is compressed by summary statistics. If a model uses a proper algorithm for representing these ambiguities, presenting the processed image in the fovea should lead to similar human performance as presenting the original unprocessed image in the periphery [<xref ref-type="bibr" rid="pcbi.1006580.ref027">27</xref>]. Accordingly, to measure the performance of textural algorithms, the stimuli are fed through a texture synthesis procedure. Then, observers freely examine the output image and report vernier orientation. If this task is easy, performance is good. For each model, we used the linking hypothesis proposed by the original authors when available. When this was not possible (for example for Alexnet, which has never been applied to crowding results before), we detail which linking hypothesis we used in the corresponding section. In the following, we present, first, textural models and, second, models using a linking hypothesis.</p>
<p>An important point is that different readouts lead to different results. Hence, the different methods of model evaluation used here could affect our results. However, we are mainly interested in qualitative rather than quantitative comparisons and the readout functions we used cannot confuse crowding and uncrowding. More specifically, the readout processes we use produce results monotonically linked to the model outputs. Hence, they cannot confuse uncrowding cases (a U-shape function where the vernier alone condition leads to good performance, a single flanker deteriorates performance, and multiple flankers lead again to good performance) with cases that do not show uncrowding (a monotonic function where the vernier alone condition leads to good performance, a single flanker deteriorates performance, and multiple flankers deteriorate performance even more).</p>
<p>Because different models were evaluated differently, it was impossible to come up with one performance measure and to compare models via something like the Akaike Information Criterion. However, despite this variety of performance measures, our results are qualitatively unambiguous: each model either is capable of producing uncrowding, or it is not. We took the parameters directly from the original models whenever possible. Otherwise, we tried our best to search the parameter space (see <xref ref-type="sec" rid="sec004">results</xref>). We cannot exclude that other combinations of parameters fit the dataset better. However, we will argue that the models that cannot produce uncrowding fail to do so for principled reasons, and not because of poor parameter choices (see <xref ref-type="sec" rid="sec020">discussion</xref>).</p>
</sec>
<sec id="sec004" sec-type="results">
<title>Results</title>
<sec id="sec005">
<title>Texture-like models</title>
<p>The following models are based on texture analysis. The outputs are images, and the texture method is applied as described in the methods.</p>
<sec id="sec006">
<title>Epitomes</title>
<p>In the Epitomes model, described by Jojic et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref028">28</xref>], large repeating patterns are summarized by small repeated representative image patches. Repeated patterns are substituted with their exemplars. The original image can subsequently be retrieved with good accuracy from the compressed representation, even though neighboring features encoded in the same patch are mingled. Epitomes are effectively a “substitution” model that exploits regularities. Although this model was not proposed as a model of crowding, it embodies many of the key characteristics of local pooling and substitution models.</p>
<p>Using the author’s code available online (<ext-link ext-link-type="uri" xlink:href="http://www.vincentcheung.ca/research/sourcecode.html" xlink:type="simple">http://www.vincentcheung.ca/research/sourcecode.html</ext-link>) we ran the model on all stimuli with the original parameters (designed to optimize image reconstruction accuracy for natural images and texture overlays). To evaluate performance, we used the texture evaluation method with the authors as subjects, analysing the results qualitatively (see <xref ref-type="sec" rid="sec003">methods</xref>). In addition, we computed the model threshold as
<disp-formula id="pcbi.1006580.e002">
<alternatives>
<graphic id="pcbi.1006580.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006580.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mrow><mml:mstyle displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>−</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="italic">rightStim</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mi>d</mml:mi><mml:mi>y</mml:mi></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where leftStim(x,y) is the normalized intensity of pixel (x,y) in the left vernier offset version of the output. Effectively, this equation quantifies how different the normalized output images are for the left and the right vernier offset versions of the stimulus. If they are very different, the task is easy. Consistently across the dataset, the model successfully produces crowding but not uncrowding: performance was always worse when adding more flankers (<xref ref-type="fig" rid="pcbi.1006580.g005">Fig 5</xref>). We suggest that the model cannot explain uncrowding because it compresses information from local regions of the image, ignoring global structure.</p>
<fig id="pcbi.1006580.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Epitomes.</title>
<p><bold>a.</bold> Illustration of the epitome model. An image (left) is compressed into an epitome (center), a summary of local features. The image on the right is reconstructed from the epitome. <bold>b.</bold> As an example for the classic texture evaluation, we show the stimulus and reconstructed image for the 1- and 7-square conditions. Human vernier offset thresholds are better for the 1-square than the 7-square condition. The model does not produce uncrowding because vernier offset direction in the output is not easier to make out in the 7-square than in the 1-square case (according to the authors’ judgment). <bold>c.</bold> Example for our performance measure. Human and model thresholds (see main text for how model threshold was computed) for vernier alone, single square and 7 squares conditions. The 7-square threshold is higher than the 1- square threshold, in contrast with human performance. Note: the model outputs a number quantifying how different the left and right vernier offset versions of the input are (so the higher this difference, the better the performance). To make comparison with the human threshold easier, we applied the following monotonic transformation to the output: “threshold-like output” = 1/“raw output”. Then, we scaled the result to be in the same range as the human results. This monotonic re-scaling cannot change the conclusions because monotonic outputs are mapped on monotonic performance and the same is true for U-shaped functions (see <xref ref-type="sec" rid="sec003">methods</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec007">
<title>Single texture model</title>
<p>Portilla &amp; Simoncelli [<xref ref-type="bibr" rid="pcbi.1006580.ref029">29</xref>] proposed a set of statistics capable of capturing key aspects of texture appearance to human vision (<xref ref-type="fig" rid="pcbi.1006580.g006">Fig 6A</xref>). Balas et al., [<xref ref-type="bibr" rid="pcbi.1006580.ref027">27</xref>] suggested an explanation of crowding in which peripheral vision might measure these texture statistics in pooling regions that overlap and tile the visual field. The intuition is that summary statistics provide an efficient way of extracting relevant information at low computational cost from natural images. Though Balas et al. proposed a model covering the entire visual field as described in the next subsection, they initially tested the predictions of a single pooling region, since texture synthesis procedures did not exist for multiple overlapping pooling regions. Each of their stimuli fell within a single Bouma-sized patch. They have since suggested that this shortcut of using a single pooling region, which greatly reduces computation time, can often suffice for texture-like stimuli that fall within a single pooling region [<xref ref-type="bibr" rid="pcbi.1006580.ref030">30</xref>].</p>
<fig id="pcbi.1006580.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Texture Synthesis and Texture Tiling Model.</title>
<p><bold>a.</bold> A texture (right) synthesized from the input on the left using the Portilla &amp; Simoncelli [<xref ref-type="bibr" rid="pcbi.1006580.ref029">29</xref>] summary statistics. The output resembles crowding. Pooling- and substitution-like effects occur. <bold>b.</bold> In the TTM, instead of applying the summary statistics process to the whole image at once, only local patches of the image are processed, yielding a local summary statistics model. The local patches are thought to reflect V2 receptive fields. <bold>c.</bold> Whole-field summary statistics. From left to right: stimuli and Portilla &amp; Simoncelli textures for the vernier, 1-square and 7-square conditions. The vernier offset is easy to determine from the texture in the vernier alone condition, and slightly harder in the crowded condition (a right-offset is discernable in the middle top of the display). Across all data, the model consistently produces crowding, but no uncrowding, as exemplified in the right condition in which no offset is present at all. <bold>d.</bold> Texture Tiling model. The left column shows three synthesized examples from the 1-square condition. On the right is the 7-flanking squares case. The model cannot produce uncrowding: since the stimulus on the right is less crowded than the stimulus on the left in the human data, the direction of the vernier should be easier to make out on the right than on the left. However, this is not the case.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g006" xlink:type="simple"/>
</fig>
<p>Although the model was intended by Balas et al. to be applied only over a Bouma’s window-sized patch, here we applied it to the entire stimulus to see if this kind of texture synthesis could capture long-range interactions between the vernier and other elements. The texture statistics are computed from pixel intensities taken from the entire image. Using the code provided online by Portilla &amp; Simoncelli (<ext-link ext-link-type="uri" xlink:href="https://github.com/LabForComputationalVision/textureSynth" xlink:type="simple">https://github.com/LabForComputationalVision/textureSynth</ext-link>), we created textures from all of our stimuli and the authors analyzed the results qualitatively using the texture measure (see <xref ref-type="fig" rid="pcbi.1006580.g006">Fig 6C</xref> for two examples). The model produces strong crowding: vernier offsets are harder to discriminate from the textures when flankers are present. However, the model cannot explain uncrowding: consistently across our whole dataset, uncrowded conditions are worse than crowded conditions for this model (<xref ref-type="fig" rid="pcbi.1006580.g006">Fig 6C</xref>). More elements always deteriorate performance. In their original contribution, Balas et al. seeded the texture synthesis algorithm using a low-pass, noisy version of the stimulus to reduce position noise. We also ran our stimuli using this method (see <xref ref-type="sec" rid="sec004">results</xref> repository online). While the output images became less distorted than without using the seed, it did not change the conclusion, because the target vernier remained much harder to detect in the textures synthesized from the uncrowded 7 flankers stimuli than from the crowded single flanker stimuli–i.e., there was no uncrowding.</p>
</sec>
<sec id="sec008">
<title>Texture tiling model (TTM)</title>
<p>The TTM model was first described by Balas et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref027">27</xref>], with its first full instantiation developed by Freeman &amp; Simoncelli [<xref ref-type="bibr" rid="pcbi.1006580.ref031">31</xref>]. It computes summary statistics for overlapping local patches of the visual field, mimicking the way V2 receptive fields grow in size with eccentricity (<xref ref-type="fig" rid="pcbi.1006580.g006">Fig 6B</xref>). Balas, Rosenholtz and others have studied this model extensively, calling it the Texture Tiling Model (TTM; [<xref ref-type="bibr" rid="pcbi.1006580.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref033">33</xref>]). In a series of papers, this model explained well the local aspects of visual tasks such as crowding and visual search. We ran a selection of stimuli through the TTM model (circles, squares, and irregular1; code for the model accompanies [<xref ref-type="bibr" rid="pcbi.1006580.ref034">34</xref>]). Similarly to the previous textures, the results were analysed by the authors using the texture measure. Crowding was well captured, but uncrowding could not be explained by TTM (<xref ref-type="fig" rid="pcbi.1006580.g006">Fig 6D</xref>). The vernier was not better represented as the number of flankers increased.</p>
<p>We suggest that TTM alone cannot explain uncrowding because it is a sophisticated local mechanism that scrambles together neighboring elements. There is no mechanism allowing elements that do not share a pooling region with the target to directly affect the target representation. Our results suggest that neither pooling summary statistics over the entire stimulus nor pooling over previously tested local regions explain the behavioural results. If the whole field is used, uncrowding cannot occur because more elements mean more interference and thus worse performance. On the other hand, using local regions does not help because far away elements cannot improve performance in cases where humans show uncrowding.</p>
</sec>
<sec id="sec009">
<title>Deep textures</title>
<p>Gatys and colleagues [<xref ref-type="bibr" rid="pcbi.1006580.ref035">35</xref>] used deep neural networks to create textures. The algorithm starts with a noise image and iteratively modifies it to match the correlations between neuron activities in a set of layers (<xref ref-type="fig" rid="pcbi.1006580.g007">Fig 7A</xref>). This procedure synthesizes textures that are often indistinguishable from the original image, creating true metamers [<xref ref-type="bibr" rid="pcbi.1006580.ref036">36</xref>]. Deep textures were not intended to be applied to images like our stimuli, nevertheless we were interested in seeing if they could handle them because one could think of deep textures as synthesizing textures based on learned features rather than on the hand-coded features of Portilla &amp; Simoncelli [<xref ref-type="bibr" rid="pcbi.1006580.ref029">29</xref>]. Perhaps the learned features provide a better representation and thus do a better job of predicting crowding.</p>
<fig id="pcbi.1006580.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Deep textures.</title>
<p><bold>a.</bold> In the deep textures algorithm, the correlation between a deep neural network’s unit activities is used as a summary statistic. Textures are then synthesized to match that statistic. <bold>b.</bold> Original stimuli and textures synthesized from these stimuli using the deep textures algorithm by Gatys et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref035">35</xref>]. The vernier offset is poorly visible, therefore, despite its clear success at synthesizing textures, the model in its present form in not suitable to model crowding with our stimuli. We tried different zooms on our stimuli but the results did not change.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g007" xlink:type="simple"/>
</fig>
<p>Using Gatys et al.’s code with their suggested set of parameters (<ext-link ext-link-type="uri" xlink:href="https://github.com/leongatys/DeepTextures" xlink:type="simple">https://github.com/leongatys/DeepTextures</ext-link>), we created textures of each stimulus in our database (<xref ref-type="fig" rid="pcbi.1006580.g007">Fig 7B</xref> shows a selection of examples). We first evaluated model performance by the texture measure performed by the authors. Since the results were much less clear than for the previous texture approaches, we also conducted a psychophysical experiment with naive participants. Five subjects performed the classic texture measure: they were first explained the texture synthesizing process and then were shown textures synthesized from our stimuli. They were asked to report if they thought the texture was synthesized from a left- or right-vernier stimulus. We used three categories of stimuli (Gestalts, squares and circles), with ten textures per stimulus (a total of 100 textures). Performance was at chance for all stimuli. Textures for the untested stimulus categories strongly resemble the tested categories (the vernier offset orientation is not visible in the textures, even for the vernier-alone condition). We tried different stimulus sizes, but this did not improve the results. In conclusion, despite its clear success at texture synthesis for natural images, the model in its present form is not suitable to study crowding with our stimuli.</p>
<p>Wallis et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref037">37</xref>] have proposed a foveated model in which these deep statistics are computed over local image patches, just as the TTM computes Portilla and Simoncelli’s statistics over local patches. The code is not yet publicly available, so we did not test it explicitly, however, we believe it will not explain uncrowding for exactly the same reasons that the TTM does not handle uncrowding better than Portilla and Simoncelli’s whole field statistics: distant elements that are not in pooling regions around the target cannot affect the target representation.</p>
</sec>
</sec>
<sec id="sec010">
<title>Models using a linking hypothesis</title>
<p>The following models all use a linking hypothesis to relate their output (a number) to human performance. Whenever possible, we used the same linking hypothesis as in the original contribution. When no linking hypothesis was available, we specify the method used.</p>
<sec id="sec011">
<title>Wilson &amp; Cowan network with end-stopped receptive fields</title>
<p>Wilson &amp; Cowan [<xref ref-type="bibr" rid="pcbi.1006580.ref038">38</xref>] proposed a mathematical model of simple cortical (excitatory and inhibitory) neurons interacting through recurrent lateral connexions. Variations of this kind of model have successfully accounted for visual masking data using stimuli similar to our lines category [<xref ref-type="bibr" rid="pcbi.1006580.ref039">39</xref>]. We used a similar neural network for our crowding stimuli. The model first convolves the input image with an on-center, off-surround receptive field mimicking processing by the LGN. Next, the input activations are fed into both an excitatory and an inhibitory layer of neurons, which are reciprocally connected such that the excitatory units excite the inhibitory units and the inhibitory units inhibit the excitatory units. Details of the model, its filters, and its parameters can be found in [<xref ref-type="bibr" rid="pcbi.1006580.ref039">39</xref>] and [<xref ref-type="bibr" rid="pcbi.1006580.ref040">40</xref>]. Although the filters are local, the strength of activity at any given pixel location partly depends on the global pattern of activity across the network because of the feedback connections. More generally, the feedback in the network functions like a discontinuity detector by enhancing discontinuities and suppressing regularities. Clarke, Herzog &amp; Francis [<xref ref-type="bibr" rid="pcbi.1006580.ref041">41</xref>] applied this model to crowding stimuli, but it performed poorly and produced no uncrowding. For example, there was no difference between the stimuli in the Gestalts category and the length of the bars in the lines category had no effect at all on performance. Here, to improve the model, we replaced the classic receptive fields by end-stopped receptive fields so that each neuron is optimally activated only by stimuli of a specific length. There were three different sizes for the end-stopped receptive-fields, corresponding to the size of a vernier bar, the size of the whole vernier, and the size of the flankers. To measure performance for each stimulus, for each end-stopped receptive field size, we took as output the state of the excitatory layer after stabilization (40 time-steps) and cross-correlated it with the vernier alone output. The cross-correlations for each end-stopped receptive field size were summed to yield a single output number per stimulus. We then fitted a psychometric function on one class of stimuli (training set) and used this function to provide model performance for all other classes of stimuli (testing set). Apart from the end-stopped receptive fields modification, we used the same parameters as in Hermens et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref039">39</xref>].</p>
<p>We fit the psychometric function based on the model’s output for the squares category, i.e., the squares category is the training set, and used this fit to measure performance on all other stimulus categories, i.e., all other categories are the testing set. We also tried to use each of the other categories as the training set; using the squares yielded the best results. The model produces crowding: performance drops in the presence of flankers. It also produces uncrowding but only for the training set (squares) and, to a lesser extent, for the irregular1 category. Indeed, performance is better in the 7 squares than in the single square condition (<xref ref-type="fig" rid="pcbi.1006580.g008">Fig 8B</xref>), and marginally better in the 7 irregular1 than in the single irregular1 condition (<xref ref-type="fig" rid="pcbi.1006580.g008">Fig 8C</xref>). For the other categories, there is no uncrowding (see <xref ref-type="fig" rid="pcbi.1006580.g008">Fig 8D</xref> for an example). The choice of the training and testing sets has a strong influence on the conditions that mimic human performance. Squares and lines are the categories for which size regularity seems to play the most important role. For all other classes, there is no uncrowding, regardless of the training. This poor generalization capability suggests that the model uses idiosyncratic features of its training set rather than capturing general regularities, similar to overfitting.</p>
<fig id="pcbi.1006580.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g008</object-id>
<label>Fig 8</label>
<caption>
<title/>
<p><bold>Wilson and Cowan network with end-stopped receptive fields: a.</bold> Structure of the network in [<xref ref-type="bibr" rid="pcbi.1006580.ref039">39</xref>] which we augmented with end-stopped receptive fields. An excitatory and an inhibitory layer of neurons are activated by the stimulus and interact with one another. The output of the excitatory layer is cross-correlated with a vernier template to measure performance. <bold>b.</bold> Output for the squares category (with psychometric function fitted on the squares category). In accordance with human results, performance is better in the 7 squares than in the 1 square case. <bold>c.</bold> Output for the irregular category (with psychometric function fitted on the squares category). Performance is marginally better in the 7 irregular1 than in the 1 irregular1 case. <bold>d.</bold> Output for the stars category (with psychometric function fitted on the squares category). There is no uncrowding for this stimulus. Uncrowding occurs only for specific kinds of stimuli, where element size regularities seem important. Further, performance depends strongly on which data are used for the training set (i.e., for fitting the psychometric function), suggestive of overfitting. <bold>e.</bold> Model output images. Columns are different stimuli: vernier, 1 square and 7 squares. The first row shows the stimuli, and the three subsequent rows show the model output for the short, medium and long end-stopped receptive fields. The crucial result is that the vernier is better represented in the short and medium populations in the 7 squares than in the 1 square conditions (i.e., uncrowding occurs). As mentioned, uncrowding occurred for very few stimuli categories. In cases that didn’t show uncrowding, the vernier representation deteriorated further when flankers were added (see <xref ref-type="sec" rid="sec004">results</xref> on the online repository). Note: the model outputs a cross-correlation quantifying how similar the model output is to the model output in the vernier alone condition (so the higher this cross-correlation, the better the performance). To make comparisons with human thresholds easier, we applied the same linking hypothesis as Hermens et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref039">39</xref>]: we fitted a psychometric function to link model outputs to behavioural results, as explained in the main text.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g008" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec012">
<title>Zhaoping’s V1 recurrent model</title>
<p>This recurrent neural network model is described by Li Zhaoping [<xref ref-type="bibr" rid="pcbi.1006580.ref042">42</xref>]. The network consists of a grid of neurons tuned to 12 orientations that are linked by lateral connections that follow a specific pattern (see <xref ref-type="fig" rid="pcbi.1006580.g009">Fig 9A &amp; 9B</xref>). The connectivity pattern allows the network to reproduce many experimental effects such as pop-out, figure-ground segmentation and border effects. It has also been shown to highlight certain parts of visual displays such as masked verniers [<xref ref-type="bibr" rid="pcbi.1006580.ref043">43</xref>], and we wondered if it could similarly produce uncrowding. We recoded the network from scratch following the detailed instructions and using the same parameters as in [<xref ref-type="bibr" rid="pcbi.1006580.ref042">42</xref>] and studied it as another recurrent model of early visual cortex. We ran all our stimuli and assessed performance by cross-correlating each output with the output of the vernier without flankers. The magnitude of the cross-correlation is taken as a measure of vernier offset discrimination performance. The model produces crowding but not uncrowding consistently across the dataset (see <xref ref-type="fig" rid="pcbi.1006580.g009">Fig 9C</xref>).</p>
<fig id="pcbi.1006580.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g009</object-id>
<label>Fig 9</label>
<caption>
<title>V1 Segmentation model.</title>
<p><bold>a.</bold> The input is sampled at each grid position by neurons tuned to 12 orientations, mimicking V1 simple cells. <bold>b.</bold> The connectivity pattern between cells depends on their relative position and orientation as shown here. Solid lines indicate excitation and dashed lines indicate inhibition. As shown, each neuron excites aligned neurons and inhibits non-aligned neurons. Each neuron has the same connectivity pattern, suitably rotated and translated. <bold>c.</bold> Output images for the square category. Each small oriented bar shows the maximally active orientation at this grid position. <bold>d.</bold> Results for the squares category. The dashed red bar shows the vernier threshold, which is matched for humans and the model. As shown, uncrowding does not occur in the model, because performance is worse for the 7 squares than the 1 square stimulus. Note: the model outputs a cross-correlation quantifying how similar the model output is to the model output in the vernier alone condition (so the higher this cross-correlation, the better the performance). To make comparison with the human threshold easier, we applied the same procedure as we did for the epitomes, i.e., we applied the following monotonic transformation to the output: “threshold-like output” = 1/”raw output”. Then we scaled the result to be in the same range as the human results. This monotonic re-scaling does not change the conclusions–the phenomenon of uncrowding cannot be altered.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g009" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec013">
<title>A variation of the LAMINART model</title>
<p>The LAMINART model by Cao &amp; Grossberg [<xref ref-type="bibr" rid="pcbi.1006580.ref044">44</xref>] is a neural network capable of computing illusory contours between collinear lines. Francis, Manassi &amp; Herzog [<xref ref-type="bibr" rid="pcbi.1006580.ref045">45</xref>] augmented it with a segmentation process in which elements linked by illusory contours are grouped together by dedicated neural populations. This dedicated neural processing operates in the same way for all conditions and plays an important role in explaining many other visual phenomena (review: [<xref ref-type="bibr" rid="pcbi.1006580.ref046">46</xref>]). This model process was intended as an implementation of a two-stage model of crowding, with a strong grouping process: stimuli are first segmented into different groups and, subsequently, elements within a group interfere. After dynamical processing, different groups are represented by distinct neural populations. Performance is determined by template matching. Importantly, crowding is low when the vernier is alone in its group (i.e., when the population representing the vernier does not also represent other elements) and high otherwise.</p>
<p>The segmentation process is started by local selection signals and spreads along connected contours (<xref ref-type="fig" rid="pcbi.1006580.g010">Fig 10</xref>). The location of each selection signal follows a Gaussian distribution centred on a given location, with a constant standard deviation. Uncrowding occurs when the selection signals hit a group of flankers without hitting the vernier, rescuing it from the deleterious effects of the flankers. In our simulations, each stimulus is run twenty times, each time drawing a new selection signal location. The final performance is averaged over these twenty trials. Crucially, segmentation becomes easier with more flankers, because a group of many flankers connected by illusory contours produces a larger region for selection (<xref ref-type="fig" rid="pcbi.1006580.g010">Fig 10</xref>).</p>
<fig id="pcbi.1006580.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g010</object-id>
<label>Fig 10</label>
<caption>
<title>The LAMINART variation.</title>
<p><bold>a</bold>: Activity in the LAMINART model. Colors represent the most active orientation (red: vertical, green: horizontal). When a stimulus is presented, segmentation starts to propagate along connected (illusory or actual) contours from two locations marked by attentional selection signals. Visual elements linked together by illusory contours form a group. After dynamic, recurrent processing, the stimulus is represented by three distinct neural populations, one for each group. Crowding is high if other elements are grouped in the same population as the vernier, and low if the vernier is alone. On the left, the flanker is hard to segment because of its proximity to the vernier. Across the trials, the selection signals often overlap with the whole stimulus, considered as a single group. Therefore, the flanker interferes with the vernier in most trials, and crowding is high. On the right, the flankers are linked by illusory contours and form a group that spans a large surface. In this case, segmentation signals can easily hit the flankers group successfully (without hitting the vernier). The vernier thus ends up alone in its group in most trials and crowding is low. <bold>b</bold>: The left row shows human performance with the square flanker stimuli. The right row is the output of the LAMINART model. It fits the data very well. The same holds true for a majority of our stimuli. To compute the LAMINART’s output values, we used the same linking hypothesis as in the original description of the model [<xref ref-type="bibr" rid="pcbi.1006580.ref045">45</xref>]: template matching is used to decide if the target vernier offset is left or right, and this result is monotonically transformed into a threshold-like measure. <bold>c</bold>: Sometimes flankers group together (illusory contours are formed) when they should not, erroneously predicting uncrowding for this condition. <bold>d</bold>: Sometimes flankers group with the vernier when they should not. Here, weak illusory contours connect the central flanker and the vernier. No uncrowding can be produced for this condition because segmentation always spreads to the vernier, independently of the success of the selection signals.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g010" xlink:type="simple"/>
</fig>
<p>To account for the observers’ proclivity to succeed in the vernier discrimination task, the central location of a selection signal is tuned to produce the least amount of crowding for each condition. This assumption follows the idea that an observer does the best job possible in each given situation. Although this added flexibility is not present in other models, it does not constitute an unfair advantage for the LAMINART. Indeed, it is not strictly necessary in order for the model to produce uncrowding. For example, if the segmentation signals’ central location followed a uniform distribution over the whole stimulus, it would still hit a large group of flankers (without hitting the target) more easily than a small group of flankers. In summary, whenever the flankers form a wide group that can be easily segregated from the vernier, uncrowding should be produced. Hence, uncrowding is largely independent of the selection signals’ distribution.</p>
<p>Many stimuli in the dataset had been simulated by the model in Francis et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref045">45</xref>]. Here, we improved the model by using more orientations and we ran the model on our dataset, using the template matching measure (some stimuli could not be run for reasons detailed below). Overall, the LAMINART explains the data set well (<xref ref-type="fig" rid="pcbi.1006580.g010">Fig 10</xref>).</p>
<p>More precisely, the categories circles, Gestalts, lines, octagons, squares and hexagons are all well explained. Categories irreg1, irreg2 and stars cannot be explained, but they include bars of many different orientations, and the current LAMINART simulation is only capable of handling eight orientations. We did not run the stimuli in the patternStars and patternIrregular categories because they are too large to be processed in realistic time. In general, situations where the model fails tend to be those in which the model groups elements while the data suggests it should not, leading in some cases to no uncrowding, and in other cases to excessive uncrowding. One example is when flankers (e.g., squares and stars) group together when they should not. Another example is when flankers group with the target vernier (e.g., irreg1), suggesting the need to improve the grouping mechanism itself (<xref ref-type="fig" rid="pcbi.1006580.g010">Fig 10</xref>).</p>
<p>Across all stimuli and all models, the LAMINART is by far the most successful model in this comparative study because it can explain a wide range of uncrowding results, as well as capture classic crowding effects.</p>
</sec>
<sec id="sec014">
<title>Alexnet (Convolutional Neural Network)</title>
<p>Deep Convolutional Neural Networks (CNNs) are local, feedforward, pooling networks. Training involves using feedback signals to adjust weights between neurons in subsequent layers. Once the network has been trained, users typically fix the weights and use the network in a feedforward manner. Given enough time and training samples, CNNs can learn any function by learning adequate weights [<xref ref-type="bibr" rid="pcbi.1006580.ref047">47</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref048">48</xref>]. CNNs fit very nicely in the standard view of vision research, in which basic features, such as edges, are combined in a hierarchical, feedforward manner to create higher-level representations of complex objects (<xref ref-type="fig" rid="pcbi.1006580.g002">Fig 2A</xref>). We reasoned that crowding would occur in these networks for exactly the same reason as in classic local pooling models: the target and the flankers’ representations at a given layer are pooled within the receptive fields of the subsequent layer, thus, leading to poorer performance. Although CNNs obviously compute groups such as objects or animals, these groups have no effect whatsoever on crowding of lower level features. Indeed, there are no connections from higher to lower level layers. Thus, elements far away from the vernier cannot interact with nearby elements and lead to uncrowding. To test this hypothesis, we processed the square category through Alexnet [<xref ref-type="bibr" rid="pcbi.1006580.ref049">49</xref>], a CNN trained to classify natural images with high accuracy, using Tensorflow [<xref ref-type="bibr" rid="pcbi.1006580.ref050">50</xref>]. In order to determine vernier offset discrimination in different layers, we trained classifiers to identify the vernier offset from the activations of different layers of Alexnet (<xref ref-type="fig" rid="pcbi.1006580.g011">Fig 11A</xref>). The classifiers had a single hidden layer with 512 units, followed by a softmax layer with two outputs, corresponding to left and right. In the training phase, we ran verniers through the network, and trained classifiers to identify the offset orientation from the different layers’ activations (which were normalized to zero mean and unit standard deviation). Each layer had its own classifier. We used all ReLU layers following the convolution layers and the last fully connected layer. A different classifier was trained for each of these layers. During the test phase, we used verniers alone, verniers flanked with a single square (crowded stimuli) and verniers with 7 squares flankers (uncrowded stimuli). Both training and testing stimuli had varying sizes, offsets and positions in the image. <xref ref-type="fig" rid="pcbi.1006580.g011">Fig 11</xref> shows average performance for each layer over 6 runs. For each run, we trained a new classifier on each layer, using 250000 verniers in the training set. In the testing phase, we ran 3000 verniers, 3000 crowded stimuli and 3000 uncrowded stimuli through Alexnet. Our classifiers predicted vernier orientation from the layer activations for each of these inputs. Interestingly, our classifiers could well retrieve the test vernier orientations with 100% accuracy in almost all convolutional layers (layers 2, 3, 4 and 5). Adding square flankers deteriorated performance strongly. The single square (crowded) stimuli could be decoded only in the convolutional layers 2, 3 and 4, and in fully connected layer 7, but with much poorer accuracy than the vernier alone. Crucially, unlike in humans, the 7 squares (uncrowded) stimulus performance was always worse or equal to the performance on the single square (crowded) stimulus. Hence, the deep network produced crowding, but not uncrowding. We suggest that the mechanism leading to these results is similar to the classic local pooling account of crowding.</p>
<fig id="pcbi.1006580.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Alexnet.</title>
<p><bold>a.</bold> Stimuli consisted of either verniers, verniers surrounded by a single square or verniers with seven squares. The stimuli had varying sizes, vernier offsets and positions. Alexnet’s architecture and a classifier are shown on the right (there was a classifier at each layer). The boxes correspond to the input (leftmost box) and activated neuron layers (see [<xref ref-type="bibr" rid="pcbi.1006580.ref049">49</xref>] for the detailed architecture of Alexnet). We trained softmax classifiers on all ReLU layers following the convolution layers and the last fully connected layer to detect vernier orientation from the layer’s activity. <bold>b.</bold> Accuracy of softmax classifiers trained to detect vernier orientation from different layers in the deep neural network Alexnet. Across all layers, the offsets in crowded stimuli (1 square flanker) are always better detected than offsets in uncrowded stimuli (7 square flankers). This runs contrary to human performance. NB. This model only produces percent correct, there is no output image.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g011" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec015">
<title>Hierarchical Sparse Selection (HSS)</title>
<p>This model was described by Chaney, Fischer &amp; Whitney [<xref ref-type="bibr" rid="pcbi.1006580.ref051">51</xref>]. In a series of experiments, it was shown that in spite of difficulty identifying a crowded target, crowding does preserve some information about the target, i.e., information is rendered inaccessible but not destroyed (see [<xref ref-type="bibr" rid="pcbi.1006580.ref008">8</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref009">9</xref>] for reviews). For example, a face surrounded by other faces cannot be explicitly identified, but information about its features can nevertheless survive crowding and contribute to the perceived average of a set of faces [<xref ref-type="bibr" rid="pcbi.1006580.ref052">52</xref>]. To accommodate these results, Chaney et al. proposed that information is not lost along the visual processing hierarchy. Instead, crowding occurs because readout is sparse. Specifically, given a feature map representing a stimulus, only a subset of the neurons from this map can be used to decode the target, which leads to crowding’s deleterious effects (<xref ref-type="fig" rid="pcbi.1006580.g012">Fig 12A</xref>).</p>
<fig id="pcbi.1006580.g012" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g012</object-id>
<label>Fig 12</label>
<caption>
<title>Hierarchical Sparse Selection model.</title>
<p><bold>a.</bold> The model posits that receptive fields along the visual hierarchy are large and dense. This allows for “lossless” transmission of information through the visual system. For instance, the offset of the vernier in this illustration is not corrupted by pooling thanks to the density of the receptive fields (blue and red circles). Crowding occurs because, when we try to access information, only a few sparse receptive fields are used for readout (red circles). Hence, crowding occurs at readout because of sparse sampling of receptive fields. This sparse readout can occur at any stage of visual processing, from low-level features (shown here) to faces. <bold>b.</bold> Uncrowding does not occur in the Hierarchical Sparse Selection model because performance is worse for the model on the 7 squares than the 1 square condition, contrary to human performance. NB. This model only produces a scalar output, there is no output image.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g012" xlink:type="simple"/>
</fig>
<p>Using the author’s code, we tested all our stimuli and found that crowding could be explained, but uncrowding did not occur in the model (<xref ref-type="fig" rid="pcbi.1006580.g012">Fig 12B</xref>). Originally, the model was used to detect crosses, triangles and circles. We modified the model’s readout layer to classify vernier orientation, which was achieved with 99.13% accuracy (the rest of the model does not need any change to accommodate new stimuli). Then, we dropped 75% of the neurons for the sparse readout, which led to a vernier classification accuracy of 81.48%. We tested all our stimuli by asking the model to classify the vernier orientation, first without dropping any neurons, then with 75% of the neurons dropped for the sparse readout, as we did for the verniers. For all stimuli, performance dropped with the sparse readout. For example, the 1 square condition was classified with 93.35% accuracy when all neurons were used, and this dropped to 75.55% with sparse readout. The 7 squares condition had a similar profile, but classification accuracy was worse than for the 1 square condition (71.73% with all neurons and 59.23% with sparse readout). This pattern of results was found in all stimulus categories: sparse readout impaired performance, and adding more flankers impaired performance too. Thus, there was crowding but no uncrowding. We would like to mention that Chaney et al. argue that uncrowding can in fact be explained, if the target and flanker are represented in different feature maps, which are however not implemented at the moment. In essence, visual stimuli are segmented into different feature maps (this must happen early in the visual pathway to explain the low-level vernier results), and subsequently the HSS model applies within feature maps, on this pre-segmented input.</p>
</sec>
</sec>
<sec id="sec016">
<title>Models tested elsewhere</title>
<p>The following models were not implemented here, but we mention them for completeness.</p>
<sec id="sec017">
<title>Saccade-confounded summary statistics</title>
<p>Nandy &amp; Tjan [<xref ref-type="bibr" rid="pcbi.1006580.ref053">53</xref>] proposed a model linking summary statistics to saccadic eye movements: crowding is proposed to occur because the acquisition of summary statistics in the periphery is confounded by eye-movement artifacts. This leads to inappropriate contextual interactions in the periphery and in this way produces crowding. For the present purposes this is not directly relevant, because foveal and peripheral uncrowding results are qualitatively identical [<xref ref-type="bibr" rid="pcbi.1006580.ref011">11</xref>], which the saccade-confounded summary statistics model cannot explain since it suggests that crowding can only occur in peripheral regions. Furthermore, it is not clear how uncrowding can occur in this model.</p>
</sec>
<sec id="sec018">
<title>Population coding</title>
<p>This kind of model was first described by Van den Berg, Roerdink, &amp; Cornelissen [<xref ref-type="bibr" rid="pcbi.1006580.ref054">54</xref>]. A similar model was proposed by Harrison &amp; Bex [<xref ref-type="bibr" rid="pcbi.1006580.ref055">55</xref>]. Both models elegantly produce both pooling and substitution behaviour by assuming that an element’s orientation is represented by a population code: a probability distribution of its orientation. When many elements are present, the population codes interfere and disturb the target element’s representation, which leads to crowding. This interference depends on distance and is usually modeled as a 2D Gaussian. Dayan &amp; Solomon [<xref ref-type="bibr" rid="pcbi.1006580.ref056">56</xref>] also proposed a model in which elements are represented as probability distributions. They added a Bayesian process to account for the accumulation of evidence over time. Their model captures local crowding effects similarly to Van den Berg et al. and Harrison &amp; Bex’s models: the interference comes from the representations of neighbouring elements deleteriously affecting each other. This model and the one by Van den Berg and colleagues cannot handle images as input and thus could not be tested with our stimuli.</p>
<p>We have shown elsewhere that the Harrison &amp; Bex [<xref ref-type="bibr" rid="pcbi.1006580.ref055">55</xref>] implementation cannot explain uncrowding [<xref ref-type="bibr" rid="pcbi.1006580.ref057">57</xref>]. Agaoglu &amp; Chung [<xref ref-type="bibr" rid="pcbi.1006580.ref058">58</xref>] showed that the interaction between elements depends on which of them is considered as the target for report. Hence, the crowding interference between elements in the display depends on the task, which is not easily incorporated in the models without a dedicated process. Van den Berg et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref054">54</xref>] suggested that elements do not interfere when they are represented in different perceptual groups, similar to the LAMINART model. Similarly, Harisson &amp; Bex [<xref ref-type="bibr" rid="pcbi.1006580.ref055">55</xref>] have suggested that a preprocessing stage determining which elements interfere is needed.</p>
</sec>
<sec id="sec019">
<title>Fourier model</title>
<p>The Fourier transform is sensitive to global aspects of spatial configurations because it is based on periodic features. Even if it was never explicitly proposed to explain crowding, it may capture some effects of uncrowding that have to do with regularities in the stimulus. Previously [<xref ref-type="bibr" rid="pcbi.1006580.ref015">15</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref041">41</xref>], we used a Fourier-based model and tested it on the entire dataset. Essentially, this is a texture-like model, assuming that the brain Fourier transforms the visual input. Repetitive structures, such as arrays of squares are more compactly coded in the Fourier space than the 2D space. We restate the results here for comparison with the other models. The model first bandpass-filters the stimuli (passing a small range of frequencies at all orientations), then computes the Fourier transforms of the filtered left- and right-offset cases for each stimulus. Similarly to what was done to measure performance of Zhaoping’s recurrent V1 model, these are cross-correlated with the filtered versions of the verniers without any flankers and the magnitude of the cross-correlation is taken as a measure of vernier offset discrimination performance. This process is repeated over all possible pass-bands (which is finite given a fixed image size) until the pass-band yielding performance most similar to humans is found. Across the dataset, this approach failed to reproduce the data (see <xref ref-type="fig" rid="pcbi.1006580.g013">Fig 13</xref>), suggesting that such a simple use of global regularities in the display is insufficient to explain crowding. Depending on the set of Gabor filters, uncrowding occurred for certain stimuli, but this was never consistent over several stimulus types, which is suggestive of overfitting. With one set of filters the lines category could be explained, with another the Gestalts category could be explained.</p>
<fig id="pcbi.1006580.g013" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g013</object-id>
<label>Fig 13</label>
<caption>
<title>Fourier model.</title>
<p><bold>Left.</bold> The Fourier model computes Fourier transforms for the left- and right-offset versions of each stimulus. If these transforms are very different, crowding is low because the offset direction is easy to decode in Fourier space [<xref ref-type="bibr" rid="pcbi.1006580.ref015">15</xref>]. <bold>Right.</bold> Output of the Fourier model. The model failed on most stimuli [<xref ref-type="bibr" rid="pcbi.1006580.ref015">15</xref>]. NB. This model only produces a scalar output, there is no output image.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g013" xlink:type="simple"/>
</fig>
</sec>
</sec>
</sec>
<sec id="sec020" sec-type="conclusions">
<title>Discussion</title>
<p>For decades, crowding was thought to be fully determined by nearby elements. For this reason, target elements were presented only with a few nearby elements, and models were local in nature. However, experiments of the last two decades have shown that elements far beyond Bouma’s window can strongly affect performance. Crowding can become stronger [<xref ref-type="bibr" rid="pcbi.1006580.ref012">12</xref>] or weaker [<xref ref-type="bibr" rid="pcbi.1006580.ref010">10</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1006580.ref016">16</xref>] when elements are presented outside Bouma’s window. Hence, local models cannot provide a complete account of crowding. In addition to spatial extent, it is the specific stimulus configuration that determines crowding. Configurational effects are not small modulations of crowding but have large effect sizes and, more importantly, can qualitatively change the pattern of results. For example in <xref ref-type="fig" rid="pcbi.1006580.g002">Fig 2B</xref>, performance changes in a non-linear U-shaped fashion with best performance for the unflanked target, strong crowding for few flankers, and weaker crowding when flankers make up a regular configuration.</p>
<p>A major question is at which computational level crowding occurs. In local models, only nearby elements interfere with target processing, often due to low level mechanisms such as pooling. In global models, features across the entire visual field are potentially important. Global interactions may be restricted to low level features, such as the orientations of the stimulus elements. At the other extreme, explicitly computing objects (such as the squares in <xref ref-type="fig" rid="pcbi.1006580.g002">Fig 2</xref>) may turn out to be necessary. Likewise, face crowding may or may not necessitate the explicit computation of faces [<xref ref-type="bibr" rid="pcbi.1006580.ref008">8</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref052">52</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref059">59</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref060">60</xref>]. For this reason, some global models explicitly compute grouping-like aspects. Only elements within a group interfere with each other. Classically, models restricting themselves to lower level features are given priority because they offer more parsimonious explanations.</p>
<sec id="sec021">
<title>Model comparison</title>
<p>Here, we investigated all available models suited to explain the global aspects of crowding.</p>
<p>All models (leaving aside Deep Textures, which was never proposed to explain crowding with laboratory stimuli) produced crowding comparable to the human data. However, only the LAMINART model was consistently able to produce <italic>un</italic>crowding (Figs <xref ref-type="fig" rid="pcbi.1006580.g014">14</xref> &amp; <xref ref-type="fig" rid="pcbi.1006580.g015">15</xref>). The Wilson and Cowan network produced uncrowding only for the squares category (and to a lesser extent for the irregular1 category). The Fourier model produced uncrowding only for the Gestalts and lines stimuli. In both models, uncrowding depended heavily on parameter values, a signature of overfitting. In the Wilson and Cowan network, the end-stopped receptive fields led to grouping elements of similar size, but this did not generalize to explain other global effects.</p>
<fig id="pcbi.1006580.g014" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g014</object-id>
<label>Fig 14</label>
<caption>
<title>Summary of results.</title>
<p>Results for all models (columns). In black, the left panel displays all crowding stimuli and the right panel displays all uncrowding stimuli (i.e., better performance when extra elements are added to the crowded condition) as observed in human data (rows). Superscript numbers indicate which publication the results are taken from (1: Sayim, Westheimer &amp; Herzog [<xref ref-type="bibr" rid="pcbi.1006580.ref017">17</xref>]; 2: Manassi et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref011">11</xref>]; 3: Manassi, Sayim &amp; Herzog [<xref ref-type="bibr" rid="pcbi.1006580.ref019">19</xref>]; 4: Manassi et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref015">15</xref>]). Red indicates that the model predicts crowding, green indicates uncrowding and gray indicates that we did not run the model on the stimulus. A perfect model would have only red in the left half of the table and only green in the right half. Only the LAMINART is capable of producing uncrowding consistently. Fourier and the Wilson-Cowan network produce uncrowding, but suffer from overfitting (see <xref ref-type="sec" rid="sec020">discussion</xref>). For these two models, we provide the results for the best parameters. For example, the Wilson and Cowan with different parameters can explain the lines category but then it cannot explain the squares and irregular1 categories.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g014" xlink:type="simple"/>
</fig>
<fig id="pcbi.1006580.g015" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006580.g015</object-id>
<label>Fig 15</label>
<caption>
<title>Model comparison.</title>
<p>All models produce crowding, but only the Fourier, Wilson and Cowan and LAMINART models produce uncrowding. The Fourier and the Wilson and Cowan model overfit and thus do not capture general principles. The LAMINART is the only model that explicitly computes grouping like aspects and segments the image into different layers.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006580.g015" xlink:type="simple"/>
</fig>
<p>We think there are principled reasons why most models cannot reproduce most of the global uncrowding findings. First, the effects of global configuration (<xref ref-type="fig" rid="pcbi.1006580.g002">Fig 2C</xref>) operate on a much higher level than most models can capture. To phrase it this way, we think that human performance is based on global configurations and not on simple hidden sub-regularities, such as repeating patterns or simple summary statistics. Second, as Wallis et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref037">37</xref>] put it: “Based on our experiments we speculate that the concept of summary statistics cannot fully account for peripheral scene appearance. Pooling in fixed regions will either discard (long-range) structure that should be preserved or preserve (local) structure that could be discarded. Rather, we believe that the size of pooling regions needs to depend on image content”. For this reason, we think that performance in crowding cannot be explained simply as a by-product of basic spatial processing, e.g., by summary statistics. In contrast, which elements interfere seems to depend on the global stimulus layout. We propose that the LAMINART can consistently produce uncrowding because it can deal with this requirement by incorporating a grouping-like process: elements linked by illusory contours are grouped together and segmented from elements in other groups. Interference happens only between elements within a group.</p>
<p>Another way to approach the importance of grouping for crowding is that it provides extra information that makes one condition inherently easier than another. Vernier acuity tasks are often thought to be mediated by the responses of one or more feature detectors. Each feature detector might itself look like a vernier offset, or might be similar to an orientation detector such as a Gabor. Regardless, correct performance at the vernier task requires precise placement of the detector; a slightly misplaced detector can easily give the wrong answer, particularly when the vernier is flanked by other stimuli. Crowding induces location uncertainty. Any information that can help correctly place the detector–essentially any cue to the right position–would improve performance. Strong stimulus grouping could be one such cue (Rosenholtz et al., under review). In this case too, it is crucial to understand how the brain groups visual elements across the entire visual field.</p>
<p>The LAMINART model links elements by illusory contours, which is a rather basic grouping mechanism. It remains an open question whether more complex features are necessary to explain crowding/uncrowding such as an explicit computation of objects, e.g. squares, faces etc. For example, can the irregular shapes category be explained with simple contour integration? Likewise, it remains an open question whether face crowding can be explained without the explicit computation of faces.</p>
<p>In the LAMINART model, the grouping and interference processes are separate. Alternatively, grouping and interference may be intimately linked. One possibility is that the groups correspond to optimal statistical representations. For example, elements may form a group when they can be well compressed by summary statistics. In this scenario, grouping is part of the summary statistics process itself. There are probably many other ways in which grouping may play a role.</p>
<p>A major problem with the grouping approach is the lack of a well-defined, objective measure of grouping. If there is no objective measure, groups can be chosen ad hoc to explain experimental results, leading to circular explanations. As a first step towards an objective measure of grouping, subjective measures (i.e., asking observers to report what they feel belongs to a group) can complement studies. Such subjective ratings about perceptual groups have correlated well with psychophysical performance levels [<xref ref-type="bibr" rid="pcbi.1006580.ref011">11</xref>].</p>
</sec>
<sec id="sec022">
<title>Future models</title>
<p>As we have shown, none of the current models can fully explain (un)crowding. What would the model of the future look like? What components are crucial?</p>
<p>First, as mentioned earlier, we can rule out local models because elements across large parts of the visual field influence perception of the target.</p>
<p>Second, to explain the complex effects of spatial configurations in crowding, our results suggest that grouping-like, mid or higher level aspects need to be incorporated in a model. However, the exact nature of this process is unknown. For example, it may or may not be that mid-level processing is sufficient. In addition, the incorporation of higher level processes does not exclude the additional use of summary statistics and other lower level components. The grouping stage is difficult to study because of the seemingly infinite number of possible visual configurations. We believe that new tools are needed to help navigate the huge search space effectively. For example, Van der Burg, Olivers, &amp; Cass [<xref ref-type="bibr" rid="pcbi.1006580.ref061">61</xref>] have proposed a genetic algorithm to find configurational features important for crowding.</p>
<p>Third, we cannot rule out feedforward models. Indeed, it is a mathematical fact that any recurrent model can be “unfolded” into a feed-forward network [<xref ref-type="bibr" rid="pcbi.1006580.ref062">62</xref>–<xref ref-type="bibr" rid="pcbi.1006580.ref064">64</xref>]. However, these feedforward models are usually extremely large and computationally expensive. For this reason, we suggest that models with feedback connections are much more likely to be able to explain how complex spatial configurations influence target processing. For example, higher level grouping processing, such as computing the squares and grouping them together, may feed back to lower level processing of the target, i.e., the vernier. Support for this hypothesis comes from the finding that the Alexnet CNN could not produce uncrowding, presumably because high-level features cannot influence low-level processing.</p>
<p>Fourth, the nature of interference remains unclear. One option is that interference occurs during complex spatial processing by an unknown mechanism. Another option is that the classic interference mechanisms operate after complex spatial processing is accomplished. For example, pooling may occur only for grouped elements. In the same line of reasoning, Chaney et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref051">51</xref>], Van den Berg et al. [<xref ref-type="bibr" rid="pcbi.1006580.ref054">54</xref>] and Harrison &amp; Bex [<xref ref-type="bibr" rid="pcbi.1006580.ref065">65</xref>] noted that adding a grouping stage to their interference mechanism may help explain a wider range of results. Combining complex spatial processing with good interference mechanisms may, therefore, allow for a happy marriage between interference- and grouping-based mechanisms leading to a truly unified model of crowding.</p>
</sec>
<sec id="sec023">
<title>Conclusion</title>
<p>The global stimulus configuration plays a crucial role in crowding, which cannot be captured by local models. For this reason, we propose that models of crowding need to include grouping like processes. While our results show that none of the current models lacking a grouping process can explain the global uncrowding phenomena, they may be good candidates for a potential second, interference stage.</p>
<p>How are basic features of the visual field grouped to form objects? The most successful model we analyzed, the LAMINART variation, suggests that this is done by linking features together by illusory contours. Further work is needed to assess how far this mechanism can go and what alternative or additional components are necessary, such as summary statistics. For example, the groups may correspond to optimal statistical representations (elements that can easily be compressed using summary statistics would form a group).</p>
<p>Most importantly, large scale, configurational effects are not restricted to visual crowding with vernier targets. Uncrowding occurs also for letters and Gabors [<xref ref-type="bibr" rid="pcbi.1006580.ref066">66</xref>], as well as in audition [<xref ref-type="bibr" rid="pcbi.1006580.ref023">23</xref>] and haptics [<xref ref-type="bibr" rid="pcbi.1006580.ref024">24</xref>]. Similar effects are found in backward masking [<xref ref-type="bibr" rid="pcbi.1006580.ref067">67</xref>] and overlay masking [<xref ref-type="bibr" rid="pcbi.1006580.ref017">17</xref>,<xref ref-type="bibr" rid="pcbi.1006580.ref068">68</xref>]. Hence, crowding is a special case of contextual processing. Vision research has largely missed these aspects because of the use of well-controlled stimuli, which are usually presented in isolation or with only a few nearby flankers. Our results suggest that in order to understand vision in general, a mid-level, contextual processing stage is inevitable.</p>
</sec>
</sec>
</body>
<back>
<ack>
<p>We thank Thomas Wallis, Alexander Ecker and Mauro Manassi for helpful discussions and the reviewers for insightful comments. We also thank the authors who shared their code on the web or by email.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006580.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bouma</surname> <given-names>H.</given-names></name> <article-title>Visual interference in the parafoveal recognition of initial and final letters of words</article-title>. <source>Vision Res</source>. <year>1973</year>;<volume>13</volume>: <fpage>767</fpage>–<lpage>782</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0042-6989(73)90041-2" xlink:type="simple">10.1016/0042-6989(73)90041-2</ext-link></comment> <object-id pub-id-type="pmid">4706350</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Levi</surname> <given-names>DM</given-names></name>. <article-title>Crowding-An essential bottleneck for object recognition: A mini-review</article-title>. <source>Vision Res</source>. <year>2008</year>;<volume>48</volume>: <fpage>635</fpage>–<lpage>654</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2007.12.009" xlink:type="simple">10.1016/j.visres.2007.12.009</ext-link></comment> <object-id pub-id-type="pmid">18226828</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pelli</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Palomares</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Majaj</surname> <given-names>NJ</given-names></name>. <article-title>Crowding is unlike ordinary masking: Distinguishing feature integration from detection</article-title>. <source>J Vis</source>. <year>2004</year>;<volume>4</volume>: <fpage>12</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/4.12.12" xlink:type="simple">10.1167/4.12.12</ext-link></comment> <object-id pub-id-type="pmid">15669917</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Strasburger</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Harvey</surname> <given-names>LO</given-names></name>, <name name-style="western"><surname>Rentschler</surname> <given-names>I</given-names></name>. <article-title>Contrast thresholds for identification of numeric characters in direct and eccentric view</article-title>. <source>Percept Psychophys</source>. <year>1991</year>;<volume>49</volume>: <fpage>495</fpage>–<lpage>508</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03212183" xlink:type="simple">10.3758/BF03212183</ext-link></comment> <object-id pub-id-type="pmid">1857623</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pelli</surname> <given-names>DG</given-names></name>. <article-title>Crowding: a cortical constraint on object recognition</article-title>. <source>Curr Opin Neurobiol</source>. <year>2008</year>;<volume>18</volume>: <fpage>445</fpage>–<lpage>451</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2008.09.008" xlink:type="simple">10.1016/j.conb.2008.09.008</ext-link></comment> <object-id pub-id-type="pmid">18835355</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pelli</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Tillman</surname> <given-names>KA</given-names></name>. <article-title>The uncrowded window of object recognition</article-title>. <source>Nat Neurosci</source>. <year>2008</year>;<volume>11</volume>: <fpage>1129</fpage>–<lpage>1135</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2187" xlink:type="simple">10.1038/nn.2187</ext-link></comment> <object-id pub-id-type="pmid">18828191</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ester</surname> <given-names>EF</given-names></name>, <name name-style="western"><surname>Klee</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Awh</surname> <given-names>E</given-names></name>. <article-title>Visual crowding cannot be wholly explained by feature pooling</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>2014</year>;<volume>40</volume>: <fpage>1022</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0035377" xlink:type="simple">10.1037/a0035377</ext-link></comment> <object-id pub-id-type="pmid">24364703</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Manassi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Whitney</surname> <given-names>D</given-names></name>. <article-title>Multi-level Crowding and the Paradox of Object Recognition in Clutter</article-title>. <source>Curr Biol</source>. <year>2018</year>;<volume>28</volume>: <fpage>R127</fpage>–<lpage>R133</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2017.12.051" xlink:type="simple">10.1016/j.cub.2017.12.051</ext-link></comment> <object-id pub-id-type="pmid">29408262</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Whitney</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Haberman</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sweeny</surname> <given-names>TD</given-names></name>. <article-title>From textures to crowds: multiple levels of summary statistical perception</article-title>. <source>New Vis Neurosci</source>. <year>2014</year>; <fpage>695</fpage>–<lpage>710</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Malania</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Westheimer</surname> <given-names>G</given-names></name>. <article-title>Grouping of contextual elements that affect vernier thresholds</article-title>. <source>J Vis</source>. <year>2007</year>;<volume>7</volume>: <fpage>1</fpage>–<lpage>1</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/7.2.1" xlink:type="simple">10.1167/7.2.1</ext-link></comment> <object-id pub-id-type="pmid">18217816</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Manassi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sayim</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>. <article-title>Grouping, pooling, and when bigger is better in visual crowding</article-title>. <source>J Vis</source>. <year>2012</year>;<volume>12</volume>: <fpage>13</fpage>–<lpage>13</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/12.10.13" xlink:type="simple">10.1167/12.10.13</ext-link></comment> <object-id pub-id-type="pmid">23019118</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vickery</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Shim</surname> <given-names>WM</given-names></name>, <name name-style="western"><surname>Chakravarthi</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Jiang</surname> <given-names>YV</given-names></name>, <name name-style="western"><surname>Luedeman</surname> <given-names>R</given-names></name>. <article-title>Supercrowding: Weakly masking a target expands the range of crowding</article-title>. <source>J Vis</source>. <year>2009</year>;<volume>9</volume>: <fpage>12</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/9.2.12" xlink:type="simple">10.1167/9.2.12</ext-link></comment> <object-id pub-id-type="pmid">19271922</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Banks</surname> <given-names>WP</given-names></name>, <name name-style="western"><surname>Larson</surname> <given-names>DW</given-names></name>, <name name-style="western"><surname>Prinzmetal</surname> <given-names>W</given-names></name>. <article-title>Asymmetry of visual interference</article-title>. <source>Percept Psychophys</source>. <year>1979</year>;<volume>25</volume>: <fpage>447</fpage>–<lpage>456</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03213822" xlink:type="simple">10.3758/BF03213822</ext-link></comment> <object-id pub-id-type="pmid">492909</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Livne</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sagi</surname> <given-names>D</given-names></name>. <article-title>Configuration influence on crowding</article-title>. <source>J Vis</source>. <year>2007</year>;<volume>7</volume>: <fpage>4</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/7.2.4" xlink:type="simple">10.1167/7.2.4</ext-link></comment> <object-id pub-id-type="pmid">18217819</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Manassi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lonchampt</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Clarke</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>. <article-title>What crowding can tell us about object representations</article-title>. <source>J Vis</source>. <year>2016</year>;<volume>16</volume>: <fpage>35</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/16.3.35" xlink:type="simple">10.1167/16.3.35</ext-link></comment> <object-id pub-id-type="pmid">26913627</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Põder</surname> <given-names>E.</given-names></name> <article-title>Crowding, feature integration, and two kinds of “attention.”</article-title> <source>J Vis</source>. <year>2006</year>;<volume>6</volume>: <fpage>7</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/6.2.7" xlink:type="simple">10.1167/6.2.7</ext-link></comment> <object-id pub-id-type="pmid">16522143</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sayim</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Westheimer</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>. <article-title>Gestalt factors modulate basic spatial vision</article-title>. <source>Psychol Sci</source>. <year>2010</year>;<volume>21</volume>: <fpage>641</fpage>–<lpage>644</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797610368811" xlink:type="simple">10.1177/0956797610368811</ext-link></comment> <object-id pub-id-type="pmid">20483840</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Sayim</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Chicherov</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Manassi</surname> <given-names>M</given-names></name>. <article-title>Crowding, grouping, and object recognition: A matter of appearance</article-title>. <source>J Vis</source>. <year>2015</year>;<volume>15</volume>: <fpage>5</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/15.6.5" xlink:type="simple">10.1167/15.6.5</ext-link></comment> <object-id pub-id-type="pmid">26024452</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Manassi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sayim</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>. <article-title>When crowding of crowding leads to uncrowding</article-title>. <source>J Vis</source>. <year>2013</year>;<volume>13</volume>: <fpage>10</fpage>–<lpage>10</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/13.13.10" xlink:type="simple">10.1167/13.13.10</ext-link></comment> <object-id pub-id-type="pmid">24213598</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Manassi</surname> <given-names>M</given-names></name>. <article-title>Uncorking the bottleneck of crowding: a fresh look at object recognition</article-title>. <source>Curr Opin Behav Sci</source>. <year>2015</year>;<volume>1</volume>: <fpage>86</fpage>–<lpage>93</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cobeha.2014.10.006" xlink:type="simple">10.1016/j.cobeha.2014.10.006</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006580.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chakravarthi</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Pelli</surname> <given-names>DG</given-names></name>. <article-title>The same binding in contour integration and crowding</article-title>. <source>J Vis</source>. <year>2011</year>;<volume>11</volume>: <fpage>10</fpage>–<lpage>10</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/11.8.10" xlink:type="simple">10.1167/11.8.10</ext-link></comment> <object-id pub-id-type="pmid">21757504</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Livne</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sagi</surname> <given-names>D</given-names></name>. <article-title>Multiple levels of orientation anisotropy in crowding with Gabor flankers</article-title>. <source>J Vis</source>. <year>2011</year>;<volume>11</volume>: <fpage>18</fpage>–<lpage>18</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/11.13.18" xlink:type="simple">10.1167/11.13.18</ext-link></comment> <object-id pub-id-type="pmid">22101017</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oberfeld</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Stahn</surname> <given-names>P</given-names></name>. <article-title>Sequential grouping modulates the effect of non-simultaneous masking on auditory intensity resolution</article-title>. <source>PloS One</source>. <year>2012</year>;<volume>7</volume>: <fpage>e48054</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0048054" xlink:type="simple">10.1371/journal.pone.0048054</ext-link></comment> <object-id pub-id-type="pmid">23110174</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Overvliet</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Sayim</surname> <given-names>B</given-names></name>. <article-title>Perceptual grouping determines haptic contextual modulation</article-title>. <source>Vision Res</source>. <year>2016</year>;<volume>126</volume>: <fpage>52</fpage>–<lpage>58</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2015.04.016" xlink:type="simple">10.1016/j.visres.2015.04.016</ext-link></comment> <object-id pub-id-type="pmid">25982716</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>DiCarlo</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Zoccolan</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Rust</surname> <given-names>NC</given-names></name>. <article-title>How Does the Brain Solve Visual Object Recognition?</article-title> <source>Neuron</source>. <year>2012</year>;<volume>73</volume>: <fpage>415</fpage>–<lpage>434</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2012.01.010" xlink:type="simple">10.1016/j.neuron.2012.01.010</ext-link></comment> <object-id pub-id-type="pmid">22325196</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Riesenhuber</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Poggio</surname> <given-names>T</given-names></name>. <article-title>Hierarchical models of object recognition in cortex</article-title>. <source>Nat Neurosci</source>. <year>1999</year>;<fpage>2</fpage>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Balas</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Nakano</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Rosenholtz</surname> <given-names>R</given-names></name>. <article-title>A summary-statistic representation in peripheral vision explains visual crowding</article-title>. <source>J Vis</source>. <year>2009</year>;<volume>9</volume>: <fpage>13</fpage>–<lpage>13</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/9.12.13" xlink:type="simple">10.1167/9.12.13</ext-link></comment> <object-id pub-id-type="pmid">20053104</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jojic</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Frey</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Kannan</surname> <given-names>A</given-names></name>. <article-title>Epitomic analysis of appearance and shape</article-title>. <source>Proceedings Ninth IEEE International Conference on Computer Vision</source>. <year>2003</year>. pp. <fpage>34</fpage>–<lpage>41</lpage> vol.<volume>1</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/ICCV.2003.1238311" xlink:type="simple">10.1109/ICCV.2003.1238311</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006580.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Portilla</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>. <article-title>A Parametric Texture Model Based on Joint Statistics of Complex Wavelet Coefficients</article-title>. <source>Int J Comput Vis</source>. <year>2000</year>;<volume>40</volume>: <fpage>49</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1023/A:1026553619983" xlink:type="simple">10.1023/A:1026553619983</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006580.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Huang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Yigit-Elliott</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rosenholtz</surname> <given-names>R</given-names></name>. <article-title>Cube search, revisited</article-title>. <source>J Vis</source>. <year>2015</year>;<volume>15</volume>: <fpage>9</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Freeman</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>. <article-title>Metamers of the ventral stream</article-title>. <source>Nat Neurosci</source>. <year>2011</year>;<volume>14</volume>: <fpage>1195</fpage>–<lpage>1201</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2889" xlink:type="simple">10.1038/nn.2889</ext-link></comment> <object-id pub-id-type="pmid">21841776</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Keshvari</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rosenholtz</surname> <given-names>R</given-names></name>. <article-title>Pooling of continuous features provides a unifying account of crowding</article-title>. <source>J Vis</source>. <year>2016</year>;<volume>16</volume>: <fpage>39</fpage>–<lpage>39</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/16.3.39" xlink:type="simple">10.1167/16.3.39</ext-link></comment> <object-id pub-id-type="pmid">26928055</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rosenholtz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Huang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Raj</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Balas</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Ilie</surname> <given-names>L</given-names></name>. <article-title>A summary statistic representation in peripheral vision explains visual search</article-title>. <source>J Vis</source>. <year>2012</year>;<volume>12</volume>: <fpage>14</fpage>–<lpage>14</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/12.4.14" xlink:type="simple">10.1167/12.4.14</ext-link></comment> <object-id pub-id-type="pmid">22523401</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rosenholtz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Keshvari</surname> <given-names>S</given-names></name>. <article-title>Challenges to pooling models of crowding: Implications for visual mechanisms</article-title>. <source>J Vis</source>. <volume>19</volume>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref035"><label>35</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Gatys</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Ecker</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Bethge</surname> <given-names>M</given-names></name>. <chapter-title>Texture Synthesis Using Convolutional Neural Networks</chapter-title>. In: <name name-style="western"><surname>Cortes</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Lawrence</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Sugiyama</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Garnett</surname> <given-names>R</given-names></name>, editors. <source>Advances in Neural Information Processing Systems 28</source>. <publisher-name>Curran Associates, Inc.</publisher-name>; <year>2015</year>. pp. <fpage>262</fpage>–<lpage>270</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/5633-texture-synthesis-using-convolutional-neural-networks.pdf" xlink:type="simple">http://papers.nips.cc/paper/5633-texture-synthesis-using-convolutional-neural-networks.pdf</ext-link></mixed-citation></ref>
<ref id="pcbi.1006580.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wallis</surname> <given-names>TSA</given-names></name>, <name name-style="western"><surname>Funke</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Ecker</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Gatys</surname> <given-names>LA</given-names></name>, <name name-style="western"><surname>Wichmann</surname> <given-names>FA</given-names></name>, <name name-style="western"><surname>Bethge</surname> <given-names>M</given-names></name>. <article-title>A parametric texture model based on deep convolutional features closely matches texture appearance for humans</article-title>. <source>J Vis</source>. <year>2017</year>;<volume>17</volume>: <fpage>5</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/17.12.5" xlink:type="simple">10.1167/17.12.5</ext-link></comment> <object-id pub-id-type="pmid">28983571</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wallis</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Funke</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Ecker</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Gatys</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wichmann</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Bethge</surname> <given-names>M</given-names></name>. <article-title>Towards matching peripheral appearance for arbitrary natural images using deep features</article-title>. <source>J Vis</source>. <year>2017</year>;<volume>17</volume>: <fpage>786</fpage>–<lpage>786</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilson</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Cowan</surname> <given-names>JD</given-names></name>. <article-title>A mathematical theory of the functional dynamics of cortical and thalamic nervous tissue</article-title>. <source>Kybernetik</source>. <year>1973</year>;<volume>13</volume>: <fpage>55</fpage>–<lpage>80</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00288786" xlink:type="simple">10.1007/BF00288786</ext-link></comment> <object-id pub-id-type="pmid">4767470</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hermens</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Luksys</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Ernst</surname> <given-names>U</given-names></name>. <article-title>Modeling spatial and temporal aspects of visual backward masking</article-title>. <source>Psychol Rev</source>. <year>2008</year>;<volume>115</volume>: <fpage>83</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.115.1.83" xlink:type="simple">10.1037/0033-295X.115.1.83</ext-link></comment> <object-id pub-id-type="pmid">18211186</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Panis</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Hermens</surname> <given-names>F</given-names></name>. <article-title>Time course of spatial contextual interference: Event history analyses of simultaneous masking by nonoverlapping patterns</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>2014</year>;<volume>40</volume>: <fpage>129</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0032949" xlink:type="simple">10.1037/a0032949</ext-link></comment> <object-id pub-id-type="pmid">23713795</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Clarke</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Francis</surname> <given-names>G</given-names></name>. <article-title>Visual crowding illustrates the inadequacy of local vs. global and feedforward vs. feedback distinctions in modeling visual perception</article-title>. <source>Front Psychol</source>. <year>2014</year>;<volume>5</volume>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>Z.</given-names></name> <article-title>Visual segmentation by contextual influences via intra-cortical interactions in the primary visual cortex</article-title>. <source>Netw Comput Neural Syst</source>. <year>1999</year>;<volume>10</volume>: <fpage>187</fpage>–<lpage>212</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhaoping</surname> <given-names>L.</given-names></name> <article-title>V1 mechanisms and some figure–ground and border effects</article-title>. <source>J Physiol-Paris</source>. <year>2003</year>;<volume>97</volume>: <fpage>503</fpage>–<lpage>515</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jphysparis.2004.01.008" xlink:type="simple">10.1016/j.jphysparis.2004.01.008</ext-link></comment> <object-id pub-id-type="pmid">15242660</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cao</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Grossberg</surname> <given-names>S</given-names></name>. <article-title>A laminar cortical model of stereopsis and 3D surface perception: closure and da Vinci stereopsis</article-title>. <source>Spat Vis</source>. <year>2005</year>;<volume>18</volume>: <fpage>515</fpage>–<lpage>578</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1163/156856805774406756" xlink:type="simple">10.1163/156856805774406756</ext-link></comment> <object-id pub-id-type="pmid">16312095</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Francis</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Manassi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>. <source>Neural dynamics of grouping and segmentation explain properties of visual crowding</source>. <year>2017</year>;</mixed-citation></ref>
<ref id="pcbi.1006580.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grossberg</surname> <given-names>S.</given-names></name> <article-title>Towards solving the hard problem of consciousness: The varieties of brain resonances and the conscious experiences that they support</article-title>. <source>Neural Netw</source>. <year>2017</year>;<volume>87</volume>: <fpage>38</fpage>–<lpage>95</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neunet.2016.11.003" xlink:type="simple">10.1016/j.neunet.2016.11.003</ext-link></comment> <object-id pub-id-type="pmid">28088645</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>LeCun</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>G</given-names></name>. <article-title>Deep learning</article-title>. <source>Nature</source>. <year>2015</year>;<volume>521</volume>: <fpage>436</fpage>–<lpage>444</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature14539" xlink:type="simple">10.1038/nature14539</ext-link></comment> <object-id pub-id-type="pmid">26017442</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lin</surname> <given-names>HW</given-names></name>, <name name-style="western"><surname>Tegmark</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rolnick</surname> <given-names>D</given-names></name>. <article-title>Why Does Deep and Cheap Learning Work So Well?</article-title> <source>J Stat Phys</source>. <year>2017</year>;<volume>168</volume>: <fpage>1223</fpage>–<lpage>1247</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10955-017-1836-5" xlink:type="simple">10.1007/s10955-017-1836-5</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006580.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krizhevsky</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sutskever</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>GE</given-names></name>. <article-title>Imagenet classification with deep convolutional neural networks</article-title>. <source>Advances in neural information processing systems</source>. <year>2012</year>. pp. <fpage>1097</fpage>–<lpage>1105</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abadi</surname> <given-names>Martín</given-names></name>, <name name-style="western"><surname>Agarwal</surname> <given-names>Ashish</given-names></name>, <name name-style="western"><surname>Barham</surname> <given-names>Paul</given-names></name>, <name name-style="western"><surname>Brevdo</surname> <given-names>Eugene</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>Zhifeng</given-names></name>, <name name-style="western"><surname>Citro</surname> <given-names>Craig</given-names></name>, <etal>et al</etal>. <source>TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems</source> [Internet]. <year>2015</year>. Available: <ext-link ext-link-type="uri" xlink:href="https://www.tensorflow.org/" xlink:type="simple">https://www.tensorflow.org/</ext-link></mixed-citation></ref>
<ref id="pcbi.1006580.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chaney</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Fischer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Whitney</surname> <given-names>D</given-names></name>. <article-title>The hierarchical sparse selection model of visual crowding</article-title>. <source>Front Integr Neurosci</source>. <year>2014</year>;<volume>8</volume>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fischer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Whitney</surname> <given-names>D</given-names></name>. <article-title>Object-level visual information gets through the bottleneck of crowding</article-title>. <source>J Neurophysiol</source>. <year>2011</year>;<volume>106</volume>: <fpage>1389</fpage>–<lpage>1398</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00904.2010" xlink:type="simple">10.1152/jn.00904.2010</ext-link></comment> <object-id pub-id-type="pmid">21676930</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nandy</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Tjan</surname> <given-names>BS</given-names></name>. <article-title>Saccade-confounded image statistics explain visual crowding</article-title>. <source>Nat Neurosci</source>. <year>2012</year>;<volume>15</volume>: <fpage>463</fpage>–<lpage>469</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3021" xlink:type="simple">10.1038/nn.3021</ext-link></comment> <object-id pub-id-type="pmid">22231425</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Roerdink</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Cornelissen</surname> <given-names>FW</given-names></name>. <article-title>A neurophysiologically plausible population code model for feature integration explains visual crowding</article-title>. <source>PLoS Comput Biol</source>. <year>2010</year>;<volume>6</volume>: <fpage>e1000646</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1000646" xlink:type="simple">10.1371/journal.pcbi.1000646</ext-link></comment> <object-id pub-id-type="pmid">20098499</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harrison</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Bex</surname> <given-names>PJ</given-names></name>. <article-title>A Unifying Model of Orientation Crowding in Peripheral Vision</article-title>. <source>Curr Biol</source>. <year>2015</year>;<volume>25</volume>: <fpage>3213</fpage>–<lpage>3219</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2015.10.052" xlink:type="simple">10.1016/j.cub.2015.10.052</ext-link></comment> <object-id pub-id-type="pmid">26628010</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Solomon</surname> <given-names>JA</given-names></name>. <article-title>Selective Bayes: Attentional load and crowding</article-title>. <source>Vision Res</source>. <year>2010</year>;<volume>50</volume>: <fpage>2248</fpage>–<lpage>2260</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2010.04.014" xlink:type="simple">10.1016/j.visres.2010.04.014</ext-link></comment> <object-id pub-id-type="pmid">20435055</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pachai</surname> <given-names>MV</given-names></name>, <name name-style="western"><surname>Doerig</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>. <article-title>How best to unify crowding?</article-title> <source>Curr Biol</source>. <year>2016</year>;<volume>26</volume>: <fpage>R352</fpage>–<lpage>R353</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2016.03.003" xlink:type="simple">10.1016/j.cub.2016.03.003</ext-link></comment> <object-id pub-id-type="pmid">27166689</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Agaoglu</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Chung</surname> <given-names>ST</given-names></name>. <article-title>Can (should) theories of crowding be unified?</article-title> <source>J Vis</source>. <year>2016</year>;<volume>16</volume>: <fpage>10</fpage>–<lpage>10</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kalpadakis-Smith</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Goffaux</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Greenwood</surname> <given-names>J</given-names></name>. <source>Crowding for faces is determined by visual (not holistic) similarity: Evidence from judgements of eye position</source>. <year>2017</year>;</mixed-citation></ref>
<ref id="pcbi.1006580.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sun</surname> <given-names>H-M</given-names></name>, <name name-style="western"><surname>Balas</surname> <given-names>B</given-names></name>. <article-title>Face features and face configurations both contribute to visual crowding</article-title>. <source>Atten Percept Psychophys</source>. <year>2015</year>;<volume>77</volume>: <fpage>508</fpage>–<lpage>519</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13414-014-0786-0" xlink:type="simple">10.3758/s13414-014-0786-0</ext-link></comment> <object-id pub-id-type="pmid">25341649</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van der Burg</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Olivers</surname> <given-names>CN</given-names></name>, <name name-style="western"><surname>Cass</surname> <given-names>J</given-names></name>. <article-title>Evolving the keys to visual crowding</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>2017</year>;<volume>43</volume>: <fpage>690</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/xhp0000337" xlink:type="simple">10.1037/xhp0000337</ext-link></comment> <object-id pub-id-type="pmid">28182476</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hornik</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Stinchcombe</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>White</surname> <given-names>H</given-names></name>. <article-title>Multilayer feedforward networks are universal approximators</article-title>. <source>Neural Netw</source>. <year>1989</year>;<volume>2</volume>: <fpage>359</fpage>–<lpage>366</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref063"><label>63</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Schäfer</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Zimmermann</surname> <given-names>HG</given-names></name>. <chapter-title>Recurrent Neural Networks Are Universal Approximators</chapter-title>. <source>Artificial Neural Networks–ICANN 2006</source>. <publisher-name>Springer</publisher-name>, <publisher-loc>Berlin, Heidelberg</publisher-loc>; <year>2006</year>. pp. <fpage>632</fpage>–<lpage>640</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/11840817_66" xlink:type="simple">10.1007/11840817_66</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006580.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Werbos</surname> <given-names>PJ</given-names></name>. <article-title>Generalization of backpropagation with application to a recurrent gas market model</article-title>. <source>Neural Netw</source>. <year>1988</year>;<volume>1</volume>: <fpage>339</fpage>–<lpage>356</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0893-6080(88)90007-X" xlink:type="simple">10.1016/0893-6080(88)90007-X</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006580.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harrison</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Bex</surname> <given-names>PJ</given-names></name>. <article-title>Reply to Pachai et al</article-title>. <source>Curr Biol</source>. <year>2016</year>;<volume>26</volume>: <fpage>R353</fpage>–<lpage>R354</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2016.03.024" xlink:type="simple">10.1016/j.cub.2016.03.024</ext-link></comment> <object-id pub-id-type="pmid">27166690</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saarela</surname> <given-names>TP</given-names></name>, <name name-style="western"><surname>Westheimer</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>. <article-title>The effect of spacing regularity on visual crowding</article-title>. <source>J Vis</source>. <year>2010</year>;<volume>10</volume>: <fpage>17</fpage>–<lpage>17</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006580.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Fahle</surname> <given-names>M</given-names></name>. <article-title>Effects of grouping in contextual modulation</article-title>. <source>Nature</source>. <year>2002</year>;<volume>415</volume>: <fpage>433</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/415433a" xlink:type="simple">10.1038/415433a</ext-link></comment> <object-id pub-id-type="pmid">11807555</object-id></mixed-citation></ref>
<ref id="pcbi.1006580.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saarela</surname> <given-names>TP</given-names></name>, <name name-style="western"><surname>Sayim</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Westheimer</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Herzog</surname> <given-names>MH</given-names></name>. <article-title>Global stimulus configuration modulates crowding</article-title>. <source>J Vis</source>. <year>2009</year>;<volume>9</volume>: <fpage>5</fpage>–<lpage>5</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-13-01355</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003282</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories>
<title-group>
<article-title>Communication and Common Interest</article-title>
<alt-title alt-title-type="running-head">Communication and Common Interest</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Godfrey-Smith</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Martínez</surname><given-names>Manolo</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><addr-line>Philosophy Program, The Graduate Center CUNY, New York City, New York, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Bergstrom</surname><given-names>Carl T.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Washington, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">mmartinez3@gc.cuny.edu</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: PGS MM. Performed the experiments: MM. Analyzed the data: PGS MM. Wrote the paper: PGS MM.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>11</month><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>7</day><month>11</month><year>2013</year></pub-date>
<volume>9</volume>
<issue>11</issue>
<elocation-id>e1003282</elocation-id>
<history>
<date date-type="received"><day>31</day><month>7</month><year>2013</year></date>
<date date-type="accepted"><day>2</day><month>9</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Godfrey-Smith, Martínez</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Explaining the maintenance of communicative behavior in the face of incentives to deceive, conceal information, or exaggerate is an important problem in behavioral biology. When the interests of agents diverge, some form of signal cost is often seen as essential to maintaining honesty. Here, novel computational methods are used to investigate the role of common interest between the sender and receiver of messages in maintaining cost-free informative signaling in a signaling game. Two measures of common interest are defined. These quantify the divergence between sender and receiver in their preference orderings over acts the receiver might perform in each state of the world. Sampling from a large space of signaling games finds that informative signaling is possible at equilibrium with zero common interest in both senses. Games of this kind are rare, however, and the proportion of games that include at least one equilibrium in which informative signals are used increases monotonically with common interest. Common interest as a predictor of informative signaling also interacts with the extent to which agents' preferences vary with the state of the world. Our findings provide a quantitative description of the relation between common interest and informative signaling, employing exact measures of common interest, information use, and contingency of payoff under environmental variation that may be applied to a wide range of models and empirical systems.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>How can honest communication evolve, given the many incentives to deceive, conceal information, or exaggerate? In recent work, it has often been supposed that either common interest between the sender and receiver of messages must be present, or special factors (such as a special cost for dishonest production of signals) must be in place. When talk is cheap, what is the minimum degree of common interest that will suffice to maintain communication? We give new quantitative measures of common interest between communicating agents, and then use a computer search of signaling games to work out the relationship between the degree of common interest and the maintenance of signaling that conveys real information. Surprisingly, we find that informative signaling can in some cases be maintained with zero common interest. These cases are rare, and we also find that the degree of common interest is a good predictor of whether informative signaling is a likely outcome of an interaction. The upshot is that two agents with highly incompatible preferences may still find ways to communicate, but the more they see eye-to-eye, the more likely it is that communication will be viable.</p>
</abstract>
<funding-group><funding-statement>This work has been partially supported by a Beatriu de Pinós grant (<ext-link ext-link-type="uri" xlink:href="http://www10.gencat.cat/agaur_web/" xlink:type="simple">http://www10.gencat.cat/agaur_web/</ext-link>); the DGI, Spanish Goverment, research project FFI2010-15717; and The Graduate Center of the City University New York (<ext-link ext-link-type="uri" xlink:href="http://gc.cuny.edu/" xlink:type="simple">http://gc.cuny.edu/</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="6"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Many theorists have seen communication as a fundamentally cooperative phenomenon <xref ref-type="bibr" rid="pcbi.1003282-Lewis1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1003282-Tomasello1">[4]</xref>. In an evolutionary context, however, cooperation cannot be taken for granted, because of problems of subversion and free-riding <xref ref-type="bibr" rid="pcbi.1003282-Williams1">[5]</xref>. In the case of communication, these problems include both refusal to share information, and deception, or lying for one's own advantage. If lying is common, there is no point in listening to what anyone says. If no one is listening, there is no point in talking.</p>
<p>In recent work the situation is often sketched as follows: it is easy to see how communication can be viable if there is complete concordance of interests between senders and receivers of signs. Then communication can result in useful coordination and division of labor. There is no mystery about signaling within multicellular organisms, for example, including hormonal and cell-to-cell signaling (although conflicts of interest may arise even here: <xref ref-type="bibr" rid="pcbi.1003282-Haig1">[6]</xref>). In between-organism contexts, the problem of conflict of interest rapidly becomes acute. Special mechanisms are needed to explain how honesty is maintained. The main approach taken in recent years has been <italic>costly signaling theory</italic> <xref ref-type="bibr" rid="pcbi.1003282-Zahavi1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1003282-MaynardSmith1">[9]</xref>. Intrinsic costs of signaling prevent dishonesty, by differential expense to liars or differential benefits to the honest.</p>
<p>“Cheap talk” models, where signaling has no costs, have seen some development <xref ref-type="bibr" rid="pcbi.1003282-Crawford1">[10]</xref>–<xref ref-type="bibr" rid="pcbi.1003282-Wagner1">[15]</xref> but have been minor players in recent years. Here we use a novel method to examine ways that informative signaling can be sustained without cost in a range of situations of partial and low common interest. We use a version of the Lewis sender-receiver model <xref ref-type="bibr" rid="pcbi.1003282-Lewis1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003282-Skyrms1">[16]</xref>, and employ a method of sampling and analyzing cases drawn from a large space of games with different relationships between sender and receiver payoffs. We then offer generalizations based on analysis of the sample of cases. The analysis uses coarse-grained measures of common interest between sender and receiver, and attends also to a feature that interacts with common interest: the degree to which payoffs for an agent depend on different acts being produced in different states, the <italic>contingency of payoff</italic> for that agent.</p>
<p>We find that using a simple and intuitive measure of common interest based on comparisons of preference orderings over actions, it is possible, though rare, for informative signaling to be maintained at equilibrium with complete divergence of interests. We then construct a more fine-grained measure of common interest, one that is more demanding in its classification of a case as one of zero common interest, and find that informative signaling with zero common interest is possible in this stronger sense as well. Defining an <italic>information-using equilibrium</italic> as one where the receiver makes use of informative signals to guide behavior, the proportion of games that include at least one information-using equilibrium increases monotonically and rather smoothly with both measures of common interest. (See below, in the <xref ref-type="sec" rid="s2"><italic>Methods</italic></xref> section, for the equilibrium concept we use throughout the paper.) We then look at the equilibria that support the <italic>highest</italic> amount of information use for a given level of common interest, and again find a monotonic, though less smooth, relationship between degree of common interest and maximum information use. A third analysis, looking at the relationship between common interest and contingency of payoff for sender and receiver (defined below), yields more complicated results.</p>
<p>We conclude that informative signaling can be stable in situations of minimal, even zero, common interest. A combination of <italic>mixed strategies</italic> of signal use by both senders and receivers, and the selective <italic>pooling</italic> of states by the sender, makes possible the extreme cases of this phenomenon. Pooling alone can suffice in cases where divergence of interests is not so extreme. As interests converge, stability of informative signaling becomes easier to achieve. Our model complements other recent work on the adaptive importance of mixed strategies and partially informative signaling in evolution.</p>
</sec><sec id="s2" sec-type="methods">
<title>Methods</title>
<p>Our modeling framework draws on Lewis <xref ref-type="bibr" rid="pcbi.1003282-Lewis1">[1]</xref> and Skyrms <xref ref-type="bibr" rid="pcbi.1003282-Skyrms1">[16]</xref>. We assume that the world varies exogenously and has three equally probable states (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e001" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e002" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e003" xlink:type="simple"/></inline-formula>). The sender perceives (without error) the state of the world and responds by mapping states to signals (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e004" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e005" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e006" xlink:type="simple"/></inline-formula>). The mapping need not be one-to-one as the sender may “pool” some states, treating them equivalently, and the sender may also probabilistically “mix” signals in response to a given state. The receiver perceives (without error) the signal sent and maps signals to acts (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e007" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e008" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e009" xlink:type="simple"/></inline-formula>), with pooling and mixes possible again. So a combination of sender and receiver rules can be represented as follows:</p>
<p><bold>Sender:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e010" xlink:type="simple"/></inline-formula></p>
<p><bold>Receiver:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e011" xlink:type="simple"/></inline-formula></p>
<p>For example, the sender here sends message 1 whenever they see state 1, message 2 whenever they see state 2, and in state 3 they flip a biased coin to send message 1 two thirds of the time and message 3 one third of the time. Both sides receive payoffs as a consequence of the combination of the receiver's action and the state of the world. Sender and receiver payoffs may differ, and can be represented in the form seen in <xref ref-type="table" rid="pcbi-1003282-t001">Table 1</xref>.</p>
<table-wrap id="pcbi-1003282-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003282.t001</object-id><label>Table 1</label><caption>
<title>A payoff matrix.</title>
</caption><alternatives><graphic id="pcbi-1003282-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003282.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>1</sub></td>
<td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>2</sub></td>
<td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>3</sub></td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>A</italic><sub>1</sub></td>
<td align="left" rowspan="1" colspan="1">5,0</td>
<td align="left" rowspan="1" colspan="1">2,4</td>
<td align="left" rowspan="1" colspan="1">0,6</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>A</italic><sub>2</sub></td>
<td align="left" rowspan="1" colspan="1">6,5</td>
<td align="left" rowspan="1" colspan="1">0,0</td>
<td align="left" rowspan="1" colspan="1">1,5</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>A</italic><sub>3</sub></td>
<td align="left" rowspan="1" colspan="1">0,6</td>
<td align="left" rowspan="1" colspan="1">6,6</td>
<td align="left" rowspan="1" colspan="1">5,3</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt101"><p>The pair of numbers in each cell represent the sender's and the receiver's payoffs, respectively, for a receiver action (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e012" xlink:type="simple"/></inline-formula>) performed in a given state of the world (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e013" xlink:type="simple"/></inline-formula>).</p></fn></table-wrap-foot></table-wrap>
<p>The payoff matrix defines a preference ordering over acts in each state for both sender and receiver. For example, in <xref ref-type="table" rid="pcbi-1003282-t001">Table 1</xref>, the preference ordering for the sender in state 1 is [<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e014" xlink:type="simple"/></inline-formula>&gt;<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e015" xlink:type="simple"/></inline-formula>&gt;<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e016" xlink:type="simple"/></inline-formula>], and for the receiver [<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e017" xlink:type="simple"/></inline-formula>&gt;<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e018" xlink:type="simple"/></inline-formula>&gt;<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e019" xlink:type="simple"/></inline-formula>]. A simple measure of the degree of common interest in a game tracks how similar the orderings for sender and receiver are, for each state: there is <italic>complete common interest</italic> when sender and receiver have the same preference ordering over acts in every state, and <italic>complete conflict of interest</italic> when these orderings are reversed in every state. Between these extremes are various kinds of <italic>partial</italic> common interest: sender and receiver might agree on the best act in each state, but disagree otherwise; they might always agree on what is worst, but not otherwise; they might agree entirely in some states but disagree in others.</p>
<p>In cases of complete common interest, some consequences for informative signaling are easily seen. With complete common interest, sender and receiver can both receive their maximum payoffs when the sender maps states to signals one-to-one and the receiver uses these signals to guide appropriate actions. This is a <italic>signaling system</italic> in the sense of Lewis <xref ref-type="bibr" rid="pcbi.1003282-Lewis1">[1]</xref>, and neither party has any incentive to change what they are doing. This state might not be attained by the selection process shaping sender and receiver behaviors, but if it is reached it is stable <xref ref-type="bibr" rid="pcbi.1003282-Huttegger1">[17]</xref>. With complete conflict of interest, it would appear that signaling cannot be maintained, as any information about the state of the world carried by signals can be used by the receiver to produce acts contrary to the sender's interests, and any sensitivity to signals in the receiver can be exploited by the sender. Exploring the generality of this phenomenon is one aim of this paper. Another is quantifying the relationship between common interest and informative signaling.</p>
<p>The varieties of partial common interest described above do not form a complete ordering. However, a coarse-grained measure of the overall degree of common interest can be constructed by modifying the <italic>Kendall tau distance</italic>. This measure describes the similarity in the ordering of the items in two lists, by counting <italic>discordant pairs</italic> of items across the lists. The first two items in the two lists form a discordant pair with respect to a preference ordering, for example, if in list 1 the first item is preferred to the second item, whereas in list 2 the second item is preferred to the first. We define a measure <italic>C</italic> of the common interest in a payoff matrix of the form in <xref ref-type="table" rid="pcbi-1003282-t001">Table 1</xref> by counting the discordant pairs in the sender's and receiver's preference orderings over acts in each state of the world, and then averaging across states and rescaling the results to yield a number between 0 and 1, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e020" xlink:type="simple"/></inline-formula> corresponds to complete common interest and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e021" xlink:type="simple"/></inline-formula> corresponds to complete conflict of interest. In response to results outlined below we also make use of a refinement of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e022" xlink:type="simple"/></inline-formula>; which compares not only the agents' preference orderings of the actions in each state, but also tracks how the agents' payoffs for each action relate to the mean value of the payoffs the agent might receive in that state. (For details see <xref ref-type="supplementary-material" rid="pcbi.1003282.s001">Text S1</xref>.) As discussed below, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e023" xlink:type="simple"/></inline-formula> is one among several ways of refining the simpler measure, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e024" xlink:type="simple"/></inline-formula>, and we do not claim it is best for all purposes.</p>
<p>We also make use of a further description of payoff matrices. For each agent, how much does payoff depend on matching different actions to each state of the world? A simple illustration of the importance of this feature is seen in a case where the receiver has the same best act for every state (has a dominant strategy available). Then the receiver can achieve maximum payoff no matter what the sender does, by mapping all signals to that cover-all act. Even if no one act is best in all states, there may be a cover-all act that works well for an agent nearly all the time. This is a within-agent matter. So we define <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e025" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e026" xlink:type="simple"/></inline-formula>, also making use of the Kendall tau distance. For each agent, we compare the preference orderings over acts that apply in different states of the world, comparing each pair of states in turn. K is high for an agent with respect to a pair of states if good acts in one state are bad acts in the other state. K for an agent averages all comparisons of states, rescaled to lie between zero and one, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e027" xlink:type="simple"/></inline-formula> corresponds to the highest degree of contingency of payoff. (For details see <xref ref-type="supplementary-material" rid="pcbi.1003282.s001">Text S1</xref>.)</p>
<p>Our aim is to generalize about games with different levels of common interest and contingency of payoff for the agents. The method used is to generate samples from the space of games with three states where sender and receiver payoffs are integers between 0 and 99. Payoffs for each player for each act in a state are chosen randomly, so 18 random choices specify payoffs for a game. We then use the implementation of Lemke's <xref ref-type="bibr" rid="pcbi.1003282-Lemke1">[18]</xref> algorithm provided by the software package <italic>Gambit</italic> <xref ref-type="bibr" rid="pcbi.1003282-McKelvey1">[19]</xref> to search for equilibria in that game where informative signals are being sent and used. The equilibrium concept used is the Nash equilibrium: a pair of strategies form a Nash equilibrium if neither player can improve their payoff by unilaterally modifying their strategy.</p>
<p>We measure the degree to which agents engage in informative signaling with <italic>mutual information</italic>, a symmetrical measure of the degree of association between two variables, measured in bits <xref ref-type="bibr" rid="pcbi.1003282-Cover1">[20, p. 7]</xref>. An equilibrium is an <italic>information-using</italic> equilibrium if there is non-zero mutual information between states of the world and the receiver's acts. We focus on mutual information between states and acts for the following reasons. If there is mutual information between states and acts, the only way for this to arise is for senders to send informative signals and receivers to use these signals to guide variation in their actions to some extent. It is possible for senders to send signals with information about the state of the world that is not used – informative signals that are ignored by the receiver. It is possible also for receivers to guide actions with different signals sent randomly by the sender. The first of these – informative signals that are ignored – is a situation which may be an equilibrium and in which there is informative signaling, but it is not a situation in which the receiver is making use of that information. Our primary focus is situations in which informative signals are both sent and used. This requires that the signals carry information about states and acts carry information about signals. Given that receivers only have access to the state of the world by attending to signals, by the <italic>data processing inequality</italic> <xref ref-type="bibr" rid="pcbi.1003282-Cover1">[20, p. 34]</xref> it is not possible for acts to carry more information about states than signals do. (States, signals, and acts form a Markov chain.) Any mutual information between states and acts arises from the use by the receiver of information about states in the signals.</p>
<p>Computational methods are described in <xref ref-type="supplementary-material" rid="pcbi.1003282.s001">Text S1</xref> but one feature should be noted here: Lemke's algorithm is not guaranteed to find every equilibrium in a game <xref ref-type="bibr" rid="pcbi.1003282-Koller1">[21]</xref>. So the reports of information-using equilibria below may be under-counts.</p>
</sec><sec id="s3">
<title>Results</title>
<p>To investigate the role of <italic>C</italic> we generated a random sample from the space of games with three equiprobable states, three receiver actions, and independently chosen payoffs for sender and receiver associated with each receiver action in each state of the world. (Each value of <italic>C</italic> is represented by 1500 games.) These sender and receiver payoffs are integers between 0 and 99. For each game we asked whether there is at least one information-using equilibrium in that game – an equilibrium with nonzero mutual information between states and acts – and then asked what proportion of games at each level of <italic>C</italic> have at least one information-using equilibrium. (All these games also have equilibria that are not information-using equilibria). The results are shown in <xref ref-type="fig" rid="pcbi-1003282-g001">Figure 1</xref>.</p>
<fig id="pcbi-1003282-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003282.g001</object-id><label>Figure 1</label><caption>
<title>The proportion of games at each level of <italic>C</italic> with at least one information-using equilibrium.</title>
<p>For each value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e028" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e029" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003282.g001" position="float" xlink:type="simple"/></fig>
<p>Very low degrees of <italic>C</italic> suffice to enable information-using equilibria, but at low <italic>C</italic> levels, only a small minority of games do so (unless the algorithm used has significant bias). As <italic>C</italic> increases, the fraction of games with information-using equilibria increases monotonically.</p>
<p>The curve in <xref ref-type="fig" rid="pcbi-1003282-g001">Figure 1</xref> does not reach 100% for the case of complete common interest. Some games with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e030" xlink:type="simple"/></inline-formula> are games with zero <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e031" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e032" xlink:type="simple"/></inline-formula>. (When <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e033" xlink:type="simple"/></inline-formula>, K is the same for sender and receiver.) The same act is best in every state. Around 1/9 games with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e034" xlink:type="simple"/></inline-formula> will also be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e035" xlink:type="simple"/></inline-formula>. In such a game, the receiver can always take the system to an equilibrium by mapping all signals to the same, optimal, act. Then there is no mutual information between states and acts, regardless of what the sender is doing, as there is no variation in acts.</p>
<p>Surprisingly, a small number of games with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e036" xlink:type="simple"/></inline-formula>, where sender and receiver have reversed preference orderings over acts in every state, have information-using equilibria. <xref ref-type="table" rid="pcbi-1003282-t002">Table 2</xref> shows a case of this kind – not a case from one of our samples, but a simplified case constructed using the computer-generated cases as a guide.</p>
<table-wrap id="pcbi-1003282-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003282.t002</object-id><label>Table 2</label><caption>
<title>A game with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e037" xlink:type="simple"/></inline-formula> and an information-using equilibrium.</title>
</caption><alternatives><graphic id="pcbi-1003282-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003282.t002" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>1</sub></td>
<td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>2</sub></td>
<td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>3</sub></td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>A</italic><sub>1</sub></td>
<td align="left" rowspan="1" colspan="1">5,5</td>
<td align="left" rowspan="1" colspan="1">2,4</td>
<td align="left" rowspan="1" colspan="1">2,1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>A</italic><sub>2</sub></td>
<td align="left" rowspan="1" colspan="1">6,0</td>
<td align="left" rowspan="1" colspan="1">0,6</td>
<td align="left" rowspan="1" colspan="1">3,0</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>A</italic><sub>3</sub></td>
<td align="left" rowspan="1" colspan="1">0,6</td>
<td align="left" rowspan="1" colspan="1">6,0</td>
<td align="left" rowspan="1" colspan="1">0,3</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p>Despite zero <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e038" xlink:type="simple"/></inline-formula>, the game in <xref ref-type="table" rid="pcbi-1003282-t002">Table 2</xref> has an information-using equilibrium, whose sender and receiver rules are as follows:</p>
<p><bold>Sender:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e039" xlink:type="simple"/></inline-formula></p>
<p><bold>Receiver:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e040" xlink:type="simple"/></inline-formula></p>
<p>The mutual information between states and acts at this equilibrium is 0.67 bits, where the highest possible value for a game with three equiprobable states (a Lewisian signaling system) is 1.58 bits.</p>
<p>A feature of the case in <xref ref-type="table" rid="pcbi-1003282-t002">Table 2</xref> is that although sender and receiver have reversed preferences in every state, in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e041" xlink:type="simple"/></inline-formula> they share a second-best outcome (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e042" xlink:type="simple"/></inline-formula>) that is almost as good as their best. This is ignored by our measure <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e043" xlink:type="simple"/></inline-formula>, and it is one kind of common interest between the two agents. A way to modify <italic>C</italic> that takes this factor into account is to compare, across sender and receiver, their preference orderings over both the payoffs that arise from different actions and also the average of the payoffs for that agent in that state. This is done by defining a “dummy act” for the receiver in each state, an act that secures for each agent the mean of the other payoffs possible in that state. This dummy act and its payoff are then included in the determination of each agent's preference ordering over acts in that state; the two agents might agree, or disagree, for example, about whether the payoff of Act 1 is higher than the mean of their payoffs possible in that state. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e044" xlink:type="simple"/></inline-formula>, like <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e045" xlink:type="simple"/></inline-formula>, counts discordant pairs of preferences and is scaled to lie between 0 and 1. (For further details see <xref ref-type="supplementary-material" rid="pcbi.1003282.s001">Text S1</xref>). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e046" xlink:type="simple"/></inline-formula> yields a similar relationship between common interest and the proportion of games with an information-using equilibrium to that seen in <xref ref-type="fig" rid="pcbi-1003282-g001">Figure 1</xref>.</p>
<p>The game in <xref ref-type="table" rid="pcbi-1003282-t002">Table 2</xref> has a nonzero <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e047" xlink:type="simple"/></inline-formula>, as sender and receiver agree about how one of their second-best outcomes compares to their means for that state, so <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e048" xlink:type="simple"/></inline-formula> is a more demanding criterion for complete conflict of interest. Even in this stronger sense, though, it is possible for a game to have an information-using equilibrium with complete conflict of interest. A case of this kind, also one modeled on a less transparent computer-generated case, is shown in <xref ref-type="table" rid="pcbi-1003282-t003">Table 3</xref>. This game has the following information-using equilibrium:</p>
<table-wrap id="pcbi-1003282-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003282.t003</object-id><label>Table 3</label><caption>
<title>A game with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e049" xlink:type="simple"/></inline-formula> and an information-using equilibrium.</title>
</caption><alternatives><graphic id="pcbi-1003282-t003-3" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003282.t003" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>1</sub></td>
<td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>2</sub></td>
<td align="left" rowspan="1" colspan="1"><italic>S</italic><sub>3</sub></td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>A</italic><sub>1</sub></td>
<td align="left" rowspan="1" colspan="1">1,8</td>
<td align="left" rowspan="1" colspan="1">8,1</td>
<td align="left" rowspan="1" colspan="1">0,6</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>A</italic><sub>2</sub></td>
<td align="left" rowspan="1" colspan="1">3,7</td>
<td align="left" rowspan="1" colspan="1">6,3</td>
<td align="left" rowspan="1" colspan="1">1,5</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>A</italic><sub>3</sub></td>
<td align="left" rowspan="1" colspan="1">8,1</td>
<td align="left" rowspan="1" colspan="1">1,8</td>
<td align="left" rowspan="1" colspan="1">5,3</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p><bold>Sender:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e050" xlink:type="simple"/></inline-formula></p>
<p><bold>Receiver:</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e051" xlink:type="simple"/></inline-formula></p>
<p>In all the cases with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e052" xlink:type="simple"/></inline-formula> and/or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e053" xlink:type="simple"/></inline-formula> with information-using equilibria we have found, the underlying pattern is as follows. Two signals are used by the sender and three acts are used by the receiver. In one state the receiver produces an act that is intermediate in value for both sides. In the cases in <xref ref-type="table" rid="pcbi-1003282-t002">Tables 2</xref> and <xref ref-type="table" rid="pcbi-1003282-t003">3</xref>, this is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e054" xlink:type="simple"/></inline-formula>. The receiver is prevented from shifting to their optimal act for this state by the fact that the signal sent in that state is ambiguous, and is sometimes also sent in a state for which the act that might “tempt” the receiver in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e055" xlink:type="simple"/></inline-formula> would be very bad. In another state, the receiver mixes their actions between optimal acts for each side. (This is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e056" xlink:type="simple"/></inline-formula> in both <xref ref-type="table" rid="pcbi-1003282-t002">Tables 2</xref> and <xref ref-type="table" rid="pcbi-1003282-t003">3</xref>.) Again, the receiver is prevented from settling on their optimal act in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e057" xlink:type="simple"/></inline-formula> by the fact that the message the sender sends in that state is ambiguous; state 2 is used by the sender to deter exploitation in the other two states, and in this state all three acts are produced.</p>
<p>In both cases in <xref ref-type="table" rid="pcbi-1003282-t002">Tables 2</xref> and <xref ref-type="table" rid="pcbi-1003282-t003">3</xref> the information-using equilbria are very fragile, as either the sender (in 3) or the receiver (in 2) can shift without penalty to a strategy in which the mutual information between states and acts goes to zero. Not all cases of information-using equilbria and zero common interest have this feature, however; sometimes information-use is less easily lost. The lowest level of common interest at which an information-using equilibrium is found in which neither sender nor receiver plays a mixed strategy, probabilistically varying their response to a state or a signal, is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e058" xlink:type="simple"/></inline-formula> (see <xref ref-type="supplementary-material" rid="pcbi.1003282.s001">Text S1</xref> for examples of both phenomena described in this paragraph).</p>
<p>A valuable feature of <italic>C</italic> is the weakness of the assumptions required for its measurement; <italic>C</italic> assumes only ordinal, not cardinal, utilities. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e059" xlink:type="simple"/></inline-formula> assumes cardinal utilities. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e060" xlink:type="simple"/></inline-formula> does not, however, assume that sender and receiver utilities are commensurable. If that further assumption is made, the notion of zero common interest can be analyzed instead by requiring that in every state, sender and receiver payoffs sum to a constant and the choice of action determines only how the division is made (a “constant-sum game”). We do not claim in this paper that information-using equilibria exist in constant-sum games. All constant-sum games have <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e061" xlink:type="simple"/></inline-formula>, though the converse does not hold. Some constant-sum games have nonzero <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e062" xlink:type="simple"/></inline-formula>, on the other hand, and not all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e063" xlink:type="simple"/></inline-formula> games are constant-sum. Due to its simplicity and weak assumptions, in the remainder of the body of this paper we will use <italic>C</italic> to measure common interest. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e064" xlink:type="simple"/></inline-formula> and constant-sum games are discussed in <xref ref-type="supplementary-material" rid="pcbi.1003282.s001">Text S1</xref>.</p>
<p>Once we know how likely a given level of <italic>C</italic> is to maintain at least one information-using equilibrium, we can also ask what is the highest level of mutual information between states and acts that can be maintained in a game with a given degree of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e065" xlink:type="simple"/></inline-formula>. <xref ref-type="fig" rid="pcbi-1003282-g002">Figure 2</xref> shows the maximum amount of mutual information between states and acts generated by an equilibrium pair of strategies from any game examined with a given level of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e066" xlink:type="simple"/></inline-formula>. In constructing the pool of cases for this analysis, we have included not just the sample of games used in <xref ref-type="fig" rid="pcbi-1003282-g001">Figure 1</xref> but also games found in earlier samples.</p>
<fig id="pcbi-1003282-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003282.g002</object-id><label>Figure 2</label><caption>
<title>The highest level of information use at each level of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e067" xlink:type="simple"/></inline-formula>.</title>
<p>Measured in bits. For each value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e068" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e069" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003282.g002" position="float" xlink:type="simple"/></fig>
<p><xref ref-type="fig" rid="pcbi-1003282-g002">Figure 2</xref> shows that the highest value for information use grows monotonically with common interest, as expected, but in a step-like way and with quite high values of mutual information between states and acts seen even at the lowest values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e070" xlink:type="simple"/></inline-formula>. Conversely, our sample includes cases with high values of <italic>C</italic> and very minimal information use at equilibrium (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e071" xlink:type="simple"/></inline-formula>, mutual information = 0.03 bits; see <xref ref-type="supplementary-material" rid="pcbi.1003282.s001">Text S1</xref>).</p>
<p>A further analysis of these cases takes into account the contingency of payoff for sender and receiver, as well as common interest. The importance of this factor has been evident already in some extreme cases. When there is complete common interest but K is zero for both sides, there is no problem for signaling to solve – a single act always delivers an optimal payoff. When there is less common interest, the contingency of payoff for sender and receiver can diverge, and in most cases will be different. <xref ref-type="fig" rid="pcbi-1003282-g003">Figure 3</xref> charts the proportion of games with at least one information-using equilibrium as a function of both common interest and contingency of payoff for an agent; separate graphs are given for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e072" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e073" xlink:type="simple"/></inline-formula> (left), and for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e074" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e075" xlink:type="simple"/></inline-formula> (right). The sample used for this chart is not the same one used for <xref ref-type="fig" rid="pcbi-1003282-g001">Figure 1</xref>, as a random sample of all games with a certain <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e076" xlink:type="simple"/></inline-formula> under-represents some combinations of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e077" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e078" xlink:type="simple"/></inline-formula>. <xref ref-type="fig" rid="pcbi-1003282-g003">Figure 3</xref> uses a sample in which every combination of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e079" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e080" xlink:type="simple"/></inline-formula> is represented by 1500 games.</p>
<fig id="pcbi-1003282-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003282.g003</object-id><label>Figure 3</label><caption>
<title>Relation between common interest, contingency of payoff for each agent, and the proportion of games with an information-using equilibrium.</title>
<p>See <xref ref-type="supplementary-material" rid="pcbi.1003282.s001">Text S1</xref> for explanations of C, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e081" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e082" xlink:type="simple"/></inline-formula>. 1500 games were sampled and analyzed for each jointly possible combination of <italic>C</italic> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e083" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e084" xlink:type="simple"/></inline-formula>).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003282.g003" position="float" xlink:type="simple"/></fig>
<p>As expected, higher values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e085" xlink:type="simple"/></inline-formula> generate more information-using equilibria than lower values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e086" xlink:type="simple"/></inline-formula>. A difference is seen, however, between the consequences of low values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e087" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e088" xlink:type="simple"/></inline-formula>. When the sender's contingency of payoff is very low, the intermediate values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e089" xlink:type="simple"/></inline-formula> present a local maximum in the proportion of games with information-using equilibria. When <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e090" xlink:type="simple"/></inline-formula> is low and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e091" xlink:type="simple"/></inline-formula> is intermediate, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e092" xlink:type="simple"/></inline-formula> will be appreciable. The receiver seeks to vary their actions with the state of the world, and though the sender would ideally like the same act to always be performed, equilibria exist in which a compromise is reached. When the receiver's <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e093" xlink:type="simple"/></inline-formula> is low, on the other hand, they can achieve optimal payoffs by mapping every signal to the same act. The receiver can “go it alone” (though information-using equilibria arise in a few cases with high <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e094" xlink:type="simple"/></inline-formula> because of ties for the optimal act in a state).</p>
</sec><sec id="s4">
<title>Discussion</title>
<p>We have given a treatment of the relation between informative signaling and common interest between sender and receiver, in a framework where signal use is associated with no differential costs and no role is given to iteration of interactions between agents. We find that informative signaling is possible in situations where sender and receiver have reversed preference orderings over receiver actions in every state of the world. This situation, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e095" xlink:type="simple"/></inline-formula>, is one sense of “complete conflict of interest,” and a sense that has been employed more informally in a range of earlier discussions (eg., <xref ref-type="bibr" rid="pcbi.1003282-MaynardSmith2">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1003282-Searcy1">[23]</xref>. In the light of our results, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e096" xlink:type="simple"/></inline-formula> is shown to be a somewhat undemanding sense of complete conflict. We discussed one refinement of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e097" xlink:type="simple"/></inline-formula>, which requires stronger assumptions about payoffs, and found that information use at equilibrium is possible with complete conflict even in this stronger sense, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e098" xlink:type="simple"/></inline-formula>. Another way to refine the idea of complete conflict, a way that uses still stronger assumptions, is by appeal to the notion of a constant-sum game. We do not claim that informative signaling is possible at equilibrium in constant-sum games. Another way to interpret our results is to suggest that the degree of conflict of interest in a game cannot be analyzed by noting the relationships holding between preferences in particular states, and then generalizing across states. Moving beyond consideration of these extreme values, we find that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e099" xlink:type="simple"/></inline-formula> is a good predictor of the existence of information-using equilibria in the space of games studied in this paper.</p>
<p>We note several limitations of our model. First, the model assumes a particular relationship between sender and receiver, one where the sender has private knowledge of a state of the world, and payoffs result from the coordination of receiver actions with this state. This “state” of the world might be the condition or quality of the sender. Another kind of model assumes that neither side has privileged information about the state of the world, and the role of signaling is to coordinate acts with acts rather than acts with states (the “battle of the sexes,” for example). In further work we hope to extend our analysis to cover these cases. Another limitation involves our use of the Nash equilibrium concept. A Nash equilibrium need not be an evolutionarily stable strategy (because rivals may increase in frequency due to “drift”). In addition, equilibria of this kind may not be easily found by an evolutionary process <xref ref-type="bibr" rid="pcbi.1003282-Huttegger1">[17]</xref>. Further work is needed to explore the dynamic properties of the games discussed in this paper. Thirdly, our analysis gives no role to the biological plausibility of games.</p>
<p>We close by comparing our treatment with two other papers, one classic and one recent. First, Crawford and Sobel <xref ref-type="bibr" rid="pcbi.1003282-Crawford1">[10]</xref> treated agreement in interests as a matter of degree, and found that when interests diverge, honest signaling is possible, but with lower informational content than there would be with complete agreement: “equilibrium signaling is more informative when agents' preferences are more similar.” In their model, the state of the world (sender quality) and the available actions both vary continuously in one dimension, and the difference between sender and receiver interests corresponds to a constant that is the difference between the actions seen as optimal by sender and by receiver in a given state of the world. In their model the degree of common interest across games can be measured exactly, but the model makes strong assumptions about the pattern of variation in the world. Our model makes weaker assumptions in this area, with the consequence that common interest is only partially ordered, motivating the introduction of coarse-grained measures such as <italic>C</italic> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e100" xlink:type="simple"/></inline-formula>. Crawford and Sobel found that as agents' interest converge, a larger number of distinct signals can be sent at equilibrium. We found that informative signaling can exist with zero common interest, through a combination of pooling and mixing, though games of this kind are rare and the proportion of games with an information-using equilibrium increases as interests converge. Crawford and Sobel's model also did not allow for variation in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e101" xlink:type="simple"/></inline-formula>, which we find has significant effects on the viability of information use.</p>
<p>Second, Zollman <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1003282-Zollman1">[24]</xref> investigated biologically plausible games with two possible states of the world (again, sender quality) that are usually analyzed with substantial differential costs enforcing honesty. These authors found that very small differences in cost or benefit across different types of senders can maintain honest signaling when both sender and receiver mix strategies in a particular way. Senders in one state mix two signals, and senders in another state send just one of those signals. Receivers mix their responses to the ambiguous signal and do not mix their responses to the other. A conclusion from their model is that variation in signal-using behavior within a given situation, on both sender and receiver sides, need not be a matter of mere “noise” but can be an essential feature of an equilibrium state. Our results, within a framework of zero signal cost, lead to a conclusion of the same kind: probabilistic mixing of strategies, along with partial “pooling” of inputs, by both sign producers and sign interpreters can be important in maintaining signaling in situations of low common interest.</p>
</sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003282.s001" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003282.s001" position="float" xlink:type="simple"><label>Text S1</label><caption>
<p>Methods – definitions – additional examples – <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e102" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003282.e103" xlink:type="simple"/></inline-formula>, and constant-sum games – Interactions between common interest and contingency of payoff.</p>
<p>(PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We are grateful to Simon Huttegger, Ron Planer, Gill Shen, Rory Smead, Elliott Wagner, and Kevin Zollman for helpful comments on an earlier draft.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003282-Lewis1"><label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">Lewis D (1969) Convention. Cambridge: Harvard University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Grice1"><label>2</label>
<mixed-citation publication-type="book" xlink:type="simple">Grice P (1975) Logic and conversation. In: Cole P, Morgan J, editors, Syntax and Semantics, vol. 3: Speech Acts, New York: Academic Press.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Millikan1"><label>3</label>
<mixed-citation publication-type="book" xlink:type="simple">Millikan R (1984) Language, Thought and Other Biological Categories. Cambridge MA: The MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Tomasello1"><label>4</label>
<mixed-citation publication-type="book" xlink:type="simple">Tomasello M (2008) Origins of Human Communication. Cambridge MA: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Williams1"><label>5</label>
<mixed-citation publication-type="book" xlink:type="simple">Williams GC (1966) Adaptation and Natural Selection: A Critique of Some Current Evolutionary Thought. Berkeley: University of California Press.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Haig1"><label>6</label>
<mixed-citation publication-type="book" xlink:type="simple">Haig D (2008) Conicting messages: Genomic imprinting and internal communication. In: d'Ettore P, Hughes D, editors, Sociobiology of Communication: An Interdisciplinary Perspective, Oxford: Oxford University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Zahavi1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zahavi</surname><given-names>A</given-names></name> (<year>1975</year>) <article-title>Mate selection – selection for a handicap</article-title>. <source>Journal of Theoretical Biology</source> <volume>53</volume>: <fpage>205</fpage>–<lpage>214</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Grafen1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grafen</surname><given-names>A</given-names></name> (<year>1990</year>) <article-title>Biological signals as handicaps</article-title>. <source>Journal of Theoretical Biology</source> <volume>144</volume>: <fpage>517</fpage>–<lpage>546</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-MaynardSmith1"><label>9</label>
<mixed-citation publication-type="book" xlink:type="simple">Maynard-Smith J, Harper D (2003) Animal Signals. Oxford: Oxford University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Crawford1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Crawford</surname><given-names>VP</given-names></name>, <name name-style="western"><surname>Sobel</surname><given-names>J</given-names></name> (<year>1982</year>) <article-title>Strategic information transmission</article-title>. <source>Econometrica</source> <volume>50</volume>: <fpage>1431</fpage>–<lpage>1451</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Farrell1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Farrell</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Rabin</surname><given-names>M</given-names></name> (<year>1996</year>) <article-title>Cheap talk</article-title>. <source>Journal of Economic Perspectives</source> <volume>10</volume>: <fpage>103</fpage>–<lpage>118</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Bergstrom1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bergstrom</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Lachmann</surname><given-names>M</given-names></name> (<year>1998</year>) <article-title>Signaling among relatives iii. talk is cheap</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>95</volume>: <fpage>5100</fpage>–<lpage>5105</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Silk1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Silk</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Kaldor</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Boyd</surname><given-names>R</given-names></name> (<year>2000</year>) <article-title>Cheap talk when interests conict</article-title>. <source>Animal Behavior</source> <volume>59</volume>: <fpage>423</fpage>–<lpage>432</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Bradbury1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bradbury</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Vehrencamp</surname><given-names>S</given-names></name> (<year>2000</year>) <article-title>Economic models of animal communication</article-title>. <source>Animal Behavior</source> <volume>59</volume>: <fpage>259</fpage>–<lpage>268</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Wagner1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wagner</surname><given-names>E</given-names></name> (<year>2012</year>) <article-title>Deterministic chaos and the evolution of meaning</article-title>. <source>British Journal for the Philosophy of Science</source> <volume>63</volume>: <fpage>547</fpage>–<lpage>575</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Skyrms1"><label>16</label>
<mixed-citation publication-type="book" xlink:type="simple">Skyrms B (2010) Signals: Evolution, Learning &amp; Information. New York: Oxford University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Huttegger1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huttegger</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Skyrms</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Smead</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Zollman</surname><given-names>K</given-names></name> (<year>2010</year>) <article-title>Evolutionary dynamics of lewis signaling games: Signaling systems vs. partial pooling</article-title>. <source>Synthese</source> <volume>172</volume>: <fpage>177</fpage>–<lpage>191</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Lemke1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lemke</surname><given-names>CE</given-names></name> (<year>1965</year>) <article-title>Bimatrix equilibrium points and mathematical programming</article-title>. <source>Management Science</source> <volume>11</volume>: <fpage>681</fpage>–<lpage>689</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-McKelvey1"><label>19</label>
<mixed-citation publication-type="other" xlink:type="simple">McKelvey RD, McLennan AM, Turocy TL (2010). Gambit: Software tools for game theory. Available: <ext-link ext-link-type="uri" xlink:href="http://www.gambit-project.org" xlink:type="simple">http://www.gambit-project.org</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Cover1"><label>20</label>
<mixed-citation publication-type="book" xlink:type="simple">Cover TM, Thomas JA (2006) Elements of Information Theory. New York: Wiley.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Koller1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koller</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Meggido</surname><given-names>N</given-names></name>, <name name-style="western"><surname>von Stengel</surname><given-names>B</given-names></name> (<year>1996</year>) <article-title>Efficient computation of equilibria for extensive two-person games</article-title>. <source>Games and Economic Behavior</source> <volume>14</volume>: <fpage>247</fpage>–<lpage>259</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-MaynardSmith2"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maynard-Smith</surname><given-names>J</given-names></name> (<year>1994</year>) <article-title>Must reliable signals always be costly</article-title>? <source>Animal Behavior</source> <volume>47</volume>: <fpage>1115</fpage>–<lpage>1120</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Searcy1"><label>23</label>
<mixed-citation publication-type="book" xlink:type="simple">Searcy WA, Nowicki S (2005) The Evolution of Animal Communication – Reliability and Deception in Signaling Games. Princeton: Princeton University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003282-Zollman1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zollman</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Bergstrom</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Huttegger</surname><given-names>S</given-names></name> (<year>2013</year>) <article-title>Between cheap and costly signals: The evolution of partial honest communication</article-title>. <source>Proceedings of the Royal Society B</source> <volume>280</volume> (<issue>1750</issue>) <fpage>20121878</fpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
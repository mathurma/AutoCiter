<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">10-PLCB-RA-2603</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002123</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Sensory systems</subject>
              <subj-group>
                <subject>Auditory system</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Computational neuroscience</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Understanding Auditory Spectro-Temporal Receptive Fields and Their Changes with Input Statistics by Efficient Coding Principles</article-title><alt-title alt-title-type="running-head">Understanding Auditory STRF from Efficient Coding</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Zhao</surname>
            <given-names>Lingyun</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Zhaoping</surname>
            <given-names>Li</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Department of Biomedical Engineering, School of Medicine, Tsinghua University, Beijing, P.R. China</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Department of Computer Science, University College London, London, United Kingdom</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Graham</surname>
            <given-names>Lyle J.</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Université Paris Descartes, Centre National de la Recherche Scientifique, France</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">z.li@ucl.ac.uk</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: L. Zhao, L. Zhaoping. Performed the experiments: L. Zhao, L. Zhaoping. Analyzed the data: L. Zhao, L. Zhaoping. Wrote the paper: L. Zhao, L. Zhaoping. Began the project as a course project: L. Zhao. Supervised and completed the project: L. Zhaoping.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>8</month>
        <year>2011</year>
      </pub-date><pub-date pub-type="epub">
        <day>18</day>
        <month>8</month>
        <year>2011</year>
      </pub-date><volume>7</volume><issue>8</issue><elocation-id>e1002123</elocation-id><history>
        <date date-type="received">
          <day>27</day>
          <month>7</month>
          <year>2010</year>
        </date>
        <date date-type="accepted">
          <day>31</day>
          <month>5</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Zhao, Zhaoping</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Spectro-temporal receptive fields (STRFs) have been widely used as linear approximations to the signal transform from sound spectrograms to neural responses along the auditory pathway. Their dependence on statistical attributes of the stimuli, such as sound intensity, is usually explained by nonlinear mechanisms and models. Here, we apply an efficient coding principle which has been successfully used to understand receptive fields in early stages of visual processing, in order to provide a computational understanding of the STRFs. According to this principle, STRFs result from an optimal tradeoff between maximizing the sensory information the brain receives, and minimizing the cost of the neural activities required to represent and transmit this information. Both terms depend on the statistical properties of the sensory inputs and the noise that corrupts them. The STRFs should therefore depend on the input power spectrum and the signal-to-noise ratio, which is assumed to increase with input intensity. We analytically derive the optimal STRFs when signal and noise are approximated as Gaussians. Under the constraint that they should be spectro-temporally local, the STRFs are predicted to adapt from being band-pass to low-pass filters as the input intensity reduces, or the input correlation becomes longer range in sound frequency or time. These predictions qualitatively match physiological observations. Our prediction as to how the STRFs should be determined by the input power spectrum could readily be tested, since this spectrum depends on the stimulus ensemble. The potentials and limitations of the efficient coding principle are discussed.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>Spectro-temporal receptive fields (STRFs) have been widely used as linear approximations of the signal transform from sound spectrograms to neural responses along the auditory pathway. Their dependence on the ensemble of input stimuli has usually been examined mechanistically as a possibly complex nonlinear process. We propose that the STRFs and their dependence on the input ensemble can be understood by an efficient coding principle, according to which the responses of the encoding neurons report the maximum amount of information about the sensory input, subject to limits on the neural cost in representing and transmitting information. This proposal is inspired by the success of the same principle in accounting for receptive fields in the early stages of the visual pathway and their adaptation to input statistics. The principle can account for the STRFs that have been observed, and the way they change with sound intensity. Further, it predicts how the STRFs should change with input correlations, an issue that has not been extensively investigated. In sum, our study provides a computational understanding of the neural transformations of auditory inputs, and makes testable predictions for future experiments.</p>
      </abstract><funding-group><funding-statement>The authors were funded by the Gatsby Charitable Foundation, Tsinghua University 985 fund, and National Science Foundation of China grant 60675029. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="16"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>In response to acoustic input signals, neurons in the auditory pathway are typically selective to sound frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e001" xlink:type="simple"/></inline-formula> and have particular response latencies. At least ignoring cases with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e002" xlink:type="simple"/></inline-formula> kHz, in which neuronal responses often phase lock to the sound waves, a spectro-temporal receptive field (STRF) is often used to describe the tuning properties of a neuron <xref ref-type="bibr" rid="pcbi.1002123-Aertsen1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Escabi1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Klein1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Theunissen1">[4]</xref>. This is a two-dimensional function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e003" xlink:type="simple"/></inline-formula> that reports the sensitivity of the neuron at response latency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e004" xlink:type="simple"/></inline-formula> to acoustic inputs of frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e005" xlink:type="simple"/></inline-formula> for a given stimulus ensemble (i.e., given input statistics). More specifically, in a stimulus ensemble, the power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e006" xlink:type="simple"/></inline-formula> of the acoustic input at frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e007" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e008" xlink:type="simple"/></inline-formula> fluctuates around an average level denoted by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e009" xlink:type="simple"/></inline-formula>. If we let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e010" xlink:type="simple"/></inline-formula> denote the neuron's response at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e011" xlink:type="simple"/></inline-formula> (typically its spike rate), then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e012" xlink:type="simple"/></inline-formula> best approximates the linear relationship between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e013" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e014" xlink:type="simple"/></inline-formula> in this stimulus ensemble as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e015" xlink:type="simple"/><label>(1)</label></disp-formula>Note that in this paper, we refer to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e016" xlink:type="simple"/></inline-formula> as the input spectrogram, although some authors also include the average input power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e017" xlink:type="simple"/></inline-formula>. Though <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e018" xlink:type="simple"/></inline-formula> is not a full description of acoustic input, since it ignores features such as the phase of the oscillation in the sound wave, it is the only relevant aspect of the auditory input as far as the STRF is concerned. Note that if we use <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e019" xlink:type="simple"/></inline-formula> to denote the deviation of the neural response from its spontaneous activity level, then both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e020" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e021" xlink:type="simple"/></inline-formula> have zero mean. We will use this simplification throughout the paper. In studies in which the temporal dimension is omitted, the STRF is called the spectral receptive field (SRF).</p>
      <p><xref ref-type="fig" rid="pcbi-1002123-g001">Figure 1</xref> cartoons a typical STRF. This has excitatory and inhibitory regions, reflecting its preferred frequency and response latency. For example, if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e022" xlink:type="simple"/></inline-formula> peaks at frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e023" xlink:type="simple"/></inline-formula> and time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e024" xlink:type="simple"/></inline-formula>, then this neuron prefers frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e025" xlink:type="simple"/></inline-formula> and should respond to an input impulse <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e026" xlink:type="simple"/></inline-formula> of this frequency with latency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e027" xlink:type="simple"/></inline-formula>. We will also refer to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e028" xlink:type="simple"/></inline-formula> as the receptive field, the filter kernel, or the transfer function from input to neural responses, as these all convey the same or similar meanings. A neuron's STRF is typically estimated using reverse correlation methods <xref ref-type="bibr" rid="pcbi.1002123-Eggermont1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Theunissen1">[4]</xref>.</p>
      <fig id="pcbi-1002123-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002123.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>A schematic example of a typical spectro-temporal receptive field, plotted with a reversed abscissa.</title>
          <p>This STRF has one excitatory and three inhibitory regions, prefers frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e029" xlink:type="simple"/></inline-formula>, and evokes response at a typical latency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e030" xlink:type="simple"/></inline-formula>. Since the response at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e031" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e032" xlink:type="simple"/></inline-formula>, an input stimulus <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e033" xlink:type="simple"/></inline-formula> exactly as depicted in this plot is most likely to elicit a large response <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e034" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e035" xlink:type="simple"/></inline-formula>, or indeed a spike.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.g001" xlink:type="simple"/>
      </fig>
      <p>However, there are extensive nonlinearities in the signal transformation along the auditory pathway. Indeed, the STRF formulation of neural responses, though linear in spectral power, is already a second-order nonlinear function of the auditory sound wave. There are two kinds of nonlinearities when inputs are represented as spectrograms. The simpler one is a static nonlinearity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e036" xlink:type="simple"/></inline-formula>, which when applied to the linear approximation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e037" xlink:type="simple"/></inline-formula> of equation (1) enables better predictions of the neural responses <xref ref-type="bibr" rid="pcbi.1002123-Eggermont2">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Lesica1">[7]</xref>. This static nonlinearity however does not alter the spectro-temporal selectivity of the neuron seen in the linear STRF. This paper is interested in the more complex nonlinearity that the STRFs are dependent on the stimulus ensemble used to estimate them <xref ref-type="bibr" rid="pcbi.1002123-Aertsen1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Eggermont1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Eggermont3">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Christianson1">[9]</xref>. For example, the STRFs are wider when the stimuli are narrow-band rather than wide-band <xref ref-type="bibr" rid="pcbi.1002123-Gourevitch1">[10]</xref>, or when the stimuli are animal vocalizations rather than noise <xref ref-type="bibr" rid="pcbi.1002123-Woolley1">[11]</xref>. The STRF (or SRF) also becomes more band-pass when sound intensity increases. The dependence of the STRFs on the stimulus ensemble holds, for example, for type IV neurons in the cochlear nucleus of cats <xref ref-type="bibr" rid="pcbi.1002123-Yu1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Young1">[13]</xref>, the inferior colliculus (IC) of the frog <xref ref-type="bibr" rid="pcbi.1002123-Eggermont3">[8]</xref> and the gerbil <xref ref-type="bibr" rid="pcbi.1002123-Lesica1">[7]</xref>, and field L region of the songbird (which is analogous to mammalian auditory cortex) <xref ref-type="bibr" rid="pcbi.1002123-Nagel1">[14]</xref>. (The dependence on sound intensity also holds for the linear relationship between the auditory nerve responses and input sound waves <xref ref-type="bibr" rid="pcbi.1002123-Eggermont1">[5]</xref>). Nonlinearities in the auditory system become progressively stronger further from the periphery.</p>
      <p>Despite the nonlinearities, the concept of the STRF is still widely used, not only because it provides a meaningful description of the spectro-temporal selectivity of the neurons in a given stimulus ensemble, but also because it can predict neural responses to novel stimuli reasonably well, as long as the stimuli are drawn from the same stimulus ensemble as that used to estimate the STRF in the first place. Reasonable predictions from the STRFs have been obtained for the responses of auditory nerves(see <xref ref-type="bibr" rid="pcbi.1002123-Kim1">[15]</xref>) and auditory midbrain neurons <xref ref-type="bibr" rid="pcbi.1002123-Eggermont2">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Lesica1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Versnel1">[16]</xref> (also see <xref ref-type="bibr" rid="pcbi.1002123-Escabi1">[2]</xref>). They have also been obtained for responses of the auditory cortical neurons when the stimulus ensemble is composed of biologically more meaningful static or dynamic ripples (broadband sound with sinusoidally modulated spectral envelopes and their linear combinations <xref ref-type="bibr" rid="pcbi.1002123-Shamma1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Kowalski1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Depireux1">[19]</xref>). If the linear neural filter is augmented to include the filtering performed by the head and ears, it is also possible to predict the preferred locations of sound sources of auditory cortical neurons based on the linear neural filter for input spectrograms <xref ref-type="bibr" rid="pcbi.1002123-Schnupp1">[20]</xref>. Meanwhile, linear STRF models fail to capture many complex phenomena, particularly in the auditory cortex, and nonlinearities are not limited to being just static or monotonic. It has been suggested that some auditory cortical neurons process auditory objects in a highly non-linear manner, by selectively responding to a weak object component while ignoring loud components that occupy the same region in frequency space in auditory mixtures of these object components <xref ref-type="bibr" rid="pcbi.1002123-Nelken1">[21]</xref>, and some prefer low over high spectral contrast sounds <xref ref-type="bibr" rid="pcbi.1002123-Barbour1">[22]</xref>. Strong nonlinearities in the auditory processes have long since motivated nonlinear models of auditory responses (e.g., <xref ref-type="bibr" rid="pcbi.1002123-Eggermont1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Yu1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Ahrens1">[23]</xref>).</p>
      <p>This paper aims to understand from a computational, rather than a mechanistic, perspective why the auditory encoding transform should depend on the stimulus ensemble in the ways observed. More specifically, the paper focuses on cases in which STRFs can reasonably capture neural responses, and aims to identify and understand the computational goal of the STRFs for a given stimulus ensemble – finding a metric according to which the STRFs are optimal for the ensemble. This would provide a rationale for how the physiologically measured STRFs should depend on or adapt to the stimulus ensemble. This paper does not address what linear or nonlinear mechanisms could build the optimal STRFs, or whether or how nonlinear auditory processes enable the adaptation of the STRFs to the stimulus ensemble. Existing computational models of auditory neurons, including ones with the notion that cochlear hair cells perform independent component analysis to provide an efficient code for inputs using spikes in the auditory nerves <xref ref-type="bibr" rid="pcbi.1002123-Lewicki1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Smith1">[25]</xref>, cannot explain the observed dependence of the STRFs on the stimulus ensemble (see <xref ref-type="sec" rid="s4">Discussion</xref> for more details).</p>
      <p>Restricting attention to the temporal properties of STRF, Lesica and Grothe <xref ref-type="bibr" rid="pcbi.1002123-Lesica2">[26]</xref> observed that the temporal filter in STRF adapted to the level of ambient noise in the input environment. In particular, the temporal receptive field in the STRF changed from being bandpass to being low pass with the increase of ambient noise. They argued using a simple model that such adaptation in the STRF enables more efficient coding of the input information.</p>
      <p>This study applies the principles of efficient coding to understand the auditory STRF and its variations with sound intensities and other input characteristics. It generalizes the work of Lesica and Grothe <xref ref-type="bibr" rid="pcbi.1002123-Lesica2">[26]</xref> to understand the temporal and spectral filtering characteristics of STRF adaptation to changes in noise, signal and correlations in input statistics. Explicitly, the principle of efficient coding states that the neural receptive fields should enable the neural responses to transmit as much sensory information as possible to the central nervous system, subject to the limitation in neural cost in representing and transmitting information. This principle has been proposed <xref ref-type="bibr" rid="pcbi.1002123-Barlow1">[27]</xref> and successfully applied to the visual system to understand the receptive fields in the early visual pathway <xref ref-type="bibr" rid="pcbi.1002123-Laughlin1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Srinivasan1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Linsker1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Atick1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Atick2">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-vanHateren1">[33]</xref> (see review <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>). We will borrow heavily techniques and intuitions from vision to derive and explain the results in this paper.</p>
      <p>To make initial progress, it is necessary to start with some simplifying assumptions. First, we assume that the statistical characteristics of the stimulus ensemble do not change more rapidly than the speed at which the sensory encoding adapts, so that the stimulus ensemble can be approximated as being stationary as far as optimal encoding is concerned. Knowing when this assumption does not hold tells us when the encoding is not optimal, e.g., when one sees poorly for a brief moment before the visual encoding adapts to a sudden change from a dark room to a bright garden. Second, for mathematical convenience, we assume that the linear STRF model as in equation (1) can approximate adapted auditory neural responses reasonably well. As we know from above, this assumption often does not hold, particularly for auditory cortical neurons. This paper leaves the extension of the optimal encoding to nonlinear cases for future studies. Third, to derive a closed-form, analytical, solution to the optimal STRF, we assume that the input statistics in the stimulus ensemble can be approximated as being Gaussian, with higher order correlations in the input contributing only negligibly to the inefficiency of the representation in the original sensory inputs. Although it is known that the natural auditory inputs are far from Gaussian <xref ref-type="bibr" rid="pcbi.1002123-Nelken2">[35]</xref>, as for the case of vision, the discrepancy may have only a limited impact on the input inefficiency, as measured by the amount of information redundancy in the original sensory input <xref ref-type="bibr" rid="pcbi.1002123-Li1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Petrov1">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Hosseini1">[38]</xref>.</p>
      <p>To understand how sensory inputs should be recoded to increase coding efficiency, we start with visual encoding to draw insights and made analogies with auditory encoding. In vision, large amounts of raw data about the visual world are transduced by photoreceptors. However, the optic nerve, which transmits the input data to the visual cortex via thalamus, can only accommodate a dramatically smaller data rate. It has thus been proposed that early visual processes use an efficient coding strategy to encode as much information as possible given the limited bandwidth <xref ref-type="bibr" rid="pcbi.1002123-Barlow1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>, in other words, to recode the data such that the redundancy in the data is reduced and consequently the data can be transmitted by the limited bandwidth. Compression (while preserving most information) is possible since images are very redundant <xref ref-type="bibr" rid="pcbi.1002123-Field1">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Kersten1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Ruderman1">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Reinagel1">[42]</xref>, e.g., with strong correlations between visual inputs at nearby points in time and space. Removing such correlations can cut down the data rate substantially <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>.</p>
      <p>One way to remove the correlations is to transform the raw input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e038" xlink:type="simple"/></inline-formula> into a different representation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e039" xlink:type="simple"/></inline-formula> in neural responses that would then have a much smaller data rate than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e040" xlink:type="simple"/></inline-formula>, yet preserving essential input information. This transform is often approximated by the visual receptive field, analogous to the auditory STRFs. For instance, the (spatial) center-surround receptive fields of the retinal ganglion cells help remove spatial redundancy <xref ref-type="bibr" rid="pcbi.1002123-Linsker1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Atick1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Daugman1">[43]</xref>. They do this by making the ganglion cells preferentially respond to spatial contrast in the input, and so eliminating responses to visual locations whose input is redundant with that of their neighbors. Consequently, the responses of retinal ganglion cells are much less correlated than those of the photoreceptors, making their representation much more efficient. One facet of this efficient encoding hypothesis is that the optimal receptive field transform should depend on the statistical properties, such as the correlation structure and intensity, of the input. This dependence has been used to explain adaptation, to changes in input statistics, of visual receptive field characteristics, such as the sizes of center-surround regions and the color tuning of retinal neurons, or the ocular dominance properties of striate cortical neurons <xref ref-type="bibr" rid="pcbi.1002123-Atick2">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Atick3">[44]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Atick4">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Li2">[46]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping2">[47]</xref>. In the auditory system, information redundancy is also reduced along the auditory pathway <xref ref-type="bibr" rid="pcbi.1002123-Chechik1">[48]</xref>. Although this redundancy reduction was only investigated in the neural responses to sensory inputs rather than in the coding (STRF) transform leading to the neural responses, it suggested that coding efficiency is one of the goals of early auditory processes.</p>
      <p>More formally, the efficient coding scheme is depicted in <xref ref-type="fig" rid="pcbi-1002123-g002">Figure 2A</xref>. The input contains sensory signal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e041" xlink:type="simple"/></inline-formula> and noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e042" xlink:type="simple"/></inline-formula> (e.g., input sampling noise). The net input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e043" xlink:type="simple"/></inline-formula> is encoded by a linear transfer function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e044" xlink:type="simple"/></inline-formula> into output.<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e045" xlink:type="simple"/><label>(2)</label></disp-formula>which also contains additional noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e046" xlink:type="simple"/></inline-formula> introduced in the encoding process. When the input has multiple channels, e.g., many different photoreceptors or hair cells, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e047" xlink:type="simple"/></inline-formula> is a vector with many components, as indeed is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e048" xlink:type="simple"/></inline-formula>. Output <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e049" xlink:type="simple"/></inline-formula> is a vector representing the neural population responses from many neurons. For output neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e050" xlink:type="simple"/></inline-formula>, we have <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e051" xlink:type="simple"/></inline-formula>. Therefore <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e052" xlink:type="simple"/></inline-formula> is a matrix, and its <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e053" xlink:type="simple"/></inline-formula> row <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e054" xlink:type="simple"/></inline-formula> models the receptive field for output neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e055" xlink:type="simple"/></inline-formula> as the array of effective weights from input receptors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e056" xlink:type="simple"/></inline-formula> to output neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e057" xlink:type="simple"/></inline-formula>. In the particular example when input neurons are photoreceptors and output neurons are retinal ganglion cells, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e058" xlink:type="simple"/></inline-formula> is the effective connection from photoreceptor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e059" xlink:type="simple"/></inline-formula> to ganglion cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e060" xlink:type="simple"/></inline-formula> (implemented via the interneurons in the amacrine cell layers of the retina), and collectively, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e061" xlink:type="simple"/></inline-formula> describe the linear receptive field of this ganglion cell. We consider the problem of finding an optimal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e062" xlink:type="simple"/></inline-formula> that maximizes the information extracted by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e063" xlink:type="simple"/></inline-formula> about <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e064" xlink:type="simple"/></inline-formula>, i.e., the mutual information <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e065" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002123-Shannon1">[49]</xref> between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e066" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e067" xlink:type="simple"/></inline-formula> subject to a given cost of the neural encoding, which depends on the responses in a way we will describe shortly.</p>
      <fig id="pcbi-1002123-g002" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002123.g002</object-id>
        <label>Figure 2</label>
        <caption>
          <title>Formulation and components of efficient coding.</title>
          <p>(A) A schematic plot of the efficient encoding transform. (B) Signal transformation in the auditory system. The cochlea turns the time-varying waveform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e068" xlink:type="simple"/></inline-formula> into a time-frequency representation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e069" xlink:type="simple"/></inline-formula>, as the population activities of the auditory nerves, which is the input to the efficient encoding system. Signal and noise pass through a series of brain nuclei such as cochlear nucleus, superior olive, inferior colliculus, etc. The current work proposes that the effective transform STRF of the spectrogram that is collectively realized by these nuclei is, in its linear form, the optimal filter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e070" xlink:type="simple"/></inline-formula> implied by the efficient coding principle. The output <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e071" xlink:type="simple"/></inline-formula> is the activity of neurons in a higher nucleus. (C) Three steps of signal flow within the linear encoding step <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e072" xlink:type="simple"/></inline-formula> or STRF in (A) and (B). Note that these three steps are merely abstract algorithmic steps, rather than neural implementation processes for the effective transform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e073" xlink:type="simple"/></inline-formula> or STRF.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.g002" xlink:type="simple"/>
      </fig>
      <p>Therefore, the optimal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e074" xlink:type="simple"/></inline-formula> should minimize the objective function:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e075" xlink:type="simple"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e076" xlink:type="simple"/></inline-formula> is a parameter whose value specifies a particular balance between the needs to minimize costs and to maximize extracted information. Neural costs can arise from various sources, such as the metabolic energy cost for generating neural activities or spikes <xref ref-type="bibr" rid="pcbi.1002123-Levy1">[50]</xref> and the cost of thicker axons to transmit higher rates of neural firing. We follow a formulation that has been productive in vision <xref ref-type="bibr" rid="pcbi.1002123-Atick1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>, and model the neural cost as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e077" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e078" xlink:type="simple"/></inline-formula> indicates the average over the stimulus ensemble. This gives<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e079" xlink:type="simple"/><label>(4)</label></disp-formula>It has been shown <xref ref-type="bibr" rid="pcbi.1002123-Srinivasan1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-vanHateren1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Atick5">[51]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref> that the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e080" xlink:type="simple"/></inline-formula> that provides the most efficient coding according to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e081" xlink:type="simple"/></inline-formula> has the following properties. At high signal-to-noise ratio (SNR), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e082" xlink:type="simple"/></inline-formula> is such that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e083" xlink:type="simple"/></inline-formula> extracts the difference between correlated channels, and thus avoids transmitting redundant information. Hence, for example, in photopic conditions, retinal ganglion cells have center-surround spatial receptive fields which extract the spatial contrast of the input. By contrast, at low SNR, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e084" xlink:type="simple"/></inline-formula> is a smoothing filter that averages out input noise instead of reducing redundancy. This avoids spending neural cost on transmitting noise. Hence, for example, in scotopic conditions, when SNR can be considered as being low, the receptive fields of retinal ganglion cells expand the sizes of their center regions and weaken their suppressive surrounds <xref ref-type="bibr" rid="pcbi.1002123-Barlow2">[52]</xref>. We will apply this framework to the auditory encoding to understand STRFs and their adaptation to stimulus ensembles.</p>
    </sec>
    <sec id="s2" sec-type="methods">
      <title>Methods</title>
      <sec id="s2a">
        <title>Auditory encoding system and its comparison to vision</title>
        <p>To apply the efficient coding principle to auditory STRFs, we borrow insights from vision by making an analogy between (aspects of) the auditory and visual systems. For simplicity, we start by ignoring input noise. While sound signals are typically air vibrations over time, at the input sampling stage, they are sampled as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e085" xlink:type="simple"/></inline-formula> from a continuous time-frequency representation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e086" xlink:type="simple"/></inline-formula>, namely the response at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e087" xlink:type="simple"/></inline-formula> of a hair cell tuned to sound vibration frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e088" xlink:type="simple"/></inline-formula>. This is analogous to visual input sampling, in which the response of a photoreceptor at location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e089" xlink:type="simple"/></inline-formula> samples the light signal in the form of electromagnetic vibrations. Auditory hair cells are tonotopically arranged in the cochlea, so that neighboring hair cells are tuned to nearby sound frequencies. Therefore, at any instant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e090" xlink:type="simple"/></inline-formula> , the response pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e091" xlink:type="simple"/></inline-formula> as a function of hair cell's location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e092" xlink:type="simple"/></inline-formula> over the cochlea is an auditory “image” of the pattern of powers across sound frequencies, analogous to a retinal image. (In our formulation, we focus on sampling the intensity or power in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e093" xlink:type="simple"/></inline-formula>, and ignore the phase of the sound wave at frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e094" xlink:type="simple"/></inline-formula>. This is because (1) auditory nerve responses do not encode the phase except for low frequency inputs via phase locking, and (2), as mentioned, our goal is to understand the STRFs which do not concern the phase information.) While a retinal image is two dimensional in space (and one additional dimension in time), the auditory “image” at any instant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e095" xlink:type="simple"/></inline-formula> is one dimensional in sound frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e096" xlink:type="simple"/></inline-formula>. One may use time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e097" xlink:type="simple"/></inline-formula> as the second dimension such that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e098" xlink:type="simple"/></inline-formula> for all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e099" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e100" xlink:type="simple"/></inline-formula> collectively can be seen as a single discrete sample of the two-dimensional auditory “image”. When input noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e101" xlink:type="simple"/></inline-formula> is included, input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e102" xlink:type="simple"/></inline-formula> becomes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e103" xlink:type="simple"/></inline-formula>.</p>
        <p>As for vision, we explore whether the auditory STRFs can be partly understood by the goal of efficiently coding auditory information. The sensory input is sampled as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e104" xlink:type="simple"/></inline-formula>, the responses of the cochlear hair cells. This input is encoded by the STRFs to give rise to outputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e105" xlink:type="simple"/></inline-formula> as the neural activities of a higher nucleus, such as the inferior colliculus (IC) or the auditory cortex (<xref ref-type="fig" rid="pcbi-1002123-g002">Figure 2B</xref>). The STRF is then analogous to a spatial receptive field, such as that of the retinal ganglion cells. Thus the STRF should be determined by the statistics of the auditory inputs, and in particular, the correlation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e106" xlink:type="simple"/></inline-formula> between different inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e107" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e108" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e109" xlink:type="simple"/></inline-formula> labels a particular spectro-temporal combination of a frequency value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e110" xlink:type="simple"/></inline-formula> and time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e111" xlink:type="simple"/></inline-formula>. Note that for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e112" xlink:type="simple"/></inline-formula>, the frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e113" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e114" xlink:type="simple"/></inline-formula>, but not both, in the two indices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e115" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e116" xlink:type="simple"/></inline-formula> may be equal. (Here, for simplicity we assume, or pre-process the signal, such that all inputs have zero mean, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e117" xlink:type="simple"/></inline-formula>, just like the input signal fluctuation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e118" xlink:type="simple"/></inline-formula> around the ensemble average in the definition of the STRF in equation (1)). As in vision, natural auditory inputs express substantial correlations between inputs of neighboring frequencies and at neighboring temporal instances. When the input SNR is sufficiently high, an optimal STRF should reduce these correlations to achieve efficient transmission. Such an STRF will have neighboring excitatory and inhibitory regions in the frequency-latency domain, making the neuron be tuned to spectro-temporal contrast and be insensitive to the spectro-temporal redundancy.</p>
      </sec>
      <sec id="s2b">
        <title>Auditory STRF filter as an efficient coding transform</title>
        <p>The general formulation and derivation of the efficient coding transform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e119" xlink:type="simple"/></inline-formula> (or STRF) can be found in its application to vision <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>. Here we outline these results and illustrate their consequences for auditory coding. Let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e120" xlink:type="simple"/></inline-formula> be the input with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e121" xlink:type="simple"/></inline-formula> input channels:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e122" xlink:type="simple"/><label>(5)</label></disp-formula>(superscript T denotes vector or matrix transpose). These <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e123" xlink:type="simple"/></inline-formula> input channels may correspond to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e124" xlink:type="simple"/></inline-formula> auditory nerves if we omit the temporal dimension, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e125" xlink:type="simple"/></inline-formula> time instances if we focus on a single frequency channel, or they may correspond to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e126" xlink:type="simple"/></inline-formula> spectro-temporal labels <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e127" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e128" xlink:type="simple"/></inline-formula>. Let the input correlation be described by correlation matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e129" xlink:type="simple"/></inline-formula> with elements <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e130" xlink:type="simple"/></inline-formula>. The optimal transform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e131" xlink:type="simple"/></inline-formula> that minimizes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e132" xlink:type="simple"/></inline-formula> in equation (4) can be decomposed in three steps (<xref ref-type="fig" rid="pcbi-1002123-g002">Figure 2C</xref>): (1) a principal component transform to de-correlate the inputs, (2) gain control of each principal component, (3) an ortho-normal or unitary transform on the array of the gain-controlled components to arrive at various output channels. We now elaborate and elucidate these three steps.</p>
        <p>The first step is a coordinate rotation, or ortho-normal transform, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e133" xlink:type="simple"/></inline-formula>, by an ortho-normal matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e134" xlink:type="simple"/></inline-formula> that de-correlates the input channels such that each of the channels in the transformed signal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e135" xlink:type="simple"/></inline-formula> contains a principal component of the original signal. We denote these principal components as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e136" xlink:type="simple"/></inline-formula>, with sub-index <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e137" xlink:type="simple"/></inline-formula> (instead of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e138" xlink:type="simple"/></inline-formula>) as the indices of the de-correlated channels (later, we also use <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e139" xlink:type="simple"/></inline-formula> to denote the de-correlated channels in the temporal domain, or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e140" xlink:type="simple"/></inline-formula> in spectro-temporal domain). Since the correlation between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e141" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e142" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e143" xlink:type="simple"/></inline-formula>, decorrelation between principal components implies that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e144" xlink:type="simple"/></inline-formula> is a diagonal matrix, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e145" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e146" xlink:type="simple"/></inline-formula> is the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e147" xlink:type="simple"/></inline-formula> eigenvalue of matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e148" xlink:type="simple"/></inline-formula> and also the average signal power of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e149" xlink:type="simple"/></inline-formula> principal component <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e150" xlink:type="simple"/></inline-formula>. As we will see later, when the input correlation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e151" xlink:type="simple"/></inline-formula> depends mainly on the differences <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e152" xlink:type="simple"/></inline-formula> in frequency and time, it turns out that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e153" xlink:type="simple"/></inline-formula> (with the index <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e154" xlink:type="simple"/></inline-formula> denoting the spectro-temporal modulation frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e155" xlink:type="simple"/></inline-formula>) is the amplitude of a dynamic or moving ripple that some experiments use to estimate the STRFs of cortical and midbrain neurons <xref ref-type="bibr" rid="pcbi.1002123-Shamma1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Kowalski1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Depireux1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Versnel1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Escabi1">[2]</xref>.</p>
        <p>The second step is gain control <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e156" xlink:type="simple"/></inline-formula> on each component <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e157" xlink:type="simple"/></inline-formula>, giving output <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e158" xlink:type="simple"/></inline-formula>. Including noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e159" xlink:type="simple"/></inline-formula>, which is the original input noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e160" xlink:type="simple"/></inline-formula> projected to the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e161" xlink:type="simple"/></inline-formula> channel by the transform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e162" xlink:type="simple"/></inline-formula>, and the encoding noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e163" xlink:type="simple"/></inline-formula> (in the decorrelated <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e164" xlink:type="simple"/></inline-formula> space), the total output becomes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e165" xlink:type="simple"/></inline-formula>. It can be shown (see <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>) that the gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e166" xlink:type="simple"/></inline-formula> that minimizes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e167" xlink:type="simple"/></inline-formula> in equation (4) is determined by the input signal-to-noise ratio <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e168" xlink:type="simple"/></inline-formula> to satisfy<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e169" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e170" xlink:type="simple"/></inline-formula> is the variance of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e171" xlink:type="simple"/></inline-formula>, and also of the input noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e172" xlink:type="simple"/></inline-formula> (assumed to be independent, identically distributed and Gaussian in each channel) , and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e173" xlink:type="simple"/></inline-formula> is the variance of the encoding noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e174" xlink:type="simple"/></inline-formula> in each channel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e175" xlink:type="simple"/></inline-formula> (and of the encoding noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e176" xlink:type="simple"/></inline-formula> in each <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e177" xlink:type="simple"/></inline-formula> since different encoding noise channels are also assumed to be independently and identically distributed).</p>
        <p>Note that the total noise at output neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e178" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e179" xlink:type="simple"/></inline-formula>. One effect of the encoding transform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e180" xlink:type="simple"/></inline-formula> is that noise corrupting different output neurons can be correlated, even when the original input noise is independent. The additional encoding noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e181" xlink:type="simple"/></inline-formula> could also be correlated in different output neurons, since it could also reflect a common origin in intermediate stages of the encoding processes. Our assumption of independence between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e182" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e183" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e184" xlink:type="simple"/></inline-formula> is thus a simplification for mathematical convenience.</p>
        <p>Since all the variables are assumed to be Gaussian, each output <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e185" xlink:type="simple"/></inline-formula> extracts the following amount of information<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e186" xlink:type="simple"/></disp-formula>about the input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e187" xlink:type="simple"/></inline-formula> and has an output power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e188" xlink:type="simple"/></inline-formula>. Since different output channels <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e189" xlink:type="simple"/></inline-formula> from different <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e190" xlink:type="simple"/></inline-formula> are decorrelated from each other, the quantity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e191" xlink:type="simple"/></inline-formula> in equation (4) is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e192" xlink:type="simple"/><label>(7)</label></disp-formula>One can then verify that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e193" xlink:type="simple"/></inline-formula> in equation (6) indeed minimizes this <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e194" xlink:type="simple"/></inline-formula> since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e195" xlink:type="simple"/></inline-formula> at that value. Note that if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e196" xlink:type="simple"/></inline-formula> is the amplitude of a moving ripple indexed by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e197" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e198" xlink:type="simple"/></inline-formula> will be the sensitivity of the neuron to the moving ripple.</p>
        <p>We can write these two steps as the product <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e199" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e200" xlink:type="simple"/></inline-formula> is the principal component transform, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e201" xlink:type="simple"/></inline-formula> performs the gain control. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e202" xlink:type="simple"/></inline-formula> is a diagonal matrix with diagonal elements <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e203" xlink:type="simple"/></inline-formula>. The net output is then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e204" xlink:type="simple"/></inline-formula>. Consider imposing on this transform an orthonormal or unitary transform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e205" xlink:type="simple"/></inline-formula> (with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e206" xlink:type="simple"/></inline-formula>), the third step in building the efficient coding filter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e207" xlink:type="simple"/></inline-formula>, giving <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e208" xlink:type="simple"/></inline-formula>. It follows <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref> from the properties of unitary matrices that neither the first term nor the second term in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e209" xlink:type="simple"/></inline-formula> in equation (4) will be affected by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e210" xlink:type="simple"/></inline-formula> (at least when signal and noise are Gaussian and when the components of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e211" xlink:type="simple"/></inline-formula> are independent and identically distributed).</p>
        <p>Each row vector of the matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e212" xlink:type="simple"/></inline-formula> determines the receptive field of a particular output channel or neuron. Without <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e213" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e214" xlink:type="simple"/></inline-formula> would specify receptive fields that would be gain controlled eigenvectors or principal components of the input correlation matrix. For example, they would look like ripples covering the entire spectro-temporal range. An appropriate choice of non-trivial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e215" xlink:type="simple"/></inline-formula> will alter the receptive field shape dramatically, giving rise to receptive field properties found in real neurons such as a finite span in input channel space. For example, if we consider only the input frequency channels <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e216" xlink:type="simple"/></inline-formula> for auditory inputs and omit the time dimension, we may prefer that the STRF for an output neuron to be selective to only a finite band of input frequencies such that the neural responses <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e217" xlink:type="simple"/></inline-formula> resemble periphery inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e218" xlink:type="simple"/></inline-formula> while maintaining coding efficiency. It can be shown <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Nelken2">[35]</xref> that this can be achieved by choosing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e219" xlink:type="simple"/></inline-formula>, such that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e220" xlink:type="simple"/></inline-formula>. We will use this choice, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e221" xlink:type="simple"/></inline-formula>, in building our STRF in frequency domain. However, insensitive to the exact form of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e222" xlink:type="simple"/></inline-formula>, the critical feature of the STRF comes from the gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e223" xlink:type="simple"/></inline-formula> specified in the second step of the encoding model (as long as one does not impose additional computational goals that may restrict the final STRFs, see <xref ref-type="sec" rid="s4">Discussion</xref>). We will show later that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e224" xlink:type="simple"/></inline-formula> often corresponds to the modulation transfer functions (MTFs, also called ripple transfer function, RTF,in different literatures) of the STRFs.</p>
        <p>We now apply this general framework to the case of auditory encoding. Sound spectrogram <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e225" xlink:type="simple"/></inline-formula> is derived from the sound waveform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e226" xlink:type="simple"/></inline-formula> as follows. The first step is to perform a temporally-windowed Fourier transform of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e227" xlink:type="simple"/></inline-formula> to obtain the sound spectrum <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e228" xlink:type="simple"/></inline-formula> as a function of time, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e229" xlink:type="simple"/></inline-formula> is a temporal window function (e.g., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e230" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e231" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e232" xlink:type="simple"/></inline-formula> otherwise). Since the cochlea performs approximately a log scale frequency analysis, we first let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e233" xlink:type="simple"/></inline-formula> to obtain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e234" xlink:type="simple"/></inline-formula> (although the more accurate form would be <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e235" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002123-Glasberg1">[53]</xref>). Then the input power in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e236" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e237" xlink:type="simple"/></inline-formula>. One may employ a further logarithmic transform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e238" xlink:type="simple"/></inline-formula> to characterize the cochlear response better (through capturing the compressive input/output transform realized by processes in the basilar membrane and hair cells) <xref ref-type="bibr" rid="pcbi.1002123-Escabi2">[54]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Gill1">[55]</xref>. However, this further logarithmic transform is not essential for our formulation, and, as pointed out previously <xref ref-type="bibr" rid="pcbi.1002123-Young2">[56]</xref>, it does not significantly affect the qualitative characteristics of the empirical STRFs. If one omits this logarithmic transform, then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e239" xlink:type="simple"/></inline-formula>. We then subtract the mean <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e240" xlink:type="simple"/></inline-formula> from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e241" xlink:type="simple"/></inline-formula>, and, for simplicity, denote the resulting zero mean signal still by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e242" xlink:type="simple"/></inline-formula>, as in the definition of STRF. We next consider discrete samples <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e243" xlink:type="simple"/></inline-formula> of the continuous <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e244" xlink:type="simple"/></inline-formula>. This leads to the input correlation matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e245" xlink:type="simple"/></inline-formula>.</p>
        <p>Finally, we follow the three encoding steps above to obtain the optimal encoding transform as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e246" xlink:type="simple"/></inline-formula>. In the sub-section “The spectral filter SRF”, we discuss the simple case in which the temporal dimension <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e247" xlink:type="simple"/></inline-formula> is omitted. Then, the input vector (equation (5)) is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e248" xlink:type="simple"/></inline-formula>, and the input correlation matrix is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e249" xlink:type="simple"/></inline-formula>. The efficient encoding procedure specifies the optimal spectral receptive field (SRF) <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e250" xlink:type="simple"/></inline-formula> for neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e251" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e252" xlink:type="simple"/></inline-formula>. When the temporal dimension is included <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e253" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e254" xlink:type="simple"/></inline-formula>, and efficient coding specifies the optimal STRF as input weights or selectivity associated with the spectrogram <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e255" xlink:type="simple"/></inline-formula>.</p>
        <p>It is apparent that the optimal SRF and STRF depend on input statistics via the input correlation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e256" xlink:type="simple"/></inline-formula> and the input SNR (through the steps 1 and 2 in the encoding scheme). Therefore, when the stimulus ensemble changes, altering the input correlations and signal intensity, the form of the encoding receptive field should adapt in order to maintain encoding optimality. We propose that it is this that explains the input ensemble dependence of the STRFs.</p>
        <p>A special class of input statistics has translation invariant correlations, i.e., with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e257" xlink:type="simple"/></inline-formula> depending only on the differences <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e258" xlink:type="simple"/></inline-formula> (quantified in octaves) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e259" xlink:type="simple"/></inline-formula>. This is a reasonable approximation of the input correlations in natural auditory scenes under two conditions. The first is that a local frequency range is considered that is not much larger than the range of the frequencies to which a neuron is sensitive, i.e., in the perspective of a neuron, the dependence of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e260" xlink:type="simple"/></inline-formula> on the frequency is mainly through <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e261" xlink:type="simple"/></inline-formula>. This is analogous to approximating spatial correlation of visual inputs as translation invariant to understand the retinal ganglion cell's spatial receptive fields although the spatial sampling density varies substantially with input eccentricity <xref ref-type="bibr" rid="pcbi.1002123-Atick1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>. The second is that the environment is statistically stationary, as then the correlations in time depend only on the temporal difference <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e262" xlink:type="simple"/></inline-formula>. It can then be shown that <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref> the principal components are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e263" xlink:type="simple"/></inline-formula>, each of which has a 2D modulation frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e264" xlink:type="simple"/></inline-formula>, which can be indexed by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e265" xlink:type="simple"/></inline-formula>. The first encoding step is then a 2D Fourier transform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e266" xlink:type="simple"/></inline-formula> of the input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e267" xlink:type="simple"/></inline-formula> to obtain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e268" xlink:type="simple"/></inline-formula>. Meanwhile, the original input can be written as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e269" xlink:type="simple"/></inline-formula>, i.e., as a weighted sum of the moving ripples <xref ref-type="bibr" rid="pcbi.1002123-Depireux1">[19]</xref>. The second encoding step determines the gains for the ripple amplitudes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e270" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref> as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e271" xlink:type="simple"/><label>(8)</label></disp-formula>i.e., replacing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e272" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e273" xlink:type="simple"/></inline-formula> in equation (6) by the corresponding <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e274" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e275" xlink:type="simple"/></inline-formula>. If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e276" xlink:type="simple"/></inline-formula> is chosen as the inverse Fourier transform<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e277" xlink:type="simple"/><label>(9)</label></disp-formula>with an extra phase function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e278" xlink:type="simple"/></inline-formula>, then the encoding transform is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e279" xlink:type="simple"/></inline-formula>. This gives<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e280" xlink:type="simple"/><label>(10)</label></disp-formula>which depends only on the differences <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e281" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e282" xlink:type="simple"/></inline-formula>. Applying this transform to input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e283" xlink:type="simple"/></inline-formula> to give output <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e284" xlink:type="simple"/></inline-formula>, we see, by comparison with equation (1), that the STRF is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e285" xlink:type="simple"/></inline-formula>. This is a temporal filter tuned to sound frequency with a tuning pattern governed by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e286" xlink:type="simple"/></inline-formula>, and centered around frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e287" xlink:type="simple"/></inline-formula>. Changing the center frequency from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e288" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e289" xlink:type="simple"/></inline-formula> is like shifting from one output neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e290" xlink:type="simple"/></inline-formula> to another neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e291" xlink:type="simple"/></inline-formula>. Altering the phase <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e292" xlink:type="simple"/></inline-formula> in equation (9) alters the STRF shape, in particular to ensure its temporal causality. In physiology, modulation tuning function (MTF) is often mentioned as the Fourier transform of auditory receptive field <xref ref-type="bibr" rid="pcbi.1002123-Depireux1">[19]</xref>. Therefore, it is clear from equation (10) that the gain profile <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e293" xlink:type="simple"/></inline-formula>, which is determined by efficient coding, corresponds to the magnitude of the MTF. However, the shape of an STRF is determined by the phase as well as the magnitude of the MTF, and efficient coding does not strongly constrain the phase. Therefore, while we will illustrate the general properties of some example STRFs predicted by the theory by choosing particular <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e294" xlink:type="simple"/></inline-formula> transforms (governed by the additional requirements of spectro-temporal locality and causality), in the Results, we will generally compare physiological data to the magnitudes of the MTFs that the theory predicts.</p>
        <p>In the Results, we will discuss the efficient coding framework for situations both with (e.g., to study temporal aspects of STRFs) and without (e.g., to study their spectral aspects) translation invariance in input statistics.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Results</title>
      <p>To illustrate how the framework explains and predicts physiological experiments, we first discuss a few examples when the temporal or the spectral dimension is omitted, and then show a full spectro-temporal STRF.</p>
      <sec id="s3a">
        <title>The spectral filter SRF</title>
        <p>We first omit time, treating the input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e295" xlink:type="simple"/></inline-formula> as varying only in frequency. In this case, the encoding filter reduces from being an STRF to an SRF. We take <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e296" xlink:type="simple"/></inline-formula> as one of 250 discrete values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e297" xlink:type="simple"/></inline-formula>, from low to high frequencies; hence input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e298" xlink:type="simple"/></inline-formula> is a one dimensional vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e299" xlink:type="simple"/></inline-formula>. In simulations, input sample <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e300" xlink:type="simple"/></inline-formula> is generated by smoothing a random noise vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e301" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3A</xref>), with all the components <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e302" xlink:type="simple"/></inline-formula> taken to be independent, zero mean, unit variance, Gaussian noise. Specifically<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e303" xlink:type="simple"/><label>(11)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e304" xlink:type="simple"/></inline-formula> is a factor to scale the overall input power intensity, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e305" xlink:type="simple"/></inline-formula> is the smoothing matrix with elements<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e306" xlink:type="simple"/><label>(12)</label></disp-formula>explained in detail below. Here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e307" xlink:type="simple"/></inline-formula> controls the scale of the signal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e308" xlink:type="simple"/></inline-formula>, which decays with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e309" xlink:type="simple"/></inline-formula> (like in an environment in which high frequency sounds do not propagate well), and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e310" xlink:type="simple"/></inline-formula> is a normalized smoothing matrix with elements <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e311" xlink:type="simple"/></inline-formula>, in which<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e312" xlink:type="simple"/><label>(13)</label></disp-formula><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e313" xlink:type="simple"/></inline-formula> is a normalization constant, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e314" xlink:type="simple"/></inline-formula> controls the range of frequency difference <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e315" xlink:type="simple"/></inline-formula> for significant correlation coefficient between the variation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e316" xlink:type="simple"/></inline-formula> and that of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e317" xlink:type="simple"/></inline-formula>.</p>
        <fig id="pcbi-1002123-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002123.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Simulation of the efficient spectral kernel SRF, when the temporal dimension is omitted.</title>
            <p>(A) 250 samples of input spectra <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e318" xlink:type="simple"/></inline-formula>, each of which is smoothed Gaussian white noise in the frequency domain (equations (11–13), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e319" xlink:type="simple"/></inline-formula>). (B) Correlation between different frequency channels <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e320" xlink:type="simple"/></inline-formula>. Left: Correlation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e321" xlink:type="simple"/></inline-formula>; Right: an zoomed-in view, as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e322" xlink:type="simple"/></inline-formula> vs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e323" xlink:type="simple"/></inline-formula>. (C) Ten examples of eigenvectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e324" xlink:type="simple"/></inline-formula> of the correlation matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e325" xlink:type="simple"/></inline-formula> in B; each is an independent component in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e326" xlink:type="simple"/></inline-formula>. Smaller indices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e327" xlink:type="simple"/></inline-formula> are associated with larger eigenvalues. (D) Gain profile (peaking at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e328" xlink:type="simple"/></inline-formula>), and signal and noise power in decorrelated channels. (E) Four examples (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e329" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e330" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e331" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e332" xlink:type="simple"/></inline-formula>) of spectral receptive fields <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e333" xlink:type="simple"/></inline-formula>; each prefers input frequencies around <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e334" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.g003" xlink:type="simple"/>
        </fig>
        <p>Consequently, each <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e335" xlink:type="simple"/></inline-formula> is also a zero mean Gaussian random variable, and the input correlations comprise a 250×250 matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e336" xlink:type="simple"/></inline-formula>. One could also estimate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e337" xlink:type="simple"/></inline-formula> from input samples <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e338" xlink:type="simple"/></inline-formula> (as when animals adapt their auditory system to environmental sound through experience), in which case element <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e339" xlink:type="simple"/></inline-formula>. <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3B</xref> illustrates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e340" xlink:type="simple"/></inline-formula> (obtained numerically from 250 samples of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e341" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3A</xref>, of course one could use more than 250 samples to estimate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e342" xlink:type="simple"/></inline-formula>) for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e343" xlink:type="simple"/></inline-formula>. The correlation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e344" xlink:type="simple"/></inline-formula> scales with strengths of the original signals <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e345" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e346" xlink:type="simple"/></inline-formula> through the scales <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e347" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e348" xlink:type="simple"/></inline-formula>, and so decays with frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e349" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e350" xlink:type="simple"/></inline-formula>. Thus the statistics of the stimulus ensemble are not translation invariant in the spectral frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e351" xlink:type="simple"/></inline-formula>. Nevertheless, the correlation coefficient<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e352" xlink:type="simple"/></disp-formula>does depend mainly on the (frequency) difference <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e353" xlink:type="simple"/></inline-formula>, since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e354" xlink:type="simple"/></inline-formula> is almost independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e355" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e356" xlink:type="simple"/></inline-formula> depends mainly on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e357" xlink:type="simple"/></inline-formula> except for the very small or very large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e358" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e359" xlink:type="simple"/></inline-formula>. This is evident in the fact that the rate of decay of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e360" xlink:type="simple"/></inline-formula> with the difference <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e361" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3B</xref> is almost constant. Since the stimulus ensemble is not translation invariant, we will use the general formulation to obtain the SRF. From <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e362" xlink:type="simple"/></inline-formula>, we obtain its 250 eigenvalues and the corresponding eigenvectors. Each of these is a vector with 250 components. We list them in the order of descending eigenvalues, denoting the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e363" xlink:type="simple"/></inline-formula> eigenvector as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e364" xlink:type="simple"/></inline-formula>, and placing it as the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e365" xlink:type="simple"/></inline-formula> row vector of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e366" xlink:type="simple"/></inline-formula> transform matrix. <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3C</xref> depicts the eigenvectors for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e367" xlink:type="simple"/></inline-formula>, where smaller <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e368" xlink:type="simple"/></inline-formula> is associated with a larger eigenvalue. Each principal component or eigenvector can be seen as a special input spectrum pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e369" xlink:type="simple"/></inline-formula>, while a general input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e370" xlink:type="simple"/></inline-formula> is a linear sum of the principal components with weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e371" xlink:type="simple"/></inline-formula>. The first encoding step is thus a transformation of the original input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e372" xlink:type="simple"/></inline-formula> by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e373" xlink:type="simple"/></inline-formula> to obtain the decorrelated signal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e374" xlink:type="simple"/></inline-formula>, for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e375" xlink:type="simple"/></inline-formula>. The average power in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e376" xlink:type="simple"/></inline-formula> is the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e377" xlink:type="simple"/></inline-formula> eigenvalue of matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e378" xlink:type="simple"/></inline-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e379" xlink:type="simple"/></disp-formula>The eigenvectors look roughly like oscillating waveforms (spectral oscillations) with different oscillation rates, and are comparable to the sinusoidal bases in the Fourier transform. They also resemble the “ripples” used in physiological experiments. This is because the input correlations are roughly translation invariant, at least within a small range of frequencies in which the signal power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e380" xlink:type="simple"/></inline-formula> is roughly independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e381" xlink:type="simple"/></inline-formula> (just like in vision when the statistics of inputs sampled at the retina can be seen as roughly translation invariant within a local region). Also note that smaller or larger <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e382" xlink:type="simple"/></inline-formula> is associated with eigenvectors with fewer or more oscillations. This makes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e383" xlink:type="simple"/></inline-formula> relate monotonically to the spectral modulation frequency (corresponding to the “ripple frequency” <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e384" xlink:type="simple"/></inline-formula> in physiological experiments). Larger eigenvalues, i.e., larger signal powers <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e385" xlink:type="simple"/></inline-formula>, are associated with fewer spectral modulations or smaller indices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e386" xlink:type="simple"/></inline-formula>, because inputs of more similar sound frequencies are more correlated with each other, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e387" xlink:type="simple"/></inline-formula> decreases with increasing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e388" xlink:type="simple"/></inline-formula>. The analogy between the eigenvectors and the Fourier bases can be understood as follows: if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e389" xlink:type="simple"/></inline-formula> is strictly translation invariant, then the eigenvectors are sine waves with different spectral modulation frequencies <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e390" xlink:type="simple"/></inline-formula>. The eigenvalues are the Fourier transforms of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e391" xlink:type="simple"/></inline-formula>, and hence they decrease with the modulation frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e392" xlink:type="simple"/></inline-formula> because <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e393" xlink:type="simple"/></inline-formula> is non-negative and decreases with increasing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e394" xlink:type="simple"/></inline-formula>.</p>
        <p>The second encoding step is to assign the gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e395" xlink:type="simple"/></inline-formula> to each of these channels <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e396" xlink:type="simple"/></inline-formula> according to equation (6), giving <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e397" xlink:type="simple"/></inline-formula> (see <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3D</xref>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e398" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e399" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e400" xlink:type="simple"/></inline-formula>). Note that while the signal power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e401" xlink:type="simple"/></inline-formula> decreases with increasing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e402" xlink:type="simple"/></inline-formula>, the gain magnitude <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e403" xlink:type="simple"/></inline-formula> first increases with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e404" xlink:type="simple"/></inline-formula> and then decreases and drops to zero at higher <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e405" xlink:type="simple"/></inline-formula>.</p>
        <p>The gain for small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e406" xlink:type="simple"/></inline-formula> is low since the SNR <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e407" xlink:type="simple"/></inline-formula> is high enough to make amplifying <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e408" xlink:type="simple"/></inline-formula> less necessary. From equation (6) <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e409" xlink:type="simple"/><label>(14)</label></disp-formula>This implies that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e410" xlink:type="simple"/></inline-formula> for sufficiently large SNRs. When each principal component <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e411" xlink:type="simple"/></inline-formula> is a modulation frequency mode, this gain profile <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e412" xlink:type="simple"/></inline-formula> is often called whitening. At smaller signal powers, the gain increases so as to utilize the channel's dynamic range fully. However, when SNR is too small, for example, when noise power is higher than signal power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e413" xlink:type="simple"/></inline-formula>, gain decreases with decreasing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e414" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>. This is because such input components are dominated by noise, and amplifying noise increases neural cost. Thus, in general, when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e415" xlink:type="simple"/></inline-formula> decreases with increasing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e416" xlink:type="simple"/></inline-formula>, the gain profile has a band-pass shape, first increasing, and then decreasing with increasing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e417" xlink:type="simple"/></inline-formula> (see the red curve in <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3D</xref>). The peak of the gain occurs at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e418" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e419" xlink:type="simple"/></inline-formula>.</p>
        <p>Third, taking <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e420" xlink:type="simple"/></inline-formula> in order to localize the receptive Fields as best as possible, the overall encoding transform is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e421" xlink:type="simple"/></inline-formula>. Here, the gain matrix is diagonal having elements <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e422" xlink:type="simple"/></inline-formula>. When <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e423" xlink:type="simple"/></inline-formula> (as when the eigenvectors are real and othornormalized)<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e424" xlink:type="simple"/></disp-formula>As the overall encoding transform gives outputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e425" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e426" xlink:type="simple"/></inline-formula>, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e427" xlink:type="simple"/></inline-formula> output neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e428" xlink:type="simple"/></inline-formula> has its SRF as a vector of weights for inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e429" xlink:type="simple"/></inline-formula> of various frequencies <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e430" xlink:type="simple"/></inline-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e431" xlink:type="simple"/></disp-formula>It can thus be seen as a weighted sum of the eigenvectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e432" xlink:type="simple"/></inline-formula> of the input correlation matrix, with weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e433" xlink:type="simple"/></inline-formula> for output neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e434" xlink:type="simple"/></inline-formula>. <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3E</xref> shows SRFs for four different output neurons (or channels <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e435" xlink:type="simple"/></inline-formula>). These SRFs have different preferred frequencies <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e436" xlink:type="simple"/></inline-formula>, so that the preferred frequencies of all the output neurons span the whole input frequency range. The shapes of the SRF depend on the input statistics via the dependence of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e437" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e438" xlink:type="simple"/></inline-formula> on the input correlation matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e439" xlink:type="simple"/></inline-formula>. In particular, for sufficiently high input SNR, while a neuron is excited by its preferred frequency, it is suppressed by nearby frequencies. This form of contrast enhancement achieves a measure of decorrelation between neighboring output neurons that would otherwise reflect the strong correlations between neighboring frequencies. For SRFs tuned to higher frequencies, the center excitatory regions are larger and the surround suppression is weaker. This is because SNRs are weaker for higher frequency inputs (the dependency of SRF on SNR will be discussed in the next sub-section). If the input statistics are strictly translation invariant, the SRFs for different output channels will have the same shape, and will just be centered on different frequencies.</p>
      </sec>
      <sec id="s3b">
        <title>Adaptation of SRF to input signal-to-noise ratio</title>
        <p>When sound intensity decreases, the basilar membrane in the cochlea undergoes a smaller vibration. This decreases the magnitudes of input signals <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e440" xlink:type="simple"/></inline-formula>, and so, if the level of the noise stays unchanged, the signal-to-noise ratio <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e441" xlink:type="simple"/></inline-formula> will decrease. This will change the optimal encoding gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e442" xlink:type="simple"/></inline-formula> via equation (6), and thus change the final SRFs. In our example, we simulate the change in input intensity by changing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e443" xlink:type="simple"/></inline-formula> in equation (11).</p>
        <p><xref ref-type="fig" rid="pcbi-1002123-g004">Figure 4A</xref> shows three example input intensity profiles <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e444" xlink:type="simple"/></inline-formula>, and the corresponding gain profiles <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e445" xlink:type="simple"/></inline-formula>. While an overall change of input intensity merely scales the profile <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e446" xlink:type="simple"/></inline-formula> up and down, the gain profile <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e447" xlink:type="simple"/></inline-formula> does not trivially scale up and down. When input intensity decreases, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e448" xlink:type="simple"/></inline-formula> at which <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e449" xlink:type="simple"/></inline-formula> becomes smaller, thereby decreasing the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e450" xlink:type="simple"/></inline-formula> at which <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e451" xlink:type="simple"/></inline-formula> peaks. Consequently, the gain profile turns from being band-pass to being low-pass (<xref ref-type="fig" rid="pcbi-1002123-g004">Figure 4A</xref>).</p>
        <fig id="pcbi-1002123-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002123.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>The effect of signal-to-noise ratio (SNR) on gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e452" xlink:type="simple"/></inline-formula> and the spectral receptive field (SRF).</title>
            <p>Same stimulus ensemble as in <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3A</xref> except the overall SNR has been scaled by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e453" xlink:type="simple"/></inline-formula>. (A) Gain control (red), signal (blue), and noise power (black) under high, medium and low SNR. (B) The corresponding SRFs of one output neuron (channel #120) in the three SNR cases.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.g004" xlink:type="simple"/>
        </fig>
        <p>The non-zero gain at higher <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e454" xlink:type="simple"/></inline-formula> implies sensitivity to weaker principal components with more spectral oscillations (or higher “ripple frequencies”). Thus, as input intensity decreases, the overall SRF filter changes in two ways (<xref ref-type="fig" rid="pcbi-1002123-g004">Figure 4B</xref>): (1) it fluctuates less (i.e., has fewer excitatory and inhibitory regions, and with decreased strength inhibitory regions); (2) the width of the excitatory and inhibitory regions increases, as the result of losing contributions from spectral modulations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e455" xlink:type="simple"/></inline-formula> with higher modulation frequencies.</p>
        <p>The insights from <xref ref-type="fig" rid="pcbi-1002123-g004">Figure 4B</xref> can help to understand the difference between the four SRFs in <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3E</xref>. Given the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e456" xlink:type="simple"/></inline-formula> as in <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3</xref>, one may divide the whole sound frequency range into two ranges of equal bandwidth, one for the lower and the other for the higher <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e457" xlink:type="simple"/></inline-formula>'s, and treat the two ranges as if they were two different stimulus ensembles. If one ignores the overall sound frequency difference between these two ensembles, then these two ensembles differ from each other only in their SNRs, with a higher SNR for the ensemble for the lower sound frequencies <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e458" xlink:type="simple"/></inline-formula>. In this perspective, one can understand why a SRF tuned to the lower frequencies in <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3E</xref> has a narrower excitatory region and a stronger surround suppression than a SRF tuned to higher frequencies, using the insights gained from <xref ref-type="fig" rid="pcbi-1002123-g004">Figure 4</xref>. (In comparing <xref ref-type="fig" rid="pcbi-1002123-g004">Figure 4B</xref> with <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3E</xref>, one should note that each SRF in <xref ref-type="fig" rid="pcbi-1002123-g004">Figure 4B</xref> is depicted by zooming to the frequency region around the preferred frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e459" xlink:type="simple"/></inline-formula> of the SRF.) One may even view the four SRFs in <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3E</xref> as if they were each exposed to one of the four different stimulus ensembles that differ in SNRs (and in sound frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e460" xlink:type="simple"/></inline-formula>, and we ignore this difference). Within each of these stimulus ensembles, the input statistics may be seen as approximately translation invariant, since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e461" xlink:type="simple"/></inline-formula> is almost independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e462" xlink:type="simple"/></inline-formula> and the correlation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e463" xlink:type="simple"/></inline-formula> is approximately only a function of the frequency difference <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e464" xlink:type="simple"/></inline-formula> within a small range of frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e465" xlink:type="simple"/></inline-formula>.</p>
      </sec>
      <sec id="s3c">
        <title>Adaptation of SRF to input signal correlation</title>
        <p>As well as adapting to the input SNR, the SRF can adapt to the signal correlations in the input. These can also vary across auditory environments. We generate two stimulus ensembles (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e466" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e467" xlink:type="simple"/></inline-formula>) based on equation (11), with short and long range (in frequency space) correlations between inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e468" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e469" xlink:type="simple"/></inline-formula> of different sound frequencies. We do this by setting the smoothing length <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e470" xlink:type="simple"/></inline-formula> in equation (13) to be <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e471" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e472" xlink:type="simple"/></inline-formula>. Since short and long range correlations give respectively smaller and larger correlations or degrees of input redundancy, in this paper, we use the terms short/long-range and small/large correlations interchangeably. The two stimulus ensembles are made to have the same overall signal power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e473" xlink:type="simple"/></inline-formula>, and consequently their <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e474" xlink:type="simple"/></inline-formula> vs. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e475" xlink:type="simple"/></inline-formula> curves cross each other at a particular frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e476" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002123-g005">Figure 5A</xref>). In <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e477" xlink:type="simple"/></inline-formula>, signal power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e478" xlink:type="simple"/></inline-formula> is more concentrated in lower <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e479" xlink:type="simple"/></inline-formula>'s, and the “bandwidth” of gain, i.e., the range of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e480" xlink:type="simple"/></inline-formula>'s with substantial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e481" xlink:type="simple"/></inline-formula>, is consequently narrower.</p>
        <fig id="pcbi-1002123-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002123.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Adaptation of gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e482" xlink:type="simple"/></inline-formula> and spectral filter kernel SRF to input correlations under high/low SNR.</title>
            <p>Same input ensemble as that in <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3A</xref>, except that the smoothing parameter, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e483" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e484" xlink:type="simple"/></inline-formula>, are set for short and long range correlations, respectively. Analogous figure format as in <xref ref-type="fig" rid="pcbi-1002123-g004">Figure 4</xref>, with added illustrations of the adaptation to input correlations. The thick and thin curves correspond to quantities for inputs with large and small correlations respectively, blue/red curves plot signal power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e485" xlink:type="simple"/></inline-formula> and gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e486" xlink:type="simple"/></inline-formula> respectively.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.g005" xlink:type="simple"/>
        </fig>
        <p>If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e487" xlink:type="simple"/></inline-formula> at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e488" xlink:type="simple"/></inline-formula>, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e489" xlink:type="simple"/></inline-formula> at which signal power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e490" xlink:type="simple"/></inline-formula> is larger in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e491" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002123-g005">Figure 5A</xref>, upper panel, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e492" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e493" xlink:type="simple"/></inline-formula> = 1, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e494" xlink:type="simple"/></inline-formula>). Thus, the frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e495" xlink:type="simple"/></inline-formula> at which gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e496" xlink:type="simple"/></inline-formula> peaks is also larger in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e497" xlink:type="simple"/></inline-formula>. If the SNR is lower, so that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e498" xlink:type="simple"/></inline-formula> at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e499" xlink:type="simple"/></inline-formula>, then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e500" xlink:type="simple"/></inline-formula> is instead smaller in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e501" xlink:type="simple"/></inline-formula> than in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e502" xlink:type="simple"/></inline-formula>. However, this is less apparent since gain profiles in both ensembles become “low-pass” in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e503" xlink:type="simple"/></inline-formula> implying that there is no obvious “peak position” (<xref ref-type="fig" rid="pcbi-1002123-g005">Figure 5A</xref>, lower panel, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e504" xlink:type="simple"/></inline-formula> ). Nevertheless, the cutoff frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e505" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e506" xlink:type="simple"/></inline-formula> is always smaller for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e507" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002123-g005">Figure 5A</xref>), and the optimal SRFs for it consequently enjoy a greater spectral extent (i.e., the SRFs are non-zero for a larger range of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e508" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002123-g005">Figure 5B</xref>). Intuition for this effect is that for it to be effective as either a contrast enhancing filter at a high SNR, or a smoothing filter at a low SNR, the SRF's spectral extent should match the range of the input correlations.</p>
      </sec>
      <sec id="s3d">
        <title>The temporal filter TRF</title>
        <p>We can similarly ignore the frequency dimension of the input to understand the temporal receptive field (TRF). This is determined from the way <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e509" xlink:type="simple"/></inline-formula>+noise, the input temporal sequence <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e510" xlink:type="simple"/></inline-formula> is transformed to the output temporal sequence <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e511" xlink:type="simple"/></inline-formula>. In a statistically stable auditory environment, the input correlation should be time shift invariant, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e512" xlink:type="simple"/></inline-formula> should depend only on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e513" xlink:type="simple"/></inline-formula>. Denote <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e514" xlink:type="simple"/></inline-formula>. Then, the de-correlating transform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e515" xlink:type="simple"/></inline-formula> should just be a Fourier transform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e516" xlink:type="simple"/></inline-formula> with the principal component <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e517" xlink:type="simple"/></inline-formula> being the Fourier Amplitude of the relevant mode. Here we use index <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e518" xlink:type="simple"/></inline-formula> instead of k to denote the principal component to signify the association with the temporal Fourier amplitude. The average power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e519" xlink:type="simple"/></inline-formula> is simply the Fourier transform of the input temporal correlation. If we set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e520" xlink:type="simple"/></inline-formula> in equation (12) to generate inputs with shift invariant correlation, then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e521" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e522" xlink:type="simple"/></inline-formula> is the Fourier amplitude of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e523" xlink:type="simple"/></inline-formula>. The gain control <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e524" xlink:type="simple"/></inline-formula> in the second encoding step is determined by equation (6) (substituting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e525" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e526" xlink:type="simple"/></inline-formula>). The final TRF will be the transform <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e527" xlink:type="simple"/></inline-formula> given an appropriate choice of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e528" xlink:type="simple"/></inline-formula>.</p>
        <p>However, the actual procedure to obtain the TRF is trickier in that the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e529" xlink:type="simple"/></inline-formula> transform in the third encoding step to give the overall <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e530" xlink:type="simple"/></inline-formula> has to be chosen to satisfy the causality constraint. That is, the output <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e531" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e532" xlink:type="simple"/></inline-formula> should only depend on past input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e533" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e534" xlink:type="simple"/></inline-formula>, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e535" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e536" xlink:type="simple"/></inline-formula>. Moreover, it is better for the TRF to have a short temporal span and latency, an outcome that can be achieved by assuming that the optimal temporal filter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e537" xlink:type="simple"/></inline-formula> has a minimum phase-shift <xref ref-type="bibr" rid="pcbi.1002123-Oppenheim1">[57]</xref>. Short latency can feasibly be implemented by neural synaptic and membrane mechanisms that typically have time constants no longer than a few hundred milliseconds <xref ref-type="bibr" rid="pcbi.1002123-Nagel2">[58]</xref>. Hence, these offer credible constraints on the TRF. Note that if we choose <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e538" xlink:type="simple"/></inline-formula>, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e539" xlink:type="simple"/></inline-formula>, then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e540" xlink:type="simple"/></inline-formula>would be an even function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e541" xlink:type="simple"/></inline-formula> and thus not a causal temporal filter given gains <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e542" xlink:type="simple"/></inline-formula> that are all real. The filter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e543" xlink:type="simple"/></inline-formula> can be made causal and minimal phase by choosing another <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e544" xlink:type="simple"/></inline-formula> simply as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e545" xlink:type="simple"/></inline-formula> with a particular phase function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e546" xlink:type="simple"/></inline-formula>, so that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e547" xlink:type="simple"/></inline-formula>. Instead of directly obtaining this phase function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e548" xlink:type="simple"/></inline-formula>, we can also equivalently obtain this minimum phase shift causal filter by transforming the acausal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e549" xlink:type="simple"/></inline-formula> using standard procedures in signal processing theory as follows (see <xref ref-type="bibr" rid="pcbi.1002123-Oppenheim1">[57]</xref> for the proof). Given a non-causal filter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e550" xlink:type="simple"/></inline-formula> with finite non-zero values in discrete time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e551" xlink:type="simple"/></inline-formula>, first let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e552" xlink:type="simple"/></inline-formula> to make a causal filter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e553" xlink:type="simple"/></inline-formula> whose nonzero values are at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e554" xlink:type="simple"/></inline-formula>. Second define<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e555" xlink:type="simple"/></disp-formula>Among the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e556" xlink:type="simple"/></inline-formula> complex roots of the equation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e557" xlink:type="simple"/></inline-formula>, let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e558" xlink:type="simple"/></inline-formula> denote the roots with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e559" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e560" xlink:type="simple"/></inline-formula> the other roots with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e561" xlink:type="simple"/></inline-formula>. Third, let<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e562" xlink:type="simple"/></disp-formula>The coefficients <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e563" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e564" xlink:type="simple"/></inline-formula> are the values of the desired causal minimum phase filter. One example of this process is demonstrated in <xref ref-type="fig" rid="pcbi-1002123-g006">Figure 6A</xref> (before the minimum phase adjustment) and <xref ref-type="fig" rid="pcbi-1002123-g006">Figure 6B</xref> (after the minimum phase adjustment)(<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e565" xlink:type="simple"/></inline-formula>).</p>
        <fig id="pcbi-1002123-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002123.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Simulation of temporal receptive field TRF, when the spectral dimension is omitted.</title>
            <p>The same stimulus ensemble is used as in <xref ref-type="fig" rid="pcbi-1002123-g003">Figure 3A</xref>, except the factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e566" xlink:type="simple"/></inline-formula> in equation (12) to ensure translation invariance of correlation. (A;B) Demonstration of transforming an acausal temporal filter (A) to its causal minimum-phase counterpart (B) at a relatively high input SNR. (C) TRF for a relatively low input SNR.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.g006" xlink:type="simple"/>
        </fig>
        <p>The temporal kernel also depends on the SNR and the input correlations. The change in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e567" xlink:type="simple"/></inline-formula> when sound intensity becomes lower is similar to that in the spectral case: from band-pass to low-pass. A temporal kernel under lower SNR is demonstrated in <xref ref-type="fig" rid="pcbi-1002123-g006">Figure 6C</xref>. The changes in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e568" xlink:type="simple"/></inline-formula> and TRF with input correlations are analogous to those in the spectral case as well (figure not shown).</p>
      </sec>
      <sec id="s3e">
        <title>The two dimensional STRF</title>
        <p>Finally, we show examples of the two dimensional <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e569" xlink:type="simple"/></inline-formula>. Here, we extended the assumption of shift invariance in the input correlations to the spectral dimension for the convenience of calculation. This assumption is reasonable when individual STRFs cover sufficiently small ranges of frequencies that the correlation in the spectral space is almost translation invariant within that range, as we see in our SRF examples. Then, spectral and temporal dimensions can be de-correlated at the same time by performing a 2-D Fourier transform on inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e570" xlink:type="simple"/></inline-formula>, with the moving ripples as decorrelated channels, each denoted by a 2D index <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e571" xlink:type="simple"/></inline-formula> marking the spectral and temporal modulation frequencies.</p>
        <p>Let the signal power in the de-correlated channels <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e572" xlink:type="simple"/></inline-formula> for input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e573" xlink:type="simple"/></inline-formula> be <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e574" xlink:type="simple"/></inline-formula>. Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e575" xlink:type="simple"/></inline-formula> typically decays with modulation frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e576" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e577" xlink:type="simple"/></inline-formula> since most natural inputs have input correlation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e578" xlink:type="simple"/></inline-formula> that decays with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e579" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e580" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e581" xlink:type="simple"/></inline-formula> is a scale factor that controls the SNR. We use the following example in our simulations<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e582" xlink:type="simple"/><label>(15)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e583" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e584" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e585" xlink:type="simple"/></inline-formula> are parameters that control input correlation, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e586" xlink:type="simple"/></inline-formula> is a normalization factor. <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7A</xref> shows an example with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e587" xlink:type="simple"/></inline-formula> According to equation (8), the gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e588" xlink:type="simple"/></inline-formula> can be obtained as shown in <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7B</xref> (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e589" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e590" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e591" xlink:type="simple"/></inline-formula>). In particular, in the frequency range <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e592" xlink:type="simple"/></inline-formula> in which noise is negligible relative to the signal, the gain<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e593" xlink:type="simple"/><label>(16)</label></disp-formula>specifies the whitening filter of equation (14). This gain profile changes from being a band-pass to a low-pass two dimensional filter as the SNR is lowered.</p>
        <fig id="pcbi-1002123-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002123.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>The 2D STRFs/MTFs implied by efficient coding and found physiologically.</title>
            <p>(A) input power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e594" xlink:type="simple"/></inline-formula> (equation (15), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e595" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e596" xlink:type="simple"/></inline-formula>) in decorrelated channels. (B, C) MTF profile <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e597" xlink:type="simple"/></inline-formula> and the corresponding STRFs with two SNRs (scaled by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e598" xlink:type="simple"/></inline-formula>'s). (D) <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e599" xlink:type="simple"/></inline-formula> and STRF as in B;C (when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e600" xlink:type="simple"/></inline-formula>) except with larger input correlations (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e601" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e602" xlink:type="simple"/></inline-formula> in equation (15)). (E;F) Modulation transfer functions (MTFs) and their properties at low and high input sound intensities averaged over 40 IC neurons from Lesica and Grothe <xref ref-type="bibr" rid="pcbi.1002123-Lesica1">[7]</xref>. Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e603" xlink:type="simple"/></inline-formula> is the spectral-temporal modulation frequency where the MTF peaks. Modulation frequencies in E and F are normalized by the same value across cells and intensities. Error bars in E indicate standard errors. The magnitude patterns of the MTFs for all neurons are normalized to peak value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e604" xlink:type="simple"/></inline-formula>. Their average across neurons at each input intensity is then normalized to the same peak value and displayed in F.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.g007" xlink:type="simple"/>
        </fig>
        <p>As we noted before, efficient coding predicts the gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e605" xlink:type="simple"/></inline-formula>, or the modulation transfer function (MTF), but does not precisely determine the STRF shape. The latter depends on the less constrained <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e606" xlink:type="simple"/></inline-formula> transform. Therefore, we qualitatively compare our <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e607" xlink:type="simple"/></inline-formula> for two different <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e608" xlink:type="simple"/></inline-formula>'s with the MTFs obtained from physiological experiments under two different input sound levels. <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7E</xref> and <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7F</xref> are obtained from data on STRFs of 40 cells in the inferior colliculus of animals exposed to natural rain sound at low and high sound levels <xref ref-type="bibr" rid="pcbi.1002123-Lesica1">[7]</xref>. We first did a two-dimensional Fourier transform on the STRF of each cell to obtain its MTF. Then the spectral modulation frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e609" xlink:type="simple"/></inline-formula> and the temporal modulation frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e610" xlink:type="simple"/></inline-formula> where the MTF has its maximum value were identified and normalized by a fixed value across cells. The average <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e611" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e612" xlink:type="simple"/></inline-formula> across all cells are shown in <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7E</xref>. These two “peak frequencies” both increased when sound intensity increased. The physiological MTF averaged across all cells (<xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7F</xref>) also becomes higher pass, both spectrally and temporally, under higher sound intensities, as predicted by efficient coding (<xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7B</xref>).</p>
        <p>For completeness, we illustrate in <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7C</xref> the model STRFs from the gain profiles <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e613" xlink:type="simple"/></inline-formula>, using an inverse Fourier transform with a proper phase function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e614" xlink:type="simple"/></inline-formula> as the candidate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e615" xlink:type="simple"/></inline-formula> matrix. Specifically, the model STRF is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e616" xlink:type="simple"/></disp-formula>where the phase <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e617" xlink:type="simple"/></inline-formula> is chosen to make the STRF causal, and with minimum phase shifts in the temporal dimension. In practice, the STRF is obtained as follows, by extending our method for obtaining the causal 1-D TRF. For each <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e618" xlink:type="simple"/></inline-formula>, we first obtain the temporal acausal filter<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e619" xlink:type="simple"/></disp-formula>and then transformed this into a causal minimum phase filter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e620" xlink:type="simple"/></inline-formula> as for the one dimensional TRF filter. The final two-dimensional STRF is then<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e621" xlink:type="simple"/></disp-formula>In general the model STRF has its highest amplitude at the preferred frequency on the spectral axis and for short latencies (i.e., the early part of the temporal axis). At low <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e622" xlink:type="simple"/></inline-formula>, the STRF has a large excitatory region and a weak inhibitory surround (<xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7C</xref>). At larger <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e623" xlink:type="simple"/></inline-formula>, the STRF involves more excitatory and inhibitory regions with an increased inhibitory strength. Overall this has a more band-pass gain profile. Meanwhile, the bandwidth for the gain <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e624" xlink:type="simple"/></inline-formula> increases with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e625" xlink:type="simple"/></inline-formula>, thus shrinking the width of the main excitatory region. Therefore, adaptation to higher sound levels makes the frequency-time tuning curve sharper, or equivalently more narrowly tuned and so, at a single cell level, supporting a more precise read out of the time and frequency of auditory input. Qualitatively, physiologically observed STRFs adapt to the input intensity in the same way <xref ref-type="bibr" rid="pcbi.1002123-Lesica1">[7]</xref> (also see <xref ref-type="bibr" rid="pcbi.1002123-Nagel1">[14]</xref>).</p>
        <p>The model also predicts changes to MTFs and STRFs for different input correlations. <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7D</xref> shows the gain function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e626" xlink:type="simple"/></inline-formula> and STRF for an example in which the input has longer-range correlations in both spectral and temporal dimensions (we set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e627" xlink:type="simple"/></inline-formula> while holding <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e628" xlink:type="simple"/></inline-formula> as in the high SNR case in <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7B and 7C</xref>). The peak modulation frequency in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e629" xlink:type="simple"/></inline-formula> is decreased, and the excitatory region is wider compared with counterparts in <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7B and 7C</xref> at high SNR. This is consistent with our 1-D results in the spectral dimension (<xref ref-type="fig" rid="pcbi-1002123-g005">Figure 5</xref>).</p>
      </sec>
    </sec>
    <sec id="s4">
      <title>Discussion</title>
      <sec id="s4a">
        <title>Summary of findings and predictions</title>
        <p>In summary, this study set out to understand the computational role of auditory spectro-temporal receptive fields (STRFs). In particular, we generalized previous work <xref ref-type="bibr" rid="pcbi.1002123-Lesica2">[26]</xref> by proposing that STRFs are efficient codes for inputs which retain maximal information for a given neural cost associated with the output. We analyzed this proposal in detail for the case that input signals and noise are approximated as Gaussian. Mathematically, the STRF transform can be shown <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref> to be composed of three abstract steps: input de-correlation, gain control, and multiplexing. For typical input statistics that are shift-invariant in sound frequency and time, the transform can be compared with two sorts of experimental data. First, gain control corresponds to the magnitude of the modulation transfer function of the STRFs. Second, by choosing the form of multiplexing to arrange the STRFs to have minimal phase, one can predict their full form. That the STRFs or the MTFs adapt to input statistics is a direct prediction of this efficient coding framework, since both the information conveyed and the neural coding cost depend on these statistics. Our efficient coding proposal is thus experimentally testable.</p>
        <p>We made two particular predictions about the adaptation of the STRFs, one associated with input intensity, the other with input correlation. For the case of intensity, we predicted that the MTF of the STRFs should become more low pass when input intensity is lowered. Intuitively, as long as inputs at nearby frequencies and times are correlated, a low pass filter smoothes the input to reduce noise, whereas a band pass filter extracts differences between input frequencies and times to remove redundancy. Compared with a band pass STRF, a low pass STRF has one or all of the following characteristics: (1) it has fewer excitatory and inhibitory regions; (2) each excitatory/inhibitory region has a larger size; (3) the secondary or opponent region, e.g., the inhibitory region for a STRF with an primary excitatory region, is weaker. All three characteristics help to smooth noise, a necessary strategy for weak inputs. In contrast, a band-pass filter has the opposite characteristics, so as not to increase the neural cost due to the transmission of redundant input information. These predictions are analogous to those seen in adaptations of visual coding to input SNR <xref ref-type="bibr" rid="pcbi.1002123-Srinivasan1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-vanHateren1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Atick5">[51]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Barlow2">[52]</xref>. They also generalize previous accounts of the adaptation of the temporal auditory filter <xref ref-type="bibr" rid="pcbi.1002123-Lesica2">[26]</xref> to input intensity.</p>
        <p>For the case of adaptation to input correlation, our framework predicts that the sizes of the excitatory and inhibitory regions of the STRFs should adapt to the range of input correlations. That is, input ensembles with longer range correlations in frequency and/or time should lead to STRFs with larger excitatory and inhibitory regions in the corresponding feature dimensions. Longer range input correlations are typically equivalent to greater input modulation power in the lower modulation frequency range in the stimulus ensemble. Equally, larger excitatory/inhibitory regions in the STRF are typically equivalent to its MTF being tuned to lower modulation frequencies. Thus, our prediction can be stated equivalently as saying that a stimulus ensemble with greater input power in the lower modulation frequency range, spectrally and/or temporally, should lead to neural MTFs tuned to the lower modulation frequency ranges. We demonstrated this form of adaptation for SRFs in <xref ref-type="fig" rid="pcbi-1002123-g005">Figure 5</xref>, and for STRFs in <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7</xref>. In particular, with a sufficiently high SNR, the MTF profile <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e630" xlink:type="simple"/></inline-formula> should whiten the ensemble specific input modulation power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e631" xlink:type="simple"/></inline-formula>.</p>
      </sec>
      <sec id="s4b">
        <title>Experimental evidence and tests of the predictions</title>
        <p>Various experimental observations pertain to these predictions about adaptation to input intensity. Lesica and Grothe <xref ref-type="bibr" rid="pcbi.1002123-Lesica1">[7]</xref> presented natural rain sounds to gerbils and found that, for a majority of cells in inferior colliculus (IC), the STRFs have more excitatory/inhibitory regions for higher input sound levels, and only have excitatory regions, or at least very weak inhibitory regions for lower sound levels. Nagel and Doupe <xref ref-type="bibr" rid="pcbi.1002123-Nagel1">[14]</xref> conducted a similar study in field L of songbirds, an area analogous to mammalian auditory cortex. In both spectral and temporal dimensions, they found that the excitatory/inhibitory regions of the STRFs become smaller and sharper under higher sound intensity, while the number of such regions do not increase. These results paralleled those of an earlier study in which they only examined the temporal dimension of the receptive fields <xref ref-type="bibr" rid="pcbi.1002123-Nagel2">[58]</xref>. Both studies are consistent with our proposal that the MTF changes from lower to higher pass when input intensity (and hence, SNR) increases. They thus offer complementary confirmation of our predictions.</p>
        <p>As mentioned in the Introduction, Lesica and Grothe <xref ref-type="bibr" rid="pcbi.1002123-Lesica2">[26]</xref> also examined the adaptation of the temporal receptive field(TRF) to vocalizations and ambient noises. They found that the TRF changed from being bandpass to lowpass when noise was mixed into the ensemble of vocalizations, and accounted for this finding in terms of efficient temporal coding. Their result can be understood as a special case of adaptation to SNR in our framework, focusing on the temporal dimension of the STRF, and treating the addition of noise as a reduction in input SNR. According to the principle of efficient coding, the spectral receptive field should also have changed from bandpass to lowpass when this noise was added.</p>
        <p>There are as yet few physiological experiments that pertain to our prediction about adaptation to input correlations. One study by Woolley et al <xref ref-type="bibr" rid="pcbi.1002123-Woolley1">[11]</xref> examined the STRFs of midbrain neurons in zebra finch in response to bird songs or modulation-limited noise. Compared to that of the noise, the input modulation power of the songs is more concentrated in lower modulation frequencies. The MTFs of the STRFs matched the corresponding modulation frequency spans, consistent with our theoretical prediction.</p>
        <p>The studies by Woolley et al <xref ref-type="bibr" rid="pcbi.1002123-Woolley1">[11]</xref> and Lesica and Grothe <xref ref-type="bibr" rid="pcbi.1002123-Lesica2">[26]</xref> could be extended to different ensembles of natural stimuli, e.g., songs, speech, animal vocalization, and environmental background, each with its own particular input correlations <xref ref-type="bibr" rid="pcbi.1002123-Rodriguez1">[59]</xref>. Findings from such extended studies would provide a stern test of the efficient coding framework. Generally, the input modulation power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e632" xlink:type="simple"/></inline-formula> in natural sounds decays with increasing modulation frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e633" xlink:type="simple"/></inline-formula>, at a rate that is specific to the ensemble <xref ref-type="bibr" rid="pcbi.1002123-Rodriguez1">[59]</xref>. Ensembles with faster decays have longer range input correlations (or larger correlations), as modelled in our <xref ref-type="fig" rid="pcbi-1002123-g005">Figure 5A</xref> and <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7BCD</xref>. We predict that this decay rate in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e634" xlink:type="simple"/></inline-formula> should dictate the shape of the neural MTFs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e635" xlink:type="simple"/></inline-formula>, such that ensembles with faster decay should lead to neural MTFs focusing on lower modulation frequency ranges. In particular, for high input SNR, the MTF profile should be that of a whitening filter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e636" xlink:type="simple"/></inline-formula>, with the upper frequency limit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e637" xlink:type="simple"/></inline-formula> for this whitening (beyond which MTF quickly decays to zero) being around the frequency at which <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e638" xlink:type="simple"/></inline-formula> is comparable to the power level of the noise. The recent study by Rodriguez et al <xref ref-type="bibr" rid="pcbi.1002123-Rodriguez1">[59]</xref> showed that inferior colliculus (IC) neurons, when examined collectively as a population, do seem to whiten typical natural stimuli, in that the population MTF <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e639" xlink:type="simple"/></inline-formula> increases with frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e640" xlink:type="simple"/></inline-formula> (up to a high frequency limit). This is to be expected for an efficient code, since natural input power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e641" xlink:type="simple"/></inline-formula> decreases with frequency. However, the neural STRFs in this study were obtained (using the moving ripple stimuli) without specific adaptation to any particular natural stimulus ensemble. We predict that if the STRFs had been measured under adaptation to the natural sounds for high SNR, then the neural MTF profile, at a neural population level if not at individual neuron level, should be ensemble specific, i.e., whitening the input power <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e642" xlink:type="simple"/></inline-formula> of the adapting stimuli.</p>
      </sec>
      <sec id="s4c">
        <title>The neural implementation of the efficient STRF and its adaptations</title>
        <p>We seek of the overall effective STRF rather than its realization. Thus, it is important to note that the three separate steps of our mathematical analysis of the efficient STRFs are purely abstract. They do not correspond to an actual physiological implementation. In principle, when a receptive field is entirely linear, it can as well be implemented in a single step, as in multiple linear steps in a cascade. Meanwhile, the observation that STRFs adapt to changes in the statistics of auditory inputs, and indeed that visual receptive fields expand when the visual environment changes from bright outdoors to dark indoors <xref ref-type="bibr" rid="pcbi.1002123-Barlow2">[52]</xref>, attest to the availability of the mechanisms for implementing (and thus adapting) efficient sensory coding.</p>
        <p>We speculate that the adaptation of a STRF in a midbrain auditory neuron is likely to involve gain control in many intervening and distributed neural processes upstream along the auditory pathway <xref ref-type="bibr" rid="pcbi.1002123-Robinson1">[60]</xref>. Even a simple adaptation of efficient coding, in the large monopolar cells (LMCs) in an insect compound eye to changes in the distribution of input contrasts in the visual environment, involves multiple stages of processes, some in the photoreceptors and others in lamina from the receptors to the LMCs <xref ref-type="bibr" rid="pcbi.1002123-Laughlin2">[61]</xref>. Synaptic and intrinsic mechanism were also found in the adaptation of retinal bipolar and ganglion cells to temporal contrast <xref ref-type="bibr" rid="pcbi.1002123-Rieke1">[62]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Kim2">[63]</xref>. Considering the multiple synapses from the hair cells to IC or auditory cortex, and the many recurrent and feedback networks with both excitatory and inhibitory connections <xref ref-type="bibr" rid="pcbi.1002123-LeBeau1">[64]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Caspary1">[65]</xref> in this pathway (for example, medial olivocochlear (MOC) efferent effects <xref ref-type="bibr" rid="pcbi.1002123-Guinan1">[66]</xref>), we speculate that gain control processes are likely to include synaptic facilitation and depression and distributed channel based adaptations. They should collectively achieve the effective adaptation in the gain such as the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e643" xlink:type="simple"/></inline-formula> in equation (6) and/or the underlying eigenmodes. Because there are multiple, redundant, and distributed synapses from the auditory periphery to the neuron whose STRF we model, a STRF could be implemented in multiple ways. Such implementational redundancy is likely to be needed to accommodate the many forms of adaptation that might be needed, given a limited degree of flexibility in any individual mechanism.</p>
        <p>The timescale of STRF adaptation to sound levels or input SNRs should be less than several or tens of seconds, or even shorter, since, in the physiological experiments, the stimulus duration for one sound intensity level is 40 s in <xref ref-type="bibr" rid="pcbi.1002123-Lesica1">[7]</xref> and 5 s in <xref ref-type="bibr" rid="pcbi.1002123-Nagel1">[14]</xref>, while adaptation to mixing noise into the vocalization inputs occurs within hundreds of milliseconds in <xref ref-type="bibr" rid="pcbi.1002123-Lesica2">[26]</xref>. Adaptation has been observed to occur over multiple time scales, ranging from tens of milliseconds to minutes in the fly visual system <xref ref-type="bibr" rid="pcbi.1002123-Wark1">[67]</xref>. In the auditory systems, midbrain neurons adapt to sound levels within hundreds of milliseconds <xref ref-type="bibr" rid="pcbi.1002123-Dean1">[68]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Dean2">[69]</xref>, while cortical adaptation happens over multiple timescales and is likely to arise from network activities <xref ref-type="bibr" rid="pcbi.1002123-Ulanovsky1">[70]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Ulanovsky2">[71]</xref>. We still know too little about the actual mechanisms for STRF adaptation <xref ref-type="bibr" rid="pcbi.1002123-Lesica2">[26]</xref> or sensory adaptation in general, although it has been suggested that channel based mechanisms at the cellular level are plausible candidates <xref ref-type="bibr" rid="pcbi.1002123-Wark1">[67]</xref>. Understanding the computational roles of the STRFs should motivate future investigations of these mechanisms.</p>
      </sec>
      <sec id="s4d">
        <title>Limitations of the framework</title>
        <p>As an initial attempt to understand the computational role of the STRFs, our framework has various limitations. First, the STRF model as a whole is quantitatively inaccurate since it specifies a linear mapping between sensory inputs and neural responses (in each adapted state). The accuracy could be improved in future work through the addition of a static nonlinearity after the STRF <xref ref-type="bibr" rid="pcbi.1002123-Eggermont2">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Lesica1">[7]</xref>. However, this would not be expected to lead to a qualitative change in STRFs or their adaptation. Extensions to dynamic nonlinearities would be much more complex. Second, for analytical convenience, we assumed that the input statistics are Gaussian, meaning that there are no input signal correlations higher than second order. The same approximation was made for the case of efficient visual coding, in the absence of good information about higher order input correlations <xref ref-type="bibr" rid="pcbi.1002123-Linsker1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Atick2">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>. Subsequent work using independent component analysis (ICA) on natural visual images avoided the Gaussian assumption, leading to models of visual encoding in primary visual cortex V1 <xref ref-type="bibr" rid="pcbi.1002123-Olshausen1">[72]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Bell1">[73]</xref>. This approach has been adopted to understand the STRFs in the auditory cortex <xref ref-type="bibr" rid="pcbi.1002123-Klein2">[74]</xref> and avian primary auditory area field L <xref ref-type="bibr" rid="pcbi.1002123-Greene1">[75]</xref>, although it cannot predict adaptation to SNR and its whitening prediction does not go beyond that obtained under the Gaussian assumption. It is still controversial whether higher order statistics are the cause for the dramatic difference between the V1 encoding and that in the retina and the lateral geniculate nucleus <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>. Furthermore, higher order correlations in natural visual inputs contribute much less redundancy (measured in signal entropy) than second order correlations <xref ref-type="bibr" rid="pcbi.1002123-Li1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Petrov1">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Hosseini1">[38]</xref>. This may explain why the Gaussian assumption was not overly deleterious to the predictions of the efficient coding principle in vision. Although higher order correlations in auditory inputs are also poorly understood, they do cause auditory adaptation, e.g., in stimulus-specific adaptation to complex temporal patterns of tones <xref ref-type="bibr" rid="pcbi.1002123-Nelken3">[76]</xref>. To what extent higher order input statistics can influence auditory encoding remains to be answered in future studies.</p>
        <p>Our focus on coding efficiency ignores aspects of auditory processing devoted to additional tasks such as sound source localization or stream segmentation. The observed STRFs may reflect elements of both efficient coding and requirements associated with these tasks. In fact, some variations are possible within the context of an efficient code. For instance, we have so far restricted ourselves by making all neurons share the same MTF profile predicted by efficient coding (by restricting the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e644" xlink:type="simple"/></inline-formula> transform to that in equation (9)). Relaxing this restriction would allow other STRFs. In particular, different neurons in the coding population could be tuned to different modulation frequency regions within the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e645" xlink:type="simple"/></inline-formula> extent covered by the overall MTF envelope <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e646" xlink:type="simple"/></inline-formula>, and could have different shapes. Accordingly, different STRFs could have different spectral bandwidths (or resolution) and shapes, in addition to preferring different center frequencies <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e647" xlink:type="simple"/></inline-formula>. Indeed, in the auditory cortex, different neurons exhibit different spectral resolutions, and even prefer different motion directions of the spectral ripples <xref ref-type="bibr" rid="pcbi.1002123-Wang1">[77]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Schreiner1">[78]</xref>, <xref ref-type="bibr" rid="pcbi.1002123-Depireux1">[19]</xref>. (Analogously, primary visual cortical neurons are tuned to multiple spatial sizes and prefer different orientations, a coding scheme that can be shown to be consistent with efficient coding <xref ref-type="bibr" rid="pcbi.1002123-Li1">[36]</xref>.) Such a collection of STRFs could satisfy the joint goals of coding efficiency and detecting ecologically meaningful auditory objects (such as vocalizations). Diversity in the shape and bandwidth of the STRFs is already present, although perhaps less so, sub-cortically, e.g., in inferior colliculus <xref ref-type="bibr" rid="pcbi.1002123-Schreiner1">[78]</xref>. When different neurons have different STRF bandwidths, our prediction that the input modulation power will be whitened by the neural MTFs should be modified, such that the ‘neural MTFs’ should mean the collective MTF of the whole neural population within a particular auditory stage (such as IC, see <xref ref-type="bibr" rid="pcbi.1002123-Rodriguez1">[59]</xref>).</p>
        <p>There could be alternative formulations (other than equation (4)) of the efficient coding principle, in particular, in the formulation of the neural cost. Our formulation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e648" xlink:type="simple"/></inline-formula> causes the degeneracy of the efficient coding solution, i.e., the existence of many choices of the equally efficient coding transforms, when the signals are gaussian. Other formulations of the neural cost could break this degeneracy. For example, formulation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e649" xlink:type="simple"/></inline-formula> in terms of the summation of individual neural channel capacity (or entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e650" xlink:type="simple"/></inline-formula>), or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002123.e651" xlink:type="simple"/></inline-formula> in terms of the total activity level, would generate neural codes to encourage very different MTFs for different neurons. In both audition and vision, the MTFs (in audition) and the contrast sensitivity functions (the vision analog of the MTFs) for different neurons tend to be similar in the sensory periphery (cochlear nucleus and retina), but they are increasingly disparate further towards the central brain. These changes could be caused by the different cost functions in the nervous system, or, as discussed in the previous paragraph, due to the breaking of the degeneracy by additional computational tasks further downstream along the sensory pathway.</p>
        <p>Redundancy redunction and information preservation are two essential ingredients of the efficient coding principle. While this principle has been quite successful in understanding the retinal coding, it cannot explain the enormous increase in the redundancy of the visual coding in the primary visual cortex (in which the number of neurons are about 100 times as many as those in the retina) <xref ref-type="bibr" rid="pcbi.1002123-Zhaoping1">[34]</xref>, nor the drastic loss of visual information outside the focus of attention in the higher visual areas without introducing task-dependent factors. It remains to be investigated how much and in what form the efficient coding will take further along the auditory pathway. One can expect that more processes will be devoted to solving specific auditory tasks, in addition to the task of sensory encoding, in the higher stages of auditory processing.</p>
      </sec>
      <sec id="s4e">
        <title>Concluding remarks</title>
        <p>This study was partly inspired by the success of the efficient coding principle in understanding receptive fields in the early stages of visual processing, and the way these receptive fields adapt across sensory environments. Analogies between visual and auditory processes have been explored by previous researchers <xref ref-type="bibr" rid="pcbi.1002123-Shamma2">[79]</xref>, and we expect that they can be carried further in higher level sensory processes including segmentation, selective attention <xref ref-type="bibr" rid="pcbi.1002123-Fritz1">[80]</xref>, and even object recognition.</p>
        <p>In conclusion, efficient coding provides a plausible computational interpretation of various recent experimental observations on STRFs, and notably the way they adapt to input environments. By making testable predictions, it motivates experimental directions which should hopefully lead to further insights and understanding.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>We are very grateful to Nick Lesica for providing us with the STRF data of 40 inferior colliculus neurons <xref ref-type="bibr" rid="pcbi.1002123-Lesica1">[7]</xref>, from which we obtained the physiological MTF plots in <xref ref-type="fig" rid="pcbi-1002123-g007">Figure 7</xref>. We would also like to thank very much Dr. Bo Hong and three anonymous reviewers for their very helpful comments, and to thank very much Peter Dayan for editing the English of the manuscript.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002123-Aertsen1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Aertsen</surname><given-names>AM</given-names></name><name name-style="western"><surname>Johannesma</surname><given-names>PI</given-names></name></person-group>             <year>1981</year>             <article-title>The spectro-temporal receptive field. A functional characteristic of auditory neurons.</article-title>             <source>Biol Cybern</source>             <volume>42</volume>             <fpage>133</fpage>             <lpage>43</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Escabi1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Escabi</surname><given-names>MA</given-names></name><name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name></person-group>             <year>2002</year>             <article-title>Nonlinear spectrotemporal sound analysis by neurons in the auditory midbrain.</article-title>             <source>J Neurosci</source>             <volume>22</volume>             <fpage>4114</fpage>             <lpage>4131</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Klein1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Klein</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Depireux</surname><given-names>DA</given-names></name><name name-style="western"><surname>Simon</surname><given-names>JZ</given-names></name><name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name></person-group>             <year>2000</year>             <article-title>Robust spectrotemporal reverse correlation for the auditory system: optimizing stimulus design.</article-title>             <source>J Comput Neurosci</source>             <volume>9</volume>             <fpage>85</fpage>             <lpage>111</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Theunissen1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name><name name-style="western"><surname>Doupe</surname><given-names>AJ</given-names></name></person-group>             <year>2000</year>             <article-title>Spectral-temporal receptive fields of nonlinear auditory neurons obtained using natural sounds.</article-title>             <source>J Neurosci</source>             <volume>20</volume>             <fpage>2315</fpage>             <lpage>31</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Eggermont1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Eggermont</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Johannesma</surname><given-names>PIM</given-names></name><name name-style="western"><surname>Aertsen</surname><given-names>AMHJ</given-names></name></person-group>             <year>1983</year>             <article-title>Reverse-correlation methods in auditory research.</article-title>             <source>Q Rev Biophys</source>             <volume>16</volume>             <fpage>341</fpage>             <lpage>414</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Eggermont2">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Eggermont</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Aertsen</surname><given-names>AMHJ</given-names></name><name name-style="western"><surname>Johannesma</surname><given-names>PIM</given-names></name></person-group>             <year>1983a</year>             <article-title>Quantitative characterisation procedure for auditory neurons based on the spectro-temporal receptive field.</article-title>             <source>Hearing Res</source>             <volume>10</volume>             <fpage>167</fpage>             <lpage>190</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Lesica1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lesica</surname><given-names>NA</given-names></name><name name-style="western"><surname>Grothe</surname><given-names>B</given-names></name></person-group>             <year>2008</year>             <article-title>Dynamic spectrotemporal feature selectivity in the auditory midbrain.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>5412</fpage>             <lpage>5421</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Eggermont3">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Eggermont</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Aertsen</surname><given-names>AMHJ</given-names></name><name name-style="western"><surname>Johannesma</surname><given-names>PIM</given-names></name></person-group>             <year>1983b</year>             <article-title>Prediction of the responses of auditory neurons in the midbrain of the grass frog based on the spectro-temporal receptive field.</article-title>             <source>Hearing Res</source>             <volume>10</volume>             <fpage>191</fpage>             <lpage>202</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Christianson1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Christianson</surname><given-names>GB</given-names></name><name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name><name name-style="western"><surname>Linden</surname><given-names>JF</given-names></name></person-group>             <year>2008</year>             <article-title>The consequences of response nonlinearities for interpretation of spectrotemporal receptive fields.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>446</fpage>             <lpage>455</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Gourevitch1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gourevitch</surname><given-names>B</given-names></name><name name-style="western"><surname>Norena</surname><given-names>A</given-names></name><name name-style="western"><surname>Shaw</surname><given-names>G</given-names></name><name name-style="western"><surname>Eggermont</surname><given-names>JJ</given-names></name></person-group>             <year>2008</year>             <article-title>Spectrotemporal receptive fields in anesthetized cat primary auditory cortex are context dependent.</article-title>             <source>Cereb Cortex</source>             <volume>19</volume>             <fpage>1448</fpage>             <lpage>1461</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Woolley1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Woolley</surname><given-names>SMN</given-names></name><name name-style="western"><surname>Gill</surname><given-names>PR</given-names></name><name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name></person-group>             <year>2006</year>             <article-title>Stimulus-dependent auditory tuning results in synchronous population coding of vocalizations in the songbird midbrain.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>2499</fpage>             <lpage>2512</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Yu1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Young</surname><given-names>ED</given-names></name></person-group>             <year>2000</year>             <article-title>Linear and nonlinear pathways of spectral information transmission in the cochlear nucleus.</article-title>             <source>P Natl Acad Sci U S A</source>             <volume>97</volume>             <fpage>11780</fpage>             <lpage>11785</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Young1">
        <label>13</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Young</surname><given-names>ED</given-names></name><name name-style="western"><surname>Oertel</surname><given-names>D</given-names></name></person-group>             <year>2003</year>             <article-title>The cochlear nucleus.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Shepherd</surname><given-names>G</given-names></name></person-group>             <source>Synaptic Organization of the Brain, Oxford Press, chapter 4. 5 edition</source>             <fpage>125</fpage>             <lpage>164</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Nagel1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nagel</surname><given-names>KI</given-names></name><name name-style="western"><surname>Doupe</surname><given-names>AJ</given-names></name></person-group>             <year>2008</year>             <article-title>Organizing principles of spectro-temporal encoding in the avian primary auditory area field L.</article-title>             <source>Neuron</source>             <volume>58</volume>             <fpage>938</fpage>             <lpage>955</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Kim1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>PJ</given-names></name><name name-style="western"><surname>Young</surname><given-names>ED</given-names></name></person-group>             <year>1994</year>             <article-title>Comparative analysis of spectro-temporal receptive fields, reverse correlation functions, and frequency tuning curves of auditory-nerve fibers.</article-title>             <source>J Acoust Soc Am</source>             <volume>95</volume>             <fpage>410</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Versnel1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Versnel</surname><given-names>H</given-names></name><name name-style="western"><surname>Zwiers</surname><given-names>MP</given-names></name><name name-style="western"><surname>van Opstal</surname><given-names>AJ</given-names></name></person-group>             <year>2009</year>             <article-title>Spectrotemporal response properties of inferior colliculus neurons in alert monkey.</article-title>             <source>J Neurosci</source>             <volume>29</volume>             <fpage>9725</fpage>             <lpage>9739</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Shamma1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name><name name-style="western"><surname>Versnel</surname><given-names>H</given-names></name></person-group>             <year>1995</year>             <article-title>Ripple analysis in ferret primary auditory cortex. II. Prediction of unit responses to arbitrary spectral profiles.</article-title>             <source>Audit Neurosci</source>             <volume>1</volume>             <fpage>255</fpage>             <lpage>270</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Kowalski1">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kowalski</surname><given-names>N</given-names></name><name name-style="western"><surname>Depireux</surname><given-names>DA</given-names></name><name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name></person-group>             <year>1996</year>             <article-title>Analysis of dynamic spectra in ferret primary auditory cortex. II. Prediction of unit responses to arbitrary dynamic spectra.</article-title>             <source>J Neurophysiol</source>             <volume>76</volume>             <fpage>3524</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Depireux1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Depireux</surname><given-names>DA</given-names></name><name name-style="western"><surname>Simon</surname><given-names>JZ</given-names></name><name name-style="western"><surname>Klein</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name></person-group>             <year>2001</year>             <article-title>Spectro-temporal response field characterization with dynamic ripples in ferret primary auditory cortex.</article-title>             <source>J Neurophysiol</source>             <volume>85</volume>             <fpage>1220</fpage>             <lpage>1234</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Schnupp1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schnupp</surname><given-names>JWH</given-names></name><name name-style="western"><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name><name name-style="western"><surname>King</surname><given-names>AJ</given-names></name></person-group>             <year>2001</year>             <article-title>Linear processing of spatial cues in primary auditory cortex.</article-title>             <source>Nature</source>             <volume>414</volume>             <fpage>200</fpage>             <lpage>204</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Nelken1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name><name name-style="western"><surname>Bar-Yosef</surname><given-names>O</given-names></name></person-group>             <year>2008</year>             <article-title>Neurons and objects: the case of auditory cortex.</article-title>             <source>Front Neurosci</source>             <volume>2</volume>             <fpage>107</fpage>             <lpage>113</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Barbour1">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Barbour</surname><given-names>DL</given-names></name><name name-style="western"><surname>Wang</surname><given-names>X</given-names></name></person-group>             <year>2003</year>             <article-title>Contrast tuning in auditory cortex.</article-title>             <source>Science</source>             <volume>299</volume>             <fpage>1073</fpage>             <lpage>1075</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Ahrens1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ahrens</surname><given-names>MB</given-names></name><name name-style="western"><surname>Linden</surname><given-names>JF</given-names></name><name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name></person-group>             <year>2008</year>             <article-title>Nonlinearities and contextual influences in auditory cortical responses modeled with multilinear spectrotemporal methods.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>1929</fpage>             <lpage>1942</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Lewicki1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name></person-group>             <year>2002</year>             <article-title>Efficient coding of natural sounds.</article-title>             <source>Nat Neurosci</source>             <volume>5</volume>             <fpage>356</fpage>             <lpage>363</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Smith1">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>EC</given-names></name><name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name></person-group>             <year>2006</year>             <article-title>Efficient auditory coding.</article-title>             <source>Nature</source>             <volume>439</volume>             <fpage>978</fpage>             <lpage>982</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Lesica2">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lesica</surname><given-names>NA</given-names></name><name name-style="western"><surname>Grothe</surname><given-names>B</given-names></name></person-group>             <year>2008</year>             <article-title>Efficient temporal processing of naturalistic sounds.</article-title>             <source>PLoS One</source>             <volume>3</volume>             <fpage>e1655</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Barlow1">
        <label>27</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Barlow</surname><given-names>HB</given-names></name></person-group>             <year>1961</year>             <article-title>Possible principles underlying the transformation of sensory messages.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Rosenblith</surname><given-names>WA</given-names></name></person-group>             <source>Sensory Communication</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>217</fpage>             <lpage>234</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Laughlin1">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Laughlin</surname><given-names>S</given-names></name></person-group>             <year>1981</year>             <article-title>A simple coding procedure enhances a neuron's information capacity.</article-title>             <source>Z Naturforsch C</source>             <volume>36</volume>             <fpage>910</fpage>             <lpage>912</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Srinivasan1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Srinivasan</surname><given-names>MV</given-names></name><name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name><name name-style="western"><surname>Dubs</surname><given-names>A</given-names></name></person-group>             <year>1982</year>             <article-title>Predictive coding: a fresh view of inhibition in the retina.</article-title>             <source>P Roy Soc Lond B Bio</source>             <volume>216</volume>             <fpage>427</fpage>             <lpage>459</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Linsker1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Linsker</surname><given-names>R</given-names></name></person-group>             <year>1990</year>             <article-title>Perceptual neural organization: some approaches based on network models and information theory.</article-title>             <source>Annu Rev Neurosci</source>             <volume>13</volume>             <fpage>257</fpage>             <lpage>281</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Atick1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name></person-group>             <year>1990</year>             <article-title>Towards a theory of early visual processing.</article-title>             <source>Neural Comput</source>             <volume>2</volume>             <fpage>308</fpage>             <lpage>320</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Atick2">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name></person-group>             <year>1992</year>             <article-title>Could information theory provide an ecological theory of sensory processing?</article-title>             <source>Network- Comp Neural</source>             <volume>3</volume>             <fpage>213</fpage>             <lpage>251</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-vanHateren1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name></person-group>             <year>1992</year>             <article-title>A theory of maximizing sensory information.</article-title>             <source>Biol Cybern</source>             <volume>68</volume>             <fpage>23</fpage>             <lpage>9</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Zhaoping1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zhaoping</surname><given-names>L</given-names></name></person-group>             <year>2006</year>             <article-title>Theoretical understanding of the early visual processes by data compression and data selection.</article-title>             <source>Network-Comp Neural</source>             <volume>17</volume>             <fpage>301</fpage>             <lpage>334</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Nelken2">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name><name name-style="western"><surname>Rotman</surname><given-names>Y</given-names></name><name name-style="western"><surname>Yosef</surname><given-names>OB</given-names></name></person-group>             <year>1999</year>             <article-title>Responses of auditory-cortex neurons to structural features of natural sounds.</article-title>             <source>Nature</source>             <volume>397</volume>             <fpage>154</fpage>             <lpage>157</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Li1">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>Z</given-names></name><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name></person-group>             <year>1994</year>             <article-title>Toward a theory of the striate cortex.</article-title>             <source>Neural Comput</source>             <volume>6</volume>             <fpage>127</fpage>             <lpage>146</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Petrov1">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Petrov</surname><given-names>Y</given-names></name><name name-style="western"><surname>Zhaoping</surname><given-names>L</given-names></name></person-group>             <year>2003</year>             <article-title>Local correlations, information redundancy, and sufficient pixel depth in natural images.</article-title>             <source>J Opt Soc Am A</source>             <volume>20</volume>             <fpage>56</fpage>             <lpage>66</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Hosseini1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hosseini</surname><given-names>R</given-names></name><name name-style="western"><surname>Sinz</surname><given-names>F</given-names></name><name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name></person-group>             <year>2010</year>             <article-title>Lower bounds on the redundancy of natural images.</article-title>             <source>Vision Res</source>             <volume>50</volume>             <fpage>2213</fpage>             <lpage>2222</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Field1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name></person-group>             <year>1987</year>             <article-title>Relations between the statistics of natural images and the response properties of cortical cells.</article-title>             <source>J Opt Soc Am A</source>             <volume>4</volume>             <fpage>2379</fpage>             <lpage>2394</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Kersten1">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kersten</surname><given-names>D</given-names></name></person-group>             <year>1987</year>             <article-title>Predictability and redundancy of natural images.</article-title>             <source>J Opt Soc Am A</source>             <volume>4</volume>             <fpage>2395</fpage>             <lpage>2400</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Ruderman1">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ruderman</surname><given-names>DL</given-names></name><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name></person-group>             <year>1994</year>             <article-title>Statistics of natural images: Scaling in the woods.</article-title>             <source>Phys Rev Lett</source>             <volume>73</volume>             <fpage>814</fpage>             <lpage>817</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Reinagel1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Reinagel</surname><given-names>P</given-names></name><name name-style="western"><surname>Zador</surname><given-names>AM</given-names></name></person-group>             <year>1999</year>             <article-title>Natural scene statistics at the centre of gaze.</article-title>             <source>Network-Comp Neural</source>             <volume>10</volume>             <fpage>341</fpage>             <lpage>350</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Daugman1">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Daugman</surname><given-names>JG</given-names></name></person-group>             <year>1989</year>             <article-title>Entropy reduction and decorrelation in visual coding by oriented neural receptive fields.</article-title>             <source>IEEE T Bio-Med Eng</source>             <volume>36</volume>             <fpage>107</fpage>             <lpage>114</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Atick3">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Li</surname><given-names>Z</given-names></name><name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name></person-group>             <year>1992</year>             <article-title>Understanding retinal color coding from first principles.</article-title>             <source>Neural Comput</source>             <volume>4</volume>             <fpage>559</fpage>             <lpage>572</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Atick4">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Li</surname><given-names>Z</given-names></name><name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name></person-group>             <year>1993</year>             <article-title>What does post-adaptation color appearance reveal about cortical color representation?</article-title>             <source>Vision Res</source>             <volume>33</volume>             <fpage>123</fpage>             <lpage>129</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Li2">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>Z</given-names></name><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name></person-group>             <year>1994</year>             <article-title>Efficient stereo coding in the multiscale representation.</article-title>             <source>Network-Comp Neural</source>             <volume>5</volume>             <fpage>157</fpage>             <lpage>174</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Zhaoping2">
        <label>47</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zhaoping</surname><given-names>L</given-names></name></person-group>             <year>1995</year>             <article-title>Understanding ocular dominance development from binocular input statistics.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Bower</surname><given-names>J</given-names></name></person-group>             <source>Proceeding of Computational Neuroscience Conference</source>             <publisher-loc>Monterey, California</publisher-loc>             <publisher-name>Kluwer Academic Publishers</publisher-name>             <fpage>397</fpage>             <lpage>402</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Chechik1">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chechik</surname><given-names>G</given-names></name><name name-style="western"><surname>Anderson</surname><given-names>MJ</given-names></name><name name-style="western"><surname>Bar-Yosef</surname><given-names>O</given-names></name><name name-style="western"><surname>Young</surname><given-names>ED</given-names></name><name name-style="western"><surname>Tishby</surname><given-names>N</given-names></name><etal/></person-group>             <year>2006</year>             <article-title>Reduction of information redundancy in the ascending auditory pathway.</article-title>             <source>Neuron</source>             <volume>51</volume>             <fpage>359</fpage>             <lpage>68</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Shannon1">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shannon</surname><given-names>CE</given-names></name></person-group>             <year>1948</year>             <article-title>A mathematical theory of communication.</article-title>             <source>Bell Syst Tech J</source>             <volume>27</volume>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Levy1">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Levy</surname><given-names>WB</given-names></name><name name-style="western"><surname>Baxter</surname><given-names>RA</given-names></name></person-group>             <year>1996</year>             <article-title>Energy efficient neural codes.</article-title>             <source>Neural Comput</source>             <volume>8</volume>             <fpage>531</fpage>             <lpage>543</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Atick5">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name></person-group>             <year>1992</year>             <article-title>What does the retina know about natural scenes?</article-title>             <source>Neural Comput</source>             <volume>4</volume>             <fpage>196</fpage>             <lpage>210</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Barlow2">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Barlow</surname><given-names>HB</given-names></name><name name-style="western"><surname>Fitzhugh</surname><given-names>R</given-names></name><name name-style="western"><surname>Kuffler</surname><given-names>SW</given-names></name></person-group>             <year>1957</year>             <article-title>Change of organization in the receptive fields of the cat's retina during dark adaptation.</article-title>             <source>J Physiol-London</source>             <volume>137</volume>             <fpage>338</fpage>             <lpage>354</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Glasberg1">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Glasberg</surname><given-names>BR</given-names></name><name name-style="western"><surname>Moore</surname><given-names>BCJ</given-names></name></person-group>             <year>1990</year>             <article-title>Derivation of auditory filter shapes from notched-noise data.</article-title>             <source>Hearing Res</source>             <volume>47</volume>             <fpage>103</fpage>             <lpage>138</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Escabi2">
        <label>54</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Escabi</surname><given-names>MA</given-names></name><name name-style="western"><surname>Miller</surname><given-names>LM</given-names></name><name name-style="western"><surname>Read</surname><given-names>HL</given-names></name><name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name></person-group>             <year>2003</year>             <article-title>Naturalistic auditory contrast improves spectrotemporal coding in the cat inferior colliculus.</article-title>             <source>J Neurosci</source>             <volume>23</volume>             <fpage>11489</fpage>             <lpage>11504</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Gill1">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gill</surname><given-names>P</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>J</given-names></name><name name-style="western"><surname>Woolley</surname><given-names>SMN</given-names></name><name name-style="western"><surname>Fremouw</surname><given-names>T</given-names></name><name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name></person-group>             <year>2006</year>             <article-title>Sound representation methods for spectro-temporal receptive field estimation.</article-title>             <source>J Comput Neurosci</source>             <volume>21</volume>             <fpage>5</fpage>             <lpage>20</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Young2">
        <label>56</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Young</surname><given-names>ED</given-names></name><name name-style="western"><surname>Calhoun</surname><given-names>BM</given-names></name></person-group>             <year>2005</year>             <article-title>Nonlinear modeling of auditory-nerve rate responses to wideband stimuli.</article-title>             <source>J Neurophysiol</source>             <volume>94</volume>             <fpage>4441</fpage>             <lpage>4454</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Oppenheim1">
        <label>57</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Oppenheim</surname><given-names>AV</given-names></name><name name-style="western"><surname>Willsky</surname><given-names>AS</given-names></name><name name-style="western"><surname>Nawab</surname><given-names>SH</given-names></name></person-group>             <year>1997</year>             <source>Signals and systems</source>             <publisher-name>Prentice Hall, 2 edition</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Nagel2">
        <label>58</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nagel</surname><given-names>KI</given-names></name><name name-style="western"><surname>Doupe</surname><given-names>AJ</given-names></name></person-group>             <year>2006</year>             <article-title>Temporal processing and adaptation in the songbird auditory forebrain.</article-title>             <source>Neuron</source>             <volume>51</volume>             <fpage>845</fpage>             <lpage>859</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Rodriguez1">
        <label>59</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rodriguez</surname><given-names>FA</given-names></name><name name-style="western"><surname>Chen</surname><given-names>C</given-names></name><name name-style="western"><surname>Read</surname><given-names>HL</given-names></name><name name-style="western"><surname>Escabi</surname><given-names>MA</given-names></name></person-group>             <year>2010</year>             <article-title>Neural modulation tuning characteristics scale to efficiently encode natural sound statistics.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>15969</fpage>             <lpage>15980</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Robinson1">
        <label>60</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Robinson</surname><given-names>B</given-names></name><name name-style="western"><surname>McAlpine</surname><given-names>D</given-names></name></person-group>             <year>2009</year>             <article-title>Gain control mechanisms in the auditory pathway.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>19</volume>             <fpage>402</fpage>             <lpage>407</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Laughlin2">
        <label>61</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name><name name-style="western"><surname>Hardie</surname><given-names>RC</given-names></name></person-group>             <year>1978</year>             <article-title>Common strategies for light adaptation in the peripheral visual systems of fly and dragonfly.</article-title>             <source>J Comp Physiol A</source>             <volume>128</volume>             <fpage>319</fpage>             <lpage>340</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Rieke1">
        <label>62</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rieke</surname><given-names>F</given-names></name></person-group>             <year>2001</year>             <article-title>Temporal contrast adaptation in salamander bipolar cells.</article-title>             <source>J Neurosci</source>             <volume>21</volume>             <fpage>9445</fpage>             <lpage>9454</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Kim2">
        <label>63</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Rieke</surname><given-names>F</given-names></name></person-group>             <year>2001</year>             <article-title>Temporal contrast adaptation in the input and output signals of salamander retinal ganglion cells.</article-title>             <source>J Neurosci</source>             <volume>21</volume>             <fpage>287</fpage>             <lpage>299</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-LeBeau1">
        <label>64</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Le Beau</surname><given-names>FE</given-names></name><name name-style="western"><surname>Rees</surname><given-names>A</given-names></name><name name-style="western"><surname>Malmierca</surname><given-names>MS</given-names></name></person-group>             <year>1996</year>             <article-title>Contribution of gaba-and glycine-mediated inhibition to the monaural temporal response properties of neurons in the inferior colliculus.</article-title>             <source>J Neurophysiol</source>             <volume>75</volume>             <fpage>902</fpage>             <lpage>919</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Caspary1">
        <label>65</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Caspary</surname><given-names>DM</given-names></name><name name-style="western"><surname>Palombi</surname><given-names>PS</given-names></name><name name-style="western"><surname>Hughes</surname><given-names>LF</given-names></name></person-group>             <year>2002</year>             <article-title>Gabaergic inputs shape responses to amplitude modulated stimuli in the inferior colliculus.</article-title>             <source>Hearing Res</source>             <volume>168</volume>             <fpage>163</fpage>             <lpage>173</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Guinan1">
        <label>66</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Guinan</surname><given-names>JJ</given-names><suffix>Jr</suffix></name></person-group>             <year>2006</year>             <article-title>Olivocochlear efferents: anatomy, physiology, function, and the measurement of efferent effects in humans.</article-title>             <source>Ear Hearing</source>             <volume>27</volume>             <fpage>589</fpage>             <lpage>607</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Wark1">
        <label>67</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wark</surname><given-names>B</given-names></name><name name-style="western"><surname>Lundstrom</surname><given-names>BN</given-names></name><name name-style="western"><surname>Fairhall</surname><given-names>A</given-names></name></person-group>             <year>2007</year>             <article-title>Sensory adaptation.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>17</volume>             <fpage>423</fpage>             <lpage>429</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Dean1">
        <label>68</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dean</surname><given-names>I</given-names></name><name name-style="western"><surname>Robinson</surname><given-names>BL</given-names></name><name name-style="western"><surname>Harper</surname><given-names>NS</given-names></name><name name-style="western"><surname>McAlpine</surname><given-names>D</given-names></name></person-group>             <year>2008</year>             <article-title>Rapid neural adaptation to sound level statistics.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>6430</fpage>             <lpage>6438</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Dean2">
        <label>69</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dean</surname><given-names>I</given-names></name><name name-style="western"><surname>Harper</surname><given-names>NS</given-names></name><name name-style="western"><surname>McAlpine</surname><given-names>D</given-names></name></person-group>             <year>2005</year>             <article-title>Neural population coding of sound level adapts to stimulus statistics.</article-title>             <source>Nat Neurosci</source>             <volume>8</volume>             <fpage>1684</fpage>             <lpage>1689</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Ulanovsky1">
        <label>70</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ulanovsky</surname><given-names>N</given-names></name><name name-style="western"><surname>Las</surname><given-names>L</given-names></name><name name-style="western"><surname>Farkas</surname><given-names>D</given-names></name><name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name></person-group>             <year>2004</year>             <article-title>Multiple time scales of adaptation in auditory cortex neurons.</article-title>             <source>J Neurosci</source>             <volume>24</volume>             <fpage>10440</fpage>             <lpage>10453</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Ulanovsky2">
        <label>71</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ulanovsky</surname><given-names>N</given-names></name><name name-style="western"><surname>Las</surname><given-names>L</given-names></name><name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name></person-group>             <year>2003</year>             <article-title>Processing of low-probability sounds by cortical neurons.</article-title>             <source>Nat Neurosci</source>             <volume>6</volume>             <fpage>391</fpage>             <lpage>398</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Olshausen1">
        <label>72</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name><name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name></person-group>             <year>1997</year>             <article-title>Sparse coding with an overcomplete basis set: A strategy employed by v1?</article-title>             <source>Vision Res</source>             <volume>37</volume>             <fpage>3311</fpage>             <lpage>3325</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Bell1">
        <label>73</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bell</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>1997</year>             <article-title>The “independent components” of natural scenes are edge filters.</article-title>             <source>Vision Res</source>             <volume>37</volume>             <fpage>3327</fpage>             <lpage>3338</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Klein2">
        <label>74</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Klein</surname><given-names>DJ</given-names></name><name name-style="western"><surname>König</surname><given-names>P</given-names></name><name name-style="western"><surname>Körding</surname><given-names>KP</given-names></name></person-group>             <year>2003</year>             <article-title>Sparse spectrotemporal coding of sounds.</article-title>             <source>EURASIP J Appl Sig P</source>             <volume>7</volume>             <fpage>659</fpage>             <lpage>667</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Greene1">
        <label>75</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Greene</surname><given-names>G</given-names></name><name name-style="western"><surname>Barrett</surname><given-names>DGT</given-names></name><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name><name name-style="western"><surname>Houghton</surname><given-names>C</given-names></name></person-group>             <year>2009</year>             <article-title>Sparse coding of birdsong and receptive field structure in songbirds.</article-title>             <source>Network-Comp Neural</source>             <volume>20</volume>             <fpage>162</fpage>             <lpage>177</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Nelken3">
        <label>76</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name></person-group>             <year>2004</year>             <article-title>Processing of complex stimuli and natural scenes in the auditory cortex.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>14</volume>             <fpage>474</fpage>             <lpage>480</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Wang1">
        <label>77</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>K</given-names></name><name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name></person-group>             <year>1995</year>             <article-title>Spectral shape analysis in the central auditory system.</article-title>             <source>IEEE T Speech Audi P</source>             <volume>3</volume>             <fpage>382</fpage>             <lpage>395</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Schreiner1">
        <label>78</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name><name name-style="western"><surname>Read</surname><given-names>HL</given-names></name><name name-style="western"><surname>Sutter</surname><given-names>ML</given-names></name></person-group>             <year>2000</year>             <article-title>Modular organization of frequency integration in primary auditory cortex.</article-title>             <source>Annu Rev Neurosci</source>             <volume>23</volume>             <fpage>501</fpage>             <lpage>529</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Shamma2">
        <label>79</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name></person-group>             <year>2001</year>             <article-title>On the role of space and time in auditory processing.</article-title>             <source>Trends Cogn Sci</source>             <volume>5</volume>             <fpage>340</fpage>             <lpage>348</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002123-Fritz1">
        <label>80</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fritz</surname><given-names>JB</given-names></name><name name-style="western"><surname>Elhilali</surname><given-names>M</given-names></name><name name-style="western"><surname>David</surname><given-names>SV</given-names></name><name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name></person-group>             <year>2007</year>             <article-title>Auditory attention-focusing the searchlight on sound.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>17</volume>             <fpage>437</fpage>             <lpage>455</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>
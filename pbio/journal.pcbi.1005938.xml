<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-01033</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005938</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain mapping</subject><subj-group><subject>Magnetoencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Magnetoencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Magnetoencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Artificial intelligence</subject><subj-group><subject>Machine learning</subject><subj-group><subject>Support vector machines</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Artificial intelligence</subject><subj-group><subject>Machine learning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Visual cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Visual cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Grammar</subject><subj-group><subject>Phonology</subject><subj-group><subject>Syllables</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Information technology</subject><subj-group><subject>Data processing</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Across-subjects classification of stimulus modality from human MEG high frequency activity</article-title>
<alt-title alt-title-type="running-head">Classifying stimulus modality from MEG high frequency activity</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3231-1076</contrib-id>
<name name-style="western">
<surname>Westner</surname> <given-names>Britta U.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1699-7218</contrib-id>
<name name-style="western">
<surname>Dalal</surname> <given-names>Sarang S.</given-names></name>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Hanslmayr</surname> <given-names>Simon</given-names></name>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Staudigl</surname> <given-names>Tobias</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Department of Psychology, University of Konstanz, Konstanz, Germany</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Center of Functionally Integrative Neuroscience, Department of Clinical Medicine, Aarhus University, Aarhus, Denmark</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>School of Psychology, University of Birmingham, Birmingham, United Kingdom</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>Donders Institute for Brain, Cognition and Behaviour, Radboud University, Nijmegen, The Netherlands</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Bush</surname> <given-names>Daniel</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University College London, UNITED KINGDOM</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">britta.wstnr@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>3</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="epub">
<day>12</day>
<month>3</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>3</issue>
<elocation-id>e1005938</elocation-id>
<history>
<date date-type="received">
<day>27</day>
<month>6</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>20</day>
<month>12</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Westner et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005938"/>
<abstract>
<p>Single-trial analyses have the potential to uncover meaningful brain dynamics that are obscured when averaging across trials. However, low signal-to-noise ratio (SNR) can impede the use of single-trial analyses and decoding methods. In this study, we investigate the applicability of a single-trial approach to decode stimulus modality from magnetoencephalographic (MEG) high frequency activity. In order to classify the auditory versus visual presentation of words, we combine beamformer source reconstruction with the random forest classification method. To enable group level inference, the classification is embedded in an across-subjects framework. We show that single-trial gamma SNR allows for good classification performance (accuracy across subjects: 66.44%). This implies that the characteristics of high frequency activity have a high consistency across trials and subjects. The random forest classifier assigned informational value to activity in both auditory and visual cortex with high spatial specificity. Across time, gamma power was most informative during stimulus presentation. Among all frequency bands, the 75 Hz to 95 Hz band was the most informative frequency band in visual as well as in auditory areas. Especially in visual areas, a broad range of gamma frequencies (55 Hz to 125 Hz) contributed to the successful classification. Thus, we demonstrate the feasibility of single-trial approaches for decoding the stimulus modality across subjects from high frequency activity and describe the discriminative gamma activity in time, frequency, and space.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Averaging brain activity across trials is a powerful way to increase signal-to-noise ratio in MEG data. This approach, however, potentially obscures meaningful brain dynamics that unfold on the single-trial level. Single-trial analyses have been successfully applied to time domain or low frequency oscillatory activity; its application to MEG high frequency activity is hindered by the low amplitude of these signals. In the present study, we show that stimulus modality (visual versus auditory presentation of words) can successfully be decoded from single-trial MEG high frequency activity by combining source reconstruction with a random forest classification algorithm. This approach reveals patterns of activity above 75 Hz in both visual and auditory cortex, highlighting the importance of high frequency activity for the processing of domain-specific stimuli. Thereby, our results extend prior findings by revealing high-frequency activity in auditory cortex related to auditory word stimuli in MEG data. The adopted across-subjects framework furthermore suggests a high inter-individual consistency in the high frequency activity patterns.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100002347</institution-id>
<institution>Bundesministerium für Bildung und Forschung</institution>
</institution-wrap>
</funding-source>
<award-id>01EW1307</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1699-7218</contrib-id>
<name name-style="western">
<surname>Dalal</surname> <given-names>Sarang S.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000781</institution-id>
<institution>European Research Council</institution>
</institution-wrap>
</funding-source>
<award-id>640488</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1699-7218</contrib-id>
<name name-style="western">
<surname>Dalal</surname> <given-names>Sarang S.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001659</institution-id>
<institution>Deutsche Forschungsgemeinschaft</institution>
</institution-wrap>
</funding-source>
<award-id>HA 5622/1-1</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Hanslmayr</surname> <given-names>Simon</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000781</institution-id>
<institution>European Research Council</institution>
</institution-wrap>
</funding-source>
<award-id>647954</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Hanslmayr</surname> <given-names>Simon</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award005">
<funding-source>
<institution>Wolfson Society</institution>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Hanslmayr</surname> <given-names>Simon</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award006">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000288</institution-id>
<institution>Royal Society</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Hanslmayr</surname> <given-names>Simon</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award007">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100007601</institution-id>
<institution>Horizon 2020</institution>
</institution-wrap>
</funding-source>
<award-id>661373</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Staudigl</surname> <given-names>Tobias</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by ERA-Net NEURON via the German Federal Ministry of Education and Research, <ext-link ext-link-type="uri" xlink:href="http://www.neuron-eranet.eu/" xlink:type="simple">http://www.neuron-eranet.eu/</ext-link>, grant 01EW1307, to SSD; European Research Council, <ext-link ext-link-type="uri" xlink:href="https://erc.europa.eu/" xlink:type="simple">https://erc.europa.eu/</ext-link>, Starting Grant 640488, to SSD; Deutsche Forschungsgemeinschaft, <ext-link ext-link-type="uri" xlink:href="http://www.dfg.de/" xlink:type="simple">http://www.dfg.de/</ext-link>, Emmy Noether Programme Grant HA 5622/1-1, to SH; European Research Council, <ext-link ext-link-type="uri" xlink:href="https://erc.europa.eu/" xlink:type="simple">https://erc.europa.eu/</ext-link>, Consolidator Grant 647954, to SH; Wolfson Foundation and Royal Society, <ext-link ext-link-type="uri" xlink:href="https://royalsociety.org/grants-schemes-awards/grants/wolfson-research-merit/" xlink:type="simple">https://royalsociety.org/grants-schemes-awards/grants/wolfson-research-merit/</ext-link>, to SH; and European Union’s Horizon 2020, <ext-link ext-link-type="uri" xlink:href="https://ec.europa.eu/programmes/horizon2020/" xlink:type="simple">https://ec.europa.eu/programmes/horizon2020/</ext-link>, 661373, to TS. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="5"/>
<table-count count="0"/>
<page-count count="14"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-03-22</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The data is hosted on Open Science Framework, DOI <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/M25N4" xlink:type="simple">10.17605/OSF.IO/M25N4</ext-link>: <ext-link ext-link-type="uri" xlink:href="https://osf.io/M25N4/" xlink:type="simple">https://osf.io/M25N4/</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Since the first reports of cortical gamma band activity [<xref ref-type="bibr" rid="pcbi.1005938.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref002">2</xref>], these high frequency responses have been linked to a plethora of brain processes and mental tasks, for example visual perception and processing [<xref ref-type="bibr" rid="pcbi.1005938.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1005938.ref006">6</xref>], auditory perception [<xref ref-type="bibr" rid="pcbi.1005938.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref008">8</xref>] or memory [<xref ref-type="bibr" rid="pcbi.1005938.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1005938.ref012">12</xref>]. Although numerous theories about the origin and function of these high frequency oscillations and their relation with lower frequencies like theta and alpha have been proposed (e.g., [<xref ref-type="bibr" rid="pcbi.1005938.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1005938.ref015">15</xref>]), there is an ongoing debate about whether gamma band responses reflect narrowband oscillations or broadband power increases, possibly echoing an increase in spiking activity [<xref ref-type="bibr" rid="pcbi.1005938.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref017">17</xref>]. One obstacle in this quest is the 1/<italic>f</italic> characteristic of the brain’s frequency power spectrum and a low signal-to-noise ratio (SNR) gamma band activity in magnetoencephalography (MEG) or electroencephalography (EEG) recordings. To increase SNR, trial averaging is a frequently used tool to cancel out random variance. However, this approach can potentially obscure or cancel meaningful brain activity [<xref ref-type="bibr" rid="pcbi.1005938.ref018">18</xref>]. Indeed, local field potentials and electrocorticographic data from monkeys revealed systematic trial-to-trial variations in gamma power and frequency in a visual [<xref ref-type="bibr" rid="pcbi.1005938.ref019">19</xref>] and a memory task [<xref ref-type="bibr" rid="pcbi.1005938.ref020">20</xref>]. Importantly, the averages across trials in these studies displayed the classic sustained gamma effect, indicating that single-trial responses are crucial to understand the brain’s dynamics [<xref ref-type="bibr" rid="pcbi.1005938.ref018">18</xref>]. One powerful approach to assess single-trial information are multivariate decoding techniques. Whether such methods are applicable to low SNR gamma band MEG data, however, remains unclear. In the present paper, we investigate the predictive value of single-trial gamma power regarding the modality of stimulus presentation (auditory or visual presentation of words) in human MEG data. While comparable contrasts have been used to test classifier performance or as example datasets (e.g., [<xref ref-type="bibr" rid="pcbi.1005938.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref022">22</xref>]), our aim was to unravel single-trial high frequency patterns in human MEG data. To decode information about stimulus-modality from the time-frequency data, we used a combination of beamforming [<xref ref-type="bibr" rid="pcbi.1005938.ref023">23</xref>] and random forest classification [<xref ref-type="bibr" rid="pcbi.1005938.ref024">24</xref>]. This approach was embedded into an across-subjects cross-validation framework, where the classifier was tested on single trials of unseen subjects to assess the generality of the spatial time-frequency pattern. Our results confirm that gamma SNR in single trials is high enough to achieve stable classification accuracy significantly above chance. Interestingly, the classification model yields high informational value to a broad bandwidth in the gamma range. Furthermore, we show that the characteristics of the gamma activity are similar enough across trials and even subjects to yield reliable classification performance.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec003">
<title>Ethics statement</title>
<p>The study was approved by the Institutional Review Board of the University of Konstanz and in accordance with the Declaration of Helsinki.</p>
</sec>
<sec id="sec004">
<title>Participants</title>
<p>A total of 24 participants (17 female; mean age = 22 years, range = 19–26 years; 21 right-handed) took part in this MEG experiment. Three participants were excluded due to technical problems, one due to excessive environmental noise. The data from the remaining 20 participants are presented here. All of the participants gave written informed consent prior to the experiment and received course credits or nominal financial compensation for participation. All participants were German native speakers and reported normal or corrected-to-normal vision, and no history of neurological disease.</p>
<p>Parts of this data have been published in [<xref ref-type="bibr" rid="pcbi.1005938.ref012">12</xref>], with respect to independent research questions and analyses.</p>
</sec>
<sec id="sec005">
<title>Design, procedure, and material</title>
<p>The experiment consisted of a study phase and a subsequent recognition test. Only data from the study phase are reported here. In the study phase, participants were presented with words either visually (projected centrally on a screen) or auditorily (via nonferromagnetic tubes to both ears). The duration of the visual word presentation was determined by the duration of the respective audio file, i.e., the time to pronounce the word (mean duration = 697 ms, <italic>s</italic>.<italic>d</italic>. = 119 ms). Each word was followed by a fixation cross. The duration of the word and fixation cross together added up to 2000 ms. Participants were instructed to count the syllables of the word and indicate via button press whether the word had two syllables. A question mark (max. duration of 1500 ms) prompted the subject’s response. The button press ended the presentation of the question mark. A fixation cross with variable duration (1000 ms to 1500 ms) was presented before each item. After the encoding phase, participants performed a distractor task and a surprise recognition test phase.</p>
<p>The stimuli consisted of 420 unrelated German nouns, grouped into three lists with 140 words. Half of each list’s words had two syllables, the other half had one, three or four syllables. Two lists were presented during the study phase and one list during the test phase. The assignment of the lists to study or test phase was counterbalanced across participants. Items were presented in random order, with the constraint that not more than 5 words of the same modality and not more than 5 words from the same condition were presented sequentially.</p>
</sec>
<sec id="sec006">
<title>MEG data acquisition and preprocessing</title>
<p>MEG data was recorded with a 148-channel magnetometer (MAGNES 2500 WH, 4D Neuroimaging, San Diego, USA) in a supine position inside a magnetically shielded room. Data was continuously recorded at a sampling rate of 678.17 Hz and bandwidth of 0.1 Hz to 200 Hz, and later downsampled to 300 Hz to reduce computational load. All data processing prior to classification was done using FieldTrip [<xref ref-type="bibr" rid="pcbi.1005938.ref025">25</xref>], an open-source MATLAB toolbox for MEEG data analysis. Data was epoched into single trials, with epochs ranging from 1500 ms before item presentation to 4000 ms after item presentation. Trials were visually inspected for artifacts, contaminated trials were rejected. Thereafter, trials were corrected for blinks, eye movements, and cardiac artifacts using independent component analysis (ICA).</p>
</sec>
<sec id="sec007">
<title>Source reconstruction</title>
<p>For coregistration with the individual structural magnetic resonance image (available for 17 out of 20 participants; for the remaining three participants we used an affine transformation of an MNI-template brain; Montreal Neurological Institute, Montreal, Canada), the shape of the participant’s head as well as three markers (nasion, left and right ear canal) and the location of the head position indicator (HPI) coils were digitized prior to the experiment using a Fastrak Polhemus 3D scanner (Polhemus, Colchester, VT, USA).</p>
<p>Single-trial source space activity was reconstructed using a linearly constrained minimum variance (LCMV) beamformer [<xref ref-type="bibr" rid="pcbi.1005938.ref023">23</xref>] with weight normalization (neural activity index; [<xref ref-type="bibr" rid="pcbi.1005938.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref026">26</xref>]). First, the spatial filter was computed adopting a realistic single shell head model [<xref ref-type="bibr" rid="pcbi.1005938.ref027">27</xref>] based on the individual structural magnetic resonance image (MRI) and a source model with grid points covering the whole brain volume (resolution: 15 mm). The data covariance matrix was computed for −500 ms to 1000 ms relative to stimulus presentation. To account for the rank-deficiency of the data that was introduced by the application of the ICA, the covariance matrix was regularized by loading its diagonal with 5% of the sensor power. Subsequently, the spatial filter was applied to the single trials to obtain virtual electrodes at all grid point locations.</p>
<p>For the classification of the oscillatory activity, single-trial time frequency representations were calculated at every virtual electrode applying a Fast Fourier Transform. Gamma band activity was estimated using frequency smoothing (Slepian sequence multi taper approach), yielding 20 Hz-wide frequency bands centered at 35 Hz, 65 Hz, 85 Hz, 115 Hz and 135 Hz. The power was calculated separately for 250 ms long time windows from −500 ms to 1000 ms and the post-stimulus activity was then expressed as relative change to baseline power, as using relative change helps to overcome issues arising from the 1/<italic>f</italic> shape of MEG data.</p>
</sec>
<sec id="sec008">
<title>Random forest classification</title>
<p>The random forest algorithm [<xref ref-type="bibr" rid="pcbi.1005938.ref024">24</xref>], an ensemble method, aggregates the results of several classifiers. These so-called base learners are classification and regression trees [<xref ref-type="bibr" rid="pcbi.1005938.ref028">28</xref>], which partition the data by adopting binary splits. The aim of this partitioning process is to reduce the impurity regarding the class labels in the daughter nodes that result from this split: preferably, all observations from one class should arrive in the same node. In every split, the tree algorithm searches first for the predictor that maximizes the purity of the daughter nodes and then for the best split point within that predictor. Random forests now grow numerous trees; each of these trees, however, is built on a bootstrap sample of the original data and in every split only a random subsample of all predictors is searched. The variance introduced by this randomness leads to a robust prediction by the aggregated model. This approach furthermore enables random forest to cope particularly well with highly correlated predictor variables [<xref ref-type="bibr" rid="pcbi.1005938.ref029">29</xref>], which is of special interest when working with MEEG data. Additionally, data with more predictors than observations (small <italic>n</italic> large <italic>p</italic> problems) are also handled effectively since the predictor variables are searched successively [<xref ref-type="bibr" rid="pcbi.1005938.ref030">30</xref>], which makes this approach particularly interesting when dealing with high-dimensional source-space MEEG data. For every predictor, the algorithm returns an estimate of how important this variable was for the model’s prediction. The version used here is based on the impurity reduction introduced by a predictor variable across all trees, which is measured by the Gini index [<xref ref-type="bibr" rid="pcbi.1005938.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref031">31</xref>].</p>
<p>Random forest classification was performed using the scikit-learn module for Python [<xref ref-type="bibr" rid="pcbi.1005938.ref032">32</xref>]. The aim of the decoding was to classify trials regarding their stimulus modality: visual or auditory. The predictors were [voxel, time point, frequency band]-triplets, providing 16 624 predictors, overall. For every subject, the more prevalent class (auditory or visual stimulation) was downsampled such that every dataset contained equal trial numbers for both cases. The total trial number across all subjects was 4270 trials.</p>
<p>The classification was embedded in a cross-validation framework across subjects: the classifier was trained on the data from all but one subject and then tested on the data of this left-out subject. This procedure was repeated for all 20 subjects, such that every dataset was used as test set once. This approach ensures that the classifier is never tested on data it was trained on and thus controls for possible overfitting of the classifier. Moreover, it allows the assessment of across-subjects predictability of the data regarding the response variable.</p>
<p>Each of the 20 cross-validation models aggregated the results of 15 000 classification trees, where every tree was built on a bootstrap sample of all observations in the trainings set. To ensure that the model incorporated a sufficient number of trees, classification performance was assessed with 25 000 trees for two folds [<xref ref-type="bibr" rid="pcbi.1005938.ref033">33</xref>], yielding comparable results as the sparser model. At each binary split, the algorithm considered <inline-formula id="pcbi.1005938.e001"><alternatives><graphic id="pcbi.1005938.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005938.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:msqrt><mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mi>f</mml:mi> <mml:mi>e</mml:mi> <mml:mi>a</mml:mi> <mml:mi>t</mml:mi> <mml:mi>u</mml:mi> <mml:mi>r</mml:mi> <mml:mi>e</mml:mi> <mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:msqrt></mml:math></alternatives></inline-formula> predictors to find the best split. The accuracies on the test datasets as well as the variable importances were merged across the cross-validation folds. The performance of the classifier was then tested against 50% chance level using a binomial test [<xref ref-type="bibr" rid="pcbi.1005938.ref034">34</xref>], since a permutation based test was computationally not feasible.</p>
</sec>
<sec id="sec009">
<title>Comparison to support vector machines</title>
<p>The performance of the random forest algorithm was compared to the accuracies obtained by fitting two support vector machine (SVM) models [<xref ref-type="bibr" rid="pcbi.1005938.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref036">36</xref>] on the data. The general procedure was as described above, instead of the random forest model, however, either a linear SVM or a non-linear SVM with a radial basis function (RBF) kernel was fitted using the scikit-learn module in Python. The penalty parameter was set to 1.0 in both models and a kernel coefficient of 1/<italic>N</italic><sub><italic>features</italic></sub> for the RBF kernel.</p>
<p>The performance of the random forest model was subsequently tested against the two SVM models by applying a Fisher’s exact test to the obtained classification accuracies.</p>
</sec>
</sec>
<sec id="sec010" sec-type="results">
<title>Results</title>
<p>To assess the predictive value of single-trial gamma power towards stimulus modality, we used MEG data from 20 subjects and adopted an across-subjects classification scheme. Data was first source reconstructed with a linearly constrained minimum variance (LCMV) beamformer, subsequently, we used the random forest algorithm to classify the modality of stimulus presentation (auditory or visual).</p>
<p>The random forest model classified auditory versus visual trials with 66.44% accuracy, which is significantly better than chance (binomial test, <italic>n</italic><sub><italic>trials</italic></sub> = 4270, <italic>p</italic> &lt; 0.001). As the confusion matrix in <xref ref-type="fig" rid="pcbi.1005938.g001">Fig 1A</xref> shows, the accuracy was slightly better for auditory trials (69.60%) than for visual trials (63.19%). In the adopted 20-fold cross-validation scheme, every fold corresponded to the data of one subject, hence, the classifier was always tested on data of one subject which was not included in building the model. The classifier accuracy on the 20 cross-validation folds is depicted in <xref ref-type="fig" rid="pcbi.1005938.g001">Fig 1B</xref>. The performance on the different folds is diverse, ranging from 50.98% to 84.86%, however, the accuracy for all but three folds is above 60% (note that the folds, since they are part of the whole classifier model, are not tested for significance). The good classifier performance indicates that the gamma power patterns are remarkably stable across trials and even subjects. For a comparison of this across-subjects approach to within-subject analyses, see supplementary Figure in the <xref ref-type="supplementary-material" rid="pcbi.1005938.s001">S1 Appendix</xref>.</p>
<fig id="pcbi.1005938.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005938.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Classifier results.</title>
<p><bold>A</bold> Confusion matrix showing the proportion of correctly classified trials (diagonal) and misclassified trials. <bold>B</bold> Classifier accuracy. The mid blue bars represent the test accuracy in the 20 folds, where every fold is a subject the classifier was not trained on. The dark blue bar shows the overall classifier accuracy, which was tested against chance level.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005938.g001" xlink:type="simple"/>
</fig>
<p>The random forest classifier provides the variable importance as an importance estimate for every predictor in the model. This measure indicates the informational value of a given predictor towards the discrimination of the two classes, auditory and visual modality. <xref ref-type="fig" rid="pcbi.1005938.g002">Fig 2</xref> reports the highest 2% of variable importance values, i.e., those [voxel, time point, frequency band]-triplets that were most informative for partitioning the data. This cutoff was chosen because cutoffs of higher values (&gt; 2%) would have included features with variable importances equal to zero, i.e., variables that did not contribute information to the classifier. Not only visual, but also auditory regions contributed to the model, even though visual areas yielded more information than the auditory cortex. Interestingly, the lower frequency bands of 25 Hz to 45 Hz and 55 Hz to 75 Hz did not rank as important as the 75 Hz to 95 Hz band. Even frequencies above 100 Hz contributed to the model in both visual and right auditory cortex. Gamma power beyond 125 Hz, however, did not add substantially to the classification model.</p>
<fig id="pcbi.1005938.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005938.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Variable importances.</title>
<p>The 2% most important predictors are shown across time, frequency and space. A higher variable importance score implies that this predictor had a higher informative value in the random forest model to partition the data into trials with auditory and visual perception. The orthogonal views are centered on the voxel showing the highest variable importance.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005938.g002" xlink:type="simple"/>
</fig>
<p>All time windows but the last one (750 ms to 1000 ms) supplied information to the classifier, in higher frequencies, the earlier time windows seemed to play a more pronounced role compared to the lower gamma frequencies. <xref ref-type="fig" rid="pcbi.1005938.g003">Fig 3</xref> shows the time-frequency representations of variable importance for the visual and auditory peak voxels: the visual peak voxel (MNI coordinates: [−4 −100 12]) falls into left calcarine sulcus, the auditory peak voxel (MNI coordinates: [68 −20 10]) into right superior temporal gyrus (labels determined with the Automated Anatomical Labeling (AAL) atlas [<xref ref-type="bibr" rid="pcbi.1005938.ref037">37</xref>]). The time-frequency representations for those two peak voxels (<xref ref-type="fig" rid="pcbi.1005938.g003">Fig 3</xref>) confirm the pattern evident across all voxels (<xref ref-type="fig" rid="pcbi.1005938.g002">Fig 2</xref>). Thus, the 75 Hz to 95 Hz band yielded a characteristic and stable activity pattern in both the auditory and visual cortex. The visual response was specifically characterized by a broadband gamma increase in the range of 55 Hz to 125 Hz. The auditory response yielded informational value in an overlapping but narrower frequency range (75 Hz to 125 Hz).</p>
<fig id="pcbi.1005938.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005938.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Variable importances in visual and auditory peak voxels.</title>
<p><bold>A</bold> Peak voxel locations for auditory and visual cortex (compare peak voxels from <xref ref-type="fig" rid="pcbi.1005938.g002">Fig 2</xref>) <bold>B</bold> Time-frequency representation of variable importances in those peak voxels. Black boxes indicate those variables which were among the 2% most informative predictors.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005938.g003" xlink:type="simple"/>
</fig>
<p>To investigate the underlying gamma power changes, the variable importance rankings were compared to the power differences between auditory and visual trials. To this end, auditory and visual power changes relative to baseline were averaged across trials and subjects, and the difference between the visual and the auditory condition was computed. These differences are depicted in <xref ref-type="fig" rid="pcbi.1005938.g004">Fig 4A</xref>: the spatial pattern of power is shown for the 250 ms to 500 ms time window and two frequency bands (75 Hz to 95 Hz, top, and 105 Hz to 125 Hz, bottom in <xref ref-type="fig" rid="pcbi.1005938.g004">Fig 4A</xref>). Red colors refer to higher gamma power in the visual condition and blue colors to higher power in the auditory condition. The black lines encircle those voxels which were among the 2% most informative predictors for the classifier. <xref ref-type="fig" rid="pcbi.1005938.g004">Fig 4B</xref> shows the underlying gamma power relations for the same peak voxels as presented in <xref ref-type="fig" rid="pcbi.1005938.g003">Fig 3</xref>. Interestingly, the classifier analysis based on single trials also rated predictors as highly informative where a difference in the averages is small, as is most evident for the time-frequency representation of the auditory condition (75 Hz to 95 Hz, 500 ms to 750 ms).</p>
<fig id="pcbi.1005938.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005938.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Underlying gamma power.</title>
<p>This figure shows the difference in averaged gamma power between visual and auditory word presentation trials. <bold>A</bold> Spatial representation of gamma power for two frequency bands (75-95 Hz, top, and 105-125 Hz, bottom). Red hues represent a higher gamma power in the average of visual trials, the blue colors depict higher gamma power in the average of the auditory condition. Black boxes indicate the 2% most informative predictors as shown in <xref ref-type="fig" rid="pcbi.1005938.g002">Fig 2</xref>. <bold>B</bold> Gamma power in visual and auditory peak voxels. Shown is the difference between the visual and auditory condition, black boxes again indicate the most informative predictors for the classifier model.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005938.g004" xlink:type="simple"/>
</fig>
<p>To get a general assessment of the relative performance of random forests on MEG data, we compared this approach to the outcome of support vector machines (SVM), a widely used method in multivariate data analysis. We applied two SVM types, a linear SVM and a non-linear SVM with a radial basis function (RBF) kernel. The results of this comparison are shown in <xref ref-type="fig" rid="pcbi.1005938.g005">Fig 5</xref>. The linear SVM yielded an accuracy of 63.07% and performed significantly worse than the random forest model (two-sided Fisher’s exact test, <italic>odds</italic> <italic>ratio</italic> = 86.79%, <italic>p</italic> = 0.002, 0.004 corrected). The RBF SVM performed slightly better than the random forest model with an accuracy of 68.34% (two-sided Fisher’s exact test, <italic>odds</italic> <italic>ratio</italic> = 91.1%, <italic>p</italic> = 0.047, 0.094 corrected). Note that the comparison between the non-linear SVM and the random forest model does not survive a correction for multiple comparisons (Bonferroni-correction for two Fisher’s exact tests).</p>
<fig id="pcbi.1005938.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005938.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Comparison to SVM models.</title>
<p>Performance comparison of the random forest algorithm to SVM models. <bold>A</bold> Results from the linear SVM compared to the results from the random forest algorithm across cross-validation folds. Random forest performed significantly better than the linear SVM (<italic>p</italic> = 0.002, 0.004 with Bonferroni correction). <bold>B</bold> Results from a non-linear SVM with RBF kernel compared to the random forest results. The non-linear SVM yielded a higher classification accuracy than the random forest model (<italic>p</italic> = 0.047), applying a Bonferroni-correction for multiple comparisons renders this effect insignificant (<italic>p</italic><sub><italic>corrected</italic></sub> = 0.094).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005938.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec011" sec-type="conclusions">
<title>Discussion</title>
<p>In the present work, we investigated the predictive value of single-trial gamma power to classify the stimuli’s modality. This was done in an across-subjects cross-validation framework which allowed us to estimate not only the gamma pattern stability across trials but also across subjects.</p>
<p>The decoding of MEEG high frequency activity on a single-trial basis can be challenging due to the low SNR: while intracranially recorded high frequency activity up to 180 Hz has been used to decode movements [<xref ref-type="bibr" rid="pcbi.1005938.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref039">39</xref>], comparable approaches with MEEG data were not successful [<xref ref-type="bibr" rid="pcbi.1005938.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref041">41</xref>]. Some studies could show a contribution of high gamma power (along with lower oscillatory activity) to the overall classifier performance [<xref ref-type="bibr" rid="pcbi.1005938.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref043">43</xref>]. In this study, we successfully decoded stimulus modality exclusively from high frequency activity: the classifier model was able to correctly classify 66.44% of the trials based on their source reconstructed gamma activity pattern, reliably distinguishing visual from auditory word presentation. Thus, the SNR of single-trial gamma power in source-level MEG data was high enough to successfully apply single-trial multivariate analyses. Interestingly, more auditory (69.60%) than visual trials (63.19%) were classified correctly, although visual areas yielded more information to the classifier. One possible explanation for this could be that the classifier-inherent cutoff values for gamma power in the visual voxels were rather conservative and therefore missed small gamma increases in visual cortex in visual trials, but still reliably detected the absence of visual activity in auditory trials.</p>
<p>The classification model was built across subjects, adopting a 20-fold across-subjects cross-validation, where the classifier was trained on 19 subjects and then tested on the data of the left-out 20<sup>th</sup> subject. Hence, the trials of any given subject were classified by a model which was built on the data from different subjects. Using this approach, we assessed the common patterns across trials and subjects. The accuracy pattern across the different folds was higher than 60% for all but three subjects. Low accuracies indicate either higher noise levels in these participants or activity patterns which deviate from the across-subjects consensus as uncovered by the random forest model. The overall classification accuracy of 66.44% is comparable to previous reports of across-subjects MEG data classification (e.g., [<xref ref-type="bibr" rid="pcbi.1005938.ref044">44</xref>]).</p>
<p>The variable importance indicates which predictors were used by the model to yield the classification performance, by providing the common pattern across trials and subjects that differentiated between the two conditions. Clearly, gamma band activity from both visual and auditory areas was exploited by the model, although the visual cortex was more important than the auditory cortices, expressed by higher ranking variable importances. Overall, a broad range of frequencies and a time span of 750 ms included gamma band activation relevant to the random forest model.</p>
<p>In this study, we show the feasibility of applying the random forest algorithm [<xref ref-type="bibr" rid="pcbi.1005938.ref024">24</xref>] to single-trial source-localized time-frequency data. With its non-parametric, non-linear approach and its capability to handle high dimensional datasets with highly correlated predictors, this method is well suited for MEG data (also see [<xref ref-type="bibr" rid="pcbi.1005938.ref045">45</xref>–<xref ref-type="bibr" rid="pcbi.1005938.ref048">48</xref>]) and can detect subtle differences concealed in the averaged data. In contrast to approaches comparing averaged time courses, the multivariate analysis presented here furthermore solves the multiple comparison problem that is inherent to the application of univariate tests for time points or similarly high-dimensional data.</p>
<p>Another advantage of this method is the possibility to directly compare predictors (e.g., frequency bands) to each other regarding their importance in the model: for example, we are able to state that the 75 Hz to 95 Hz frequency band is the most important frequency band, and that the visual cortex has higher informational value for the classification than the auditory cortex.</p>
<p>Comparing the random forest algorithm to SVM methods shows that it clearly outperforms a linear SVM model in this dataset. The SVM with the non-linear kernel showed a comparable performance to the random forest, however, using non-linear SVMs comes at the expense of interpretability and usability. While it is possible to assess the relative importance of the different predictors with random forests, this is hindered with non-linear SVMs, since the classification is not computed in the original feature space. Furthermore, while SVMs often require an extensive search for optimal parameter settings, the application of the random forest algorithm is less complex and needs less fine-tuning.</p>
<p>In our data, the left primary visual cortex was most informative for the classification among all brain regions. Additionally, also higher visual areas ranked as highly informative, which is concordant with the localization of visual gamma band responses in intracranial electroencephalography (iEEG) and MEG studies (e.g., [<xref ref-type="bibr" rid="pcbi.1005938.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref049">49</xref>–<xref ref-type="bibr" rid="pcbi.1005938.ref051">51</xref>]). The classification further identified auditory regions as informative. Although iEEG reliably shows high gamma responses to auditory stimuli [<xref ref-type="bibr" rid="pcbi.1005938.ref052">52</xref>–<xref ref-type="bibr" rid="pcbi.1005938.ref055">55</xref>], auditory high frequency activity above 75 Hz has only rarely been shown in MEG studies: examples include high gamma responses to sound and pitch perception [<xref ref-type="bibr" rid="pcbi.1005938.ref056">56</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref057">57</xref>]. Within the auditory regions, the most important voxel in our data was located in the right superior temporal gyrus, which is in line with iEEG studies investigating phoneme and word processing [<xref ref-type="bibr" rid="pcbi.1005938.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref055">55</xref>] and the above-mentioned MEG studies. Further important regions included Heschl’s gyrus and the planum temporale. Interestingly, the right auditory cortex showed higher importance with more voxels involved compared to the left auditory cortex, although the stimuli were words and should typically evoke language-related activity localized to the left hemisphere [<xref ref-type="bibr" rid="pcbi.1005938.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref055">55</xref>]. This may be explained by the fact that both conditions used words as stimuli and thus, left-hemispheric language related activity is not able to distinguish between auditory and visual trials.</p>
<p>The time windows most important to the classification covered 0 ms to 750 ms after stimulus onset, while the last time window (750 ms to 1000 ms) did not show any high ranking variable importance values, implying that gamma activity was most informative to the classifier during presentation of a word (mean = 700 ms).</p>
<p>Informative predictors in auditory areas, however, were only found between 250 ms and 750 ms, although previous studies reported early auditory (high) gamma responses following phoneme or word stimuli (e.g., [<xref ref-type="bibr" rid="pcbi.1005938.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref055">55</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref058">58</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref059">59</xref>]).</p>
<p>In both, visual and auditory brain areas, the most important frequency band was the 75 Hz to 95 Hz band. Especially in the 250 ms to 500 ms window, this frequency band exhibited exceeding informative value for the classification. Yet, the visual areas overall provided informative predictors across a broad frequency range (55 Hz to 125 Hz). This points to underlying broadband gamma activity in single trials rather than a narrowband response, which is typically elicited by high contrast stimuli such as gratings, (e.g., [<xref ref-type="bibr" rid="pcbi.1005938.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref051">51</xref>]). The high frequency activity beneficial for classification is similar to visually induced broadband gamma activity reported in iEEG and MEG studies [<xref ref-type="bibr" rid="pcbi.1005938.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref060">60</xref>–<xref ref-type="bibr" rid="pcbi.1005938.ref062">62</xref>]. Vidal et al. [<xref ref-type="bibr" rid="pcbi.1005938.ref061">61</xref>], for example, describe a lower frequency band of 45 Hz to 65 Hz and high gamma activity of 70 Hz to 120 Hz in their MEG study on visual grouping. Related to reading, broadband high frequency activity above 50 Hz has been reported in iEEG studies [<xref ref-type="bibr" rid="pcbi.1005938.ref063">63</xref>–<xref ref-type="bibr" rid="pcbi.1005938.ref066">66</xref>]. Furthermore, compared to the narrowband responses elicited by high contrast stimuli such as gratings, which are typically centered at lower frequencies, (e.g., 50 Hz [<xref ref-type="bibr" rid="pcbi.1005938.ref005">5</xref>] or 60 Hz [<xref ref-type="bibr" rid="pcbi.1005938.ref051">51</xref>]), our results yielded the 75 Hz to 95 Hz frequency band as most informative.</p>
<p>In the auditory areas, the most important variables were concentrated in the 75 Hz to 95 Hz and 105 Hz to 125 Hz frequency bands. This is in line with iEEG studies on syllable and word processing, which report gamma responses from 80 Hz up to 200 Hz [<xref ref-type="bibr" rid="pcbi.1005938.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1005938.ref067">67</xref>]. Thus, our results might reflect the lower end of the high gamma response described in these studies, potentially cropped by low SNR above 125 Hz.</p>
<p>To summarize, we have shown that single-trial gamma activity can be successfully used to classify stimulus modality. Importantly, the successful across-subjects classification suggested that single-trial gamma-band activity contains high inter-individual consistency. Future studies investigating discriminative rather than consistent activity across trials should explore the possibilities provided by the present approach. The classifier identified both visual and auditory areas as informative with high spatial specificity. Our results furthermore suggest that single-trial high frequency activity after visual word presentation is characterized by a broadband rather than a narrowband response.</p>
</sec>
<sec id="sec012">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005938.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005938.s001" xlink:type="simple">
<label>S1 Appendix</label>
<caption>
<title>Within-subject classification.</title>
<p>Classifier accuracies obtained when training and testing the random forest model within instead of across subjects. The procedure adopted a split-half cross-validation scheme including both the fitting of the beamformer and the classification modelling.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Ann-Kristin Rombach, Leona Hellwig, Marina Koepfer, and Janine Weichert for help with data acquisition and Sabine Leske and Tzvetan Popov for valuable discussion.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005938.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gray</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>. <article-title>Stimulus-specific neuronal oscillations in orientation columns of cat visual cortex</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>1989</year>;<volume>86</volume>:<fpage>1698</fpage>–<lpage>1702</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.86.5.1698" xlink:type="simple">10.1073/pnas.86.5.1698</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gray</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>König</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Engel</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>. <article-title>Oscillatory responses in cat visual cortex exhibit inter-columnar synchronization which reflects global stimulus properties</article-title>. <source>Nature</source>. <year>1989</year>;<volume>338</volume>:<fpage>334</fpage>–<lpage>337</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/338334a0" xlink:type="simple">10.1038/338334a0</ext-link></comment> <object-id pub-id-type="pmid">2922061</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hoogenboom</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Schoffelen</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Oostenveld</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Parkes</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>. <article-title>Localizing human visual gamma-band activity in frequency, time and space</article-title>. <source>NeuroImage</source>. <year>2006</year>;<volume>29</volume>(<issue>3</issue>):<fpage>764</fpage>–<lpage>773</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2005.08.043" xlink:type="simple">10.1016/j.neuroimage.2005.08.043</ext-link></comment> <object-id pub-id-type="pmid">16216533</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dalal</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Vidal</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Hamamé</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Ossandón</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Bertrand</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Lachaux</surname> <given-names>JP</given-names></name>, <etal>et al</etal>. <article-title>Spanning the rich spectrum of the human brain: slow waves to gamma and beyond</article-title>. <source>Brain Structure and Function</source>. <year>2011</year>;<volume>216</volume>:<fpage>77</fpage>–<lpage>84</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00429-011-0307-z" xlink:type="simple">10.1007/s00429-011-0307-z</ext-link></comment> <object-id pub-id-type="pmid">21437655</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Muthukumaraswamy</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Singh</surname> <given-names>KD</given-names></name>, <name name-style="western"><surname>Swettenham</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Jones</surname> <given-names>DK</given-names></name>. <article-title>Visual gamma oscillations and evoked responses: variability, repeatability and structural MRI correlates</article-title>. <source>NeuroImage</source>. <year>2010</year>;<volume>49</volume>(<issue>4</issue>):<fpage>3349</fpage>–<lpage>3357</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2009.11.045" xlink:type="simple">10.1016/j.neuroimage.2009.11.045</ext-link></comment> <object-id pub-id-type="pmid">19944770</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hermes</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Wandell</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Winawer</surname> <given-names>J</given-names></name>. <article-title>Stimulus dependence of gamma oscillations in human visual cortex</article-title>. <source>Cerebral Cortex</source>. <year>2014</year>;<volume>25</volume>(<issue>9</issue>):<fpage>2951</fpage>–<lpage>2959</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhu091" xlink:type="simple">10.1093/cercor/bhu091</ext-link></comment> <object-id pub-id-type="pmid">24855114</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Crone</surname> <given-names>NE</given-names></name>, <name name-style="western"><surname>Boatman</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Gordon</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Hao</surname> <given-names>L</given-names></name>. <article-title>Induced electrocorticographic gamma activity during auditory perception</article-title>. <source>Clinical Neurophysiology</source>. <year>2001</year>;<volume>112</volume>:<fpage>565</fpage>–<lpage>582</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S1388-2457(00)00545-9" xlink:type="simple">10.1016/S1388-2457(00)00545-9</ext-link></comment> <object-id pub-id-type="pmid">11275528</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brosch</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Budinger</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Scheich</surname> <given-names>H</given-names></name>. <article-title>Stimulus-related gamma oscillations in primate auditory cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2002</year>;<volume>87</volume>(<issue>6</issue>):<fpage>2715</fpage>–<lpage>2725</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.2002.87.6.2715" xlink:type="simple">10.1152/jn.2002.87.6.2715</ext-link></comment> <object-id pub-id-type="pmid">12037173</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fell</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Klaver</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Lehnertz</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Grunwald</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Schaller</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Elger</surname> <given-names>CE</given-names></name>, <etal>et al</etal>. <article-title>Human memory formation is accompanied by rhinal-hippocampal coupling and decoupling</article-title>. <source>Nature Neuroscience</source>. <year>2001</year>;<volume>4</volume>:<fpage>1259</fpage>–<lpage>1264</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn759" xlink:type="simple">10.1038/nn759</ext-link></comment> <object-id pub-id-type="pmid">11694886</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Osipova</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Takashima</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Oostenveld</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Fernandez</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Maris</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Jensen</surname> <given-names>O</given-names></name>. <article-title>Theta and gamma oscillations predict encoding and retrieval of declarative memory</article-title>. <source>Journal of Neuroscience</source>. <year>2006</year>;<volume>26</volume>(<issue>28</issue>):<fpage>7523</fpage>–<lpage>7531</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1948-06.2006" xlink:type="simple">10.1523/JNEUROSCI.1948-06.2006</ext-link></comment> <object-id pub-id-type="pmid">16837600</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jensen</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Kaiser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Lachaux</surname> <given-names>JP</given-names></name>. <article-title>Human gamma-frequency oscillations associated with attention and memory</article-title>. <source>Trends in Neurosciences</source>. <year>2007</year>;<volume>30</volume>:<fpage>317</fpage>–<lpage>324</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2007.05.001" xlink:type="simple">10.1016/j.tins.2007.05.001</ext-link></comment> <object-id pub-id-type="pmid">17499860</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Staudigl</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Hanslmayr</surname> <given-names>S</given-names></name>. <article-title>Theta oscillations at encoding mediate the context-dependent nature of human episodic memory</article-title>. <source>Current Biology</source>. <year>2013</year>;<volume>23</volume>(<issue>12</issue>):<fpage>1101</fpage>–<lpage>1106</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2013.04.074" xlink:type="simple">10.1016/j.cub.2013.04.074</ext-link></comment> <object-id pub-id-type="pmid">23746635</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Akam</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Kullmann</surname> <given-names>DM</given-names></name>. <article-title>Oscillatory multiplexing of population codes for selective communication in the mammalian brain</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2014</year>;<volume>15</volume>:<fpage>111</fpage>–<lpage>122</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn3668" xlink:type="simple">10.1038/nrn3668</ext-link></comment> <object-id pub-id-type="pmid">24434912</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jensen</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Mazaheri</surname> <given-names>A</given-names></name>. <article-title>Shaping functional architecture by oscillatory alpha activity: gating by inhibition</article-title>. <source>Frontiers in Human Neuroscience</source>. <year>2010</year>;<volume>4</volume>(<issue>186</issue>).</mixed-citation>
</ref>
<ref id="pcbi.1005938.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>. <article-title>Rhythms for cognition: communication through coherence</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>88</volume>(<issue>1</issue>):<fpage>220</fpage>–<lpage>235</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.09.034" xlink:type="simple">10.1016/j.neuron.2015.09.034</ext-link></comment> <object-id pub-id-type="pmid">26447583</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Miller</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Sorensen</surname> <given-names>LB</given-names></name>, <name name-style="western"><surname>Ojemann</surname> <given-names>JG</given-names></name>, <name name-style="western"><surname>Den Nijs</surname> <given-names>M</given-names></name>. <article-title>Power-law scaling in the brain surface electric potential</article-title>. <source>PLoS Computational Biology</source>. <year>2009</year>;<volume>5</volume>(<issue>12</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1000609" xlink:type="simple">10.1371/journal.pcbi.1000609</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ray</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JH</given-names></name>. <article-title>Differences in gamma frequencies across visual cortex restrict their possible use in computation</article-title>. <source>Neuron</source>. <year>2010</year>;<volume>67</volume>(<issue>5</issue>):<fpage>885</fpage>–<lpage>896</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2010.08.004" xlink:type="simple">10.1016/j.neuron.2010.08.004</ext-link></comment> <object-id pub-id-type="pmid">20826318</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stokes</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Spaak</surname> <given-names>E</given-names></name>. <article-title>The Importance of single-trial analyses in cognitive neuroscience</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2016</year>;<volume>20</volume>(<issue>7</issue>):<fpage>483</fpage>–<lpage>486</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2016.05.008" xlink:type="simple">10.1016/j.tics.2016.05.008</ext-link></comment> <object-id pub-id-type="pmid">27237797</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lowet</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Roberts</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Bosman</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>De Weerd</surname> <given-names>P</given-names></name>. <article-title>Areas V1 andV2 show microsaccade-related 3-4-Hz covariation in gamma power and frequency</article-title>. <source>European Journal of Neuroscience</source>. <year>2016</year>;<volume>43</volume>:<fpage>1286</fpage>–<lpage>1296</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/ejn.13126" xlink:type="simple">10.1111/ejn.13126</ext-link></comment> <object-id pub-id-type="pmid">26547390</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lundqvist</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rose</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Herman</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Brincat</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Buschman</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>EK</given-names></name>. <article-title>Gamma and beta bursts underlie working memory</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>90</volume>:<fpage>152</fpage>–<lpage>164</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2016.02.028" xlink:type="simple">10.1016/j.neuron.2016.02.028</ext-link></comment> <object-id pub-id-type="pmid">26996084</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Guimaraes</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Wong</surname> <given-names>DK</given-names></name>, <name name-style="western"><surname>Uy</surname> <given-names>ET</given-names></name>, <name name-style="western"><surname>Grosenick</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Suppes</surname> <given-names>P</given-names></name>. <article-title>Single-trial classification of MEG recordings</article-title>. <source>IEEE Transactions on Biomedical Engineering</source>. <year>2007</year>;<volume>54</volume>(<issue>3</issue>):<fpage>436</fpage>–<lpage>443</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TBME.2006.888824" xlink:type="simple">10.1109/TBME.2006.888824</ext-link></comment> <object-id pub-id-type="pmid">17355055</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gramfort</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Luessi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Larson</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Engemann</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Strohmeier</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Brodbeck</surname> <given-names>C</given-names></name>, <etal>et al</etal>. <article-title>MEG and EEG data analysis with MNE-Python</article-title>. <source>Frontiers in Neuroscience</source>. <year>2013</year>;<volume>7</volume>:<fpage>267</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnins.2013.00267" xlink:type="simple">10.3389/fnins.2013.00267</ext-link></comment> <object-id pub-id-type="pmid">24431986</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Van Veen</surname> <given-names>BD</given-names></name>, <name name-style="western"><surname>van Drongelen</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Yuchtman</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Suzuki</surname> <given-names>A</given-names></name>. <article-title>Localization of Brain Electrical Activity via linearly constrained minimum variance spatial filtering</article-title>. <source>IEEE Transaction on Biomedical Engineering</source>. <year>1997</year>;<volume>44</volume>(<issue>9</issue>):<fpage>867</fpage>–<lpage>880</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/10.623056" xlink:type="simple">10.1109/10.623056</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Breiman</surname> <given-names>L</given-names></name>. <article-title>Random forests</article-title>. <source>Machine Learning</source>. <year>2001</year>;<volume>45</volume>(<issue>1</issue>):<fpage>5</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1023/A:1010933404324" xlink:type="simple">10.1023/A:1010933404324</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Oostenveld</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Maris</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Schoffelen</surname> <given-names>JM</given-names></name>. <article-title>FieldTrip: Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title>. <source>Computational Intelligence and Neuroscience</source>. <year>2011</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1155/2011/156869" xlink:type="simple">10.1155/2011/156869</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref026">
<label>26</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Sekihara</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Nagarajan</surname> <given-names>SS</given-names></name>. <source>Adaptive spatial filters for electromagnetic brain imaging</source>. <publisher-name>Springer Science &amp; Business Media</publisher-name>; <year>2008</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005938.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nolte</surname> <given-names>G</given-names></name>. <article-title>The magnetic lead field theorem in the quasi-static approximation and its use for magnetoencephalography forward calculation in realistic volume conductors</article-title>. <source>Physics in Medicine and Biology</source>. <year>2003</year>;<volume>48</volume>(<issue>22</issue>):<fpage>3637</fpage>–<lpage>3652</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1088/0031-9155/48/22/002" xlink:type="simple">10.1088/0031-9155/48/22/002</ext-link></comment> <object-id pub-id-type="pmid">14680264</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref028">
<label>28</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Breiman</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Friedman</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Stone</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Olshen</surname> <given-names>RA</given-names></name>. <chapter-title>Classification and regression trees</chapter-title>. <source>CRC press</source>; <year>1984</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005938.ref029">
<label>29</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Cutler</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Cutler</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Stevens</surname> <given-names>JR</given-names></name>. <chapter-title>Tree-based methods</chapter-title>. In: <source>High-Dimensional Data Analysis in Cancer Research</source>. <publisher-name>Springer</publisher-name> <publisher-loc>New York</publisher-loc>; <year>2009</year>. p. <fpage>1</fpage>–<lpage>19</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005938.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Strobl</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Malley</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Tutz</surname> <given-names>G</given-names></name>. <article-title>An introduction to recursive partitioning: rationale, application, and characteristics of classification and regression trees, bagging, and random forests</article-title>. <source>Psychological Methods</source>. <year>2009</year>;<volume>14</volume>(<issue>4</issue>):<fpage>323</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0016973" xlink:type="simple">10.1037/a0016973</ext-link></comment> <object-id pub-id-type="pmid">19968396</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref031">
<label>31</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Gini</surname> <given-names>C</given-names></name>. <chapter-title>Variabilitá e Mutuabilitá: Contributo allo Studio delle Distribuzioni e delle Relazioni Statistiche</chapter-title>. <publisher-name>Tipografia di Cuppini</publisher-name>; <year>1912</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005938.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pedregosa</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Varoquaux</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Gramfort</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Michel</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Thirion</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Grisel</surname> <given-names>O</given-names></name>, <etal>et al</etal>. <article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>Journal of Machine Learning Research</source>. <year>2011</year>;<volume>12</volume>:<fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005938.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liaw</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Wiener</surname> <given-names>M</given-names></name>. <article-title>Classification and regression by randomForest</article-title>. <source>R news</source>. <year>2002</year>;<volume>2</volume>(<issue>3</issue>):<fpage>18</fpage>–<lpage>22</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005938.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Combrisson</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Jerbi</surname> <given-names>K</given-names></name>. <article-title>Exceeding chance level by chance: The caveat of theoretical chance levels in brain signal classification and statistical assessment of decoding accuracy</article-title>. <source>Journal of Neuroscience Methods</source>. <year>2015</year>;<volume>30</volume>:<fpage>126</fpage>–<lpage>136</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jneumeth.2015.01.010" xlink:type="simple">10.1016/j.jneumeth.2015.01.010</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref035">
<label>35</label>
<mixed-citation publication-type="other" xlink:type="simple">Boser BE, Guyon IM, Vapnik VN. A Training Algorithm for Optimal Margin Classifiers. In: Proceedings of the Fifth Annual Workshop on Computational Learning Theory. ACM; 1992. p. 144–152.</mixed-citation>
</ref>
<ref id="pcbi.1005938.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cortes</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Vapnik</surname> <given-names>V</given-names></name>. <article-title>Support-vector networks</article-title>. <source>Machine Learning</source>. <year>1995</year>;<volume>20</volume>(<issue>3</issue>):<fpage>273</fpage>–<lpage>297</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00994018" xlink:type="simple">10.1007/BF00994018</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tzourio-Mazoyer</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Landeau</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Papathanassiou</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Crivello</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Etard</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Delcroix</surname> <given-names>N</given-names></name>, <etal>et al</etal>. <article-title>Automated Anatomical Labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title>. <source>NeuroImage</source>. <year>2002</year>;<volume>15</volume>:<fpage>273</fpage>–<lpage>289</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/nimg.2001.0978" xlink:type="simple">10.1006/nimg.2001.0978</ext-link></comment> <object-id pub-id-type="pmid">11771995</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Leuthardt</surname> <given-names>EC</given-names></name>, <name name-style="western"><surname>Schalk</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Wolpaw</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Ojemann</surname> <given-names>JG</given-names></name>, <name name-style="western"><surname>Moran</surname> <given-names>DW</given-names></name>. <article-title>A brain—computer interface using electrocorticographic signals in humans</article-title>. <source>Journal of Neural Engineering</source>. <year>2004</year>;<volume>1</volume>(<issue>2</issue>):<fpage>63</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1088/1741-2560/1/2/001" xlink:type="simple">10.1088/1741-2560/1/2/001</ext-link></comment> <object-id pub-id-type="pmid">15876624</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rickert</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>de Oliveira</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Vaadia</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Mehring</surname> <given-names>C</given-names></name>. <article-title>Encoding of movement direction in different frequency ranges of motor cortical local field potentials</article-title>. <source>Journal of Neuroscience</source>. <year>2005</year>;<volume>25</volume>(<issue>39</issue>):<fpage>8815</fpage>–<lpage>8824</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0816-05.2005" xlink:type="simple">10.1523/JNEUROSCI.0816-05.2005</ext-link></comment> <object-id pub-id-type="pmid">16192371</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Waldert</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Preissl</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Demandt</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Braun</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Birbaumer</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Hand movement direction decoded from MEG and EEG</article-title>. <source>Journal of Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>4</issue>):<fpage>1000</fpage>–<lpage>1008</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.5171-07.2008" xlink:type="simple">10.1523/JNEUROSCI.5171-07.2008</ext-link></comment> <object-id pub-id-type="pmid">18216207</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Quandt</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Reichert</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Hinrichs</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Heinze</surname> <given-names>HJ</given-names></name>, <name name-style="western"><surname>Knight</surname> <given-names>RT</given-names></name>, <name name-style="western"><surname>Rieger</surname> <given-names>JW</given-names></name>. <article-title>Single trial discrimination of individual finger movements on one hand: a combined MEG and EEG study</article-title>. <source>NeuroImage</source>. <year>2012</year>;<volume>59</volume>(<issue>4</issue>):<fpage>3316</fpage>–<lpage>3324</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2011.11.053" xlink:type="simple">10.1016/j.neuroimage.2011.11.053</ext-link></comment> <object-id pub-id-type="pmid">22155040</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fuentemilla</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Penny</surname> <given-names>WD</given-names></name>, <name name-style="western"><surname>Cashdollar</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Bunzeck</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Düzel</surname> <given-names>E</given-names></name>. <article-title>Theta-coupled periodic replay in working memory</article-title>. <source>Current Biology</source>. <year>2010</year>;<volume>20</volume>(<issue>7</issue>):<fpage>606</fpage>–<lpage>612</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2010.01.057" xlink:type="simple">10.1016/j.cub.2010.01.057</ext-link></comment> <object-id pub-id-type="pmid">20303266</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schulz</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Zherdin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Tiemann</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Plant</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Ploner</surname> <given-names>M</given-names></name>. <article-title>Decoding an individual’s sensitivity to pain from the multivariate analysis of EEG data</article-title>. <source>Cerebral Cortex</source>. <year>2011</year>;<volume>22</volume>(<issue>5</issue>):<fpage>1118</fpage>–<lpage>1123</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhr186" xlink:type="simple">10.1093/cercor/bhr186</ext-link></comment> <object-id pub-id-type="pmid">21765182</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref044">
<label>44</label>
<mixed-citation publication-type="other" xlink:type="simple">Olivetti E, Kia SM, Avesani P. MEG decoding across subjects. In: Pattern Recognition in Neuroimaging, 2014 International Workshop on. IEEE; 2014. p. 1–4.</mixed-citation>
</ref>
<ref id="pcbi.1005938.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fraiwan</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Lweesy</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Khasawneh</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Wenz</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Dickhaus</surname> <given-names>H</given-names></name>. <article-title>Automated sleep stage identification system based on time—frequency analysis of a single EEG channel and random forest classifier</article-title>. <source>Computer Methods and Programs in Biomedicine</source>. <year>2012</year>;<volume>108</volume>(<issue>1</issue>):<fpage>10</fpage>–<lpage>19</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cmpb.2011.11.005" xlink:type="simple">10.1016/j.cmpb.2011.11.005</ext-link></comment> <object-id pub-id-type="pmid">22178068</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lehmann</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Koenig</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Jelic</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Prichep</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>John</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>Wahlund</surname> <given-names>LO</given-names></name>, <etal>et al</etal>. <article-title>Application and comparison of classification algorithms for recognition of Alzheimer’s disease in electrical brain activity (EEG)</article-title>. <source>Journal of Neuroscience Methods</source>. <year>2007</year>;<volume>161</volume>(<issue>2</issue>):<fpage>342</fpage>–<lpage>350</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jneumeth.2006.10.023" xlink:type="simple">10.1016/j.jneumeth.2006.10.023</ext-link></comment> <object-id pub-id-type="pmid">17156848</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref047">
<label>47</label>
<mixed-citation publication-type="other" xlink:type="simple">Bentlemsan M, Zemouri ET, Bouchaffra D, Yahya-Zoubir B, Ferroudji K. Random forest and filter bank common spatial patterns for EEG-based motor imagery classification. In: 5th International Conference on Intelligent Systems, Modelling and Simulation (ISMS). IEEE; 2014. p. 235–238.</mixed-citation>
</ref>
<ref id="pcbi.1005938.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Donos</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Dümpelmann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schulze-Bonhage</surname> <given-names>A</given-names></name>. <article-title>Early seizure detection algorithm based on intracranial EEG and random forest classification</article-title>. <source>International journal of neural systems</source>. <year>2015</year>;<volume>25</volume>(<issue>05</issue>):<fpage>1550023</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1142/S0129065715500239" xlink:type="simple">10.1142/S0129065715500239</ext-link></comment> <object-id pub-id-type="pmid">26022388</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tallon-Baudry</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Bertrand</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Hénaff</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Isnard</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Fischer</surname> <given-names>C</given-names></name>. <article-title>Attention modulates gamma-band oscillations differently in the human lateral occipital cortex and fusiform gyrus</article-title>. <source>Cerebral Cortex</source>. <year>2005</year>;<volume>15</volume>(<issue>5</issue>):<fpage>654</fpage>–<lpage>662</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhh167" xlink:type="simple">10.1093/cercor/bhh167</ext-link></comment> <object-id pub-id-type="pmid">15371290</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Swettenham</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Muthukumaraswamy</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Singh</surname> <given-names>KD</given-names></name>. <article-title>Spectral properties of induced and evoked gamma oscillations in human early visual cortex to moving and stationary stimuli</article-title>. <source>Journal of Neurophysiology</source>. <year>2009</year>;<volume>102</volume>(<issue>2</issue>):<fpage>1241</fpage>–<lpage>1253</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.91044.2008" xlink:type="simple">10.1152/jn.91044.2008</ext-link></comment> <object-id pub-id-type="pmid">19515947</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tan</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Gross</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Uhlhaas</surname> <given-names>P</given-names></name>. <article-title>MEG sensor and source measures of visually induced gamma-band oscillations are highly reliable</article-title>. <source>NeuroImage</source>. <year>2016</year>;<volume>137</volume>:<fpage>34</fpage>–<lpage>44</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2016.05.006" xlink:type="simple">10.1016/j.neuroimage.2016.05.006</ext-link></comment> <object-id pub-id-type="pmid">27153980</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Edwards</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Soltani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Deouell</surname> <given-names>LY</given-names></name>, <name name-style="western"><surname>Berger</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Knight</surname> <given-names>RT</given-names></name>. <article-title>High gamma activity in response to deviant auditory stimuli recorded directly from human cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2005</year>;<volume>94</volume>(<issue>6</issue>):<fpage>4269</fpage>–<lpage>4280</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00324.2005" xlink:type="simple">10.1152/jn.00324.2005</ext-link></comment> <object-id pub-id-type="pmid">16093343</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bidet-Caulet</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Fischer</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Bauchet</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Aguera</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Bertrand</surname> <given-names>O</given-names></name>. <article-title>Neural substrate of concurrent sound perception: direct electrophysiological recordings from human auditory cortex</article-title>. <source>Frontiers in Human Neuroscience</source>. <year>2007</year>;<volume>1</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/neuro.09.005.2007" xlink:type="simple">10.3389/neuro.09.005.2007</ext-link></comment> <object-id pub-id-type="pmid">18958219</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Canolty</surname> <given-names>RT</given-names></name>, <name name-style="western"><surname>Soltani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dalal</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Edwards</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Dronkers</surname> <given-names>NF</given-names></name>, <name name-style="western"><surname>Nagarajan</surname> <given-names>SS</given-names></name>, <etal>et al</etal>. <article-title>Spatiotemporal dynamics of word processing in the human brain</article-title>. <source>Frontiers in Neuroscience</source>. <year>2007</year>;<volume>1</volume>:<fpage>14</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/neuro.01.1.1.014.2007" xlink:type="simple">10.3389/neuro.01.1.1.014.2007</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Edwards</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Soltani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Dalal</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Nagarajan</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Berger</surname> <given-names>MS</given-names></name>, <etal>et al</etal>. <article-title>Comparison of time—frequency responses and the event-related potential to auditory speech stimuli in human cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2009</year>;<volume>102</volume>(<issue>1</issue>):<fpage>377</fpage>–<lpage>386</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.90954.2008" xlink:type="simple">10.1152/jn.90954.2008</ext-link></comment> <object-id pub-id-type="pmid">19439673</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schepers</surname> <given-names>IM</given-names></name>, <name name-style="western"><surname>Hipp</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Schneider</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Röder</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Engel</surname> <given-names>AK</given-names></name>. <article-title>Functionally specific oscillatory activity correlates between visual and auditory cortex in the blind</article-title>. <source>Brain</source>. <year>2012</year>;<volume>135</volume>(<issue>3</issue>):<fpage>922</fpage>–<lpage>934</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/brain/aws014" xlink:type="simple">10.1093/brain/aws014</ext-link></comment> <object-id pub-id-type="pmid">22366801</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sedley</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Teki</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kumar</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Overath</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Barnes</surname> <given-names>GR</given-names></name>, <name name-style="western"><surname>Griffiths</surname> <given-names>TD</given-names></name>. <article-title>Gamma band pitch responses in human auditory cortex measured with magnetoencephalography</article-title>. <source>NeuroImage</source>. <year>2012</year>;<volume>59</volume>(<issue>2</issue>):<fpage>1904</fpage>–<lpage>1911</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2011.08.098" xlink:type="simple">10.1016/j.neuroimage.2011.08.098</ext-link></comment> <object-id pub-id-type="pmid">21925281</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Edwards</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Nagarajan</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Dalal</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Canolty</surname> <given-names>RT</given-names></name>, <name name-style="western"><surname>Kirsch</surname> <given-names>HE</given-names></name>, <name name-style="western"><surname>Barbaro</surname> <given-names>NM</given-names></name>, <etal>et al</etal>. <article-title>Spatiotemporal imaging of cortical activation during verb generation and picture naming</article-title>. <source>NeuroImage</source>. <year>2010</year>;<volume>50</volume>(<issue>1</issue>):<fpage>291</fpage>–<lpage>301</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2009.12.035" xlink:type="simple">10.1016/j.neuroimage.2009.12.035</ext-link></comment> <object-id pub-id-type="pmid">20026224</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Steinschneider</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Nourski</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Kawasaki</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Oya</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Brugge</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Howard</surname> <given-names>MA</given-names></name>. <article-title>Intracranial study of speech-elicited activity on the human posterolateral superior temporal gyrus</article-title>. <source>Cerebral Cortex</source>. <year>2011</year>;<volume>21</volume>(<issue>10</issue>):<fpage>2332</fpage>–<lpage>2347</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhr014" xlink:type="simple">10.1093/cercor/bhr014</ext-link></comment> <object-id pub-id-type="pmid">21368087</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lachaux</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>George</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Tallon-Baudry</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Martinerie</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hugueville</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Minotti</surname> <given-names>L</given-names></name>, <etal>et al</etal>. <article-title>The many faces of the gamma band response to complex visual stimuli</article-title>. <source>NeuroImage</source>. <year>2005</year>;<volume>25</volume>(<issue>2</issue>):<fpage>491</fpage>–<lpage>501</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2004.11.052" xlink:type="simple">10.1016/j.neuroimage.2004.11.052</ext-link></comment> <object-id pub-id-type="pmid">15784428</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Vidal</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Chaumon</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>O’Regan</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Tallon-Baudry</surname> <given-names>C</given-names></name>. <article-title>Visual grouping and the focusing of attention induce gamma-band oscillations at different frequencies in human magnetoencephalogram signals</article-title>. <source>Journal of Cognitive Neuroscience</source>. <year>2006</year>;<volume>18</volume>(<issue>11</issue>):<fpage>1850</fpage>–<lpage>1862</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn.2006.18.11.1850" xlink:type="simple">10.1162/jocn.2006.18.11.1850</ext-link></comment> <object-id pub-id-type="pmid">17069476</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Siegel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Donner</surname> <given-names>TH</given-names></name>, <name name-style="western"><surname>Oostenveld</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Engel</surname> <given-names>AK</given-names></name>. <article-title>High-frequency activity in human visual cortex is modulated by visual motion strength</article-title>. <source>Cerebral Cortex</source>. <year>2007</year>;<volume>17</volume>(<issue>3</issue>):<fpage>732</fpage>–<lpage>741</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhk025" xlink:type="simple">10.1093/cercor/bhk025</ext-link></comment> <object-id pub-id-type="pmid">16648451</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jung</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Mainy</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Kahane</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Minotti</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Hoffmann</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Bertrand</surname> <given-names>O</given-names></name>, <etal>et al</etal>. <article-title>The neural bases of attentive reading</article-title>. <source>Human Brain Mapping</source>. <year>2008</year>;<volume>29</volume>(<issue>10</issue>):<fpage>1193</fpage>–<lpage>1206</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hbm.20454" xlink:type="simple">10.1002/hbm.20454</ext-link></comment> <object-id pub-id-type="pmid">17894399</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dalal</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Baillet</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Adam</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Ducorps</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Jerbi</surname> <given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Simultaneous MEG and intracranial EEG recordings during attentive reading</article-title>. <source>NeuroImage</source>. <year>2009</year>;<volume>45</volume>(<issue>4</issue>):<fpage>1289</fpage>–<lpage>1304</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2009.01.017" xlink:type="simple">10.1016/j.neuroimage.2009.01.017</ext-link></comment> <object-id pub-id-type="pmid">19349241</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hamamé</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Vidal</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Ossandón</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Jerbi</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dalal</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Minotti</surname> <given-names>L</given-names></name>, <etal>et al</etal>. <article-title>Reading the mind’s eye: Online detection of visuo-spatial working memory and visual imagery in the inferior temporal lobe</article-title>. <source>NeuroImage</source>. <year>2012</year>;<volume>59</volume>(<issue>1</issue>):<fpage>872</fpage>–<lpage>879</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2011.07.087" xlink:type="simple">10.1016/j.neuroimage.2011.07.087</ext-link></comment> <object-id pub-id-type="pmid">21839843</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hamamé</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Szwed</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sharman</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Vidal</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Perrone-Bertolotti</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kahane</surname> <given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Dejerine’s reading area revisited with intracranial EEG: Selective responses to letter strings</article-title>. <source>Neurology</source>. <year>2013</year>;<volume>80</volume>(<issue>6</issue>):<fpage>602</fpage>–<lpage>603</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1212/WNL.0b013e31828154d9" xlink:type="simple">10.1212/WNL.0b013e31828154d9</ext-link></comment> <object-id pub-id-type="pmid">23382370</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005938.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chang</surname> <given-names>EF</given-names></name>, <name name-style="western"><surname>Edwards</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Nagarajan</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Fogelson</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dalal</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Canolty</surname> <given-names>RT</given-names></name>, <etal>et al</etal>. <article-title>Cortical spatio-temporal dynamics underlying phonological target detection in humans</article-title>. <source>Journal of Cognitive Neuroscience</source>. <year>2011</year>;<volume>23</volume>(<issue>6</issue>):<fpage>1437</fpage>–<lpage>1446</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn.2010.21466" xlink:type="simple">10.1162/jocn.2010.21466</ext-link></comment> <object-id pub-id-type="pmid">20465359</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005996</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-00803</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Behavior</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Animal signaling and communication</subject><subj-group><subject>Vocalization</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Zoology</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Animal signaling and communication</subject><subj-group><subject>Vocalization</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Speech</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Signal processing</subject><subj-group><subject>Speech signal processing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Acoustics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Acoustics</subject><subj-group><subject>Acoustic signals</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Acoustics</subject><subj-group><subject>Bioacoustics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Bioacoustics</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Signal processing</subject><subj-group><subject>Bandwidth (signal processing)</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Origins of scale invariance in vocalization sequences and speech</article-title>
<alt-title alt-title-type="running-head">Origins of scale invariance in vocalization sequences and speech</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Khatami</surname>
<given-names>Fatemeh</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6986-5684</contrib-id>
<name name-style="western">
<surname>Wöhr</surname>
<given-names>Markus</given-names>
</name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Read</surname>
<given-names>Heather L.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7271-1061</contrib-id>
<name name-style="western">
<surname>Escabí</surname>
<given-names>Monty A.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Biomedical Engineering, University of Connecticut, Storrs, Connecticut, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Behavioral Neuroscience, Experimental and Biological Psychology, Faculty of Psychology, Philipps-University of Marburg, Marburg, Germany</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Center for Mind, Brain, and Behavior (CMBB), Philipps-University of Marburg, Marburg, Germany</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Department of Psychological Sciences, University of Connecticut, Storrs, Connecticut, United States of America</addr-line></aff>
<aff id="aff005"><label>5</label> <addr-line>Electrical and Computer Engineering, University of Connecticut, Storrs, Connecticut, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Theunissen</surname>
<given-names>Frédéric E.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of California at Berkeley, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>No</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">escabi@engr.uconn.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>16</day>
<month>4</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="collection">
<month>4</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>4</issue>
<elocation-id>e1005996</elocation-id>
<history>
<date date-type="received">
<day>18</day>
<month>5</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>23</day>
<month>1</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Khatami et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005996"/>
<abstract>
<p>To communicate effectively animals need to detect temporal vocalization cues that vary over several orders of magnitude in their amplitude and frequency content. This large range of temporal cues is evident in the power-law scale-invariant relationship between the power of temporal fluctuations in sounds and the sound modulation frequency (<italic>f</italic>). Though various forms of scale invariance have been described for natural sounds, the origins and implications of scale invariant phenomenon remain unknown. Using animal vocalization sequences, including continuous human speech, and a stochastic model of temporal amplitude fluctuations we demonstrate that temporal acoustic edges are the primary acoustic cue accounting for the scale invariant phenomenon. The modulation spectrum of vocalization sequences and the model both exhibit a dual regime lowpass structure with a flat region at low modulation frequencies and scale invariant 1/<italic>f</italic><sup>2</sup> trend for high modulation frequencies. Moreover, we find a time-frequency tradeoff between the average vocalization duration of each vocalization sequence and the cutoff frequency beyond which scale invariant behavior is observed. These results indicate that temporal edges are universal features responsible for scale invariance in vocalized sounds. This is significant since temporal acoustic edges are salient perceptually and the auditory system could exploit such statistical regularities to minimize redundancies and generate compact neural representations of vocalized sounds.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>The efficient coding hypothesis posits that the brain encodes sensory signals efficiently in order to reduce metabolic cost and preserve behaviorally relevant environment information. In audition, recognition and coding depends on the brain’s ability to accurately and efficiently encode statistical regularities that are prevalent in natural sounds. Similarly, efficient audio coding and compression schemes attempt to preserve salient sound qualities while minimizing data bandwidth. A widely observed statistical regularity in nearly all natural sounds is the presence of scale invariance where the power of amplitude fluctuations is inversely related to the sound amplitude modulation frequency. In this study, we explore the physical sound cues responsible for the scale invariant phenomenon previously observed. We demonstrate that for animal vocalizations, including human speech, the scale invariant behavior is fully accounted by the presence of temporal acoustic edges that are largely created by opening and closing of the oral cavity and which mark the beginning and end of isolated vocalizations. The findings thus identify a single physical cue responsible for the universal scale invariant phenomenon that the brain can exploit to optimize coding and perception of vocalized sounds.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000055</institution-id>
<institution>National Institute on Deafness and Other Communication Disorders</institution>
</institution-wrap>
</funding-source>
<award-id>R01DC015138</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Escabí</surname>
<given-names>Monty A.</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000154</institution-id>
<institution>Division of Integrative Organismal Systems</institution>
</institution-wrap>
</funding-source>
<award-id>1355065</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Read</surname>
<given-names>Heather L.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by the National Institute On Deafness And Other Communication Disorders of the National Institutes of Health under award R01DC015138 to M.A.E. and the National Science Foundation under award IOS 1355065 to H.L.R. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH or NSF. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="3"/>
<page-count count="20"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-04-26</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The sounds used in this study consists of copyrighted sound samples from commercially available media or from previously published works. Information regarding the original sources and sound tracks has been provided in the manuscript (Materials and Methods).</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Efficient coding strategies for representing natural sensory signals aim to generate compact neural representations of the external world. Barlow originally proposed the efficient coding hypothesis as a theoretical model of neural coding that aims to maximize information transfer between the external world and the brain while reducing metabolic and computational cost to an organism [<xref ref-type="bibr" rid="pcbi.1005996.ref001">1</xref>]. According to this model, neural computations performed by the brain should be optimized for extracting information from natural sensory signals and thus should be adapted for statistical regularities prevalent in natural environments.</p>
<p>One such statistical regularity is the widely-observed scale invariant relationship between the signal power and frequency of a sensory signal in which the power can be described as a power-law function of general form <italic>S</italic><sub><italic>xx</italic></sub>(<italic>f</italic>) ∝ <italic>f</italic><sup>−<italic>α</italic></sup>, where <italic>f</italic> is the signal frequency and <italic>α</italic> is the scaling exponent. Natural visual scenes, for instance, exhibit this generalized form of scaling [<xref ref-type="bibr" rid="pcbi.1005996.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1005996.ref003">3</xref>] and it has been demonstrated that the spatial arrangement of object boundaries which contain edges are necessary to account for the empirically observed scaling exponent of <italic>α</italic> ≈ 2 [<xref ref-type="bibr" rid="pcbi.1005996.ref004">4</xref>–<xref ref-type="bibr" rid="pcbi.1005996.ref006">6</xref>]. Neurons in the central visual system are optimized to encode a wide range of edge orientations [<xref ref-type="bibr" rid="pcbi.1005996.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1005996.ref007">7</xref>], supporting the hypothesis that the brain is specialized for such statistical regularities in natural environments.</p>
<p>As for visual scenes, natural sounds also exhibit various forms of scale invariance, although the acoustic features that contribute to such phenomenon have remained elusive. Long-term fluctuations in the intensity profile of speech and music where first reported to exhibit scale invariance for frequencies &lt; 1 Hz and with a scaling exponent of <italic>α</italic> ≈ 1 [<xref ref-type="bibr" rid="pcbi.1005996.ref008">8</xref>]. Subsequent studies further demonstrated that amplitude modulations of natural sounds including speech, animal vocalizations, environmental sounds also exhibit scale invariance [<xref ref-type="bibr" rid="pcbi.1005996.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1005996.ref012">12</xref>]. Upon representing a natural sound by the analytic signal <italic>S</italic><sub><italic>A</italic></sub>(<italic>t</italic>) = <italic>x</italic>(<italic>t</italic>)e<sup><italic>iθ</italic>(<italic>t</italic>)</sup>, where <inline-formula id="pcbi.1005996.e001"><alternatives><graphic id="pcbi.1005996.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:msqrt></mml:math></alternatives></inline-formula>, <italic>θ</italic>(<italic>t</italic>) is the carrier phase, and <italic>x</italic>(<italic>t</italic>) is the modulation signal or equivalently the temporal envelope [<xref ref-type="bibr" rid="pcbi.1005996.ref013">13</xref>], the amplitude modulation power spectrum (AMPS) is defined as the Fourier transform magnitude of the envelope signal, <italic>x</italic>(<italic>t</italic>). For natural sounds the AMPS is well described by a generalized power-law function of the form <italic>S</italic><sub><italic>xx</italic></sub>(<italic>f</italic>) ∝ <italic>f</italic><sup>−<italic>α</italic></sup>, such that the power in the envelope signal drops off with increasing modulation frequency (<italic>f</italic>) with exponent between <italic>α</italic> ≈ 1 − 2 within the approximate frequency range 1 to 100 Hz [<xref ref-type="bibr" rid="pcbi.1005996.ref010">10</xref>–<xref ref-type="bibr" rid="pcbi.1005996.ref012">12</xref>]. With the exception of water sounds, where scale invariance is accounted for by the distribution of self-similar acoustic “droplets” [<xref ref-type="bibr" rid="pcbi.1005996.ref009">9</xref>], it remains a mystery as to whether there are universal acoustic features that contribute to scale invariance for broader categories of natural and man-made sounds. Answering this question has important implications as neurons in the mammalian auditory system efficiently encode scale invariant structure in the sound envelope [<xref ref-type="bibr" rid="pcbi.1005996.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005996.ref014">14</xref>] suggesting it is a critical driver of brain pathway function and perception abilities.</p>
<p>Physically, vocalization production in many species entails a source generator (e.g., vocal folds) that produces quasi-periodic envelope signal and articulatory gestures, for instance the opening and closing of the mouth and postural adjustments of the lips and tongue, that dynamically shape the sound envelope during speech production. Envelope fluctuations created by vocal fold vibration lie outside the modulation frequency range where scaling is observed [<xref ref-type="bibr" rid="pcbi.1005996.ref012">12</xref>] (i.e., &gt;100 Hz) and thus should not contribute to scaling directly. In contrast, transient temporal onset and offset that mark the boundaries between isolated vocalizations are evident across many species and produce transient envelope fluctuations that may contribute to scaling behavior. In human speech, for instance, these salient features are generated by the time-dependent opening and closing of the oral cavity and related articulatory gestures. Drawing analogies from the statistics of natural visual scenes and the prevailing role of object boundaries [<xref ref-type="bibr" rid="pcbi.1005996.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1005996.ref005">5</xref>], we test the hypothesis that transient temporal edges account for the scaling phenomenon observed in natural vocalized sounds. We demonstrate that temporal edge boundaries in vocalizations are responsible for producing a amplitude modulation spectrum with dual-regime lowpass structure consisting of a flat region for low modulation frequencies and <italic>f</italic><sup>−2</sup> scale invariant trend at high modulation frequencies.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec003">
<title>Sound database</title>
<p>Sequences of vocalized sounds were obtained from a variety of digital sound sources. Vocalization sequences for a rat pup (HsdCpb/Wistar) [<xref ref-type="bibr" rid="pcbi.1005996.ref015">15</xref>], a mouse pup (C57BL/6 mice) [<xref ref-type="bibr" rid="pcbi.1005996.ref016">16</xref>], and a crying infant [<xref ref-type="bibr" rid="pcbi.1005996.ref017">17</xref>] all consisted of a single long-duration vocalization sequence (5–7 min duration; <xref ref-type="table" rid="pcbi.1005996.t001">Table 1</xref>). Excerpts of continuously spoken speech totaling five minutes were obtained from a BBC broadcast reproduction of Hamlet [<xref ref-type="bibr" rid="pcbi.1005996.ref018">18</xref>]. Vocalization sequences were also obtained from various bird species [<xref ref-type="bibr" rid="pcbi.1005996.ref019">19</xref>] (Track 4: superb lyrebird, 35: winter wren, 41: common loon, and 46: gray-necked wood rail) and several species of new-world monkeys [<xref ref-type="bibr" rid="pcbi.1005996.ref020">20</xref>] (Track 9: Black Mantle Tamarin, Track 18: Golden Lion Tamarin, Track 32: White-Throated Capuchin Monkey, Track 43: Black Howler Monkeys, Track 48: Yellow Tail Wooly Monkey, Track 49: Common Wooly Monkey). Single long-duration sequences were not available for either bird or monkey vocalization categories and for this reason shorter sequences (monkey sequence range = 20–120 sec duration, average duration = 48 sec; bird sequence range = 26–135 sec, average duration = 60 sec) from different species were used to measure the envelope group statistics and AMPS for these groups. All of the vocalization sequence segments were selected because they contained well-isolated vocalization with minimal background noise. Vocalization sequences were sampled at a sampling rate (<italic>F</italic><sub><italic>s</italic></sub>) to preserve the frequency content of each species (<xref ref-type="table" rid="pcbi.1005996.t001">Table 1</xref>).</p>
<table-wrap id="pcbi.1005996.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005996.t001</object-id>
<label>Table 1</label> <caption><title>Parameters used for envelope extraction and model fitting.</title></caption>
<alternatives>
<graphic id="pcbi.1005996.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005996.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center"/>
<th align="center">Sound Duration (min)</th>
<th align="center"><italic>F</italic><sub><italic>s</italic></sub><break/>(kHz)<break/></th>
<th align="center"><italic>DF</italic><break/></th>
<th align="center"><italic>T</italic><sub><italic>x</italic></sub><break/></th>
<th align="left"><italic>f</italic><sub><italic>low</italic></sub><break/>(kHz)<break/></th>
<th align="center"><italic>f</italic><sub><italic>high</italic></sub><break/>(kHz)<break/></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><bold><italic>Rat</italic></bold></td>
<td align="center"><italic>6</italic></td>
<td align="center">250</td>
<td align="center">100</td>
<td align="center">10</td>
<td align="center">30</td>
<td align="center">100</td>
</tr>
<tr>
<td align="center"><bold><italic>Mouse</italic></bold></td>
<td align="center"><italic>5</italic></td>
<td align="center">300</td>
<td align="center">100</td>
<td align="center">30</td>
<td align="center">30</td>
<td align="center">100</td>
</tr>
<tr>
<td align="center"><bold><italic>Bird</italic></bold></td>
<td align="center"><italic>5</italic></td>
<td align="center">44.1</td>
<td align="center">10</td>
<td align="center">30</td>
<td align="center">0.5</td>
<td align="center">20</td>
</tr>
<tr>
<td align="center"><bold><italic>Monkey</italic></bold></td>
<td align="center"><italic>9</italic>.<italic>66</italic></td>
<td align="center">44.1</td>
<td align="center">10</td>
<td align="center">30</td>
<td align="center">0.5</td>
<td align="center">20</td>
</tr>
<tr>
<td align="center"><bold><italic>Infant</italic></bold></td>
<td align="center"><italic>7</italic></td>
<td align="center">44.1</td>
<td align="center">10</td>
<td align="center">30</td>
<td align="center">0.5</td>
<td align="center">20</td>
</tr>
<tr>
<td align="center"><bold><italic>Speech</italic></bold></td>
<td align="center"><italic>5</italic></td>
<td align="center">44.1</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center">0.5</td>
<td align="center">20</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec004">
<title>Amplitude modulation power spectrum</title>
<p>For each vocalization sequence, we computed the vocalization sequence envelopes and computed the amplitude modulation power spectrum (AMPS) by extracting the temporal envelope of each sound sequence and subsequently computing the Fourier transform magnitude. Sounds were first bandpass filtered between frequencies <italic>f</italic><sub><italic>low</italic></sub> and <italic>f</italic><sub><italic>high</italic></sub> so as to encompass the frequency range of each vocalization sequence
<disp-formula id="pcbi.1005996.e002">
<alternatives>
<graphic id="pcbi.1005996.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where <italic>h</italic><sub><italic>band</italic></sub>(<italic>t</italic>) is a Kaiser bandpass filter impulse response (<italic>β</italic> = 5.6, filter order = 640, sidelobe error 60 dB) and * is the convolution operator. Since the vocalizations for each species has dominant energy over a unique frequency range, the frequencies <italic>f</italic><sub><italic>low</italic></sub> and <italic>f</italic><sub><italic>high</italic></sub> were individually selected based on visual inspection of the sound spectrum (<xref ref-type="table" rid="pcbi.1005996.t001">Table 1</xref>). For the rat and mouse vocalizations the bandpass filter was selected to overlap the ultrasonic range (<italic>f</italic><sub><italic>low</italic></sub> = 30 kHz and <italic>f</italic><sub><italic>high</italic></sub> = 100 kHz) where the vocalizations had dominant energy. For the remaining vocalizations, <italic>f</italic><sub><italic>low</italic></sub> = 500 Hz and <italic>f</italic><sub><italic>high</italic></sub> = 20 kHz. <italic>f</italic><sub><italic>low</italic></sub> was chosen as 500 Hz because we measured the AMPS up to 250 Hz modulation frequency, which requires a carrier frequency of at least 500 Hz. The upper filter cutoff was selected as 20kHz which encompasses the bandwidth of the anti-aliasing filters for each recording.</p>
<p>For each of the bandpass filtered signals, we next extracted the envelope. This was done by first computing the analytic signal:
<disp-formula id="pcbi.1005996.e003">
<alternatives>
<graphic id="pcbi.1005996.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:mi>H</mml:mi><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>θ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup>
</mml:math>
</alternatives>
</disp-formula>
where <italic>H</italic>{∙} is the Hilbert transform [<xref ref-type="bibr" rid="pcbi.1005996.ref013">13</xref>]. The temporal envelope is then obtained by taking the analytic signal magnitude
<disp-formula id="pcbi.1005996.e004">
<alternatives>
<graphic id="pcbi.1005996.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
The envelopes were next passed through an antialiasing lowpass filter (250 Hz cutoff) to limit the modulation content to the range of interest (0–250 Hz), down sampled by a factor <italic>DF</italic> (see <xref ref-type="table" rid="pcbi.1005996.t001">Table 1</xref>), and scaled for unit standard deviation. An example speech waveform excerpt and the corresponding filtered envelope obtained with the above procedure are shown in <xref ref-type="fig" rid="pcbi.1005996.g001">Fig 1</xref> (<xref ref-type="fig" rid="pcbi.1005996.g001">Fig 1<bold>A</bold></xref>, black = original sound waveform; <xref ref-type="fig" rid="pcbi.1005996.g001">Fig 1<bold>B</bold> and 1<bold>C</bold></xref>, red = 250 Hz filtered envelope).</p>
<fig id="pcbi.1005996.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005996.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Envelope extraction, segmentation, and model fitting.</title>
<p>(<bold>a</bold>) Acoustic waveform for a speech sample from the BBC reproduction of Hamlet containing the phrase “That’s not my meaning: but breathes his faults so quaintly.” (<bold>b</bold>) The envelope used for segmentation (blue) was obtained by lowpass filtering the analytic signal amplitude at 30 Hz whereas the envelope used for data analysis and model fitting was filtered at 250 Hz (red). The optimized model envelope for this example consists of sequence of non-overlapping rectangular pulses of variable duration and amplitude (green). (<bold>c</bold>) Zoomed-in view of a short segment of the corresponding envelopes in (<bold>b</bold>). The model (green) captures the transient onsets and offsets between consecutive speech elements and words, but is unable to capture other envelope features such as the fast-periodic fluctuations created through vocal fold vibration (~190 Hz fundamental in <bold>c</bold>) that are evident in the original envelope (red).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005996.g001" xlink:type="simple"/>
</fig>
<p>Finally, we computed the AMPS of each animal group. The power spectral density of the envelope, <italic>x</italic>(<italic>t</italic>), was estimated using a multi-taper spectral estimator (pmtm.m MATLAB function, NFFT = 16384, NW = 7/2). This procedure generates a power spectral density estimate with nominal frequency resolution of ~0.1 Hz. An NFFT value of 16384 was used to analyze all of the data with the exception the periodic simulated envelope of <xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2</xref> (magenta curves in <xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2B and 2F</xref>). In order to achieve sufficiently high frequency resolution to resolve all of the envelope harmonics a value of NFFT = 262144 was used for this example.</p>
<fig id="pcbi.1005996.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005996.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Relationship between sounds’ acoustic envelope parameters and AMPS illustrated for a crying infant and a rat pup vocalization sequences.</title>
<p>(a and e) The original sound waveforms (gray line) and envelopes (black line) are shown along with the pulsed vocalization model (red line). Three models are also shown where one of the three parameters (amplitude, inter-vocalization interval, and duration) was perturbed. The perturbed pulse sequences have either constant pulse amplitudes (green), constant inter-vocalization intervals (magenta line), or zero durations (blue line). (b and f) Amplitude modulation power spectrum for original vocalization envelope and corresponding models (same color convention) show that manipulating durations has the most pronounced effect on the AMPS. (c and g) Vocalizations are also perturbed by synthetically modifying the duration distributions for infant (c) or rat (g) vocalization (uniform, exponential, or gamma distribution with matched mean and variance as the original vocalization). The duration distribution has minimal effect on the AMPS (d and h).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005996.g002" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec005">
<title>Vocalization sequence model</title>
<p>To test whether the envelope of isolated vocalizations contribute to the scale-invariant structure observed in vocalization sequences, we developed a stochastic vocalization sequence model consisting of a sequence of nonoverlapping rectangular pulses, <italic>p</italic><sub><italic>n</italic></sub>(<italic>t</italic>). Each pulse marks the beginning and end of isolated vocalizations. The vocalization envelope can be approximated as
<disp-formula id="pcbi.1005996.e005">
<alternatives>
<graphic id="pcbi.1005996.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∙</mml:mo></mml:mrow></mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where <italic>n</italic> is the pulse number and rect(∙) is a unit amplitude rectangular pulse with start time zero and 1 s duration. The number of isolated vocalizations within the <italic>T</italic> second interval is <italic>N</italic> ≅ <italic>λT</italic> where <italic>λ</italic> is the average vocalization rate in units of vocalizations/s. To account for the vocalization-to-vocalization variability in the sequence, pulse amplitudes (<italic>A</italic><sub><italic>n</italic></sub>), onset times (<italic>t</italic><sub><italic>n</italic></sub>) and durations (<italic>D</italic><sub><italic>n</italic></sub>) are modeled as random variables. The envelopes from each vocalization sequence were fitted to the model of <xref ref-type="disp-formula" rid="pcbi.1005996.e005">Eq 1</xref> to assess how temporal sequence parameters (vocalization peak amplitudes, durations and onset times) contribute to 1/<italic>f</italic> structure. The fitting procedure consisted of two separate steps outlined in the following sections. This includes 1) a segmentation phase in which we detected and segmented the sequence into isolated vocalizations that stand out above the background noise level followed by 2) fitting the envelope from the segmented vocalization to rectangular pulses.</p>
</sec>
<sec id="sec006">
<title>Vocalization segmentation</title>
<p>In order to fit the vocalization sequence data for each animal group to the model of <xref ref-type="disp-formula" rid="pcbi.1005996.e005">Eq 1</xref>, we first segmented the data into segments that contain single isolated vocalizations. Since isolated vocalizations occur at relatively low rates [<xref ref-type="bibr" rid="pcbi.1005996.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005996.ref022">22</xref>] the envelopes of each vocalization sequence, <italic>x</italic>(<italic>t</italic>), were initially filtered to a maximum frequency <italic>f</italic><sub><italic>m</italic></sub> = 30 Hz with a 5-th order B-spline lowpass filter with continuously differentiable impulse response (differentiable to 5<sup>th</sup> order) as shown for a speech segment (<xref ref-type="fig" rid="pcbi.1005996.g001">Fig 1<bold>A</bold></xref>, black = original sound waveform; <xref ref-type="fig" rid="pcbi.1005996.g001">Fig 1<bold>B</bold></xref>, blue = 30 Hz envelope). This 30 Hz lowpass filter is only applied during the vocalization segmentation phase and is used to identify sequence segments that contain isolated vocalizations (consisting of an onset and an offset component). Envelope segments that contained both an onset and offset were identified if the envelope exceeded a designated threshold level (<italic>T</italic><sub><italic>x</italic></sub>, <xref ref-type="table" rid="pcbi.1005996.t001">Table 1</xref>) above the envelope of sequence segments containing background noise. A short 2.7 sec long noise segment from each vocalization was identified audio-visually and used to measure the noise variance for each recording. The threshold level was set to 30 standard deviations (SD) above the noise floor for all vocalizations except for the rat and speech sequence (<italic>T</italic><sub><italic>x</italic></sub> = 10 SD) which required a lower threshold to minimize false negatives (i.e., vocalizations not detected by the algorithm as identified audio-visually). Using this approach total 2957 vocalization segments were identified (rat = 571, mouse = 492, bird = 518, monkey = 590, infant = 389, speech = 801).</p>
</sec>
<sec id="sec007">
<title>Vocalization model fitting</title>
<p>The model fitting procedure was performed on each isolated vocalization following the segmentation. During the fitting procedure, we used the signal envelopes that were lowpass filtered with a cutoff of 250 Hz (<xref ref-type="fig" rid="pcbi.1005996.g001">Fig 1<bold>B</bold></xref>, red, shown for the speech segment in <xref ref-type="fig" rid="pcbi.1005996.g001">Fig 1<bold>A</bold></xref>). Although it is theoretically possible to fit the vocalization model sequence of <xref ref-type="disp-formula" rid="pcbi.1005996.e005">Eq 1</xref> directly to the vocalization sequence envelope, the large number of parameters that would be required in the optimization are prohibitive. For instance, for the crying infant vocalization sequence there are <italic>N</italic> = 389 detected vocalizations, which would require that the algorithm optimize for a total of 1167 (389x3) model parameters. We tested such a global fitting procedure using least-squares and were unable to achieve convergence because of the high parameter dimensionality. Instead, we optimized for each of the detected vocalization sequence segments, which individually requires only three parameters. That is, for each detected vocalization segment, <italic>x</italic><sub><italic>n</italic></sub>(<italic>t</italic>), we fitted a rectangular pulse, <italic>p</italic><sub><italic>n</italic></sub>(<italic>t</italic>), of variable start time (<italic>t</italic><sub><italic>n</italic></sub>), duration (<italic>D</italic><sub><italic>n</italic></sub>), and peak amplitude (<italic>A</italic><sub><italic>n</italic></sub>) using least-squares optimization. The optimization was carried out for all of the detected segments in each sequence. The results of this fitting procedure are illustrated for brief speech segment (<xref ref-type="fig" rid="pcbi.1005996.g001">Fig 1<bold>B</bold> and 1<bold>C</bold></xref>, green). The model envelope accounts for the transient onsets and offsets that mark the beginning and end of vocalizations. It is not intended to model fast modulations that are also evident in the envelopes, such as those arising from periodic vocal fold vibration and which can be seen as a superimposed components (red) that ride on top of the slower vocalization envelope (blue) (zoomed in view in <xref ref-type="fig" rid="pcbi.1005996.g001">Fig 1<bold>C</bold></xref>). The optimal parameters for each segment were then combined into three time-series (<italic>t</italic><sub><italic>n</italic></sub>, <italic>D</italic><sub><italic>n</italic></sub> and <italic>A</italic><sub><italic>n</italic></sub>) that were used to implement the full vocalization sequence model (<xref ref-type="disp-formula" rid="pcbi.1005996.e005">Eq 1</xref>).</p>
</sec>
<sec id="sec008">
<title>Cutoff frequency estimation</title>
<p>For each of the vocalization AMPS, we empirically estimated the cutoff frequency, <italic>f</italic><sub><italic>c</italic></sub>, where the AMPS transitions from a predominantly flat curve at low frequencies to a <italic>f</italic><sup>−2</sup> trend at higher frequencies. This was done by fitting the AMPS of each vocalization to a first-order lowpass spectrum model of the form
<disp-formula id="pcbi.1005996.e006">
<alternatives>
<graphic id="pcbi.1005996.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>C</italic> and <italic>f</italic><sub><italic>c</italic></sub> are free parameters to be determined. The estimated cutoff frequency was derived from the best fit solution of the first order model obtained numerically using least squares.</p>
</sec>
<sec id="sec009">
<title>Vocalization model AMPS derivation</title>
<p>In this section we derive a closed form solution for the AMPS of the stochastic vocalization sequence model of <xref ref-type="disp-formula" rid="pcbi.1005996.e005">Eq 1</xref>. The modulation power spectrum of the vocalization model is obtained by taking the long-term expectation of the Fourier Transform Magnitude:
<disp-formula id="pcbi.1005996.e007">
<alternatives>
<graphic id="pcbi.1005996.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">lim</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mi>E</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:msup><mml:mrow><mml:mi>X</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where <italic>E</italic>[∙] is the expectation operator taken across the three random variables (onset time, duration and amplitude),
<disp-formula id="pcbi.1005996.e008">
<alternatives>
<graphic id="pcbi.1005996.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mi>X</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="fraktur">I</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="fraktur">I</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>π</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>j</mml:mi><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>f</mml:mi><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup>
</mml:math>
</alternatives>
</disp-formula>
is the envelope Fourier transform (<inline-formula id="pcbi.1005996.e009"><alternatives><graphic id="pcbi.1005996.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mi mathvariant="fraktur">I</mml:mi><mml:mo>{</mml:mo><mml:mrow><mml:mo>∙</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:math></alternatives></inline-formula>), and * represents the complex conjugate. The model AMPS is then obtained as
<disp-formula id="pcbi.1005996.e010">
<alternatives>
<graphic id="pcbi.1005996.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">lim</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>→</mml:mo><mml:mo>∞</mml:mo></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>X</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">lim</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>→</mml:mo><mml:mo>∞</mml:mo></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>A</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>π</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>j</mml:mi><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>f</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>A</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>π</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>+</mml:mo><mml:mi>j</mml:mi><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>f</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">lim</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:mrow><mml:msubsup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munder></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>π</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>π</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>j</mml:mi><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
</alternatives>
</disp-formula></p>
<p>As will be illustrated subsequently the measured model parameters are largely independent and onset times are serially uncorrelated for the experimental data. This allows us to assume independence of the model parameters so that the second term inside the expectation approaches zero so that
<disp-formula id="pcbi.1005996.e011">
<alternatives>
<graphic id="pcbi.1005996.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">lim</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:mrow><mml:mi>E</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">lim</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Since in the limiting case <italic>λ</italic> ≃ <italic>N</italic>/<italic>T</italic> and the random variables are approximately independent the AMPS simplifies as follows
<disp-formula id="pcbi.1005996.e012">
<alternatives>
<graphic id="pcbi.1005996.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e012" xlink:type="simple"/>
<mml:math display="block" id="M12">
<mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mo>∙</mml:mo><mml:mi>E</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo><mml:mo>∙</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mo>∙</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo><mml:mo>∙</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Finally, under the assumption that the vocalization durations are uniformly distributed within the interval [<italic>T</italic><sub>1</sub>, <italic>T</italic><sub>2</sub>]
<disp-formula id="pcbi.1005996.e013">
<alternatives>
<graphic id="pcbi.1005996.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:mi>γ</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>γ</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mstyle><mml:msup><mml:mrow><mml:mi>sin</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:mi>γ</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∙</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mstyle><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>γ</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>γ</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>∙</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>so that the AMPS is
<disp-formula id="pcbi.1005996.e014">
<alternatives>
<graphic id="pcbi.1005996.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e014" xlink:type="simple"/>
<mml:math display="block" id="M14">
<mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>λ</mml:mi><mml:mo>∙</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mo>∙</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>∙</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>λ</mml:mi><mml:mo>∙</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mo>∙</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sinc</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sinc</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable>
</mml:math>
</alternatives>
</disp-formula></p>
</sec>
<sec id="sec010">
<title>Vocalization model cutoff frequency derivation</title>
<p>Given that the experimental and model AMPS both have lowpass structure, we derived in closed form the vocalization model AMPS cutoff frequency in order to relate this AMPS parameter to the vocalization model parameters (amplitude, duration and onset times). The vocalization model AMPS cutoff frequency (<italic>f</italic><sub><italic>c</italic></sub>) is defined as the frequency where AMPS achieves half power (- 3dB) relative to the AMPS at zero frequency
<disp-formula id="pcbi.1005996.e015">
<alternatives>
<graphic id="pcbi.1005996.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e015" xlink:type="simple"/>
<mml:math display="block" id="M15">
<mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
which for the model requires that the following equation be satisfied
<disp-formula id="pcbi.1005996.e016">
<alternatives>
<graphic id="pcbi.1005996.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e016" xlink:type="simple"/>
<mml:math display="block" id="M16">
<mml:mfrac><mml:mrow><mml:mi>λ</mml:mi><mml:mo>∙</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mo>∙</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>∙</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>λ</mml:mi><mml:mo>∙</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>6</mml:mn><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
An approximate solution is obtained by noting that for large <italic>f</italic><sub><italic>c</italic></sub> &gt; 1/2<italic>π</italic>(<italic>T</italic><sub>2</sub> − <italic>T</italic><sub>1</sub>)
<disp-formula id="pcbi.1005996.e017">
<alternatives>
<graphic id="pcbi.1005996.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e017" xlink:type="simple"/>
<mml:math display="block" id="M17">
<mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>∙</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>&lt;</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>∙</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
Considering this upper bound, the above equation is approximated as
<disp-formula id="pcbi.1005996.e018">
<alternatives>
<graphic id="pcbi.1005996.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e018" xlink:type="simple"/>
<mml:math display="block" id="M18">
<mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mo>∙</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>≈</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>6</mml:mn><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
and solving for the cutoff frequency yields
<disp-formula id="pcbi.1005996.e019">
<alternatives>
<graphic id="pcbi.1005996.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e019" xlink:type="simple"/>
<mml:math display="block" id="M19">
<mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>3</mml:mn><mml:mo>∙</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:msqrt>
</mml:math>
</alternatives>
</disp-formula>
Finally, since <italic>μ</italic><sub><italic>D</italic></sub> = (<italic>T</italic><sub>1</sub> + <italic>T</italic><sub>2</sub>)/2 and <inline-formula id="pcbi.1005996.e020"><alternatives><graphic id="pcbi.1005996.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> for a uniform distribution the cutoff can be expressed as
<disp-formula id="pcbi.1005996.e021">
<alternatives>
<graphic id="pcbi.1005996.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e021" xlink:type="simple"/>
<mml:math display="block" id="M21">
<mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mi>E</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
</sec>
</sec>
<sec id="sec011" sec-type="results">
<title>Results</title>
<sec id="sec012">
<title>Temporal cues responsible for power-law scaling</title>
<p>We explore which temporal cues contribute to scaling phenomena in vocalization sequences. We consider a stochastic model of vocalization envelope sequence, <italic>x</italic>(<italic>t</italic>), containing three distinct forms of temporal variability (<xref ref-type="disp-formula" rid="pcbi.1005996.e005">Eq 1</xref>, <bold>Materials and methods</bold>). The envelope of each vocalization sequence is approximated as a superposition of rectangular pulses each with a distinct onset time (<italic>t</italic><sub><italic>n</italic></sub>), pulse amplitude (<italic>A</italic><sub><italic>n</italic></sub>), and duration (<italic>D</italic><sub><italic>n</italic></sub>). Each parameter is modeled as a random variable to account for vocalization-to-vocalization variability in the sequence.</p>
<p><xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2</xref> illustrates how each of the model acoustic features contributes to the AMPS of natural vocalization sequences from an infant (a-d) and a rat pup (e-h), respectively. Vocalization amplitudes, onset times, and duration parameters are obtained for each vocalization in the sequence by fitting the model (a and e; red curve) to the original sound envelope (a and e; black curve) and the AMPS of the model envelope is computed (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2B and 2F</xref>; see <xref ref-type="sec" rid="sec002">Materials and methods</xref>). Statistics for each of the estimated model parameters from the vocalization recordings is provided in <xref ref-type="table" rid="pcbi.1005996.t002">Table 2</xref> (see <xref ref-type="sec" rid="sec002">Materials and methods</xref> for details). The model AMPS (red) has a lowpass shape and power-law scaling similar to the original vocalization sequence AMPS (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2B and 2F</xref>, black) with an RMS error of 3.9 dB (for frequencies between 1–100 Hz). Although the model follows the natural sound AMPS for low and intermediate modulation frequencies, it deviates at high modulation frequencies (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2B</xref>, &gt;100 Hz for infant; <xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2F</xref>, &gt;40 Hz for rat pup). In humans, this model disparity is partly explained by periodic modulations generated by the vocal fold vibrations [<xref ref-type="bibr" rid="pcbi.1005996.ref012">12</xref>] that contribute to the perceived vocal pitch and, though critical for identifying speech source attributes such as gender, they are not essential for speech intelligibility [<xref ref-type="bibr" rid="pcbi.1005996.ref023">23</xref>]. This result indicates that our model captures much of the general AMPS shape of natural vocalization sequences, particularly the power-law scaling trend.</p>
<table-wrap id="pcbi.1005996.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005996.t002</object-id>
<label>Table 2</label> <caption><title>Estimated model parameters for each vocalization sequence.</title></caption>
<alternatives>
<graphic id="pcbi.1005996.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005996.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center"><italic> </italic></th>
<th align="center"><italic>μ</italic><sub><italic>A</italic></sub></th>
<th align="center"><italic>σ</italic><sub><italic>A</italic></sub></th>
<th align="center"><italic>μ</italic><sub><italic>D</italic></sub> (s)</th>
<th align="center"><italic>σ</italic><sub><italic>D</italic></sub> (s)</th>
<th align="center"><italic>μ</italic><sub><italic>I</italic></sub> (s)</th>
<th align="center"><italic>σ</italic><sub><italic>I</italic></sub> (s) </th>
<th align="center"> <italic>λ</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><bold><italic>Rat</italic></bold></td>
<td align="center">0.86</td>
<td align="center">2.14</td>
<td align="center">0.036</td>
<td align="center">0.039</td>
<td align="center">0.63</td>
<td align="center">0.82</td>
<td align="center">1.59</td>
</tr>
<tr>
<td align="center"><bold><italic>Mouse</italic></bold></td>
<td align="center">1.22</td>
<td align="center">3.66</td>
<td align="center">0.013</td>
<td align="center">0.011</td>
<td align="center">0.6</td>
<td align="center">1.47</td>
<td align="center">1.65</td>
</tr>
<tr>
<td align="center"><bold><italic>Bird</italic></bold></td>
<td align="center">1.51</td>
<td align="center">1.16</td>
<td align="center">0.14</td>
<td align="center">0.37</td>
<td align="center">0.57</td>
<td align="center">1.29</td>
<td align="center">1.74</td>
</tr>
<tr>
<td align="center"><bold><italic>Monkey</italic></bold></td>
<td align="center">1.14</td>
<td align="center">0.86</td>
<td align="center">0.14</td>
<td align="center">0.21</td>
<td align="center">0.53</td>
<td align="center">0.76</td>
<td align="center">1.89</td>
</tr>
<tr>
<td align="center"><bold><italic>Infant</italic></bold></td>
<td align="center">1.58</td>
<td align="center">1.02</td>
<td align="center">0.33</td>
<td align="center">0.2</td>
<td align="center">1.06</td>
<td align="center">0.99</td>
<td align="center">0.94</td>
</tr>
<tr>
<td align="center"><bold><italic>Speech</italic></bold></td>
<td align="center">0.84</td>
<td align="center">0.72</td>
<td align="center">0.22</td>
<td align="center">0.27</td>
<td align="center">0.37</td>
<td align="center">0.36</td>
<td align="center">2.68</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>Mean and standard deviation values are provided for the vocalization amplitude (<italic>μ</italic><sub><italic>A</italic></sub>, <italic>σ</italic><sub><italic>A</italic></sub>), duration (<italic>μ</italic><sub><italic>D</italic></sub>, <italic>σ</italic><sub><italic>D</italic></sub>) and inter-vocalization interval (<italic>μ</italic><sub><italic>I</italic></sub>, <italic>σ</italic><sub><italic>I</italic></sub>). <italic>λ</italic> is the vocalization rate (units of vocalizations/s).</p></fn>
</table-wrap-foot>
</table-wrap>
<p>By synthetically altering the model parameters we further explore how each temporal cue shapes the AMPS. First, we assess the contribution of vocalization amplitude variability by assigning a fixed amplitude to each model vocalization pulse (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2A and 2E</xref>, green) while keeping all other parameters fixed. The pulse amplitudes are chosen so that the fixed amplitude model envelope and the original model envelope have matched variance. This manipulation has minimal effect on the AMPS (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2B and 2F</xref>, green) since it maintains the lowpass shape and power-law scaling similar to the original vocalization sequence. Secondly, we manipulated the inter-vocalization intervals, defined as the time difference between consecutive vocalization onset times, Δ<italic>t</italic><sub><italic>n</italic></sub> = <italic>t</italic><sub><italic>n</italic>+1</sub> − <italic>t</italic><sub><italic>n</italic></sub>, to determine whether timing variability between vocalizations contributes to the power-law scaling. When we impose a constant inter-vocalization interval of 1 second (a and e, magenta) the modulation spectrum exhibits harmonic structure with 1Hz fundamental component that reflects the periodic structure of the inter-vocalization intervals. However, the resulting spectrum and the peak amplitude of the harmonics still follow the <italic>f</italic><sup>−2</sup> modulation spectrum trend (b and f, magenta), which suggest that the exact structure of the inter-vocalization intervals are not the critical parameters accounting for this behavior. Thirdly, temporal variation in vocalization durations is explored by replacing the pulse model approximation of each natural vocalization with a Dirac impulse that has a fixed duration of zero seconds (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2A and 2E</xref>, blue). Removing the variation in vocalization duration results in a flat AMPS (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2B and 2F</xref>, blue) that no longer exhibits scaling. The last manipulation conserves variations in the inter-vocalization intervals and amplitudes, indicating that these features alone are not sufficient to account for the lowpass trend with scaling at high frequencies whereas vocalization duration is critical.</p>
<p>To further explore the impact of vocalization durations we synthetically manipulated the duration distribution to determine how it contributes to scaling. We replaced the empirically measured durations with samples drawn from either a uniform (orange), exponential (light blue), or gamma (dark green) distribution with matched mean and variance (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2C and 2G</xref>). As can be seen, the resulting AMPS is largely unaffected by the model distributions used as long as the vocalization durations have the same mean and variance (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2D and 2H</xref>; as described subsequently). The measured RMS error between the simulated model AMPS with different duration distributions and the actual AMPS for modulation frequencies between 1–100 Hz was relatively small (between 3–4 dB for all of the distributions). This indicates that the AMPS shape is largely independent of the type of distribution used to model the vocalization durations.</p>
<p>It is conceivable that scaling emerges due to serial correlations and co-variation between the vocalization amplitudes, durations, and intervals. We assess these possibilities by examining the statistical structure of these three acoustic parameters for the infant and rat pup (<xref ref-type="fig" rid="pcbi.1005996.g003">Fig 3</xref>). The joint duration-amplitude distribution (<xref ref-type="fig" rid="pcbi.1005996.g003">Fig 3A and 3F</xref>) is relatively compact and these parameters exhibit a significant but weak correlation (infant, 0.11±0.04; rat, r = 0.49±0.05; mean±SE; t-test, p&lt;0.01; see <xref ref-type="table" rid="pcbi.1005996.t003">Table 3</xref> for additional vocalization statistics). The autocorrelation for the duration and amplitude time series has impulsive structure, indicating minimal serial correlation for the infant and rat pup vocalization sequences (infant, <xref ref-type="fig" rid="pcbi.1005996.g003">Fig 3C and 3D</xref>; rat pup, <xref ref-type="fig" rid="pcbi.1005996.g003">Fig 3H and 3I</xref>). Furthermore, the inter-vocalization intervals follow an approximately exponential distribution as expected for a Poisson point process (<xref ref-type="fig" rid="pcbi.1005996.g003">Fig 3B and 3G</xref>), although there is a short latent period (~150 ms, infant; ~30 ms, rat pup) in the interval distribution indicating a brief silent period between consecutive vocalizations. Inter-vocalization intervals are weakly correlated with the vocalization duration and amplitude parameters (<xref ref-type="table" rid="pcbi.1005996.t003">Table 3</xref>). Finally, upon treating the vocalization onset times as a renewal point process, we find that these are uncorrelated as evident from the impulse structure of the point process autocorrelation (<xref ref-type="fig" rid="pcbi.1005996.g003">Fig 3E and 3J</xref>). These analyses indicate that vocalization durations, amplitudes, and inter-vocalization intervals are distributed in a largely independent and serially uncorrelated fashion.</p>
<fig id="pcbi.1005996.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005996.g003</object-id>
<label>Fig 3</label>
<caption>
<title/>
<p><bold>Vocalization parameters and serial statistics for a crying infant (a-e) and rat pup call (f-j).</bold> (a and f) Joint distribution of vocalization duration and amplitude is tightly distributed. The duration and amplitude marginal distributions are shown to the left and above the joint distribution. Inter-vocalization interval distributions (b and g) exhibit long exponential-like tails and a refractory region at short intervals. Serial statistics of the vocalization parameters exhibit weak temporal autocorrelation (c-e for a crying infant and h-j for rat pup call). Duration (c and h) and amplitude (d and i) parameters are largely serially uncorrelated. (e and j) Normalized autocorrelation for a point process consisting of onset times for each vocalization exhibits an impulsive autocorrelation.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005996.g003" xlink:type="simple"/>
</fig>
<table-wrap id="pcbi.1005996.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005996.t003</object-id>
<label>Table 3</label> <caption><title>Joint correlation statistics between the measured model parameters.</title></caption>
<alternatives>
<graphic id="pcbi.1005996.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005996.t003" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center"><italic> </italic></th>
<th align="center"> <italic>r</italic><sub><italic>AD</italic></sub></th>
<th align="center"><italic>r</italic><sub><italic>AI</italic></sub> </th>
<th align="center"> <italic>r</italic><sub><italic>DI</italic></sub></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><bold><italic>Rat</italic></bold></td>
<td align="center">0.49±0.05*</td>
<td align="center">0.12±0.04*</td>
<td align="center">0.18±0.04*</td>
</tr>
<tr>
<td align="center"><bold><italic>Mouse</italic></bold></td>
<td align="center">0.21±0.06*</td>
<td align="center">-0.05±0.01*</td>
<td align="center">-0.05±0.04</td>
</tr>
<tr>
<td align="center"><bold><italic>Bird</italic></bold></td>
<td align="center">0.10±0.02*</td>
<td align="center">0.022±0.029</td>
<td align="center">0.39±0.08*</td>
</tr>
<tr>
<td align="center"><bold><italic>Monkey</italic></bold></td>
<td align="center">0.33±0.04*</td>
<td align="center">0.08±0.03</td>
<td align="center">0.1±0.05</td>
</tr>
<tr>
<td align="center"><bold><italic>Infant</italic></bold></td>
<td align="center">0.11±0.04*</td>
<td align="center">-0.20±0.03*</td>
<td align="center">-0.01±0.05</td>
</tr>
<tr>
<td align="center"><bold><italic>Speech</italic></bold></td>
<td align="center">0.37±0.03*</td>
<td align="center">0.11±0.04*</td>
<td align="center">0.08±0.03</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001"><p>Correlation statistics between the vocalization amplitudes (<italic>A</italic>), durations (<italic>D</italic>), and inter-vocalization intervals (<italic>I</italic>) are quantified using the Pearson correlation coefficient (mean±SEM). A significant correlation is noted by a * (bootstrap t-test, p&lt;0.01).</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec013">
<title>Amplitude modulation power spectrum of the stochastic model</title>
<p>To gain further insight on how each envelope parameter contributes to the scaling behavior in the AMPS, we derive the model AMPS in closed form by computing the power spectral density of the stochastic envelope model. Given that the estimated vocalization model parameters are weakly correlated (<xref ref-type="fig" rid="pcbi.1005996.g003">Fig 3</xref> and <xref ref-type="table" rid="pcbi.1005996.t003">Table 3</xref>), we assume independence of the model parameters to simplify the derivation. The model AMPS is (<bold>Materials and methods,</bold> Vocalization model AMPS derivation)
<disp-formula id="pcbi.1005996.e022">
<alternatives>
<graphic id="pcbi.1005996.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e022" xlink:type="simple"/>
<mml:math display="block" id="M22">
<mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mo>∙</mml:mo><mml:mi>E</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo><mml:mo>∙</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mo>∙</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo><mml:mo>∙</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
where <italic>E</italic>[∙] is the expectation operator, <inline-formula id="pcbi.1005996.e023"><alternatives><graphic id="pcbi.1005996.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005996.e024"><alternatives><graphic id="pcbi.1005996.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> are the amplitude mean-squared and variance, and <inline-formula id="pcbi.1005996.e025"><alternatives><graphic id="pcbi.1005996.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mi>E</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is the second-order moment of <italic>A</italic><sub><italic>n</italic></sub>. This result demonstrates that although the rate of vocalizations (<italic>λ</italic>) and amplitude statistics (<inline-formula id="pcbi.1005996.e026"><alternatives><graphic id="pcbi.1005996.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) both affect the overall AMPS by a multiplicative gain factor, they do not depend on <italic>f</italic> and therefore do not affect the AMPS shape. Instead, the AMPS shape is primarily determined by the distribution of vocalization durations (term containing <italic>E</italic>[∙]). Since, as shown above, the exact duration distribution used has minimal impact on the AMPS shape (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2D and 2H</xref>) we use a uniform distribution to simplify the analytic derivation. The AMPS is then evaluated in closed form as (<bold>Materials and methods</bold>, Vocalization model AMPS derivation)
<disp-formula id="pcbi.1005996.e027">
<alternatives>
<graphic id="pcbi.1005996.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e027" xlink:type="simple"/>
<mml:math display="block" id="M27">
<mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>λ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<fig id="pcbi.1005996.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005996.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Comparison of AMPS from different species with the simulated model and the analytical solutions.</title>
<p>AMPS (black) are shown for a mouse pup (a), rat pup (b), crying infant (c), speech (d), new world monkey (e), and bird (f) vocalizations. The simulated pulse vocalization model (red curves) has lowpass structure and 1/<italic>f</italic><sup>2</sup> trend at high frequencies that mirrors the scaling observed in the actual AMPS. The analytical solution likewise exhibits a lowpass structure with 1/<italic>f</italic><sup>2</sup> trend at high frequencies (<xref ref-type="disp-formula" rid="pcbi.1005996.e027">Eq 3</xref>; dotted blue). (g) The residual error between the actual vocalization AMPS and simulated model AMPS lack the 1/<italic>f</italic><sup>2</sup> trend for different species.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005996.g004" xlink:type="simple"/>
</fig>
<p>Despite the simplifying assumptions, the analytic solution captures the general AMPS structure including the 1/<italic>f</italic><sup>2</sup> trend and the flat low frequency region for a human infant and rat pup vocalizations (<xref ref-type="fig" rid="pcbi.1005996.g004">Fig 4</xref>; actual AMPS, black; simulated AMPS, red; analytic solution AMPS, dotted blue).</p>
<p>Next, we evaluated the limiting AMPS behavior for these two regimes. For low frequencies (<italic>f</italic> → 0), it can be shown by applying L'Hospital's rule that:
<disp-formula id="pcbi.1005996.e028">
<alternatives>
<graphic id="pcbi.1005996.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e028" xlink:type="simple"/>
<mml:math display="block" id="M28">
<mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>λ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
which is the limiting value in the flat low frequency AMPS region observed in <xref ref-type="fig" rid="pcbi.1005996.g004">Fig 4</xref>. By comparison, in the limiting case where the modulation frequency is large (i.e., <italic>f</italic> → ∞):
<disp-formula id="pcbi.1005996.e029">
<alternatives>
<graphic id="pcbi.1005996.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e029" xlink:type="simple"/>
<mml:math display="block" id="M29">
<mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>λ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula>
so that the AMPS behaves as a power-law for high <italic>f</italic> with a power-law exponent of <italic>α</italic> = 2. We find this dual regime lowpass structure is evident in all of the vocalization sequences examined (<xref ref-type="fig" rid="pcbi.1005996.g004">Fig 4</xref>). Although the model can deviate from the data as a result of vocalization production mechanisms not related to the temporal edges created by the initiation of isolated vocalizations (e.g., vocal fold vibration), in all cases the model captures the general lowpass structure. Furthermore, the model captures nearly all of the variability associated with the 1/<italic>f</italic><sup>2</sup> trend since the residual error spectrum lacks 1/<italic>f</italic><sup>2</sup> structure (<xref ref-type="fig" rid="pcbi.1005996.g004">Fig 4G</xref>) and all of the measured vocalizations sequence AMPS deviated from the simulated model by at most 3.9 dB (RMS error between model and data for frequencies between 1–100 Hz). This suggests that temporal edges are the main acoustic features accounting for the general scaling behavior.</p>
<p>Next, we explore the mechanism by which temporal edges in isolated vocalizations contribute to power-law scaling and the dual-regime structure. We start by noting that the vocalization sequence AMPS is precisely the average AMPS of individual vocalization envelopes if the vocalization onset times are serially uncorrelated. Considering the rectangular pulse vocalization sequence model (<xref ref-type="disp-formula" rid="pcbi.1005996.e005">Eq 1</xref>), the AMPS of each rectangular pulse (<italic>p</italic><sub><italic>n</italic></sub>(<italic>t</italic>)) is:
<disp-formula id="pcbi.1005996.e030">
<alternatives>
<graphic id="pcbi.1005996.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e030" xlink:type="simple"/>
<mml:math display="block" id="M30">
<mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula>
Thus, although isolated vocalizations contain both temporal onsets and offsets, which contribute to the 1/<italic>f</italic><sup>2</sup> behavior, on their own individual isolated vocalizations deviate from the 1/<italic>f</italic><sup>2</sup> trend. Based on <xref ref-type="disp-formula" rid="pcbi.1005996.e030">Eq 6</xref> the individual vocalization envelope power spectrum is approximated as a sinc<sup>2</sup>(∙) function with a spectrum amplitude proportional to the pulse amplitude squared and bandwidth that is inversely related to the pulse duration. This is evident from the power spectra (<xref ref-type="fig" rid="pcbi.1005996.g005">Fig 5B</xref>) of three exemplar rectangular pulses (<xref ref-type="fig" rid="pcbi.1005996.g005">Fig 5A</xref>) taken from the speech ensemble. The spectrum of a single pulse has a lowpass structure with oscillatory side-lobes that deviate from the 1/<italic>f</italic><sup>2</sup> trend (<xref ref-type="fig" rid="pcbi.1005996.g005">Fig 5B</xref>, black curves) although the peak amplitude of the side-lobes precisely follows the 1/<italic>f</italic><sup>2</sup> trend (blue curves).</p>
<fig id="pcbi.1005996.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005996.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Ensemble averaging of vocalization pulse spectra predicts the observed vocalization AMPS.</title>
<p>(a) Three example pulses from the speech ensemble. (b) The AMPS for each pulse consists of a sinc<sup>2</sup> function with side lobe peaks and notch locations that depend on the vocalization duration and the side-lobe amplitudes that drop off proportional to 1/<italic>f</italic><sup>2</sup> (blue dotted lines). (c) The AMPS is obtained as the ensemble average across all durations, which produces an AMPS with lowpass structure and 1/<italic>f</italic><sup>2</sup> trend at high frequencies.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005996.g005" xlink:type="simple"/>
</fig>
<p>We propose that the observed dual-regime 1/<italic>f</italic><sup>2</sup> structure arises from the collective averaging across an ensemble of isolated vocalizations in a sequence. As can be seen in <xref ref-type="fig" rid="pcbi.1005996.g003">Fig 3</xref>, isolated vocalizations have variable durations which consequently produce different notch and side-lobe configurations in the frequency domain (<xref ref-type="fig" rid="pcbi.1005996.g005">Fig 5B</xref>). Upon averaging the spectrum of each vocalization, notches and side-lobes interfere and cancel producing the 1/<italic>f</italic><sup>2</sup> regime. In contrast, the sinc<sup>2</sup>(∙) main lobes average constructively producing the flat AMPS regime at low frequencies. Thus, the dual-regime vocalization sequence AMPS behavior including the 1/<italic>f</italic><sup>2</sup> trend emerge naturally from the collective averaging across an ensemble of isolated vocalizations of variable durations.</p>
</sec>
<sec id="sec014">
<title>Tradeoff between vocalization duration and cutoff</title>
<p>As demonstrated in the simulations of Figs <xref ref-type="fig" rid="pcbi.1005996.g002">2</xref> and <xref ref-type="fig" rid="pcbi.1005996.g005">5</xref> and the closed form model derivations, the dual-regime lowpass structure of the vocalizations sequence AMPS likely arises through the superposition of spectra from isolated vocalizations each with a bandwidth that is inversely related to the vocalization duration. To determine the relationship between vocalization duration distribution and the transition point for the 1/<italic>f</italic><sup>2</sup> regime in the vocalization sequence AMPS, we derive the solution for the half power or cutoff frequency (<italic>f</italic><sub><italic>c</italic></sub>) of the model AMPS (<bold>Materials and methods</bold>, Vocalization model cutoff frequency derivation). The analytic solution yields:
<disp-formula id="pcbi.1005996.e031">
<alternatives>
<graphic id="pcbi.1005996.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e031" xlink:type="simple"/>
<mml:math display="block" id="M31">
<mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mi>E</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:msqrt></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula>
where <italic>μ</italic><sub><italic>D</italic></sub> and <inline-formula id="pcbi.1005996.e032"><alternatives><graphic id="pcbi.1005996.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> are the duration mean and variance. This result indicates that the vocalization duration statistics are the primary determinants of the <italic>f</italic><sub><italic>c</italic></sub>. Specifically, <italic>f</italic><sub><italic>c</italic></sub> is inversely related to the square root of the second order moment of the vocalization duration distribution. That is, vocalizations with a longer average duration will tend to have a lower <italic>f</italic><sub><italic>c</italic></sub> values while vocalizations with shorter durations will tend to have larger <italic>f</italic><sub><italic>c</italic></sub> values. This result is consistent with the results of (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2A, 2B, 2E and 2F</xref>; blue curves) where we synthetically manipulated and set the vocalization model durations to zero. In such a case, vocalization pulses approach an impulse while the <italic>f</italic><sub><italic>c</italic></sub> approaches infinity and only the flat region of the AMPS is observed. This mathematical formulation is a statistical variant of the uncertainty principle for a vocalization ensemble, which requires that the signal duration in the time-domain be inversely related to its bandwidth in the frequency-domain [<xref ref-type="bibr" rid="pcbi.1005996.ref013">13</xref>].</p>
<p>Finally, we examine whether the measured durations from natural vocalization sequences can be used to predict <italic>f</italic><sub><italic>c</italic></sub> and therefore the transition point between the lowpass and 1/<italic>f</italic><sup>2</sup> regimes. As seen in <xref ref-type="fig" rid="pcbi.1005996.g006">Fig 6</xref>, the <italic>f</italic><sub><italic>c</italic></sub> estimated with our analytic model is correlated with the empirically measured <italic>f</italic><sub><italic>c</italic></sub> for the animal vocalization recordings examined (<xref ref-type="fig" rid="pcbi.1005996.g006">Fig 6A</xref>; log(<italic>f</italic><sub><italic>c</italic></sub>) vs. log(<italic>f</italic><sub><italic>c</italic>,<italic>model</italic></sub>), Pearson r = 0.76±0.24, mean±SEM; bootstrap t-test, p&lt;0.05). Furthermore, measured <italic>f</italic><sub><italic>c</italic></sub> for the six recordings are inversely related to the experimentally measured second-order duration moment (<xref ref-type="fig" rid="pcbi.1005996.g006">Fig 6B</xref>; log(<italic>f</italic><sub><italic>c</italic></sub>) vs. <inline-formula id="pcbi.1005996.e033"><alternatives><graphic id="pcbi.1005996.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005996.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>E</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, Pearson r = -0.76±0.24, mean±SEM; bootstrap t-test, p&lt;0.05) as predicted by <xref ref-type="disp-formula" rid="pcbi.1005996.e031">Eq 7</xref> (<xref ref-type="fig" rid="pcbi.1005996.g005">Fig 5</xref>, dotted line). This supports the idea that there is an inverse relationship between the vocalization durations and <italic>f</italic><sub><italic>c</italic></sub> that manifests as a tradeoff in time-frequency resolution.</p>
<fig id="pcbi.1005996.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005996.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Time-frequency resolution tradeoff is predicted by the model.</title>
<p>(a) The predicted cutoff frequencies from the vocalization duration statistics (<xref ref-type="disp-formula" rid="pcbi.1005996.e031">Eq 7</xref>) for different vocalization recordings closely match the actual measurements. (b) Empirically measured <italic>f</italic><sub><italic>c</italic></sub> and duration second moment follow an inverse relationship as predicted by the model (<xref ref-type="disp-formula" rid="pcbi.1005996.e031">Eq 7</xref>; dashed dot line).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005996.g006" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec015" sec-type="conclusions">
<title>Discussion</title>
<p>The results describe for the first time a single physical cue that universally accounts for scale invariant phenomenon in the envelope of natural vocalization sequences from several animal recordings. We find that the ensemble of temporal boundaries or edges for isolated vocalizations is the principal determinant of power-law scaling relationship. In addition, we find a systematic inverse relationship between the average vocalization duration and frequency at which scaling behavior initiates (<italic>f</italic><sub><italic>c</italic></sub>). Edges are responsible for the observed 1/<italic>f</italic><sup>2</sup> scaling region of the AMPS whereas the timing between consecutive on and off edges, which determine the vocalization duration, are critical in determining the flat region of the AMPS and the cutoff frequency (<italic>f</italic><sub><italic>c</italic></sub>). These findings thus provide a new conceptual framework for characterizing the temporal statistics of natural vocalized sounds in terms of definable temporal cues within ongoing sound sequences. For example, one can conceptualize vocalization elements such as words and phonemes in speech as acoustic objects formed by temporal edges in the sound envelope and our study indicates that these are primary determinants of the temporal statistics captured in the AMPS of vocalization sequences. Moreover, temporal edges are perceptually salient [<xref ref-type="bibr" rid="pcbi.1005996.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1005996.ref024">24</xref>] and serve as temporal boundaries for grouping acoustic objects [<xref ref-type="bibr" rid="pcbi.1005996.ref025">25</xref>].</p>
<p>Although we have not extended our analysis to broader categories of sounds, other natural sounds [<xref ref-type="bibr" rid="pcbi.1005996.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1005996.ref012">12</xref>] also exhibit scaling. The models and conceptual framework introduced here may have broad applicability as sound sequences and music in general are composed of transient and time-varying acoustic elements that can be coarsely modeled by onsets and offsets.</p>
<p>In vision, the spatial arrangement of object boundaries and the distribution of object size in opaque natural images all contribute to scale invariance [<xref ref-type="bibr" rid="pcbi.1005996.ref004">4</xref>–<xref ref-type="bibr" rid="pcbi.1005996.ref006">6</xref>]. In an analogous fashion, we have shown that vocalization boundaries consisting of edges in the time-domain likewise contribute to scaling in the acoustic realm. Importantly, isolated vocalizations are not sufficient since the 1/<italic>f</italic><sup>2</sup> trend arises from the collective averaging amongst an ensemble of vocalization with variable durations (<xref ref-type="fig" rid="pcbi.1005996.g005">Fig 5</xref>). Yet, unlike for natural scenes where the object size distribution needs to follow a power-law relationship, scaling for natural sounds does not depend critically on the exact vocalization duration distribution as long as the distributions have similar means (<xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2</xref> and closed form solutions). Furthermore, we point out that vocalization sequence onset times and amplitudes statistics are not critical to this result as determined from the closed form solutions of the model and demonstrated in <xref ref-type="fig" rid="pcbi.1005996.g002">Fig 2</xref>, where the model parameters where perturbed to constant values (periodic case for onset times and constant amplitude). Thus, the combined findings from the model and empirical perturbations provide strong evidence that the temporal edge boundaries in vocalizations are responsible for 1/<italic>f</italic><sup>2</sup> phenomenon.</p>
<p>In our analysis, we considered isolated vocalization sequences which have well-identified vocalizations and well-defined temporal boundaries. Whether similar results apply to more complex acoustic scenarios including natural soundscapes consisting of mixtures of vocalizations that are superimposed is unclear and needs to be determined. This is plausible given that images containing mixtures of translucent objects can also exhibit scale invariance [<xref ref-type="bibr" rid="pcbi.1005996.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1005996.ref005">5</xref>]. Previous works have demonstrated that although scaling is observed in natural environmental sounds, such sounds tend to have a scaling exponent that is somewhat lower than for vocalizations (scaling exponent closer to <italic>α</italic> = 1) [<xref ref-type="bibr" rid="pcbi.1005996.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1005996.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1005996.ref026">26</xref>]. One plausible hypothesis that needs to be considered is that background sounds often consist of mixtures of isolated sound, each of which has a well-marked onsets and offsets, so that the superposition of isolated acoustic objects could create phase distortions at the sound boundaries that distort temporal edges and ultimately have a whitening effect on the envelope AMPS, thus reducing the scaling exponent. Future studies need to explore how and if our findings can be generalized into a theoretical framework that applies to an even broader range of natural and man-made sounds.</p>
<p>Although the results provide a concise explanation for the 1/<italic>f</italic><sup>2</sup> scaling region that is linked to the temporal boundaries in vocalized sounds our model is not intended to account for other forms of scaling or features of the AMPS. Future studies and models are needed to further elucidate the acoustic generation mechanisms responsible for distinct regions of the AMPS of natural vocalized sounds. For instance, 1/<italic>f</italic> scaling has been previously described for very low modulation frequency (&lt;0.1 Hz) for speech and music [<xref ref-type="bibr" rid="pcbi.1005996.ref008">8</xref>]. One plausible explanation for this phenomenon is that inter-vocalization statistics in sound sequences, such as for speech, have self-similar fractal structure at very long time scales [<xref ref-type="bibr" rid="pcbi.1005996.ref027">27</xref>] that may be responsible for 1/<italic>f</italic> scaling for very low modulation frequencies. Our model also is not intended to account for other features of the modulation spectrum, for instance the presence of periodic modulations created through vocal vibration and which are clearly evident in our speech envelopes and AMPS (<xref ref-type="fig" rid="pcbi.1005996.g001">Fig 1</xref>). These fast-periodic modulations are visible in the speech and infant vocalizations and show up as an additive modulation component in the AMPS (positive AMPS deflection above the expected model results). A recent study observed the presence of peaks in the modulation spectrum of speech and music in the vicinity of 3–5 Hz [<xref ref-type="bibr" rid="pcbi.1005996.ref028">28</xref>] and lacked 1/<italic>f</italic><sup>2</sup> structure described here. This difference is due to the fact that the calculation of the modulation spectrum in that study used modulation filters with logarithmic bandwidths that mimic neural modulation tuning functions [<xref ref-type="bibr" rid="pcbi.1005996.ref012">12</xref>] to estimate the modulation power. Applying such modulation filters magnifies the output power by a factor proportional to <italic>f</italic>, so that the flat region of the AMPS we describe increases proportional to <italic>f</italic> and the region containing the 1/<italic>f</italic><sup>2</sup> trend decreases proportional to 1/<italic>f</italic>. Consequently, a peak is observed in the modulation spectrum within the vicinity of the cutoff frequency (<italic>f</italic><sub><italic>c</italic></sub>) where the transition between the flat and 1/<italic>f</italic><sup>2</sup> behavior is observed in our model. We have confirmed the observations of Ding et al. by estimating modulation spectrum with octave band filters or alternately multiplying the modulation spectrum by <italic>f</italic> as described (<xref ref-type="supplementary-material" rid="pcbi.1005996.s001">S1 Fig</xref>). In both cases, the resulting modulation spectrum contain a primary peak in the vicinity of ~3 Hz as observed by Ding et al., but we also observe a secondary peak within the vicinity of 100–300 Hz where vocal fold vibration is prominent. Ding et al did not observed such a peak because they characterized the modulation power spectrum only up to 32 Hz.</p>
<p>The results have a number of implications for theories of coding by the brain since auditory neurons are exquisitely sensitive to temporal transitions with millisecond precision [<xref ref-type="bibr" rid="pcbi.1005996.ref029">29</xref>–<xref ref-type="bibr" rid="pcbi.1005996.ref031">31</xref>] and have been shown to produce an efficient neural representation that equalize the modulation power of natural sounds [<xref ref-type="bibr" rid="pcbi.1005996.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005996.ref014">14</xref>]. Similar strategies have been proposed in vision where neurons through edge detection equalize or “whiten” the spectrum of natural images enabling an equitable use of neural resources [<xref ref-type="bibr" rid="pcbi.1005996.ref003">3</xref>]. Mechanistically, two distinct temporal coding mechanisms could contribute to such efficient representation in audition. First, auditory neurons have excitatory-inhibitory (on-off) responses to temporal edges that effectively perform a smooth temporal derivative operation on the sound envelope [<xref ref-type="bibr" rid="pcbi.1005996.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1005996.ref035">35</xref>]. In the time domain, this could facilitate temporal edge detection for important information bearing acoustic temporal elements, analogous to edge detection in vision [<xref ref-type="bibr" rid="pcbi.1005996.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1005996.ref007">7</xref>]. In the frequency domain, such temporal derivative operation has a transfer function squared-magnitude <italic>H</italic><sup>2</sup>(<italic>f</italic>) = 4<italic>π</italic><sup>2</sup><italic>f</italic><sup>2</sup> that opposes and precisely cancels the 1/<italic>f</italic><sup>2</sup> scaling of natural sounds thus whitening the spectrum. Secondly, power equalization could be partly achieved through modulation filter bandwidth scaling as previously observed for auditory midbrain neurons [<xref ref-type="bibr" rid="pcbi.1005996.ref012">12</xref>] and perceptually [<xref ref-type="bibr" rid="pcbi.1005996.ref036">36</xref>]. For both neurons and perception, modulation filter bandwidths increase proportional to <italic>f</italic>. This bandwidth scaling magnifies the output power by <italic>f</italic>, partly canceling the 1/<italic>f</italic><sup>2</sup> power trend observed for natural sounds [<xref ref-type="bibr" rid="pcbi.1005996.ref012">12</xref>] (as shown in <xref ref-type="supplementary-material" rid="pcbi.1005996.s001">S1 Fig</xref>). In combination, temporal edge detection and bandwidth scaling could provide mechanisms to equalize modulation power in vocalizations allowing for efficient information transfer and coding, analogous to principles in vision.</p>
<p>The findings are also relevant for sound coding and hearing technologies. For instance, the stochastic framework could be used to improve coding, compression, and sound recognition algorithms. The findings could further be used to improve algorithms to enhance detection of transient sound elements [<xref ref-type="bibr" rid="pcbi.1005996.ref037">37</xref>] in order to facilitate recognition in hearing aid, cochlear implant, and other assistive hearing technologies.</p>
</sec>
<sec id="sec016">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005996.s001" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005996.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Speech AMPS obtained using a proportional resolution modulation filter bank that mirrors neural modulation filters in the auditory midbrain (Rodriguez et al 2010).</title>
<p>The AMPS of speech derived with constant quality factor modulation filters (Q = 1, black curve) exhibits a primary peak within the rhythm perceptual range at ~3 Hz. A secondary peak is observed at ~150 Hz which corresponds to the temporal modulations created through vocal fold vibration. The green curve corresponds to the speech AMPS after multiplying by the modulation frequency (<italic>f)</italic>.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank James Green and Gwen Gustafson for providing baby vocalization recordings.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005996.ref001"><label>1</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Barlow</surname> <given-names>H</given-names></name>. <chapter-title>Possible principles underlying the transformation of sensory messages</chapter-title>. <source>Sensory Communication</source>: <publisher-name>MIT Press</publisher-name>; <year>1961</year>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ruderman</surname> <given-names>DL</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>Statistics of natural images: Scaling in the woods</article-title>. <source>Physical Review Letters</source>. <year>1994</year>;<volume>73</volume>(<issue>6</issue>):<fpage>814</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevLett.73.814" xlink:type="simple">10.1103/PhysRevLett.73.814</ext-link></comment> <object-id pub-id-type="pmid">10057546</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Field</surname> <given-names>DJ</given-names></name>. <article-title>Relations between the statistics of natural images and the response properties of cortical cells</article-title>. <source>J Opt Soc Am A</source>. <year>1987</year>;<volume>4</volume>(<issue>12</issue>):<fpage>2379</fpage>–<lpage>94</lpage>. Epub 1987/12/01. <object-id pub-id-type="pmid">3430225</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zylberberg</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Pfau</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Deweese</surname> <given-names>MR</given-names></name>. <article-title>Dead leaves and the dirty ground: low-level image statistics in transmissive and occlusive imaging environments</article-title>. <source>Phys Rev E Stat Nonlin Soft Matter Phys</source>. <year>2012</year>;<volume>86</volume>(<issue>6</issue> Pt 2):<fpage>066112</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevE.86.066112" xlink:type="simple">10.1103/PhysRevE.86.066112</ext-link></comment> <object-id pub-id-type="pmid">23368009</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hsiao</surname> <given-names>WH</given-names></name>, <name name-style="western"><surname>Millane</surname> <given-names>RP</given-names></name>. <article-title>Effects of occlusion, edges, and scaling on the power spectra of natural images</article-title>. <source>J Opt Soc Am A Opt Image Sci Vis</source>. <year>2005</year>;<volume>22</volume>(<issue>9</issue>):<fpage>1789</fpage>–<lpage>97</lpage>. <object-id pub-id-type="pmid">16211805</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ruderman</surname> <given-names>DL</given-names></name>. <article-title>Origins of scaling in natural images</article-title>. <source>Vision Res</source>. <year>1997</year>;<volume>37</volume>(<issue>23</issue>):<fpage>3385</fpage>–<lpage>98</lpage>. <object-id pub-id-type="pmid">9425551</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hubel</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Wiesel</surname> <given-names>TN</given-names></name>. <article-title>Receptive fields of single neurones in the cat's striate cortex</article-title>. <source>J Physiol</source>. <year>1959</year>;<volume>148</volume>:<fpage>574</fpage>–<lpage>91</lpage>. <object-id pub-id-type="pmid">14403679</object-id>; PubMed Central PMCID: PMCPMC1363130.</mixed-citation></ref>
<ref id="pcbi.1005996.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Voss</surname> <given-names>RF</given-names></name>, <name name-style="western"><surname>Clarke</surname> <given-names>J</given-names></name>. <article-title>'1/f noise' in music and speech</article-title>. <source>Nature</source>. <year>1975</year>;<volume>258</volume>(<issue>5533</issue>):<fpage>317</fpage>–<lpage>18</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Geffen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Gervain</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Werker</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Magnasco</surname> <given-names>MO</given-names></name>. <article-title>Auditory perception of self-similarity in water sounds</article-title>. <source>Front Integr Neurosci</source>. <year>2011</year>;<volume>5</volume>:<fpage>15</fpage>. Epub 2011/05/28. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnint.2011.00015" xlink:type="simple">10.3389/fnint.2011.00015</ext-link></comment> <object-id pub-id-type="pmid">21617734</object-id>; PubMed Central PMCID: PMC3095814.</mixed-citation></ref>
<ref id="pcbi.1005996.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Attias</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>C</given-names></name>. <article-title>Low-order temporal statistics of natural sounds</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>1997</year>;<volume>9</volume>:<fpage>27</fpage>–<lpage>33</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Singh</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>. <article-title>Modulation spectra of natural sounds and ethological theories of auditory processing</article-title>. <source>J Acoust Soc Am</source>. <year>2003</year>;<volume>114</volume>(<issue>6</issue> Pt 1):<fpage>3394</fpage>–<lpage>411</lpage>. <object-id pub-id-type="pmid">14714819</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rodriguez</surname> <given-names>FA</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Read</surname> <given-names>HL</given-names></name>, <name name-style="western"><surname>Escabi</surname> <given-names>MA</given-names></name>. <article-title>Neural modulation tuning characteristics scale to efficiently encode natural sound statistics</article-title>. <source>J Neurosci</source>. <year>2010</year>;<volume>30</volume>(<issue>47</issue>):<fpage>15969</fpage>–<lpage>80</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0966-10.2010" xlink:type="simple">10.1523/JNEUROSCI.0966-10.2010</ext-link></comment> <object-id pub-id-type="pmid">21106835</object-id>; PubMed Central PMCID: PMC3351116.</mixed-citation></ref>
<ref id="pcbi.1005996.ref013"><label>13</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>L</given-names></name>. <chapter-title>Time-Frequency Analysis</chapter-title>. <publisher-loc>Englewood Cliffs, NJ</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>; <year>1995</year>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lesica</surname> <given-names>NA</given-names></name>, <name name-style="western"><surname>Grothe</surname> <given-names>B</given-names></name>. <article-title>Efficient temporal processing of naturalistic sounds</article-title>. <source>PLoS ONE</source>. <year>2008</year>;<volume>3</volume>(<issue>2</issue>):<fpage>e1655</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0001655" xlink:type="simple">10.1371/journal.pone.0001655</ext-link></comment> <object-id pub-id-type="pmid">18301738</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wohr</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schwarting</surname> <given-names>RK</given-names></name>. <article-title>Maternal care, isolation-induced infant ultrasonic calling, and their relations to adult anxiety-related behavior in the rat</article-title>. <source>Behav Neurosci</source>. <year>2008</year>;<volume>122</volume>(<issue>2</issue>):<fpage>310</fpage>–<lpage>30</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0735-7044.122.2.310" xlink:type="simple">10.1037/0735-7044.122.2.310</ext-link></comment> <object-id pub-id-type="pmid">18410171</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wohr</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dahlhoff</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Wolf</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Holsboer</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Schwarting</surname> <given-names>RK</given-names></name>, <name name-style="western"><surname>Wotjak</surname> <given-names>CT</given-names></name>. <article-title>Effects of genetic background, gender, and early environmental factors on isolation-induced ultrasonic calling in mouse pups: an embryo-transfer study</article-title>. <source>Behav Genet</source>. <year>2008</year>;<volume>38</volume>(<issue>6</issue>):<fpage>579</fpage>–<lpage>95</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10519-008-9221-4" xlink:type="simple">10.1007/s10519-008-9221-4</ext-link></comment> <object-id pub-id-type="pmid">18712592</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Green</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Gustafson</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>McGhie</surname> <given-names>AC</given-names></name>. <article-title>Changes in infants' cries as a function of time in a cry bout</article-title>. <source>Child Dev</source>. <year>1998</year>;<volume>69</volume>(<issue>2</issue>):<fpage>271</fpage>–<lpage>9</lpage>. <object-id pub-id-type="pmid">9586204</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref018"><label>18</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Shakespeare</surname> <given-names>W</given-names></name>. <chapter-title>BBC Radio Presents: Hamlet</chapter-title>. In: <name name-style="western"><surname>Branagh</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dearman</surname> <given-names>G</given-names></name>, editors. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Bantam Doubleday Dell Audio Publishing</publisher-name>; <year>1992</year>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref019"><label>19</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Bradbury</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Budney</surname> <given-names>GF</given-names></name>. <chapter-title>The Diversity of Animal Sounds</chapter-title>. <publisher-loc>Ithaca, NY</publisher-loc>: <publisher-name>Macaulay Library of Natural Sounds, Cornell Laboratory of Ornithology</publisher-name>; <year>2001</year>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref020"><label>20</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Emmons</surname> <given-names>LH</given-names></name>, <name name-style="western"><surname>Whitney</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Ross</surname> <given-names>DL</given-names></name>. <chapter-title>Sounds of Neotropical Rainforest Mammals: An Audio Field Guide</chapter-title>. <publisher-loc>Ithaca, NY</publisher-loc>: <publisher-name>Macaulay Library of Natural Sounds, Cornell Laboratory of Ornithology</publisher-name>; <year>1997</year>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Greenberg</surname> <given-names>S</given-names></name>. <article-title>Speaking in shorthand–A syllable-centric perspective for understanding pronunciation variation</article-title>. <source>Speech Communication</source>. <year>1999</year>;<volume>29</volume>(<issue>2</issue>):<fpage>159</fpage>–<lpage>76</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>KD</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Acoustic variability and distinguishability among mouse ultrasound vocalizations</article-title>. <source>J Acoust Soc Am</source>. <year>2003</year>;<volume>114</volume>(<issue>6</issue> Pt 1):3412–22. <object-id pub-id-type="pmid">14714820</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elliott</surname> <given-names>TM</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>. <article-title>The modulation transfer function for speech intelligibility</article-title>. <source>PLoS Comput Biol</source>. <year>2009</year>;<volume>5</volume>(<issue>3</issue>):<fpage>e1000302</fpage>. Epub 2009/03/07. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1000302" xlink:type="simple">10.1371/journal.pcbi.1000302</ext-link></comment> <object-id pub-id-type="pmid">19266016</object-id>; PubMed Central PMCID: PMC2639724.</mixed-citation></ref>
<ref id="pcbi.1005996.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Irino</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Patterson</surname> <given-names>RD</given-names></name>. <article-title>Temporal asymmetry in the auditory system</article-title>. <source>J Acoust Soc Am</source>. <year>1996</year>;<volume>99</volume>(<issue>4</issue> Pt 1):<fpage>2316</fpage>–<lpage>31</lpage>. <object-id pub-id-type="pmid">8730078</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref025"><label>25</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Bregman</surname> <given-names>AS</given-names></name>. <chapter-title>Auditory scene analysis: the perceptual organization of sound</chapter-title>. <publisher-loc>Cambridge, Mass</publisher-loc>.: <publisher-name>MIT Press</publisher-name>; <year>1990</year>. <volume>xiii</volume>, 773 p.</mixed-citation></ref>
<ref id="pcbi.1005996.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rodriguez</surname> <given-names>FA</given-names></name>, <name name-style="western"><surname>Read</surname> <given-names>HL</given-names></name>, <name name-style="western"><surname>Escabi</surname> <given-names>MA</given-names></name>. <article-title>Spectral and temporal modulation tradeoff in the inferior colliculus</article-title>. <source>J Neurophysiol</source>. <year>2010</year>;<volume>103</volume>(<issue>2</issue>):<fpage>887</fpage>–<lpage>903</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00813.2009" xlink:type="simple">10.1152/jn.00813.2009</ext-link></comment> <object-id pub-id-type="pmid">20018831</object-id>; PubMed Central PMCID: PMC2822687.</mixed-citation></ref>
<ref id="pcbi.1005996.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abney</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Kello</surname> <given-names>CT</given-names></name>, <name name-style="western"><surname>Warlaumont</surname> <given-names>AS</given-names></name>. <article-title>Production and Convergence of Multiscale Clustering in Speech</article-title>. <source>Ecological Psychology</source>. <year>2015</year>; <volume>27</volume>(<issue>3</issue>):<fpage>222</fpage>–<lpage>35</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ding</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Patel</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Butler</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Luo</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Poeppel</surname> <given-names>D</given-names></name>. <article-title>Temporal modulations in speech and music</article-title>. <source>Neurosci Biobehav Rev</source>. <year>2017</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neubiorev.2017.02.011" xlink:type="simple">10.1016/j.neubiorev.2017.02.011</ext-link></comment> <object-id pub-id-type="pmid">28212857</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heil</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Irvine</surname> <given-names>DR</given-names></name>. <article-title>First-spike timing of auditory-nerve fibers and comparison with auditory cortex</article-title>. <source>J Neurophysiol</source>. <year>1997</year>;<volume>78</volume>(<issue>5</issue>):<fpage>2438</fpage>–<lpage>54</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1997.78.5.2438" xlink:type="simple">10.1152/jn.1997.78.5.2438</ext-link></comment> <object-id pub-id-type="pmid">9356395</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zheng</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Escabi</surname> <given-names>MA</given-names></name>. <article-title>Distinct roles for onset and sustained activity in the neuronal code for temporal periodicity and acoustic envelope shape</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>(<issue>52</issue>):<fpage>14230</fpage>–<lpage>44</lpage>. Epub 2008/12/26. 28/52/14230 [pii] <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2882-08.2008" xlink:type="simple">10.1523/JNEUROSCI.2882-08.2008</ext-link></comment> <object-id pub-id-type="pmid">19109505</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Osman</surname> <given-names>AF</given-names></name>, <name name-style="western"><surname>Volgushev</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Escabi</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Read</surname> <given-names>HL</given-names></name>. <article-title>Neural spike-timing patterns vary with sound shape and periodicity in three auditory cortical fields</article-title>. <source>J Neurophysiol</source>. <year>2016</year>;<volume>115</volume>(<issue>4</issue>):<fpage>1886</fpage>–<lpage>904</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00784.2015" xlink:type="simple">10.1152/jn.00784.2015</ext-link></comment> <object-id pub-id-type="pmid">26843599</object-id>; PubMed Central PMCID: PMCPMC4869486.</mixed-citation></ref>
<ref id="pcbi.1005996.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Depireux</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Simon</surname> <given-names>JZ</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Spectro-temporal response field characterization with dynamic ripples in ferret primary auditory cortex</article-title>. <source>J Neurophysiol</source>. <year>2001</year>;<volume>85</volume>(<issue>3</issue>):<fpage>1220</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.2001.85.3.1220" xlink:type="simple">10.1152/jn.2001.85.3.1220</ext-link></comment> <object-id pub-id-type="pmid">11247991</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Escabi</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Read</surname> <given-names>HL</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Spectrotemporal receptive fields in the lemniscal auditory thalamus and cortex</article-title>. <source>J Neurophysiol</source>. <year>2002</year>;<volume>87</volume>(<issue>1</issue>):<fpage>516</fpage>–<lpage>27</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00395.2001" xlink:type="simple">10.1152/jn.00395.2001</ext-link></comment> <object-id pub-id-type="pmid">11784767</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>, <name name-style="western"><surname>Doupe</surname> <given-names>AJ</given-names></name>. <article-title>Feature analysis of natural sounds in the songbird auditory forebrain</article-title>. <source>J Neurophysiol</source>. <year>2001</year>;<volume>86</volume>(<issue>3</issue>):<fpage>1445</fpage>–<lpage>58</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.2001.86.3.1445" xlink:type="simple">10.1152/jn.2001.86.3.1445</ext-link></comment> <object-id pub-id-type="pmid">11535690</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Qiu</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Escabi</surname> <given-names>MA</given-names></name>. <article-title>Gabor analysis of auditory midbrain receptive fields: spectro-temporal and binaural composition</article-title>. <source>J Neurophysiol</source>. <year>2003</year>;<volume>90</volume>(<issue>1</issue>):<fpage>456</fpage>–<lpage>76</lpage>. Epub 2003/03/28. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00851.2002" xlink:type="simple">10.1152/jn.00851.2002</ext-link></comment> [pii]. <object-id pub-id-type="pmid">12660353</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ewert</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Dau</surname> <given-names>T</given-names></name>. <article-title>Characterizing frequency selectivity for envelope fluctuations</article-title>. <source>J Acoust Soc Am</source>. <year>2000</year>;<volume>108</volume>(<issue>3</issue> Pt 1):<fpage>1181</fpage>–<lpage>96</lpage>. Epub 2000/09/29. <object-id pub-id-type="pmid">11008819</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005996.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Jenkins</surname> <given-names>WM</given-names></name>, <name name-style="western"><surname>Johnston</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Tallal</surname> <given-names>P</given-names></name>. <article-title>Temporal processing deficits of language-learning impaired children ameliorated by training</article-title>. <source>Science</source>. <year>1996</year>;<volume>271</volume>(<issue>5245</issue>):<fpage>77</fpage>–<lpage>81</lpage>. <object-id pub-id-type="pmid">8539603</object-id>.</mixed-citation></ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article article-type="research-article" dtd-version="3.0" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004683</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-00927</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Animals</subject><subj-group><subject>Invertebrates</subject><subj-group><subject>Arthropoda</subject><subj-group><subject>Insects</subject><subj-group><subject>Hymenoptera</subject><subj-group><subject>Ants</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Nervous system</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Synapses</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Behavior</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Animal migration</subject><subj-group><subject>Animal navigation</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Zoology</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Animal migration</subject><subj-group><subject>Animal navigation</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Animals</subject><subj-group><subject>Invertebrates</subject><subj-group><subject>Arthropoda</subject><subj-group><subject>Insects</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Using an Insect Mushroom Body Circuit to Encode Route Memory in Complex Natural Environments</article-title>
<alt-title alt-title-type="running-head">A Mushroom Body Model of Ant Route Memory</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Ardin</surname>
<given-names>Paul</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Peng</surname>
<given-names>Fei</given-names>
</name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Mangan</surname>
<given-names>Michael</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Lagogiannis</surname>
<given-names>Konstantinos</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Webb</surname>
<given-names>Barbara</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>School of Informatics, University of Edinburgh, Edinburgh, United Kingdom</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Biological and Experimental Psychology, School of Biological and Chemical Sciences, Queen Mary University of London, London, United Kingdom</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Ayers</surname>
<given-names>Joseph</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Northeastern University, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: BW MM PA FP. Performed the experiments: PA FP MM. Analyzed the data: PA FP MM KL BW. Wrote the paper: BW PA FP MM KL.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">B.Webb@ed.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>11</day>
<month>2</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<month>2</month>
<year>2016</year>
</pub-date>
<volume>12</volume>
<issue>2</issue>
<elocation-id>e1004683</elocation-id>
<history>
<date date-type="received">
<day>9</day>
<month>6</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>30</day>
<month>11</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Ardin et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004683"/>
<abstract>
<p>Ants, like many other animals, use visual memory to follow extended routes through complex environments, but it is unknown how their small brains implement this capability. The mushroom body neuropils have been identified as a crucial memory circuit in the insect brain, but their function has mostly been explored for simple olfactory association tasks. We show that a spiking neural model of this circuit originally developed to describe fruitfly (<italic>Drosophila melanogaster)</italic> olfactory association, can also account for the ability of desert ants (<italic>Cataglyphis velox)</italic> to rapidly learn visual routes through complex natural environments. We further demonstrate that abstracting the key computational principles of this circuit, which include one-shot learning of sparse codes, enables the theoretical storage capacity of the ant mushroom body to be estimated at hundreds of independent images.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>We propose a model based directly on insect neuroanatomy that is able to account for the route following capabilities of ants. We show this mushroom body circuit has the potential to store a large number of images, generated in a realistic simulation of an ant traversing a route, and to distinguish previously stored images from highly similar images generated when looking in the wrong direction. It can thus control successful recapitulation of routes under ecologically valid test conditions.</p>
</abstract>
<funding-group>
<funding-statement>This research was support by Biotechnology and Biological Sciences Research Council UK (<ext-link ext-link-type="uri" xlink:href="http://www.bbsrc.ac.uk" xlink:type="simple">www.bbsrc.ac.uk</ext-link>) grant BB/I014543/1; Engineering and Physical Sciences Research Council UK (<ext-link ext-link-type="uri" xlink:href="http://www.epsrc.ac.uk" xlink:type="simple">www.epsrc.ac.uk</ext-link>) EP/F500385/1; European Commission Seventh Framework Programme (ec.europa.eu/research/fp7) 618045; China Scholarship Council (en.csc.edu.cn); Queen Mary University London. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="3"/>
<page-count count="22"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All matlab code used to produce our data are available from the Dryad database: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.pf66v" xlink:type="simple">http://dx.doi.org/10.5061/dryad.pf66v.</ext-link></meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The nature of the spatial memory that underlies navigational behaviour in insects remains a controversial issue, particularly as the neural mechanisms are largely unknown. Insects can perform path integration (PI), using a sky compass and odometer to accumulate velocity into a vector indicating the distance and direction of their start location, typically the nest or hive [<xref ref-type="bibr" rid="pcbi.1004683.ref001">1</xref>]. They are also known to be able to use landmark and/or panoramic visual memories of previously visited locations to guide their movements independently of PI [<xref ref-type="bibr" rid="pcbi.1004683.ref002">2</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref003">3</xref>]. Under normal conditions, both systems are functioning. This raises the possibility that insects additionally store PI vector information with their visual memories [<xref ref-type="bibr" rid="pcbi.1004683.ref004">4</xref>]; or link their visual memories in sequences [<xref ref-type="bibr" rid="pcbi.1004683.ref005">5</xref>] or with relative heading vectors [<xref ref-type="bibr" rid="pcbi.1004683.ref006">6</xref>], forming a topological map; or could even use the PI information to integrate their visual memories into a metric map that represents the spatial relationship of known locations [<xref ref-type="bibr" rid="pcbi.1004683.ref007">7</xref>].</p>
<p>However another possibility is that PI information is used to determine <italic>which</italic> visual memories to store, for example, the views experienced when facing the nest [<xref ref-type="bibr" rid="pcbi.1004683.ref008">8</xref>]. Subsequently, such memories can be used directly for guidance without further reference to vector information. Rotating to match the current visual experience with a stored view will give the required heading direction [<xref ref-type="bibr" rid="pcbi.1004683.ref009">9</xref>], e.g., towards the nest. Surprisingly, this navigation mechanism can exploit multiple memories without necessarily requiring recovery of the ‘correct’ memory for the current location. Baddeley et al [<xref ref-type="bibr" rid="pcbi.1004683.ref010">10</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref011">11</xref>] presented an algorithm by which an animal attempting to navigate home simultaneously compares the view experienced while it rotates to all memories ever stored while following a PI vector homewards. The direction in which the view looks ‘most familiar’, i.e., has the best match across all stored views, is generally the correct heading to take to retrace its previous path. In [<xref ref-type="bibr" rid="pcbi.1004683.ref011">11</xref>] this principle was implemented using the Infomax learning algorithm to train the weights in a two-layer network, where the input is successive images along simulated routes, and the summed activation of the output layer represents the novelty of each image. This implementation was able to replicate many features of ant route following in an agent simulation [<xref ref-type="bibr" rid="pcbi.1004683.ref011">11</xref>] and has also been shown (with some assumptions about the ant’s previous experience) to produce similar search strategies to ants in visual homing paradigms [<xref ref-type="bibr" rid="pcbi.1004683.ref012">12</xref>].</p>
<p>Strategies of this nature, where the animal does not need to know where it is to know where to go, have been invoked as a more parsimonious explanation for experimental results presented as evidence for a cognitive maps in insects [<xref ref-type="bibr" rid="pcbi.1004683.ref013">13</xref>]. But is this explanation of navigation plausible, given realistic environmental, perceptual and neural constraints? As pointed out in a recent review [<xref ref-type="bibr" rid="pcbi.1004683.ref014">14</xref>], parsimony based on what appears simple in computational terms may not map to simplicity with respect to the underlying neural architecture. Yet so far, “nothing is known about neural implementation of navigational space in insects” [<xref ref-type="bibr" rid="pcbi.1004683.ref014">14</xref>]. In particular, Baddeley et al [<xref ref-type="bibr" rid="pcbi.1004683.ref011">11</xref>] do not claim that the Infomax implementation of their familiarity algorithm represents the actual neural processing of the ant.</p>
<p>Visual processing in the ant brain has not been extensively studied, but anatomically resembles that of other insects in terms of the initial sensory layers at least. Ants have typical apposition compound eyes, but the size and resolution varies substantially across species. For the desert ants <italic>Cataglyphis</italic> [<xref ref-type="bibr" rid="pcbi.1004683.ref015">15</xref>] and <italic>Melaphorus bagoti</italic> [<xref ref-type="bibr" rid="pcbi.1004683.ref016">16</xref>] each eye subtends a large visual field (estimated at 150–170 degrees horizontal extent, with a small frontal overlap) with low visual resolution (interommatidia angles between 3 and 5 degrees). Visual signals pass through the three layers of the optic lobe (lamina, medulla and lobula) maintaining a retinotopic projection but with increasing integration across the visual field [<xref ref-type="bibr" rid="pcbi.1004683.ref017">17</xref>]. Visual signals then pass directly or indirectly to several other brain regions, including the protocerebrum, the central complex, and the calyxes of the mushroom bodies [<xref ref-type="bibr" rid="pcbi.1004683.ref017">17</xref>]. The mushroom body (MB) neuropils are conspicuous central brain structures, made up from a large number of Kenyon cells (KCs), whose dendrites together form the calyx and whose axons run in parallel through the penduculus and then bifurcate to form the vertical (or α) and medial (or β) lobes [<xref ref-type="bibr" rid="pcbi.1004683.ref018">18</xref>]. The extent of visual input to the MB is significantly greater in ants and other hymenoptera than for many other insects for which the MB input is predominantly olfactory [<xref ref-type="bibr" rid="pcbi.1004683.ref019">19</xref>]. In fact there is increasing evidence that the MB may play a role in visual learning and navigation in insects. There is evidence of expansion or reorganisation of MB at the onset of foraging in ants [<xref ref-type="bibr" rid="pcbi.1004683.ref020">20</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref021">21</xref>] and bees [<xref ref-type="bibr" rid="pcbi.1004683.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1004683.ref024">24</xref>]. Upregulation of a learning related gene in the MB of honeybees has been linked to orientation flights in novel environments [<xref ref-type="bibr" rid="pcbi.1004683.ref025">25</xref>]. Cockroaches show impairment on a visual homing task after MB silencing [<xref ref-type="bibr" rid="pcbi.1004683.ref026">26</xref>], although the central complex rather than the MB appears essential for this task in Drosophila [<xref ref-type="bibr" rid="pcbi.1004683.ref027">27</xref>]. The MB may nevertheless play a role in some visual learning paradigms in Drosophila [<xref ref-type="bibr" rid="pcbi.1004683.ref028">28</xref>][<xref ref-type="bibr" rid="pcbi.1004683.ref029">29</xref>].</p>
<p>To date, the MB have been much more extensively studied in the context of olfactory associative learning, for which they appear crucial [<xref ref-type="bibr" rid="pcbi.1004683.ref018">18</xref>]. We have previously implemented a spiking neuron model of adult Drosophila MB olfactory learning [<xref ref-type="bibr" rid="pcbi.1004683.ref030">30</xref>] which used three stages of processing. Olfactory inputs produced a spatio-temporal pattern (an ‘image’ of the odour) in the antennal lobe (consistent with evidence in flies [<xref ref-type="bibr" rid="pcbi.1004683.ref031">31</xref>] but also observed in many other insects, including ants [<xref ref-type="bibr" rid="pcbi.1004683.ref032">32</xref>]). Divergent connectivity from the antennal lobe to the much larger number of KCs that make up the MB project this pattern onto a sparse encoding in a higher dimensional space [<xref ref-type="bibr" rid="pcbi.1004683.ref033">33</xref>–<xref ref-type="bibr" rid="pcbi.1004683.ref035">35</xref>]. Reward-dependent learning occurs in the synapses between the KC and a small number of output extrinsic neurons (ENs) [<xref ref-type="bibr" rid="pcbi.1004683.ref036">36</xref>–<xref ref-type="bibr" rid="pcbi.1004683.ref038">38</xref>], depending on the delivery at the synapse of an aminergic reward signal [<xref ref-type="bibr" rid="pcbi.1004683.ref039">39</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref040">40</xref>], such that each pattern becomes associated with a positive or negative outcome. This is a simplification of the insect MB circuit, which in reality includes significant feedback connectivity, synaptic adaptation at other levels including in the calyx [<xref ref-type="bibr" rid="pcbi.1004683.ref041">41</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref042">42</xref>] and has a substantial compartmentalisation of its inputs and outputs both between and within the lobes [<xref ref-type="bibr" rid="pcbi.1004683.ref040">40</xref>]. Nevertheless the basic feedforward architecture implemented in our model was shown to be sufficient to support learning of the association of non-elemental (configural) olfactory stimulus patterns to a reinforcement signal.</p>
<p>Our proposal here is that the MB of the ant allows it to similarly associate visual stimulus patterns, as viewed along a route, with the ‘reinforcement’ of facing, moving towards or reaching home. In fact the learnt pattern could be multimodal (e.g., including olfactory cues, see <xref ref-type="sec" rid="sec007">Discussion</xref>) but we focus here on demonstrating that the ecologically realistic visual learning task posed by route following could be achieved by this circuit architecture. In other words, we suggest the neural architecture of the ant MB could plausibly form the substrate for the familiarity algorithm of Baddeley et al [<xref ref-type="bibr" rid="pcbi.1004683.ref011">11</xref>]. The complexity of navigation tasks make it difficult to directly measure or manipulate neural circuits in ants under naturalistic conditions to evaluate their contribution to navigation behaviour. Instead, we take a modelling approach, and explore whether our previously developed spiking neural simulation of olfactory learning in the MB of <italic>Drosophila</italic> [<xref ref-type="bibr" rid="pcbi.1004683.ref030">30</xref>] could be directly applied to the complex ecological task of route memory in ants, using realistic stimuli derived directly from our field experiments.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Reconstruction of the ant’s task</title>
<p>We created a realistic reconstruction of the visual experience of ants based on ecologically relevant data from our study of route following in <italic>Cataglyphis velox</italic> [<xref ref-type="bibr" rid="pcbi.1004683.ref043">43</xref>]. The field site was a flat semi-arid area covered in low scrub and grass tussocks. Ants were trained to forage from a feeder 7.5m from their nest. 15 individual ants were tracked over multiple trips, each revealing an idiosyncratic route to and from the feeder, which they consistently reproduced. We mapped the tussock location and size, and used panoramic pictures taken from ground level to estimate tussock height, and to generate a corresponding virtual environment, where each tussock is a collection of triangular grass blades with a distribution of shading taken randomly from the intensity range in the panoramic pictures (<xref ref-type="fig" rid="pcbi.1004683.g001">Fig 1</xref>). The ground is flat and featureless, and the sky is uniform, without intensity or polarized light gradients. A simulated ant can be placed at any position, with any heading, within this environment. The simulated ant’s visual input is reconstructed from a point 1cm above the ground plane, with a field of view that extends horizontally for 296 degrees and vertically for 76 degrees, with 4 degree/pixel resolution [<xref ref-type="bibr" rid="pcbi.1004683.ref016">16</xref>], producing a 19x74 pixel image. The image is inverted in intensity and histogram equalized [<xref ref-type="bibr" rid="pcbi.1004683.ref044">44</xref>] and further down-sampled to 10x36 pixels (effectively 8 degree/pixel resolution) for input to the MB network.</p>
<fig id="pcbi.1004683.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004683.g001</object-id>
<label>Fig 1</label>
<caption>
<title>The ant’s navigational task.</title>
<p>Left: 3D mapping of the real ant environment, which consists of flat ground and clumps of vegetation. Two actual routes followed repeatedly by individual ants from feeder to nest are shown. From a given ground point (e.g. locations A, B, C and D as indicated), the visual input of a simulated ant facing a given direction can be reconstructed, applying a 296 degree horizontal field of view, 8 degree/pixel resolution, inversion of intensity values and histogram equalization. The task of following a specific route requires distinguishing ‘familiar views’, e.g. for the red route, views A and C, from ‘unfamilar views’ e.g. B and D from the blue route, despite their substantial similarity. Right: how route following capability is assessed. The simulated ant is trained with images taken at 10cm intervals facing along a route. To retrace the route, it scans +/-60 degrees (i), evaluating the familiarity at each angle (distribution shown in blue), then moves 10 cm in the most familiar direction (ii). Deviating more than 20cm from the route is counted as an error (iii) and the ant is replaced on the nearest point of the route to continue (iv), until home is reached.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.g001" xlink:type="simple"/>
</fig>
<p><xref ref-type="fig" rid="pcbi.1004683.g001">Fig 1</xref> shows the potential difficulty of the route following task within this environment. The ant is surrounded by relatively dense vegetation, which blocks any distant landmarks (see also supplementary <xref ref-type="supplementary-material" rid="pcbi.1004683.s002">S1 Fig</xref> which shows a sequence of panoramic photographs taken from ground level along an ant’s route, illustrating the lack of any distant features visible throughout the route). The vegetation density is around 2 tussocks/m<sup>2</sup> (compared to 0.05–0.75 tussocks/m<sup>2</sup> used in previous simulations [<xref ref-type="bibr" rid="pcbi.1004683.ref011">11</xref>]) and ants are often observed to go directly through tussocks leading to abrupt changes in the view. As a consequence, multiple non-overlapping views need to be stored to encode the full route, and searched when recapitulating it. The views lack unique features, especially at the ant eye’s low resolution, so the potential for aliasing seems high. In particular, there is no reason to expect images seen by the ant along one route (e.g. <xref ref-type="fig" rid="pcbi.1004683.g001">Fig 1A and 1C</xref>) to have any common properties that could be learnt to distinguish them from non-route images (e.g. those from another ant’s route, <xref ref-type="fig" rid="pcbi.1004683.g001">Fig 1B and 1D</xref>; or those experienced when not aligned with the route).</p>
</sec>
<sec id="sec004">
<title>Mushroom body processing</title>
<p>We altered our mushroom body model [<xref ref-type="bibr" rid="pcbi.1004683.ref030">30</xref>] (<xref ref-type="fig" rid="pcbi.1004683.g002">Fig 2</xref>) only by increasing the number of neurons (staying well below estimates for the ant brain [<xref ref-type="bibr" rid="pcbi.1004683.ref017">17</xref>]), and introducing anti-Hebbian learning [<xref ref-type="bibr" rid="pcbi.1004683.ref039">39</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref040">40</xref>]. Our input layer consists of 360 visual projection neurons (vPNs), activated proportionally to the intensity of the pixels in a scaled and normalized image (<xref ref-type="fig" rid="pcbi.1004683.g001">Fig 1</xref>). We intentionally kept this visual pre-processing simple, as there is little evidence on which to make assumptions about the nature of the visual input to the MB in the ant. The second layer contains 20,000—KCs, each receiving input from 10 randomly selected vPNs [<xref ref-type="bibr" rid="pcbi.1004683.ref035">35</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref045">45</xref>] (note this does not preserve retinotopy), and needing coincident activation from multiple vPNs to fire. This allows decorrelation of images using a sparse code [<xref ref-type="bibr" rid="pcbi.1004683.ref046">46</xref>], i.e., only a few KCs (around 200) will be activated, and the activation patterns will be more different than the input patterns. All KC outputs converge on a single extrinsic neuron (EN) with a three-factor rule for learning [<xref ref-type="bibr" rid="pcbi.1004683.ref047">47</xref>]. This uses the relationship of presynaptic and postsynaptic spike timing to ‘tag’ synapses, and a global reinforcement signal to permanently decrease the strength of tagged synapses, consistent with neurophysiological evidence from the MB of locusts [<xref ref-type="bibr" rid="pcbi.1004683.ref039">39</xref>]. Thus, images that have been previously paired with reinforcement will excite KCs that no longer activate EN as these connections have been weakened.</p>
<fig id="pcbi.1004683.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004683.g002</object-id>
<label>Fig 2</label>
<caption>
<title>The architecture of the mushroom body (MB) model.</title>
<p>Images (see <xref ref-type="fig" rid="pcbi.1004683.g001">Fig 1</xref>) activate the visual projection neurons (vPNs). Each Kenyon cell (KC) receives input from 10 (random) vPNs and exceeds firing threshold only for coincident activation from several vPNs, thus images are encoded as a sparse pattern of KC activation. All KCs converge on a single extrinsic neuron (EN) and if activation coincides with a reward signal, the connection strength is decreased. After training the EN output to previously rewarded (familiar) images is few or no spikes.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.g002" xlink:type="simple"/>
</fig>
<p>We assume that the ant learns a homeward route by storing the views encountered as it follows its path integration home vector back to the nest. The ‘reinforcement’ signal could thus be generated by decreases in home vector length. In practice, we train the network by generating the images that would be seen every 10cm along the ~8m recorded route of a real ant, with the heading direction towards the next 10cm waypoint. These 80 images are each presented (statically) to the network for 40ms, followed by a transient reinforcement signal (<xref ref-type="fig" rid="pcbi.1004683.g003">Fig 3</xref>). The parameters in the model are set to effectively result in ‘one shot’ learning given this timing of presentation: i.e., a single pairing of image and reinforcement causes the relevant synaptic weights to be reduced to near zero. Such learning is not implausible as it has been shown that, for example, individual bees can acquire odour associations in one or two trials [<xref ref-type="bibr" rid="pcbi.1004683.ref048">48</xref>]. After training, the ant should be able to recover the heading direction at any point along the route by scanning and choosing the ‘most familiar’ direction as indicated by the minima in the activity of EN during the scan.</p>
<fig id="pcbi.1004683.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004683.g003</object-id>
<label>Fig 3</label>
<caption>
<title>The response of the network during training with one image.</title>
<p>A: The image is presented for 40ms, directly activating the vPNs which respond with a spiking rate proportional to the intensity of their input pixel. This produces sparse activation of the KC, which causes the EN to fire. B: An STDP process tags KC synapses depending on the relative timing, Δt, of their spikes to spikes in EN. C: Within 40ms, an active KC will have a strongly negative tag. An increase of amine d, representing reinforcement, will combine with the tag to greatly reduce the weight of the KC-EN synapse.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.g003" xlink:type="simple"/>
</fig>
<p>We compare the MB model to two alternatives. ‘Perfect memory’ represents the best possible performance, by assuming the ant photographically stores all 80 images and directly compares the current viewpoint with all stored images to find the highest similarity, i.e., the minimum in the sum of squared pixel intensity differences (see <xref ref-type="sec" rid="sec008">Methods</xref>). The Infomax algorithm, used previously for this task [<xref ref-type="bibr" rid="pcbi.1004683.ref011">11</xref>] but under less realistic environmental and perceptual processing constraints, attempts to build a generative model of the 80 views using a fully connected two layer neural network (see <xref ref-type="sec" rid="sec008">Methods</xref>). We note that a much higher learning rate was needed in the current study to get successful results from Infomax, and it is possibly learning by overfitting, i.e., its ‘model’ consists essentially of the 80 presented views. In <xref ref-type="fig" rid="pcbi.1004683.g004">Fig 4A–4C</xref> we show the directional choice that would be made using the output from each method for a short segment of the path, using displacements at 5cm intervals up to +/-25cm away from the locations at which images were stored. The MB model produces directional output of equivalent reliability to the other visual memory methods, pointing the simulated ant along the route with only a few exceptions. Note that a perfect match is possible only if the simulated ant is in exactly the same location as the memory was stored, but all the methods are quite robust for nearby locations.</p>
<fig id="pcbi.1004683.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004683.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Performance of the familiarity algorithm.</title>
<p>A-C: Perfect memory (A), the mushroom body (B) and infomax (C) are evaluated for a segment of the route (triangles are grass blades) after training with ~80 images along this route. For test locations in 5cm displacements up to 25cm away from the trained image locations (on red line), all three familiarity algorithms are robust, recovering directions (arrows) that enable route following, but even ‘perfect’ memory can produce errors when not tested at an identical location to where the image was stored. D: Comparison of number of errors made by each algorithm when retracing a route (see <xref ref-type="fig" rid="pcbi.1004683.g001">Fig 1</xref>), compared to random choice of direction. Boxplots show the median, interquartile range and maximum and minimum results for 15 different routes, each ~8m long, with images stored every 10cm.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.g004" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec005">
<title>Evaluating route following</title>
<p>We simulate retracing the route starting from the feeder, heading along the route (<xref ref-type="fig" rid="pcbi.1004683.g001">Fig 1</xref>, right). The next heading direction is determined by the minima in EN firing (or the equivalent choice made using Perfect Memory or Infomax) for a directional scan of ±60 degrees (reflecting a general bias to continue in the same direction). A 10cm step is taken in this direction and the process repeated until the ant reaches home. Note that it is thus possible for the simulated ant to be scanning from a slightly different position from where memory was stored, and hence for the wrong direction to be chosen, even for perfect memory. If successive movements lead the ant a significant distance from the route (&gt; 20cm) then, in the cluttered environment we are testing, matches become poor and the ant will pursue a random course with little chance of recovery. Hence, if a step results in a location more than 20cm from the route, the error count is increased by one and the ant is placed back on the nearest point on route. We count the total number of such errors that occur before the ant comes within 20cm of the home position. As a baseline, we include a random control in which the visual information is ignored and the direction on each step is chosen randomly from ±60 degrees.</p>
<p>The performance of the model is assessed using 15 different ~8m routes, based on the observed routes of real ants recorded in our field study. The results are shown in <xref ref-type="fig" rid="pcbi.1004683.g004">Fig 4</xref>. Random directional choice produces a mean of 18.7 errors (standard deviation = 3.6) per route. Perfect memory has a much lower number of errors (mean 1.1, s.d. = 0.9) suggesting familiarity is an effective route following method. The MB model is only slightly less successful than this benchmark, with a mean of 2.6 errors (s.d. = 1.5). This is significantly worse than Perfect Memory (Bayes factor, calculated using the method in [<xref ref-type="bibr" rid="pcbi.1004683.ref049">49</xref>], is 28:1 in favour of non-equal means), but the drop in performance is small (1.5 additional errors) given the substantial reduction in computational demand − Perfect Memory requires separate comparison of the test view with every stored view for every direction in a scan, whereas MB simply uses the immediate output of the network. Infomax produces a mean of 1.5 errors (s.d. = 0.8), which is marginally better than MB (Bayes factor 2.8:1 in favour of non-equal means). But note that compared to MB, Infomax uses at least 5 times more synaptic weights, and needs to adjust every weight in the network for every training input, using a non-local rule, which is biologically less feasible. <xref ref-type="supplementary-material" rid="pcbi.1004683.s001">S1 Movie</xref> shows a route and images corresponding to a run in which MB produced no errors.</p>
</sec>
<sec id="sec006">
<title>Analytical solution for storage capacity of the mushroom body circuit</title>
<p>The key properties of the MB circuit for this task are the small number of neurons activated in the KC layer (around 1% of neurons activated by each image) and fast (one-shot) learning with no forgetting. We can abstract the spiking KCs as nodes with a binary state, representing whether or not they activated above threshold by the input pattern, and also abstract the KC-EN synaptic strength as either high (contributes to response in EN, the initial state) or low (no input to EN, the state after unidirectional, rapid learning). Because of the initially high setting (if KC is active, EN will fire), we can also simplify to a two factor learning rule: if KC activation coincides with reward, set the synapse strength permanently to low. This abstraction essentially views the learning network of the MB as a layer of binary units with outputs converging on one output unit via binary synapses that have a unidirectional plasticity rule.</p>
<p>Such a network is comparable to a Willshaw net [<xref ref-type="bibr" rid="pcbi.1004683.ref050">50</xref>] for which theoretical estimations of information capacity for a given number of input units N has been previously examined within a framework of fixed sparseness, binomially distributed [<xref ref-type="bibr" rid="pcbi.1004683.ref051">51</xref>]. However, the activity of each KC is not completely independent because all KCs sample from the same population of vPNs activity patterns at any given time and thus the probability distribution for the number of active KCs is not a binomial distribution [<xref ref-type="bibr" rid="pcbi.1004683.ref052">52</xref>]. Nevertheless, the expected number of active KCs is <italic>Np</italic><sub><italic>kc</italic></sub> (where N is the number of KCs and <italic>p</italic><sub><italic>kc</italic></sub> the probability of a connection between each vPN and KC) as required, while the correlation between KCs can be reduced by changing the number of vPNs sampled by each KC and thus the capacity estimation with binomial approximation may hold. Similar capacity estimations have been previously performed for networks with binary synapses and bidirectional plasticity, showing that sparseness prolongs memory lifetimes by reducing the rate of plasticity [<xref ref-type="bibr" rid="pcbi.1004683.ref053">53</xref>] and therefore the interference between new memory encoding and stored memories. Note, in our MB model, increased sparseness also influences plasticity rates and thus changes in capacity can be seen as variations in the interference of the learned patterns.</p>
<p>The abstracted MB allows theoretical estimation of the memory capacity <italic>m</italic> (the number of patterns that can be stored) of the mushroom body for a given size <italic>N</italic> (number of KC) and average activity <italic>p</italic> (average proportion of KC activated by each pattern). We derived (see <xref ref-type="sec" rid="sec008">Methods</xref>) an expression for the mean number of patterns <italic>m</italic> that can be stored before the probability of error reaches <italic>P</italic><sub><italic>error</italic></sub>, where error is defined as having a random unlearned pattern that activates only KC nodes that already have their KC-EN weight set low, thus producing the same EN output as a learned pattern. The resulting capacity is given by:
<disp-formula id="pcbi.1004683.e001">
<alternatives>
<graphic id="pcbi.1004683.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mi>p</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula></p>
<p>The storage capacity as a function of network size and sparsity is shown in <xref ref-type="fig" rid="pcbi.1004683.g005">Fig 5</xref>. Given the above assumptions, our MB model, with <italic>N</italic> = 20,000 input units, one output unit, and average KC activity <italic>p</italic> = 0.01 should allow around 375 random images to be stored before the probability of confusing a novel image with a stored image exceeds <italic>P</italic><sub><italic>error</italic></sub> = 0.01. We confirmed this by training our MB network with random KC patterns, and testing with 100 novel patterns. It was indeed the case that more than 350 patterns could be stored before any of the novel patterns were mistakenly classed as familiar (i.e. produced no spikes in EN, see <xref ref-type="supplementary-material" rid="pcbi.1004683.s003">S2 Fig</xref>). Following the same procedure for varying network size and average KC activity also produces results comparable with the theoretical predictions (<xref ref-type="fig" rid="pcbi.1004683.g005">Fig 5</xref>, diamonds). If memories are stored every 10cm as we have assumed, memorising 350 patterns corresponds to an ant being able to recall a route of 37.5m, or several routes of around 10m, before any confusion would occur; in uncluttered environments, memories could be more spaced (e.g. every 1m or more) and distances correspondingly increased (routes of hundreds of metres, [<xref ref-type="bibr" rid="pcbi.1004683.ref054">54</xref>]). The actual upper limit of ant route memory has not been systematically explored but these values are on the same order as those used in most experimental studies (e.g. [<xref ref-type="bibr" rid="pcbi.1004683.ref043">43</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref055">55</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref056">56</xref>]). There are also a number of plausible ways in which the capacity could be increased: e.g., having more than one EN; more states for synapses; probabilistic rather than deterministic synapse switching; or preprocessing the image data.</p>
<fig id="pcbi.1004683.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004683.g005</object-id>
<label>Fig 5</label>
<caption>
<title>The number of independent images that an abstracted MB network can store before the probability of an error (producing an output of 0 for a novel image) exceeds 0.01.</title>
<p>Lines: predictions from theoretical analysis. Diamonds: results from equivalent simulations using the full spiking model. The capacity scales logarithmically with the number of neurons, and increases if fewer KCs are activated on average by each pattern.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.g005" xlink:type="simple"/>
</fig>
<p>To compare further the capacity estimate derived from this abstraction (with independent random input patterns) to the practical performance of the MB network (with correlated input patterns from routes) we ran the following test. The MB was trained successively with each image from every route, to a total of 1200 images. After each image was added to memory, the EN response was recorded i) for that image, ii) for an image taken 5cm away and facing the same direction, iii) for an image taken from a random location in the ant environment, and iv) for a completely random image. Distinguishing i) from ii-iv) means that stored memories are not confused with new images. Distinguishing ii) from iii) is helpful for robust route following, i.e., the right direction from small displacements should still look more familiar than random locations. Distinguishing i-iii) from iv) might be expected because completely random images will rarely look like images from the environment, where sky is always above grass, which is above the ground, etc. As shown in <xref ref-type="fig" rid="pcbi.1004683.g006">Fig 6</xref>, the response of EN is very noisy (plotted points), hence occasional mistakes in familiarity will occur, but nevertheless the response for stored images is on average (fitted curves) clearly distinguishable from other images as it produces no EN spikes, and images from nearby locations tend to be more familiar than images from random locations, even after storing 1200 images.</p>
<fig id="pcbi.1004683.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004683.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Testing the capacity of the MB network to distinguish familiar from novel images as additional route images are stored (x-axis).</title>
<p>On average (fitted curves), the EN output to learned images is zero. Images from nearby locations with the same heading are more familiar (lower EN response) than those from random locations. Random images remain clearly distinguishable even with 1200 images stored.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.g006" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec007" sec-type="conclusions">
<title>Discussion</title>
<p>We have shown that the neural architecture of the insect mushroom body can implement the ‘familiarity’ algorithm [<xref ref-type="bibr" rid="pcbi.1004683.ref011">11</xref>] for ant route following. In our simulation, the MB learns over 80 on-route images, reconstructed from real ant viewpoints in their natural habitat, and reliably distinguishes them from the highly similar images obtained when looking off-route. This is the first model of visual navigation in insects to draw such a close connection to known neural circuits, rather than appealing to abstract computational capacities; as a result we found that a simpler associative learning network (computationally equivalent to a Willshaw net [<xref ref-type="bibr" rid="pcbi.1004683.ref050">50</xref>]) than Infomax suffices for the task.</p>
<p>Strikingly, the network which was originally developed for modelling simple olfactory associative learning in flies required almost no modification other than increased size to perform the apparently much more complex function of supporting navigation under realistic conditions. Ants (and other navigating insects such as bees) are known to have significantly enlarged MB compared to flies [<xref ref-type="bibr" rid="pcbi.1004683.ref057">57</xref>]. Visual memory has also been localised to the central complex of the insect brain [<xref ref-type="bibr" rid="pcbi.1004683.ref027">27</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref058">58</xref>], and it remains possible that navigation, including visual memory for homing routes, is carried out entirely in the central complex and does not involve the MB. We would agree that the central complex is likely to be a key area for navigational capabilities in many insects [<xref ref-type="bibr" rid="pcbi.1004683.ref027">27</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref059">59</xref>], in particular processing polarised light [<xref ref-type="bibr" rid="pcbi.1004683.ref060">60</xref>], and potentially for path integration. However the extreme memory demands of extended route following in hymenoptera such as ants and bees may have co-opted the unique circuit properties of the MB: a divergent projection of patterns into a sparse code across a very large array of neurons, enabling separation and storage of a large number of arbitrary, similar patterns. Such an architecture appears to be unique to the MB neuropils in the insect brain, and has interesting parallels to the cerebellum in vertebrates [<xref ref-type="bibr" rid="pcbi.1004683.ref061">61</xref>].</p>
<p>Although we have used whole images in our simulation, we believe the approach is neutral to the issue of whether insects actually use the whole panorama, the skyline, the ground pattern, optic flow, or salient landmarks. Indeed there is no reason why the patterns stored should represent only one modality at a time. The multimodal inputs to the MB in ants [<xref ref-type="bibr" rid="pcbi.1004683.ref062">62</xref>] suggest that the KC activation pattern might combine olfactory, visual and other sensory (and possibly proprioceptive or motivational) inputs into a gestalt experience of the current location, and alteration of any of these cues might reduce the familiarity. Manipulation of olfactory [<xref ref-type="bibr" rid="pcbi.1004683.ref063">63</xref>], wind [<xref ref-type="bibr" rid="pcbi.1004683.ref064">64</xref>] and tactile [<xref ref-type="bibr" rid="pcbi.1004683.ref065">65</xref>] cues have been shown to affect navigational memory in ants.</p>
<p>The network we have described simply stores patterns, rather than trying to learn an underlying generative model to classify ‘on-route’ vs ‘off-route’ memories. Nevertheless, in common with many learning problems, the ideal visual memory for route following has an over-fitting/generalization tradeoff. If the memory for individual views is too specific, then any small displacement from the route will result in no direction looking familiar and the animal being lost; and if the similar views resulting from small displacements could be stored as ‘one class’, the environmental range of a limited capacity memory would be increased. However, if parameters (or the learning rule) are adjusted to allow greater generalization to similar views, there will be increased aliasing and hence risk of mistaking a new view for a familiar one, which would result in moving in the wrong direction, with potentially fatal consequences. One way to deal with this problem might be to introduce more sophisticated visual processing. In particular, a more effective vPN-KC mapping than the random connectivity assumed here might be obtained by allowing self-organisation (unsupervised learning) in response to visual experience in the natural environment [<xref ref-type="bibr" rid="pcbi.1004683.ref066">66</xref>] so that only ‘useful’ correlations (for example features that vary strongly with rotation but not displacement [<xref ref-type="bibr" rid="pcbi.1004683.ref067">67</xref>]) are preserved. Evidence for adaptive synapses at this level of the circuit exists for bees [<xref ref-type="bibr" rid="pcbi.1004683.ref041">41</xref>] and flies [<xref ref-type="bibr" rid="pcbi.1004683.ref042">42</xref>]. More complex pre-processing might also be needed to deal with some aspects of the real performance of ants, who continue to follow a route under changing light conditions and movement of vegetation by wind, with some robustness to changing landmark information, and probably also pitch and roll of the head [<xref ref-type="bibr" rid="pcbi.1004683.ref068">68</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref069">69</xref>].</p>
<p>Similarly, we recognise there is likely to be more complexity to the ant’s use of PI and visual memory than the algorithm presented here suggests. For example, it would be necessary to postulate a separate memory to explain the outwards routes of ants, with acquisition guided by successful progress along an outbound vector that is expected to lead to a food source. Insects also appear to acquire visual memory during learning walks and flights, by turning back to view the nest [<xref ref-type="bibr" rid="pcbi.1004683.ref008">8</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref070">70</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref071">71</xref>]. In this case we would need to assume that the reinforcement signal is under more complex control of a motor programme that maintains or generates fixations in the nest direction. Another possibility is that memory storage is triggered by significant change in the view. Interestingly, this is already inherently determined by the use of a three-factor learning rule in our MB model. If a view is already sufficiently ‘familiar’, the EN will not fire in response to the KC activation, so the synapses will not be tagged and learning will not occur.</p>
<p>The model we present provides a neurophysiological underpinning for the claim that ants can perform route navigation without requiring a map and for assessing the range over which views can provide guidance. We should be cautious to extend results from ants to other insects, particularly bees, whose sensorimotor habitat is significantly different and might thus have developed different strategies for navigation. However, although it might seem difficult to account for novel routes (or short cuts) ever being taken using the familiarity algorithm, great care is needed to distinguish a truly novel route from the behaviour that may emerge from an animal continuously orienting to make the best visual memory match possible given its current location and stored memories. This can include visual homing within a catchment area larger than that actually explored by the animal [<xref ref-type="bibr" rid="pcbi.1004683.ref012">12</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref072">72</xref>,<xref ref-type="bibr" rid="pcbi.1004683.ref073">73</xref>]. We also note that though PI is not used in route guidance in our simulations, it will normally still be active in the animal, with potential to influence the direction taken. In particular, recent results have shown that conflicting visual and PI cues often result in a compromise direction being taken by ants [<xref ref-type="bibr" rid="pcbi.1004683.ref073">73</xref>–<xref ref-type="bibr" rid="pcbi.1004683.ref077">77</xref>]. Under some circumstances, the result could appear to be a novel shortcut.</p>
</sec>
<sec id="sec008" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec009">
<title>Ant data</title>
<p>The data on ant routes and environment comes from our previous study of route following in <italic>Cataglyphis velox</italic> [<xref ref-type="bibr" rid="pcbi.1004683.ref043">43</xref>]. Briefly, individual foragers were tracked over repeated journeys, by marking their location on squared paper at approximately 2 second intervals relative to a grid marked on the ground with bottle caps at 1 metre spacing. Subsequently a continuous path was reconstructed using polynomial interpolation. Mapping of tussock locations and panoramic photos from this environment were used to create the virtual environment based on the same software used in [<xref ref-type="bibr" rid="pcbi.1004683.ref010">10</xref>–<xref ref-type="bibr" rid="pcbi.1004683.ref011">11</xref>]; details and the simulated world itself are available from <ext-link ext-link-type="uri" xlink:href="http://www.insectvision.org/walking-insects/antnavigationchallenge" xlink:type="simple">www.insectvision.org/walking-insects/antnavigationchallenge</ext-link>.</p>
</sec>
<sec id="sec010">
<title>Image processing</title>
<p>The simulated ant’s visual input, for a specific location and heading direction, is reconstructed from a point 1cm above the ground plane, with a field of view that extends horizontally for 296 degrees and vertically for 76 degrees, with 4 degree/pixel resolution, producing a 19x74 pixel image. The greyscale image values are inverted and the local contrast is enhanced using contrast-limited adaptive histogram equalisation, by applying the Matlab function <italic>adapthisteq</italic> [<ext-link ext-link-type="uri" xlink:href="http://uk.mathworks.com/help/images/ref/adapthisteq.html" xlink:type="simple">http://uk.mathworks.com/help/images/ref/adapthisteq.html</ext-link>] with default values. It is then further downsampled to 10x36 pixels using the Matlab function <italic>imresize</italic> [<ext-link ext-link-type="uri" xlink:href="http://uk.mathworks.com/help/images/ref/imresize.html" xlink:type="simple">http://uk.mathworks.com/help/images/ref/imresize.html</ext-link>] in which each output pixel is a weighted average of the pixels in the nearest 4x4 neighbourhood. For input into all models, the image is normalised by dividing each pixel value by the square root of the sum of squares of all pixel values. Matlab function <italic>reshape</italic>[<ext-link ext-link-type="uri" xlink:href="http://uk.mathworks.com/help/matlab/ref/reshape.html" xlink:type="simple">http://uk.mathworks.com/help/matlab/ref/reshape.html</ext-link>] is applied to convert the normalised 2D (10x36) image into an 1D (360x1) vector used for subsequent processing.</p>
</sec>
<sec id="sec011">
<title>Spiking neural network</title>
<p>The Mushroom Body network is essentially the same as that described in [<xref ref-type="bibr" rid="pcbi.1004683.ref030">30</xref>] except that it uses more neurons and has anti-Hebbian learning. It is composed of three layers (see <xref ref-type="fig" rid="pcbi.1004683.g002">Fig 2</xref> and Tables <xref ref-type="table" rid="pcbi.1004683.t001">1</xref>–<xref ref-type="table" rid="pcbi.1004683.t003">3</xref>) of ‘Izhikevich’ spiking neurons [<xref ref-type="bibr" rid="pcbi.1004683.ref078">78</xref>], i.e., for each neuron the change in membrane potential <italic>v</italic>(mV) is modelled as follows:
<disp-formula id="pcbi.1004683.e002">
<alternatives>
<graphic id="pcbi.1004683.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mrow><mml:mi>C</mml:mi><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>ν</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>ν</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>ξ</mml:mi><mml:mo> </mml:mo><mml:mo>~</mml:mo><mml:mo> </mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>σ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
<disp-formula id="pcbi.1004683.e003">
<alternatives>
<graphic id="pcbi.1004683.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>ν</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>The variables <italic>v</italic> (membrane potential) and <italic>u</italic> (recovery current) are reset if the membrane potential exceeds a threshold <italic>v</italic><sub><italic>t</italic></sub>:
<disp-formula id="pcbi.1004683.e004">
<alternatives>
<graphic id="pcbi.1004683.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:mrow><mml:mo>{</mml:mo> <mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>ν</mml:mi><mml:mo>←</mml:mo><mml:mi>c</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>u</mml:mi><mml:mo>←</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula></p>
<p>The parameter C is the membrane capacitance, <italic>v</italic><sub><italic>r</italic></sub> is the resting membrane potential, <italic>I</italic> is the input current, <italic>ξ</italic> ~ <italic>N</italic>(0, <italic>σ</italic>) is noise with a Gaussian distribution, and <italic>a</italic>, <italic>b</italic>, <italic>c</italic>, <italic>d</italic> and <italic>k</italic> are model parameters (see <xref ref-type="table" rid="pcbi.1004683.t002">Table 2</xref>) which determine the characteristic response of the neuron.</p>
<p>Synaptic input to the first layer, which consists of 360 visual projection neurons (vPNs), is given as an input current proportional to the corresponding pixel in the normalised image 1D vector (360x1) described above:
<disp-formula id="pcbi.1004683.e005">
<alternatives>
<graphic id="pcbi.1004683.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mrow><mml:mi>P</mml:mi><mml:mi>N</mml:mi><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mo> </mml:mo><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mo>×</mml:mo><mml:mi>V</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>The normalization and choice of scaling factor ensures that approximately half the vPNs are activated by each image. The subsequent layers consist of 20,000 Kenyon cells (KC), each receiving input from 10 randomly selected vPNs, and a single extrinsic neuron (EN) receiving input from all KC, and their synaptic input is modelled by:
<disp-formula id="pcbi.1004683.e006">
<alternatives>
<graphic id="pcbi.1004683.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:mrow><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>ν</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula>
where <italic>g</italic> (nS) is the maximal synaptic conductance (the synaptic ‘weight’), <italic>v</italic><sub><italic>rev</italic></sub> = 0 is the reversal potential of the synapses, and <italic>S</italic> is the amount of active neurotransmitter which is updated as follows:
<disp-formula id="pcbi.1004683.e007">
<alternatives>
<graphic id="pcbi.1004683.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula>
where the parameter <italic>ϕ</italic> is a quantile of the amount of neurotransmitters released when a presynaptic spike occurred, <italic>τ</italic><sub><italic>syn</italic></sub> is the synaptic time constant, <italic>t</italic><sub><italic>pre</italic></sub> is the time at which the presynaptic spike occurred and <italic>δ</italic> is the Dirac delta function. See <xref ref-type="table" rid="pcbi.1004683.t003">Table 3</xref> for synapse parameter values. The weights from vPN to KC are fixed. The weights <italic>g</italic> from KC to EN are altered by learning using a modification of the three-factor rule from [<xref ref-type="bibr" rid="pcbi.1004683.ref079">79</xref>]:
<disp-formula id="pcbi.1004683.e008">
<alternatives>
<graphic id="pcbi.1004683.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>d</mml:mi></mml:mrow>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula>
where <italic>g</italic> is the synaptic conductance, <italic>c</italic> is a synaptic ‘tag’ which maintains an eligibility trace over short periods of time, signalling which KC was involved in activating EN (see below); and <italic>d</italic> is the extracellular concentration of a biogenic amine, modelled by:
<disp-formula id="pcbi.1004683.e009">
<alternatives>
<graphic id="pcbi.1004683.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mrow><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula>
where <italic>BA(t)</italic> is the amount of biogenic amine released at time <italic>t</italic>, which depends on the presence of the reinforcement signal [<xref ref-type="bibr" rid="pcbi.1004683.ref030">30</xref>] (see training procedure below) and <italic>τ</italic><sub><italic>d</italic></sub> is a time constant for the decay of concentration <italic>d</italic>.</p>
<p>The synaptic tag <italic>c</italic> is modified using spike timing dependent plasticity (STDP):
<disp-formula id="pcbi.1004683.e010">
<alternatives>
<graphic id="pcbi.1004683.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mrow><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>S</mml:mi><mml:mi>T</mml:mi><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>*</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(9)</label>
</disp-formula>
where <italic>δ(t)</italic> is the Dirac delta function, <italic>t</italic><sub><italic>pre</italic></sub> is the time of a pre-synaptic spike, <italic>t</italic><sub><italic>post</italic></sub> is the time of a post-synaptic spike, and <italic>τ</italic><sub><italic>c</italic></sub> is a time constant for decay of the tag <italic>c</italic>. Thus, either pre- or post-synaptic neuronal firing will change variable c by the amount STDP, defined as:
<disp-formula id="pcbi.1004683.e011">
<alternatives>
<graphic id="pcbi.1004683.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:mrow><mml:mi>S</mml:mi><mml:mi>T</mml:mi><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>   </mml:mtext><mml:msub><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext>  </mml:mtext><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mo> </mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:msub><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mo>−</mml:mo></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mo> </mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
<label>(10)</label>
</disp-formula>
<italic>A</italic><sub>+</sub> and <italic>A</italic><sub>−</sub> are the amplitudes, and <italic>τ</italic><sub>+</sub>/<italic>τ</italic><sub>−</sub> are the time constants. However we use an anti-Hebbian form of this rule, such that the tag is always negative:
<disp-formula id="pcbi.1004683.e012">
<alternatives>
<graphic id="pcbi.1004683.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e012" xlink:type="simple"/>
<mml:math display="block" id="M12">
<mml:mrow><mml:mrow> <mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:msub><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mo>−</mml:mo><mml:mn>1.0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mtext>  </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>τ</mml:mi><mml:mo>−</mml:mo></mml:msub><mml:mtext>  </mml:mtext><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>15</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(11)</label>
</disp-formula></p>
</sec>
<sec id="sec012">
<title>Network geometry</title>
<table-wrap id="pcbi.1004683.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004683.t001</object-id>
<label>Table 1</label> <caption><title>Connectivity and synaptic weights.</title></caption>
<alternatives>
<graphic id="pcbi.1004683.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">From X to Y</th>
<th align="center">Prob. of connection</th>
<th align="center">Initial Weight per connection</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">vPN to KC</td>
<td align="center">Each KC receives input from 10 randomly selected PNs</td>
<td align="center">0.25 (constant)</td>
</tr>
<tr>
<td align="center">KC to EN</td>
<td align="center">1 (all KCs connect to the EN)</td>
<td align="center">2.0 (subject to learning)</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="pcbi.1004683.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004683.t002</object-id>
<label>Table 2</label> <caption><title>Parameters for each neuron type.</title></caption>
<alternatives>
<graphic id="pcbi.1004683.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Parameter</th>
<th align="center">PN</th>
<th align="center">KC</th>
<th align="center">EN</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Neuron Number</td>
<td align="center">360</td>
<td align="center">20000</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">Scaling factor</td>
<td align="center">5250</td>
<td align="center">N/A</td>
<td align="center">N/A</td>
</tr>
<tr>
<td align="center">C</td>
<td align="center">100</td>
<td align="center">4</td>
<td align="center">100</td>
</tr>
<tr>
<td align="center">a</td>
<td align="center">0.3</td>
<td align="center">0.01</td>
<td align="center">0.3</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center">-0.2</td>
<td align="center">-0.3</td>
<td align="center">-0.2</td>
</tr>
<tr>
<td align="center">c</td>
<td align="center">-65</td>
<td align="center">-65</td>
<td align="center">-65</td>
</tr>
<tr>
<td align="center">d</td>
<td align="center">8</td>
<td align="center">8</td>
<td align="center">8</td>
</tr>
<tr>
<td align="center">k</td>
<td align="center">2</td>
<td align="center">0.035</td>
<td align="center">2</td>
</tr>
<tr>
<td align="center"><italic>v</italic><sub><italic>r</italic></sub></td>
<td align="center">-60</td>
<td align="center">-85</td>
<td align="center">-60</td>
</tr>
<tr>
<td align="center"><italic>v</italic><sub><italic>t</italic></sub></td>
<td align="center">-40</td>
<td align="center">-25</td>
<td align="center">-40</td>
</tr>
<tr>
<td align="center">ξ</td>
<td align="center"><italic>N</italic>(0, 0.05)</td>
<td align="center"><italic>N</italic>(0, 0.05)</td>
<td align="center"><italic>N</italic>(0, 0.05)</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>Neuron Number is the number of neurons in each type. Scaling factor is specifically for visual Projection Neurons: the input signal without scaling is the result from normalisation of grayscale images, thus in the range of [0, 1]. The scaling factor amplifies the signal so that any image will activate about half of the vPNs. The parameters from C to <italic>v</italic><sub><italic>t</italic></sub> in the first column are Izhikevich spiking neuronal model parameters. ξ defines Gaussian random noise current injected into each neuron.</p></fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="pcbi.1004683.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004683.t003</object-id>
<label>Table 3</label> <caption><title>Parameters for each synapse type.</title></caption>
<alternatives>
<graphic id="pcbi.1004683.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.t003" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Parameter</th>
<th align="center">PN to KC</th>
<th align="center">KC to EN</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><italic>τ</italic><sub><italic>syn</italic></sub></td>
<td align="center">3.0</td>
<td align="center">8.0</td>
</tr>
<tr>
<td align="center"><italic>ϕ</italic></td>
<td align="center">0.93</td>
<td align="center">8.0</td>
</tr>
<tr>
<td align="center">g</td>
<td align="center">0.25</td>
<td align="center">[0, 2.0]</td>
</tr>
<tr>
<td align="center"><italic>τ</italic><sub><italic>c</italic></sub></td>
<td align="center">N/A</td>
<td align="center">40ms</td>
</tr>
<tr>
<td align="center"><italic>τ</italic><sub><italic>d</italic></sub></td>
<td align="center">N/A</td>
<td align="center">20ms</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001"><p>The parameter <italic>τ</italic><sub><italic>syn</italic></sub> is the time constant for synapses, <italic>ϕ</italic> represents the quantity of neurotransmitter released per synapse, and g is the weight per synapse. Note that the weights of connections from vPN to KC are fixed whereas the weights from KC to EN are bounded to the range of 0 to 2.0. The parameter <italic>τ</italic><sub><italic>c</italic></sub> is the time constant for Izhikevich type synaptic eligibility trace in KC-EN synapses, and <italic>τ</italic><sub><italic>d</italic></sub> is the Biogenic Amine concentration time constant.</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec013">
<title>Training procedure</title>
<p>We assume that an ant learns a route while running home (following a home vector) and avoiding obstacles. This gives rise to a unique set of visual experiences which it memorises, so that subsequent traversals of the same route can be made without a home vector, and starting from any point along it. In practice, we take each recorded route of a real ant (of average length 8m) and use it to train the spiking neural network as follows. From nest to home, every 10cm along the route, we use the simulated environment to generate an image facing the next 10cm waypoint. After pre-processing as described above, the normalised image pixel values are given as input to the first layer (vPNs) of the network every 1ms for 40ms. Then a reinforcement signal is presented for one time-step (BA(t) = 0.5, for t = 40ms from image onset) and a further 10ms of simulation time (with no image or reinforcement signal presented) allowed to elapse, during which any synaptic weight changes will occur. Given the parameters below, this presentation results in rapid, ‘one-shot’ learning of the presented image, with weights between any active KC and EN decreasing rapidly to zero (see <xref ref-type="fig" rid="pcbi.1004683.g003">Fig 3</xref>). To save computation time, we do not explicitly model network activity during the lapse of time until the next image to be learnt would be encountered (during which the ant moves 10cm further along the route). Instead we simply reset the membrane potentials, synaptic tags and amine levels in the network to their initial state, and then present the new image for 40ms, followed by reinforcement, etc., until all the images for that route (around 80 for an 8m route) have been presented. Subsequently the spiking rate output of EN will indicate the novelty of any image presented to the network.</p>
</sec>
<sec id="sec014">
<title>Perfect memory</title>
<p>As a benchmark for the difficulty of the navigation task, we determine the performance of a simulated ant which has a perfect memory, i.e., it simply stores the complete set of training images, and uses direct pixel-by-pixel image differencing to compare images [<xref ref-type="bibr" rid="pcbi.1004683.ref009">9</xref>]. When recapitulating a route, novelty of the current view <italic>I</italic> with respect to all stored images is calculated as:
<disp-formula id="pcbi.1004683.e013">
<alternatives>
<graphic id="pcbi.1004683.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(12)</label>
</disp-formula>
Where <italic>V</italic><sub><italic>i</italic></sub> is each of the stored images, and <italic>x</italic>,<italic>y</italic> define the individual pixels.</p>
</sec>
<sec id="sec015">
<title>Infomax</title>
<p>For comparison, we also implemented the Infomax algorithm, a continuous 2-layer network, closely following the method described in [<xref ref-type="bibr" rid="pcbi.1004683.ref011">11</xref>], except with a much higher learning rate. The input layer has <italic>N</italic> = 360 units and the normalized intensities of the 36x10 image pixels are mapped row by row onto the input layer to provide the activation level of each unit, <italic>x</italic><sub><italic>i</italic></sub>. The output layer also has 360 units and is fully connected to the input layer. The activation of each unit of the output layer, <italic>h</italic><sub><italic>i</italic></sub>, is given by:
<disp-formula id="pcbi.1004683.e014">
<alternatives>
<graphic id="pcbi.1004683.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e014" xlink:type="simple"/>
<mml:math display="block" id="M14">
<mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow>
</mml:math>
</alternatives>
<label>(13)</label>
</disp-formula>
Where <italic>w</italic><sub><italic>ij</italic></sub> is the weight of the connection from the <italic>jth</italic> input unit to the <italic>ith</italic> output unit. The output <italic>y</italic><sub><italic>i</italic></sub> is then given by:
<disp-formula id="pcbi.1004683.e015">
<alternatives>
<graphic id="pcbi.1004683.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e015" xlink:type="simple"/>
<mml:math display="block" id="M15">
<mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>tanh</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(14)</label>
</disp-formula>
Each image is learnt in turn by adjusting all the weights (initialized with random values) by:
<disp-formula id="pcbi.1004683.e016">
<alternatives>
<graphic id="pcbi.1004683.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e016" xlink:type="simple"/>
<mml:math display="block" id="M16">
<mml:mrow><mml:mi>Δ</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>η</mml:mi><mml:mi>N</mml:mi></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(15)</label>
</disp-formula>
Where <italic>η</italic> = 1.1 is the learning rate.</p>
<p>Subsequently the novelty of an image is given by the summed activation of the output layer:
<disp-formula id="pcbi.1004683.e017">
<alternatives>
<graphic id="pcbi.1004683.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e017" xlink:type="simple"/>
<mml:math display="block" id="M17">
<mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mrow><mml:mo>∣</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∣</mml:mo></mml:mrow></mml:mstyle></mml:mrow>
</mml:math>
</alternatives>
<label>(16)</label>
</disp-formula></p>
</sec>
<sec id="sec016">
<title>Capacity</title>
<p>For this analysis we simplify the MB model by assuming the KC have a binary state (activated if input is above threshold, otherwise not active) and learning will alter the state of the respective KC-EN synapse by setting it to zero when KC activity coincides with reward. We can analyse the storage capacity of a network with <italic>N</italic> input nodes and average activity <italic>p</italic> by deriving an expression for the probability of error <italic>P</italic><sub><italic>error</italic></sub>, defined as the probability that a random unlearned pattern activates only KC nodes that already have their weight set to 0, producing the same EN output as a learned pattern (i.e. 0). We assume the number of neurons <italic>k</italic> coding a pattern is drawn from the binomial distribution with probability <italic>p</italic>. After learning <italic>m</italic> random patterns:
<disp-formula id="pcbi.1004683.e018">
<alternatives>
<graphic id="pcbi.1004683.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e018" xlink:type="simple"/>
<mml:math display="block" id="M18">
<mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>m</mml:mi></mml:msup></mml:mrow>
</mml:math>
</alternatives>
<label>(17)</label>
</disp-formula></p>
<p>The probability that a new pattern activates only neurons with <italic>w</italic><sub><italic>i</italic></sub> = <italic>0</italic> is given by:
<disp-formula id="pcbi.1004683.e019">
<alternatives>
<graphic id="pcbi.1004683.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e019" xlink:type="simple"/>
<mml:math display="block" id="M19">
<mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle><mml:mi>K</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>N</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>k</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>m</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math>
</alternatives>
<label>(18)</label>
</disp-formula></p>
<p>That is, the sum of possible arrangements of <italic>k</italic> active units that all have weights set to 0. This can be written as:
<disp-formula id="pcbi.1004683.e020">
<alternatives>
<graphic id="pcbi.1004683.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e020" xlink:type="simple"/>
<mml:math display="block" id="M20">
<mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>N</mml:mi></mml:msup><mml:mrow><mml:munder><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle><mml:mi>k</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>N</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>k</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>m</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>N</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>m</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>m</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math>
</alternatives>
<label>(19)</label>
</disp-formula></p>
<p>For a given acceptable error rate <italic>P</italic><sub><italic>error</italic></sub>, we can solve for the number of patterns <italic>m</italic> that can be stored before that error rate will be exceeded:
<disp-formula id="pcbi.1004683.e021">
<alternatives>
<graphic id="pcbi.1004683.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004683.e021" xlink:type="simple"/>
<mml:math display="block" id="M21">
<mml:mrow><mml:mtext>m</mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mi>p</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
</alternatives>
<label>(20)</label>
</disp-formula></p>
<p><xref ref-type="fig" rid="pcbi.1004683.g005">Fig 5</xref> shows how the capacity <italic>m</italic> of the network changes with the number of neurons <italic>N</italic> and average activity <italic>p</italic>, for <italic>P</italic><sub><italic>error</italic></sub> = 0.01.</p>
<p>To confirm this analysis is consistent with the behaviour of the full spiking network, we carried out an equivalent capacity testing process using the simulation. For a network of a given size, we generated random activation of the KC neurons at different levels of average activity. Patterns were learned as before, i.e., by applying a reward signal after 40ms, resulting in altered KC-EN weights. After each successive pattern was learned, we tested the network with 100 random patterns, to see if any produced a spiking response as low as that of the learned patterns, i.e., would potentially be confused with a learnt pattern (see <xref ref-type="supplementary-material" rid="pcbi.1004683.s003">S2 Fig</xref> for the result with N = 20000, p = 0.01). We noted how many patterns could be learnt before <italic>P</italic><sub><italic>error</italic></sub> = 0.01, i.e. where ≥ 1 out of 100 new patterns would start to be confused with a learnt pattern.</p>
<p>Note however this analysis and simulation assumes both learned and tested KC patterns are independent and random, which is not strictly true in the navigation task. We also tested the spiking network (with N = 20000, p = 0.01) by continuously storing additional patterns generated by real route images, and counting the spikes produced by EN for the learnt image, for an image taken from a 5cm displacement facing the same way, for an image taken at a random location in the ant environment, and for a random image. The results are shown in <xref ref-type="fig" rid="pcbi.1004683.g006">Fig 6</xref>.</p>
</sec>
<sec id="sec017">
<title>External database</title>
<p>The virtual ant world is available from: <ext-link ext-link-type="uri" xlink:href="http://www.insectvision.org/walking-insects/antnavigationchallenge" xlink:type="simple">www.insectvision.org/walking-insects/antnavigationchallenge</ext-link>.</p>
</sec>
</sec>
<sec id="sec018">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004683.s001" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.s001" xlink:type="simple">
<label>S1 Movie</label>
<caption>
<title>This movie shows the result of a route re-capitulation by a simulated ant using the mushroom body model, and the corresponding visual information from the ant’s point of view that is used as input to the model.</title>
<p>The direction of each 10cm step along the route is chosen by scanning (the scanning movement is not shown) ±60 degrees and choosing the direction producing the fewest spikes from the extrinsic neuron output. The simulated ant never departs far enough from the trained route to get lost, and successfully returns home over 8 meters in the complex environment.</p>
<p>(ZIP)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004683.s002" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.s002" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title/>
<p>A. Distant view of the study site on the outskirts of Seville, Spain with the approximate nest position indicated by the arrow. The nest is surrounded by grass shrub blocking the view of distant objects such as trees. B. Close up view of the field site with the ant nest and experimental feeder marked. C. An example route followed by an ant through the environment shown in blue from an overhead perspective. D. Panoramic images sampled along the route are shown which clearly demonstrate that distant objects were not visible to homing ants.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004683.s003" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004683.s003" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Capacity of a MB network with N = 20000 and p = 0.01.</title>
<p>From <xref ref-type="fig" rid="pcbi.1004683.g005">Fig 5</xref>, the abstracted model provides the estimate that around 375 random images can be stored (KC weights set to 0) before the probability of an error (a new random image activates only KCs that have already had weights set to 0) exceeds 0.01. Using the full spiking network and the three factor learning rule, we train successively with 500 random KC activation patterns. After each additional pattern is stored, we test the network with 100 random patterns to see how many produce an error (have an EN output of 0 spikes, indicating a familiar pattern). More than 350 patterns could be stored before &gt; 1/100 errors occur. The same method is used to generate data points for other values of N and p plotted in <xref ref-type="fig" rid="pcbi.1004683.g005">Fig 5</xref>.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>Bart Baddeley introduced us to the familiarity and 3D world recreation approaches, Saran Lertpredit helped with the visual image generation, Jan Wessnitzer &amp; Jonas Klein developed the original spiking MB neural network, and Shang Zhao first explored it for navigation. Lars Chittka, Paul Graham and Antoine Wystrach commented on earlier versions of the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004683.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wehner</surname> <given-names>R</given-names></name>. <article-title>The architecture of the desert ant’s navigational toolkit (Hymenoptera: Formicidae)</article-title>. <source>Myrmecological News</source>. <year>2009</year>;<volume>12</volume>:<fpage>85</fpage>–<lpage>96</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Collett</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Graham</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Harris</surname> <given-names>RA</given-names></name>. <article-title>Novel landmark-guided routes in ants</article-title>. <source>J. Exp. Biol</source>. <year>2007</year>;<volume>210</volume>:<fpage>2025</fpage>–<lpage>32</lpage>. <object-id pub-id-type="pmid">17562876</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zeil</surname> <given-names>J</given-names></name>. <article-title>Visual homing: An insect perspective</article-title>. <source>Curr. Opin. Neurobiol</source>. <year>2012</year>;<volume>22</volume>:<fpage>285</fpage>–<lpage>93</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2011.12.008" xlink:type="simple">10.1016/j.conb.2011.12.008</ext-link></comment> <object-id pub-id-type="pmid">22221863</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cruse</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Wehner</surname> <given-names>R</given-names></name>. <article-title>No need for a cognitive map: Decentralized memory for insect navigation</article-title>. <source>PLoS Comput. Biol</source>. <year>2011</year>;<volume>7</volume>:<fpage>e1002009</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002009" xlink:type="simple">10.1371/journal.pcbi.1002009</ext-link></comment> <object-id pub-id-type="pmid">21445233</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wehner</surname> <given-names>R</given-names></name>. <article-title>Desert ant navigation: How miniature brains solve complex tasks</article-title>. <source>J. Comp. Physiol. A Neuroethol. Sensory, Neural, Behav. Physiol</source>. <year>2003</year>;<volume>189</volume>:<fpage>579</fpage>–<lpage>88</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Collett</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Collett</surname> <given-names>M</given-names></name>. <article-title>Memory use in insect visual navigation</article-title>. <source>Nat. Rev. Neurosci</source>. <year>2002</year>;<volume>3</volume>:<fpage>542</fpage>–<lpage>52</lpage>. <object-id pub-id-type="pmid">12094210</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Menzel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Greggers</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Berger</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Brandt</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Brunke</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Honey bees navigate according to a map-like spatial memory</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A</source>. <year>2005</year>;<volume>102</volume>:<fpage>3040</fpage>–<lpage>5</lpage>. <object-id pub-id-type="pmid">15710880</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Müller</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Wehner</surname> <given-names>R</given-names></name>. <article-title>Path integration provides a scaffold for landmark learning in desert ants</article-title>. <source>Curr. Biol</source>. <year>2010</year>;<volume>20</volume>:<fpage>1368</fpage>–<lpage>71</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2010.06.035" xlink:type="simple">10.1016/j.cub.2010.06.035</ext-link></comment> <object-id pub-id-type="pmid">20619653</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zeil</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hofmann</surname> <given-names>MI</given-names></name>, <name name-style="western"><surname>Chahl</surname> <given-names>JS</given-names></name>. <article-title>Catchment areas of panoramic snapshots in outdoor scenes</article-title>. <source>J. Opt. Soc. Am. A. Opt. Image Sci. Vis</source>. <year>2003</year>;<volume>20</volume>:<fpage>450</fpage>–<lpage>69</lpage>. <object-id pub-id-type="pmid">12630831</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baddeley</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Graham</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Philippides</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Husbands</surname> <given-names>P</given-names></name>. <article-title>Holistic visual encoding of ant-like routes: Navigation without waypoints</article-title>. <source>Adapt. Behav</source>. <year>2011</year>;<volume>19</volume>:<fpage>3</fpage>–<lpage>15</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baddeley</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Graham</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Husbands</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Philippides</surname> <given-names>A</given-names></name>. <article-title>A Model of Ant Route Navigation Driven by Scene Familiarity</article-title>. <source>PLoS Comput. Biol</source>. <year>2012</year>;<volume>8</volume>:<fpage>e1002336</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002336" xlink:type="simple">10.1371/journal.pcbi.1002336</ext-link></comment> <object-id pub-id-type="pmid">22241975</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wystrach</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Mangan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Philippides</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Graham</surname> <given-names>P</given-names></name>. <article-title>Snapshots in ants? New interpretations of paradigmatic experiments</article-title>. <source>J. Exp. Biol</source>. <year>2013</year>;<volume>216</volume>:<fpage>1766</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1242/jeb.082941" xlink:type="simple">10.1242/jeb.082941</ext-link></comment> <object-id pub-id-type="pmid">23348949</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cheung</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Collett</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Collett</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Dewar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Dyer</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Graham</surname> <given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Still no convincing evidence for cognitive map use by honeybees</article-title>: <source>Proc. Natl. Acad. Sci</source>. <year>2014</year>;<volume>111</volume>:<fpage>E4396</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1413581111" xlink:type="simple">10.1073/pnas.1413581111</ext-link></comment> <object-id pub-id-type="pmid">25277972</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Menzel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Greggers</surname> <given-names>U</given-names></name>. <article-title>The memory structure of navigation in honeybees</article-title>. <source>J. Comp. Physiol. A</source>. <year>2015</year>;<fpage>1</fpage>–<lpage>15</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zollikofer</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Wehner</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Fukushi</surname> <given-names>T</given-names></name>. <article-title>Optical scaling in conspecific Cataglyphis ants</article-title>. <source>J. Exp. Biol</source>. <year>1995</year>;<volume>198</volume>:<fpage>1637</fpage>–<lpage>46</lpage>. <object-id pub-id-type="pmid">9319542</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwarz</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Narendra</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zeil</surname> <given-names>J</given-names></name>. <article-title>The properties of the visual system in the Australian desert ant Melophorus bagoti</article-title>. <source>Arthropod Struct. Dev</source>. <year>2011</year>;<volume>40</volume>:<fpage>128</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.asd.2010.10.003" xlink:type="simple">10.1016/j.asd.2010.10.003</ext-link></comment> <object-id pub-id-type="pmid">21044895</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ehmer</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gronenberg</surname> <given-names>W</given-names></name>. <article-title>Mushroom Body Volumes and Visual Interneurons in Ants: Comparison between Sexes and Castes</article-title>. <source>J. Comp. Neurol</source>. <year>2004</year>;<volume>469</volume>:<fpage>198</fpage>–<lpage>213</lpage>. <object-id pub-id-type="pmid">14694534</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heisenberg</surname> <given-names>M</given-names></name>. <article-title>Mushroom body memoir: from maps to models</article-title>. <source>Nat. Rev. Neurosci</source>. <year>2003</year>;<volume>4</volume>:<fpage>266</fpage>–<lpage>75</lpage>. <object-id pub-id-type="pmid">12671643</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fahrbach</surname> <given-names>SE</given-names></name>. <article-title>Structure of the mushroom bodies of the insect brain</article-title>.<source>Ann, Rev. Entomology</source> <year>2006</year>;<volume>51</volume>:<fpage>209</fpage>–<lpage>232</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stieb</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Muenz</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Wehner</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Rössler</surname> <given-names>W</given-names></name>. <article-title>Visual experience and age affect synaptic organization in the mushroom bodies of the desert ant Cataglyphis fortis</article-title>. <source>Dev. Neurobiol</source>. <year>2010</year>;<volume>70</volume>:<fpage>408</fpage>–<lpage>23</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/dneu.20785" xlink:type="simple">10.1002/dneu.20785</ext-link></comment> <object-id pub-id-type="pmid">20131320</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kühn-Bühlmann</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wehner</surname> <given-names>R</given-names></name>. <article-title>Age-dependent and task-related volume changes in the mushroom bodies of visually guided desert ants, Cataglyphis bicolor</article-title>. <source>J. Neurobiol</source>. <year>2006</year>;<volume>66</volume>:<fpage>511</fpage>–<lpage>21</lpage>. <object-id pub-id-type="pmid">16555240</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fahrbach</surname> <given-names>SE</given-names></name>, <name name-style="western"><surname>Giray</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Farris</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Robinson</surname> <given-names>GE</given-names></name>. <article-title>Expansion of the neuropil of the mushroom bodies in male honey bees is coincident with initiation of flight</article-title>. <source>Neurosci. Lett</source>. <year>1997</year>;<volume>236</volume>:<fpage>135</fpage>–<lpage>8</lpage>. <object-id pub-id-type="pmid">9406755</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Durst</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Eichmüller</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Menzel</surname> <given-names>R</given-names></name>. <article-title>Development and experience lead to increased volume of subcompartments of the honeybee mushroom body</article-title>. <source>Behav. Neural Biol</source>. <year>1994</year>;<volume>62</volume>:<fpage>259</fpage>–<lpage>63</lpage>. <object-id pub-id-type="pmid">7857249</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Withers</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Fahrbach</surname> <given-names>SE</given-names></name>, <name name-style="western"><surname>Robinson</surname> <given-names>GE</given-names></name>. <article-title>Effects of experience and juvenile hormone on the organization of the mushroom bodies of honey bees</article-title>. <source>J. Neurobiol</source>. <year>1995</year>;<volume>26</volume>:<fpage>130</fpage>–<lpage>44</lpage>. <object-id pub-id-type="pmid">7714522</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lutz</surname> <given-names>CC</given-names></name>, <name name-style="western"><surname>Robinson</surname> <given-names>GE</given-names></name>. <article-title>Activity-dependent gene expression in honey bee mushroom bodies in response to orientation flight</article-title>. <source>J. Exp. Biol</source>. <year>2013</year>;<volume>216</volume>:<fpage>2031</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1242/jeb.084905" xlink:type="simple">10.1242/jeb.084905</ext-link></comment> <object-id pub-id-type="pmid">23678099</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mizunami</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Weibrecht</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Strausfeld</surname> <given-names>NJ</given-names></name>. <article-title>Mushroom bodies of the cockroach: Their participation in place memory</article-title>. <source>J. Comp. Neurol</source>. <year>1998</year>;<volume>402</volume>:<fpage>520</fpage>–<lpage>37</lpage>. <object-id pub-id-type="pmid">9862324</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ofstad</surname> <given-names>T a</given-names></name>, <name name-style="western"><surname>Zuker</surname> <given-names>CS</given-names></name>, <name name-style="western"><surname>Reiser</surname> <given-names>MB</given-names></name>. <article-title>Visual place learning in Drosophila melanogaster</article-title>. <source>Nature</source>. <year>2011</year>;<volume>474</volume>:<fpage>204</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature10131" xlink:type="simple">10.1038/nature10131</ext-link></comment> <object-id pub-id-type="pmid">21654803</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wolf</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ernst</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Heisenberg</surname> <given-names>M</given-names></name>. <article-title>Context generalization in Drosophila visual learning requires the mushroom bodies</article-title>. <source>Nature</source>. <year>1999</year>;<volume>400</volume>:<fpage>753</fpage>–<lpage>6</lpage>. <object-id pub-id-type="pmid">10466722</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vogt</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Schnaitmann</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Dylla</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Knapek</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Aso</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>GM</given-names></name>, <etal>et al</etal>. <article-title>Shared mushroom body circuits operate visual and olfactory memories in Drosophila</article-title>. <source>Elife</source>. <year>2014</year>;<volume>3</volume>:<fpage>1</fpage>–<lpage>22</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wessnitzer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Young</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Armstrong</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Webb</surname> <given-names>B</given-names></name>. <article-title>A model of non-elemental olfactory learning in Drosophila</article-title>. <source>J. Comput. Neurosci</source>. <year>2012</year>;<volume>32</volume>:<fpage>197</fpage>–<lpage>212</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-011-0348-6" xlink:type="simple">10.1007/s10827-011-0348-6</ext-link></comment> <object-id pub-id-type="pmid">21698405</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Wong</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Flores</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Vosshall</surname> <given-names>LB</given-names></name>, <name name-style="western"><surname>Axel</surname> <given-names>R</given-names></name>. <article-title>Two-photon calcium imaging reveals an odor-evoked map of activity in the fly brain</article-title>. <source>Cell</source>. <year>2003</year>;<volume>112</volume>:<fpage>271</fpage>–<lpage>82</lpage>. <object-id pub-id-type="pmid">12553914</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Galizia</surname> <given-names>CG</given-names></name>, <name name-style="western"><surname>Menzel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Hölldobler</surname> <given-names>B</given-names></name>. <article-title>Optical imaging of odor-evoked glomerular activity patterns in the antennal lobes of the ant Camponotus rufipes</article-title>. <source>Naturwissenschaften</source>. <year>1999</year>;<volume>86</volume>:<fpage>533</fpage>–<lpage>7</lpage>. <object-id pub-id-type="pmid">10551948</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Honegger</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Campbell</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>GC</given-names></name>. <article-title>Cellular-resolution population imaging reveals robust sparse coding in the Drosophila mushroom body</article-title>. <source>J. Neurosci</source>. <year>2011</year>;<volume>31</volume>:<fpage>11772</fpage>–<lpage>85</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1099-11.2011" xlink:type="simple">10.1523/JNEUROSCI.1099-11.2011</ext-link></comment> <object-id pub-id-type="pmid">21849538</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perez-Orive</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Mazor</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Cassenaer</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>RI</given-names></name>, <name name-style="western"><surname>Laurent</surname> <given-names>G</given-names></name>. <article-title>Oscillations and sparsening of odor representations in the mushroom body</article-title>. <source>Science</source>. <year>2002</year>;<volume>297</volume>:<fpage>359</fpage>–<lpage>65</lpage>. <object-id pub-id-type="pmid">12130775</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Szyszka</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Ditzen</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Galkin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Galizia</surname> <given-names>CG</given-names></name>, <name name-style="western"><surname>Menzel</surname> <given-names>R</given-names></name>. <article-title>Sparsening and temporal sharpening of olfactory representations in the honeybee mushroom bodies</article-title>. <source>J. Neurophysiol</source>. <year>2005</year>;<volume>94</volume>:<fpage>3303</fpage>–<lpage>13</lpage>. <object-id pub-id-type="pmid">16014792</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gerber</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Tanimoto</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Heisenberg</surname> <given-names>M</given-names></name>. <article-title>An engram found? Evaluating the evidence from fruit flies</article-title>. <source>Curr. Opin. Neurobiol</source>. <year>2004</year>;<volume>14</volume>:<fpage>737</fpage>–<lpage>44</lpage>. <object-id pub-id-type="pmid">15582377</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Menzel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Manz</surname> <given-names>G</given-names></name>. <article-title>Neural plasticity of mushroom body-extrinsic neurons in the honeybee brain</article-title>. <source>J. Exp. Biol</source>. <year>2005</year>;<volume>208</volume>:<fpage>4317</fpage>–<lpage>32</lpage>. <object-id pub-id-type="pmid">16272254</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Strube-Bloss</surname> <given-names>MF</given-names></name>, <name name-style="western"><surname>Nawrot</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Menzel</surname> <given-names>R</given-names></name>. <article-title>Mushroom body output neurons encode odor-reward associations</article-title>. <source>J. Neurosci</source>. <year>2011</year>;<volume>31</volume>:<fpage>3129</fpage>–<lpage>40</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2583-10.2011" xlink:type="simple">10.1523/JNEUROSCI.2583-10.2011</ext-link></comment> <object-id pub-id-type="pmid">21414933</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cassenaer</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Laurent</surname> <given-names>G</given-names></name>. <article-title>Conditional modulation of spike-timing-dependent plasticity for olfactory learning</article-title>. <source>Nature</source>. <year>2012</year>;<volume>482</volume>:<fpage>47</fpage>–<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature10776" xlink:type="simple">10.1038/nature10776</ext-link></comment> <object-id pub-id-type="pmid">22278062</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aso</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hattori</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Johnston</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Iyer</surname> <given-names>NA</given-names></name>, <name name-style="western"><surname>Ngo</surname> <given-names>T-T</given-names></name>, <etal>et al</etal>. <article-title>The neuronal architecture of the mushroom body provides a logic for associative learning</article-title>. <source>Elife</source>. <year>2014</year>;<volume>3</volume>:<fpage>e04577</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.7554/eLife.04577" xlink:type="simple">10.7554/eLife.04577</ext-link></comment> <object-id pub-id-type="pmid">25535793</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Szyszka</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Galkin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Menzel</surname> <given-names>R</given-names></name>. <article-title>Associative and non-associative plasticity in Kenyon cells of the honeybee mushroom body</article-title>. <source>Front. Syst. Neurosci</source>. <year>2008</year>;<volume>2</volume>:<fpage>3</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/neuro.06.003.2008" xlink:type="simple">10.3389/neuro.06.003.2008</ext-link></comment> <object-id pub-id-type="pmid">18958247</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hourcade</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Muenz</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Sandoz</surname> <given-names>J-C</given-names></name>, <name name-style="western"><surname>Rössler</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Devaud</surname> <given-names>J-M</given-names></name>. <article-title>Long-term memory leads to synaptic reorganization in the mushroom bodies: a memory trace in the insect brain?</article-title> <source>J. Neurosci</source>. <year>2010</year>;<volume>30</volume>:<fpage>6461</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0841-10.2010" xlink:type="simple">10.1523/JNEUROSCI.0841-10.2010</ext-link></comment> <object-id pub-id-type="pmid">20445072</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mangan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Webb</surname> <given-names>B</given-names></name>. <article-title>Spontaneous formation of multiple routes in individual desert ants (Cataglyphis velox)</article-title>. <source>Behav. Ecol</source>. <year>2012</year>;<volume>23</volume>:<fpage>944</fpage>–<lpage>54</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laughlin</surname> <given-names>S</given-names></name>. <article-title>A simple coding procedure enhances a neuron’s information capacity</article-title>. <source>Z. Naturforsch. C</source>. <year>1981</year>;<volume>36</volume>:<fpage>910</fpage>–<lpage>2</lpage>. <object-id pub-id-type="pmid">7303823</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Caron</surname> <given-names>SJC</given-names></name>, <name name-style="western"><surname>Ruta</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>, <name name-style="western"><surname>Axel</surname> <given-names>R</given-names></name>. <article-title>Random convergence of olfactory inputs in the Drosophila mushroom body</article-title>. <source>Nature</source>. <year>2013</year>;<volume>497</volume>:<fpage>113</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature12063" xlink:type="simple">10.1038/nature12063</ext-link></comment> <object-id pub-id-type="pmid">23615618</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laurent</surname> <given-names>G</given-names></name>. <article-title>Olfactory network dynamics and the coding of multidimensional signals</article-title>. <source>Nat. Rev. Neurosci</source>. <year>2002</year>;<volume>3</volume>:<fpage>884</fpage>–<lpage>95</lpage>. <object-id pub-id-type="pmid">12415296</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Izhikevich</surname> <given-names>EM</given-names></name>. <article-title>Simple model of spiking neurons</article-title>. <source>IEEE Trans. Neural Networks</source>. <year>2003</year>;<volume>14</volume>:<fpage>1569</fpage>–<lpage>72</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TNN.2003.820440" xlink:type="simple">10.1109/TNN.2003.820440</ext-link></comment> <object-id pub-id-type="pmid">18244602</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pamir</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Chakroborty</surname> <given-names>NK</given-names></name>, <name name-style="western"><surname>Stollhoff</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Gehring</surname> <given-names>KB</given-names></name>, <name name-style="western"><surname>Antemann</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Morgenstern</surname> <given-names>L</given-names></name>, <etal>et al</etal>. <article-title>Average group behavior does not represent individual behavior in classical conditioning of the honeybee</article-title>. <source>Learn. Mem</source>. <year>2011</year>;<volume>18</volume>:<fpage>733</fpage>–<lpage>41</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1101/lm.2232711" xlink:type="simple">10.1101/lm.2232711</ext-link></comment> <object-id pub-id-type="pmid">22042602</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rouder</surname> <given-names>JN</given-names></name>, <name name-style="western"><surname>Speckman</surname> <given-names>PL</given-names></name>, <name name-style="western"><surname>Sun</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Morey</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Iverson</surname> <given-names>G</given-names></name>. <article-title>Bayesian t tests for accepting and rejecting the null hypothesis</article-title>. <source>Psychon. Bull. Rev</source>. <year>2009</year>;<volume>16</volume>:<fpage>225</fpage>–<lpage>37</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3758/PBR.16.2.225" xlink:type="simple">10.3758/PBR.16.2.225</ext-link></comment> <object-id pub-id-type="pmid">19293088</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Willshaw</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Buneman</surname> <given-names>OP</given-names></name>, <name name-style="western"><surname>Longuet-Higgins</surname> <given-names>HC</given-names></name>. <article-title>Non-holographic associative memory</article-title>. <source>Nature</source>. <year>1969</year>;<volume>222</volume>:<fpage>960</fpage>–<lpage>2</lpage>. <object-id pub-id-type="pmid">5789326</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barrett</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Van Rossum</surname> <given-names>MCW</given-names></name>. <article-title>Optimal learning rules for discrete synapses</article-title>. <source>PLoS Comput. Biol</source>. <year>2008</year>;<volume>4</volume>(<issue>11</issue>):<fpage>e1000230</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000230" xlink:type="simple">10.1371/journal.pcbi.1000230</ext-link></comment> <object-id pub-id-type="pmid">19043540</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huerta</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Nowotny</surname> <given-names>T</given-names></name>. <article-title>Fast and robust learning by reinforcement signals: explorations in the insect brain</article-title>. <source>Neural Comput</source>. <year>2009</year>;<volume>21</volume>:<fpage>2123</fpage>–<lpage>51</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2009.03-08-733" xlink:type="simple">10.1162/neco.2009.03-08-733</ext-link></comment> <object-id pub-id-type="pmid">19538091</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsodyks</surname> <given-names>MV</given-names></name>. <article-title>Associative Memory in Neural Networks With Binary Synapses</article-title>. <source>Mod. Phys. Lett. B</source>. <year>1990</year>;<volume>04</volume>:<fpage>713</fpage>–<lpage>6</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huber</surname> <given-names>R</given-names></name>, <article-title>Egocentric and geocentric navigation during extremely long foraging paths of desert ants</article-title>. <source>J.Comp.Physiol.A</source>;<volume>201</volume>:<fpage>609</fpage>–<lpage>616</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kohler</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Wehner</surname> <given-names>R</given-names></name>. <article-title>Idiosyncratic route-based memories in desert ants, Melophorus bagoti: How do they interact with path-integration vectors?</article-title> <source>Neurobiol. Learn. Mem</source>. <year>2005</year>;<volume>83</volume>:<fpage>1</fpage>–<lpage>12</lpage>. <object-id pub-id-type="pmid">15607683</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wystrach</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schwarz</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Schultheiss</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Beugnon</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Cheng</surname> <given-names>K</given-names></name>. <article-title>Views, landmarks, and routes: How do desert ants negotiate an obstacle course?</article-title> <source>J. Comp. Physiol. A Neuroethol. Sensory, Neural, Behav. Physiol</source>. <year>2011</year>;<volume>197</volume>:<fpage>167</fpage>–<lpage>79</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gronenberg</surname> <given-names>W</given-names></name>. <article-title>Subdivisions of hymenopteran mushroom body calyces by their afferent supply</article-title>. <source>J. Comp. Neurol</source>. <year>2001</year>;<volume>435</volume>:<fpage>474</fpage>–<lpage>89</lpage>. <object-id pub-id-type="pmid">11406827</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Seiler</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Wen</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zars</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ito</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Wolf</surname> <given-names>R</given-names></name>, <etal>et al</etal>. <article-title>Distinct memory traces for two visual features in the Drosophila brain</article-title>. <source>Nature</source>. <year>2006</year>;<volume>439</volume>:<fpage>551</fpage>–<lpage>6</lpage>. <object-id pub-id-type="pmid">16452971</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Seelig</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Jayaraman</surname> <given-names>V</given-names></name>. <article-title>Neural dynamics for landmark orientation and angular path integration</article-title>. <source>Nature</source>. <year>2015</year>;<volume>521</volume>:<fpage>186</fpage>–<lpage>91</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature14446" xlink:type="simple">10.1038/nature14446</ext-link></comment> <object-id pub-id-type="pmid">25971509</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heinze</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Homberg</surname> <given-names>U</given-names></name>. <article-title>Maplike representation of celestial E-vector orientations in the brain of an insect</article-title>. <source>Science</source>. <year>2007</year>;<volume>315</volume>:<fpage>995</fpage>–<lpage>7</lpage>. <object-id pub-id-type="pmid">17303756</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Farris</surname> <given-names>SM</given-names></name>. <article-title>Are mushroom bodies cerebellum-like structures?</article-title> <source>Arthropod Struct. Dev</source>. <year>2011</year>;<volume>40</volume>:<fpage>368</fpage>–<lpage>79</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.asd.2011.02.004" xlink:type="simple">10.1016/j.asd.2011.02.004</ext-link></comment> <object-id pub-id-type="pmid">21371566</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gronenberg</surname> <given-names>W</given-names></name>. <article-title>Structure and function of ant (Hymenoptera: Formicidae) brains: strength in numbers</article-title>. <source>Myrmecological News</source>. <year>2008</year>;<volume>11</volume>:<fpage>25</fpage>–<lpage>36</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Steck</surname> <given-names>K</given-names></name>. <article-title>Just follow your nose: Homing by olfactory cues in ants</article-title>. <source>Curr. Opin. Neurobiol</source>. <year>2012</year>;<volume>22</volume>:<fpage>231</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2011.10.011" xlink:type="simple">10.1016/j.conb.2011.10.011</ext-link></comment> <object-id pub-id-type="pmid">22137100</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wolf</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Wehner</surname> <given-names>R</given-names></name>. <article-title>Pinpointing food sources: olfactory and anemotactic orientation in desert ants, Cataglyphis fortis</article-title>. <source>J. Exp. Biol</source>. <year>2000</year>;<volume>203</volume>:<fpage>857</fpage>–<lpage>68</lpage>. <object-id pub-id-type="pmid">10667968</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Seidl</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Wehner</surname> <given-names>R</given-names></name>. <article-title>Visual and tactile learning of ground structures in desert ants</article-title>. <source>J. Exp. Biol</source>. <year>2006</year>;<volume>209</volume>:<fpage>3336</fpage>–<lpage>44</lpage>. <object-id pub-id-type="pmid">16916970</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rao</surname> <given-names>RPN</given-names></name>, <name name-style="western"><surname>Fuentes</surname> <given-names>O</given-names></name>. <article-title>Hierarchical Learning of Navigational Behaviors in an Autonomous Robot using a Predictive Sparse Distributed Memory</article-title>. <source>Mach. Learn</source>. <year>1998</year>;<volume>31</volume>:<fpage>87</fpage>–<lpage>113</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stürzl</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Zeil</surname> <given-names>J</given-names></name>. <article-title>Depth, contrast and view-based homing in outdoor scenes</article-title>. <source>Biol. Cybern</source>. <year>2007</year>;<volume>96</volume>:<fpage>519</fpage>–<lpage>31</lpage>. <object-id pub-id-type="pmid">17443340</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ardin</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Mangan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Wystrach</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Webb</surname> <given-names>B</given-names></name>. <article-title>How variation in head pitch could affect image matching algorithms for ant navigation</article-title>. <source>J. Comp. Physiol. A</source>. <year>2015</year>;<volume>201</volume>:<fpage>585</fpage>–<lpage>97</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raderschall</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Narendra</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zeil</surname> <given-names>J</given-names></name>. <article-title>Balancing act: Head stabilisation in Myrmecia ants during twilight</article-title>. <source>Int. Union Study Soc. Insects</source>. <year>2014</year>. p. <fpage>P192</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref070"><label>70</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>von Frish</surname> <given-names>K</given-names></name>. <source>The dance language and orientation of bees</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>; <year>1967</year>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nicholson</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Judd</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Cartwright</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Collett</surname> <given-names>T</given-names></name>. <article-title>Learning walks and landmark guidance in wood ants (Formica rufa)</article-title>. <source>J. Exp. Biol</source>. <year>1999</year>;<volume>202</volume> (<issue>Pt 13</issue>:<fpage>1831</fpage>–<lpage>8</lpage>. <object-id pub-id-type="pmid">10359685</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stürzl</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Grixa</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Mair</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Narendra</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zeil</surname> <given-names>J</given-names></name>. <article-title>Three-dimensional models of natural environments and the mapping of navigational information</article-title>. <source>J. Comp. Physiol. A</source>. <year>2015</year>;<volume>201</volume>:<fpage>563</fpage>–<lpage>84</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Narendra</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Gourmaud</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Zeil</surname> <given-names>J</given-names></name>. <article-title>Mapping the navigational knowledge of individually foraging ants, Myrmecia croslandi</article-title>. <source>Proc. R. Soc. B Biol. Sci</source>. <year>2013</year>;<volume>280</volume>:<fpage>20130683</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref074"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wystrach</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Mangan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Webb</surname> <given-names>B</given-names></name>. <article-title>Optimal cue integration in ants</article-title>. <source>Proc. R. Soc. B Biol. Sci</source>. <year>2015</year>;</mixed-citation></ref>
<ref id="pcbi.1004683.ref075"><label>75</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Legge</surname> <given-names>ELG</given-names></name>, <name name-style="western"><surname>Wystrach</surname> <given-names>a.</given-names></name>, <name name-style="western"><surname>Spetch</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Cheng</surname> <given-names>K</given-names></name>. <article-title>Combining sky and earth: desert ants (Melophorus bagoti) show weighted integration of celestial and terrestrial cues</article-title>. <source>J. Exp. Biol</source>. <year>2014</year>;<volume>217</volume>:<fpage>4159</fpage>–<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1242/jeb.107862" xlink:type="simple">10.1242/jeb.107862</ext-link></comment> <object-id pub-id-type="pmid">25324340</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref076"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Collett</surname> <given-names>M</given-names></name>. <article-title>How navigational guidance systems are combined in a desert ant</article-title>. <source>Curr. Biol. Elsevier</source>; <year>2012</year>;<volume>22</volume>:<fpage>927</fpage>–<lpage>32</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004683.ref077"><label>77</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reid</surname> <given-names>SF</given-names></name>, <name name-style="western"><surname>Narendra</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hemmi</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Zeil</surname> <given-names>J</given-names></name>. <article-title>Polarised skylight and the landmark panorama provide night-active bull ants with compass information during route following</article-title>. <source>J. Exp. Biol</source>. <year>2011</year>;<volume>214</volume>:<fpage>363</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1242/jeb.049338" xlink:type="simple">10.1242/jeb.049338</ext-link></comment> <object-id pub-id-type="pmid">21228195</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref078"><label>78</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Izhikevich</surname> <given-names>EM</given-names></name>. <article-title>Which model to use for cortical spiking neurons?</article-title> <source>IEEE Trans. Neural Networks</source>. <year>2004</year>;<volume>15</volume>:<fpage>1063</fpage>–<lpage>70</lpage>. <object-id pub-id-type="pmid">15484883</object-id></mixed-citation></ref>
<ref id="pcbi.1004683.ref079"><label>79</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Izhikevich</surname> <given-names>EM</given-names></name>. <article-title>Solving the distal reward problem through linkage of STDP and dopamine signaling</article-title>. <source>Cereb. Cortex</source>. <year>2007</year>;<volume>17</volume>:<fpage>2443</fpage>–<lpage>52</lpage>. <object-id pub-id-type="pmid">17220510</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
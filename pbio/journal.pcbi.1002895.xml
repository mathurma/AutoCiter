<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">plos</journal-id>
      <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
      <journal-id journal-id-type="pmc">ploscomp</journal-id>
      <journal-title-group>
        <journal-title>PLoS Computational Biology</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1553-734X</issn>
      <issn pub-type="epub">1553-7358</issn>
      <publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">PCOMPBIOL-D-12-01046</article-id>
      <article-id pub-id-type="doi">10.1371/journal.pcbi.1002895</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Cognitive neuroscience</subject>
              <subj-group>
                <subject>Decision making</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Behavioral neuroscience</subject>
              <subject>Computational neuroscience</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Decision theory</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Social and behavioral sciences</subject>
          <subj-group>
            <subject>Psychology</subject>
            <subj-group>
              <subject>Cognitive psychology</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
          <subject>Mathematics</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Activity in Inferior Parietal and Medial Prefrontal Cortex Signals the Accumulation of Evidence in a Probability Learning Task</article-title>
        <alt-title alt-title-type="running-head">Accumulation of Evidence for Probabilistic Events</alt-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>d'Acremont</surname>
            <given-names>Mathieu</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Fornari</surname>
            <given-names>Eleonora</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Bossaerts</surname>
            <given-names>Peter</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <label>1</label>
        <addr-line>Computation and Neural Systems, California Institute of Technology, Pasadena, California, United States of America</addr-line>
      </aff>
      <aff id="aff2">
        <label>2</label>
        <addr-line>Department of Radiology, CHUV and University of Lausanne, Lausanne, Switzerland</addr-line>
      </aff>
      <contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Behrens</surname>
            <given-names>Tim</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group>
      <aff id="edit1">
        <addr-line>University of Oxford, United Kingdom</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">dacremon@hss.caltech.edu</email></corresp>
        <fn fn-type="conflict">
          <p>The authors have declared that no competing interests exist.</p>
        </fn>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: MdA PB. Performed the experiments: MdA EF. Analyzed the data: MdA EF PB. Wrote the paper: MdA PB.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="collection">
        <month>1</month>
        <year>2013</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>31</day>
        <month>1</month>
        <year>2013</year>
      </pub-date>
      <volume>9</volume>
      <issue>1</issue>
      <elocation-id>e1002895</elocation-id>
      <history>
        <date date-type="received">
          <day>25</day>
          <month>6</month>
          <year>2012</year>
        </date>
        <date date-type="accepted">
          <day>7</day>
          <month>12</month>
          <year>2012</year>
        </date>
      </history>
      <permissions>
        <copyright-year>2013</copyright-year>
        <copyright-holder>d'Acremont et al</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>In an uncertain environment, probabilities are key to predicting future events and making adaptive choices. However, little is known about how humans learn such probabilities and where and how they are encoded in the brain, especially when they concern more than two outcomes. During functional magnetic resonance imaging (fMRI), young adults learned the probabilities of uncertain stimuli through repetitive sampling. Stimuli represented payoffs and participants had to predict their occurrence to maximize their earnings. Choices indicated loss and risk aversion but unbiased estimation of probabilities. BOLD response in medial prefrontal cortex and angular gyri increased linearly with the probability of the currently observed stimulus, untainted by its value. Connectivity analyses during rest and task revealed that these regions belonged to the default mode network. The activation of past outcomes in memory is evoked as a possible mechanism to explain the engagement of the default mode network in probability learning. A BOLD response relating to value was detected only at decision time, mainly in striatum. It is concluded that activity in inferior parietal and medial prefrontal cortex reflects the amount of evidence accumulated in favor of competing and uncertain outcomes.</p>
      </abstract>
      <abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>In order to make adaptive choices, people need to gather evidence to predict what will happen next. In general, the more frequently an event is observed, the more likely it will occur in the future. Thus the probability of an event is useful to predict its future occurrence. Previous studies have identified regions in the brain that react to rewarding or surprising events, but not to likely events. In the present study, participants had to predict payoffs by observing their repeated occurrence. Functional imaging showed that brain activity in inferior parietal and medial prefrontal cortex increased if the currently observed payoff had been seen many times before. This suggests that these two cortical regions accumulate evidence to predict future events. Further analyses revealed that they belonged to the larger default mode network. This network is involved in introspection and remembering. The inferior parietal and medial prefrontal cortex might thus support the prediction of future events by activating memories of past events.</p>
      </abstract>
      <funding-group>
        <funding-statement>The study was supported by the AXA Insurance Research Fund, Centre d'Imagerie BioMédicale of the University of Lausanne, Centre Hospitalier Universitaire Vaudois, Ecole Polytechnique Fédérale de Lausanne, University of Geneva, Hopitaux Universitaires de Genève, the Leenaards and Jeantet Foundations, and the Swiss Finance Institute. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
      </funding-group>
      <counts>
        <page-count count="11"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>In an uncertain environment, probabilities are crucial information because they improve prediction of future events. For humans, information about the likelihood of events can be described with abstract symbols, for instance with a verbal sentence or a pie chart. But in many situations, probabilities are learned through experience by observing the occurrence of events <xref ref-type="bibr" rid="pcbi.1002895-Hertwig1">[1]</xref>. Animals can only learn probabilities through experience as they have no access to language. Thus understanding how information about probabilities is acquired in the brain is a fundamental question in decision neuroscience for both humans and animals.</p>
      <p>In the present study, we focused on the probability of events independently of their value. The motivation came from the observation that people can memorize, make predictions, and decide in the absence of immediate reinforcements. This ability to build a representation of the environment independently of the rewards to be received is made explicit in model-based reinforcement learning <xref ref-type="bibr" rid="pcbi.1002895-Sutton1">[2]</xref>. In addition, a separate estimation of probability and value is necessary to ensure rational choices <xref ref-type="bibr" rid="pcbi.1002895-Savage1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Machina1">[4]</xref>. This principle called “probabilistic sophistication” might seem counter-intuitive because probabilities are combined with values to estimate expected value in many decision models (e.g., expected utility). Nevertheless, the fact that probabilities and values are multiplied does not contradict the necessity to estimate them independently. The concept of probabilistic sophistication is illustrated in <xref ref-type="fig" rid="pcbi-1002895-g001">Fig. 1</xref>.</p>
      <fig id="pcbi-1002895-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002895.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Probabilistic sophistication.</title>
          <p>A separate estimation of probability and value is necessary to guarantee rational choices in decision theory. This separation also offers more flexibility in goal oriented decisions. Indeed, the subjective values of events change with our goals but not their probabilities of occurrence which are controlled by the environment (or the response of the environment to our actions). For instance, a person is trying to estimate the probability that it will rain. On the left side of the figure, she wants to water her garden. Thus “rain” is a positive event relative to her goal. On the right side, she wants to go for a bike ride. Thus “rain” is a negative event. It can be seen that the subjective value of “rain” changes with personal goals but not the chance it will rain. Therefore, it would be adaptive for the brain to encode the probabilities and values of events separately.</p>
        </caption>
        <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002895.g001" position="float" xlink:type="simple"/>
      </fig>
      <p>In psychology, there has been a long tradition of research showing that people can learn the probabilities of stimuli with no value like neutral words or symbols <xref ref-type="bibr" rid="pcbi.1002895-Beach1">[5]</xref>–<xref ref-type="bibr" rid="pcbi.1002895-Gardner1">[7]</xref>. In neuroscience, this type of inference has been studied with categorization tasks <xref ref-type="bibr" rid="pcbi.1002895-Knowlton1">[8]</xref>. In the weather prediction task for instance, participants have to predict the occurrence of two probabilistic outcomes through trial and error (e.g., sunshine or rain). The probability of the outcome is conditional on a set of four symbols. When comparing this task to a control condition, authors have found activation in a large network including the medial and lateral prefrontal cortex, inferior parietal cortex, posterior cingulate cortex and striatum <xref ref-type="bibr" rid="pcbi.1002895-Poldrack1">[9]</xref>–<xref ref-type="bibr" rid="pcbi.1002895-Weickert1">[11]</xref>. A limitation of these studies is the use of a subtraction instead of a parametric approach. It is thus unknown if regions in the brain encode the probability of the outcome in this task.</p>
      <p>Following a parametric approach, authors have observed a larger BOLD response in striatum and ventro medial prefrontal cortex when the probability of an anticipated reward increased <xref ref-type="bibr" rid="pcbi.1002895-Tobler1">[12]</xref>–<xref ref-type="bibr" rid="pcbi.1002895-Hsu1">[14]</xref>. These results have been interpreted in terms of value because for a single and uncertain reward, probability and expected value are positively correlated. Other regions of the brain, like the parietal cortex and the amygdala, have been found to increase with the probability of an upcoming punishment <xref ref-type="bibr" rid="pcbi.1002895-Berns1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Yacubian1">[16]</xref>. To support probabilistic sophistication however, one has to identify structures in the brain which encode probability independently of value.</p>
      <p>The effect of value can be controlled for by relating brain activity to the probabilities of events and making sure these probabilities do not covary with reward expectation. An event can be defined as a stimulus, its omission, a feed-back and so on. In reinforcement learning studies, authors have shown a larger BOLD response to the occurrence of rare events <xref ref-type="bibr" rid="pcbi.1002895-Strange1">[17]</xref>–<xref ref-type="bibr" rid="pcbi.1002895-Fletcher1">[19]</xref>. Activity has generally been found in the lateral parietal and prefrontal cortex. Using EEG, numerous studies have shown an enhanced brain response (P300) to rare target in the odd ball paradigm <xref ref-type="bibr" rid="pcbi.1002895-DuncanJohnson1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Mars1">[21]</xref>. It should be noted that in these fMRI and EEG studies, brain activity was not always related to the probability of the outcome, but to other measures like surprise or “state” prediction error (one minus the estimated probability of the outcome). However, these measures are highly and negatively correlated with probability. If the surprise or state prediction error is large, the outcome probability is low.</p>
      <p>The brain response to rare events has been explained by associative learning theory (as a prediction error) <xref ref-type="bibr" rid="pcbi.1002895-Glascher1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Fletcher1">[19]</xref> or statistical inference (as a Bayesian surprise) <xref ref-type="bibr" rid="pcbi.1002895-Strange1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Mars1">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Friston1">[22]</xref>. In a learning context however, we are not aware of experiments showing a positive correlation between brain activity and event probabilities. This is surprising because several models explain choices as the result of evidence accumulation <xref ref-type="bibr" rid="pcbi.1002895-Ratcliff1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Heekeren1">[24]</xref>. When the environment is stable (probabilities do not change overtime), the past occurrence of an uncertain stimulus constitutes evidence for its future occurrence.</p>
      <p>In a perceptual decision-making task, the agent has to make a decision based on a noisy signal. Several studies in monkeys have shown that the firing rate of neurons in the lateral intraparietal cortex increased over time as a function of the proportion of dots moving in the same direction <xref ref-type="bibr" rid="pcbi.1002895-Huk1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Shadlen1">[26]</xref> and this pattern is well explained with artificial neural networks <xref ref-type="bibr" rid="pcbi.1002895-Beck1">[27]</xref>. In these studies, accumulation of evidence is observed by recording the firing rates of neurons with a specific response field <xref ref-type="bibr" rid="pcbi.1002895-Shadlen1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Yang1">[28]</xref>. With fMRI, the researcher only has access to the activation of a large population of neurons and evidence accumulated by neurons of one response field (e.g left direction) might cancel out the evidence accumulated by neurons sensitive to a different response field (e.g. right direction).</p>
      <p>In a probability learning task evidence is not presented simultaneously but one after another. This offers the opportunity to relate brain activity to the characteristic of the currently observed evidence (which serves as a probe). If the evidence has been observed many times, retrieval models based on accumulation processes predict a stronger brain response because the probe matches numerous traces of past outcomes in memory <xref ref-type="bibr" rid="pcbi.1002895-Ratcliff2">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Murdock1">[30]</xref>. In neuroscience, it has been proposed that the inferior parietal cortex plays the role of a mnemonic accumulator because this area is more activated during the successful recognition of old versus new items <xref ref-type="bibr" rid="pcbi.1002895-Wagner1">[31]</xref>–<xref ref-type="bibr" rid="pcbi.1002895-Shimamura1">[33]</xref>. Other regions of the default mode network (medial temporal lobes, medial prefrontal cortex, posterior cingulate cortex) have been found to be more activated for objects which are easily associated to a specific context compared to objects eliciting weak association <xref ref-type="bibr" rid="pcbi.1002895-Bar1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Bar2">[35]</xref>. According to the principle of an accumulation of evidence in memory, a positive BOLD response can be expected for likely events, particularly in the default mode network.</p>
      <p>Overall, studies have identified regions in the brain where activity increased with the probability of a single and random reward. BOLD response related to reward probability has been observed, mainly in striatum <xref ref-type="bibr" rid="pcbi.1002895-Tobler1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Yacubian2">[36]</xref> and ventro medial prefrontal cortex <xref ref-type="bibr" rid="pcbi.1002895-Behrens1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Boorman1">[37]</xref>. However, when the effect of value was controlled for, an increase of activity in response to unlikely outcomes has been found in lateral parietal and lateral prefrontal cortex <xref ref-type="bibr" rid="pcbi.1002895-Strange1">[17]</xref>–<xref ref-type="bibr" rid="pcbi.1002895-Fletcher1">[19]</xref>. As such, previous studies on learning have shown that the brain reacts to rewarding or rare events but not to likely events. This conflicts with models of perception and memory <xref ref-type="bibr" rid="pcbi.1002895-Beck1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Ratcliff2">[29]</xref> where activity increases with the accumulation of evidence. In a probability learning task, we found that activity in bilateral inferior parietal and medial prefrontal cortex increased for events which had been observed many times and were likely to occur again.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Rational of the task</title>
        <p>We developed a task where evidence for future outcomes were balls drawn from a bin. The bin contained balls of different colors and each color was associated to a payoff (<xref ref-type="fig" rid="pcbi-1002895-g002">Fig. 2a</xref>). The composition of the bin was hidden, therefore payoff probabilities were unknown to the participants. However, they had the opportunity to learn these probabilities by observing 10 to 14 drawings from the bin. Balls were sampled one after another with replacement and shown in the center of the bin. The sample payoff was displayed but not the color of the ball. Thus colors were hidden states and payoffs were stimuli (Top insert, <xref ref-type="fig" rid="pcbi-1002895-g002">Fig. 2b</xref>). Colors could be inferred from payoffs because the color-payoff association was shown to the participants in the periphery of the bin. After the 10 to 14 draws, this association changed while color probabilities remained constant. In this resampling phase, 10 to 14 balls were drawn again.</p>
        <fig id="pcbi-1002895-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002895.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Task design.</title>
            <p>(<bold>a</bold>) Payoffs were determined by the colors of balls drawn from a bin. In two sampling stages, participants had the opportunity to learn probabilities by observing several drawings. Payoffs were shown in the center of the screen (stimuli). Colors were not displayed (hidden states). After each sampling stage, participants had to decide to buy the gamble or not for a certain price. In the initial sampling stage, both the composition of the bin and the color-payoff association were new. In the resampling stage, the composition of the bin remained the same (same color probabilities) but the associated payoffs were new. (<bold>b</bold>) <bold>Top insert.</bold> The color-payoff association changed in the resampling stage. <bold>Histograms.</bold> These are the true probabilities used to generate the drawings for bins with 2, 5, or 10 colors.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002895.g002" position="float" xlink:type="simple"/>
        </fig>
        <p>At the end of the sampling and resampling phases, participants had to decide to buy or not a gamble for a certain price. After their choice, the payoff was determined by drawing an additional ball from the bin. If participants decided to buy, they earned the price minus the payoff (this net payoff could be negative). If they decided to pass, the net payoff was 0. To maximize their earning, it was optimal for them to predict the payoffs (stimuli) based on the colors (hidden states). Participants learned the probability of 2, 5, or 10 payoffs (Histograms, <xref ref-type="fig" rid="pcbi-1002895-g002">Fig. 2b</xref>).</p>
        <p>For the main analysis, brain activity in the sampling stages was regressed on the probability of the currently observed stimulus, that is the probability of seeing the evidence. Probabilities of stimuli were orthogonal to their values and the value to be expected at the end of the sampling or resampling period. For instance, if a red ball was associated with a low payoff, sampling a red ball increased the probability of seeing this low payoff, but it decreased the expected payoff. The independence between probability and value was obtained by randomly assigning payoffs to colors.</p>
      </sec>
      <sec id="s2b">
        <title>Behavioral choice</title>
        <p>To decide whether to buy the gamble for a certain price or to pass it, participants had to predict the gamble payoff at the end of each sampling stage. Analysis was conducted to determine from gamble choices whether participants estimated probabilities based on the color or payoff history (Fig. S1 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). If inference is based on colors (hidden states), it can be concluded that people are able to make abstraction of rewards when estimating the likelihood of future outcomes. When extracting probabilities from choices, one needs to control for attitudes towards uncertainty. We did so in a generally accepted way, using prospect theory, which allows one to separately control for loss aversion (“losses loom larger than gains”) and differential risk attitudes.</p>
        <p>When a new bin was introduced, initial beliefs were set to equiprobable priors, and subsequent updating was assumed to follow Bayes' law. The posterior stimulus probability increased with the accumulation of evidence. At the end of each sampling stage, probabilities and payoff magnitudes (net of the price) were combined to compute gamble expected value according to prospect theory principles. The decision to buy was predicted from valuation with a logistic regression. We compared models with the Bayesian Information Criterion (BIC), because it can be used with non-nested models and limits the risk of over-fit by penalizing free parameters (a lower BIC is better). Models are indexed by the number of free parameter (M2, M3, etc.) and are presented in the <italic>Methods</italic> section below.</p>
        <p>The most efficient model (the best compromise between parsimony and fitting) was a model with payoff probabilities calculated conditional on the colors of the balls drawn since the presentation of a new bin (model M4, BIC = 1250, <xref ref-type="table" rid="pcbi-1002895-t001">Table 1</xref>). Colors were hidden states but could be inferred from the observed payoffs. It was more efficient than a model with payoff probabilities calculated conditional on the payoffs observed since the beginning of the sampling or resampling stage (M4a, BIC = 1271). In this model, participants ignore colors and have to re-estimate probabilities after the payoff-color association changed. Further analyses at the individual level showed that model M4 offered a better fit than M4a for all participants (section <italic>Behavioral choice</italic> &amp; Fig. S2 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). Thus all participants appeared to be “sophisticated”: their inference was indirect, based on the hidden states behind the observed payoffs, rather than on the observed payoffs directly. Model M4 was more efficient than a model which did not update payoff probabilities (M4b, BIC = 1354). In this latter model, participants used equiprobable payoffs to make decisions (absence of learning).</p>
        <table-wrap id="pcbi-1002895-t001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002895.t001</object-id>
          <label>Table 1</label>
          <caption>
            <title>Choice models.</title>
          </caption>
          <alternatives>
            <graphic id="pcbi-1002895-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002895.t001" xlink:type="simple"/>
            <table>
              <colgroup span="1">
                <col align="left" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Probability Model</td>
                  <td align="left" rowspan="1" colspan="1">
                    <italic>Value</italic>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <italic>Probability</italic>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <italic>Inference</italic>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <italic>BIC</italic>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e001" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e002" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e003" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e004" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e005" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" rowspan="1" colspan="1">M2</td>
                  <td align="left" rowspan="1" colspan="1">Linear</td>
                  <td align="left" rowspan="1" colspan="1">Linear</td>
                  <td align="left" rowspan="1" colspan="1">Hidden states</td>
                  <td align="left" rowspan="1" colspan="1">1312</td>
                  <td align="left" rowspan="1" colspan="1">−0.49</td>
                  <td align="left" rowspan="1" colspan="1">0.38</td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">M4<xref ref-type="table-fn" rid="nt101">*</xref></td>
                  <td align="left" rowspan="1" colspan="1">Non-linear</td>
                  <td align="left" rowspan="1" colspan="1">Linear</td>
                  <td align="left" rowspan="1" colspan="1">Hidden states</td>
                  <td align="left" rowspan="1" colspan="1">1250</td>
                  <td align="left" rowspan="1" colspan="1">0.95</td>
                  <td align="left" rowspan="1" colspan="1">0.54</td>
                  <td align="left" rowspan="1" colspan="1">2.57</td>
                  <td align="left" rowspan="1" colspan="1">0.69</td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">M4a</td>
                  <td align="left" rowspan="1" colspan="1">Non-linear</td>
                  <td align="left" rowspan="1" colspan="1">Linear</td>
                  <td align="left" rowspan="1" colspan="1">Observations</td>
                  <td align="left" rowspan="1" colspan="1">1271</td>
                  <td align="left" rowspan="1" colspan="1">1.00</td>
                  <td align="left" rowspan="1" colspan="1">0.53</td>
                  <td align="left" rowspan="1" colspan="1">2.66</td>
                  <td align="left" rowspan="1" colspan="1">0.68</td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">M4b</td>
                  <td align="left" rowspan="1" colspan="1">Non-linear</td>
                  <td align="left" rowspan="1" colspan="1">Linear</td>
                  <td align="left" rowspan="1" colspan="1">No learning</td>
                  <td align="left" rowspan="1" colspan="1">1354</td>
                  <td align="left" rowspan="1" colspan="1">0.51</td>
                  <td align="left" rowspan="1" colspan="1">1.31</td>
                  <td align="left" rowspan="1" colspan="1">1.69</td>
                  <td align="left" rowspan="1" colspan="1">0.44</td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">M5</td>
                  <td align="left" rowspan="1" colspan="1">Non-linear</td>
                  <td align="left" rowspan="1" colspan="1">Non-linear</td>
                  <td align="left" rowspan="1" colspan="1">Hidden states</td>
                  <td align="left" rowspan="1" colspan="1">1251</td>
                  <td align="left" rowspan="1" colspan="1">1.00</td>
                  <td align="left" rowspan="1" colspan="1">0.59</td>
                  <td align="left" rowspan="1" colspan="1">2.55</td>
                  <td align="left" rowspan="1" colspan="1">0.63</td>
                  <td align="left" rowspan="1" colspan="1">0.89</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">
                    <bold>Reinforcement Model</bold>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <italic>
                      <bold>Value</bold>
                    </italic>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <italic>
                      <bold>Probability</bold>
                    </italic>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <italic>
                      <bold>Inference</bold>
                    </italic>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <italic>
                      <bold>BIC</bold>
                    </italic>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e006" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e007" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e008" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1"/>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">M3</td>
                  <td align="left" rowspan="1" colspan="1">Linear</td>
                  <td align="left" rowspan="1" colspan="1">Ignored</td>
                  <td align="left" rowspan="1" colspan="1">Observations</td>
                  <td align="left" rowspan="1" colspan="1">1428</td>
                  <td align="left" rowspan="1" colspan="1">−0.39</td>
                  <td align="left" rowspan="1" colspan="1">0.31</td>
                  <td align="left" rowspan="1" colspan="1">0.17</td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="nt101">
              <label>*</label>
              <p>Best efficiency; Nbr. data = 1648; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e009" xlink:type="simple"/></inline-formula> = intercept, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e010" xlink:type="simple"/></inline-formula> = slope, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e011" xlink:type="simple"/></inline-formula> = loss aversion, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e012" xlink:type="simple"/></inline-formula> = diminishing sensitivity, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e013" xlink:type="simple"/></inline-formula> = probability weighting, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e014" xlink:type="simple"/></inline-formula> = learning rate; Tversky et al., 1992: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e015" xlink:type="simple"/></inline-formula> = 2.25, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e016" xlink:type="simple"/></inline-formula> = 0.88/0.88 (gain/loss), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e017" xlink:type="simple"/></inline-formula> = 0.61/0.69; Hau et al., 08: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e018" xlink:type="simple"/></inline-formula> = 0.94/0.86, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e019" xlink:type="simple"/></inline-formula> = 0.99/0.93.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>Model M4 included a prospect theory value function. It was more efficient than a simpler model using a linear value function (M2, BIC = 1312). The shape of the estimated non-linear function revealed diminishing sensitivity for large payoffs (either positive or negative) and greater importance of losses compared to gains. Decision parameters found in previous studies are reported in the footnote of <xref ref-type="table" rid="pcbi-1002895-t001">Table 1</xref>. Loss aversion was close to the estimation by Tversky and Kahneman in a study made on decisions from description <xref ref-type="bibr" rid="pcbi.1002895-Tversky1">[38]</xref>. Diminishing sensitivity was more pronounced in the present study (<xref ref-type="fig" rid="pcbi-1002895-g003">Fig. 3a</xref>).</p>
        <fig id="pcbi-1002895-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002895.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Value and probability functions.</title>
            <p>(<bold>a</bold>) Value function as estimated from participants' decisions (red, model M4.) Estimation obtained by Tversky and Kahneman (1992) in a study on decisions from description. (<bold>b</bold>) Probability weighting inferred from choices (red, model M5) and comparison with estimations from other studies in the gain and loss domains (Gain - Hau et al., 2008 is confounded with the linear function.) (<bold>c</bold>) <bold>Top insert</bold>. To avoid circularity, ROIs for each individual were determined based on the data of all other participants. ROI voxels common to all participants are shown in yellow. ROI voxels belonging to at least one participant are shown in red. This representation shows to which extent the ROI definitions vary in the cross-validation. <bold>Main</bold>. Increase of BOLD response with stimulus probabilities in medial prefrontal cortex and angular gyri during the learning phase. Data of the 3 ROIs has been merged. The y axis indicates the effect the presentation of new stimulus (payoff) had in the ROIs. The effect increased with the probability of the currently observed stimulus. The non-linear regression (red) includes a probability weighting function.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002895.g003" position="float" xlink:type="simple"/>
        </fig>
        <p>Model M4 was more efficient than a model that included a prospect theory probability weighting function (M5, BIC = 1251). Indeed, the later model led to a quasi-linear function. We also report the estimation found in decisions from description by Tversky and Kahneman <xref ref-type="bibr" rid="pcbi.1002895-Tversky1">[38]</xref> and in decisions from experience by Hau et al. <xref ref-type="bibr" rid="pcbi.1002895-Hau1">[39]</xref>. Probability weighting appears to be minimal in decisions from experience (<xref ref-type="fig" rid="pcbi-1002895-g003">Fig. 3b</xref>).</p>
        <p>Finally a reinforcement learning algorithm was estimated (M3). The first payoff observed at the beginning of the sampling or resampling period defined the initial forecast. Then each new payoff was compared to the previous forecast to compute a prediction error. This prediction error multiplied by a learning rate was added to the previous forecast to find the new forecast. This model used a linear value function and bypassed probabilities in order to directly estimate the expected payoff of the gamble. Results showed it had the lowest efficiency (BIC = 1428). Thus probability-based models offered a better explanation of decisions than a reinforcement algorithm.</p>
        <p>In sum, the analysis of choices indicated that participants were loss and risk averse (non-linear value function), but there was no indication of a distortion of probabilities (linear probability weighting function). Supporting the principle of probabilistic sophistication, participants learned probabilities based on the hidden states and not simply the observed payoffs. A reinforcement learning model tracking payoffs to estimate gamble values performed worse than any of the probability-based models.</p>
      </sec>
      <sec id="s2c">
        <title>Brain response to stimulus probabilities</title>
        <p>The threshold for significance was set at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e020" xlink:type="simple"/></inline-formula>, uncorrected, cluster <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e021" xlink:type="simple"/></inline-formula> voxels for voxel-based analyses (including the identification of ROIs). False Discovery Rates (FDRs) are reported in tables, to gauge the risk of false-positive results. Coordinates are given in MNI space [mm]. The threshold was set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e022" xlink:type="simple"/></inline-formula> to analyze mean activation in ROIs. Circularity in ROI analysis was avoided with cross-validation. Subject variability was modeled as a random factor in voxel-based and ROI analyses. Details on the GLMs (GLM1, GLM2, etc.) are given in the <italic>Brain analysis</italic> section of <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>.</p>
        <p>The display of a new payoff in the center of the bin is referred as a stimulus and gives evidence for future outcomes. Stimuli were defined as 1 [s] events and led to a significant activation in the occipital cortex and bilateral hippocampus (GLM1, Table S1 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>).</p>
        <p>Probabilities inferred from the history of the hidden states were entered as a covariate to modulate the effect of stimuli (model M4). For instance in <xref ref-type="fig" rid="pcbi-1002895-g002">Fig. 2a</xref> (Resampling), when “68” was displayed the probability of seeing “68” was used as a parametric covariate. When “46” was displayed the probability of seeing “46” was used instead. Thus analyses were conducted with the probability of the currently observed stimulus. Probabilities estimated with model M4 ranged from 0.08 to 0.92. The probability of the stimulus did not correlate with its associated payoff magnitude (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e023" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e024" xlink:type="simple"/></inline-formula>) or the gamble expected payoff (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e025" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e026" xlink:type="simple"/></inline-formula>). This is because payoffs were randomly assigned to colors which in turn were randomly assigned to probabilities. For example, in <xref ref-type="fig" rid="pcbi-1002895-g002">Fig. 2a</xref> (Resampling), the stimulus “46”, which was the lowest payoff in the bin, could have a low or high probability of occurrence because it was randomly assigned to the color blue. There is thus no confound between probability and value in our design.</p>
        <p>Results showed a positive and significant effect of stimulus probabilities medially in the prefrontal cortex and bilaterally in the angular gyrus (<xref ref-type="fig" rid="pcbi-1002895-g004">Fig. 4a+b</xref>, Table S2 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). In these regions, brain activity increased when a stimulus was likely to be observed (confirmatory signal). A negative and significant effect of probabilities was also observed in the occipital, superior parietal, and middle frontal gyrus. Activity in the middle frontal gyrus was posterior and reached the precentral gyrus (Fig. S3a in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). A significant effect was also observed in the bilateral hippocampus (Table S3 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). In these regions, brain activity increased when a stimulus – learned to be rare – was observed (surprise signal). Activation related to stimulus probabilities survived correction for multiple comparisons, except in the hippocampus (FWE, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e027" xlink:type="simple"/></inline-formula>).</p>
        <fig id="pcbi-1002895-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002895.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Learning phase.</title>
            <p>(<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e028" xlink:type="simple"/></inline-formula>, uncorr.) Volume (<bold>a</bold>) and sectional (<bold>b</bold>) views of the BOLD response to stimulus probabilities in medial prefrontal cortex and bilateral angular gyrus. Activity increases with the probability of the currently observed stimulus. (<bold>c</bold>) Voxels showing increased connectivity with angular gyri and medial prefrontal cortex ROIs compared to the resting phase.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002895.g004" position="float" xlink:type="simple"/>
        </fig>
        <p>When a payoff was displayed in the sampling or resampling period, it generated a prediction error. This prediction error was calculated with model M4 as the change in expected value before and after the new payoff was revealed. Results indicated that prediction errors did not increase or decrease the effect of stimuli on the brain (GLM2, no table or figure was reported for this non-significant covariate). Thus, the brain encoded stimulus probabilities but not values during the learning phase. We used the sign of the prediction error to define positive and negative stimuli (GLM3). Results showed BOLD response to probabilities in the angular gyri and medial prefrontal cortex for both positive and negative stimuli (Tables S4 &amp; S5 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). Thus, the encoding of probabilities was comparable for positive and negative stimuli. In short, it appeared that during the learning phase the brain ignored values (probabilistic sophistication) and focused on probabilities.</p>
        <p>A BOLD response to unlikely stimuli has been reported in the literature <xref ref-type="bibr" rid="pcbi.1002895-Strange1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Fletcher1">[19]</xref>. The BOLD response to likely stimuli is novel. We will focus on this positive correlation in the rest of the results. ROIs were defined as the cluster of voxel significantly activated for a given variable of interest (GLM4) and mean activations in ROIs (GLM5) were further analyzed with mixed effect regressions. ROIs analyses revealed that BOLD response in angular gyrus and medial prefrontal cortex was better explained by stimulus probabilities inferred from the hidden states (model M4) rather than the observed payoffs (model M4a), in line with the behavioral results. The interaction of probabilities with ROI location was not significant. The effect of stimulus probabilities is thus similar in the three ROIs (Table S6 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>, see <xref ref-type="bibr" rid="pcbi.1002895-Nieuwenhuis1">[40]</xref> for the necessity to test interactions before making simple contrasts). The number of colors did not interact with stimulus probabilities, meaning that the effect of probabilities was not influenced by the number of states (Table S6 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). When the effect of probabilities was estimated for each number of states, it was found to be significant for 2 (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e029" xlink:type="simple"/></inline-formula>), 5 (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e030" xlink:type="simple"/></inline-formula>), and 10 states (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e031" xlink:type="simple"/></inline-formula>, Table S7 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>).</p>
        <p>Analysis of choices revealed that expected utility was linear relative to probabilities. We also tested whether BOLD responses in the three ROIs increased linearly with probabilities. The first model included only an intercept and yielded to a BIC of 78707. In the second model, we added a linear effect for stimulus probabilities. This linear effect of probabilities was significant (Table S8 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>) and the BIC fell to 78491, showing an increase in efficiency. Finally, a non linear weighting function was added. The linear effect was again significant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e032" xlink:type="simple"/></inline-formula>). In contrast with the inverted-S shape of prospect theory, there was a slight diminution of sensitivity for probabilities close to 0 and 1 (<xref ref-type="fig" rid="pcbi-1002895-g003">Fig. 3c</xref>) but this non-linear effect was not significant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e033" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e034" xlink:type="simple"/></inline-formula>, Table S9 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). The BIC of this model was 78542, showing a decrease in efficiency compared to the previous model. Similar results were found when the non-linear model was tested on each ROI separately (no table was reported for the separate analyses). Thus, we found no evidence for a non-linear encoding of stimulus probabilities when learned from experience.</p>
        <p>Connectivity analysis was conducted to explore the functional link between the ROIs encoding stimulus probabilities and the rest of the brain. Each of the ROIs was taken as a seed region in three separate analyses. Results showed that during the learning phase (compared to the resting phase) the correlation increased between each ROI and voxels in the two other ROIs. Correlations also increased between each ROI and the posterior cingulate (no table or figure was reported for the separate analyses). Connections with posterior cingulate cortex were also observed when voxels of the three ROIs were merged to define a single seed region (<xref ref-type="fig" rid="pcbi-1002895-g004">Fig. 4c</xref>, GLM6, Table S10 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>).</p>
      </sec>
      <sec id="s2d">
        <title>Brain response to value and uncertainty</title>
        <p>Comparing the active phase (when choices were made without knowing the outcome in advance) to the control phase (when the outcome was known before making choices), significant activity was observed in the occipital cortex, suggesting that visual exploration of the bin was more intense when the outcome was unknown (GLM1, Table S11 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). In addition, BOLD responses in the right anterior insula and bilateral caudate were significant. These regions have been involved in risky decision-making, which is present in the active phase but not in the control phase <xref ref-type="bibr" rid="pcbi.1002895-Paulus1">[41]</xref>.</p>
        <p>During the learning phase, we have reported above how brain activity changed as a function of probabilities of a specific stimulus. This approach was possible because stimuli (payoffs) were presented one at a time. But the approach cannot be used when the participants deliberated on their choice because all possible outcomes should be contemplated at once. To study the link between brain activity and probabilities during the decision epoch, a measure that summarizes the set of outcome probabilities should be used instead. Here, we chose entropy, which measures the uncertainty reflected in a set of probabilities. Entropy increases as the probability distribution approaches the uniform distribution.</p>
        <p>During the deliberation preceding the decision to buy or pass, the expected gamble value (net of the price) was related to activity in the caudate and spread to other regions in the brain (Fig. S4a, Table S12 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). At the same period, expected value interacted with outcome entropy in the bilateral insula (<xref ref-type="fig" rid="pcbi-1002895-g005">Fig. 5a</xref> &amp; Table S13 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). An ROI analysis revealed a main and positive effect of expected value in insula. The interaction showed that this effect of value was stronger when the outcome entropy was high (Fig. S4b+c &amp; Table S14 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). Thus, the insula seems to be especially sensitive to the value of gambles with uncertain outcomes.</p>
        <fig id="pcbi-1002895-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002895.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Active decision phase.</title>
            <p>(<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e035" xlink:type="simple"/></inline-formula>, uncorr.) (<bold>a</bold>) BOLD response in the bilateral insula to gambles combining high outcome entropy and high expected value. Outcome uncertainty increased with entropy. (<bold>b</bold>) BOLD response to choice entropy in the dorsal anterior cingulate. Participants faced a more difficult choice when the probabilities to buy and pass the gamble were close, that is when choice entropy was high. (<bold>c</bold>) Striatal activation related to the magnitude of the total payoff received at the end of the decision phase (net of the total price). Whereas activation related to outcome and choice entropy were observed before participants made a choice (anticipation), BOLD response to the net payoff was observed afterwards (feedback).</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002895.g005" position="float" xlink:type="simple"/>
        </fig>
        <p>In order to quantify uncertainty regarding choices, we computed the entropy of the probabilities (and complementary probabilities) that participants bought into the gamble (as predicted by model M4). Voxel-based analyses showed a significant effect of choice entropy in dorsal anterior cingulate cortex (<xref ref-type="fig" rid="pcbi-1002895-g005">Fig. 5b</xref> &amp; Table S15 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). ROI analyses were conducted to further test the double dissociation between outcome and choice entropy in insula and anterior cingulate. Results indicated that choice entropy was specifically encoded in anterior cingulate and not insula. The dissociation was not significant for outcome entropy. Finally, BOLD response in the bilateral striatum (putamen and caudate) was related to the net payoff revealed at the end of each decision phase (<xref ref-type="fig" rid="pcbi-1002895-g005">Fig. 5c</xref> &amp; Table S16 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>).</p>
      </sec>
      <sec id="s2e">
        <title>Resting phase</title>
        <p>The three ROIs found to encode stimulus probabilities along with the posterior cingulate are all key regions of the default mode network. Regions forming the default network have two characteristics: (1) their spontaneous activity is correlated when people are at rest, (2) they are deactivated during tasks requiring attention to external stimuli <xref ref-type="bibr" rid="pcbi.1002895-Buckner1">[42]</xref>. The default mode network includes the inferior parietal cortex, the posterior cingulate cortex, the medial prefrontal cortex, the lateral temporal cortex, and the hippocampus.</p>
        <p>To test the involvement of the default network in the present study, we explored the spontaneous correlations between ROIs encoding probabilities and the whole brain during the resting phase (threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e036" xlink:type="simple"/></inline-formula>). Results showed a functional link between each ROI and voxels in the other two. Each ROI was also connected to activity in the posterior cingulate cortex (no table or figure was reported for the separate analyses). Connections with the posterior cingulate cortex were also observed when voxels of the three ROIs were merged to define a single seed region (<xref ref-type="fig" rid="pcbi-1002895-g006">Fig. 6a</xref>, GLM7, Table S17 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>).</p>
        <fig id="pcbi-1002895-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002895.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Default mode network.</title>
            <p>(<bold>a</bold>) Voxels showing connectivity with angular gyri and medial prefrontal cortex ROIs during the resting phase. (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e037" xlink:type="simple"/></inline-formula>, uncorr.) (<bold>b</bold>) Voxels showing activation (red, task-positive network) and deactivation (blue, task-negative network) during the learning and decision phases (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e038" xlink:type="simple"/></inline-formula>, uncorr.) (<bold>c</bold>) Overlap between voxels encoding stimulus probabilities (<xref ref-type="fig" rid="pcbi-1002895-g004">Fig. 4a+b</xref>) and the task-negative network (panel b, blue voxels).</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002895.g006" position="float" xlink:type="simple"/>
        </fig>
        <p>Baseline activity was compared between the decision-making task (learning and decision phases) and the resting phase. Results showed an increase of BOLD response in occipital, superior parietal cortex, supplementary motor areas, and lateral prefrontal cortex (red voxels, <xref ref-type="fig" rid="pcbi-1002895-g006">Fig. 6b</xref>, GLM1, S18 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). Decreased activity was found bilaterally in angular gyrus, supramarginal gyrus, and middle and superior temporal gyri. Decreased activity was also observed in cingulate and medial prefrontal cortex (blue voxels, <xref ref-type="fig" rid="pcbi-1002895-g006">Fig. 6b</xref>, Table S19 in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>, similar results were found when comparing the resting phase to the learning phase only). There was a substantial overlap between the task-negative network and voxels encoding stimulus probabilities during the learning period (<xref ref-type="fig" rid="pcbi-1002895-g006">Fig. 6c</xref>). The results indicated that regions reacting to likely events belonged to the default network. On the other hand, there was a substantial overlap between the task-positive network and voxels reacting to rare stimuli (Fig. S3b in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). For a schematic of the main findings, see <xref ref-type="fig" rid="pcbi-1002895-g007">Fig. 7</xref>.</p>
        <fig id="pcbi-1002895-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002895.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Main findings.</title>
            <p>(<bold>a</bold>) During the resting phase, the spontaneous activity of the brain correlated between angular gyri, medial prefrontal cortex, and posterior cingulate cortex. This constitutes the first characteristic of the default mode network. (<bold>b</bold>) During the task (learning &amp; decision phases), baseline activity in these regions decreased. This is the second characteristic of the default network. At the same time, activation in the occipital, superior parietal, lateral prefrontal cortex, and other regions involved in visual attention increased. (<bold>c</bold>) During the learning phase, participants only saw the payoff in the center of the bin (stimulus). Nevertheless, the brain encoded the probability of currently observed stimulus inferred from the hidden states (colors). BOLD response for frequent stimuli increased in angular gyri and medial prefrontal cortex. BOLD response for rare stimuli increased in occipital areas, superior parietal cortex, middle frontal gyri, and hippocampus (Fig. S3a in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref>). (<bold>d</bold>) Compared to the resting phase, correlations between these regions increased during learning. (<bold>e</bold>) When participants had to decide whether to buy the gamble or not, BOLD response in the insula increased with with gamble expected value, especially for when outcome entropy was high. At the same time, the dorsal anterior cingulate cortex signaled choice entropy (<xref ref-type="fig" rid="pcbi-1002895-g005">Fig. 5b</xref>). (<bold>f</bold>) After six choices, a feedback was displayed. The bilateral striatum encoded the net payoff magnitude.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002895.g007" position="float" xlink:type="simple"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>In a complex and uncertain environment, probabilities are essential for predicting future events. To make consistent choices, it is necessary for a decision maker to separate the chances of objective events (“it will snow”) from the values that could potentially be attached to those events (“we can go skiing”). With such a strategy the decision maker can make inference in the absence of immediate reinforcements and quickly adjust his predictions when the reinforcing values of events change <xref ref-type="bibr" rid="pcbi.1002895-Dayan1">[43]</xref>. Here, we developed a paradigm in which the probability and value of stimuli were statistically independent. This allowed us to identify the regions in the brain encoding event probabilities and exclude a confound with value.</p>
      <p>Analysis of brain activity during the learning period revealed both positive and negative correlations with stimulus probabilities. BOLD response in angular gyrus and medial prefrontal cortex increased for stimuli which had been observed many times in the current trial. This relationship was significant in conditions with 2, 5, and 10 different stimuli. This shows that the brain can keep track of the probabilities of multiple events. Comparison with the resting state condition and connectivity analyses indicated that these regions belonged to the default mode network and that their baseline activity decreased during the task (task-negative network). A negative correlation between stimulus probabilities was observed in the occipital, superior parietal and lateral prefrontal cortex. Here BOLD response increased for improbable stimuli. These regions were more activated during the task (task-positive network). Before a choice was made activity in striatum and insula increased with gamble expected value. The effect of value in insula was stronger when outcome entropy was high, that is when the future was uncertain. Choice entropy which reflects decision uncertainty was preferentially associated to a BOLD response in dorsal anterior cingulate. After the decision, activity in the striatum increased with the net payoff.</p>
      <p>The principle of a separation between probability and value, namely probabilistic sophistication <xref ref-type="bibr" rid="pcbi.1002895-Savage1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Machina1">[4]</xref>, was supported by several results. In the learning period, the effect of probabilities was significant for both positive and negative events and the main effect of probability did not interact with event value. No significant effect of value was observed during the learning period. These results suggest that when reinforcements are delayed, the brain focuses on event probabilities while abstracting from rewards. It is only during the decision period that activation in relation with value was observed.</p>
      <p>These results are relevant for the debate on value-based and model-based reinforcement learning <xref ref-type="bibr" rid="pcbi.1002895-Glascher1">[18]</xref>. In value-based reinforcement learning, the agent learns the expected value associated to a situation or action by updating his forecast with a reward prediction error. Through this process, the agent acquires information about value <italic>but remains ignorant of probabilities</italic>. This stands in sharp contrast with model-based reinforcement learning. There, in order to forecast future rewards, the agent forms a representation of how the world “behaves” and this can be done by learning the probabilities of all events given the current situation (i.e. “state transition probabilities”, <xref ref-type="bibr" rid="pcbi.1002895-Kaelbling1">[44]</xref>). A neural signature of probabilities but not value was observed during the learning period. In addition, model comparison showed that choices were better explained by a probability rather than a reinforcement learning algorithm. Thus both behavioral and biological data favored model-based over value-based reinforcement learning in our task. By showing both positive and negative BOLD response to event probabilities, the present study add to the previous literature on model-based reinforcement learning <xref ref-type="bibr" rid="pcbi.1002895-ODoherty1">[45]</xref>.</p>
      <p>The functionality of the regions encoding probabilities deserves further discussion. Based on prior literature and our own results, we would argue that activation correlating with rare stimuli in occipital cortex reflects the visual exploration of the bin, while that in parietal and middle frontal gyrus captures the attention triggered by surprising events. Activation in hippocampus enhances encoding of rare stimuli. In contrast, the positive correlation between probabilities and activation in angular gyrus and medial prefrontal cortex would reflect the reactivation and reinforcement of past events in memory.</p>
      <p>BOLD activity increased in the occipital cortex for rare stimuli and this could be due to visual exploration. When a rare payoff was sampled, its probability of occurrence increased. This might incite participants to identify its associated color and re-evaluate its relative importance by looking at all the colors and payoffs in the periphery of the bin. Previous studies have shown increased activation in the occipital cortex for visually incongruent stimuli and this effect seems to generalize to rare events in our study <xref ref-type="bibr" rid="pcbi.1002895-Michelon1">[46]</xref>. Rare events were also related to activation in the superior parietal cortex and middle frontal gyrus and this could be explained by attentional processes. Indeed, these regions were more activated during the task compared to the resting period (task-positive network) and have been related to attention or the oddball effect <xref ref-type="bibr" rid="pcbi.1002895-Strange1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Corbetta1">[47]</xref>. Activity in the hippocampus was observed when a new stimulus was displayed, and the effect was stronger when the stimulus was rare. Lesions to the middle temporal area and the hippocampus can lead to amnesia and the inability to retain new information <xref ref-type="bibr" rid="pcbi.1002895-Penfield1">[48]</xref>. The BOLD response in the hippocampus suggests that rare events benefit from a better encoding when they occur. This is consistent with behavioural studies showing that surprising stimuli are better memorized <xref ref-type="bibr" rid="pcbi.1002895-Hirshman1">[49]</xref>.</p>
      <p>Activity in the default network has been found to increase during tasks of theory of mind, mind wandering, and memory <xref ref-type="bibr" rid="pcbi.1002895-AndrewsHanna1">[50]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Hassabis1">[51]</xref>. On the contrary, it has been found to decrease when participants pay attention to external stimuli (task-negative network). This was also the case in our task because participants had to pay attention to the sampled payoffs. While controlling for the effect of the task, activity increased in several regions of the task-positive network when a rare stimuli was displayed. On the contrary, a BOLD response in angular gyrus and medial prefrontal cortex increased for frequent stimuli. A possible explanation for this novel result is that frequent stimuli attract less attention and hence allow for more resting-state introspection, the role traditionally assigned to the default mode network. This switch would be consistent with optimal use of the limited amount of energy available in the brain <xref ref-type="bibr" rid="pcbi.1002895-Raichle1">[52]</xref>. However, the switch would have to take place within the time frame of display of our stimuli (1 [s]). If this interpretation is indeed true, our findings would amount to evidence for high-frequency switching between elemental states of the brain, namely, attention and rest. An alternative explanation is that activity in angular gyrus and medial prefrontal cortex reflects a distinct process, namely, evidence accumulation. This process can be modeled as we did, in terms of learning of probabilities. A drift-diffusion approach <xref ref-type="bibr" rid="pcbi.1002895-Ratcliff3">[53]</xref> could be used instead, though this approach is fundamentally the same.</p>
      <p>A cognitive mechanism that could explain the positive correlation between stimulus probability and brain activity is memory <xref ref-type="bibr" rid="pcbi.1002895-Ratcliff2">[29]</xref>. Cognitive psychologists have developed models centered on memory to explain how people judge the likelihood of events <xref ref-type="bibr" rid="pcbi.1002895-Hintzman1">[54]</xref>. In these models, each outcome is encoded as a trace in memory. An event will be considered as probable if many traces are retrieved from memory in response to a probe (the payoff in our task). Neuroimaging studies have confirmed the involvement of parietal and medial prefrontal cortex in memory: activity in these areas predicts the successful recognition of items <xref ref-type="bibr" rid="pcbi.1002895-Wagner1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Rugg1">[55]</xref>. Furthermore, many studies have demonstrated involvement of the default mode network in memory tasks <xref ref-type="bibr" rid="pcbi.1002895-Addis1">[56]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Kim1">[57]</xref>. As a consequence, the positive brain response to stimulus probabilities in the angular gyrus and medial prefrontal cortex might reflect the activation and reinforcement of memory traces in reaction to a probe. This hypothesis is compatible with an “attention to memory” model developed in neuroscience <xref ref-type="bibr" rid="pcbi.1002895-Sestieri1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Cabeza1">[58]</xref>. In this model, activation in the inferior parietal cortex reflects the attention captured by information retrieved from memory. Still, because fMRI can only recover correlation, other approaches like TMS are needed to determine the causal role of angular gyrus and medial prefrontal cortex in the acquisition and retrieval of event probabilities.</p>
      <p>In decision neuroscience, the posterior cingulate and ventro-medial prefrontal are often involved in the judgement of value <xref ref-type="bibr" rid="pcbi.1002895-Fellows1">[59]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Kable1">[60]</xref>. For instance the ventro-medial prefrontal cortex is more activated when participants see the image of food they like <xref ref-type="bibr" rid="pcbi.1002895-Chib1">[61]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Lebreton1">[62]</xref>. A recent study has shown that the time spent watching an item increased the likelihood to choose it and this type of behavior was well formalized by drift-diffusion models <xref ref-type="bibr" rid="pcbi.1002895-Krajbich1">[63]</xref>. Preferences depend on the sensory characteristics of goods, but they are also shaped by our past experience and memories <xref ref-type="bibr" rid="pcbi.1002895-Weber1">[64]</xref>. The reactivation of memory traces could partially explain why a key structure to evaluate the value of goods, the ventro medial prefrontal cortex, belongs to the default mode network and not to a task-positive or saliency network like the striatum <xref ref-type="bibr" rid="pcbi.1002895-Zink1">[65]</xref>. Accordingly, a recent study has shown that affective value and associative processing shared a common substrate in medial prefrontal cortex <xref ref-type="bibr" rid="pcbi.1002895-Shenhav1">[66]</xref>.</p>
      <p>Our study sheds new light on decision making under uncertainty when uncertainty is described as opposed to experienced <xref ref-type="bibr" rid="pcbi.1002895-Hertwig1">[1]</xref>. In a task where decisions were based on experience, BOLD response to uncertain stimuli increased linearly with their probabilities of occurrence. This was confirmed in behavior: choices exhibited no bias is assessment of probabilities, in contrast to decision making based on description of available gambles <xref ref-type="bibr" rid="pcbi.1002895-Gonzalez1">[67]</xref>. Our results therefore cast doubt on the generalizability of probability weighting in prospect theory to decision making from experience <xref ref-type="bibr" rid="pcbi.1002895-Fox1">[68]</xref>.</p>
      <p>In addition to a better understanding of the neural foundation of probability learning, the present study brings new knowledge concerning the representation of various kind of uncertainties in the brain <xref ref-type="bibr" rid="pcbi.1002895-PayzanLeNestour1">[69]</xref>. Previous studies have linked uncertainty to activity in the insula <xref ref-type="bibr" rid="pcbi.1002895-Huettel1">[70]</xref>, <xref ref-type="bibr" rid="pcbi.1002895-Bossaerts1">[71]</xref>, but also in the anterior cingulate cortex <xref ref-type="bibr" rid="pcbi.1002895-Critchley1">[72]</xref>. In the present study, we found that BOLD response in insula and dorsal anterior cingulate were related to different forms of uncertainty. Activity in the anterior cingulate correlated with choice entropy which reflected uncertainty in making a choice. The later interpretation matches previous studies reporting BOLD response in dorsal anterior cingulate when a conflict existed between several responses <xref ref-type="bibr" rid="pcbi.1002895-Carter1">[73]</xref> (difficulty of choice).</p>
      <p>Activity in the insula increased with the gamble expected value and this effect was more pronounced when the outcome entropy was high. Entropy corresponds to the notion of expected uncertainty discussed by A. Yu and P. Dayan <xref ref-type="bibr" rid="pcbi.1002895-Yu1">[74]</xref>. It is a function of probabilities only and thus does not depend on the value associated with the stimuli. An agent separating probability from value would favor entropy over reward volatility to estimate risk. When the outcome is a single and uncertain payoff, its standard deviation and entropy covary. This might explain why previous studies have found activation related to payoff standard-deviation in the insula <xref ref-type="bibr" rid="pcbi.1002895-Bossaerts1">[71]</xref>. Another possibility is that the insula becomes sensitive to entropy when participants learn state probabilities as in the present study and rely less on summary statistics like payoff mean and variance <xref ref-type="bibr" rid="pcbi.1002895-dAcremont1">[75]</xref>.</p>
      <p>The general view that emerges from our study is that the brain does not only react to rewarding or surprising events, but also to likely events. When people observed uncertain stimuli, the average activity in the default mode network decreased compared to a resting condition. Nevertheless, the functional connectivity in this network increased and stimulus probabilities were positively correlated with BOLD response in angular gyrus and medial prefrontal cortex. Thus activity in these two regions signalled the accumulation of evidence (confirmatory signal). Brain response to uncertain stimuli increased linearly in probability and there was no evidence of probability weighting in choices. Further research is needed to test if the brain response to likely events reflects an activation of memory traces (internal world) or a lack of attention to the environment (external world).</p>
    </sec>
    <sec id="s4" sec-type="methods">
      <title>Methods</title>
      <sec id="s4a">
        <title>Participants</title>
        <p>Twenty-five students from the Université de Lausanne and the Ecole Polytechnique Fédérale de Lausanne were enrolled in the study. One participant was removed from the analysis because of significant head movements. Another, because her decisions to buy the gamble were random. The analyzed sample included 23 participants (10 women, 13 men; median age = 22, min = 19, max = 30; all right handed). The study took place at the University Hospital of Lausanne and was approved by its institutional review board. At the end of the experiment, students received 1/10 of their net play money in real currency, in addition to a 10 Frs (Swiss francs) participation reward.</p>
        <p>To explain the task, the investigator read the instructions aloud and students played with one demonstration bin. They completed the task in a 3 Tesla MRI scanner. During the functional image acquisition, participants watched the display through goggles and indicated their decision to buy or to pass the gamble by pressing the left or right button of a response box. Participants learned probabilities and made decisions on 9 different bins. After bin 3 and 6, a resting phase of 60 [s] was introduced.</p>
      </sec>
      <sec id="s4b">
        <title>Task</title>
        <p>Payoffs were determined by the colors of balls drawn from a bin. Bins contained balls of different colors, with same-colored balls yielding the same payoff. The composition of the bin was hidden therefore probabilities were unknown. The time line for one example bin is shown in <xref ref-type="fig" rid="pcbi-1002895-g002">Fig. 2a</xref>. During the first sampling stage, 10 to 14 balls were drawn from the bin one after another and the associated payoff was displayed for 1 [s] at the center of the screen. Balls were drawn with replacement. Only stimuli representing the payoffs were shown. Colors were hidden states. These states could be inferred from the colored balls displayed in the periphery of the bin.</p>
        <p>This learning phase was followed by a decision phase. The participant had to decide whether to buy the gamble or not for a certain price. After each choice, an additional ball was drawn. If the participant bought the gamble, he earned the payoff written on the ball minus the price. Otherwise, the payoff was 0 and the play money remained unchanged. Four choices were made without knowing the outcome in advance (active condition) and two choices were made while knowing the outcome in advance (control condition). For each of the six choices, a different price was posted. Prices were drawn from a uniform distribution between the minimum and maximum payoffs. After each decision, a message indicating that the gamble was bought or passed was shown (but the payoff was not shown to limit learning in the decision period). The total net payoff of the current decision period was displayed after the six choices.</p>
        <p>The learning and decision phases were repeated with the same bin after changing the color-payoff association. That is, color probabilities remained unchanged (same composition of the bin), but each color was associated with a new payoff. It was thus adaptive to learn probabilities based on the color of the past drawings. In <xref ref-type="fig" rid="pcbi-1002895-g002">Fig. 2</xref>, the color-payoff association in panel a is reproduced in the top insert of panel b. For instance, red was associated with 57 in the sampling stage and with 67 in the resampling stage. Bins contained balls of 2, 5, or 10 different colors. The probabilities used to generate the drawings are represented by the histograms in <xref ref-type="fig" rid="pcbi-1002895-g002">Fig. 2b</xref>. Because balls were drawn with replacement, these probabilities remained constant during the sampling and resampling stages.</p>
        <p>Nine different bins were presented in the task. Importantly, colors were randomly assigned to probabilities at the beginning of each new bin. Payoffs were randomly assigned to colors at the beginning of each sampling stage. As a consequence, payoff probabilities are orthogonal to payoff magnitudes and expected payoff. Uncertainty at decision time increased with both the number of possible payoffs and the payoff standard-deviation. To disentangle their effects, these two factors were manipulated independently (Fig. S5). See section <italic>Task</italic> in <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref> for more details.</p>
      </sec>
      <sec id="s4c">
        <title>Choice modeling</title>
        <sec id="s4c1">
          <title>Learning phase</title>
          <p>During the learning phase, probabilities were updated following Bayes' rule. In the mathematical formulation of the models, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e039" xlink:type="simple"/></inline-formula> indexes the states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e040" xlink:type="simple"/></inline-formula> in the bin, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e041" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e042" xlink:type="simple"/></inline-formula> the number of states (2, 5 or 10 colors). So <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e043" xlink:type="simple"/></inline-formula> refers to a color (e.g., blue). The probability of state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e044" xlink:type="simple"/></inline-formula> at drawing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e045" xlink:type="simple"/></inline-formula> is a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e046" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e047" xlink:type="simple"/></inline-formula> (with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e048" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e049" xlink:type="simple"/></inline-formula> referring to the first and last drawing the initial sampling stage and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e050" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e051" xlink:type="simple"/></inline-formula> to the first and last drawing in the resampling stage). The vector of probabilities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e052" xlink:type="simple"/></inline-formula> follows a Dirichlet distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e053" xlink:type="simple"/></inline-formula>. The PDF of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e054" xlink:type="simple"/></inline-formula> is given by:<disp-formula id="pcbi.1002895.e055"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002895.e055" xlink:type="simple"/></disp-formula>with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e056" xlink:type="simple"/></inline-formula>. Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e057" xlink:type="simple"/></inline-formula> denote the true probability of state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e058" xlink:type="simple"/></inline-formula>. The point estimation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e059" xlink:type="simple"/></inline-formula> of this true probability is given by:<disp-formula id="pcbi.1002895.e060"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002895.e060" xlink:type="simple"/></disp-formula>with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e061" xlink:type="simple"/></inline-formula> the information available at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e062" xlink:type="simple"/></inline-formula>.</p>
          <p>We use <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e063" xlink:type="simple"/></inline-formula> to indicate the number of times state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e064" xlink:type="simple"/></inline-formula> was observed at drawing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e065" xlink:type="simple"/></inline-formula>. Before any drawing, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e066" xlink:type="simple"/></inline-formula>. To specify the Dirichlet distribution at any time, we set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e067" xlink:type="simple"/></inline-formula>. Without any knowledge of the composition of the bin, it is rational to assume that all colors have the same chance of occurrence when a new bin is encountered. Thus we chose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e068" xlink:type="simple"/></inline-formula>. As a result and before any sample had been observed, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e069" xlink:type="simple"/></inline-formula> for all state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e070" xlink:type="simple"/></inline-formula>. E.g., for a bin with 5 colors, all probabilities are expected to equal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e071" xlink:type="simple"/></inline-formula>. In model M4b (no probability learning), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e072" xlink:type="simple"/></inline-formula> for all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e073" xlink:type="simple"/></inline-formula>, thus probabilities are not updated and remain equal to the priors. In model M4a (probabilities inferred from observations), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e074" xlink:type="simple"/></inline-formula> is set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e075" xlink:type="simple"/></inline-formula> at the beginning of the sampling and resampling stages but it records the occurrence of states. This is equivalent to learning the probabilities without reference to colors. In model M4 (probabilities inferred from hidden states), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e076" xlink:type="simple"/></inline-formula> is set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e077" xlink:type="simple"/></inline-formula> at the beginning of the initial sampling stage and it records the occurrence of states. It is not reset to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e078" xlink:type="simple"/></inline-formula> at the beginning of the resampling stage.</p>
        </sec>
        <sec id="s4c2">
          <title>Decision phase</title>
          <p>We first need to define a function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e079" xlink:type="simple"/></inline-formula> that associate a payoff <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e080" xlink:type="simple"/></inline-formula> to each state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e081" xlink:type="simple"/></inline-formula>. So this function links each color to a payoff. In the task, we only show the payoff in the center of the bin (stimulus), so the underlying state is inferred with the inverse function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e082" xlink:type="simple"/></inline-formula>. In model M2, the identity function was used to transform payoffs (net of the posted price <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e083" xlink:type="simple"/></inline-formula>). In models M4, M4a, M4b, and M5, a non-differentiable value function was used instead:<disp-formula id="pcbi.1002895.e084"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002895.e084" xlink:type="simple"/><label>(1)</label></disp-formula>with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e085" xlink:type="simple"/></inline-formula> representing the diminishing sensitivity parameter and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e086" xlink:type="simple"/></inline-formula> representing the loss aversion parameter.</p>
          <p>In all models the identity function was used for probabilities, expect for model M5 which had a probability weighting function:<disp-formula id="pcbi.1002895.e087"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002895.e087" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e088" xlink:type="simple"/></inline-formula> controls the S shape.</p>
          <p>Subjective values and probabilities were multiplied and then summed over states to compute the expected value of the gamble:<disp-formula id="pcbi.1002895.e089"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002895.e089" xlink:type="simple"/><label>(3)</label></disp-formula>To convert estimated values into choices, we used the softmax model. There, the probability that the gamble is bought is given by:<disp-formula id="pcbi.1002895.e090"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002895.e090" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e091" xlink:type="simple"/></inline-formula> denotes the estimated value of the gamble at the end of the learning phase (i.e., at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e092" xlink:type="simple"/></inline-formula> for the sampling stage, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e093" xlink:type="simple"/></inline-formula> for the resampling stage). Nelder-Mead optimization was used to find the maximum likelihood (MLL) of this logistic regression. Search was repeated 5 times with different starting values. The best fit was retained (restarts yielded to very close results).</p>
          <p>Outcome entropy at the end of the learning phase was computed with:<disp-formula id="pcbi.1002895.e094"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002895.e094" xlink:type="simple"/><label>(4)</label></disp-formula>with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e095" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002895.e096" xlink:type="simple"/></inline-formula>. To compute the entropy of choices, state probabilities were replaced by choice probabilities derived from the softmax function.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pcbi.1002895.s001" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1002895.s001" position="float" xlink:type="simple">
        <label>Text S1</label>
        <caption>
          <p><bold>Supplementary information.</bold> <xref ref-type="supplementary-material" rid="pcbi.1002895.s001">Text S1</xref> provides additional methods, results, figures, and tables.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002895-Hertwig1">
        <label>1</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hertwig</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Erev</surname><given-names>I</given-names></name> (<year>2009</year>) <article-title>The description-experience gap in risky choice</article-title>. <source>Trends in Cognitive Sciences</source> <volume>13</volume>: <fpage>517</fpage>–<lpage>523</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Sutton1">
        <label>2</label>
        <mixed-citation publication-type="other" xlink:type="simple">Sutton R, Barto A (1998) Reinforcement learning: An introduction. The MIT Press. 322 p.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Savage1">
        <label>3</label>
        <mixed-citation publication-type="other" xlink:type="simple">Savage L (1954) The Foundations of Statistics. Canada: John Wiley &amp; Sons.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Machina1">
        <label>4</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Machina</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Schmeidler</surname><given-names>D</given-names></name> (<year>1992</year>) <article-title>A more robust definition of subjective probability</article-title>. <source>Econometrica</source> <volume>60</volume>: <fpage>745</fpage>–<lpage>780</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Beach1">
        <label>5</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beach</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Shoenberger</surname><given-names>R</given-names></name> (<year>1965</year>) <article-title>Event salience and response frequency on a ten-alternative probability-learning situation</article-title>. <source>Journal of Experimental Psychology</source> <volume>69</volume>: <fpage>312</fpage>–<lpage>316</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Cotton1">
        <label>6</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cotton</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Rechtschaffen</surname><given-names>A</given-names></name> (<year>1958</year>) <article-title>Replication report: Two-and three-choice verbal-conditioning phenomena</article-title>. <source>Journal of Experimental Psychology</source> <volume>56</volume>: <fpage>96</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Gardner1">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gardner</surname><given-names>R</given-names></name> (<year>1957</year>) <article-title>Probability-learning with two and three choices</article-title>. <source>The American Journal of Psychology</source> <volume>70</volume>: <fpage>174</fpage>–<lpage>185</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Knowlton1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knowlton</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Squire</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Gluck</surname><given-names>M</given-names></name> (<year>1994</year>) <article-title>Probabilistic classification learning in amnesia</article-title>. <source>Learning &amp; Memory</source> <volume>1</volume>: <fpage>106</fpage>–<lpage>120</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Poldrack1">
        <label>9</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Poldrack</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Prabhakaran</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Seger</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Gabrieli</surname><given-names>J</given-names></name> (<year>1999</year>) <article-title>Striatal activation during acquisition of a cognitive skill</article-title>. <source>Neuropsychology</source> <volume>13</volume>: <fpage>564</fpage>–<lpage>574</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Fera1">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fera</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Weickert</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Goldberg</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Tessitore</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hariri</surname><given-names>A</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Neural mechanisms underlying probabilistic category learning in normal aging</article-title>. <source>The Journal of Neuroscience</source> <volume>25</volume>: <fpage>11340</fpage>–<lpage>11348</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Weickert1">
        <label>11</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weickert</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Goldberg</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Callicott</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>Q</given-names></name>, <name name-style="western"><surname>Apud</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Neural correlates of probabilistic category learning in patients with schizophrenia</article-title>. <source>The Journal of Neuroscience</source> <volume>29</volume>: <fpage>1244</fpage>–<lpage>1254</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Tobler1">
        <label>12</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tobler</surname><given-names>P</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name> (<year>2007</year>) <article-title>Reward value coding distinct from risk attitude-related uncertainty coding in human reward systems</article-title>. <source>Journal of Neurophysiology</source> <volume>97</volume>: <fpage>1621</fpage>–<lpage>1632</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Behrens1">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Behrens</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Hunt</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Woolrich</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Rushworth</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>Associative learning of social value</article-title>. <source>Nature</source> <volume>456</volume>: <fpage>245</fpage>–<lpage>249</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Hsu1">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hsu</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Krajbich</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Camerer</surname><given-names>C</given-names></name> (<year>2009</year>) <article-title>Neural response to reward anticipation under risk is nonlinear in probabilities</article-title>. <source>The Journal of Neuroscience</source> <volume>29</volume>: <fpage>2231</fpage>–<lpage>2237</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Berns1">
        <label>15</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berns</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Capra</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Chappelow</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Moore</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Noussair</surname><given-names>C</given-names></name> (<year>2008</year>) <article-title>Nonlinear neurobiological probability weighting functions for aversive outcomes</article-title>. <source>Neuroimage</source> <volume>39</volume>: <fpage>2047</fpage>–<lpage>2057</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Yacubian1">
        <label>16</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yacubian</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Glascher</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Schroeder</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Sommer</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Braus</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Dissociable systems for gain-and loss-related value predictions and errors of prediction in the human brain</article-title>. <source>Journal of Neuroscience</source> <volume>26</volume>: <fpage>9530</fpage>–<lpage>9537</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Strange1">
        <label>17</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Strange</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Duggins</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Penny</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>K</given-names></name> (<year>2005</year>) <article-title>Information theory, novelty and hippocampal responses: Unpredicted or unpredictable?</article-title> <source>Neural Networks</source> <volume>18</volume>: <fpage>225</fpage>–<lpage>230</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Glascher1">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Glascher</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>J</given-names></name> (<year>2010</year>) <article-title>States versus rewards: Dissociable neural pre-diction error signals underlying model-based and model-free reinforcement learning</article-title>. <source>Neuron</source> <volume>66</volume>: <fpage>585</fpage>–<lpage>595</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Fletcher1">
        <label>19</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fletcher</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Shanks</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Honey</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Carpenter</surname><given-names>T</given-names></name>, <etal>et al</etal>. (<year>2001</year>) <article-title>Responses of human frontal cortex to surprising events are predicted by formal associative learning theory</article-title>. <source>Nature Neuroscience</source> <volume>4</volume>: <fpage>1043</fpage>–<lpage>1048</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-DuncanJohnson1">
        <label>20</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Duncan-Johnson</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Donchin</surname><given-names>E</given-names></name> (<year>1977</year>) <article-title>On quantifying surprise: The variation of event-related potentials with subjective probability</article-title>. <source>Psychophysiology</source> <volume>14</volume>: <fpage>456</fpage>–<lpage>467</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Mars1">
        <label>21</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mars</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Debener</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Gladwin</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Harrison</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Haggard</surname><given-names>P</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Trial-by-trial fluctuations in the event-related electroencephalogram reflect dynamic changes in the degree of surprise</article-title>. <source>The Journal of Neuroscience</source> <volume>28</volume>: <fpage>12539</fpage>–<lpage>12545</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Friston1">
        <label>22</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>K</given-names></name> (<year>2010</year>) <article-title>The free-energy principle: A unified brain theory?</article-title> <source>Nature reviews Neuroscience</source> <volume>11</volume>: <fpage>127</fpage>–<lpage>138</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Ratcliff1">
        <label>23</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ratcliff</surname><given-names>R</given-names></name>, <name name-style="western"><surname>McKoon</surname><given-names>G</given-names></name> (<year>2008</year>) <article-title>The diffusion decision model: Theory and data for two-choice decision tasks</article-title>. <source>Neural computation</source> <volume>20</volume>: <fpage>873</fpage>–<lpage>922</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Heekeren1">
        <label>24</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heekeren</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Marrett</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Ungerleider</surname><given-names>L</given-names></name> (<year>2008</year>) <article-title>The neural systems that mediate human perceptual decision making</article-title>. <source>Nature Reviews Neuroscience</source> <volume>9</volume>: <fpage>467</fpage>–<lpage>479</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Huk1">
        <label>25</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huk</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Shadlen</surname><given-names>M</given-names></name> (<year>2005</year>) <article-title>Neural activity in macaque parietal cortex reects temporal integration of visual motion signals during perceptual decision making</article-title>. <source>The Journal of Neuroscience</source> <volume>25</volume>: <fpage>10420</fpage>–<lpage>10436</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Shadlen1">
        <label>26</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shadlen</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Newsome</surname><given-names>W</given-names></name> (<year>2001</year>) <article-title>Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey</article-title>. <source>Journal of Neurophysiology</source> <volume>86</volume>: <fpage>1916</fpage>–<lpage>1936</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Beck1">
        <label>27</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beck</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Ma</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Kiani</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Hanks</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Churchland</surname><given-names>A</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Probabilistic population codes for Bayesian decision making</article-title>. <source>Neuron</source> <volume>60</volume>: <fpage>1142</fpage>–<lpage>1152</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Yang1">
        <label>28</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yang</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Shadlen</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>Probabilistic reasoning by neurons</article-title>. <source>Nature</source> <volume>447</volume>: <fpage>1075</fpage>–<lpage>1080</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Ratcliff2">
        <label>29</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ratcliff</surname><given-names>R</given-names></name> (<year>1978</year>) <article-title>A theory of memory retrieval</article-title>. <source>Psychological review</source> <volume>85</volume>: <fpage>59</fpage>–<lpage>108</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Murdock1">
        <label>30</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Murdock</surname><given-names>B</given-names></name> (<year>1993</year>) <article-title>TODAM2: A model for the storage and retrieval of item, associative, and serial-order information</article-title>. <source>Psychological Review</source> <volume>100</volume>: <fpage>183</fpage>–<lpage>203</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Wagner1">
        <label>31</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wagner</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Shannon</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Kahn</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Buckner</surname><given-names>R</given-names></name> (<year>2005</year>) <article-title>Parietal lobe contributions to episodic memory retrieval</article-title>. <source>Trends in Cognitive Sciences</source> <volume>9</volume>: <fpage>445</fpage>–<lpage>453</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Sestieri1">
        <label>32</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sestieri</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Shulman</surname><given-names>GL</given-names></name>, <name name-style="western"><surname>Corbetta</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>Attention to memory and the environment: Func-tional specialization and dynamic competition in human posterior parietal cortex</article-title>. <source>The Journal of Neuroscience</source> <volume>30</volume>: <fpage>8445</fpage>–<lpage>8456</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Shimamura1">
        <label>33</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shimamura</surname><given-names>A</given-names></name> (<year>2011</year>) <article-title>Episodic retrieval and the cortical binding of relational activity</article-title>. <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source> <volume>11</volume>: <fpage>277</fpage>–<lpage>291</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Bar1">
        <label>34</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bar</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>The proactive brain: Using analogies and associations to generate predictions</article-title>. <source>Trends in Cognitive Sciences</source> <volume>11</volume>: <fpage>280</fpage>–<lpage>289</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Bar2">
        <label>35</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bar</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Aminoff</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Mason</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Fenske</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>The units of thought</article-title>. <source>Hippocampus</source> <volume>17</volume>: <fpage>420</fpage>–<lpage>428</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Yacubian2">
        <label>36</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yacubian</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sommer</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Schroeder</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Glascher</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Braus</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Subregions of the ventral striatum show preferential coding of reward magnitude and probability</article-title>. <source>Neuroimage</source> <volume>38</volume>: <fpage>557</fpage>–<lpage>563</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Boorman1">
        <label>37</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boorman</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Behrens</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Woolrich</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Rushworth</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>How green is the grass on the other side? Frontopolar cortex and the evidence in favor of alternative courses of action</article-title>. <source>Neuron</source> <volume>62</volume>: <fpage>733</fpage>–<lpage>743</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Tversky1">
        <label>38</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tversky</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kahneman</surname><given-names>D</given-names></name> (<year>1992</year>) <article-title>Advances in prospect theory: Cumulative representation of un-certainty</article-title>. <source>Journal of Risk and Uncertainty</source> <volume>5</volume>: <fpage>297</fpage>–<lpage>323</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Hau1">
        <label>39</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hau</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Pleskac</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Kiefer</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Hertwig</surname><given-names>R</given-names></name> (<year>2008</year>) <article-title>The description–experience gap in risky choice: The role of sample size and experienced probabilities</article-title>. <source>Journal of Behavioral Decision Making</source> <volume>21</volume>: <fpage>493</fpage>–<lpage>518</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Nieuwenhuis1">
        <label>40</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nieuwenhuis</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Forstmann</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Wagenmakers</surname><given-names>E</given-names></name> (<year>2011</year>) <article-title>Erroneous analyses of interactions in neuro-science: A problem of significance</article-title>. <source>Nature Neuroscience</source> <volume>14</volume>: <fpage>1105</fpage>–<lpage>1107</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Paulus1">
        <label>41</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Paulus</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Rogalsky</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Simmons</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Feinstein</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Stein</surname><given-names>M</given-names></name> (<year>2003</year>) <article-title>Increased activation in the right insula during risk-taking decision making is related to harm avoidance and neuroticism</article-title>. <source>Neuroimage</source> <volume>19</volume>: <fpage>1439</fpage>–<lpage>1448</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Buckner1">
        <label>42</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buckner</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Andrews-Hanna</surname><given-names>J</given-names></name> (<year>2008</year>) <article-title>The brain's default network: Anatomy, function, and rele-vance to disease</article-title>. <source>Annals of the New York Academy of Sciences</source> <volume>1124</volume>: <fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Dayan1">
        <label>43</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Niv</surname><given-names>Y</given-names></name> (<year>2008</year>) <article-title>Reinforcement learning: The good, the bad and the ugly</article-title>. <source>Current Opinion in Neurobiology</source> <volume>18</volume>: <fpage>185</fpage>–<lpage>196</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Kaelbling1">
        <label>44</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kaelbling</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Littman</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Moore</surname><given-names>A</given-names></name> (<year>1996</year>) <article-title>Reinforcement learning: A survey</article-title>. <source>Journal of Artiffcial Intelligence Research</source> <volume>4</volume>: <fpage>237</fpage>–<lpage>285</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-ODoherty1">
        <label>45</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name> (<year>2012</year>) <article-title>Beyond simple reinforcement learning: The computational neurobiology of reward-learning and valuation</article-title>. <source>The European Journal of Neuroscience</source> <volume>35</volume>: <fpage>987</fpage>–<lpage>990</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Michelon1">
        <label>46</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Michelon</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Snyder</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Buckner</surname><given-names>R</given-names></name>, <name name-style="western"><surname>McAvoy</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Zacks</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2003</year>) <article-title>Neural correlates of incon-gruous visual information: An event-related fMRI study</article-title>. <source>Neuroimage</source> <volume>19</volume>: <fpage>1612</fpage>–<lpage>1626</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Corbetta1">
        <label>47</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Corbetta</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kincade</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Lewis</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Snyder</surname><given-names>AZ</given-names></name>, <name name-style="western"><surname>Sapir</surname><given-names>A</given-names></name> (<year>2005</year>) <article-title>Neural basis and recovery of spatial attention deficits in spatial neglect</article-title>. <source>Nature Neuroscience</source> <volume>8</volume>: <fpage>1603</fpage>–<lpage>1610</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Penfield1">
        <label>48</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Penfield</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Milner</surname><given-names>B</given-names></name> (<year>1958</year>) <article-title>Memory deficit produced by bilateral lesions in the hippocampal zone</article-title>. <source>Archives of Neurology and Psychiatry</source> <volume>79</volume>: <fpage>475</fpage>–<lpage>497</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Hirshman1">
        <label>49</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hirshman</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Whelley</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Palij</surname><given-names>M</given-names></name> (<year>1989</year>) <article-title>An investigation of paradoxical memory effects</article-title>. <source>Journal of Memory and Language</source> <volume>28</volume>: <fpage>594</fpage>–<lpage>609</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-AndrewsHanna1">
        <label>50</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Andrews-Hanna</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>The brain's default network and its adaptive role in internal mentation</article-title>. <source>The Neuroscientist</source> <volume>18</volume>: <fpage>251</fpage>–<lpage>270</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Hassabis1">
        <label>51</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hassabis</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Kumaran</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Maguire</surname><given-names>E</given-names></name> (<year>2007</year>) <article-title>Using imagination to understand the neural basis of episodic memory</article-title>. <source>The Journal of Neuroscience</source> <volume>27</volume>: <fpage>14365</fpage>–<lpage>14374</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Raichle1">
        <label>52</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raichle</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Gusnard</surname><given-names>D</given-names></name> (<year>2002</year>) <article-title>Appraising the brain's energy budget</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>99</volume>: <fpage>10237</fpage>–<lpage>10239</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Ratcliff3">
        <label>53</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ratcliff</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>P</given-names></name> (<year>2004</year>) <article-title>A comparison of sequential sampling models for two-choice reaction time</article-title>. <source>Psychological Review</source> <volume>111</volume>: <fpage>333</fpage>–<lpage>367</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Hintzman1">
        <label>54</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hintzman</surname><given-names>D</given-names></name> (<year>1988</year>) <article-title>Judgments of frequency and recognition memory in a multiple-trace memory model</article-title>. <source>Psychological Review</source> <volume>95</volume>: <fpage>528</fpage>–<lpage>551</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Rugg1">
        <label>55</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rugg</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Fletcher</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Frith</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Frackowiak</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>R</given-names></name> (<year>1996</year>) <article-title>Differential activation of the prefrontal cortex in successful and unsuccessful memory retrieval</article-title>. <source>Brain</source> <volume>119</volume>: <fpage>2073</fpage>–<lpage>2083</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Addis1">
        <label>56</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Addis</surname><given-names>DR</given-names></name>, <name name-style="western"><surname>Pan</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Vu</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Laiser</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Schacter</surname><given-names>DL</given-names></name> (<year>2009</year>) <article-title>Constructive episodic simulation of the future and the past: Distinct subsystems of a core brain network mediate imagining and remembering</article-title>. <source>Neuropsychologia</source> <volume>47</volume>: <fpage>2222</fpage>–<lpage>2238</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Kim1">
        <label>57</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kim</surname><given-names>H</given-names></name> (<year>2012</year>) <article-title>A dual-subsystem model of the brain's default network: Self-referential processing, memory retrieval processes, and autobiographical memory retrieval</article-title>. <source>Neuroimage</source> <volume>61</volume>: <fpage>966</fpage>–<lpage>977</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Cabeza1">
        <label>58</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cabeza</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Ciaramelli</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Olson</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Moscovitch</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>The parietal cortex and episodic memory: An attentional account</article-title>. <source>Nature Reviews Neuroscience</source> <volume>9</volume>: <fpage>613</fpage>–<lpage>625</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Fellows1">
        <label>59</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fellows</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Farah</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>The role of ventromedial prefrontal cortex in decision making: Judgment under uncertainty or judgment per se?</article-title> <source>Cerebral Cortex</source> <volume>17</volume>: <fpage>2669</fpage>–<lpage>2674</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Kable1">
        <label>60</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kable</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Glimcher</surname><given-names>P</given-names></name> (<year>2007</year>) <article-title>The neural correlates of subjective value during intertemporal choice</article-title>. <source>Nature Neuroscience</source> <volume>10</volume>: <fpage>1625</fpage>–<lpage>1633</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Chib1">
        <label>61</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chib</surname><given-names>VS</given-names></name>, <name name-style="western"><surname>Rangel</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Shimojo</surname><given-names>S</given-names></name>, <name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name> (<year>2009</year>) <article-title>Evidence for a common representation of decision values for dissimilar goods in human ventromedial prefrontal cortex</article-title>. <source>The Journal of Neuroscience</source> <volume>29</volume>: <fpage>12315</fpage>–<lpage>12320</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Lebreton1">
        <label>62</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lebreton</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Jorge</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Michel</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Thirion</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Pessiglione</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>An automatic valuation system in the human brain: Evidence from functional neuroimaging</article-title>. <source>Neuron</source> <volume>64</volume>: <fpage>431</fpage>–<lpage>439</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Krajbich1">
        <label>63</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krajbich</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Armel</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Rangel</surname><given-names>A</given-names></name> (<year>2010</year>) <article-title>Visual fixations and the computation and comparison of value in simple choice</article-title>. <source>Nature Neuroscience</source> <volume>13</volume>: <fpage>1292</fpage>–<lpage>1298</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Weber1">
        <label>64</label>
        <mixed-citation publication-type="other" xlink:type="simple">Weber E, Johnson E (2006) Constructing preferences from memory. In: Lichtenstein S, Slovic P, editors. The Construction of Preference. New-York: Cambridge University Press. pp. 397–410.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Zink1">
        <label>65</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zink</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>Pagnoni</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Martin-Skurski</surname><given-names>ME</given-names></name>, <name name-style="western"><surname>Chappelow</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Berns</surname><given-names>GS</given-names></name> (<year>2004</year>) <article-title>Human striatal re-sponses to monetary reward depend on saliency</article-title>. <source>Neuron</source> <volume>42</volume>: <fpage>509</fpage>–<lpage>517</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Shenhav1">
        <label>66</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shenhav</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Barrett</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Bar</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Affective value and associative processing share a cortical substrate</article-title>. <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source> <fpage>1</fpage>–<lpage>14</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Gonzalez1">
        <label>67</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gonzalez</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>G</given-names></name> (<year>1999</year>) <article-title>On the shape of the probability weighting function</article-title>. <source>Cognitive Psychology</source> <volume>38</volume>: <fpage>129</fpage>–<lpage>166</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Fox1">
        <label>68</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fox</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Hadar</surname><given-names>L</given-names></name> (<year>2006</year>) <article-title>Decisions from experience = sampling error+prospect theory: Reconsid-ering Hertwig, Barron, Weber &amp; Erev (2004)</article-title>. <source>Judgment and Decision Making</source> <volume>1</volume>: <fpage>159</fpage>–<lpage>161</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-PayzanLeNestour1">
        <label>69</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Payzan-LeNestour</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name> (<year>2010</year>) <article-title>Risk, estimation uncertainty, and unexpected uncertainty: Bayesian learning in unstable settings</article-title>. <source>PLoS Computational Biology</source> <volume>6</volume>: <fpage>29</fpage>–<lpage>30</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Huettel1">
        <label>70</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huettel</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Song</surname><given-names>A</given-names></name>, <name name-style="western"><surname>McCarthy</surname><given-names>G</given-names></name> (<year>2005</year>) <article-title>Decisions under uncertainty: Probabilistic context inu-ences activation of prefrontal and parietal cortices</article-title>. <source>Journal of Neuroscience</source> <volume>25</volume>: <fpage>3304</fpage>–<lpage>3311</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Bossaerts1">
        <label>71</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name> (<year>2010</year>) <article-title>Risk and risk prediction error signals in anterior insula</article-title>. <source>Brain Structure and Function</source> <volume>214</volume>: <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Critchley1">
        <label>72</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Critchley</surname><given-names>HD</given-names></name>, <name name-style="western"><surname>Mathias</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name> (<year>2001</year>) <article-title>Neural activity in the human brain relating to uncer-tainty and arousal during anticipation</article-title>. <source>Neuron</source> <volume>29</volume>: <fpage>537</fpage>–<lpage>545</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Carter1">
        <label>73</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carter</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Veen</surname><given-names>VV</given-names></name> (<year>2007</year>) <article-title>Anterior cingulate cortex and conflict detection: An update of theory and data</article-title>. <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source> <volume>7</volume>: <fpage>367</fpage>–<lpage>379</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-Yu1">
        <label>74</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yu</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name> (<year>2003</year>) <article-title>Expected and unexpected uncertainty: ACh and NE in the neocortex</article-title>. <source>Advances in neural information processing systems</source> <volume>15</volume>: <fpage>173</fpage>–<lpage>180</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002895-dAcremont1">
        <label>75</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>d'Acremont</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name> (<year>2008</year>) <article-title>Neurobiological studies of risk assessment: A comparison of expected utility and mean-variance approaches</article-title>. <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source> <volume>8</volume>: <fpage>363</fpage>–<lpage>374</lpage>.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
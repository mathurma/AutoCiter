<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-02217</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004268</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Predicting Cortical Dark/Bright Asymmetries from Natural Image Statistics and Early Visual Transforms</article-title>
<alt-title alt-title-type="running-head">Visual Asymmetries between Darks and Brights</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Cooper</surname> <given-names>Emily A.</given-names></name>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Norcia</surname> <given-names>Anthony M.</given-names></name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001">
<addr-line>Department of Psychology, Stanford University, Stanford, California, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Einhäuser</surname> <given-names>Wolfgang</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Technische Universitat Chemnitz, GERMANY</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: EAC AMN. Performed the experiments: EAC. Analyzed the data: EAC. Wrote the paper: EAC AMN.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">emily.a.cooper@dartmouth.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>5</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>28</day>
<month>5</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>5</issue>
<elocation-id>e1004268</elocation-id>
<history>
<date date-type="received">
<day>9</day>
<month>12</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>28</day>
<month>3</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Cooper, Norcia</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004268" xlink:type="simple"/>
<abstract>
<p>The nervous system has evolved in an environment with structure and predictability. One of the ubiquitous principles of sensory systems is the creation of circuits that capitalize on this predictability. Previous work has identified predictable non-uniformities in the distributions of basic visual features in natural images that are relevant to the encoding tasks of the visual system. Here, we report that the well-established statistical distributions of visual features -- such as visual contrast, spatial scale, and depth -- differ between bright and dark image components. Following this analysis, we go on to trace how these differences in natural images translate into different patterns of cortical input that arise from the separate bright (ON) and dark (OFF) pathways originating in the retina. We use models of these early visual pathways to transform natural images into statistical patterns of cortical input. The models include the receptive fields and non-linear response properties of the magnocellular (M) and parvocellular (P) pathways, with their ON and OFF pathway divisions. The results indicate that there are regularities in visual cortical input beyond those that have previously been appreciated from the direct analysis of natural images. In particular, several dark/bright asymmetries provide a potential account for recently discovered asymmetries in how the brain processes visual features, such as violations of classic energy-type models. On the basis of our analysis, we expect that the dark/bright dichotomy in natural images plays a key role in the generation of both cortical and perceptual asymmetries.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Sensory systems must contend with a tremendous amount of diversity in the natural world. Gaining a detailed description of the natural world’s statistical regularities is a critical part of understanding how the nervous system is adapted to its environment. Here, we report that the well-established statistical distributions of basic visual features—such as visual contrast and spatial scale—diverge when separated into bright and dark components. Operations such as dark/bright segregation are key features of early visual pathways. By modeling these pathways, we demonstrate that the dark and bright visual patterns driving cortical networks are asymmetric across a number of visual features, producing previously unappreciated second-order regularities. The results provide a parsimonious account for recently discovered asymmetries in cortical activity.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by National Institutes of Health Grant 5R01EY018875-05 (AMN) and a research contract between Sony Corporation and Stanford University (AMN). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="1"/>
<page-count count="25"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>All data analyzed in this paper are already available from the cited researchers. MATLAB code for performing the visual modeling are included in Supporting Information (<xref ref-type="supplementary-material" rid="pcbi.1004268.s001">S1 File</xref>).</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>One of the major insights of modern neuroscience is the recognition that regularities in the environment are embedded and exploited in neural circuitry [<xref ref-type="bibr" rid="pcbi.1004268.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref002">2</xref>]. In the case of the visual system, this insight has led to the discovery of fundamental principles for encoding basic visual features, such as contrast, spatial scale, and edge orientation [<xref ref-type="bibr" rid="pcbi.1004268.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1004268.ref005">5</xref>]. Environmental regularities also play a role in the higher level processes of visual perception and inference. For example, when hunting for berries, it is useful to have prior knowledge that berries tend to be small, round, and red. Perception relies on using such prior knowledge about the environment to make inferences from the imperfect visual signals [<xref ref-type="bibr" rid="pcbi.1004268.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1004268.ref008">8</xref>]. It is thus clear that a detailed quantification of the statistical regularities in natural images is a critical part of understanding the visual brain. However, it is equally critical that these regularities be understood in the context of known pre-cortical visual transformations. Here, we describe an ensemble of robust statistical patterns in natural images that arise from the spatial layouts of bright and dark visual features. We furthermore show that these patterns, when combined with neural transforms in the early visual pathways, produce statistical regularities in the signals arriving to primary visual cortex. These regularities in the input to cortex provide a simple explanation for a range of recent neurophysiological findings: cells in visual cortex respond asymmetrically to brights and darks [<xref ref-type="bibr" rid="pcbi.1004268.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1004268.ref017">17</xref>], with greater cortical responses to dark features particularly at high visual contrasts, low spatial frequencies, and far depths [<xref ref-type="bibr" rid="pcbi.1004268.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref015">15</xref>].</p>
<p><xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1</xref> illustrates the known first-order statistical regularities of natural images for various basic visual features, derived here from a large calibrated image set [<xref ref-type="bibr" rid="pcbi.1004268.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref019">19</xref>]. These features include visual contrast (<xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1B</xref>), spatial frequency (or scale) (<xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1C</xref>), edge orientation (<xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1D</xref>), and relative depth (<xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1E</xref>). Note that the ordinate scales differ between the different feature types. To understand how the structure particular to natural images contributes to these patterns, the same probability distributions are also shown for a set of randomly generated image pixels and randomly generated distances (Fig <xref ref-type="fig" rid="pcbi.1004268.g001">1F</xref>–<xref ref-type="fig" rid="pcbi.1004268.g001">1J</xref>).</p>
<fig id="pcbi.1004268.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004268.g001</object-id>
<label>Fig 1</label>
<caption>
<title>First-order statistical patterns in natural images.</title>
<p>(A) Example of a natural image taken from a calibrated dataset [<xref ref-type="bibr" rid="pcbi.1004268.ref018">18</xref>]. The image has been gamma-corrected for visibility. (B-D) Probability density distributions for percent contrast (Weber), spatial frequency, and orientation calculated over an ensemble of 200 images. Contrast values for each pixel were calculated using calibrated image filter responses, and spatial frequency and orientation were calculated as magnitudes in the Fourier spectrum (See <xref ref-type="sec" rid="sec002">Methods</xref> for details). None of these distributions are uniform in natural scenes: low contrasts, low spatial frequencies, and cardinal orientations (0/180 = horizontal, 90 = vertical) are observed relatively more frequently than high contrasts, high spatial frequencies, and oblique orientations. (E) Probability density distribution for relative depth calculated over an ensemble of 31 depth maps from natural scenes [<xref ref-type="bibr" rid="pcbi.1004268.ref019">19</xref>]. Relative depth at each pixel was defined as the distance relative to the average distance of the local neighborhood. The most likely depth is near zero, with nearer depths (negative) and farther depths (positive) being relatively less likely. (F) Example of a white noise image with a Gaussian luminance distribution. (G-J) Using the same techniques as for natural images, the probability distributions were calculated over 25 noise images or noise depth maps. Distributions for spatial frequency and orientation are uniform for these images, whereas contrast and depth are both dominated by near-zero values. (Abbreviations: cycles per degree (cpd), degrees (deg), diopters (D)).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.g001"/>
</fig>
<p>Natural images are dominated by low contrasts (<xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1B</xref>) [<xref ref-type="bibr" rid="pcbi.1004268.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref021">21</xref>], but have relatively more high contrasts than the random pixels (<xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1G</xref>). Natural images also contain more low spatial frequencies [<xref ref-type="bibr" rid="pcbi.1004268.ref022">22</xref>]—or large scale patterns—reflecting the fact that visual features tend to cluster together with other similar features (Fig <xref ref-type="fig" rid="pcbi.1004268.g001">1C</xref> and <xref ref-type="fig" rid="pcbi.1004268.g001">1H</xref>). In terms of edge orientation, natural images contain a slight bias towards having more cardinally oriented edges (Fig <xref ref-type="fig" rid="pcbi.1004268.g001">1D</xref> and <xref ref-type="fig" rid="pcbi.1004268.g001">1I</xref>) [<xref ref-type="bibr" rid="pcbi.1004268.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref023">23</xref>]. This pattern can be attributed both to natural phenomena such as the horizon and tree lines, as well as to the carpentered lines of man-made structures. Finally, natural scenes can also be decomposed into a distribution of depths. In <xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1E</xref>, we show the distributions of relative depths—distances compared to the average distance in the local neighborhood. This distribution is peaked near zero. A randomly generated set of distances resulted in a similar, although broader, distribution shape (<xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1J</xref>). These first-order patterns in natural scenes have all been well-described in the previous literature. Here, we quantify a set of second-order patterns and show that these patterns arise naturally from interactions between first-order natural image properties.</p>
<p>The key to uncovering these regularities is a separate consideration of bright and dark visual features. In the early stages of visual processing in the retina, bright and dark features are processed separately via parallel pathways—one pathway encodes local areas of brightness (ON) and the other encodes local areas of darkness (OFF). This dark/bright dichotomy, however, has been largely overlooked in the study of natural scene statistics. There are three relevant observations that motivate our analysis: natural scenes contain more dark visual contrast [<xref ref-type="bibr" rid="pcbi.1004268.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref025">25</xref>], this dark bias increases at higher contrast levels [<xref ref-type="bibr" rid="pcbi.1004268.ref015">15</xref>], and dark visual contrasts also tend to be associated with farther relative depths [<xref ref-type="bibr" rid="pcbi.1004268.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref026">26</xref>]. These observations led us to hypothesize that the bright and dark visual features of natural images may differ along other dimensions as well. If this was the case, it would make sense for the visual system to exploit these differences.</p>
<p>Confirming and expanding on previous results, we found that bright and dark visual features are distributed asymmetrically in terms of their contrast levels and relative depths [<xref ref-type="bibr" rid="pcbi.1004268.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref026">26</xref>]. In addition, we found that the spatial frequency content of natural scenes differs substantially between brights and darks, with a higher dark bias at low spatial frequencies. We identify the origins of each of these regularities by synthesizing and analyzing noise images containing combinations of first-order image statistics. We then model the stages of early visual processing—which themselves contain several dark/bright asymmetries—and measure the statistical distribution of the cortical inputs from natural scenes after they have been processed through the ON and OFF pathways. Our analysis provides a parsimonious explanation for dark/bright asymmetries in well-known perceptual phenomena and recently discovered cortical phenomena.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec003">
<title>Creation of Bright and Dark Images</title>
<p>We analyzed 200 images in the Van Hateren Dataset (IML format, 1536 × 1024 pixels) [<xref ref-type="bibr" rid="pcbi.1004268.ref018">18</xref>] for the main analysis and 80 images in the McGill Calibrated Color Image Database (TIF format, 768 × 576 pixels) [<xref ref-type="bibr" rid="pcbi.1004268.ref027">27</xref>] for an additional analysis. We converted pixel values to light intensity using the provided camera calibration information. The McGill images were additionally converted from color to grayscale by applying a standard conversion to the red (<italic>r</italic>), green (<italic>g</italic>) and blue (<italic>b</italic>) channels: <italic>gray</italic> = 0.299<italic>r</italic>+0.587<italic>g</italic>+0.114<italic>b</italic>. Based on the provided camera and image information, Van Hateren image pixels were assumed to be approximately 1 arcminute (arcmin) wide squares and McGill image pixels were assumed to be approximately half that size. To segment these images into their bright and dark features, we convolved them with 2D difference of Gaussian (DOG) filters (Fig <xref ref-type="fig" rid="pcbi.1004268.g002">2A</xref> and <xref ref-type="fig" rid="pcbi.1004268.g002">2B</xref>). Several different DOG sizes and shapes were used to ensure that any results were not idiosyncratic to a specific filter. For the main analysis, we report results for a DOG with a standard deviation for the central Gaussian (<italic>σ</italic><sub><italic>c</italic></sub>) of 4 arcmin and a surround/center ratio (<italic>σ</italic><sub><italic>s</italic></sub>/<italic>σ</italic><sub><italic>c</italic></sub>) of 2. Results for the remaining DOG types are reported in the Supporting Information. These results include DOGs with smaller and larger central standard deviations (2 and 8 arcmin), and surround/center ratios (1.5 and 4). All Gaussians were unit sum, so the resulting filters were zero sum. We then applied a normalizing division to scale the filter response according to the local mean luminance. The responses were thus similar to percent contrast. The normalizing filter was equal in size to the surround Gaussian (<italic>σ</italic><sub><italic>n</italic></sub> = <italic>σ</italic><sub><italic>s</italic></sub>). Thus, the resulting contrast filter response <italic>c</italic> for a pixel at location (<italic>x</italic>, <italic>y</italic>) was:
<disp-formula id="pcbi.1004268.e001"><alternatives><graphic id="pcbi.1004268.e001g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e001"/><mml:math id="M1" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>y</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>g</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>y</mml:mi> <mml:mo>;</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>c</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi>g</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>y</mml:mi> <mml:mo>;</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mi>g</mml:mi> <mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>y</mml:mi> <mml:mo>;</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>g</italic>(<italic>x</italic>, <italic>y</italic>;<italic>σ</italic>) is a 2D Gaussian of the form <inline-formula id="pcbi.1004268.e002"><mml:math id="M2" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mi>π</mml:mi> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mi>exp</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mo>−</mml:mo> <mml:mo stretchy="false">(</mml:mo> <mml:msup><mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:msup><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo stretchy="false">)</mml:mo> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. This contrast filter was based on previous work examining physiologically meaningful computations of contrast in natural images [<xref ref-type="bibr" rid="pcbi.1004268.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref028">28</xref>]. After convolution, the image edges were cropped by 1/2 filter width to remove boundary artifacts.</p>
<fig id="pcbi.1004268.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004268.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Separating images into bright and dark features.</title>
<p>(A) Images from calibrated data sets [<xref ref-type="bibr" rid="pcbi.1004268.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref027">27</xref>] were filtered with normalized bandpass contrast operators—difference of Gaussians (DOGs). Filter outputs were divisively normalized by the local luminance as determined by a third Gaussian with a standard deviation equal to the larger Gaussian of the DOG. (B) The resulting images contained both negative and positive local contrast features. The colormap goes from black (negative contrast) to white (positive contrast), with middle gray indicating zero contrast. (C,D) These images were separated into brights (positive contrasts) and darks (negative contrasts).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.g002"/>
</fig>
<p>The range of values that result from convolving an image with <italic>c</italic> depends on the properties of the component Gaussians and therefore is not immediately comparable to the percent contrast values typically reported for experimental stimuli such as points of light or oriented gratings. So next, we converted these filter responses into units of equivalent contrast. As has been described previously [<xref ref-type="bibr" rid="pcbi.1004268.ref020">20</xref>], we applied the contrast filters to a range of individual images of spots of light or dark on a solid background. The diameter of the spot was always equal to the full width half maximum (FWHM) of the positive lobe of the DOG filter and the luminance values were uniform within the spot. Images were created with normalized luminance values ranging from zero to one, with the surrounding values always set to 0.5. The specific luminance values selected do not affect the calibration results. The percent contrast of these spots can be computed using two standard definitions: Weber contrast (<italic>w</italic>) and Michelson contrast (<italic>m</italic>). The equations for these two types of contrast were defined as follows:
<disp-formula id="pcbi.1004268.e003"><alternatives><graphic id="pcbi.1004268.e003g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e003"/><mml:math id="M3" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>w</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mo>-</mml:mo> <mml:mi>b</mml:mi></mml:mrow> <mml:mi>b</mml:mi></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula> <disp-formula id="pcbi.1004268.e004"><alternatives><graphic id="pcbi.1004268.e004g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e004"/><mml:math id="M4" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mo>-</mml:mo> <mml:mi>b</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where <italic>s</italic> is the luminance of the spot and <italic>b</italic> is the luminance of the background. Michelson contrast is typically used for gratings rather than spots, but we included this definition in our analysis for completeness. We created a lookup table for each filter and converted the filter response levels into the Weber or Michelson contrast of a single spot that would produce an equivalent response. We used linear interpolation for responses that fell in-between lookup table values.</p>
<p>This calculation results in lookup tables in which filter responses of equal and opposite magnitude will not necessarily translate to equal and opposite percent contrast values. These differences arise because the divisive term of the filter (<italic>g</italic>(<italic>x</italic>, <italic>y</italic>;<italic>σ</italic><sub><italic>n</italic></sub>) in <xref ref-type="disp-formula" rid="pcbi.1004268.e001">Eq 1</xref>) is affected by the luminance of both the central spot <italic>s</italic> and the background region <italic>b</italic> in a way that is not necessarily equivalent to the divisive terms of the contrast definitions. For Weber contrast, only the background luminance affects the divisive term, and for Michelson contrast, the spot and background contribute with equal weight (Eqs <xref ref-type="disp-formula" rid="pcbi.1004268.e003">2</xref> and <xref ref-type="disp-formula" rid="pcbi.1004268.e004">3</xref>). In the case of the Weber definition, the filter response divisive term is relatively larger than the Weber divisive term when the spot is bright, and relatively smaller when the spot is dark. Thus, a bright spot tends to produce a lower filter response than a dark spot of the same Weber Contrast. In addition, the magnitude of these positive and negative contrast differences will scale with the size of the spot relative to the DOG filter, because more and more of the divisive Gaussian is affected by the spot. As stated above, we selected spots with diameters equal to the FWHM of the DOGs. This size produces a reasonable compromise between minimizing the positive and negative contrast differences, while still producing a robust filter response at ±100% contrast. Responses that fell outside of this range of equivalent contrasts were clamped to these maximum and minimum values—this was only 3.6% of responses in the main analysis. In the resulting values, positive contrasts indicate the locally bright visual points and negative contrasts indicate the locally dark visual points in the natural images. The images were segmented into their bright and dark features by taking either only the positive values (bright contrasts) or only the negative values (dark contrasts), in each case setting the remaining pixel values to zero (Fig <xref ref-type="fig" rid="pcbi.1004268.g002">2C</xref> and <xref ref-type="fig" rid="pcbi.1004268.g002">2D</xref>).</p>
<p>To make sure that our results were not idiosyncratic to this formulation of image contrast, we implemented an alternative contrast definition with only one free parameter and no need for equivalent contrast conversions. In this case, we simply low-pass filtered each image with a single 2D Gaussian and computed the Weber contrast (<italic>w</italic>) of each pixel, treating the original image pixel value as <italic>s</italic> and the low-passed local average value as <italic>b</italic>.</p>
</sec>
<sec id="sec004">
<title>Creation of Noise Images</title>
<p>We created five classes of noise images for comparison with natural images. Each class contained 25 distinct image/distance map pairs (1024 × 1024 pixels each). The first image class, <italic>Gaussian white noise</italic>, had a uniform frequency distribution and random-phase intensities drawn from a Gaussian distribution. Each subsequent image class was constrained to have an additional global characteristic typical of natural images. The next class, <italic>Gaussian 1/<italic>f</italic><sup><italic>α</italic></sup> noise</italic>, had a non-uniform spatial frequency distribution characterized by a 1/<italic>f</italic><sup><italic>α</italic></sup> fall off (<italic>α</italic> = 1.3). The third class, <italic>skew 1/<italic>f</italic><sup><italic>α</italic></sup> noise</italic>, additionally contained intensity values drawn from a positively skewed distribution (the intensities were gamma-adjusted by raising each intensity value to a power of three). The fourth class, <italic>skew 1/<italic>f</italic><sup><italic>α</italic></sup> oriented noise</italic>, additionally contained boosted intensity values in orientation bands centered along vertical and horizontal orientations. The fifth class, <italic>skew 1/<italic>f</italic><sup><italic>α</italic></sup> oriented noise with correlation</italic>, was identical to the fourth class in the images, but contained modified distance maps.</p>
<p>Distance maps for all classes were also generated as Gaussian distributed values around a randomly selected average distance (mean distance = 40 meters, mean depth range = 80 meters), and attenuated high spatial frequencies (1/<italic>f</italic><sup><italic>α</italic></sup> fall off with <italic>α</italic> = 1.3). For the fifth class of noise, the intensity values were scaled by a factor of 2.5 and subtracted from the distance values, imposing a modest negative intensity/depth correlation (mean <italic>r</italic> = -0.07). Noise images were separated into brights and darks and analyzed in the same way as the natural images.</p>
</sec>
<sec id="sec005">
<title>Distributions of Visual Contrast, Spatial Orientation, and Spatial Frequency</title>
<p>We computed contrast frequencies via a smoothed histogram of equivalent contrasts using equally spaced 5.4%-wide bins in steps of 2.7%. Values where contrast was equal to zero were excluded. To create spatial frequency and orientation distributions, we first computed the Fourier amplitude of each image, after multiplication with a circularly symmetric Hanning window. The amplitude spectrum was masked to the highest spatial frequency present at all orientations and to a low spatial frequency of 4 cycles per image. We then used 10°-wide, anti-aliased wedge masks to compute the mean amplitude centered around each orientation, in steps of 5°. We used 37 equally spaced log steps in spatial frequency and computed the mean across anti-aliased ring masks in cycles per degree (the width of each ring also increased logarithmically with spatial frequency). Each distribution was summed across all images and normalized to produce a probability density distribution for bright and dark contrast, orientation, and spatial frequency. Probability densities were normalized to the number of occurrences across both bright and dark contrasts in order to preserve the global dark/bright differences. In addition, the ratio of the summed distributions was calculated to produce the dark/bright amplitude ratio. Feature values with probability density of less than 10<sup>−5</sup> were excluded from this ratio calculation. Because this analysis in the Fourier domain removed the DC offset (overall mean amplitude) of the images, we computed the overall amplitude difference separately and added it back in to dark/bright ratio distribution of orientations (for spatial frequencies, the mean difference is not plotted). For the distributions shown in the Introduction (<xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1</xref>), the contrast probabilities were averaged over bright and dark points to get a one-sided contrast distribution, and all other analyses were performed prior to dark/bright segregation (i.e., on the original image pixel values).</p>
</sec>
<sec id="sec006">
<title>Distributions of Relative Depth</title>
<p>A separate dataset containing paired natural image and distance information (measured with a laser range scanner) was used to compute the relative depth distributions [<xref ref-type="bibr" rid="pcbi.1004268.ref019">19</xref>]. We used a subset of 31 images from this dataset that all had a pixel size of approximately 3 arcmin. We first converted the color images to grayscale using the same conversion described above. Next we converted the distance values to relative depth. The average local distance around each pixel was computed by convolving the distance map with a Gaussian filter with standard deviation of 30 arcmin. Distance maps had some missing or undefined values (for example, in the sky), so averages included only the valid distance estimates within the filter. Distance values were then converted from meters to Diopters (D; 1/meters) and the mean dioptric distance was subtracted out. This was done for two reasons: the binocular disparities encoded in early visual cortex scale linearly with diopters and are related to depth relative to a reference fixation. We computed the amplitude at each relative depth for bright and dark points by summing up the filter response amplitude in bins 1.6 × 10<sup>−3</sup> D-wide in steps of 7.9 × 10<sup>−4</sup> D. These distributions were highly kurtotic, so in <xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3</xref> the axes are clipped to contain 95% of the values. Again, for <xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1</xref> in the Introduction, an identical analysis was performed using the original pixel values.</p>
<fig id="pcbi.1004268.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004268.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Dark and bright features are asymmetric in natural scenes.</title>
<p>(A-D) Probability distributions are plotted as in <xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1</xref>. Solid red lines show results for brights and dashed blue lines show results for darks. Results for contrast, orientation, and spatial frequency come from a single data set [<xref ref-type="bibr" rid="pcbi.1004268.ref018">18</xref>] and results for relative depth come from a second data set [<xref ref-type="bibr" rid="pcbi.1004268.ref019">19</xref>]. The inset in panel A shows the results if the Michelson definition of contrast is used instead of the Weber definition. Probability values are normalized across both dark and bright features. (E-H) For each value in the upper panels, the ratio of the dark probability to the bright probability is plotted. Values greater than 1 (dashed line, blue arrow) indicate that the feature is more likely to be observed as dark. The inset in panel E shows the results if the Michelson definition of contrast is used instead of the Weber definition. (I-K) Sets of results for three individual natural images are shown. Each group of 4 panels includes the original image, and normalized histograms for Weber contrast, spatial frequency, and orientation. The images have been gamma-corrected. Abscissa scales are the same as panels (A-D), and ordinates scales are normalized frequency within the single image (0-1). The spatial frequency data in panel K have a smaller range because this example comes from a second image set with smaller image sizes [<xref ref-type="bibr" rid="pcbi.1004268.ref027">27</xref>].</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.g003"/>
</fig>
</sec>
<sec id="sec007">
<title>Simulation of Retinal Ganglion Cell Responses</title>
<p>We wanted to determine how the statistical patterns in natural images translate into statistical patterns of input to primary visual cortex. To do this, we simulated the receptive fields and response nonlinearities of earlier stages of visual processing, as these provide the relevant input to cortex. The normalized DOG contrast filters that we used to separate visual images into bright and dark features were modified to simulate the spatial receptive fields of retinal ganglion cells (RGCs) as reported in [<xref ref-type="bibr" rid="pcbi.1004268.ref029">29</xref>]. We modeled two classes of RGCs: a parvocellular pathway (P) comprised of midget cells and a magnocellular pathway (M) comprised of parasol cells. For each class, we also modeled receptive fields for foveal and peripheral cells and ON and OFF divisions. The standard deviations of the central Gaussians for each cell type in arcmin are given in <xref ref-type="table" rid="pcbi.1004268.t001">Table 1</xref>. M receptive fields tend to be larger than P, peripheral receptive fields tend to be larger than foveal, and ON receptive fields tend to be larger than OFF. The values reported in [<xref ref-type="bibr" rid="pcbi.1004268.ref029">29</xref>] were collapsed across ON and OFF cell types, so to include the well-known tendency for ON cells of a given subclass to have larger receptive fields than OFF cells, we scaled the standard deviations by 110% to estimate the ON receptive field size and 90% to estimate the OFF receptive field size [<xref ref-type="bibr" rid="pcbi.1004268.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref031">31</xref>]. To determine the surround Gaussian standard deviation, the central Gaussian’s standard deviation for each subclass was scaled by a factor of six [<xref ref-type="bibr" rid="pcbi.1004268.ref029">29</xref>]. All receptive fields were treated as zero sum prior to applying response nonlinearities, and were divisively normalized by a Gaussian equivalent to the surround region to simulate the effects of local light adaptation.</p>
<table-wrap id="pcbi.1004268.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004268.t001</object-id>
<label>Table 1</label>
<caption>
<title>Standard deviations for central Gaussians in model RGCs (in arcminutes).</title>
</caption>
<alternatives>
<graphic id="pcbi.1004268.t001g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004268.t001" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Pathway (cell type)</th>
<th align="left" rowspan="1" colspan="1">Location</th>
<th colspan="2" align="center" rowspan="1">Center Std Dev (arcmin)</th>
</tr>
<tr>
<th align="left" rowspan="1" colspan="1"/>
<th align="left" rowspan="1" colspan="1"/>
<th align="left" rowspan="1" colspan="1">ON</th>
<th align="left" rowspan="1" colspan="1">OFF</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Parvocellular (midget)</td>
<td align="left" rowspan="1" colspan="1">foveal</td>
<td align="char" char="." rowspan="1" colspan="1">1.4</td>
<td align="char" char="." rowspan="1" colspan="1">1.1</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">peripheral</td>
<td align="char" char="." rowspan="1" colspan="1">3.3</td>
<td align="char" char="." rowspan="1" colspan="1">2.7</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Magnocellular (parasol)</td>
<td align="left" rowspan="1" colspan="1">foveal</td>
<td align="char" char="." rowspan="1" colspan="1">4.7</td>
<td align="char" char="." rowspan="1" colspan="1">3.8</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1">peripheral</td>
<td align="char" char="." rowspan="1" colspan="1">8.4</td>
<td align="char" char="." rowspan="1" colspan="1">6.9</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001">
<p>Model RGC receptive field sizes taken after [<xref ref-type="bibr" rid="pcbi.1004268.ref029">29</xref>]. Values are based on median <italic>r</italic><sub><italic>c</italic></sub> parameter reported in Table 1 of the previous report. For foveal regions, values were taken from the 0-5° range for P cells and the 0-10° range for M cells. Values from the cited Table are in terms of half width of a Gaussian fit at 1/<italic>e</italic> of the Gaussian’s maximum. These values were converted to standard deviation by dividing by <inline-formula id="pcbi.1004268.e005"><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow></mml:math></inline-formula>.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>RGCs have nonlinear and asymmetric contrast response functions. We modeled these response functions on previously reported direct measurements from the mammalian retina [<xref ref-type="bibr" rid="pcbi.1004268.ref031">31</xref>–<xref ref-type="bibr" rid="pcbi.1004268.ref033">33</xref>]. Both ON and OFF cell responses are rectifying, but the OFF response is more so. The ON RGCs begin increasing their spike rate when contrast is still negative, and thus have a higher response rate at zero and low contrasts [<xref ref-type="bibr" rid="pcbi.1004268.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref032">32</xref>]. However, the ON response rate at high (near 100%) contrasts has been reported to be much lower than the OFF response at high (near -100%) contrasts [<xref ref-type="bibr" rid="pcbi.1004268.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref033">33</xref>]. To model these contrast response properties, we first defined two functions that reflected the properties of the normalized ON and OFF cell responses as a function of stimulus Weber contrast. These were created by first taking a cumulative Gaussian function:
<disp-formula id="pcbi.1004268.e006"><alternatives><graphic id="pcbi.1004268.e006g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e006"/><mml:math id="M6" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>;</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>f</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>f</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mtext>erf</mml:mtext> <mml:mo>(</mml:mo> <mml:mfrac><mml:mrow><mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>f</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mi>σ</mml:mi> <mml:mi>f</mml:mi></mml:msub> <mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
where <italic>w</italic>′ is the equivalent Weber contrast of a filter response, erf(⋅) denotes the error function, and <italic>μ</italic><sub><italic>f</italic></sub> and <italic>σ</italic><sub><italic>f</italic></sub> were selected to reflect RGC response properties (37.5% and 30% for the ON responses, 60% and 20% for the OFF responses, respectively). The values of <italic>f</italic> were normalized to have a value of 1 at maximum contrast (100%). These functions were then modified to reflect the differences in preferred contrast polarity and response maximum between the two pathways:
<disp-formula id="pcbi.1004268.e007"><alternatives><graphic id="pcbi.1004268.e007g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e007"/><mml:math id="M7" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>;</mml:mo> <mml:mn>37</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn> <mml:mo>,</mml:mo> <mml:mn>30</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>O</mml:mi> <mml:mi>N</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>f</mml:mi> <mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>;</mml:mo> <mml:mn>60</mml:mn> <mml:mo>,</mml:mo> <mml:mn>20</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>O</mml:mi> <mml:mi>F</mml:mi> <mml:mi>F</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo/></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
where <italic>k</italic> is the expected RGC response. We then used these functions to remap the filter responses from equivalent Weber contrast into ON and OFF RGC response magnitudes. For example, a filter response reflecting positive Weber contrast of 25% would be mapped to a minor ON response (0.17) and an effectively zero OFF response. For -25% contrast, the OFF response would be present (0.04) and there would be a small ON response as well (0.01). This model assumes that the contrast response functions of RGCs are similar for different levels of mean luminance, although some recent work raises the possibility that mean luminance may interact with these responses [<xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>]. For this analysis, filter responses with equivalent Weber contrast out of the range of modeled values (+/-100%) were clamped to this range. MATLAB code for simulating RGC responses with this model is provided in the Supporting Information (<xref ref-type="supplementary-material" rid="pcbi.1004268.s001">S1 File</xref>).</p>
<p>Finally, the simulated RGC response amplitudes for each subclass of cells were computed across all of the natural images. These were broken down into visual features as described in the previous Methods sections in order to estimate the expected distributions of cortical input magnitude over all of the visual features of interest.</p>
</sec>
</sec>
<sec id="sec008" sec-type="results">
<title>Results</title>
<sec id="sec009">
<title>Dark and Bright Features Distribute Asymmetrically in Natural Images</title>
<p>The statistical properties of natural images differ along several dimensions between brights (<xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3</xref> solid red lines) and darks (<xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3</xref> dashed blue lines). The upper panels of Fig <xref ref-type="fig" rid="pcbi.1004268.g003">3(A)</xref>–<xref ref-type="fig" rid="pcbi.1004268.g003">3(D)</xref> show the probability distributions of contrast, spatial frequency, orientation, and relative depth. The lower panels (3E–3H) show the ratio of dark to bright amplitude for each of these features, where values greater than 1 (dashed horizontal line) indicate a greater probability for darks. The overall bias towards dark features shown in these panels reflects the previously established dominance of darkness in natural scenes [<xref ref-type="bibr" rid="pcbi.1004268.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref025">25</xref>]. Across all visual features, the dark amplitude exceeded bright by a factor of 1.4. However, we can now see that this bias is not evenly distributed across the space of visual features.</p>
<p>Weber contrast has a steeper fall off for brights than for darks (<xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3A</xref>). As visual contrast increases, the ratio of dark to bright increases as well (<xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3E</xref>). As suggested by a previous analysis [<xref ref-type="bibr" rid="pcbi.1004268.ref015">15</xref>], this means that low contrast features are equally likely to be bright or dark, but relatively high contrast features are biased towards being dark. Dark Weber contrasts, however, are limited to be 100% in magnitude or below, whereas bright contrasts can go to infinity. Thus, very high contrasts (not shown) will be exclusively produced by brights. When the Michelson contrast definition is used instead, the results are qualitatively similar, but with a larger dark bias (see insets).</p>
<p>Spatial frequency has a shallower fall off for brights (Fig <xref ref-type="fig" rid="pcbi.1004268.g003">3B</xref> and <xref ref-type="fig" rid="pcbi.1004268.g003">3F</xref>). This manifests as a cross-over of the two curves. Note that the computation of bright and dark features is by its nature a bandpass calculation—features are determined to be bright or dark relative to the mean luminance of their local region. This bandpass filtering can be seen in the attenuation of low frequencies relative to the more typical frequency distribution shown in <xref ref-type="fig" rid="pcbi.1004268.g001">Fig 1C</xref>. Despite this bandpass effect, the probability for darks is still high at relatively low spatial frequencies, and exceeds that for brights. Interestingly, the relative probabilities of brights and darks reverse at higher spatial frequencies. At the highest frequencies present in the images, the probabilities become very similar. This occurs because the dark/bright image segmentation produces sharp edges at the transitions between brights and darks, which are identical in the two images. Orientation has a slight second-order asymmetry between brights and darks at cardinal orientations (Fig <xref ref-type="fig" rid="pcbi.1004268.g003">3C</xref> and <xref ref-type="fig" rid="pcbi.1004268.g003">3G</xref>), but is otherwise evenly distributed. Finally, relative depth (Fig <xref ref-type="fig" rid="pcbi.1004268.g003">3D</xref> and <xref ref-type="fig" rid="pcbi.1004268.g003">3H</xref>) exhibits a different pattern. There is a tendency for the dark bias to increase at farther depths (darks are on average 1.2 times more likely at near depths and this increases to 1.6 times more at far depths). Note that fewer images with both luminance and depth information were available, so the depth results are noisier than the results for the other features.</p>
<p>Examining the results for some individual images can suggest which properties of natural scenes give rise to these asymmetries. Fig <xref ref-type="fig" rid="pcbi.1004268.g003">3I</xref>–<xref ref-type="fig" rid="pcbi.1004268.g003">3K</xref> show three example images with their individual frequency distributions for Weber contrast, spatial frequency, and orientation. The image in Panel I has feature distributions that are reflective of the average results across all of the images. Panel J shows an example image for which the dark bias at low spatial frequencies is absent, and Panel K shows an image for which the distributions of Weber contrast are similar for brights and darks. From these examples, we can hypothesize how the interplay between natural lighting, object surfaces, and shadows may lead to bright/dark asymmetries. In natural images, dark shadows tend to occur in the spaces between objects, whereas dark and bright textural features within objects may occur with similar frequency. This general pattern could lead to a dark bias at lower spatial frequencies (the spaces between objects), but no bias at high spatial frequencies (the details within objects), as seen in Panels I and K. In Panel J, the entire scene is extremely dark, and thus there is no clear distinction between objects and shadows. In the same vein, the prevalence of dark shadows and shading in natural scenes might tend to boost the presence of dark contrasts relative to bright contrasts. In the image in Panel K, there is only a single area of shadow, which might not be sufficient to accentuate this pattern. Similarly, it has been argued that shadows play a role in introducing a dark/far bias in natural images (not shown for these examples)[<xref ref-type="bibr" rid="pcbi.1004268.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref019">19</xref>].</p>
<p>Distributions for a second set of natural images ([<xref ref-type="bibr" rid="pcbi.1004268.ref027">27</xref>]) are shown in <xref ref-type="supplementary-material" rid="pcbi.1004268.s002">S1 Fig</xref>. Additionally, we computed the same overall statistics using contrast filters of different sizes (<xref ref-type="supplementary-material" rid="pcbi.1004268.s003">S2 Fig</xref>), different shapes (<xref ref-type="supplementary-material" rid="pcbi.1004268.s004">S3 Fig</xref>), and different forms (Gaussians instead of DOGs; <xref ref-type="supplementary-material" rid="pcbi.1004268.s005">S4 Fig</xref>). Altering the contrast filter shape and dimensions effectively modifies the specific parameters used to determine whether a point in an image is locally bright or dark relative to the surroundings. The patterns shown in <xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3</xref> appear robustly in each of these additional calculations. The factor with the most noticeable effect on the scene statistics is the total size of the contrast filter, regardless of shape. Larger filters average over a larger area of the image in determining whether a point is bright or dark. These larger filters result in a shift of the low frequency dark bias towards lower and lower spatial frequencies, and accentuate the bright bias at high spatial frequencies. Applying these different contrast filters exposes the multi-scale way in which natural scenes differ in their bright and dark content. In order to understand which features of these dark/bright differences are relevant to the visual system of the brain, however, it is essential to create physiologically-based contrast filters, which we will describe in the Results section on modeling the early visual pathways.</p>
</sec>
<sec id="sec010">
<title>Dark/Bright Asymmetries Arise from Statistical Regularities in Natural Images</title>
<p>We wanted to understand the underlying source of the dark/bright asymmetries in natural images. Are they due to the specific geometric and lighting patterns in natural scenes, or could simpler statistical patterns account for these biases? To answer this question, we performed identical analyses on synthetic noise images: white noise with a Gaussian luminance distribution (<xref ref-type="fig" rid="pcbi.1004268.g004">Fig 4A</xref>) and structured noise that we will call <italic>naturalistic noise</italic> (<xref ref-type="fig" rid="pcbi.1004268.g004">Fig 4B</xref>). Naturalistic noise contains four first-order patterns from natural scenes: a positively skewed luminance histogram (more dark points than bright points) [<xref ref-type="bibr" rid="pcbi.1004268.ref034">34</xref>], a fall off in spatial frequency (<italic>f</italic>) amplitude determined by the function 1/<italic>f</italic><sup><italic>α</italic></sup>, a predominance of vertical and horizontal orientations, and a negative correlation between the intensity of a pixel and the pixel distance.</p>
<fig id="pcbi.1004268.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004268.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Dark/bright asymmetries arise from global statistical image properties.</title>
<p>(A,B) White noise images (indicated throughout with yellow outlines) and naturalistic noise images (indicated throughout with green outlines) were separated into dark and bright features as described for the natural images analysis. (C-F) In white noise images, the distributions of visual features are identical for brights and darks. (Note that the spatial frequency distribution for these images is not flat due to the bandpass nature of the contrast filters.) (G-J) Naturalistic noise images were generated to reflect several global features of natural images, but were otherwise unstructured. In naturalistic noise images, many of the dark/bright asymmetries in natural images are reproduced. (K-N) Dark-to-bright ratios are shown for each type of noise as in <xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3</xref> to further illustrate the areas of agreement and disagreement. Yellow lines indicate white noise, green lines indicate naturalistic noise, and grey lines show the results for natural images from <xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3</xref> for comparison.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.g004"/>
</fig>
<p>Thus, naturalistic noise contains common patterns in the amplitude spectrum of natural images, but lacks the phase characteristics that result from recognizable image features, such as object boundaries, shadows, and occlusions. Do either of these types of noise images contain any of the dark/bright asymmetries found in natural images? If white noise images contain asymmetries, it would suggest that the asymmetries are due to an inherent bias present in the current definition of brights and darks, rather than a systematic pattern particular to natural images. If naturalistic noise images contain asymmetries, it would suggest that the basic first-order patterns of natural images are sufficient to drive these asymmetries, independent to particular geometric or lighting features. If geometric features are necessary for producing dark/bright asymmetries, however, then naturalistic noise should fail to reproduce the dark/bright asymmetries from natural scenes. Thus, to the extent that naturalistic noise includes dark/bright asymmetries absent in white noise, we can attribute these effects to one the four first-order patterns that were imposed on these images.</p>
<p>The lower panels of <xref ref-type="fig" rid="pcbi.1004268.g004">Fig 4</xref> show the probability distributions for these two types of noise. Panels C-F are the results for white noise, and panels G-J are the results for naturalistic noise. White noise images clearly do not contain the same dark/bright biases found in natural scenes. However, the simple model of global image patterns in naturalistic noise closely reproduces many of these biases in detail. This is further illustrated in panels K-N, which show the same dark-to-bright ratios as plotted in <xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3</xref> (yellow lines: white noise, green lines: naturalistic noise, gray lines: natural scenes). Several of the biases from natural scenes are qualitatively present in the naturalistic noise.</p>
<p>By deconstructing the four types of structure that were imposed on naturalistic noise, it is possible to hypothesize about the causes of the dark/bright asymmetries in natural images. (See Supporting Information <xref ref-type="supplementary-material" rid="pcbi.1004268.s006">S5 Fig</xref> for results from the intermediate patterns of noise that support these conclusions.) First, a positively skewed histogram increases the prevalence of dark image regions and accentuates greater dark contrasts (<xref ref-type="fig" rid="pcbi.1004268.g004">Fig 4K</xref>). Note that the white noise images are so dominated by low contrasts that almost all are below 16% (for visibility, the contrast of the example white noise bright and dark images in panel A have been increased by a factor for 3 relative to the naturalistic noise).</p>
<p>On top of this, a fall off at high spatial frequencies leads to images in which larger dark regions are clustered together separately from bright regions. That is to say, neighboring pixel intensity values become spatially correlated. Recall that the definition of local contrast entailed a normalization stage. This normalization stage converts the luminance differences into percent luminance difference, similar to the effect of local light adaptation in the early visual system [<xref ref-type="bibr" rid="pcbi.1004268.ref035">35</xref>]. Given the clustering pattern of naturalistic noise, it makes sense that normalized local contrast is boosted at the relatively low spatial scales at which dark clusters emerge (<xref ref-type="fig" rid="pcbi.1004268.g004">Fig 4L</xref>). This is because the contrast boosting within dark pixel clusters will only occur for spatial scales at which the normalization area of the contrast filter can fall mostly or entirely within a cluster of dark pixels. These dark clusters in naturalistic noise may be serving a similar function to the attached and unattached shadows if objects in natural scenes. This analysis suggests that two key factors contribute to boosting dark low spatial frequencies: local light adaptation and a 1/<italic>f</italic><sup><italic>α</italic></sup> spatial frequency distributions. Given that each of these factors are common in natural vision and images, we can predict that the dark/bright asymmetry in spatial frequency may be a nearly universal pattern for most biological visual systems. Note that simply generating 1/<italic>f</italic><sup><italic>α</italic></sup> noise with Gaussian luminance distributions is sufficient to produce images with this bias, without including the other features of naturalistic noise (<xref ref-type="supplementary-material" rid="pcbi.1004268.s006">S5 Fig</xref>). Finally, having an overall cardinal orientation bias produces largely symmetric distributions for brights and darks (<xref ref-type="fig" rid="pcbi.1004268.g004">Fig 4M</xref>) and adding a slight negative intensity/depth correlation (as has been observed in natural scenes [<xref ref-type="bibr" rid="pcbi.1004268.ref019">19</xref>]) reproduces a near/far asymmetry (<xref ref-type="fig" rid="pcbi.1004268.g004">Fig 4N</xref>).</p>
<p>This analysis shows that dark/bright asymmetries can arise from very simple statistical regularities that are shared by natural images, but are not specific to them. We propose that these regularities are likely a pervasive property of the input received by the visual system. However, just because naturalistic noise can reproduce these patterns does not prove that the structural properties that we imposed on these noise images are the actual or exclusive sources of the biases in natural images. For example, natural images contain edges and sharp object boundaries that are absent from all of the examined noise images. It is very likely that this spatial phase property of natural images contributes to their dark/bright asymmetries, because object edges are often the source of both luminance and depth discontinuities [<xref ref-type="bibr" rid="pcbi.1004268.ref036">36</xref>].</p>
</sec>
<sec id="sec011">
<title>Early Visual Pathways Carry Different Image Statistics Forward into Visual Cortex</title>
<p>Cells in primary visual cortex respond asymmetrically to the presentation of bright and dark visual features. The most striking asymmetry is a general dominance of cortical cells and cell activity devoted to processing darks. This <italic>dark dominance</italic> has been reported in multiple species, including cat, tree shrew, and human and non-human primates [<xref ref-type="bibr" rid="pcbi.1004268.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1004268.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref037">37</xref>]. Within this general dominance, a few additional patterns have started to emerge. The results of three studies show a tendency for this dark dominance to increase with greater visual contrast [<xref ref-type="bibr" rid="pcbi.1004268.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref015">15</xref>]. Two studies also found a greater dark dominance for lower spatial frequencies [<xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>] and far depths (measured via cell tuning for the binocular disparity between the two eyes)[<xref ref-type="bibr" rid="pcbi.1004268.ref012">12</xref>].</p>
<p>We showed that natural images have more dark features overall, and particularly at high contrasts, low spatial frequencies, and far depths (Fig <xref ref-type="fig" rid="pcbi.1004268.g003">3E</xref>–<xref ref-type="fig" rid="pcbi.1004268.g003">3H</xref>). Could cortical dark dominance reflect an adaptation to these patterns in the incoming visual signals? One previous study showed good agreement between the pattern of dark dominance in primary visual cortex and the distribution of contrasts in natural scenes [<xref ref-type="bibr" rid="pcbi.1004268.ref015">15</xref>]. However, it is well-known that the pre-cortical stages of visual processing contain substantial asymmetries in their treatment of brights and darks, so it is not possible to draw conclusions about cortical input patterns from the properties of natural scenes alone. For example, the responses of ON RGCs are greater at low contrasts than OFF cells [<xref ref-type="bibr" rid="pcbi.1004268.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref032">32</xref>]. This difference could easily tip the balance away from dark dominance in the afferent signal to visual cortex. We wanted to determine how pre-cortical processing asymmetries would affect the subsequent input patterns to visual cortex. To do this, we simulated the operations of the receptive fields and nonlinearities of eight RGC subpopulations and applied them to natural images. The receptive field shapes for each subpopulation and the contrast response nonlinearities for the ON and OFF divisions are shown in Fig <xref ref-type="fig" rid="pcbi.1004268.g005">5A</xref>–<xref ref-type="fig" rid="pcbi.1004268.g005">5C</xref>. We treat the ratio of OFF-signal to ON-signal (<italic>OFF bias</italic>) as a prediction of the ratio of cortical input received for dark and bright visual features over typical visual experience.</p>
<fig id="pcbi.1004268.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004268.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Patterns of dark dominance in cortical input.</title>
<p>(A) Two schematics of retinal location illustrate the layout of 8 RGC subpopulations: P pathway and M pathway, foveal and peripheral, ON and OFF. ON (bright center, dark surround) and OFF (dark center, bright surround) cells are illustrated as alternating for clarity, however each subpopulation actually fully tiles the retinal space. Bright values indicate excitatory regions and dark values indicate suppressive regions. P cells are smaller and more numerous than M cells, and foveal cells of both types are smaller than peripheral cells. Four colors are used throughout to indicate each subpopulation: P foveal (yellow), P peripheral (green), M foveal (purple), and M peripheral (orange). (B) Illustrations of the spatial receptive fields of the simulated retinal ganglion cells. Each of the four plots shows the receptive fields for ON and OFF cells of one subpopulation. Each line shows a middle slice through the isotropic 2D DOGs used to simulate RGC receptive fields. Solid lines show the extent of ON receptive fields and dashed lines show the extent of OFF receptive fields, offset laterally for visualization. The black dashed line indicates zero response. OFF receptive fields respond positively when the center is darker than the surround and visa versa. Because the surrounding Gaussian has a large standard deviation, the suppressive surrounds appear very weak in these plots. Icons located within each plot show the ratio of center-to-surround standard deviations. Details of the receptive field parameters can be found in the Methods. (C) Models of the contrast response nonlinearities previously measured for retinal ganglion cells. (D) The overall ratio of OFF to ON cortical input from each pathway for natural images and white noise images. The horizontal dashed line at 1 indicates equal OFF and ON input, values greater than 1 indicate an OFF bias. (E-H) Normalized amplitude (Amp.) distributions for each visual feature are shown for each subpopulation. For Weber contrast, ON and OFF responses were only aggregated for positive contrasts and negative contrasts, respectively. (I-L) The OFF bias was computed as the ratio of the summed OFF responses to the ON responses over all input images.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.g005"/>
</fig>
<p>For each subpopulation, the OFF bias over a set of natural scenes tended to be greater than 1 (<xref ref-type="fig" rid="pcbi.1004268.g005">Fig 5D</xref>). We wondered how much of this OFF bias was inherent to the RGC responses, so we also performed the simulation on a set of white noise images. As expected, the OFF bias shrank to less than one for this image content. This is because white noise images are dominated by low contrasts (<xref ref-type="fig" rid="pcbi.1004268.g004">Fig 4C</xref>) and the ON RGC response is greater than the OFF response at low contrasts (<xref ref-type="fig" rid="pcbi.1004268.g005">Fig 5C</xref>). These global OFF/ON ratios are affected not just by the RGC response properties, but also by the way local contrast is defined. Recall that the calculation of contrast in these images required the selection of a calibration spot stimulus. Pilot testing indicated that the global OFF bias was sensitive to this spot size, because changing the size creates shifts in the resulting contrast histograms of natural and synthetic images. Thus, the predicted OFF bias could take on a range of values, and in some scenarios reversed to be an ON bias. It remains an open question exactly how to relate RGC responses measured in the laboratory (which we used to create this model) to their responses to the complex contrast patterns in natural scenes (which we are trying to infer). Importantly, the non-uniformities in the OFF bias across visual features, discussed below, were largely robust to the selection of spot size. These second-order patterns thus provide a potential avenue for investigating the encoding on bright and dark features independent of a specific contrast model.</p>
<p>Each subpopulation also has its own signature feature distribution (Fig <xref ref-type="fig" rid="pcbi.1004268.g005">5E</xref>–<xref ref-type="fig" rid="pcbi.1004268.g005">5H</xref>). Features are plotted as normalized amplitude: the predicted amount of that subpopulation’s overall signal devoted to that feature. This is determined by both the scene properties and the cell responses. For example, because ON RGCs respond above baseline to low contrast features, the amplitude for all ON subpopulations is relatively high at low contrasts, but lower at high contrasts because high contrasts are overall less likely to occur (<xref ref-type="fig" rid="pcbi.1004268.g005">Fig 5E</xref>). In comparison, all OFF RGCs have a low amplitude at low contrasts and begin increasing their amplitude as contrast increases. Additionally, the larger receptive fields associated with the M pathway and the peripheral retina produce less signal attenuation at low spatial frequencies (<xref ref-type="fig" rid="pcbi.1004268.g005">Fig 5F</xref>). When plotted in terms of OFF bias for each subpopulation (Fig <xref ref-type="fig" rid="pcbi.1004268.g005">5I</xref>–<xref ref-type="fig" rid="pcbi.1004268.g005">5L</xref>), it becomes evident that the smallest receptive fields produce the largest OFF bias at low frequencies, as predicted by the natural images analysis (<xref ref-type="fig" rid="pcbi.1004268.g005">Fig 5J</xref>). The asymmetric receptive field sizes for ON and OFF (ON larger than OFF) lead to a second boost of OFF input at higher spatial frequencies. These frequencies are much higher than have currently been measured in primary visual cortex. For example, Kremkow et al. ([<xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>]) described a dark bias increasing from higher to lower spatial frequencies in the range of 0.03–0.75 cpd, a range over which the P pathway RGC models clearly show the same pattern, but did not report results for higher frequencies. Conversely, the near/far bias is strongest in the M pathway (<xref ref-type="fig" rid="pcbi.1004268.g005">Fig 5L</xref>). The black lines in Fig <xref ref-type="fig" rid="pcbi.1004268.g005">5I</xref>–<xref ref-type="fig" rid="pcbi.1004268.g005">5L</xref> show a weighted average response assuming that the P pathway cells are nine times more numerous than the M pathway cells [<xref ref-type="bibr" rid="pcbi.1004268.ref029">29</xref>]. It is clear from these averages that this simulation predicts more afferent signals for dark features overall, and particularly at higher contrasts, low spatial frequencies (and very high ones) and far depths.</p>
<p>Thus, specific patterns of cortical dark dominance [<xref ref-type="bibr" rid="pcbi.1004268.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref015">15</xref>] may be matched to the input from afferent pathways to primary visual cortex. In addition to these major patterns, a previous study found that dark dominance does not vary substantially with spatial orientation, which is also consistent with the modeling results (Fig <xref ref-type="fig" rid="pcbi.1004268.g005">5G</xref> and <xref ref-type="fig" rid="pcbi.1004268.g005">5K</xref>)[<xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>]. Finally, two previous studies reported a reversal towards bright dominance at low contrasts [<xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref015">15</xref>]. This pattern is not present when contrast distributions are measured from natural images directly (<xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3A</xref>), but emerges in the modeling due to the different ON and OFF response nonlinearities (<xref ref-type="fig" rid="pcbi.1004268.g005">Fig 5I</xref>). The model predicts additional bias patterns, such as the dipper shape as a function of spatial frequency and the M and P pathway differences, that can be tested experimentally.</p>
</sec>
</sec>
<sec id="sec012" sec-type="conclusions">
<title>Discussion</title>
<sec id="sec013">
<title>Implications for Classic Energy Models</title>
<p>According to hierarchical visual processing models, cortical receptive fields for basic visual features such as spatial orientation, spatial frequency, motion, and binocular disparity arise from a confluence of the ON and OFF pathways [<xref ref-type="bibr" rid="pcbi.1004268.ref038">38</xref>]. A hallmark of the energy models that have classically been used to describe these cortical receptive fields is the symmetric combination of opposite contrast polarity input [<xref ref-type="bibr" rid="pcbi.1004268.ref039">39</xref>–<xref ref-type="bibr" rid="pcbi.1004268.ref041">41</xref>]. For example, a complex cell might increase its firing rate when a vertically oriented edge is visible regardless of whether the edge is bright or dark. This could be achieved by receiving equal input from a pair of simple cells that each has a receptive field oriented to respond to either a dark (OFF) or bright (ON) vertical edge. Contrast invariance has been considered an advantage of complex cells, because they become pure detectors of the target visual feature and discard irrelevant information. However, responses from recent recordings of visual cells violate this pure contrast invariance assumption of energy models [<xref ref-type="bibr" rid="pcbi.1004268.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref042">42</xref>]. One outcome of the current work is to suggest a functional explanation for this discrepancy.</p>
<p>We propose that two factors could underly these energy model violations. The first is simply the instantaneous effect of the early visual nonlinearities on the afferent visual signal. The second is a cortical process of long-term potentiation and depression over visual experience—connections that are more active are potentiated (or up-weighted) and those that are less active are depressed (or down-weighted). To examine the first factor, we asked if two stimuli of equal and opposite Weber contrast (such as those used in physiological experiments) might generate afferent visual signals of unequal magnitude. Based on our analysis, we predicted that negative Weber contrast should produce a larger afferent signal than an equal positive contrast. We illustrate this in <xref ref-type="fig" rid="pcbi.1004268.g006">Fig 6</xref>. Images of small vertical bars with 100% positive or negative Weber contrast were presented to our RGC models (<xref ref-type="fig" rid="pcbi.1004268.g006">Fig 6A</xref>). The resulting ON and OFF pathway signals are illustrated in the right panels, with bright values indicating the presence of an ON response and dark values indicating the presence of an OFF response. These panels only show the responses for P pathway foveal cells. We summed ON and OFF signals across all pathways over a small region containing the bar to simulate the overall afferent activity reaching visual cortex. The simulation activity for the dark bar was 1.9 times greater than for the bright bar (<xref ref-type="fig" rid="pcbi.1004268.g006">Fig 6B</xref>). This calculation just provides a single example of this ratio, because the exact ratio varies depending on the size of the bar, the image area over which the responses are pooled, and the retinal location being modeled (here we included both foveal and peripheral results to get an average prediction). Nonetheless, if visual complex cells instantiating an energy-model-type computation responded with the same response gain to ON and OFF pathway signals generated by a stimulus such as this one, we would still predict a greater response to dark stimuli based on the early visual nonlinearities alone. Note, however, that some studies have reported lower dark biases in LGN cells and cortical input layers, suggesting a lower input OFF bias that is not consistent with this example [<xref ref-type="bibr" rid="pcbi.1004268.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>].</p>
<fig id="pcbi.1004268.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004268.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Patterns of dark dominance in cortical input from simple visual stimuli.</title>
<p>(A) Images of a small bright bar and dark bar (10 arcmin wide, 30 arcmin tall, on a 50 arcmin square) were shown to the model RGCs. For each bar, the response for all RGCs over the whole square, (both ON and OFF) were summed together and weighted by a factor of 9:1 for P pathway to M pathway. Example responses are shown for the foveal P pathway cells. (B) Resulting prediction for the magnitude of the afferent signals to primary visual cortex stimulated by the bright and dark bars.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.g006"/>
</fig>
<p>Previous studies have reported the OFF bias in populations of V1 neurons as being on average ∼ 1.2–3 (in cat and monkey, depending on the cortical layer [<xref ref-type="bibr" rid="pcbi.1004268.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>]). Similar OFF biases have been reported in local field potential (LFP) and electroencephalogram (EEG) recordings in monkeys and humans [<xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref037">37</xref>]. Generally, models of synaptic dynamics predict that a neuronal circuit that starts out with equal or arbitrary synaptic weights will drift towards an equilibrium state in which the weighting value for a given synapse is roughly proportionate to the activity level of the presynaptic neuron [<xref ref-type="bibr" rid="pcbi.1004268.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref044">44</xref>]. The more active synapse will be up-weighted and the less active synapse will be down-weighted. Our results are consistent with the proposal that the dark bias in afferent signals is inherited and may also be amplified in visual cortex [<xref ref-type="bibr" rid="pcbi.1004268.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>]. Indeed, prior work has demonstrated that this OFF bias reflects both a decrease in ON responses and an increase in OFF responses from V1 input layers to output layers, as predicted by combined potentiation and depression [<xref ref-type="bibr" rid="pcbi.1004268.ref011">11</xref>].</p>
<p>As described in the previous section, the contrast, scale, and depth dependent patterns in natural scenes also qualitatively agree with recent physiological measurements [<xref ref-type="bibr" rid="pcbi.1004268.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref015">15</xref>]. However, additional work is needed to establish the level of quantitative agreement on a feature-by-feature basis.</p>
</sec>
<sec id="sec014">
<title>Implications for Visual Perception</title>
<p>Taken together, our results and those of previous studies suggest that the cortical asymmetries in encoding dark and bright visual features reflect a highly specific match to the visual input coming from the natural environment. But for these asymmetries to be adaptive, they must also confer a performance advantage on the organism.</p>
<p>In many cases, visual perceptual performance tends to be enhanced for dark patterns relative to brights. This enhancement has been demonstrated for contrast sensitivity ([<xref ref-type="bibr" rid="pcbi.1004268.ref045">45</xref>–<xref ref-type="bibr" rid="pcbi.1004268.ref048">48</xref>]), speed and accuracy of target detection ([<xref ref-type="bibr" rid="pcbi.1004268.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref049">49</xref>]), judgments of texture variance ([<xref ref-type="bibr" rid="pcbi.1004268.ref050">50</xref>]), and several other tasks (see [<xref ref-type="bibr" rid="pcbi.1004268.ref051">51</xref>] for review). It should also be noted that several of the same studies and others have identified conditions under which perception of brights and darks appear to be highly similar ([<xref ref-type="bibr" rid="pcbi.1004268.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref052">52</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref053">53</xref>]). It is nonetheless appealing to think that the cortical asymmetries described here may be the underlying substrate of a “dark advantage” in some perceptual tasks. By allocating greater processing resources for dark features, the visual system is in effect making a prior assumption that certain visual features are more likely to appear as darks than to appear as brights.</p>
<p>We quantified this prediction using an information-theoretic approach and a neuronal population model that is illustrated schematically in <xref ref-type="fig" rid="pcbi.1004268.g007">Fig 7A</xref>. We start by considering a population of complex cells that are all tuned for a particular visual feature. The population is parameterized as a family of Gaussian tuning curves that uniformly tile the space of a scalar visual feature <italic>s</italic>. The shape of the tuning function for the <italic>j</italic><sup><italic>th</italic></sup> neuron in the population is determined by:
<disp-formula id="pcbi.1004268.e008"><alternatives><graphic id="pcbi.1004268.e008g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e008"/><mml:math id="M8" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>h</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mfrac><mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:mrow><mml:mn>2</mml:mn> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>j</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
where <italic>μ</italic><sub><italic>j</italic></sub> is the value of <italic>s</italic> for which the response of neuron <italic>j</italic> is at its peak, and the standard deviation <italic>σ</italic><sub><italic>j</italic></sub> is the same for all neurons. The function values range from 0-1, with a value of 1 for the preferred stimulus. The absolute spike rate of a complex cell to a given stimulus (<italic>r</italic><sub><italic>j</italic></sub>(<italic>s</italic>)) is determined by scaling this tuning shape by the maximum spike rate of the cell (<italic>R</italic>):
<disp-formula id="pcbi.1004268.e009"><alternatives><graphic id="pcbi.1004268.e009g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e009"/><mml:math id="M9" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>R</mml:mi> <mml:msub><mml:mi>h</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
Consistent with a wide range of physiological studies, we assumed that the overall spike rates of the cells will be two times greater when the visual feature is presented with dark contrast (blue lines in <xref ref-type="fig" rid="pcbi.1004268.g007">Fig 7A</xref>) than when it is presented with bright contrast (red lines <xref ref-type="fig" rid="pcbi.1004268.g007">Fig 7A</xref>) [<xref ref-type="bibr" rid="pcbi.1004268.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref037">37</xref>], but that the tuning curves will otherwise be similar in shape [<xref ref-type="bibr" rid="pcbi.1004268.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>].</p>
<fig id="pcbi.1004268.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004268.g007</object-id>
<label>Fig 7</label>
<caption>
<title>A population model can be used to predict biases in perceptual discrimination.</title>
<p>(A) Illustrations of complex cell tuning functions for an imaginary visual feature <italic>s</italic>. Each cell’s tuning function is illustrated as a Gaussian function. We model the population as a set of identical functions <italic>r</italic><sub><italic>j</italic></sub> that are uniformly spaced over the range of stimulus values. The responses are shown separately for dark features (blue lines) and bright features (red lines). To simulate the dark bias in primary visual cortex, we model the dark-input responses as being 2 times greater than bright-input responses. (B,C) We computed the Fisher Information and lower perceptual discrimination bounds of the population responses to brights and darks assuming a maximum spike rate of 25 spikes per second in response to dark input.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.g007"/>
</fig>
<p>The expected information value of the population activity at each value of <italic>s</italic> can be quantified as the Fisher information. This Fisher information can be approximated as:
<disp-formula id="pcbi.1004268.e010"><alternatives><graphic id="pcbi.1004268.e010g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e010"/><mml:math id="M10" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>J</mml:mi></mml:munderover> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
where <italic>J</italic> is the total number of complex cells in the population, and <inline-formula id="pcbi.1004268.e011"><mml:math id="M11" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi> <mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is the first derivative of the response curve of the <italic>j</italic><sup><italic>th</italic></sup> neuron with respect to <italic>s</italic> [<xref ref-type="bibr" rid="pcbi.1004268.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref055">55</xref>]. Intuitively, the Fisher information of a population increases when tuning curves are steeper and/or more densely packed. This information measure is plotted in <xref ref-type="fig" rid="pcbi.1004268.g007">Fig 7B</xref> for dark and bright features. Because the increased response gain for dark features makes the tuning curves steeper, these responses have a higher level of Fisher information.</p>
<p>We can show that the ratio of the Fisher information in the dark and bright responses is equal to the ratio of the maximum response rates for dark and bright stimuli. First, substituting <italic>Rh</italic><sub><italic>j</italic></sub>(<italic>s</italic>) for <italic>r</italic><sub><italic>j</italic></sub>(<italic>s</italic>) in <xref ref-type="disp-formula" rid="pcbi.1004268.e010">Eq (8)</xref> yields:
<disp-formula id="pcbi.1004268.e012"><alternatives><graphic id="pcbi.1004268.e012g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e012"/><mml:math id="M12" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>J</mml:mi></mml:munderover> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>R</mml:mi> <mml:msubsup><mml:mi>h</mml:mi> <mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mi>R</mml:mi> <mml:msub><mml:mi>h</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
Since <italic>R</italic> is a constant, this equation simplifies to:
<disp-formula id="pcbi.1004268.e013"><alternatives><graphic id="pcbi.1004268.e013g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e013"/><mml:math id="M13" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:mi>R</mml:mi> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>J</mml:mi></mml:munderover> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>h</mml:mi> <mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:msub><mml:mi>h</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
Because we are calculating Fisher information for the same population (just with bright or dark input stimuli), the sum of the tuning curves drop out in the ratio of Fisher information between dark and bright input. This leaves:
<disp-formula id="pcbi.1004268.e014"><alternatives><graphic id="pcbi.1004268.e014g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e014"/><mml:math id="M14" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>F</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msub><mml:mi>F</mml:mi> <mml:mi>b</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>R</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:msub><mml:mi>R</mml:mi> <mml:mi>b</mml:mi></mml:msub></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
where subscripts <italic>b</italic> and <italic>d</italic> indicate the Fisher information and mean firing rates for bright and dark input, respectively.</p>
<p>Turning to the perceptual implications of the model, it has been shown that the lower bound on perceptual discrimination can be predicted from the Fisher information in the cell population. This lower limit is simply:
<disp-formula id="pcbi.1004268.e015"><alternatives><graphic id="pcbi.1004268.e015g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e015"/><mml:math id="M15" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>δ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≥</mml:mo> <mml:mfrac><mml:mo>Δ</mml:mo> <mml:msqrt><mml:mrow><mml:mi>F</mml:mi> <mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
where Δ is a constant that is determined by the experimental paradigm [<xref ref-type="bibr" rid="pcbi.1004268.ref056">56</xref>]. This lower bound is shown in <xref ref-type="fig" rid="pcbi.1004268.g007">Fig 7C</xref>. Assuming that the experimental paradigm is the same for assessing discrimination thresholds for brights and darks, we can now calculate the predicted dark advantage. We will define the dark advantage as the ratio of the discrimination thresholds for bright and dark stimuli:
<disp-formula id="pcbi.1004268.e016"><alternatives><graphic id="pcbi.1004268.e016g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004268.e016"/><mml:math id="M16" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>δ</mml:mi> <mml:mi>b</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msub><mml:mi>δ</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:msqrt><mml:mfrac><mml:mrow><mml:msub><mml:mi>F</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msub><mml:mi>F</mml:mi> <mml:mi>b</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:msqrt> <mml:mo>=</mml:mo> <mml:msqrt><mml:mfrac><mml:msub><mml:mi>R</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:msub><mml:mi>R</mml:mi> <mml:mi>b</mml:mi></mml:msub></mml:mfrac></mml:msqrt> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula>
So, given the assumption that the dark and bright responses are identical up to a spike rate scale factor, it is simple to calculate that if <italic>R</italic> is approximately two times higher for darks, <italic>δ</italic><sub><italic>b</italic></sub>(<italic>s</italic>)/<italic>δ</italic><sub><italic>d</italic></sub>(<italic>s</italic>) will be <inline-formula id="pcbi.1004268.e017"><mml:math id="M17" display="inline" overflow="scroll"><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mo>≈</mml:mo> <mml:mn>1</mml:mn> <mml:mo>.</mml:mo> <mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>, indicating a 40% lower discrimination threshold. This value is in keeping with a recent extensive study of the perceptual dark advantage at supra threshold contrasts (including eleven different experiments), which found that it ranges from 19% to 43% over a variety of perceptual tasks [<xref ref-type="bibr" rid="pcbi.1004268.ref051">51</xref>]. This agreement does not hold for contrast discrimination, which had a substantially higher dark advantage than the other tasks. However, the current analysis applies to neurons with Gaussian tuning profiles, which likely does not reflect the manner in which contrast is encoded in the early visual system.</p>
<p>Here, we have used a simplified case in which the cortical dark bias is the same for all values of <italic>s</italic> and the neuronal population is uniform. More work will be needed to determine if this cortical dark bias and perceptual advantage are distributed across visual features in a way that agrees with the more complex natural scene patterns reported in our results. A clear prediction of this model is that the relative dark advantage for two values of a particular feature should have the same sign as the relative OFF bias (Fig <xref ref-type="fig" rid="pcbi.1004268.g005">5J</xref>–<xref ref-type="fig" rid="pcbi.1004268.g005">5L</xref>). Because this OFF bias in the environment varies across visual features, these variations may provide an explanation for why some experimental paradigms reveal a dark bias and others do not. For example, one might predict that the perceptual dark bias would be much smaller for stimuli with mid-range spatial frequencies (1–4 cpd) relative to higher or lower frequencies.</p>
</sec>
<sec id="sec015">
<title>Future Directions</title>
<p>One challenge to determining the statistics of cortical input is developing a more detailed model of the early visual pathways, particularly when it comes to the simulation of contrast response functions. Our ability to predict cortical input statistics will be improved as we learn more about how pre-cortical cell response properties are affected by the spatial patterns of natural input. For example, recent work showed that the difference in the ON and OFF RGC receptive field sizes—and perhaps their different response functions as well—fluctuate based on the mean luminance of a stimulus [<xref ref-type="bibr" rid="pcbi.1004268.ref013">13</xref>]. Factors such as these will clearly interact with the complex visual input patterns from natural scenes in ways that are difficult to predict without a more complete description of RGC responses to a wide variety of stimuli.</p>
<p>Another interesting avenue for future work would be to examine how visual statistics might vary as a function of retinal eccentricity. For example, observers may tend to preferentially fixate the detailed, high contrast areas of a visual scene. Thus, neurons representing foveal and peripheral regions may be tasked with encoding different distributions of contrast and spatial frequency. Investigating this would require the use of principled estimates or measurements of the fixation point within each analyzed image. In addition, once fixations and eye movements are being considered, it would be natural to extend the measurements into the temporal domain. This could provide new insights into how the temporal asymmetries between the ON and OFF pathways may contribute to differences in the motion input to cortex [<xref ref-type="bibr" rid="pcbi.1004268.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref057">57</xref>].</p>
<p>Future work can also address the question of what the underlying geometric properties of natural scenes are that produce biases in visual cortical input. Addressing this question will require generating a 3D rather than a 2D synthetic scene model. For example, in future work we can test the hypothesis that shadows between objects produce more low spatial frequencies in the OFF pathway. This can be done by synthesizing 3D scenes and rendering them with and without directional light and shadows. However, the synthetic scenes must first be matched to natural scenes in terms of their material properties and distribution of 3D surfaces. Another potential direction for examining the sources of dark/bright biases is to determine if the magnitude of each bias correlates with any basic global image property, such as mean luminance. This approach would be advantageous because it can be performed on existing natural image datasets, however one would still be left to speculate as to which fundamental 3D scene properties produce the global image differences.</p>
<p>Recently, analogues of the visual ON and OFF domains—encoding positive and negative input states—have been identified in the olfactory and auditory systems [<xref ref-type="bibr" rid="pcbi.1004268.ref058">58</xref>, <xref ref-type="bibr" rid="pcbi.1004268.ref059">59</xref>]. Future work can examine if similar adaptive asymmetries exist for these other sensory modalities as well.</p>
</sec>
<sec id="sec016">
<title>Conclusions</title>
<p>Previous statistical descriptions of the building-blocks of our visual world—small contours, regions of shading and contrast, three-dimensionality—have largely considered bright and dark features to be equivalent. Here, we have described the asymmetries between the statistics of brights and darks. We found that low spatial frequency image content is dominated by dark features. In addition, areas of high visual contrast are biased towards being dark, as are relatively distant features. We have also shown that a simple naturalistic image model can reproduce these biases in detail. This suggests that dark/bright asymmetries represent fundamental regularities of natural images and therefore do not arise from particularities of any specific image sets.</p>
<p>In addition, a basic visual computation—local light adaptation—contributes to the asymmetries by boosting contrast in dark image regions. Adaptation and normalization processes exist throughout the visual system, protecting against neuronal response saturation and allowing perceived contrast to be roughly invariant to light intensity [<xref ref-type="bibr" rid="pcbi.1004268.ref060">60</xref>]. In our synthetic image analysis, we showed that contrast normalization operations may interact with the 1/<italic>f</italic><sup><italic>α</italic></sup> spatial frequency spectrum of natural images to boost low spatial frequency patterns in the OFF pathway. Thus, the dark/bright asymmetries are likely a pervasive property of visual input to the brain.</p>
<p>One key outcome of our analysis is to show that it does not make sense to directly connect natural scene image patterns in pixels to efficient and optimal encoding principles in visual cortex. We have demonstrated that the early stages of visual processing—which themselves are likely guided by efficiency [<xref ref-type="bibr" rid="pcbi.1004268.ref061">61</xref>]—alter the statistical patterns of visual features, and it is these patterns that must be driving the cortical encoding process.</p>
<p>Having performed these analyses, we can now propose a more comprehensive explanation for a body of recent work showing that primary cortical cells often violate the assumptions of the classic energy models used to describe them. We propose that many of the asymmetries in activity devoted to darks and brights in primary visual cortex—and even the visual system of flies [<xref ref-type="bibr" rid="pcbi.1004268.ref042">42</xref>]—reflect a specialization for processing the patterns of dark and bright input from the early visual pathways. While previous work has argued that dark dominance is overall adaptive for environmental input [<xref ref-type="bibr" rid="pcbi.1004268.ref025">25</xref>], we have shown here that highly specific patterns of visual features are reflected in this cortical specialization.</p>
</sec>
</sec>
<sec id="sec017">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004268.s001" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.s001" mimetype="application/zip" xlink:type="simple">
<label>S1 File</label>
<caption>
<title>MATLAB code for simulating retinal ganglion cell responses to an image.</title>
<p>(ZIP)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004268.s002" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.s002" mimetype="application/eps" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Probabilities and dark/bright ratios from a second set of natural scenes.</title>
<p>(A-C) Probability densities are plotted as in <xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3</xref> for a set of images from a second dataset [<xref ref-type="bibr" rid="pcbi.1004268.ref027">27</xref>]. (C-D) Dark/bright ratios also plotted as in <xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3</xref>. A few differences appear but the overall results are similar. Depth results are omitted because they were only available from a single dataset [<xref ref-type="bibr" rid="pcbi.1004268.ref019">19</xref>]</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004268.s003" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.s003" mimetype="application/eps" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Dark/bright ratios across contrast-operator sizes.</title>
<p>(A-D) Results are plotted as in Fig <xref ref-type="fig" rid="pcbi.1004268.g003">3E</xref>–<xref ref-type="fig" rid="pcbi.1004268.g003">3H</xref> with the standard deviation of the central Gaussian (<italic>σ</italic><sub><italic>c</italic></sub>) set to three different sizes in arcmin (see legend). Results for <italic>σ</italic><sub><italic>c</italic></sub> = 4 are the same as <xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3</xref>. Across sizes ranging by a factor of 4, the qualitative dark/bright patterns are similar. As the size of the contrast operator increases, the spatial frequency asymmetry shifts towards lower spatial scales, because the contrast normalization area increases. The depth-dependent asymmetry also changes with size: the largest bias appears at the largest size.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004268.s004" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.s004" mimetype="application/eps" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Dark/bright ratios across contrast-operator shapes.</title>
<p>(A-D) Results are plotted as in Fig <xref ref-type="fig" rid="pcbi.1004268.g003">3E</xref>–<xref ref-type="fig" rid="pcbi.1004268.g003">3H</xref> with the ratio of the standard deviation of the surround Gaussian (<italic>σ</italic><sub><italic>s</italic></sub>) to the central Gaussian (<italic>σ</italic><sub><italic>c</italic></sub>) set to three different values (see legend). The standard deviation of the central Gaussian was fixed at 4 arcmin. Results for <italic>σ</italic><sub><italic>s</italic></sub>/<italic>σ</italic><sub><italic>c</italic></sub> = 2 are the same as <xref ref-type="fig" rid="pcbi.1004268.g003">Fig 3</xref>. As in <xref ref-type="supplementary-material" rid="pcbi.1004268.s003">S2 Fig</xref>, when the size of the contrast operator increases, the spatial frequency asymmetry shifts towards lower spatial scales. This shift is rather substantial for the largest filter size (red line), for which <italic>σ</italic><sub><italic>s</italic></sub> is over 0.25 visual degrees.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004268.s005" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.s005" mimetype="application/eps" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Dark/bright ratios with an alternate definition of image contrast.</title>
<p>(A-D) Results are plotted as in Fig <xref ref-type="fig" rid="pcbi.1004268.g003">3E</xref>–<xref ref-type="fig" rid="pcbi.1004268.g003">3H</xref>, except that here local contrast is defined as the Weber contrast of each image pixel relative to a low-pass Gaussian filtered version of the image. The standard deviation of the low-pass Gaussian (<italic>σ</italic>) was set to three different sizes in arcminutes (see legend). Using this alternate definition of contrast, the overall dark/bright patterns are qualitatively similar to the main analysis. As in <xref ref-type="supplementary-material" rid="pcbi.1004268.s003">S2 Fig</xref>, it is clear that when the local normalization pool becomes relatively the large, the spatial frequency asymmetry is shifted.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004268.s006" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004268.s006" mimetype="application/eps" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Dark/bright ratios for multiple types of noise images.</title>
<p>In addition to the white noise versus naturalistic noise comparison reported in the main analysis, we also compared the results for multiple classes of noise, each one containing an additional global feature of natural images (see <xref ref-type="sec" rid="sec002">Methods</xref>). This analysis uncovered which properties of natural images may lead to the dark dominance patterns. (A-D) Each line shows the results for a different type of noise image. Gaussian white (purple line) is the least naturalistic noise, and the dark dominance patterns are dissimilar to the natural scenes. Introducing a 1/<italic>f</italic><sup><italic>α</italic></sup> spatial frequency distribution (orange line) begins to produce a spatial frequency bias similar to that of natural scenes. The patterns become more similar to natural scenes when positively skewed luminance values are added (red line). Adding in a cardinal orientation bias (blue line) recreates the very minor fluctuations in OFF dominance over orientation, and imposing a negative correlation between intensity and depth (yellow line) produces a similar far/dark dominance. The final class of noise is referred to in the main analysis as <italic>naturalistic noise</italic> because it has all of the global features necessary to reproduce the dark dominance patterns in natural scenes. The fact that these patterns can be closely matched by random phase noise images suggests that they arise from the global statistics of natural images, rather than specific geometric properties.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Thomas Clandinin and Eero Simoncelli for feedback on the manuscript and helpful discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004268.ref001">
<label>1</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Attneave</surname> <given-names>F</given-names></name> (<year>1954</year>) <article-title>Some informational aspects of visual perception</article-title>. <source>Psychological Review</source> <volume>61</volume>: <fpage>183</fpage>–<lpage>193</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/h0054663" xlink:type="simple">10.1037/h0054663</ext-link></comment> <object-id pub-id-type="pmid">13167245</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref002">
<label>2</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Barlow</surname> <given-names>HB</given-names></name> (<year>1961</year>) <chapter-title>Possible principles underlying the transformations of sensory messages</chapter-title>. In: <name name-style="western"><surname>Rosenblith</surname> <given-names>WA</given-names></name>, editor, <source>Sensory Communication</source>, <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>. pp. <fpage>217</fpage>–<lpage>234</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004268.ref003">
<label>3</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Laughlin</surname> <given-names>S</given-names></name> (<year>1981</year>) <article-title>A simple coding procedure enhances a neuron’s information capacity</article-title>. <source>Z Naturforsch</source> <volume>36</volume>: <fpage>910</fpage>–<lpage>912</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004268.ref004">
<label>4</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Olshausen</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>DJ</given-names></name> (<year>1996</year>) <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source> <volume>381</volume>: <fpage>607</fpage>–<lpage>609</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/381607a0" xlink:type="simple">10.1038/381607a0</ext-link></comment> <object-id pub-id-type="pmid">8637596</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref005">
<label>5</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Mante</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Frazor</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Bonin</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Geisler</surname> <given-names>WS</given-names></name>, <name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name> (<year>2005</year>) <article-title>Independence of luminance and contrast in natural scenes and in the early visual system</article-title>. <source>Nature Neuroscience</source> <volume>8</volume>: <fpage>1690</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1556" xlink:type="simple">10.1038/nn1556</ext-link></comment> <object-id pub-id-type="pmid">16286933</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref006">
<label>6</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Richards</surname> <given-names>W</given-names></name> (<year>1996</year>) <source>Perception as Bayesian inference</source>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation>
</ref>
<ref id="pcbi.1004268.ref007">
<label>7</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Burge</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Fowlkes</surname> <given-names>CC</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name> (<year>2010</year>) <article-title>Natural-scene statistics predict how the figure-ground cue of convexity affects human depth perception</article-title>. <source>Journal of Neuroscience</source> <volume>30</volume>: <fpage>7269</fpage>–<lpage>80</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5551-09.2010" xlink:type="simple">10.1523/JNEUROSCI.5551-09.2010</ext-link></comment> <object-id pub-id-type="pmid">20505093</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref008">
<label>8</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Girshick</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name> (<year>2011</year>) <article-title>Cardinal rules: Visual orientation perception reflects knowledge of environmental statistics</article-title>. <source>Nat Neurosci</source> <volume>14</volume>: <fpage>926</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2831" xlink:type="simple">10.1038/nn.2831</ext-link></comment> <object-id pub-id-type="pmid">21642976</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref009">
<label>9</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Jin</surname> <given-names>JZ</given-names></name>, <name name-style="western"><surname>Weng</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Yeh</surname> <given-names>CI</given-names></name>, <name name-style="western"><surname>Gordon</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Ruthazer</surname> <given-names>ES</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>On and off domains of geniculate afferents in cat primary visual cortex</article-title>. <source>Nat Neurosci</source> <volume>11</volume>: <fpage>88</fpage>–<lpage>94</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn2029" xlink:type="simple">10.1038/nn2029</ext-link></comment> <object-id pub-id-type="pmid">18084287</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref010">
<label>10</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Yeh</surname> <given-names>CI</given-names></name>, <name name-style="western"><surname>Xing</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Shapley</surname> <given-names>RM</given-names></name> (<year>2009</year>) <article-title>“Black” responses dominate macaque primary visual cortex V1</article-title>. <source>Journal of Neuroscience</source> <volume>29</volume>: <fpage>11753</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1991-09.2009" xlink:type="simple">10.1523/JNEUROSCI.1991-09.2009</ext-link></comment> <object-id pub-id-type="pmid">19776262</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref011">
<label>11</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Xing</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Yeh</surname> <given-names>CI</given-names></name>, <name name-style="western"><surname>Shapley</surname> <given-names>RM</given-names></name> (<year>2010</year>) <article-title>Generation of black-dominant responses in V1 cortex</article-title>. <source>Journal of Neuroscience</source> <volume>30</volume>: <fpage>13504</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2473-10.2010" xlink:type="simple">10.1523/JNEUROSCI.2473-10.2010</ext-link></comment> <object-id pub-id-type="pmid">20926676</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref012">
<label>12</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Samonds</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Potetz</surname> <given-names>BR</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>TS</given-names></name> (<year>2012</year>) <article-title>Relative luminance and binocular disparity preferences are correlated in macaque primary visual cortex, matching natural scene statistics</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>109</volume>: <fpage>6313</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1200125109" xlink:type="simple">10.1073/pnas.1200125109</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref013">
<label>13</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kremkow</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Jianzhong</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Komban</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Lashgari</surname> <given-names>R</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Neuronal nonlinearity explains greater visual spatial resolution for darks than lights</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>111</volume>: <fpage>3170</fpage>–<lpage>3175</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1310442111" xlink:type="simple">10.1073/pnas.1310442111</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref014">
<label>14</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Veit</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bhattacharyya</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kretz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Rainer</surname> <given-names>G</given-names></name> (<year>2014</year>) <article-title>On the relation between receptive field structure and stimulus selectivity in the tree shrew primary visual cortex</article-title>. <source>Cerebral Cortex</source> <volume>24</volume>: <fpage>2761</fpage>–<lpage>71</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bht133" xlink:type="simple">10.1093/cercor/bht133</ext-link></comment> <object-id pub-id-type="pmid">23696278</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref015">
<label>15</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Liu</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Yao</surname> <given-names>H</given-names></name> (<year>2014</year>) <article-title>Contrast-dependent OFF-dominance in cat primary visual cortex facilitates discrimination of stimuli with natural contrast statistics</article-title>. <source>European Journal of Neuroscience</source> <volume>39</volume>: <fpage>2060</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/ejn.12567" xlink:type="simple">10.1111/ejn.12567</ext-link></comment> <object-id pub-id-type="pmid">24931049</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref016">
<label>16</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Komban</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Kremkow</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Jin</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Lashgari</surname> <given-names>R</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Neuronal and perceptual differences in the temporal processing of darks and lights</article-title>. <source>Neuron</source> <volume>82</volume>: <fpage>224</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.02.020" xlink:type="simple">10.1016/j.neuron.2014.02.020</ext-link></comment> <object-id pub-id-type="pmid">24698277</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref017">
<label>17</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Jin</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kremkow</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Lashgari</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Komban</surname> <given-names>SJ</given-names></name>, <etal>et al</etal>. (<year>2015</year>) <article-title>Columnar organization of spatial phase in visual cortex</article-title>. <source>Nature Neuroscience</source> <volume>18</volume>: <fpage>97</fpage>–<lpage>103</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3878" xlink:type="simple">10.1038/nn.3878</ext-link></comment> <object-id pub-id-type="pmid">25420070</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref018">
<label>18</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>van Hateren</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>van der Schaaf</surname> <given-names>A</given-names></name> (<year>1998</year>) <article-title>Independent component filters of natural images compared with simple cells in primary visual cortex</article-title>. <source>Proceedings of the Royal Society of London B</source> <volume>265</volume>: <fpage>359</fpage>–<lpage>366</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rspb.1998.0577" xlink:type="simple">10.1098/rspb.1998.0577</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref019">
<label>19</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Potetz</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>TS</given-names></name> (<year>2003</year>) <article-title>Statistical correlations between two-dimensional images and three-dimensional structures in natural images</article-title>. <source>Journal of the Optical Society of America A</source> <volume>20</volume>: <fpage>1292</fpage>–<lpage>1303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1364/JOSAA.20.001292" xlink:type="simple">10.1364/JOSAA.20.001292</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref020">
<label>20</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Tadmor</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Tolhurst</surname> <given-names>DJ</given-names></name> (<year>2000</year>) <article-title>Calculating the contrasts that retinal ganglion cells and LGN neurones encounter in natural scenes</article-title>. <source>Vision Research</source> <volume>40</volume>: <fpage>3145</fpage>–<lpage>3157</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0042-6989(00)00166-8" xlink:type="simple">10.1016/S0042-6989(00)00166-8</ext-link></comment> <object-id pub-id-type="pmid">10996617</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref021">
<label>21</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Frazor</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Geisler</surname> <given-names>WS</given-names></name> (<year>2006</year>) <article-title>Local luminance and contrast in natural images</article-title>. <source>Vision Research</source> <volume>46</volume>: <fpage>1585</fpage>–<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2005.06.038" xlink:type="simple">10.1016/j.visres.2005.06.038</ext-link></comment> <object-id pub-id-type="pmid">16403546</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref022">
<label>22</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Field</surname> <given-names>DJ</given-names></name> (<year>1987</year>) <article-title>Relations between the statistics of natural images and the response properties of cortical cells</article-title>. <source>Journal of the Optical Society of America A</source> <volume>4</volume>: <fpage>2379</fpage>–<lpage>2394</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1364/JOSAA.4.002379" xlink:type="simple">10.1364/JOSAA.4.002379</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref023">
<label>23</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Coppola</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Purves</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>McCoy</surname> <given-names>AN</given-names></name>, <name name-style="western"><surname>Purves</surname> <given-names>D</given-names></name> (<year>1998</year>) <article-title>The distribution of oriented contours in the real world</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>95</volume>: <fpage>4002</fpage>–<lpage>4006</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.95.7.4002" xlink:type="simple">10.1073/pnas.95.7.4002</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref024">
<label>24</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Burkhardt</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Fahey</surname> <given-names>PK</given-names></name>, <name name-style="western"><surname>Sikora</surname> <given-names>MA</given-names></name> (<year>2006</year>) <article-title>Natural images and contrast encoding in bipolar cells in the retina of the land- and aquatic-phase tiger salamander</article-title>. <source>Visual Neuroscience</source> <volume>23</volume>: <fpage>35</fpage>–<lpage>47</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S0952523806231043" xlink:type="simple">10.1017/S0952523806231043</ext-link></comment> <object-id pub-id-type="pmid">16597349</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref025">
<label>25</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ratliff</surname> <given-names>CP</given-names></name>, <name name-style="western"><surname>Borghuis</surname> <given-names>BG</given-names></name>, <name name-style="western"><surname>Kao</surname> <given-names>YH</given-names></name>, <name name-style="western"><surname>Sterling</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Balasubramanian</surname> <given-names>V</given-names></name> (<year>2010</year>) <article-title>Retina is structured to process an excess of darkness in natural scenes</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>107</volume>: <fpage>17368</fpage>–<lpage>17373</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1005846107" xlink:type="simple">10.1073/pnas.1005846107</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref026">
<label>26</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Cooper</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Norcia</surname> <given-names>AM</given-names></name> (<year>2014</year>) <article-title>Perceived depth in natural images reflects encoding of low-level luminance statistics</article-title>. <source>Journal of Neuroscience</source> <volume>34</volume>: <fpage>11761</fpage>–<lpage>11768</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1336-14.2014" xlink:type="simple">10.1523/JNEUROSCI.1336-14.2014</ext-link></comment> <object-id pub-id-type="pmid">25164671</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref027">
<label>27</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Olmos</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kingdom</surname> <given-names>FAA</given-names></name> (<year>2004</year>) <article-title>A biologically inspired algorithm for the recovery of shading and reflectance images</article-title>. <source>Perception</source> <volume>33</volume>: <fpage>1463</fpage>–<lpage>1473</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1068/p5321" xlink:type="simple">10.1068/p5321</ext-link></comment> <object-id pub-id-type="pmid">15729913</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref028">
<label>28</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Peli</surname> <given-names>E</given-names></name> (<year>1990</year>) <article-title>Contrast in complex images</article-title>. <source>Journal of the Optical Society of America A</source> <volume>7</volume>: <fpage>2032</fpage>–<lpage>2040</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1364/JOSAA.7.002032" xlink:type="simple">10.1364/JOSAA.7.002032</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref029">
<label>29</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Croner</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Kaplan</surname> <given-names>E</given-names></name> (<year>1995</year>) <article-title>Receptive fields of P and M ganglion cells across the primate retina</article-title>. <source>Vision Research</source> <volume>35</volume>: <fpage>7</fpage>–<lpage>24</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0042-6989(94)E0066-T" xlink:type="simple">10.1016/0042-6989(94)E0066-T</ext-link></comment> <object-id pub-id-type="pmid">7839612</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref030">
<label>30</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Dacey</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Petersen</surname> <given-names>MR</given-names></name> (<year>1992</year>) <article-title>Dendritic field size and morphology of midget and parasol ganglion cells of the human retina</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>89</volume>: <fpage>9666</fpage>–<lpage>9670</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.89.20.9666" xlink:type="simple">10.1073/pnas.89.20.9666</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref031">
<label>31</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Chichilnisky</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Kalmar</surname> <given-names>RS</given-names></name> (<year>2002</year>) <article-title>Functional asymmetries in ON and OFF ganglion cells of primate retina</article-title>. <source>Journal of Neuroscience</source> <volume>22</volume>: <fpage>2737</fpage>–<lpage>2747</lpage>. <object-id pub-id-type="pmid">11923439</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref032">
<label>32</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Zaghloul</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Boahen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Demb</surname> <given-names>JB</given-names></name> (<year>2003</year>) <article-title>Different circuits for ON and OFF retinal ganglion cells cause different contrast sensitivities</article-title>. <source>Journal of Neuroscience</source> <volume>23</volume>: <fpage>2645</fpage>–<lpage>2654</lpage>. <object-id pub-id-type="pmid">12684450</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref033">
<label>33</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Li</surname> <given-names>PH</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Greschner</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ahn</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Gunning</surname> <given-names>DE</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Retinal representation of the elementary visual signal</article-title>. <source>Neuron</source> <volume>81</volume>: <fpage>130</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2013.10.043" xlink:type="simple">10.1016/j.neuron.2013.10.043</ext-link></comment> <object-id pub-id-type="pmid">24411737</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref034">
<label>34</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Brady</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>DJ</given-names></name> (<year>2000</year>) <article-title>Local contrast in natural images: normalisation and coding efficiency</article-title>. <source>Perception</source> <volume>29</volume>: <fpage>1041</fpage>–<lpage>1055</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1068/p2996" xlink:type="simple">10.1068/p2996</ext-link></comment> <object-id pub-id-type="pmid">11144818</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref035">
<label>35</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name> (<year>2012</year>) <article-title>Normalization as a canonical neural computation</article-title>. <source>Nature Reviews Neuroscience</source> <volume>13</volume>: <fpage>51</fpage>–<lpage>62</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004268.ref036">
<label>36</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Liu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Cormack</surname> <given-names>LK</given-names></name>, <name name-style="western"><surname>Bovik</surname> <given-names>AC</given-names></name> (<year>2011</year>) <article-title>Statistical modeling of 3-d natural scenes with application to Bayesian stereopsis</article-title>. <source>IEEE Transactions on Image Processing</source> <volume>20</volume>: <fpage>2515</fpage>–<lpage>2530</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TIP.2011.2118223" xlink:type="simple">10.1109/TIP.2011.2118223</ext-link></comment> <object-id pub-id-type="pmid">21342845</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref037">
<label>37</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Zemon</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Gordon</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Welch</surname> <given-names>J</given-names></name> (<year>1988</year>) <article-title>Asymmetries in ON and OFF visual pathways of humans revealed using contrast-evoked cortical potentials</article-title>. <source>Visual Neuroscience</source> <volume>1</volume>: <fpage>145</fpage>–<lpage>150</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S0952523800001085" xlink:type="simple">10.1017/S0952523800001085</ext-link></comment> <object-id pub-id-type="pmid">3154786</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref038">
<label>38</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hubel</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Wiesel</surname> <given-names>TN</given-names></name> (<year>1962</year>) <article-title>Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex</article-title>. <source>Journal of Physiology</source> <volume>160</volume>: <fpage>106</fpage>–<lpage>154</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.1962.sp006837" xlink:type="simple">10.1113/jphysiol.1962.sp006837</ext-link></comment> <object-id pub-id-type="pmid">14449617</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref039">
<label>39</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Adelson</surname> <given-names>EH</given-names></name>, <name name-style="western"><surname>Bergen</surname> <given-names>JR</given-names></name> (<year>1985</year>) <article-title>Spatiotemporal energy models for the perception of motion</article-title>. <source>Journal of the Optical Society of America A</source> <volume>2</volume>: <fpage>284</fpage>–<lpage>299</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1364/JOSAA.2.000284" xlink:type="simple">10.1364/JOSAA.2.000284</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref040">
<label>40</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ohzawa</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Freeman</surname> <given-names>RD</given-names></name> (<year>1990</year>) <article-title>Stereoscopic depth discrimination in the visual cortex: Neurons ideally suited as disparity detectors</article-title>. <source>Science</source> <volume>249</volume>: <fpage>1037</fpage>–<lpage>1041</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.2396096" xlink:type="simple">10.1126/science.2396096</ext-link></comment> <object-id pub-id-type="pmid">2396096</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref041">
<label>41</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Emerson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Bergen</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Adelson</surname> <given-names>EH</given-names></name> (<year>1992</year>) <article-title>Directionally selective complex cells and the computation of motion energy in cat visual cortex</article-title>. <source>Vision Res</source> <volume>32</volume>: <fpage>203</fpage>–<lpage>218</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0042-6989(92)90130-B" xlink:type="simple">10.1016/0042-6989(92)90130-B</ext-link></comment> <object-id pub-id-type="pmid">1574836</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref042">
<label>42</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Clark</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Fitzgerald</surname> <given-names>JE</given-names></name>, <name name-style="western"><surname>Ales</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Gohl</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Silies</surname> <given-names>MA</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Flies and humans share a motion estimation strategy that exploits natural scene statistics</article-title>. <source>Nature Neuroscience</source> <volume>17</volume>: <fpage>296</fpage>–<lpage>303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3600" xlink:type="simple">10.1038/nn.3600</ext-link></comment> <object-id pub-id-type="pmid">24390225</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref043">
<label>43</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bienenstock</surname> <given-names>EL</given-names></name>, <name name-style="western"><surname>Cooper</surname> <given-names>LN</given-names></name>, <name name-style="western"><surname>Munro</surname> <given-names>PW</given-names></name> (<year>1982</year>) <article-title>Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex</article-title>. <source>Journal of Neuroscience</source> <volume>2</volume>: <fpage>32</fpage>–<lpage>48</lpage>. <object-id pub-id-type="pmid">7054394</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref044">
<label>44</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rumelhart</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Zipser</surname> <given-names>D</given-names></name> (<year>1985</year>) <article-title>Feature discovery by competitive learning</article-title>. <source>Cognitive Science</source> <volume>9</volume>: <fpage>75</fpage>–<lpage>112</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1207/s15516709cog0901_5" xlink:type="simple">10.1207/s15516709cog0901_5</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref045">
<label>45</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Blackwell</surname> <given-names>HR</given-names></name> (<year>1946</year>) <article-title>Contrast thresholds of the human eye</article-title>. <source>Journal of the Optical Society of America</source> <volume>36</volume>: <fpage>624</fpage>–<lpage>643</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1364/JOSA.36.000624" xlink:type="simple">10.1364/JOSA.36.000624</ext-link></comment> <object-id pub-id-type="pmid">20274431</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref046">
<label>46</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Short</surname> <given-names>AD</given-names></name> (<year>1966</year>) <article-title>Decremental and incremental thresholds</article-title>. <source>Journal of Physiology</source> <volume>185</volume>: <fpage>646</fpage>–<lpage>654</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.1966.sp008007" xlink:type="simple">10.1113/jphysiol.1966.sp008007</ext-link></comment> <object-id pub-id-type="pmid">5918061</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref047">
<label>47</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Patel</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Jones</surname> <given-names>RW</given-names></name> (<year>1968</year>) <article-title>Increment and decrement thresholds</article-title>. <source>Journal of the Optical Society of America</source> <volume>58</volume>: <fpage>696</fpage>–<lpage>699</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1364/JOSA.58.000696" xlink:type="simple">10.1364/JOSA.58.000696</ext-link></comment> <object-id pub-id-type="pmid">5647008</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref048">
<label>48</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bowen</surname> <given-names>RW</given-names></name>, <name name-style="western"><surname>Pokorny</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>VC</given-names></name> (<year>1989</year>) <article-title>Sawtooth contrast sensitivity: decrements have the edge</article-title>. <source>Vision Research</source> <volume>29</volume>: <fpage>1501</fpage>–<lpage>1509</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0042-6989(89)90134-X" xlink:type="simple">10.1016/0042-6989(89)90134-X</ext-link></comment> <object-id pub-id-type="pmid">2635476</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref049">
<label>49</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Komban</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Alonso</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Zaidi</surname> <given-names>Q</given-names></name> (<year>2011</year>) <article-title>Darks are processed faster than lights</article-title>. <source>Journal of Neuroscience</source> <volume>31</volume>: <fpage>8654</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0504-11.2011" xlink:type="simple">10.1523/JNEUROSCI.0504-11.2011</ext-link></comment> <object-id pub-id-type="pmid">21653869</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref050">
<label>50</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Chubb</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Nam</surname> <given-names>JH</given-names></name> (<year>2000</year>) <article-title>Variance of high contrast textures is sensed using negative half-wave rectification</article-title>. <source>Vision Research</source> <volume>40</volume>: <fpage>1677</fpage>–<lpage>1694</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0042-6989(00)00007-9" xlink:type="simple">10.1016/S0042-6989(00)00007-9</ext-link></comment> <object-id pub-id-type="pmid">10814756</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref051">
<label>51</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Lu</surname> <given-names>ZL</given-names></name>, <name name-style="western"><surname>Sperling</surname> <given-names>G</given-names></name> (<year>2012</year>) <article-title>Black-white asymmetry in visual perception</article-title>. <source>J Vis</source> <volume>12</volume>(<issue>8</issue>): <fpage>1</fpage>–<lpage>21</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004268.ref052">
<label>52</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Whittle</surname> <given-names>P</given-names></name> (<year>1986</year>) <article-title>Increments and decrements: luminance discrimination</article-title>. <source>Vision Research</source> <volume>26</volume>: <fpage>1677</fpage>–<lpage>1691</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0042-6989(86)90055-6" xlink:type="simple">10.1016/0042-6989(86)90055-6</ext-link></comment> <object-id pub-id-type="pmid">3617509</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref053">
<label>53</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Levi</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Westheimer</surname> <given-names>G</given-names></name> (<year>1987</year>) <article-title>Spatial-interval discrimination in the human fovea: what delimits the interval?</article-title> <source>Journal of the Optical Society of America A</source> <volume>4</volume>: <fpage>1304</fpage>–<lpage>1313</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1364/JOSAA.4.001304" xlink:type="simple">10.1364/JOSAA.4.001304</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref054">
<label>54</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Seung</surname> <given-names>HS</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name> (<year>1993</year>) <article-title>Simple models for reading neuronal population codes</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>90</volume>: <fpage>10749</fpage>–<lpage>10753</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.90.22.10749" xlink:type="simple">10.1073/pnas.90.22.10749</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref055">
<label>55</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ganguli</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name> (<year>2014</year>) <article-title>Efficient sensory encoding and Bayesian inference with heterogeneous neural populations</article-title>. <source>Neural Computation</source> <volume>26</volume>: <fpage>2103</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/NECO_a_00638" xlink:type="simple">10.1162/NECO_a_00638</ext-link></comment> <object-id pub-id-type="pmid">25058702</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref056">
<label>56</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Series</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Stocker</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name> (<year>2009</year>) <article-title>Is the homunculus “aware” of sensory adaptation?</article-title> <source>Neural Computation</source> <volume>21</volume>: <fpage>3271</fpage>–<lpage>3304</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2009.09-08-869" xlink:type="simple">10.1162/neco.2009.09-08-869</ext-link></comment> <object-id pub-id-type="pmid">19686064</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref057">
<label>57</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Nichols</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Nirenberg</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Victor</surname> <given-names>J</given-names></name> (<year>2013</year>) <article-title>Interacting linear and nonlinear characteristics produce population coding asymmetries between ON and OFF cells in the retina</article-title>. <source>Journal of Neuroscience</source> <volume>33</volume>: <fpage>14958</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1004-13.2013" xlink:type="simple">10.1523/JNEUROSCI.1004-13.2013</ext-link></comment> <object-id pub-id-type="pmid">24027295</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref058">
<label>58</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Burgstaller</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Tichy</surname> <given-names>H</given-names></name> (<year>2011</year>) <article-title>Functional asymmetries in cockroach ON and OFF olfactory receptor neurons</article-title>. <source>Journal of Neurophysiology</source> <volume>105</volume>: <fpage>834</fpage>–<lpage>45</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00785.2010" xlink:type="simple">10.1152/jn.00785.2010</ext-link></comment> <object-id pub-id-type="pmid">21160009</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref059">
<label>59</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Tian</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Kusmierek</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Rauschecker</surname> <given-names>JP</given-names></name> (<year>2013</year>) <article-title>Analogues of simple and complex cells in rhesus monkey auditory cortex</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>110</volume>: <fpage>7892</fpage>–<lpage>7897</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1221062110" xlink:type="simple">10.1073/pnas.1221062110</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref060">
<label>60</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name> (<year>1992</year>) <article-title>Normalization of cell responses in cat striate cortex</article-title>. <source>Visual Neuroscience</source> <volume>9</volume>: <fpage>181</fpage>–<lpage>197</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S095252380001124X" xlink:type="simple">10.1017/S095252380001124X</ext-link></comment> <object-id pub-id-type="pmid">1504027</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004268.ref061">
<label>61</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Karklin</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name> (<year>2011</year>) <chapter-title>Efficient coding of natural images with a population of noisy linear-nonlinear neurons</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>. <publisher-name>MIT Press</publisher-name>, <volume>volume 24</volume>, pp. <fpage>999</fpage>–<lpage>1007</lpage>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
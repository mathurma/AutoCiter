<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">09-PLCB-RA-0801R3</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000587</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience/Theoretical Neuroscience</subject></subj-group></article-categories><title-group><article-title>Effective Reduced Diffusion-Models: A Data Driven Approach to the Analysis of Neuronal Dynamics</article-title><alt-title alt-title-type="running-head">Effective Reduced Rate-Models</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Deco</surname><given-names>Gustavo</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Martí</surname><given-names>Daniel</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Ledberg</surname><given-names>Anders</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Reig</surname><given-names>Ramon</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Sanchez Vives</surname><given-names>Maria V.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>Institució Catalana de Recerca i Estudis Avançats (ICREA), Barcelona, Spain</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Computational Neuroscience Group, DTIC, Universitat Pompeu Fabra, Barcelona, Spain</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Institut d'Investigacions Biomèdiques August Pi i Sunyer (IDIBAPS), Barcelona, Spain</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>Karl J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">gustavo.deco@upf.edu</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: GD DM AL RR MVSV. Performed the experiments: GD DM AL RR MVSV. Analyzed the data: GD DM AL RR MVSV. Contributed reagents/materials/analysis tools: GD DM AL RR MVSV. Wrote the paper: GD DM AL RR MVSV.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>12</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>4</day><month>12</month><year>2009</year></pub-date><volume>5</volume><issue>12</issue><elocation-id>e1000587</elocation-id><history>
<date date-type="received"><day>6</day><month>7</month><year>2009</year></date>
<date date-type="accepted"><day>30</day><month>10</month><year>2009</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2009</copyright-year><copyright-holder>Deco et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>We introduce in this paper a new method for reducing neurodynamical data to an effective diffusion equation, either experimentally or using simulations of biophysically detailed models. The dimensionality of the data is first reduced to the first principal component, and then fitted by the stationary solution of a mean-field-like one-dimensional Langevin equation, which describes the motion of a Brownian particle in a potential. The advantage of such description is that the stationary probability density of the dynamical variable can be easily derived. We applied this method to the analysis of cortical network dynamics during up and down states in an anesthetized animal. During deep anesthesia, intracellularly recorded up and down states transitions occurred with high regularity and could not be adequately described by a one-dimensional diffusion equation. Under lighter anesthesia, however, the distributions of the times spent in the up and down states were better fitted by such a model, suggesting a role for noise in determining the time spent in a particular state.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>We introduce a novel methodology that allows for an effective description of a neurodynamical system in a data-driven fashion. In particular, no knowledge of the dynamics operating at the neuronal or synaptic level is required. The idea is to fit the underlying dynamics of the data using a stochastic differential equation. We use a Langevin equation that describes the stochastic dynamics of the system with the assumption that there exists an underlying potential, or energy function. The advantage of this description is the fact that, for one-dimensional systems, the stationary distribution of the variable can be straightforwardly related to the underlying energy function. In cases where the dataset is high-dimensional we reduce the dimensionality with techniques like principal curves or principal components analysis. The methodology we propose is particularly relevant for cases where an <italic>ab initio</italic> approach cannot be applied like, for example, when an explicit description of the dynamics at the neuronal and synaptic levels is not available.</p>
</abstract><funding-group><funding-statement>This work was supported by the Spanish Ministry of Science (Spanish Research Project BFU2007-61710, and CONSOLIDER CSD2007-00012). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="10"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Deciphering the fundamental mechanisms that underlie brain function requires an explicit description of the dynamics of the neuronal and synaptic substrate. Explicit neurodynamical models can describe the complex dynamics arising from the involved neuronal networks <xref ref-type="bibr" rid="pcbi.1000587-Rolls1">[1]</xref>,<xref ref-type="bibr" rid="pcbi.1000587-Dayan1">[2]</xref>. Traditionally, theoretical neuroscience follows an <italic>ab initio</italic> approach consisting of two main steps: 1) construction and simulation of models based on detailed descriptions of the neuronal and synaptic operations with a large number of neurons in a specified (hypothesized) network architecture, and 2) reduction of the hypothesized models such that an in-depth analytical study is feasible, and a systematic relation between structure (parameters), dynamics, and functional behavior can be solidly established. Models of neurons such as integrate-and-fire <xref ref-type="bibr" rid="pcbi.1000587-Tuckwell1">[3]</xref> are frequently used. The advantage of this type of models is that the simulation of biologically realistic networks allows the study of the neural correlates of brain function, for comparison with experimental data. On the other hand, the model is simple enough so that it is possible to obtain a reduced description based on <italic>mean-field</italic> techniques <xref ref-type="bibr" rid="pcbi.1000587-Brunel1">[4]</xref>,<xref ref-type="bibr" rid="pcbi.1000587-Brunel2">[5]</xref>. The mean-field reduction simplifies the analysis of networks of spiking neurons, by partitioning the network into populations of neurons that share the same statistical properties. Using some plausible approximations, the stationary firing rate of each population can be expressed as a function of the firing rates of all the populations in the network. The set of stationary, self-reproducing rates for the different populations in the network can then be found solving a set of coupled self-consistency equations (see e.g. <xref ref-type="bibr" rid="pcbi.1000587-Brunel1">[4]</xref>). The method allows to characterize the activity of the network as a function of the neuronal and synaptic parameters.</p>
<p>For this <italic>ab initio</italic> approach to be applicable, however, one needs an explicit representation of the dynamics at the microscopic level. Even when such representation is actually available, it may not be possible or easy to come up with a low-dimensional description of the original system. Here we introduce an alternative methodology that allows for an effective reduction of dimensionality. The method is data-driven, in the sense that it does not require any knowledge of the dynamics at the microscopic level. The basic idea is is to fit the underlying dynamics of the data using a stochastic, nonlinear differential equation. In general, fitting a model to data from a nonlinear stochastic system is a difficult problem because of the high dimensionality of the space of available models. Without some prior knowledge to guide model selection, the likelihood of picking the “correct” model for some data set is slim. Here we describe a method that can be applied to data from systems that are (a) stationary, (b) driven by additive white noise, and (c) whose deterministic motion is governed by an effective one-dimensional energy function. In such type of systems, the stationary distribution of the variable can be straightforwardly related with the underlying energy function. When neurodynamical data is high-dimensional, the dimensionality of the system can be first reduced using principal curves or principal components analysis.</p>
<p>To model data from such systems we proceed in two steps. We estimate first the energy function and then the intensity of the noise. The energy function is uniquely determined by the stationary distribution, so to accomplish the first step we estimate this distribution from data. In particular we assume that we have access to samples from this distribution and that the underlying potential can be fit by a piecewise quadratic polynomial. To fit the intensity of the noise we need a measure that is dependent on this parameter in a known way. In this work we use the mean first-passage time through a particular boundary, for which there are closed-form expressions. That is, given samples of the first-passage times of the system under study, we find the noise intensity that yields the same mean first-passage time in the system described by the fitted energy function.</p>
<p>We first apply the method to simulated data from a one-dimensional rate equation. In this case, the assumptions of the method are fulfilled and we can recover the original model with high accuracy if the number of data points is sufficiently high. Next we show that the method is applicable also to data from high-dimensional neuronal models. In particular, we use the method to obtain the effective dynamics of a network of spiking neurons operating near a bifurcation. Finally, we apply the method to real data from intracellular recordings from cortical neurons <italic>in vivo</italic>.</p>
</sec><sec id="s2">
<title>Results</title>
<p>We next show the effectiveness of the method by applying it to three different systems of different complexity: (1) a one-dimensional stochastic rate model; (2) a network of spiking neurons showing bistability; and (3) experimental data from slow oscillatory activity in the cerebral cortex <italic>in vivo</italic>.</p>
<sec id="s2a">
<title>One-dimensional rate model</title>
<p>Here we show how the method works for a one-dimensional rate model described by a Langevin equation,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e001" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e002" xlink:type="simple"/></inline-formula> is a nonlinear function and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e003" xlink:type="simple"/></inline-formula> is Gaussian white noise with standard deviation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e004" xlink:type="simple"/></inline-formula>. The method described in this article provides an effective description of the system of exactly the same type as Equation (1), given a sample of states <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e005" xlink:type="simple"/></inline-formula>. Since the system is one-dimensional, an energy function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e006" xlink:type="simple"/></inline-formula> satisfying <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e007" xlink:type="simple"/></inline-formula> can be trivially defined without resorting to any approximation method. Thus, we do not gain much insight in applying this method to such a simple system. Our aim in this section is rather to check that the piecewise approximation of the probability density described in <xref ref-type="sec" rid="s4">Methods</xref> recovers correctly the energy of the system, which is well-defined in this particular example. We also study the sensitivity of the estimation to the number of subintervals used in the piecewise quadratic approximation.</p>
<sec id="s2a1">
<title>Fixed points and stability of the noiseless system</title>
<p>For the sake of concreteness, we choose <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e008" xlink:type="simple"/></inline-formula> to be of the form:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e009" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e010" xlink:type="simple"/></inline-formula> is a sigmoidal activation function<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e011" xlink:type="simple"/><label>(3)</label></disp-formula>The parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e012" xlink:type="simple"/></inline-formula> sets the location of the sigmoid's soft threshold, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e013" xlink:type="simple"/></inline-formula> is a scale parameter. This specific choice of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e014" xlink:type="simple"/></inline-formula> is motivated by the form of the rate models used to describe the firing activity of neuronal assemblies <xref ref-type="bibr" rid="pcbi.1000587-Wilson1">[6]</xref>–<xref ref-type="bibr" rid="pcbi.1000587-Amit1">[8]</xref>, although any other system satisfying the condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e015" xlink:type="simple"/></inline-formula>, which ensures the existence of at least one stable fixed point, would be equally valid (see <xref ref-type="sec" rid="s4">Methods</xref>).</p>
<p>We first consider the deterministic system that results from switching noise off by setting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e016" xlink:type="simple"/></inline-formula> in Equation (1). The fixed points of the noiseless system satisfy the condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e017" xlink:type="simple"/></inline-formula> or, equivalently, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e018" xlink:type="simple"/></inline-formula>. Depending on the values of the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e019" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e020" xlink:type="simple"/></inline-formula>, there may be either one or three solutions to this equation. In the former case, the only intersection point will always correspond to a stable fixed point by construction, and the system will be monostable. When instead three solutions coexist, the system is bistable, with two of the solutions corresponding to stable fixed points and the remaining one corresponding to an unstable fixed point. We illustrate in <xref ref-type="fig" rid="pcbi-1000587-g001">Figures 1A–C</xref> the presence and number of fixed points as a function of the parameters. Note that bistability is only possible for high enough values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e021" xlink:type="simple"/></inline-formula>, which dictates the degree of nonlinearity in the system. Also, in order for the system to be bistable, the value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e022" xlink:type="simple"/></inline-formula> should lie in some interval centered at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e023" xlink:type="simple"/></inline-formula>. The endpoints of the interval can be actually derived from the fixed point condition, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e024" xlink:type="simple"/></inline-formula>, and the condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e025" xlink:type="simple"/></inline-formula> that determines where pairs of fixed points appear or disappear (see <xref ref-type="supplementary-material" rid="pcbi.1000587.s001">Text S1</xref>). The region of bistability shown in <xref ref-type="fig" rid="pcbi-1000587-g001">Figure 1D</xref>.</p>
<fig id="pcbi-1000587-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000587.g001</object-id><label>Figure 1</label><caption>
<title>Bistability in a one-dimensional rate model.</title>
<p>The rate model described by Equations (1)–(3) has two stable fixed points for some values of the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e026" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e027" xlink:type="simple"/></inline-formula>. A, B, and C: Location of the fixed points as a function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e028" xlink:type="simple"/></inline-formula>, for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e029" xlink:type="simple"/></inline-formula> (A) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e030" xlink:type="simple"/></inline-formula> (C), and as a function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e031" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e032" xlink:type="simple"/></inline-formula> (B). Solid curves correspond to stable fixed points, and the dotted curves to unstable fixed points. D: Regions of monostability (white) and bistability (gray) in the parameter space <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e033" xlink:type="simple"/></inline-formula>. Blue lines show the sections of the parameter space represented in the bifurcation diagrams A–C.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.g001" xlink:type="simple"/></fig>
<p>It is straightforward to compute the energy function of the system:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e034" xlink:type="simple"/><label>(4)</label></disp-formula>By construction, the local minima of the energy function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e035" xlink:type="simple"/></inline-formula> are at the stable fixed points of the system (1), while the local maxima are at the unstable fixed points.</p>
</sec><sec id="s2a2">
<title>Stochastic system: extraction of the effective parameters</title>
<p>A bistable deterministic system like the one described in the previous section will always decay to either one of the two available stable states depending on the initial conditions. Once reached equilibrium, the system will remain there indefinitely. The picture changes dramatically when noise is added to the system: the variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e036" xlink:type="simple"/></inline-formula> spends most of the time wandering around either one of the two fixed points until some rare and large fluctuation drives it to the neighborhood of the other fixed point, where the process starts over. Therefore, rather than a pair of stable states, we have two <italic>metastable</italic> states that are long-lived in terms of the characteristic time scales of the system, but that are not truly stable at much longer time scales. Each of these two metastable <italic>states</italic> are better regarded as a unimodal <italic>distribution</italic> centered at one of the stable fixed points of the noiseless system. We loosely refer to each of these distributions as an <italic>attractor</italic>. Since the system spends most of the time in either one of the attractors, and there are quick, random, and rare switches between the two, the stationary distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e037" xlink:type="simple"/></inline-formula> is bimodal.</p>
<p>As an example, we choose the parameter values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e038" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e039" xlink:type="simple"/></inline-formula>, which lie within region of bistability depicted in <xref ref-type="fig" rid="pcbi-1000587-g001">Figure 1D</xref>. The analysis of stability of the deterministic limit of Equations (1)–(3) shows that for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e040" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e041" xlink:type="simple"/></inline-formula> the stable fixed points are located at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e042" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e043" xlink:type="simple"/></inline-formula>. By adding a moderate amount of noise, the two stable fixed points become metastable and alternate with each other (<xref ref-type="fig" rid="pcbi-1000587-g002">Figure 2A</xref>). The stationary distribution of the state variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e044" xlink:type="simple"/></inline-formula>, when the stochastic system described by Equations (1)–(3) is simulated long enough, is shown in <xref ref-type="fig" rid="pcbi-1000587-g002">Figure 2B</xref>. Note that we are implicitly assuming that the sampling of the system over a long enough time can be identified with the sampling of independent realizations of the same process —i.e., we are assuming ergodicity. <xref ref-type="fig" rid="pcbi-1000587-g002">Figure 2B</xref> also shows the maximum likelihood estimate of the stationary distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e045" xlink:type="simple"/></inline-formula> using a piecewise quadratic approximation, as well as the associated energy function. The two peaks of the distribution are centered at the stable fixed points of the noiseless system. With the estimated probability density we can easily extract the underlying energy, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e046" xlink:type="simple"/></inline-formula>, following the procedure described in <xref ref-type="sec" rid="s4">Methods</xref>. For a comparison with the estimated energy function, we also include in <xref ref-type="fig" rid="pcbi-1000587-g002">Figure 2B</xref> the true energy function of the original system (Equation (4)). Note the good agreement between the two.</p>
<fig id="pcbi-1000587-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000587.g002</object-id><label>Figure 2</label><caption>
<title>Statistical properties of the one-dimensional, bistable rate model in the presence of noise.</title>
<p>A: Stationary distribution of the rate variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e047" xlink:type="simple"/></inline-formula> of the system (1)–(3) with parameter values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e048" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e049" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e050" xlink:type="simple"/></inline-formula>. Blue: normalized histogram of the simulated data. Black: maximum likelihood fit of the stationary distribution, using a piecewise quadratic approximation. Red: estimated energy function. Black dashed: original energy function. B: Distribution of the residence times in each of the attractors. Due to the symmetry of the system when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e051" xlink:type="simple"/></inline-formula>, the two attractor states share the same statistical properties; here we show only the distribution of residence times in the <italic>left</italic> attractor, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e052" xlink:type="simple"/></inline-formula>. Red and black curves are, respectively, the distributions estimated from the original stochastic Equation (1) and from the reconstructed system. C: Error in the estimation of the true energy function, as a function of the number of data points. Error bars are mean squared errors.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.g002" xlink:type="simple"/></fig>
<p>The noise intensity was estimated from the mean escape time from a metastable state, Equation (13). In our example, we estimated the average time needed for the system initialized at the fixed point at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e053" xlink:type="simple"/></inline-formula> (<italic>left</italic> attractor) to cross a boundary at some <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e054" xlink:type="simple"/></inline-formula>. The location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e055" xlink:type="simple"/></inline-formula> of the boundary was chosen somewhere between the separatrix at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e056" xlink:type="simple"/></inline-formula> to the fixed point at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e057" xlink:type="simple"/></inline-formula> (<italic>right</italic> attractor), to make sure that the mean first-passage time corresponded to a real escape from one attractor to the other. The analytical form for the mean escape time from an interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e058" xlink:type="simple"/></inline-formula>, when the system is initialized at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e059" xlink:type="simple"/></inline-formula>, is given by Equation (13) in <xref ref-type="sec" rid="s4">Methods</xref>. The expression (13) can be further simplified using the property that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e060" xlink:type="simple"/></inline-formula> goes to infinity in the limit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e061" xlink:type="simple"/></inline-formula>, which ensures the system can escape only through the right endpoint of the interval. Thus identifying <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e062" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e063" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e064" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e065" xlink:type="simple"/></inline-formula>, the mean escape time through <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e066" xlink:type="simple"/></inline-formula> reads<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e067" xlink:type="simple"/><label>(5)</label></disp-formula>The noise intensity can then be estimated as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e068" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e069" xlink:type="simple"/></inline-formula> is the numerical evaluation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e070" xlink:type="simple"/></inline-formula> using the piecewise-quadratic approximation of the potential, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e071" xlink:type="simple"/></inline-formula> is the sample mean of first-passage times. We obtained an estimated value for the noise intensity of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e072" xlink:type="simple"/></inline-formula>, which is close to the value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e073" xlink:type="simple"/></inline-formula>, used in the simulations. The value of the error in estimating the true energy function, as a function of the number of data points, is shown in <xref ref-type="fig" rid="pcbi-1000587-g002">Figure 2D</xref>. Good fits are already obtained with 300 data points.</p>
</sec></sec><sec id="s2b">
<title>Network of spiking neurons</title>
<p>As a second example of our reduction method, we consider a large-scale network of spiking neurons exhibiting bistability. The network we use is the binary decision network introduced by Wang <xref ref-type="bibr" rid="pcbi.1000587-Wang1">[9]</xref>, with identical architecture and parameters (see <xref ref-type="fig" rid="pcbi-1000587-g003">Figure 3</xref> and <xref ref-type="supplementary-material" rid="pcbi.1000587.s001">Text S1</xref> for the details).</p>
<fig id="pcbi-1000587-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000587.g003</object-id><label>Figure 3</label><caption>
<title>Architecture of the winner-take-all spiking network.</title>
<p>The network is fully connected and structured in different subpopulations of cells sharing the same connectivity and input statistics. All neurons receive background noise input modeled as independent Poisson trains. Cells in neural populations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e074" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e075" xlink:type="simple"/></inline-formula> receive in addition a Poisson train of rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e076" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e077" xlink:type="simple"/></inline-formula>, respectively, to account for selective input. These two so-called selective populations are composed of excitatory cells strongly interconnected.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.g003" xlink:type="simple"/></fig>
<p>In short, the model consists of a fully connected network of integrate-and-fire neurons with synaptic dynamics mediated by excitatory AMPA and NMDA receptors, and by inhibitory GABA receptors <xref ref-type="bibr" rid="pcbi.1000587-Brunel1">[4]</xref>. Excitatory neurons are structured into two subpopulations. Due to the strong recurrent connections between cells within each population and to the shared inhibitory feedback, the two subpopulations compete with each other for higher activity. This competition eventually culminates with the network settling into an attractor where the activation of one population suppresses the activity of the other. There are two such attractors, called asymmetric attractors, associated with the two possible outcomes of the competition. Apart from recurrent currents, all cells receive AMPA-mediated synaptic currents from external neurons that emit spikes following Poisson statistics.</p>
<p>For a wide range of external inputs and connection weights, the network operates as a winner-take-all, and is therefore able to sustain either one of the two asymmetric stable states. As in the rate model analyzed in the previous section, noise induces transitions between states that are simultaneously stable, giving rise to a bimodal distribution in the rate variables when the system is observed long enough. This bimodality can be seen in <xref ref-type="fig" rid="pcbi-1000587-g004">Figure 4A</xref>, which shows the two-dimensional histograms of the population-averaged activities of both populations, for different levels of external input.</p>
<fig id="pcbi-1000587-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000587.g004</object-id><label>Figure 4</label><caption>
<title>Extraction of the effective parameters from data generated by a winner-take-all network of spiking neurons.</title>
<p>A: Estimated probability density functions of the population rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e078" xlink:type="simple"/></inline-formula>. (Ai): symmetric network with balanced external inputs (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e079" xlink:type="simple"/></inline-formula>) for different values of input intensity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e080" xlink:type="simple"/></inline-formula>, indicated at the top of each plot. Aii: unbalanced inputs, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e081" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e082" xlink:type="simple"/></inline-formula>. Probability densities are shown as 2-dimensional histograms of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e083" xlink:type="simple"/></inline-formula> bins and Gaussian interpolation. B, and D: Blue: stationary distribution of the projection on the principal component <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e084" xlink:type="simple"/></inline-formula> of the firing rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e085" xlink:type="simple"/></inline-formula> of a network with symmetric (B) and asymmetric (D) inputs. Black: maximum likelihood fit using a piecewise quadratic approximation. Red: energy function. C, E, F: Distribution of the residence times in the attractor states, for the symmetric (C) and asymmetric cases (E,F). For the asymmetric case, the <italic>deep</italic> attractor corresponds to the network state where the active population firing at highest rate is the population receiving strongest inputs. Conversely, in the <italic>shallow</italic> attractor the active population is that receiving weakest inputs. The dashed red curves are the distributions estimated directly from the data, while the solid black curves are the distributions derived from the effective one-dimensional Langevin system.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.g004" xlink:type="simple"/></fig>
<p>Note that the strength of the method is not in reducing the dimensionality of the system, but in extracting effectively the underlying stochastic dynamics in the form of a diffusion equation. Thus a prerequisite for applying the method is to select a range of parameters where the dynamics of the system can be reduced to one-dimensional dynamics. In this type of system, this is the case in the neighborhood of a bifurcation (see, e.g., <xref ref-type="bibr" rid="pcbi.1000587-Roxin1">[10]</xref>).</p>
<p>Given the reduced first principal component <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e086" xlink:type="simple"/></inline-formula> of the original data, we apply the procedure detailed in <xref ref-type="sec" rid="s4">Methods</xref> to extract the effective energy function associated with a one-dimensional Langevin equation (see Equations (6) and (9)). We show in <xref ref-type="fig" rid="pcbi-1000587-g004">Figures 4B and 4D</xref> the effective energy function for the symmetric and asymmetric case, respectively. The figures also show the stationary distribution of the reduced variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e087" xlink:type="simple"/></inline-formula> capturing the essential part of the dynamics, as well as the maximum likelihood fit of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e088" xlink:type="simple"/></inline-formula>, Equation (10). By using Equation (10) we can easily extract the effective energy function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e089" xlink:type="simple"/></inline-formula>.</p>
<p>We then estimated the noise intensity along the same lines of the previous section. In brief, we generated a large set of sample paths, starting out at one the attractors, and computed the first-passage time through some prescribed boundary. In our case, the boundary was halfway to the main barrier separating the two attractors. Choosing the boundary this way, the first-passage times were considerably shorter than the transition times between attractors, allowing for larger samples and thus better numerical estimation. We could then estimate from Eq.(13) the noise intensity, using the sample mean of the first-passage times and the effective potential. For the symmetric case (<xref ref-type="fig" rid="pcbi-1000587-g004">Figures 4B,C</xref>), we initialized the system at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e090" xlink:type="simple"/></inline-formula> and set the boundary at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e091" xlink:type="simple"/></inline-formula>. For the asymmetric case (<xref ref-type="fig" rid="pcbi-1000587-g004">Figure 4D–F</xref>), the system was initialized at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e092" xlink:type="simple"/></inline-formula> and the barrier was at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e093" xlink:type="simple"/></inline-formula>.</p>
<p>Using the estimates of the noise intensity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e094" xlink:type="simple"/></inline-formula> and the effective energy function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e095" xlink:type="simple"/></inline-formula>, we checked the approximation by comparing the residence times in each of the attractors (<xref ref-type="fig" rid="pcbi-1000587-g004">Figures 4C and 4E,F</xref> for the symmetric and asymmetric case, respectively). The agreement between the distribution of residence times for the one-dimensional Langevin and for the original data is remarkable.</p>
<p>Note that with this method we can easily estimate the transition times between attractors, using just the one-dimensional reduced system. This is particularly useful when the transition times are long, of the order of seconds, for which a reliable estimation requires simulations of the high-dimensional system, defined in our case by a system of several thousands of nonlinear differential equations. The reduction can be done without such computational effort, since it requires only a good estimate of the stationary distribution, to extract the underlying energy, as well as an estimate of the escape times, in order to get the estimate of the noise intensity. The effective data-driven reduction allows us to extract explicitly the underlying form of the energy function associated with the bistable behavior, the level of fluctuations, and consequently allow us to calculate the characteristic escape times in a much more efficient way, due to the fact that with the reduced system they can be calculated semi-analytically.</p>
</sec><sec id="s2c">
<title>Up and Down State Dynamics in the Cerebral Cortex <italic>in vivo</italic></title>
<p>We next analyzed experimental data from intracellular recordings in the auditory cortex of anesthetized rats. During anesthesia with ketamine-xylazine, the cerebral cortex exhibits robust slow oscillatory activity, as it has been previously described in the cat <xref ref-type="bibr" rid="pcbi.1000587-Steriade1">[11]</xref>,<xref ref-type="bibr" rid="pcbi.1000587-Steriade2">[12]</xref>, ferret <xref ref-type="bibr" rid="pcbi.1000587-Haider1">[13]</xref>, and rat <xref ref-type="bibr" rid="pcbi.1000587-Mahon1">[14]</xref>,<xref ref-type="bibr" rid="pcbi.1000587-Reig1">[15]</xref>. Up and down states were recorded both by means of local field potential (not shown) and intracellularly (<xref ref-type="fig" rid="pcbi-1000587-g005">Figure 5</xref>) during periods of lighter and deeper anesthesia. Anesthesia levels were deeper after the injection of supplemental doses (see <xref ref-type="sec" rid="s4">Methods</xref>).</p>
<fig id="pcbi-1000587-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000587.g005</object-id><label>Figure 5</label><caption>
<title>Up and down alternations recorded in vivo in the auditory cortex of a rat under light and deep anesthesia.</title>
<p>A, and E: Trace of the subthreshold membrane potential, measured intracellularly for light (A) and deep (E) anesthesia. B, F: Stationary distribution of the membrane potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e096" xlink:type="simple"/></inline-formula> for light and deep anesthesia. Red: energy function derived from the distribution. Black: maximum likelihood estimate. C, D, G, H: Distribution of up-state and down-state durations, for light (C,D) and deep (G,H) anesthesia. Dashed red: experimental data. Solid black: data from simulations.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.g005" xlink:type="simple"/></fig>
<p>During periods of light anesthesia, without reaching the transition to the awake state (for a complete transition from sleep to awake, see <xref ref-type="bibr" rid="pcbi.1000587-Steriade3">[16]</xref>), cortical activity still shows up and down states, but their distribution appears to be more random (<xref ref-type="fig" rid="pcbi-1000587-g005">Figure 5A</xref>). Given the normalized and centered membrane potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e097" xlink:type="simple"/></inline-formula> of the recorded data, we applied the procedure detailed in <xref ref-type="sec" rid="s4">Methods</xref> to extract the effective energy function associated with a reduced Langevin equation, (<xref ref-type="fig" rid="pcbi-1000587-g005">Figure 5B</xref>). Using Equation (10) we can easily extract the underlying energy or potential function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e098" xlink:type="simple"/></inline-formula>. In both cases we shifted the variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e099" xlink:type="simple"/></inline-formula> to be in the positive range, and scaled the energy function by a factor 1/100 to facilitate its visualization. We then estimated the underlying noise by using Equation (13) and the estimate of the escape time from a meta-stable state. In our case, we took the escape time that the system initialized in the down state (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e100" xlink:type="simple"/></inline-formula>) need to cross a barrier at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e101" xlink:type="simple"/></inline-formula>. We found that the time spent in the down-state could be well fitted with our model, whereas the time spent in the up-state was less well described (<xref ref-type="fig" rid="pcbi-1000587-g005">Figure 5C and D</xref>).</p>
<p>As a quantitative measure of how well the reduced model can describe the distribution of transition times we used the Kolmogorov-Smirnov test. This is a non-parametric test of the hypothesis that two sets of observations are sampled from the same probability distribution. We applied this test to the dwell times in the down and up-states respectively (e.g. the data shown in <xref ref-type="fig" rid="pcbi-1000587-g005">Figure 5C and D</xref>). We can not reject the hypothesis that the dwell times in the data have the same distribution as those in the reduced model (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e102" xlink:type="simple"/></inline-formula>). However, the distributions of the dwell-times in the upstate are significantly different (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e103" xlink:type="simple"/></inline-formula>). The Kolmogorov-Smirnov test hence reinforce the conclusions drawn by looking at <xref ref-type="fig" rid="pcbi-1000587-g005">Figure 5C and D</xref>.</p>
<p>During periods of deep anesthesia, up and down states generated in the cortex were quite regular, both in their amplitude and time intervals between up states (<xref ref-type="fig" rid="pcbi-1000587-g005">Figure 5E</xref>). Next, we will see how well this data can be described by our reduction. In this case, to estimate the noise intensity we considered the mean escape time needed for the system initialized in the down state (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e104" xlink:type="simple"/></inline-formula>) to cross a barrier at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e105" xlink:type="simple"/></inline-formula>. In this case, the stationary distribution can be of course fitted, but the distributions of the residence time in the down and up states cannot be captured by our model (<xref ref-type="fig" rid="pcbi-1000587-g005">Figures 5G and H</xref>). An application of the Kolmogorov-Smirnov test in this case confirms that dwell-times in both the up- and down-state were significantly different between the data and the reduced model (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e106" xlink:type="simple"/></inline-formula> for both). In summary, when the same procedure is carried out, we no longer get a good fit of the distribution of dwell times. Note the strong regularity in the data as evidenced by the peak in the probability distribution of the life time of the experimental data. This result is nevertheless relevant because tells us that the data is not purely noise driven. In fact, previous studies have shown that these data evidenced a strong adaptation effect <xref ref-type="bibr" rid="pcbi.1000587-Wilson2">[17]</xref>–<xref ref-type="bibr" rid="pcbi.1000587-Cunningham1">[20]</xref>, which plays a crucial role in the transitions. The method is therefore also useful to reject the hypothesis of a pure noise driven transition.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>We have introduced a novel methodology for extracting, in a data-driven fashion, the stochastic dynamics underlying experimental or simulated neuronal data. The main idea of the method is to test the hypothesis that the underlying dynamics is consistent with a Langevin equation, which describes the motion of a Brownian particle in a potential. This is done by extracting an effective potential consistent with the asymptotic stationary distribution of the data and subsequently estimating the intensity of the underlying fluctuations from the average escape time from a specific region. The initial hypothesis can then be tested by checking how well the escape-time distribution of the data can be fitted by the reduced model. If this fit is reasonably good then we can affirm that the observed dynamics are consistent with an underlying stochastic process of the Langevin type. Note that the test could be extended to all possible escape times, i.e., considering different escape boundaries, allowing for a sharper test of the original hypothesis. If the distribution of escape times is not well fitted by the reduced model, we can reject the hypothesis that the system is described by a one-dimensional Langevin equation.</p>
<p>We applied the method to data from models of simulated neuronal activity as well as recordings from real cortical neurons. The method is however applicable to data from any system that obeys the assumptions of the dynamics and the noise. Indeed, our method generalizes a similar approach suggested in the context of laser dynamics <xref ref-type="bibr" rid="pcbi.1000587-Giacomelli1">[21]</xref>. In this work we propose an efficient and semi-analytical way of estimating the noise through the estimation of Â transition times. After extracting a parametric form of the underlying energy function, we can express the transition times by a closed form expression (Equation (13)), which can be used to estimate the noise intensity. Furthermore, we use a more robust maximum-likelihood-based method for the estimation of the underlying effective energy by decomposing the stationary distribution of the main variable as a mixture of Gaussians. The method is directly applicable to data from one-dimensional systems but we also demonstrated how it could be applied to data originating from a higher dimensional system. This implied first reducing the dimensionality by projecting the data onto the first principal component, and then provide an effective model for the reduced one-dimensional data. This approach will work whenever the dynamics of the original system is confined to a one-dimensional manifold which is approximately the case for the spiking network that we studied <xref ref-type="bibr" rid="pcbi.1000587-Roxin1">[10]</xref>,<xref ref-type="bibr" rid="pcbi.1000587-Mart1">[22]</xref>. We have applied the method to data from bistable systems but it is equally straightforward to apply the method to multistable systems. As long as the dynamics can be described approximately as a diffusion in an energy landscape our method is applicable.</p>
<p>The fact of transitions between up and down states in the cerebral cortex is a neural network phenomenon that has aroused great interest, since the mechanisms involved may be critical for persistent activity, memory or attention. However, the cellular and network mechanisms involved in the initiation, maintenance and termination of up states are still a matter of debate. Different mechanisms of initiation of up states have been proposed, either appealing to stochastic or alternatively deterministic processes. The cortical network <italic>in vivo</italic> generates slow rhythmic activity in complex interaction with other rhythms in the thalamocortical network rhythmic activity <xref ref-type="bibr" rid="pcbi.1000587-Steriade1">[11]</xref>,<xref ref-type="bibr" rid="pcbi.1000587-Steriade2">[12]</xref>. A role for thalamic inputs has been proposed <xref ref-type="bibr" rid="pcbi.1000587-Steriade1">[11]</xref>,<xref ref-type="bibr" rid="pcbi.1000587-Rigas1">[23]</xref>, and both intracortical or thalamocortical synaptic inputs can eventually start up states <xref ref-type="bibr" rid="pcbi.1000587-Reig1">[15]</xref>,<xref ref-type="bibr" rid="pcbi.1000587-Rigas1">[23]</xref>,<xref ref-type="bibr" rid="pcbi.1000587-Shu1">[24]</xref>. However, it is known that the thalamus is not required for the rhythm to occur, since it persists after thalamic lesions and it can be recorded in isolated cortical slabs <italic>in vivo</italic> <xref ref-type="bibr" rid="pcbi.1000587-Timofeev1">[25]</xref> and in cortical slices <italic>in vitro</italic> <xref ref-type="bibr" rid="pcbi.1000587-SanchezVives1">[18]</xref>. In the isolated cortex, it has been proposed that up states start by spontaneous spikes that activate the recurrent cortical circuitry, bringing the network to an up state where activity reverberates <xref ref-type="bibr" rid="pcbi.1000587-Compte1">[19]</xref>. This model relies on strong cortical recurrence plus activity-dependent hyperpolarizing currents that terminate the up states and maintain down states. Alternative proposed mechanisms are the initiation of up states by summation of spike-independent stochastic releases of neurotransmitters or noise producing random transition between up and down states <xref ref-type="bibr" rid="pcbi.1000587-Bazhenov1">[26]</xref>. Those mechanisms would determine the initiation of up states given that they overcome the ones believed to start, and to maintain, down states such as potassium currents <xref ref-type="bibr" rid="pcbi.1000587-Wilson2">[17]</xref>–<xref ref-type="bibr" rid="pcbi.1000587-Compte1">[19]</xref>, metabolically modulated currents <xref ref-type="bibr" rid="pcbi.1000587-Cunningham1">[20]</xref>, or cortical disfacilitation <xref ref-type="bibr" rid="pcbi.1000587-Contreras1">[27]</xref>.</p>
<p>The study presented here suggests that some of those seemingly mutually exclusive mechanisms regulating up and down states could indeed coexist. The analysis of intracellularly recorded up and down transitions by means of a reduced Langevin equation reveals that the stochasticity of up state occurrence varies with the dynamic state of the <italic>in vivo</italic> network. While in deep anesthesia, the occurrence of up states is not well fitted by the Langevin equation. Given that the Langevin equation describes the stochastic dynamics of a network, the bad fit to the data in deep anesthesia suggests that the process is not stochastic but deterministic and therefore controlled by non-random processes. However, <italic>in vivo</italic> during lighter anesthesia the time spent in the up and down states was better described by a one-dimensional model. In particular, the time spent in the down state was reasonably described by the model. This could indicate a role for random fluctuations in shaping the transitions from the down to the up-state. It is important to notice however that there are several aspects of the intracellular data that are not well described by the model (nor intended to be well described). There are for example high frequency oscillations in the upstate not captured by the model. Our findings suggest that different network mechanisms inducing up states that have been proposed by different authors and appeared to be incompatible, could indeed be simultaneously participating but in different functional states of the network. Thus, transitional states between sleep and awake (or light anesthesia) would be dominated by mechanisms involving stochasticity while deep sleep would be dominated by deterministic mechanisms. Another possible scenario is that in which the same mechanisms of initiation of up states would trigger more or less regular waves. This possibility has been achieved in a computer model by varying the cortical synaptic strength <xref ref-type="bibr" rid="pcbi.1000587-Esser1">[28]</xref>.</p>
</sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<sec id="s4a">
<title>Ethics statements</title>
<p>Rats were cared for and treated in accordance with the EU guidelines on protection of vertebrates used for experimentation (Strasbourg 3/18/1986) as well as local ethical guidelines and regulations.</p>
</sec><sec id="s4b">
<title>Fokker-Planck description</title>
<p>In this section, we describe how to extract the <italic>effective</italic> energy function from a data set like, for example, the temporal sequence of firing activity in a network of spiking neurons. We also show how to estimate the intensity of the concomitant noise. By doing this, we will able to write the stochastic neurodynamical equation describing the generation of the data set. We assume that the system is stationary.</p>
<sec id="s4b1">
<title>One-dimensional Langevin equation</title>
<p>To keep the analysis as simple as possible, we focus on cases where the description of the neural system can be captured by one single dimension. In those cases, it suffices to project the original dynamical variables on the first principal component, that is, on the direction where the variables show highest variability. We denote this projection by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e107" xlink:type="simple"/></inline-formula>. To derive the effective energy function underlying the stochastic evolution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e108" xlink:type="simple"/></inline-formula>, we assume that the trajectory <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e109" xlink:type="simple"/></inline-formula> can be described by a one-dimensional Langevin equation generating a Brownian motion of a highly damped particle in a one-dimensional potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e110" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1000587-Gardiner1">[29]</xref><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e111" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e112" xlink:type="simple"/></inline-formula> is a Gaussian fluctuation term with<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e113" xlink:type="simple"/><label>(7)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e114" xlink:type="simple"/><label>(8)</label></disp-formula>The parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e115" xlink:type="simple"/></inline-formula> is the noise intensity. The time coordinate we use is dimensionless and normalized to the time constant, so that time derivatives are of order unity and noise intensities have dimensions of a variance. The probability density of the stochastic process described by Equations (6)–(8) satisfies the Fokker-Planck equation:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e116" xlink:type="simple"/><label>(9)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e117" xlink:type="simple"/></inline-formula> is the probability density of the random variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e118" xlink:type="simple"/></inline-formula>. Equation (9) admits a nontrivial stationary solution given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e119" xlink:type="simple"/><label>(10)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e120" xlink:type="simple"/></inline-formula> is the normalized potential. This solution is well-defined as long as the integral in the denominator converges, which is the case when the potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e121" xlink:type="simple"/></inline-formula> grows to infinity as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e122" xlink:type="simple"/></inline-formula> goes to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e123" xlink:type="simple"/></inline-formula>. This limit is satisfied if we impose the condition that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e124" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4b2">
<title>Estimation of the one-dimensional potential</title>
<p>The effective potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e125" xlink:type="simple"/></inline-formula> is obtained by fitting the estimated probability density of the reduced empirical data with the stationary solution, Equation (10). We perform this estimation assuming a continuous piecewise quadratic potential. First, we partition the range of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e126" xlink:type="simple"/></inline-formula> into <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e127" xlink:type="simple"/></inline-formula> subintervals <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e128" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e129" xlink:type="simple"/></inline-formula>. In each interval the potential is given by a quadratic polynomial<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e130" xlink:type="simple"/><label>(11)</label></disp-formula>where the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e131" xlink:type="simple"/></inline-formula> parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e132" xlink:type="simple"/></inline-formula> are to be determined. To ensure continuity and differentiability of the potential at the boundaries the subintervals, the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e133" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e134" xlink:type="simple"/></inline-formula> must obey the recurrent relation<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e135" xlink:type="simple"/></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e136" xlink:type="simple"/></disp-formula>for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e137" xlink:type="simple"/></inline-formula>. We are then left with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e138" xlink:type="simple"/></inline-formula> free parameters, which we denote by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e139" xlink:type="simple"/></inline-formula>. Given the experimental data <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e140" xlink:type="simple"/></inline-formula>, the values of the free parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e141" xlink:type="simple"/></inline-formula> are set maximizing the logarithm of the likelihood function<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e142" xlink:type="simple"/><label>(12)</label></disp-formula>where we assume in the second equality that the data is drawn independently and identically from the distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e143" xlink:type="simple"/></inline-formula>, given by Equation (10). The maximization over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e144" xlink:type="simple"/></inline-formula> is computed using a downhill simplex method <xref ref-type="bibr" rid="pcbi.1000587-Nelder1">[30]</xref>,<xref ref-type="bibr" rid="pcbi.1000587-Lagarias1">[31]</xref>.</p>
</sec><sec id="s4b3">
<title>Estimation of the noise intensity</title>
<p>In addition to the potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e145" xlink:type="simple"/></inline-formula> the effective stochastic dynamical equation (6) and the Fokker-Planck counterpart, Equation (9), involve the noise intensity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e146" xlink:type="simple"/></inline-formula>. This parameter has to be specified in order to describe the full stochastic system. We estimate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e147" xlink:type="simple"/></inline-formula> through the mean escape time of the system from a metastable state. The analytical form of the mean escape time from an interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e148" xlink:type="simple"/></inline-formula> for the stochastic process described by Equation (6) starting at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e149" xlink:type="simple"/></inline-formula> is <xref ref-type="bibr" rid="pcbi.1000587-Gardiner1">[29]</xref> (an alternative procedure was derived in <xref ref-type="bibr" rid="pcbi.1000587-Malakhov1">[32]</xref> for this case using piecewise parabolic potential profiles):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e150" xlink:type="simple"/><label>(13)</label></disp-formula>where in the first equality we have defined<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e151" xlink:type="simple"/></disp-formula>The mean escape time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e152" xlink:type="simple"/></inline-formula> can be estimated from empirical data, while <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e153" xlink:type="simple"/></inline-formula> can be evaluated numerically once the potential has been approximated maximizing Equation (12). If we denote by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e154" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e155" xlink:type="simple"/></inline-formula> the estimated values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e156" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e157" xlink:type="simple"/></inline-formula>, the noise intensity can be inferred from the relation (13),<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e158" xlink:type="simple"/><label>(14)</label></disp-formula></p>
<p>Once the energy function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e159" xlink:type="simple"/></inline-formula> and the noise intensity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e160" xlink:type="simple"/></inline-formula> are determined, the effective description given by Equations (6)–(8), or, equivalently, by the associated Fokker-Planck Equation (9), is complete. Note that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e161" xlink:type="simple"/></inline-formula> fixes also the time scale of the problem. The stationary distribution of the data determines uniquely the normalized potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e162" xlink:type="simple"/></inline-formula> but it does not specify the time scale of dynamical evolution. Only after fixing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e163" xlink:type="simple"/></inline-formula> can we also fit the time scale of the data. In fact, the estimation of the residence time distributions shown in <xref ref-type="sec" rid="s2">Results</xref> was carried out by explicit simulations of the Langevin Equation (6), using the maximum-likelihood value of the noise intensity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e164" xlink:type="simple"/></inline-formula> that fits best the mean escape time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e165" xlink:type="simple"/></inline-formula> from a particular interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e166" xlink:type="simple"/></inline-formula>, given the initial condition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e167" xlink:type="simple"/></inline-formula>.</p>
</sec></sec><sec id="s4c">
<title>Large-scale spiking network</title>
<sec id="s4c1">
<title>Population rates</title>
<p>The firing rate of population <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e168" xlink:type="simple"/></inline-formula> is defined as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e169" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e170" xlink:type="simple"/></inline-formula> is the total number of spikes emitted in population <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e171" xlink:type="simple"/></inline-formula> between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e172" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e173" xlink:type="simple"/></inline-formula>, being <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e174" xlink:type="simple"/></inline-formula> a small time interval, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e175" xlink:type="simple"/></inline-formula> is the number of neurons in the population.</p>
</sec><sec id="s4c2">
<title>Probability densities</title>
<p>The 2-dimensional probability density function for the population rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e176" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e177" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e178" xlink:type="simple"/></inline-formula>, shown in <xref ref-type="fig" rid="pcbi-1000587-g004">Figure 4</xref>, was estimated from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e179" xlink:type="simple"/></inline-formula> trials of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e180" xlink:type="simple"/></inline-formula> simulated time each, and using a timestep of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e181" xlink:type="simple"/></inline-formula>. This gives a total of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e182" xlink:type="simple"/></inline-formula> data points per trial. The duration of the trial was long enough for the network to to alternate between the two decision states a few tens of times. Such transitions were due to finite-size effects in the network, and allowed the system to explore most of the state space within the whole duration of the trial. We then invoked ergodicity, by which time averages are identified with state space averages, and estimate the probability density from the sample <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e183" xlink:type="simple"/></inline-formula> formed by all the visited states <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e184" xlink:type="simple"/></inline-formula> across all trials<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e185" xlink:type="simple"/></disp-formula></p>
</sec><sec id="s4c3">
<title>Reduction to one dimension</title>
<p>The dimensionality of the system can be further reduced by projecting the multidimensional data <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e186" xlink:type="simple"/></inline-formula> on the direction with the maximum variance, using principal component analysis (see, e.g., <xref ref-type="bibr" rid="pcbi.1000587-Johnson1">[33]</xref>). For all the cases considered, this direction coincided with the direction of the line connecting the two peaks of the estimated two-dimensional probability density. The one-dimensional histograms shown in <xref ref-type="fig" rid="pcbi-1000587-g004">Figures 4B,D</xref> result from projecting the original two-dimensional data points in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e187" xlink:type="simple"/></inline-formula> onto the principal component. Specifically, if the principal component is represented by the unit vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e188" xlink:type="simple"/></inline-formula>, the sample of scalar values used in those histograms is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e189" xlink:type="simple"/></inline-formula>). The histogram was clearly bimodal, with a trough at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e190" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4c4">
<title>Escape boundaries</title>
<p>We considered that a good estimate of the separatrix between two attractor basins was given, in the two-dimensional phase space, by the line passing through the origin and the point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e191" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e192" xlink:type="simple"/></inline-formula> denotes the sample average. The inner escape boundaries used to estimate the noise intensity were also straight lines parallel to the separatrix and located at 0.75 the distance between the separatrix and the peaks. Thus, the inner boundary for peak 1 was a line parallel to the separatrix and passing through the point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e193" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e194" xlink:type="simple"/></inline-formula> is the value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e195" xlink:type="simple"/></inline-formula> at which the one-dimensional histogram showed the local maximum corresponding to peak 1. The inner boundary for peak 2 was found analogously.</p>
</sec></sec><sec id="s4d">
<title>Intracellular recordings in auditory cortex of the anesthetized rat</title>
<p>Recordings from primary auditory cortex A1 were obtained from adult wistar rats (230–350 g). Anesthesia was induced by intraperitoneal injection of ketamine (100 mg/kg) and xylacine (8–10 mg/kg). The animals were not paralyzed. Supplemental doses by intramuscular injection of ketamine were 75 mg/(kg h) and were given with intervals of 30–60 min. The depth of anesthesia was monitored by the recording of low-frequency electroencephalogram (EEG) and the absence of reflexes. The anesthesia level was deeper after a new dose and would progressive lightened during the interval (see <xref ref-type="sec" rid="s2">Results</xref>). Rectal temperature was maintained at 37, heart rate (250–300 bpm) and blood <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e196" xlink:type="simple"/></inline-formula> concentration (95%). Once in the stereotaxic apparatus, a craniotomy (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e197" xlink:type="simple"/></inline-formula> mm) was made at coordinates AP −3.5 to 5.5 mm from bregma, L 7 mm. After opening the dura, intracellular recordings were obtained with borosilicate glass capillaries 1 mm O.D. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e198" xlink:type="simple"/></inline-formula> 0.5 I.D. (Harvard Apparatus) filled with potassium acetate (resistances 50–80 <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000587.e199" xlink:type="simple"/></inline-formula>). For stability, and to avoid desiccation, agar (4%) was used to cover the area. Data was acquired with a CED commercial acquisition board (Cambridge Electronic Design, UK) and its commercial software Spike 2. Further details of the procedure can be found in <xref ref-type="bibr" rid="pcbi.1000587-Reig1">[15]</xref>.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1000587.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000587.s001" xlink:type="simple"><label>Text S1</label><caption>
<p>Description of the network of spiking neurons used to generate synthetic data.</p>
<p>(0.09 MB PDF)</p>
</caption></supplementary-material></sec></body>
<back><ref-list>
<title>References</title>
<ref id="pcbi.1000587-Rolls1"><label>1</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rolls</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Deco</surname><given-names>G</given-names></name>
</person-group>             <year>2002</year>             <source>Computational Neuroscience of Vision</source>             <publisher-loc>Oxford</publisher-loc>             <publisher-name>Oxford University Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000587-Dayan1"><label>2</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Abbott</surname><given-names>L</given-names></name>
</person-group>             <year>2002</year>             <source>Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems</source>             <publisher-loc>Boston</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000587-Tuckwell1"><label>3</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tuckwell</surname><given-names>H</given-names></name>
</person-group>             <year>1988</year>             <source>Introduction to Theoretical Neurobiology</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000587-Brunel1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Brunel</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Wang</surname><given-names>X</given-names></name>
</person-group>             <year>2001</year>             <article-title>Effects of neuromodulation in a cortical networks model of object working memory dominated by recurrent inhibition.</article-title>             <source>J Comput Neurosci</source>             <volume>11</volume>             <fpage>63</fpage>             <lpage>85</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Brunel2"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Brunel</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Amit</surname><given-names>D</given-names></name>
</person-group>             <year>1997</year>             <article-title>Model of global spontaneous activity and local structured delay activity during delay periods in the cerebral cortex.</article-title>             <source>Cereb Cortex</source>             <volume>7</volume>             <fpage>237</fpage>             <lpage>252</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Wilson1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wilson</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Cowan</surname><given-names>J</given-names></name>
</person-group>             <year>1972</year>             <article-title>Excitatory and inhibitory interactions in localised populations of model neurons.</article-title>             <source>Biophys J</source>             <volume>12</volume>             <fpage>1</fpage>             <lpage>24</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Knight1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Knight</surname><given-names>BW</given-names></name>
</person-group>             <year>1972</year>             <article-title>Dynamics of encoding in a population of neurons.</article-title>             <source>J Gen Physiol</source>             <volume>59</volume>             <fpage>734</fpage>             <lpage>766</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Amit1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Amit</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name>
</person-group>             <year>1991</year>             <article-title>Quantitative study of attractor neural network retrieving at low spike rates: I. Substrate spikes, rates and neuronal gain.</article-title>             <source>Network</source>             <volume>2</volume>             <fpage>259</fpage>             <lpage>273</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Wang1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wang</surname><given-names>XJ</given-names></name>
</person-group>             <year>2002</year>             <article-title>Probabilistic decision making by slow reverberation in cortical circuit.</article-title>             <source>Neuron</source>             <volume>36</volume>             <fpage>955</fpage>             <lpage>968</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Roxin1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Roxin</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Ledberg</surname><given-names>A</given-names></name>
</person-group>             <year>2008</year>             <article-title>Neurobiological models of two-choice decision making can be reduced to a one-dimensional nonlinear diffusion equation.</article-title>             <source>PLoS Computational Biology</source>             <volume>4(3)</volume>             <fpage>e1000046</fpage>          </element-citation></ref>
<ref id="pcbi.1000587-Steriade1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Steriade</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Nunez</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Amzica</surname><given-names>F</given-names></name>
</person-group>             <year>1993</year>             <article-title>Intracellular analysis of relations between the slow (&lt;1 Hz) neocortical oscillation and other sleep rhythms of the electroencephalogram.</article-title>             <source>J Neurosci</source>             <volume>13</volume>             <fpage>3266</fpage>             <lpage>3283</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Steriade2"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Steriade</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Contreras</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Dossi</surname><given-names>RC</given-names></name>
<name name-style="western"><surname>Nunez</surname><given-names>A</given-names></name>
</person-group>             <year>1993</year>             <article-title>The slow (&lt;1 Hz) oscillation in reticular thalamic and thalamocortical neurons: scenario of sleep rhythm generation in interacting thalamic and neocortical networks.</article-title>             <source>J Neurosci</source>             <volume>13</volume>             <fpage>3248</fpage>             <lpage>3299</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Haider1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Haider</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Duque</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Hasenstaub</surname><given-names>A</given-names></name>
<name name-style="western"><surname>McCormick</surname><given-names>D</given-names></name>
</person-group>             <year>2006</year>             <article-title>Neocortical network activity in vivo is generated through a dynamic balance of excitation and inhibition.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>4535</fpage>             <lpage>4545</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Mahon1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mahon</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Deniau</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Charpier</surname><given-names>S</given-names></name>
</person-group>             <year>2001</year>             <article-title>Relationship between EEG potentials and intracellular activity of striatal and cortico-striatal neurons: an in vivo study under different anesthetics.</article-title>             <source>Cereb Cortex</source>             <volume>11</volume>             <fpage>360</fpage>             <lpage>373</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Reig1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reig</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Sanchez-Vives</surname><given-names>M</given-names></name>
</person-group>             <year>2007</year>             <article-title>Synaptic transmission and plasticity in an active cortical network.</article-title>             <source>PLoS ONE</source>             <volume>2(7)</volume>             <fpage>e670</fpage>          </element-citation></ref>
<ref id="pcbi.1000587-Steriade3"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Steriade</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Timofeev</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Grenier</surname><given-names>F</given-names></name>
</person-group>             <year>2001</year>             <article-title>Natural waking and sleep states: a view from inside neocortical neurons.</article-title>             <source>J Neurophysiol</source>             <volume>86</volume>             <fpage>1969</fpage>             <lpage>1985</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Wilson2"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wilson</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Kawaguchi</surname><given-names>Y</given-names></name>
</person-group>             <year>1996</year>             <article-title>The origins of two-state spontaneous membrane potential fluctuations of neostriatal spiny neurons.</article-title>             <source>J Neurosci</source>             <volume>16</volume>             <fpage>2397</fpage>             <lpage>2410</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-SanchezVives1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sanchez-Vives</surname><given-names>M</given-names></name>
<name name-style="western"><surname>McCormick</surname><given-names>D</given-names></name>
</person-group>             <year>2000</year>             <article-title>Cellular and network mechanisms of rhythmic recurrent activity in neocortex.</article-title>             <source>Nat Neurosci</source>             <volume>3</volume>             <fpage>1027</fpage>             <lpage>1034</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Compte1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Compte</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Sanchez-Vives</surname><given-names>M</given-names></name>
<name name-style="western"><surname>McCormick</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Wang</surname><given-names>W</given-names></name>
</person-group>             <year>2003</year>             <article-title>Cellular and network mechanisms of slow oscillatory activity (&lt;1 Hz) and wave propagations in a cortical network model.</article-title>             <source>J Neurophysiol</source>             <volume>89</volume>             <fpage>2707</fpage>             <lpage>2725</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Cunningham1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cunningham</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Pervouchine</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Racca</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Kopell</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Davies</surname><given-names>C</given-names></name>
<etal/></person-group>             <year>2006</year>             <article-title>Neuronal metabolism governs cortical network response state.</article-title>             <source>P Natl Acad Sci USA</source>             <volume>103</volume>             <fpage>5597</fpage>             <lpage>5601</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Giacomelli1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Giacomelli</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Marin</surname><given-names>F</given-names></name>
</person-group>             <year>1998</year>             <article-title>Statistics of polarization competition in VCSELs.</article-title>             <source>Quantum Semicl Opt</source>             <volume>10</volume>             <fpage>469</fpage>             <lpage>476</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Mart1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mart</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Deco</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Mattia</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Gigante</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Del Giudice</surname><given-names>P</given-names></name>
</person-group>             <year>2008</year>             <article-title>A fluctuation-driven mechanism for slow decision processes in reverberant networks.</article-title>             <source>PLoS ONE</source>             <volume>3</volume>             <fpage>e2534</fpage>          </element-citation></ref>
<ref id="pcbi.1000587-Rigas1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rigas</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Castro-Alamancos</surname><given-names>M</given-names></name>
</person-group>             <year>2007</year>             <article-title>Thalamocortical up states: Differential effects of intrinsic and extrinsic cortical inputs on persistent activity.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>4261</fpage>             <lpage>4272</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Shu1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Shu</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Hasenstaub</surname><given-names>A</given-names></name>
<name name-style="western"><surname>McCormick</surname><given-names>D</given-names></name>
</person-group>             <year>2003</year>             <article-title>Turning on and off recurrent balanced cortical activity.</article-title>             <source>Nature</source>             <volume>423</volume>             <fpage>288</fpage>             <lpage>293</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Timofeev1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Timofeev</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Grenier</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Bazhenov</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Sejnowski</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Steriade</surname><given-names>M</given-names></name>
</person-group>             <year>2000</year>             <article-title>Origin of slow cortical oscillations in deafferented cortical slabs.</article-title>             <source>Cereb Cortex</source>             <volume>10</volume>             <fpage>1185</fpage>             <lpage>1199</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Bazhenov1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bazhenov</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Timofeev</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Steriade</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Sejnowski</surname><given-names>T</given-names></name>
</person-group>             <year>2002</year>             <article-title>Model of thalamocortical slow-wave sleep oscillations and transitions to activated states.</article-title>             <source>J Neurosci</source>             <volume>22(19)</volume>             <fpage>8691</fpage>             <lpage>8704</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Contreras1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Contreras</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Timofeev</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Steriade</surname><given-names>M</given-names></name>
</person-group>             <year>1996</year>             <article-title>Mechanisms of long-lasting hyperpolarizations underlying slow sleep oscillations in cat corticothalamic networks.</article-title>             <source>J Physiol</source>             <volume>494</volume>             <fpage>251</fpage>             <lpage>264</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Esser1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Esser</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Hill</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name>
</person-group>             <year>2007</year>             <article-title>Sleep homeostasis and cortical synchronization: I. modeling the effects of synaptic strength on sleep slow waves.</article-title>             <source>Sleep</source>             <volume>30(12)</volume>             <fpage>1617</fpage>             <lpage>1630</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Gardiner1"><label>29</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gardiner</surname><given-names>C</given-names></name>
</person-group>             <year>1991</year>             <source>Handbook of Stochastic Methods (for Physics, Chemistry and the Natural Sciences). Springer Series in Synergetics</source>             <publisher-name>Springer-Verlag</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000587-Nelder1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nelder</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Mead</surname><given-names>R</given-names></name>
</person-group>             <year>1965</year>             <article-title>A simplex method for function minimization.</article-title>             <source>Comput J</source>             <volume>7</volume>             <fpage>308</fpage>          </element-citation></ref>
<ref id="pcbi.1000587-Lagarias1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lagarias</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Reeds</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Wright</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Wright</surname><given-names>P</given-names></name>
</person-group>             <year>1998</year>             <article-title>Convergence properties of the nelder-mead simplex algorithm in low dimensions.</article-title>             <source>SIAM J Optimiz</source>             <volume>9</volume>             <fpage>112</fpage>             <lpage>147</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Malakhov1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Malakhov</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Pankratov</surname><given-names>A</given-names></name>
</person-group>             <year>1996</year>             <article-title>Exact solution of Kramers' problem for piecewise parabolic potential profiles.</article-title>             <source>Physica A</source>             <volume>229</volume>             <fpage>109</fpage>             <lpage>126</lpage>          </element-citation></ref>
<ref id="pcbi.1000587-Johnson1"><label>33</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Johnson</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Wichern</surname><given-names>D</given-names></name>
</person-group>             <year>1998</year>             <article-title>Principal Components.</article-title>             <source>Applied Multivariate Statistical Analysis</source>             <publisher-loc>New Jersey</publisher-loc>             <publisher-name>Prentice Hall</publisher-name>          </element-citation></ref>
</ref-list>

</back>
</article>
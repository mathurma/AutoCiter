<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">08-PLBI-RA-5408R3</article-id><article-id pub-id-type="doi">10.1371/journal.pbio.1000129</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience/Cognitive Neuroscience</subject><subject>Neuroscience/Sensory Systems</subject></subj-group></article-categories><title-group><article-title>Interaction between Attention and Bottom-Up Saliency Mediates the Representation of Foreground and Background in an Auditory Scene</article-title><alt-title alt-title-type="running-head">Attention in Auditory Scenes Analysis</alt-title></title-group><contrib-group>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple"><name name-style="western"><surname>Elhilali</surname><given-names>Mounya</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple"><name name-style="western"><surname>Xiang</surname><given-names>Juanjuan</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Shamma</surname><given-names>Shihab A.</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Simon</surname><given-names>Jonathan Z.</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff5"><sup>5</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, Maryland, United States of America</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Starkey Laboratories, Eden Prairie, Minnesota, United States of America</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Department of Electrical and Computer Engineering, University of Maryland, College Park, Maryland, United States of America</addr-line>       </aff><aff id="aff4"><label>4</label><addr-line>Institute for Systems Research, University of Maryland, College Park, Maryland, United States of America</addr-line>       </aff><aff id="aff5"><label>5</label><addr-line>Department of Biology, University of Maryland, College Park, Maryland, United States of America</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Griffiths</surname><given-names>Timothy D.</given-names></name>
<role>Academic Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">Newcastle University Medical School, United Kingdom</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">jzsimon@umd.edu</email></corresp>
<fn fn-type="con"><p>The author(s) have made the following declarations about their contributions: Conceived and designed the experiments: ME JX SAS JZS. Performed the experiments: ME JX SAS JZS. Analyzed the data: ME JX SAS JZS. Wrote the paper: ME JX SAS JZS.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>6</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>16</day><month>6</month><year>2009</year></pub-date><volume>7</volume><issue>6</issue><elocation-id>e1000129</elocation-id><history>
<date date-type="received"><day>15</day><month>12</month><year>2008</year></date>
<date date-type="accepted"><day>5</day><month>5</month><year>2009</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2009</copyright-year><copyright-holder>Elhilali et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract abstract-type="toc">
<p>Bottom-up (stimulus-driven) and top-down (attentional) processes interact when a complex acoustic scene is parsed. Both modulate the neural representation of the target in a manner strongly correlated with behavioral performance.</p>
</abstract><abstract>
<p>The mechanism by which a complex auditory scene is parsed into coherent objects depends on poorly understood interactions between task-driven and stimulus-driven attentional processes. We illuminate these interactions in a simultaneous behavioral–neurophysiological study in which we manipulate participants' attention to different features of an auditory scene (with a regular target embedded in an irregular background). Our experimental results reveal that attention to the target, rather than to the background, correlates with a sustained (steady-state) increase in the measured neural target representation over the entire stimulus sequence, beyond auditory attention's well-known transient effects on onset responses. This enhancement, in both power and phase coherence, occurs exclusively at the frequency of the target rhythm, and is only revealed when contrasting two attentional states that direct participants' focus to different features of the acoustic stimulus. The enhancement originates in auditory cortex and covaries with both behavioral task and the bottom-up saliency of the target. Furthermore, the target's perceptual detectability improves over time, correlating strongly, within participants, with the target representation's neural buildup. These results have substantial implications for models of foreground/background organization, supporting a role of neuronal temporal synchrony in mediating auditory object formation.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>Attention is the cognitive process underlying our ability to focus on specific aspects of our environment while ignoring others. By its very definition, attention plays a key role in differentiating foreground (the object of attention) from unattended clutter, or background. We investigate the neural basis of this phenomenon by engaging listeners to attend to different components of a complex acoustic scene. We present a spectrally and dynamically rich, but highly controlled, stimulus while participants perform two complementary tasks: to attend either to a repeating target note in the midst of random interferers (“maskers”), or to the background maskers themselves. Simultaneously, the participants' neural responses are recorded using the technique of magnetoencephalography (MEG). We hold all physical parameters of the stimulus fixed across the two tasks while manipulating one free parameter: the attentional state of listeners. The experimental findings reveal that auditory attention strongly modulates the sustained neural representation of the target signals in the direction of boosting foreground perception, much like known effects of visual attention. This enhancement originates in auditory cortex, and occurs exclusively at the frequency of the target rhythm. The results show a strong interaction between the neural representation of the attended target with the behavioral task demands, the bottom-up saliency of the target, and its perceptual detectability over time.</p>
</abstract><funding-group><funding-statement>Support has been provided by National Institutes of Health (NIH) grants R01DC008342, 1R01DC007657, and (via the Collaborative Research in Computational Neuroscience National Science Foundation/NIH joint mechanism) 1R01AG027573. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="14"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Attention is the cognitive process underlying our ability to focus on specific components of the environment while ignoring others. By its very definition, attention plays a key role in defining what foreground is, i.e., an object of attention, and differentiating it from task-irrelevant clutter, or background <xref ref-type="bibr" rid="pbio.1000129-Posner1">[1]</xref>–<xref ref-type="bibr" rid="pbio.1000129-Fritz1">[5]</xref>. In the visual modality, studies have shown that figure/ground segmentation is mediated by a competition for neural resources between objects in the scene <xref ref-type="bibr" rid="pbio.1000129-Desimone1">[2]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Craft1">[6]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Lamme1">[7]</xref>. This competition is biased in favor of different objects via top-down attention as well as behavioral and contextual effects that work to complement or counteract automatic bottom-up processes. An intricate neural circuitry has been postulated to take place in this process spanning primary visual, extrastriate, temporal, and frontal cortical areas <xref ref-type="bibr" rid="pbio.1000129-Lamme1">[7]</xref>–<xref ref-type="bibr" rid="pbio.1000129-Neri1">[19]</xref>.</p>
<p>In the auditory modality, however, there have been a limited number of studies that attempted to explore the neural underpinnings of attention in the context of auditory stream segregation, and the mechanisms governing the extraction of target sounds from a background of distracters <xref ref-type="bibr" rid="pbio.1000129-Hubel1">[20]</xref>–<xref ref-type="bibr" rid="pbio.1000129-Alain2">[28]</xref>. It is largely unknown how top-down (e.g., task-driven or context-dependent) and bottom-up (e.g., acoustic saliency or “pop-out”) attentional processes interact to parse a complex auditory scene <xref ref-type="bibr" rid="pbio.1000129-Carlyon2">[29]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Bregman1">[30]</xref>.</p>
<p>In a simultaneous behavioral and neurophysiological study using magnetoencephalography (MEG), we illuminate this interaction using stimuli shown in <xref ref-type="fig" rid="pbio-1000129-g001">Figure 1A</xref>, consisting of a repeating target note in the midst of random interferers (“maskers”). This design generalizes paradigms commonly used in informational masking experiments, <xref ref-type="bibr" rid="pbio.1000129-Kidd1">[31]</xref>, which explore how listeners' ability to perceive an otherwise salient auditory element is strongly affected by the presence of competing elements. For these stimuli, the ability to segregate the target note depends on various acoustic parameters, including the width of the spectral protection region (the spectral separation between target and masker frequencies). We adapt classic informational masking stimuli to the purposes of this study by randomly desynchronizing all background maskers throughout the duration of the trial, making the target note the only regular frequency channel in the sequence (with repetition rhythm of 4 Hz). The informational masking paradigm has been shown to invoke similar mechanisms to those at play in classic stream segregation experiments <xref ref-type="bibr" rid="pbio.1000129-Micheyl1">[32]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Sheft1">[33]</xref>, both in the systematic dependence of performance on the size of masker–target spectral separation, as well as the improvement of performance over time over the course of few seconds.</p>
<fig id="pbio-1000129-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1000129.g001</object-id><label>Figure 1</label><caption>
<title>Stimulus description and behavioral performance.</title>
<p>(A) Cartoon spectrogram of a typical stimulus. The stimulus consists of a repeating target note embedded in random interferers. A spectral protection region surrounds the target frequency with a spectral width of twice the minimal distance between the target note and nearest masker component (orange band). In the target task, participants were instructed to detect a frequency-shifted (ΔF) deviant in the repeating target notes. In the masker task, participants were instructed to detect a sudden temporal elongation (ΔT) of the masker notes. (B) Behavioral performance results for target and masker tasks, as measured by d-prime as a function of spectral protection region width. Orange (respectively, light-blue) lines show the mean performance in task detection in the target task (respectively, masker task) in the psychoacoustical study. Red (respectively, dark-blue) points show the mean performance in task detection in the target task (respectively, masker task) in the MEG study (eight-semitone condition only). Error bars represent standard error.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1000129.g001" xlink:type="simple"/></fig>
<p>While maintaining the same physical stimulus, we contrasted the performance of human listeners in two complementary tasks: (1) a “target task” in which participants are asked to detect a frequency-shifted (ΔF) deviant in the repeating target signal; and (2) a “masker task” in which participants are asked to detect a sudden temporal elongation (ΔT) of the masker notes. Crucially, attention is required to perform either task, but the participants' attention must be focused on different sound components of the acoustic stimulus in each case. Additionally, all the stimuli are diotic (identical in both ears), averting any confounding effects of spatial attention.</p>
</sec><sec id="s2">
<title>Results</title>
<p>The effect of spectral protection region width on the performance of both tasks is illustrated in <xref ref-type="fig" rid="pbio-1000129-g001">Figure 1B</xref>. In the left panel, it can be seen that the detectability of the target becomes easier with increasing protection region (significantly positive slope; bootstrap across participants, <italic>p</italic>&lt;10<sup>−4</sup>), a result that is in line with previous hypotheses of streaming that correlate the ease of target detection with the frequency selectivity of neurons in the central auditory system <xref ref-type="bibr" rid="pbio.1000129-Fishman1">[34]</xref>–<xref ref-type="bibr" rid="pbio.1000129-Kowalski1">[38]</xref>.</p>
<p>In contrast, the same manipulations of protection region do not substantively affect masker task performance (right panel) (not significantly different from zero; bootstrap across participants, <italic>p</italic>&gt;0.3). The masker task, designed to divert attentional resources away from the target, involves a more diffuse attention to the spectrally broad and distributed masker configuration; and compared to the target task, reflects a different top-down bias in the way the same stimulus is parsed. The behavioral performance was unchanged whether tested under purely psychoacoustic or neural recording conditions (no significant difference; unpaired <italic>t</italic>-test; target task: <italic>t</italic> = −0.75, <italic>p</italic> = 0.46; masker task: <italic>t</italic> = 0.09, <italic>p</italic> = 0.93).</p>
<p>For the neural recordings, we used the stimuli with the eight-semitones spectral protection region because they roughly matched the behavioral performance across tasks (d-prime for both is approximately equal to three). The target task is not at ceiling with the chosen protection region, hence still engaging participants' selective attentional processes.</p>
<p>Depending on listeners' attentional focus, the percept of an auditory target in a complex scene is differentially mirrored by the responses of neurons in auditory cortex. Using the high temporal resolution of MEG, we measure the neural responses to this stimulus paradigm in 14 human participants. <xref ref-type="fig" rid="pbio-1000129-g002">Figure 2A</xref> reveals that, during the performance of the target task, the target rhythm emerges as a strong 4-Hz component in the neural signal of an individual participant. In contrast, during the masker task, the cortical response entrained at 4 Hz is noticeably suppressed in comparison (<xref ref-type="fig" rid="pbio-1000129-g002">Figure 2A, right panel</xref>). This differential activation is strong evidence of the modulatory effect of task-dependent attention on the neural representation of a single acoustic stimulus, much like visual attention <xref ref-type="bibr" rid="pbio.1000129-Maunsell1">[39]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Reynolds2">[40]</xref>. Additionally, this attentional effect on the neural signal is not just momentary but is sustained over the duration of the trial (steady state).</p>
<fig id="pbio-1000129-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1000129.g002</object-id><label>Figure 2</label><caption>
<title>Neural responses.</title>
<p>(A) Power spectral density of MEG responses for a single participant (participant 14 in <xref ref-type="fig" rid="pbio-1000129-g002">Figure 2B</xref> below) in target (left) and masker (right) tasks, averaged over 20 channels. Insets: the MEG magnetic field distributions of the target rhythm response component. Red and green contours represent the target magnetic field strength projected onto a line with constant phase. (B) Normalized neural response to the target rhythm by participant (individual bars) and task (red for target task, blue for masker task). The normalized neural response is computed as the ratio of the neural response power at the target rate (4 Hz) to the average power of the background neural activity (from 3–5 Hz; see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). Bar height is the mean of the 20 best channels; error bars represent standard error. Light-pink background (respectively, light-blue) is the mean over participants for the target task (respectively, masker task).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1000129.g002" xlink:type="simple"/></fig>
<p>This attentional effect is confirmed in the population of 14 participants (<xref ref-type="fig" rid="pbio-1000129-g002">Figure 2B</xref>), with an average normalized neural response of 20.9 in the target task and 8.3 in the masker task: a gain of more than two and a half for neural phase-locked, sustained activity when participants' attention is directed towards the repeating note (individually, 11 out of 14 participants showed a significant increase: paired <italic>t</italic>-test, <italic>p</italic>&lt;10<sup>−4</sup>). Direct correlation between the target task neural response and target task behavior is not observed, but as shown below, changes in a participant's target neural response are significantly correlated with changes in the participant's behavioral responses.</p>
<p>The MEG magnetic field distributions of the target rhythm response component, examples of which are shown in the inset of the graphs in <xref ref-type="fig" rid="pbio-1000129-g002">Figure 2A</xref>, reveal the stereotypical pattern for neural activity originating separately in left and right auditory cortex. The neural sources of all the target rhythm response components with a sufficiently high signal-to-noise ratio originate in auditory cortex <xref ref-type="bibr" rid="pbio.1000129-Ahmar1">[41]</xref>. The neural source's mean displacement from the source of the auditory M100 response <xref ref-type="bibr" rid="pbio.1000129-Naatanen1">[42]</xref> was significantly different (two-tailed <italic>t</italic>-test; <italic>t</italic> = 2.9, <italic>p</italic> = 0.017) by 13.8±4.9 mm in the anterior direction, for the left auditory cortex only (no significant differences were found in the right hemisphere due to higher variability there). The displacement was not statistically significant in the remaining directions (3.2±3.5 mm lateral; 11.3±6.4 mm superior); the goodness of fit for these sources was 0.51±0.05 (artificially reduced in accordance with <xref ref-type="bibr" rid="pbio.1000129-Simon1">[43]</xref>). Assuming an M100 origin of planum temporale, an area of associative auditory cortex, this is consistent with an origin for the neural response to the target rhythm in Heschl's gyrus, the site of core auditory cortex including primary auditory cortex, and a region known to phase-lock well to 4-Hz rhythms <xref ref-type="bibr" rid="pbio.1000129-LiegeoisChauvel1">[44]</xref>.</p>
<p>The neural response change at the target rate of 4 Hz is highly significant (bootstrap across participants, <italic>p</italic>&lt;10<sup>−4</sup>) (<xref ref-type="fig" rid="pbio-1000129-g003">Figure 3A</xref>). In contrast, there is no significant change in normalized neural response at other frequencies, whether at frequencies nearby (one frequency bin on either side of 4 Hz) or distant (alpha, theta, and low gamma band frequencies sampled with approximately 5-Hz spacing up to 55 Hz). This demonstrates that this feature-selective sustained attention modulates the cortical representation of the specific feature, but not general intrinsic rhythms, whether in the same band or other bands.</p>
<fig id="pbio-1000129-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1000129.g003</object-id><label>Figure 3</label><caption>
<title>Power and phase enhancement during target task.</title>
<p>(A) Normalized neural response of target task relative to masker task shows differential enhancement exclusively at 4 Hz (the frequency of the target rhythm). Each data point represents the difference between normalized neural response of target relative to masker task; error bars represent standard error The asterisk at 4 Hz shows that only that particular frequency yields a statistically significant enhancement. (B) Phase coherence between distant MEG channels of target relative to masker task. The difference between the number of long-range channel pairs with robust increased coherence in target task, and channel pairs with decreased coherence, is normalized over the total number of long-range channel pairs. The phase enhancement is significant (shown with asterisk) only at 4 Hz. (C) Channel pairs with robust coherence difference at target rate for single participant, overlaid on the contour map of normalized neural response at target rate. Each channel pair with enhancement coherence is connected by a red line, whereas pairs with decreased coherence are connected by a blue line. Coherence is only analyzed for the 20 channels with the best normalized response to target rhythm. (D) Neural responses to target across hemispheres. The 20 channels with the strongest normalized neural response at target rate were chosen from the left and right hemispheres, respectively, to represent the overall neural activity of each hemisphere. Neural responses were averaged across the 20 channels, and 14 participants were compared across hemispheres and tasks. The left hemisphere shows stronger differential activation at target rate in target task, whereas the right hemisphere shows stronger activation in masker task (asterisks indicate that the differences are significant).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1000129.g003" xlink:type="simple"/></fig>
<p>Changes in response phase coherence across channels were also assessed at the same frequencies (<xref ref-type="fig" rid="pbio-1000129-g003">Figure 3B</xref>, sample participant in <xref ref-type="fig" rid="pbio-1000129-g003">Figure 3C</xref>). This analysis focuses on the distant channel pairs with enhanced phase coherence at each specific frequency. Only the phase coherence at the target rate shows a significant enhancement (bootstrap across participants, <italic>p</italic> = 0.002), further demonstrating that change from one form of attention to another does not modulate general intrinsic rhythms. This 30% enhancement is distributed across channel pairs, revealing increased phase coherence both within and across hemispheres.</p>
<p>We also observe a task-dependent hemispheric asymmetry in the representation of the neural response at the target rate. During the target task, the left hemisphere showed a greater normalized neural response than the right hemisphere (bootstrap across participants, <italic>p</italic> = 0.001); during the masker task, the right hemisphere showed a greater normalized neural response than the left hemisphere (bootstrap across participants, <italic>p</italic> = 0.04) (<xref ref-type="fig" rid="pbio-1000129-g003">Figure 3D</xref>).</p>
<p>Together with the behavioral demands of the task, the bottom-up saliency of a target note contributes to both the neural response and participant performance. A close examination of the physical parameters of the stimulus reveals that the frequency of the target note affects the audibility of the repeating rhythm, with higher-frequency targets popping out more prominently than their lower-frequency counterparts. This variation in the pop-out sensation may be explained by the contours of constant loudness of human hearing showing an approximately 5-dB increase over the target note range 250–500 Hz <xref ref-type="bibr" rid="pbio.1000129-ISO1">[45]</xref>, because our stimuli were normalized according to their spectral power, not loudness. We exploit this physical sensitivity of the auditory system and determine the effect of this target pop-out on the neural and behavioral performances in both target and masker tasks. <xref ref-type="fig" rid="pbio-1000129-g004">Figure 4A</xref> (orange line) confirms that behavioral performance in the target task is easier for higher-frequency targets (&gt;350 Hz) than for lower frequencies (<italic>t</italic>-test; <italic>t</italic> = −3.3, <italic>p</italic> = 0.002). Correlated with this trend is an increased neural response to the target for higher frequencies compared to lower frequencies (red line) (increase not statistically significant alone). Conversely, the masker task shows a trend of being oppositely affected by the physical saliency of the target note despite its irrelevance for task performance (approaching significance; <italic>t</italic>-test, <italic>t</italic> = 1.8, <italic>p</italic> = 0.08). On the one hand, the neural power is increased for high-frequency targets reflecting their increased audibility (dark-blue line) (though not statistically significant alone). On the other hand, as the target becomes more prominent, the participants' performance of the background task deteriorates, indicating a distraction effect caused by the presence of the repeating note (light-blue line). Additionally, phase coherence is significantly enhanced for high-frequency targets over low-frequency targets only during the target task (bootstrap across participants, <italic>p</italic>&lt;10<sup>−3</sup>) (<xref ref-type="fig" rid="pbio-1000129-g004">Figure 4C</xref>). This result confirms that the physical parameters and acoustic saliency of a signal can interfere with the intended attentional spotlight of listeners and effectively deteriorate task performance <xref ref-type="bibr" rid="pbio.1000129-Gottlieb1">[46]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Naatanen2">[47]</xref>, both neurally and behaviorally.</p>
<fig id="pbio-1000129-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1000129.g004</object-id><label>Figure 4</label><caption>
<title>The effect of bottom-up acoustic saliency on behavior and neural responses.</title>
<p>(A) Normalized neural response to target rhythm, and behavioral performance, as a function of target frequency in target task (left) and masker task (right), averaged over participants. Error bars represent standard error. (B) Correlation of behavioral and neural responses as a function of target frequency. The ratio of the neural to behavioral response differences as a function of target frequency, interpreted as a slope angle, is averaged across participants yielding a mean slope angle of 55.1° for target (left) task and −36.3° for masker (right) task (yellow line). Bootstrap estimates (overlying green lines) and their 95% confidence intervals (gray background) confirm the positive (respectively, negative) correlations for target (respectively, masker) task. (C) Phase coherence between distant MEG channels of target relative to masker task for high-frequency targets over low-frequency targets. High- versus low-frequency targets show significant enhancement only for target task (indicated by the asterisk).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1000129.g004" xlink:type="simple"/></fig>
<p>In order to establish the correspondence within participants between the neural and behavioral responses under both task conditions in a parametric way, we quantified the slope (converted into an angle) relating the normalized neural signal with the listener's d-prime performance on a per-participant basis. The average slope angle for the target task is 55.1°, i.e., a positive slope, demonstrating the positive correlation between the two measures. Bootstrap analysis confirms this; <xref ref-type="fig" rid="pbio-1000129-g004">Figure 4B, left panel</xref>, illustrates both the bootstrap mean of 55.3° (green line) and the 5th to 95th percentile confidence limits (gray background), all with positive slopes. Analysis of the masker task also demonstrates the anticorrelation trend between the neural and behavioral data, with an average slope angle of −36.3° shown in yellow. The bootstrap analysis also confirms this; <xref ref-type="fig" rid="pbio-1000129-g004">Figure 4B</xref> (right panel) shows that the 5th to 95th confidence intervals (gray background) yield a robust negative slope with a bootstrap mean of −37.6° (green line).</p>
<p>The perceptual detectability of the regular target rhythm improves over time, following a pattern that is highly correlated with the neural buildup of the signal representation. Consistent with previous findings of buildup of auditory stream segregation <xref ref-type="bibr" rid="pbio.1000129-Carlyon1">[24]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Micheyl2">[35]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Anstis1">[48]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Bregman2">[49]</xref>, participants' performance during the target task improves significantly over several seconds as shown in <xref ref-type="fig" rid="pbio-1000129-g005">Figure 5A</xref> (solid orange line) (bootstrap across participants, <italic>p</italic>&lt;10<sup>–4</sup>). This similarity suggests that target detection is mediated by top-down mechanisms analogous to those employed in auditory streaming and object formation <xref ref-type="bibr" rid="pbio.1000129-Griffiths1">[50]</xref>. These streaming buildup effects tend to operate over the course of a few seconds, and cannot be explained by attentional buildup dynamics reported to be much faster or much slower in time <xref ref-type="bibr" rid="pbio.1000129-Hansen1">[51]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Donald1">[52]</xref>. Moreover, the neural response to the target rhythm also displays a statistically significant buildup (<xref ref-type="fig" rid="pbio-1000129-g005">Figure 5A</xref>, dashed red line) (bootstrap across participants, <italic>p</italic> = 0.02) closely aligned with the behavioral curve, and consequently, decoupled from the actual acoustics. The remarkable correspondence between these two measures strongly suggests that the enhanced perception of the target over time is mediated by an enhancement of the neural signal representation, itself driven by an accumulation of sensory evidence mediated by top-down mechanisms. No such neural buildup of the neural response to the target rhythm is present for the masker task.</p>
<fig id="pbio-1000129-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1000129.g005</object-id><label>Figure 5</label><caption>
<title>Buildup over time of behavioral and neural responses in target task.</title>
<p>(A) Normalized neural response to target rhythm, and behavioral performance, as a function of time in target task, averaged over participants. Error bars represent standard error. Insets: the MEG magnetic field distributions of the target rhythm response component for a single participant at representative moments in time (participant 10 from <xref ref-type="fig" rid="pbio-1000129-g002">Figure 2B</xref>). (B) Correlation of behavioral and neural responses as a function of time. The ratio of the neural to behavioral response trends as a function of time, interpreted as a slope angle, is averaged across participants, yielding a mean slope angle of 34.3° (yellow line). Bootstrap estimates (overlying green line) and the 95% confidence intervals (gray background) confirm the positive correlation between the psychometric and neurometric buildup curves.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1000129.g005" xlink:type="simple"/></fig>
<p>The MEG magnetic field distributions of the target rhythm response component in <xref ref-type="fig" rid="pbio-1000129-g005">Figure 5A</xref> (insets), showing the stereotypical pattern of neural activity originating separately in left and right auditory cortex, illustrate the changing strength of the neural activity over time in an individual participant.</p>
<p>We confirm the correlation within participants between the psychometric and neurometric curves over time by running a bootstrap analysis on a per-participant basis. As expected, the slope correlating the d-prime and neural response curves for each participant yield a mean positive slope angle of 34.3°; bootstrap across participants shows a mean of 32.7°, with the 5th to 95th confidence intervals falling within the upper-right quadrant (<xref ref-type="fig" rid="pbio-1000129-g005">Figure 5B</xref>).</p>
<p>We also note that the subsegments over which the neural buildup is measured are required to span several rhythmic periods (at least three; see <xref ref-type="fig" rid="pbio-1000129-g006">Figure 6A</xref>). There is no buildup using intervals with shorter durations, despite sufficient statistical power. (This can be shown via the data plotted in the dashed curve in <xref ref-type="fig" rid="pbio-1000129-g006">Figure 6A</xref>. The normalized responses in the range 3.5 to 4.5 are elements of an <italic>F</italic>(2,180) distribution, corresponding to <italic>p</italic>-values in the range 1.5% to 3.5%.) This implicates temporal phase coherence (in contrast to spatial phase coherence) as critical to the buildup of the neural target representation. That is, the power in each period is not increasing, but the power integrated over several periods is increasing. This can only occur if the phase variability decreases with time, i.e., the neural buildup is due to a buildup in temporal phase coherence rather than power.</p>
<fig id="pbio-1000129-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.1000129.g006</object-id><label>Figure 6</label><caption>
<title>Analysis of neural buildup over time in target task for different duration windows, both for data and in a model of the data.</title>
<p>(A) Normalized neural response to target rhythm as a function of time, in target task, averaged over participants. The solid curve is identical to the red curve in <xref ref-type="fig" rid="pbio-1000129-g005">Figure 5</xref>. The dashed curve is the result of identical analysis except that the normalized neural response is calculated for every 250-ms cycle of the target rhythm, rather than over the 750-ms window of three-cycles used above. Only the longer window shows buildup, implying that it is not power per cycle that is growing, but phase coherence over several cycles. Error bars represent standard error over all participants. (B) Model results for 750 ms (three cycles) windows, solid curve, and for 250 ms (one cycle) windows, dashed curve. The modeled normalized neural response rises as temporal phase jitter decreases, but only in the three-cycle case, since the power per cycle is constant but the temporal phase coherence across cycles increases. Error bars represent standard deviation over 30 simulation runs.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1000129.g006" xlink:type="simple"/></fig>
<p>As noted above, the subsegments, or windows, over which the neural buildup is measured are required to span at least three rhythmic periods, since there is no buildup observed using intervals with shorter durations. <xref ref-type="fig" rid="pbio-1000129-g006">Figure 6A</xref> illustrates this buildup for both the three-cycle and one-cycle cases. The requirement of a longer time window shows that the buildup is not merely due to increased power at 4 Hz, since in that case, a window of one rhythmic period would also show buildup. This in turn implies that temporal phase coherence (in contrast to spatial phase coherence) is critical to the buildup of the neural target representation.</p>
<p>This is further demonstrated by a quantitative model. Typical simulated response profiles generated by the model are shown in <xref ref-type="fig" rid="pbio-1000129-g006">Figure 6B</xref>. The horizontal axis in the model is not increasing time, but decreasing variability of the distribution of phase of the 4-Hz signal (i.e., the phase of the signal has greater variability initially and gets more regular as one proceeds along the axis). In the three-cycle window case, the buildup is pronounced, but not in the one-cycle window case. Note that the model does not attempt to emulate the downturn at the end of the experimental curve, nor does it attempt to emulate the rate at which the buildup occurs as a function of time (which would assume a linear decrease in temporal phase coherence over time).</p>
<p>The model results show that buildup can be due to increasing temporal coherence, and not due to increasing power. The neural noise, representing the stochastic firing patterns of the neurons underlying the MEG signal, is also required for the model's agreement with the data. A slight rise in the model's one-cycle window case may be seen, but it is not due to power (which never changes), rather it is due to increased coherence over trials, which is a weak side effect of increased temporal coherence.</p>
</sec><sec id="s3">
<title>Discussion</title>
<p>This study's novel experimental paradigm builds on previous work in stream segregation using simpler stimuli <xref ref-type="bibr" rid="pbio.1000129-Fishman1">[34]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Micheyl2">[35]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Gutschalk1">[53]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Snyder1">[54]</xref>, but (1) using a richer stimulus design and (2) keeping the physical parameters of the stimulus fixed while manipulating only the attentional state of the listeners. One major finding is that auditory attention strongly modulates the sustained (steady-state) neural representation of the target. Specifically, sustained attention correlates with a sustained increase in the time-varying neural signal, in contrast with onset transients <xref ref-type="bibr" rid="pbio.1000129-Tiitinen1">[22]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Naatanen3">[55]</xref> or nonspecific, constant (“DC”) <xref ref-type="bibr" rid="pbio.1000129-Picton1">[56]</xref>–<xref ref-type="bibr" rid="pbio.1000129-Hari1">[58]</xref> effects of attention on auditory signals. The location of the modulated neural representation is consistent with core auditory cortex, hence supporting current evidence implicating neuronal mechanisms of core auditory cortex in the analysis of auditory scenes <xref ref-type="bibr" rid="pbio.1000129-Micheyl2">[35]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Nelken1">[59]</xref>–<xref ref-type="bibr" rid="pbio.1000129-BidetCaulet1">[61]</xref>. Furthermore, this modulation of neural signal is significantly distant from the source of the M100 and so cannot be explained as simply a train of repeated M100 responses. This steady-state increase in the signal strength is specific to the frequency of the target rhythm, and is additionally complemented by an enhancement in coherence over distant channels, reflecting an increased synchronization between distinct underlying neural populations. This attentional effect (in both power and phase) appears exclusively at the target frequency and is absent not only from other frequency bands whose intrinsic rhythms and induced response might show attentional changes, but even from adjacent frequency bins, which argues against any theory of neural recruitment or redistribution of energy at the low-frequency spectrum. Therefore, our findings argue that processes of attention interact with the physical parameters of the stimulus, and can act exclusively to enhance particular features to be attended to in the scene, with a resolution of a fraction of a hertz. Our analysis focuses on steady-state components of feature-based analysis, hence, complementing event-based analyses that relate temporal components of the recorded potential to specific mechanisms of feature-based attention <xref ref-type="bibr" rid="pbio.1000129-Alho1">[62]</xref>–<xref ref-type="bibr" rid="pbio.1000129-Arnott1">[66]</xref>.</p>
<p>Second, the data reveal that enhanced acoustic saliency (driven by bottom-up processes), which causes an increase in perceptual detectability, also correlates with an increase in the sustained power and coherence of the neural signal. In this case, the increase in neural signal occurs regardless of the task being performed, but with different behavioral consequences: in the target task, it leads to an increase in performance, but in the masker task, a decrease (via interference). This outcome allows us to give different explanations of this “attentionally modulated” neural change: as a marker of object detectability during the first task, but as a neural correlate of perceptual interference during the second task.</p>
<p>Third, the data show a left-hemisphere bias in the cortical representation of the target, for the target task, suggesting a functional role of the left hemisphere in selective attention, consistent with previous findings in visual <xref ref-type="bibr" rid="pbio.1000129-Zani1">[67]</xref> and auditory <xref ref-type="bibr" rid="pbio.1000129-BidetCaulet1">[61]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Coch1">[68]</xref> modalities. This bias may also be due to a left-hemisphere bias specific to Heschl's gyrus (the location of core auditory cortex), for slow rhythmic tone pips (without a masker background), as seen in <xref ref-type="bibr" rid="pbio.1000129-Devlin1">[69]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Muller1">[70]</xref>. In contrast, for the masker task, the hemispheric bias in cortical representation of the (now nonattended) target is reversed to the right, and might be simply due to the nature of the attentional demands of the task (more diffuse attention to the global structure of the sound), or to the right-hemispheric bias of steady-state responses when attention is not specifically directed to the rhythm <xref ref-type="bibr" rid="pbio.1000129-Ross1">[71]</xref>. It also appears, for both tasks, that the deviant detection itself is not guiding the lateralization of the response, running counter to that of Zatorre and Belin <xref ref-type="bibr" rid="pbio.1000129-Zatorre1">[72]</xref>, since the task/deviant requiring spectral change detection shows a left-hemisphere bias, and the task/deviant requiring temporal change detection shows a right-hemisphere bias.</p>
<p>Finally, this study offers the first demonstration of the top-down–mediated buildup over time of the neural representation of a target signal that also follows the same temporal profile of the buildup based on listeners' detectability performance in the same participant. Using the current experimental paradigm, we are able to monitor the evolution in time of attentional processes as they interact with the sensory input. Many studies overlook the temporal dynamics of the neural correlates of attention, either by using cues that prime participants to the object of attention (thereby stabilizing attention before the onset of the stimulus), or by explicitly averaging out the buildup of the neural signal in their data analysis (focusing instead on the overall contribution of attention in different situations, and not monitoring the dynamics by which the process builds up). Our findings reveal that even though the sensory target signal is unchanged, attention allows its neural representation to grow over time, closely following the time course of the perceptual representation of the signal, within participants.</p>
<p>Together, these findings support a view of a tightly coupled interaction between the lower-level neural representation and the higher-level cognitive representation of auditory objects, in a clear demonstration of auditory scene segregation: the cocktail party effect <xref ref-type="bibr" rid="pbio.1000129-Cherry1">[73]</xref>. Our experimental paradigm allows both task-driven (top-down) and stimulus-driven (bottom-up) processes to guide perception. For listeners performing the target task, the target rhythm is the attended auditory object, a foreground stream to be separated from a noisy background. The masker task, requiring the listener to reverse the role of the foreground and background, allows the contrasting situation to be considered under otherwise identical acoustical conditions. This permits a controlled de-emphasis of the auditory role of the target rhythm, without the need for a “passive” listening condition under which the amount of the listener's attention is lessened, but actually unknown, and strongly variable across participants.</p>
<p>The data suggest that new models of attention may be required, based on temporally coherent or locally synchronous neural activity rather than neural amplification <xref ref-type="bibr" rid="pbio.1000129-Niebur1">[74]</xref>. The buildup of neural responses over time is seen only when integrated over several periods of the target rhythm, but not for individual periods. This result is difficult to explain using standard models of attention that rely solely on gain-based changes, or even on gain/spectral-sensitivity hybrid models <xref ref-type="bibr" rid="pbio.1000129-Kauramaki1">[75]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Okamoto1">[76]</xref>. Instead, a more plausible theory of neural mechanisms underlying the role of top-down attention in the buildup of perceptual streams would involve top-down projections acting in conjunction with the physical stimulus as regulators or clocks for the firing patterns of neuronal populations in auditory cortex. Another conceivable mechanism for this increase in temporal coherence may arise from general sharpening of temporal tuning, which would work for auditory streams far more complex than the regular stream presented here. The neural underpinnings of this bottom-up/top-down interaction are likely to mediate changes in the response profiles of cortical neurons, via mechanisms of synaptic and receptive field plasticity which have been shown to be gated by attention; whereby attention plays a crucial role in shifting cortical circuits from one state to another depending on behavioral demands <xref ref-type="bibr" rid="pbio.1000129-Fritz2">[77]</xref>–<xref ref-type="bibr" rid="pbio.1000129-Atiani1">[80]</xref>. We speculate that temporal patterns of neuronal firings are crucial in any scene segregation task to resolve the competition between attended and unattended objects, hence, delimiting the cognitive border between different streams.</p>
<p>Overall, a significant outcome of this study is that it not only demonstrates a strong coupling between the measured neural representation of a signal and its perceptual manifestation, but also places the source of this coupling at the level of sensory cortex. As such, the neural representation of the percept is encoded using the feature-driven mechanisms of sensory cortex, but shaped in a sustained manner via attention-driven projections from higher-level areas. Such a framework may underlie general mechanisms of “scene” organization in any sensory modality.</p>
</sec><sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Participants</title>
<p>Nine participants (six males; mean age 29 y, range 24–38 y) participated in the psychoacoustic study. Eighteen participants (11 males; mean age 27 y, range 21–49 y) participated in the MEG study. Three participants took part in both studies. Among the 18 participants in the MEG study, four participants were excluded from further analysis due to an excess of nonneural electrical artifacts or an inability to perform the tasks, leaving 14 participants (eight males; mean age 27 y, range 21–49 y). All participants were right handed <xref ref-type="bibr" rid="pbio.1000129-Oldfield1">[81]</xref>, had normal hearing, and had no history of neurological disorder. The experiments were approved by the University of Maryland Institutional Review Board, and written informed consent was obtained from each participant. Participants were paid for their participation.</p>
</sec><sec id="s4b">
<title>Stimulus Design</title>
<p>The stimuli were generated using MATLAB (MathWorks). Each trial was 5.5 s in duration with 8-kHz sampling. Every trial contained one target note, repeating at 4 Hz, whose frequency was randomly chosen in the range 250–500 Hz in two semitone intervals. The background consisted of random tones at a density of 50 tones/s, uniformly distributed over time and log-frequency (except for the spectral protection region). The frequencies of the random notes were randomly chosen from the five-octave range centered at 353 Hz, in two semitone intervals, with the constraint that no masker components were permitted within a four, or eight, or 12 semitone around the target frequency (the spectral protection region half-width). This random sampling of masker frequencies ensures a minimum spectral distance of two semitones between maskers, and keeps the probability of harmonically related maskers minimal. Masker and target tones were 75 ms in duration with 10-ms onset and offset cosine ramps. All masker tones were presented at the same intensity as the target tone.</p>
<p>Fifteen exemplar stimuli were generated for each of the four condition types: null condition (no deviants); target condition (one target deviant per stimulus); masker condition (one masker deviant per stimulus); and combined condition (one target deviant and one masker deviant, at independent times, per stimulus). Each target deviant was the displacement of a target note (upward or downward) by two semitones from the target frequency. Each masker deviant was a single 500-ms time window in which all masker tones were elongated from 75 ms to 400 ms. The temporal location of the deviant (for both target and masker tasks) was randomly distributed along the 5.5-s trial duration, with timing as indicated by the behavioral buildup curve in <xref ref-type="fig" rid="pbio-1000129-g004">Figure 4</xref>.</p>
</sec><sec id="s4c">
<title>Experimental Procedure</title>
<p>In the psychoacoustic experiment, participants were presented with 180 stimuli (three protection regions×four conditions×15 exemplars) per task. The progression from one trial to the next was initiated by the participant with a button-press.</p>
<p>In the MEG experiment, only the eight-semitone spectral protection region half-width was used, giving 60 stimuli (1 protection region × 4 conditions × 15 exemplars) per task. The interstimulus intervals (ISIs) were randomly chosen to be 1,800, 1,900, or 2,000 ms. For each task, the participants were presented with three blocks, repeating the ensemble of 60 stimuli three times (totaling 180 stimuli). Participants were allowed to rest after each block, but were required to stay still.</p>
<p>The identical stimulus ensemble (including identical ISIs in the MEG case) was presented for both target and masker tasks. Depending on the task being performed, participants were instructed to listen for the presence of a frequency deviant in the target rhythm (target task) or a duration deviant in the masker (masker task); each task deviant was present in exactly half the trials.</p>
<sec id="s4c1">
<title>Psychoacoustical study</title>
<p>Participants were seated at a computer in a soundproof room. The signals were created offline and presented diotically through Sony MDR-V700 headphones. Participants controlled the computer using a Graphical User Interface (GUI) using the mouse. The task, as well as the basic use of the GUI, was described to participants. Participants were allowed to adjust the volume to a comfortable level before proceeding with the experiment.</p>
<p>A training block of 20 trials was presented before each task. In the target task training, the protection region half-width decreased from 12 semitones to four semitones in steps of four semitones. In the masker task training, it increased from four semitones to 12 semitones in steps of four semitones. Participants were permitted to listen to each sound as many times as desired; then participants were prompted to indicate whether a deviant was present. The correct answer was displayed afterwards. Participants pressed a button to initiate the presentation of the next stimulus.</p>
<p>Each participant performed both the masker task and the target task, with task order counterbalanced across participants. Each task required the participant to listen to the entire set of 180 stimuli described above. Each stimulus was presented only once, and no feedback was given after each trial. The entire session of both tasks lasted approximately 1.5 h.</p>
</sec><sec id="s4c2">
<title>MEG study</title>
<p>Participants were placed horizontally in a dimly lit magnetically shielded room (Yokogawa Electric Corporation). Stimuli were presented using Presentation software (Neurobehavioral Systems). The signals were delivered to the participants' ears with 50-Ω sound tubing (E-A-RTONE 3A; Etymotic Research), attached to E-A-RLINK foam plugs inserted into the ear canal, and presented at a comfortable loudness of approximately 70 dB SPL. The entire acoustic delivery system is equalized to give an approximately flat transfer function from 40–3,000 Hz.</p>
<p>Before the main experiment, a pre-experiment was run in which a 1-kHz, 50-ms tone pip was presented about 200 times. The ISI was randomized between 750 ms and 1,550 ms, and participants were instructed to count the tone pips. The aim of this task was to record the M100 response (a prominent peak approximately 100 ms after pip onset, also called N1m) used for differential source localization. The responses were checked to verify that the location and strength of neural signals fell within a normal range.</p>
<p>In the main experiment, participants were presented with three blocks of the 60 stimuli described above. Each participant performed both the masker task and the target task, with task order counterbalanced across participants. Participants were instructed to press a button held in the right hand as soon as they heard the appropriate deviant.</p>
<p>A training block with 12 sounds was presented before each task. Each training sound was presented twice. Participants verbally indicated the existence of the deviants and the feedback was given by the investigator. The entire session of both tasks lasted approximately 1 h.</p>
<p>MEG recordings were conducted using a 160-channel whole-head system (Kanazawa Institute of Technology). Its detection coils are arranged in a uniform array on a helmet-shaped surface on the bottom of the dewar, with about 25 mm between the centers of two adjacent 15.5-mm-diameter coils. Sensors are configured as first-order axial gradiometers with a baseline of 50 mm; their field sensitivities are 5 fT/√Hz or better in the white noise region. Three of the 160 channels are magnetometers separated from the others and used as reference channels in noise-filtering methods. The magnetic signals were bandpassed between 1 Hz and 200 Hz, notch filtered at 60 Hz, and sampled at the rate of <italic>f<sub>s</sub></italic> = 1,000 Hz. All neural channels were denoised twice with a block least mean square (LMS) adaptive filter, first, using the three external reference channels <xref ref-type="bibr" rid="pbio.1000129-Ahmar1">[41]</xref>, and second, using the two channels with the strongest cardiac artifacts <xref ref-type="bibr" rid="pbio.1000129-Xiang1">[82]</xref>.</p>
</sec></sec><sec id="s4d">
<title>Data Analysis</title>
<sec id="s4d1">
<title>Behavioral performance analysis</title>
<p>The ability of participants to perform the requested task was assessed by calculating a d-prime measure of performance <xref ref-type="bibr" rid="pbio.1000129-Kay1">[83]</xref>. For each condition (i.e., each task and protection region), we estimated the correct detection and false alarm probabilities for detecting the target or masker deviants; converted them to normal deviates (<italic>z</italic>-scores), and computed the d-prime value. The performance shown in <xref ref-type="fig" rid="pbio-1000129-g001">Figure 1</xref> depicts the mean d-prime values across participants. The error bars represent the standard error of mean.</p>
<p>To determine the effect of the target's tonal frequency on the neural responses, the stimuli were divided spectrally: each sound was characterized as a low- or high-frequency target tone sequence depending on the target tone's relation to the middle frequency 353 Hz (those with target tone frequency of 353 Hz were randomly assigned as low or high in such a way as to equipartition the high and low categories). A d-prime measure was then derived for each of the low or high target trials from both target and masker tasks.</p>
<p>To investigate the buildup of the target object during the target task, we divided the deviant trials according to the nine possible temporal locations of the deviant throughout the stimulus sequence. A probability of hit was then measured for each trial. Because of the temporal uncertainty in the false alarm trials, we calculated an average false alarm rate (irrespective of when the false response was issued), and combined it with the time-specific hit rate to derive a d-prime measure for each time segment. Using this behavioral assessment measure, five participants yielded nonpositive d-prime values due to their high false alarm rate and low hit rate, and were excluded from the analysis of buildup.</p>
</sec><sec id="s4d2">
<title>Neural data analysis</title>
<p>After recordings were completed and noise reduction algorithms applied, the responses to each stimulus, from 1.25 s to 5.5 s poststimulus, were extracted and concatenated, forming a single extended response with duration <italic>T</italic> = 765 s (4.25 s×60 sounds×three blocks) for each channel. This was done separately for each task block. The discrete Fourier transform (DFT) was applied on the single response, giving a single Fourier response from 0 to 500 Hz with frequency resolution of 1/765 Hz.</p>
<p>The evoked neural responses to the target sequences were characterized by the magnitude and phase of the frequency component at 4 Hz (the tone presentation rate) and were used for localization and for phasor maps. The complex magnetic field strength is given by the product of the value of DFT times the sampling interval (1/<italic>f<sub>s</sub></italic>), and has units of fT/Hz. Power spectral density is calculated as the product of the inverse duration (1/<italic>T</italic>) times the modulus squared of the complex magnetic field strength, and has units of fT<sup>2</sup>/Hz. The remainder of the analysis was based on the normalized neural responses, defined to be the squared magnitude of the frequency component at 4 Hz divided by the average squared magnitude of the frequency components between 3 Hz and 5 Hz (excluding the component at 4 Hz), averaged over the 20 channels with the strongest normalized neural responses for each participant. The channels were allowed to vary from participant to participant to allow for inter-participant configuration variability. Using 10, 20, or 50 channels yielded similar findings; however, only the 20 channel analysis is reported here, indicating that this method is robust against the particular subset of channels used. This normalization is not biased by the task, since the average squared magnitude of the frequency components between 3 Hz and 5 Hz did not significantly differ between tasks.</p>
<p>The spatial pattern of the neural responses was represented by a phasor map, a graph of the complex (magnitude and phase) magnetic field on all channels. For each channel, the length of the vector arrow is proportional to the magnitude of the 4-Hz frequency component, and the direction of the arrow represents the phase according to standard polar coordinates. Red and green contours represent the magnetic field strength projected onto the line of constant phase that maximizes the projected field's variance <xref ref-type="bibr" rid="pbio.1000129-Simon1">[43]</xref>. The phasors are visually faded using the signal-to-noise ratio (SNR) of each channel as linear fading coefficients.</p>
<p>The normalized neural responses difference between target task and masker task was averaged across 14 participants to characterize attention gain effect. Furthermore, to evaluate the effect of attention at across frequencies, the same analysis is done at 4 Hz and the two adjacent frequency bins (4 Hz−Δ<italic>f</italic> and 4 Hz+Δ<italic>f</italic>), and also at 11 frequencies in the alpha, theta, and low gamma frequency bands, in approximately 5-Hz increments from approximately 5 Hz to approximately 55 Hz. For consistency with the frequencies examined in tests of phase coherence (next), we used Δ<italic>f</italic> = 1/(4.25) Hz, with analysis performed only at its integer multiples (e.g., 17Δ<italic>f</italic> = 4.0 Hz and 21Δ<italic>f</italic>≈4.94 Hz). The normalization is only weakly affected by the task, since the average squared magnitude of the frequency components did not vary strongly by task (no difference below 5 Hz, a relative enhancement in the target task of approximately 1 dB from 5 to 25 Hz, and a relative enhancement for the masker task of approximately 1 dB from 25 to 50 Hz).</p>
<p>To study attention modulation effects on the synchronization between two distinct neural populations, phase coherence between channels <italic>m</italic> and <italic>n</italic>, γ<sup>2</sup><italic><sub>mn</sub></italic>, is obtained from <italic>Q = </italic>180 trials <xref ref-type="bibr" rid="pbio.1000129-Bendat1">[84]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Srinivasan1">[85]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1000129.e001" xlink:type="simple"/></disp-formula>where <italic>X<sub>mn</sub></italic>(<italic>f</italic>) is the average cross spectrum between channel <italic>m</italic> and channel <italic>n</italic>, <italic>X<sub>mm</sub></italic>(<italic>f</italic>) is average power spectrum of the individual channel <italic>m</italic>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1000129.e002" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1000129.e003" xlink:type="simple"/></inline-formula> is the Fourier transform of the <italic>q</italic>th trial of channel <italic>m</italic> at frequency <italic>f</italic>. A coherence value of one indicates that the two channels maintain the same phase difference on every trial, whereas a coherence value near zero indicates a random phase difference across trials. The coherence difference between target task and masker task was computed for every channel pair. The standard error of the mean (SEM) ε<italic><sub>mn</sub></italic> was constructed to identify robust coherence change <xref ref-type="bibr" rid="pbio.1000129-Bendat1">[84]</xref>,<xref ref-type="bibr" rid="pbio.1000129-Srinivasan1">[85]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1000129.e004" xlink:type="simple"/></disp-formula></p>
<p>To emphasis phase modulation in auditory cortex, each participant's 20 channels with the strongest normalized neural response at target rate were included in further analysis. In addition, to exclude the artificial coherence that resulted from volume conduction effects on extracranial magnetic field and measure genuine phase correlation between distinct populations of neurons, only long-distance channel pairs (channel separation &gt;100 mm) were included <xref ref-type="bibr" rid="pbio.1000129-Srinivasan1">[85]</xref>. The difference between number of channel pairs with robust increased coherence and channel pairs with decreased coherence is normalized over the total number of long-range channel pairs for each participant. Furthermore, to evaluate the effect of attention at across frequencies, the same analysis is done at 4 Hz and the two adjacent frequency bins (4 Hz−Δ<italic>f</italic> and 4 Hz+Δ<italic>f</italic>), and also at 11 frequencies in the alpha, theta, and low gamma frequency bands, in approximately 5 Hz increments from approximately 5 Hz to approximately 55 Hz. For phase coherence (measured across trials), Δ<italic>f</italic> = 1/(4.25) Hz, and phase coherence was analyzed only at its integer multiples (e.g., 17Δ<italic>f</italic> = 4.0 Hz and 21Δ<italic>f</italic>≈4.94 Hz).</p>
<p>To investigate the possibility of hemispheric bias, the 20 channels with the strongest normalized neural response at the target rate were chosen from left and right hemispheres, respectively, to represent the overall neural activity of each hemisphere. Neural responses averaged across the 20 channels were subtracted across hemispheres for each task and for all 14 participants. Using 10, 20, or 60 channels yielded similar findings; however, only the 20-channel analysis is reported here.</p>
<p>To determine the effect of the tonal frequency on the neural responses, the stimuli were divided spectrally as described above. The neural responses at the target rate (both normalized response and phase coherence), from low- and high-frequency target tone stimuli, were obtained for each participant in the same way as described above, but with only appropriate epochs concatenated or phase-averaged.</p>
<p>To investigate the buildup of the target object in target task, the responses were divided temporally: the analysis epochs were divided into five temporal segments of 750-ms duration each, e.g., from 1.25 s to 2 s poststimulus (or 2 s to 2.75 s, etc.), were extracted and concatenated, forming a single extended response with duration <italic>T</italic> = 135 s (0.75 s × 60 sounds × 3 blocks) for each channel. The discrete Fourier transform (DFT) was applied on the single response, giving a single Fourier response of from 0 to 500 Hz with frequency resolution 1/135 Hz. The first segment began at 1,250-ms poststimulus since earlier time intervals showed substantial power at the frequency corresponding to the segment duration, an artifact indicating that the measured spectral power was extrinsic to the analysis window, not intrinsic to the neural signal. The segment duration of 750 ms was used since shorter durations did not show the buildup effect, an effect that is elaborated upon in the discussion of the quantitative model of neural buildup. An analogous analysis of phase coherence buildup over time was performed but did not yield significant results.</p>
</sec><sec id="s4d3">
<title>Behavioral versus neural correlation and bootstrap analysis</title>
<p>We correlated the effect of high versus low target frequencies in the behavioral and neural responses by contrasting the per-participant psychometric and neurometric measures. First, we scaled the neural data (i.e., the normalized responses to target) by a factor of three in order to match the absolute ranges of both neural and behavioral values. We then derived the angle (i.e., inverse tangent) of the slope relating the high versus low frequencies of the behavioral and neural data points for each participant and each task. The across-participant slopes were then combined using circular statistics to yield an angular mean for each task <xref ref-type="bibr" rid="pbio.1000129-Fisher1">[86]</xref>.</p>
<p>We performed a bootstrap procedure in order to confirm the positive (respectively, negative) correlation between the neurometric and psychometric functions in the target (respectively, masker) task. We followed a balanced bootstrap sampling procedure <xref ref-type="bibr" rid="pbio.1000129-Efron1">[87]</xref> by randomly selecting 14 participants with replacement and computing their angular sample mean and repeating this process 1,000 times. The procedure was controlled to ensure that all participants appeared the same number of times over all 1,000 bootstrap samplings. Confidence measures were then derived from the bootstrap statistics.</p>
<p>A similar statistical analysis was performed to correlate the psychometric and neurometric curves for the target detection buildup. To match the range of values from the neural and behavioral data, we scaled the neural responses by a factor of two (note that the different scaling is due to the reduced values of the normalized neural response due to the smaller window for the buildup analysis). The behavioral curves for each participant were then interpolated to match the sampling rate of the neural data. Subsequently, these two curves were then fitted by a first-order polynomial to derive the slope relating the two functions. The slope value was transformed into an angle and then combined across participants, following the same procedure described above. Note that the five participants with negative d-prime values were excluded from this correlation analysis, because of their questionable behavioral performance.</p>
</sec><sec id="s4d4">
<title>Neural source localization</title>
<p>Source localization for the M100 response was obtained by calculating the current-equivalent dipole best fitting the magnetic field configuration at the M100 peak, in each hemisphere. Source localization for the neural response to the target was obtained by calculating the complex current-equivalent dipole best fitting the complex magnetic field configuration at 4-Hz peak, in each hemisphere <xref ref-type="bibr" rid="pbio.1000129-Simon1">[43]</xref>. Only channels with SNR &gt;4 were used in the fitting. Goodness of fit, as a function of the complex current-equivalent dipole, is given by one minus the residual variance ratio. As discussed in <xref ref-type="bibr" rid="pbio.1000129-Simon1">[43]</xref>, the goodness of fit for complex magnetic field distributions and complex dipoles gives typical values that are much lower than for comparable real distributions, due to the doubling of number of degrees of freedom absorbing noise power. Significance of the relative displacement between the M100 and 4-Hz dipole sources were determined by a two-tailed paired <italic>t</italic>-test in each of three dimensions: lateral/medial, anterior/posterior, and superior/inferior.</p>
</sec></sec><sec id="s4e">
<title>Quantitative Model of Neural Buildup</title>
<p>A model simulation to illustrate a mechanism of neural buildup was implemented in MATLAB (MathWorks). The model simulates MEG responses by generating 4-Hz signals whose phase is a random variable with constant mean, additionally corrupted by additive Gaussian white noise. This noise represents neural variability inherent in the neural processing mechanisms underlying the MEG signal and is critical to the model (external magnetic field noise had already been removed from the data by active filtering <xref ref-type="bibr" rid="pbio.1000129-Ahmar1">[41]</xref> and is not modeled). The normalized response power was calculated by the same method as in the experiment: concatenating 50 signals and normalizing the power at 4 Hz by the average power in the 3–5 Hz band, averaging the 20 best channels (out of 100 simulated auditory channels), and then averaging that over simulation runs. This was done for five different distributions of the phase random variable with standard deviations ranging from 1/60 to 1/12 of a cycle.</p>
<p>The model's level of Gaussian white noise was obtained by the biological requirement that the model's normalized response for the three-cycle window, with highest jitter, match the data's; the buildup rate as a function of decreased variability, as well as the average level of the normalized response for the one-cycle window, follow automatically. The simulated response results depend weakly on the number of channels simulated. The experimental MEG system records from 157 channels, but not all are strongly auditory. The results shown here use 100 simulated auditory channels.</p>
</sec></sec></body>
<back>
<ack>
<p>We thank Jonathan Fritz and David Poeppel for comments and discussion. We are grateful to Jeff Walker for excellent technical support.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pbio.1000129-Posner1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Posner</surname><given-names>MI</given-names></name>
<name name-style="western"><surname>Petersen</surname><given-names>SE</given-names></name>
</person-group>             <year>1990</year>             <article-title>The attention system of the human brain.</article-title>             <source>Annu Rev Neurosci</source>             <volume>13</volume>             <fpage>25</fpage>             <lpage>42</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Desimone1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Desimone</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Duncan</surname><given-names>J</given-names></name>
</person-group>             <year>1995</year>             <article-title>Neural mechanisms of selective visual attention.</article-title>             <source>Annu Rev Neurosci</source>             <volume>18</volume>             <fpage>193</fpage>             <lpage>222</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Gilbert1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gilbert</surname><given-names>CD</given-names></name>
<name name-style="western"><surname>Sigman</surname><given-names>M</given-names></name>
</person-group>             <year>2007</year>             <article-title>Brain states: top-down influences in sensory processing.</article-title>             <source>Neuron</source>             <volume>54</volume>             <fpage>677</fpage>             <lpage>696</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Knudsen1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Knudsen</surname><given-names>EI</given-names></name>
</person-group>             <year>2007</year>             <article-title>Fundamental components of attention.</article-title>             <source>Annu Rev Neurosci</source>             <volume>30</volume>             <fpage>57</fpage>             <lpage>78</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Fritz1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fritz</surname><given-names>JB</given-names></name>
<name name-style="western"><surname>Elhilali</surname><given-names>M</given-names></name>
<name name-style="western"><surname>David</surname><given-names>SV</given-names></name>
<name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name>
</person-group>             <year>2007</year>             <article-title>Auditory attention–focusing the searchlight on sound.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>17</volume>             <fpage>437</fpage>             <lpage>455</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Craft1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Craft</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Schutze</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Niebur</surname><given-names>E</given-names></name>
<name name-style="western"><surname>von der Heydt</surname><given-names>R</given-names></name>
</person-group>             <year>2007</year>             <article-title>A neural model of figure-ground organization.</article-title>             <source>J Neurophysiol</source>             <volume>97</volume>             <fpage>4310</fpage>             <lpage>4326</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Lamme1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lamme</surname><given-names>VA</given-names></name>
</person-group>             <year>1995</year>             <article-title>The neurophysiology of figure-ground segregation in primary visual cortex.</article-title>             <source>J Neurosci</source>             <volume>15</volume>             <fpage>1605</fpage>             <lpage>1615</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Martinez1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Martinez</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Anllo-Vento</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Sereno</surname><given-names>MI</given-names></name>
<name name-style="western"><surname>Frank</surname><given-names>LR</given-names></name>
<name name-style="western"><surname>Buxton</surname><given-names>RB</given-names></name>
<etal/></person-group>             <year>1999</year>             <article-title>Involvement of striate and extrastriate visual cortical areas in spatial attention.</article-title>             <source>Nat Neurosci</source>             <volume>2</volume>             <fpage>364</fpage>             <lpage>369</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Reynolds1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reynolds</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Chelazzi</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Desimone</surname><given-names>R</given-names></name>
</person-group>             <year>1999</year>             <article-title>Competitive mechanisms subserve attention in macaque areas V2 and V4.</article-title>             <source>J Neurosci</source>             <volume>19</volume>             <fpage>1736</fpage>             <lpage>1753</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Ghose1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ghose</surname><given-names>GM</given-names></name>
<name name-style="western"><surname>Maunsell</surname><given-names>JH</given-names></name>
</person-group>             <year>2002</year>             <article-title>Attentional modulation in visual cortex depends on task timing.</article-title>             <source>Nature</source>             <volume>419</volume>             <fpage>616</fpage>             <lpage>620</lpage>          </element-citation></ref>
<ref id="pbio.1000129-MartinezTrujillo1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Martinez-Trujillo</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Treue</surname><given-names>S</given-names></name>
</person-group>             <year>2002</year>             <article-title>Attentional modulation strength in cortical area MT depends on stimulus contrast.</article-title>             <source>Neuron</source>             <volume>35</volume>             <fpage>365</fpage>             <lpage>370</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Delorme1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Delorme</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Rousselet</surname><given-names>GA</given-names></name>
<name name-style="western"><surname>Mace</surname><given-names>MJ</given-names></name>
<name name-style="western"><surname>Fabre-Thorpe</surname><given-names>M</given-names></name>
</person-group>             <year>2004</year>             <article-title>Interaction of top-down and bottom-up processing in the fast visual analysis of natural scenes.</article-title>             <source>Brain Res Cogn Brain Res</source>             <volume>19</volume>             <fpage>103</fpage>             <lpage>113</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Gazzaley1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gazzaley</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Cooney</surname><given-names>JW</given-names></name>
<name name-style="western"><surname>McEvoy</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Knight</surname><given-names>RT</given-names></name>
<name name-style="western"><surname>D'Esposito</surname><given-names>M</given-names></name>
</person-group>             <year>2005</year>             <article-title>Top-down enhancement and suppression of the magnitude and speed of neural activity.</article-title>             <source>J Cogn Neurosci</source>             <volume>17</volume>             <fpage>507</fpage>             <lpage>517</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Li1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Li</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Piech</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Gilbert</surname><given-names>CD</given-names></name>
</person-group>             <year>2004</year>             <article-title>Perceptual learning and top-down influences in primary visual cortex.</article-title>             <source>Nat Neurosci</source>             <volume>7</volume>             <fpage>651</fpage>             <lpage>657</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Buschman1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Buschman</surname><given-names>TJ</given-names></name>
<name name-style="western"><surname>Miller</surname><given-names>EK</given-names></name>
</person-group>             <year>2007</year>             <article-title>Top-down versus bottom-up control of attention in the prefrontal and posterior parietal cortices.</article-title>             <source>Science</source>             <volume>315</volume>             <fpage>1860</fpage>             <lpage>1862</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Qiu1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Qiu</surname><given-names>FT</given-names></name>
<name name-style="western"><surname>Sugihara</surname><given-names>T</given-names></name>
<name name-style="western"><surname>von der Heydt</surname><given-names>R</given-names></name>
</person-group>             <year>2007</year>             <article-title>Figure-ground mechanisms provide structure for selective attention.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <fpage>1492</fpage>             <lpage>1499</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Roelfsema1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Roelfsema</surname><given-names>PR</given-names></name>
<name name-style="western"><surname>Tolboom</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Khayat</surname><given-names>PS</given-names></name>
</person-group>             <year>2007</year>             <article-title>Different processing phases for features, figures, and selective attention in the primary visual cortex.</article-title>             <source>Neuron</source>             <volume>56</volume>             <fpage>785</fpage>             <lpage>792</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Saalmann1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Saalmann</surname><given-names>YB</given-names></name>
<name name-style="western"><surname>Pigarev</surname><given-names>IN</given-names></name>
<name name-style="western"><surname>Vidyasagar</surname><given-names>TR</given-names></name>
</person-group>             <year>2007</year>             <article-title>Neural mechanisms of visual attention: how top-down feedback highlights relevant locations.</article-title>             <source>Science</source>             <volume>316</volume>             <fpage>1612</fpage>             <lpage>1615</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Neri1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Neri</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Levi</surname><given-names>DM</given-names></name>
</person-group>             <year>2007</year>             <article-title>Temporal dynamics of figure-ground segregation in human vision.</article-title>             <source>J Neurophysiol</source>             <volume>97</volume>             <fpage>951</fpage>             <lpage>957</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Hubel1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hubel</surname><given-names>DH</given-names></name>
<name name-style="western"><surname>Henson</surname><given-names>CO</given-names></name>
<name name-style="western"><surname>Rupert</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Galambos</surname><given-names>R</given-names></name>
</person-group>             <year>1959</year>             <article-title>Attention units in the auditory cortex.</article-title>             <source>Science</source>             <volume>129</volume>             <fpage>1279</fpage>             <lpage>1280</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Hillyard1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hillyard</surname><given-names>SA</given-names></name>
<name name-style="western"><surname>Hink</surname><given-names>RF</given-names></name>
<name name-style="western"><surname>Schwent</surname><given-names>VL</given-names></name>
<name name-style="western"><surname>Picton</surname><given-names>TW</given-names></name>
</person-group>             <year>1973</year>             <article-title>Electrical signs of selective attention in the human brain.</article-title>             <source>Science</source>             <volume>182</volume>             <fpage>177</fpage>             <lpage>180</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Tiitinen1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tiitinen</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Sinkkonen</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Reinikainen</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Alho</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Lavikainen</surname><given-names>J</given-names></name>
<etal/></person-group>             <year>1993</year>             <article-title>Selective attention enhances the auditory 40-Hz transient response in humans.</article-title>             <source>Nature</source>             <volume>364</volume>             <fpage>59</fpage>             <lpage>60</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Woldorff1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Woldorff</surname><given-names>MG</given-names></name>
<name name-style="western"><surname>Gallen</surname><given-names>CC</given-names></name>
<name name-style="western"><surname>Hampson</surname><given-names>SA</given-names></name>
<name name-style="western"><surname>Hillyard</surname><given-names>SA</given-names></name>
<name name-style="western"><surname>Pantev</surname><given-names>C</given-names></name>
<etal/></person-group>             <year>1993</year>             <article-title>Modulation of early sensory processing in human auditory cortex during auditory selective attention.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>90</volume>             <fpage>8722</fpage>             <lpage>8726</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Carlyon1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Carlyon</surname><given-names>RP</given-names></name>
<name name-style="western"><surname>Cusack</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Foxton</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Robertson</surname><given-names>IH</given-names></name>
</person-group>             <year>2001</year>             <article-title>Effects of attention and unilateral neglect on auditory stream segregation.</article-title>             <source>J Exp Psychol Hum Percept Perform</source>             <volume>27</volume>             <fpage>115</fpage>             <lpage>127</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Sussman1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sussman</surname><given-names>ES</given-names></name>
</person-group>             <year>2005</year>             <article-title>Integration and segregation in auditory scene analysis.</article-title>             <source>J Acoust Soc Am</source>             <volume>117</volume>             <fpage>1285</fpage>             <lpage>1298</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Brechmann1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Brechmann</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Scheich</surname><given-names>H</given-names></name>
</person-group>             <year>2005</year>             <article-title>Hemispheric shifts of sound representation in auditory cortex with conceptual listening.</article-title>             <source>Cereb Cortex</source>             <volume>15</volume>             <fpage>578</fpage>             <lpage>587</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Alain1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Alain</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Woods</surname><given-names>DL</given-names></name>
</person-group>             <year>1993</year>             <article-title>Distractor clustering enhances detection speed and accuracy during selective listening.</article-title>             <source>Percept Psychophys</source>             <volume>54</volume>             <fpage>509</fpage>             <lpage>514</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Alain2"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Alain</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Woods</surname><given-names>DL</given-names></name>
</person-group>             <year>1994</year>             <article-title>Signal clustering modulates auditory cortical activity in humans.</article-title>             <source>Percept Psychophys</source>             <volume>56</volume>             <fpage>501</fpage>             <lpage>516</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Carlyon2"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Carlyon</surname><given-names>RP</given-names></name>
</person-group>             <year>2004</year>             <article-title>How the brain separates sounds.</article-title>             <source>Trends Cogn Sci</source>             <volume>8</volume>             <fpage>465</fpage>             <lpage>471</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Bregman1"><label>30</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bregman</surname><given-names>AS</given-names></name>
</person-group>             <year>1990</year>             <source>Auditory scene analysis: the perceptual organization of sound</source>             <publisher-loc>Cambridge (Massachusetts)</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">773</size>          </element-citation></ref>
<ref id="pbio.1000129-Kidd1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kidd</surname><given-names>G</given-names><suffix>Jr</suffix></name>
<name name-style="western"><surname>Mason</surname><given-names>CR</given-names></name>
<name name-style="western"><surname>Deliwala</surname><given-names>PS</given-names></name>
<name name-style="western"><surname>Woods</surname><given-names>WS</given-names></name>
<name name-style="western"><surname>Colburn</surname><given-names>HS</given-names></name>
</person-group>             <year>1994</year>             <article-title>Reducing informational masking by sound segregation.</article-title>             <source>J Acoust Soc Am</source>             <volume>95</volume>             <fpage>3475</fpage>             <lpage>3480</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Micheyl1"><label>32</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Micheyl</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name>
<name name-style="western"><surname>Oxenham</surname><given-names>AJ</given-names></name>
</person-group>             <year>2007</year>             <article-title>Hearing out repeating elements in randomly varying multitone sequences: a case of streaming?</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Kollmeier</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Klump</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Hohmann</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Langemann</surname><given-names>U</given-names></name>
<name name-style="western"><surname>Mauermann</surname><given-names>M</given-names></name>
<etal/></person-group>             <source>Hearing: from sensory processing to perception</source>             <publisher-loc>Berlin (Germany)</publisher-loc>             <publisher-name>Springer Verlag</publisher-name>             <fpage>267</fpage>             <lpage>274</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Sheft1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sheft</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Yost</surname><given-names>WA</given-names></name>
</person-group>             <year>2008</year>             <article-title>Method-of-adjustment measures of informational masking between auditory streams.</article-title>             <source>J Acoust Soc Am</source>             <volume>124</volume>             <fpage>EL1</fpage>             <lpage>7</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Fishman1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fishman</surname><given-names>YI</given-names></name>
<name name-style="western"><surname>Reser</surname><given-names>DH</given-names></name>
<name name-style="western"><surname>Arezzo</surname><given-names>JC</given-names></name>
<name name-style="western"><surname>Steinschneider</surname><given-names>M</given-names></name>
</person-group>             <year>2001</year>             <article-title>Neural correlates of auditory stream segregation in primary auditory cortex of the awake monkey.</article-title>             <source>Hear Res</source>             <volume>151</volume>             <fpage>167</fpage>             <lpage>187</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Micheyl2"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Micheyl</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Tian</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Carlyon</surname><given-names>RP</given-names></name>
<name name-style="western"><surname>Rauschecker</surname><given-names>JP</given-names></name>
</person-group>             <year>2005</year>             <article-title>Perceptual organization of tone sequences in the auditory cortex of awake macaques.</article-title>             <source>Neuron</source>             <volume>48</volume>             <fpage>139</fpage>             <lpage>148</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Fishman2"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fishman</surname><given-names>YI</given-names></name>
<name name-style="western"><surname>Steinschneider</surname><given-names>M</given-names></name>
</person-group>             <year>2006</year>             <article-title>Spectral resolution of monkey primary auditory cortex (A1) revealed with two-noise masking.</article-title>             <source>J Neurophysiol</source>             <volume>96</volume>             <fpage>1105</fpage>             <lpage>1115</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Miller1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Miller</surname><given-names>LM</given-names></name>
<name name-style="western"><surname>Escabi</surname><given-names>MA</given-names></name>
<name name-style="western"><surname>Read</surname><given-names>HL</given-names></name>
<name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name>
</person-group>             <year>2002</year>             <article-title>Spectrotemporal receptive fields in the lemniscal auditory thalamus and cortex.</article-title>             <source>J Neurophysiol</source>             <volume>87</volume>             <fpage>516</fpage>             <lpage>527</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Kowalski1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kowalski</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Depireux</surname><given-names>DA</given-names></name>
<name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name>
</person-group>             <year>1996</year>             <article-title>Analysis of dynamic spectra in ferret primary auditory cortex. I. Characteristics of single-unit responses to moving ripple spectra.</article-title>             <source>J Neurophysiol</source>             <volume>76</volume>             <fpage>3503</fpage>             <lpage>3523</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Maunsell1"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Maunsell</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Treue</surname><given-names>S</given-names></name>
</person-group>             <year>2006</year>             <article-title>Feature-based attention in visual cortex.</article-title>             <source>Trends Neurosci</source>             <volume>29</volume>             <fpage>317</fpage>             <lpage>322</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Reynolds2"><label>40</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reynolds</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Chelazzi</surname><given-names>L</given-names></name>
</person-group>             <year>2004</year>             <article-title>Attentional modulation of visual processing.</article-title>             <source>Annu Rev Neurosci</source>             <volume>27</volume>             <fpage>611</fpage>             <lpage>647</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Ahmar1"><label>41</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ahmar</surname><given-names>NE</given-names></name>
<name name-style="western"><surname>Simon</surname><given-names>JZ</given-names></name>
</person-group>             <year>2005</year>             <article-title>MEG adaptive noise suppression using Fast LMS.</article-title>             <source>Conference Proceedings. 2nd International IEEE EMBS Conference on Neural Engineering; 16–19 March 2005: Arlington, Virginia, United States</source>             <fpage>29</fpage>             <lpage>32</lpage>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?tp=&amp;arnumber=1419543&amp;isnumber=30683" xlink:type="simple">http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?tp=&amp;arnumber=1419543&amp;isnumber=30683</ext-link></comment>          </element-citation></ref>
<ref id="pbio.1000129-Naatanen1"><label>42</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Naatanen</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Picton</surname><given-names>T</given-names></name>
</person-group>             <year>1987</year>             <article-title>The N1 wave of the human electric and magnetic response to sound: a review and an analysis of the component structure.</article-title>             <source>Psychophysiology</source>             <volume>24</volume>             <fpage>375</fpage>             <lpage>425</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Simon1"><label>43</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Simon</surname><given-names>JZ</given-names></name>
<name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name>
</person-group>             <year>2005</year>             <article-title>Fully complex magnetoencephalography.</article-title>             <source>J Neurosci Methods</source>             <volume>149</volume>             <fpage>64</fpage>             <lpage>73</lpage>          </element-citation></ref>
<ref id="pbio.1000129-LiegeoisChauvel1"><label>44</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Liegeois-Chauvel</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Lorenzi</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Trebuchon</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Regis</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Chauvel</surname><given-names>P</given-names></name>
</person-group>             <year>2004</year>             <article-title>Temporal envelope processing in the human left and right auditory cortices.</article-title>             <source>Cereb Cortex</source>             <volume>14</volume>             <fpage>731</fpage>             <lpage>740</lpage>          </element-citation></ref>
<ref id="pbio.1000129-ISO1"><label>45</label><element-citation publication-type="other" xlink:type="simple">             <collab xlink:type="simple">ISO 226</collab>             <year>2003</year>             <source>Acoustics—normal equal-loudness-level contours</source>             <publisher-loc>Geneva (Switzerland)</publisher-loc>             <publisher-name>International Organization for Standardization. Report Number ISO-226:2003</publisher-name>             <fpage>18</fpage>          </element-citation></ref>
<ref id="pbio.1000129-Gottlieb1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gottlieb</surname><given-names>JP</given-names></name>
<name name-style="western"><surname>Kusunoki</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Goldberg</surname><given-names>ME</given-names></name>
</person-group>             <year>1998</year>             <article-title>The representation of visual salience in monkey parietal cortex.</article-title>             <source>Nature</source>             <volume>391</volume>             <fpage>481</fpage>             <lpage>484</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Naatanen2"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Naatanen</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Tervaniemi</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Sussman</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Paavilainen</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Winkler</surname><given-names>I</given-names></name>
</person-group>             <year>2001</year>             <article-title>“Primitive intelligence” in the auditory cortex.</article-title>             <source>Trends Neurosci</source>             <volume>24</volume>             <fpage>283</fpage>             <lpage>288</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Anstis1"><label>48</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Anstis</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Saida</surname><given-names>S</given-names></name>
</person-group>             <year>1985</year>             <article-title>Adaptation to auditory streaming of frequency-modulated tones.</article-title>             <source>J Exp Psychol Hum Percept Perform</source>             <volume>11</volume>             <fpage>257</fpage>             <lpage>271</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Bregman2"><label>49</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bregman</surname><given-names>AS</given-names></name>
</person-group>             <year>1978</year>             <article-title>Auditory streaming is cumulative.</article-title>             <source>J Exp Psychol Hum Percept Perform</source>             <volume>4</volume>             <fpage>380</fpage>             <lpage>387</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Griffiths1"><label>50</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Griffiths</surname><given-names>TD</given-names></name>
<name name-style="western"><surname>Warren</surname><given-names>JD</given-names></name>
</person-group>             <year>2004</year>             <article-title>What is an auditory object?</article-title>             <source>Nat Rev Neurosci</source>             <volume>5</volume>             <fpage>887</fpage>             <lpage>892</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Hansen1"><label>51</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hansen</surname><given-names>JC</given-names></name>
<name name-style="western"><surname>Hillyard</surname><given-names>SA</given-names></name>
</person-group>             <year>1988</year>             <article-title>Temporal dynamics of human auditory selective attention.</article-title>             <source>Psychophysiology</source>             <volume>25</volume>             <fpage>316</fpage>             <lpage>329</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Donald1"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Donald</surname><given-names>MW</given-names></name>
<name name-style="western"><surname>Young</surname><given-names>MJ</given-names></name>
</person-group>             <year>1982</year>             <article-title>A time-course analysis of attentional tuning of the auditory evoked response.</article-title>             <source>Exp Brain Res</source>             <volume>46</volume>             <fpage>357</fpage>             <lpage>367</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Gutschalk1"><label>53</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gutschalk</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Micheyl</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Melcher</surname><given-names>JR</given-names></name>
<name name-style="western"><surname>Rupp</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Scherg</surname><given-names>M</given-names></name>
<etal/></person-group>             <year>2005</year>             <article-title>Neuromagnetic correlates of streaming in human auditory cortex.</article-title>             <source>J Neurosci</source>             <volume>25</volume>             <fpage>5382</fpage>             <lpage>5388</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Snyder1"><label>54</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Snyder</surname><given-names>JS</given-names></name>
<name name-style="western"><surname>Alain</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Picton</surname><given-names>TW</given-names></name>
</person-group>             <year>2006</year>             <article-title>Effects of attention on neuroelectric correlates of auditory stream segregation.</article-title>             <source>J Cogn Neurosci</source>             <volume>18</volume>             <fpage>1</fpage>             <lpage>13</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Naatanen3"><label>55</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Naatanen</surname><given-names>R</given-names></name>
</person-group>             <year>1990</year>             <article-title>The Role of attention in auditory information-processing as revealed by event-related potentials and other brain measures of cognitive function.</article-title>             <source>Behav Brain Sci</source>             <volume>13</volume>             <fpage>201</fpage>             <lpage>232</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Picton1"><label>56</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Picton</surname><given-names>TW</given-names></name>
<name name-style="western"><surname>Woods</surname><given-names>DL</given-names></name>
<name name-style="western"><surname>Proulx</surname><given-names>GB</given-names></name>
</person-group>             <year>1978</year>             <article-title>Human auditory sustained potentials. I. The nature of the response.</article-title>             <source>Electroencephalogr Clin Neurophysiol</source>             <volume>45</volume>             <fpage>186</fpage>             <lpage>197</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Picton2"><label>57</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Picton</surname><given-names>TW</given-names></name>
<name name-style="western"><surname>Woods</surname><given-names>DL</given-names></name>
<name name-style="western"><surname>Proulx</surname><given-names>GB</given-names></name>
</person-group>             <year>1978</year>             <article-title>Human auditory sustained potentials. II. Stimulus relationships.</article-title>             <source>Electroencephalogr Clin Neurophysiol</source>             <volume>45</volume>             <fpage>198</fpage>             <lpage>210</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Hari1"><label>58</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hari</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Aittoniemi</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Jarvinen</surname><given-names>ML</given-names></name>
<name name-style="western"><surname>Katila</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Varpula</surname><given-names>T</given-names></name>
</person-group>             <year>1980</year>             <article-title>Auditory evoked transient and sustained magnetic fields of the human brain. Localization of neural generators.</article-title>             <source>Exp Brain Res</source>             <volume>40</volume>             <fpage>237</fpage>             <lpage>240</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Nelken1"><label>59</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name>
</person-group>             <year>2004</year>             <article-title>Processing of complex stimuli and natural scenes in the auditory cortex.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>14</volume>             <fpage>474</fpage>             <lpage>480</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Elhilali1"><label>60</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Elhilali</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Ma</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Micheyl</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Oxenham</surname><given-names>AJ</given-names></name>
<name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name>
</person-group>             <year>2009</year>             <article-title>Temporal coherence in the perceptual organization and cortical representation of auditory scenes.</article-title>             <source>Neuron</source>             <volume>61</volume>             <fpage>317</fpage>             <lpage>329</lpage>          </element-citation></ref>
<ref id="pbio.1000129-BidetCaulet1"><label>61</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bidet-Caulet</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Fischer</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Besle</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Aguera</surname><given-names>PE</given-names></name>
<name name-style="western"><surname>Giard</surname><given-names>MH</given-names></name>
<etal/></person-group>             <year>2007</year>             <article-title>Effects of selective attention on the electrophysiological representation of concurrent sounds in the human auditory cortex.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>9252</fpage>             <lpage>9261</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Alho1"><label>62</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Alho</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Tottola</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Reinikainen</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Sams</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Naatanen</surname><given-names>R</given-names></name>
</person-group>             <year>1987</year>             <article-title>Brain mechanism of selective listening reflected by event-related potentials.</article-title>             <source>Electroencephalogr Clin Neurophysiol</source>             <volume>68</volume>             <fpage>458</fpage>             <lpage>470</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Michie1"><label>63</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Michie</surname><given-names>PT</given-names></name>
<name name-style="western"><surname>Bearpark</surname><given-names>HM</given-names></name>
<name name-style="western"><surname>Crawford</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Glue</surname><given-names>LC</given-names></name>
</person-group>             <year>1990</year>             <article-title>The nature of selective attention effects on auditory event-related potentials.</article-title>             <source>Biol Psychol</source>             <volume>30</volume>             <fpage>219</fpage>             <lpage>250</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Woods1"><label>64</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Woods</surname><given-names>DL</given-names></name>
<name name-style="western"><surname>Alain</surname><given-names>C</given-names></name>
</person-group>             <year>2001</year>             <article-title>Conjoining three auditory features: an event-related brain potential study.</article-title>             <source>J Cogn Neurosci</source>             <volume>13</volume>             <fpage>492</fpage>             <lpage>509</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Woods2"><label>65</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Woods</surname><given-names>DL</given-names></name>
<name name-style="western"><surname>Alain</surname><given-names>C</given-names></name>
</person-group>             <year>1993</year>             <article-title>Feature processing during high-rate auditory selective attention.</article-title>             <source>Percept Psychophys</source>             <volume>53</volume>             <fpage>391</fpage>             <lpage>402</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Arnott1"><label>66</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Arnott</surname><given-names>SR</given-names></name>
<name name-style="western"><surname>Alain</surname><given-names>C</given-names></name>
</person-group>             <year>2002</year>             <article-title>Effects of perceptual context on event-related brain potentials during auditory spatial attention.</article-title>             <source>Psychophysiology</source>             <volume>39</volume>             <fpage>625</fpage>             <lpage>632</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Zani1"><label>67</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Zani</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Proverbio</surname><given-names>AM</given-names></name>
</person-group>             <year>1995</year>             <article-title>ERP signs of early selective attention effects to check size.</article-title>             <source>Electroencephalogr Clin Neurophysiol</source>             <volume>95</volume>             <fpage>277</fpage>             <lpage>292</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Coch1"><label>68</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Coch</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Sanders</surname><given-names>LD</given-names></name>
<name name-style="western"><surname>Neville</surname><given-names>HJ</given-names></name>
</person-group>             <year>2005</year>             <article-title>An event-related potential study of selective auditory attention in children and adults.</article-title>             <source>J Cogn Neurosci</source>             <volume>17</volume>             <fpage>605</fpage>             <lpage>622</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Devlin1"><label>69</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Devlin</surname><given-names>JT</given-names></name>
<name name-style="western"><surname>Raley</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Tunbridge</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Lanary</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Floyer-Lea</surname><given-names>A</given-names></name>
<etal/></person-group>             <year>2003</year>             <article-title>Functional asymmetry for auditory processing in human primary auditory cortex.</article-title>             <source>J Neurosci</source>             <volume>23</volume>             <fpage>11516</fpage>             <lpage>11522</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Muller1"><label>70</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Muller</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Schlee</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Hartmann</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Lorenz</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Weisz</surname><given-names>N</given-names></name>
</person-group>             <year>2009</year>             <article-title>Top-down modulation of the auditory steady-state response in a task-switch paradigm.</article-title>             <source>Front Hum Neurosci</source>             <volume>3</volume>             <fpage>1</fpage>          </element-citation></ref>
<ref id="pbio.1000129-Ross1"><label>71</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ross</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Herdman</surname><given-names>AT</given-names></name>
<name name-style="western"><surname>Pantev</surname><given-names>C</given-names></name>
</person-group>             <year>2005</year>             <article-title>Right hemispheric laterality of human 40 Hz auditory steady-state responses.</article-title>             <source>Cereb Cortex</source>             <volume>15</volume>             <fpage>2029</fpage>             <lpage>2039</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Zatorre1"><label>72</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Zatorre</surname><given-names>RJ</given-names></name>
<name name-style="western"><surname>Belin</surname><given-names>P</given-names></name>
</person-group>             <year>2001</year>             <article-title>Spectral and temporal processing in human auditory cortex.</article-title>             <source>Cereb Cortex</source>             <volume>11</volume>             <fpage>946</fpage>             <lpage>953</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Cherry1"><label>73</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cherry</surname><given-names>EC</given-names></name>
</person-group>             <year>1953</year>             <article-title>Some experiments on the recognition of speech, with one and with two ears.</article-title>             <source>J Acoust Soc Am</source>             <volume>25</volume>             <fpage>975</fpage>             <lpage>979</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Niebur1"><label>74</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Niebur</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Hsiao</surname><given-names>SS</given-names></name>
<name name-style="western"><surname>Johnson</surname><given-names>KO</given-names></name>
</person-group>             <year>2002</year>             <article-title>Synchrony: a neuronal mechanism for attentional selection?</article-title>             <source>Curr Opin Neurobiol</source>             <volume>12</volume>             <fpage>190</fpage>             <lpage>194</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Kauramaki1"><label>75</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kauramaki</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Jaaskelainen</surname><given-names>IP</given-names></name>
<name name-style="western"><surname>Sams</surname><given-names>M</given-names></name>
</person-group>             <year>2007</year>             <article-title>Selective attention increases both gain and feature selectivity of the human auditory cortex.</article-title>             <source>PLoS ONE</source>             <volume>2</volume>             <fpage>e909</fpage>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0000909" xlink:type="simple">10.1371/journal.pone.0000909</ext-link></comment>          </element-citation></ref>
<ref id="pbio.1000129-Okamoto1"><label>76</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Okamoto</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Stracke</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Wolters</surname><given-names>CH</given-names></name>
<name name-style="western"><surname>Schmael</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Pantev</surname><given-names>C</given-names></name>
</person-group>             <year>2007</year>             <article-title>Attention improves population-level frequency tuning in human auditory cortex.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>10383</fpage>             <lpage>10390</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Fritz2"><label>77</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fritz</surname><given-names>JB</given-names></name>
<name name-style="western"><surname>Elhilali</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name>
</person-group>             <year>2005</year>             <article-title>Differential dynamic plasticity of A1 receptive fields during multiple spectral tasks.</article-title>             <source>J Neurosci</source>             <volume>25</volume>             <fpage>7623</fpage>             <lpage>7635</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Polley1"><label>78</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Polley</surname><given-names>DB</given-names></name>
<name name-style="western"><surname>Steinberg</surname><given-names>EE</given-names></name>
<name name-style="western"><surname>Merzenich</surname><given-names>MM</given-names></name>
</person-group>             <year>2006</year>             <article-title>Perceptual learning directs auditory cortical map reorganization through top-down influences.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>4970</fpage>             <lpage>4982</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Weinberger1"><label>79</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Weinberger</surname><given-names>NM</given-names></name>
</person-group>             <year>1998</year>             <article-title>Physiological memory in primary auditory cortex: characteristics and mechanisms.</article-title>             <source>Neurobiol Learn Mem</source>             <volume>70</volume>             <fpage>226</fpage>             <lpage>251</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Atiani1"><label>80</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Atiani</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Elhilali</surname><given-names>M</given-names></name>
<name name-style="western"><surname>David</surname><given-names>SV</given-names></name>
<name name-style="western"><surname>Fritz</surname><given-names>JB</given-names></name>
<name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name>
</person-group>             <year>2009</year>             <article-title>Task difficulty and performance induce diverse adaptive patterns in gain and shape of primary auditory cortical receptive fields.</article-title>             <source>Neuron</source>             <volume>61</volume>             <fpage>467</fpage>             <lpage>480</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Oldfield1"><label>81</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Oldfield</surname><given-names>RC</given-names></name>
</person-group>             <year>1971</year>             <article-title>The assessment and analysis of handedness: the Edinburgh inventory.</article-title>             <source>Neuropsychologia</source>             <volume>9</volume>             <fpage>97</fpage>             <lpage>113</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Xiang1"><label>82</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Xiang</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Simon</surname><given-names>JZ</given-names></name>
</person-group>             <year>2005</year>             <article-title>MEG Responses to speech and stimuli with speechlike modulations.</article-title>             <source>Conference Proceedings. 2nd International IEEE EMBS Conference on Neural Engineering; 16–19 March 2005: Arlington, Virginia, United States</source>             <fpage>33</fpage>             <lpage>46</lpage>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1419544" xlink:type="simple">http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1419544</ext-link></comment>          </element-citation></ref>
<ref id="pbio.1000129-Kay1"><label>83</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kay</surname><given-names>SM</given-names></name>
</person-group>             <year>1993</year>             <source>Fundamentals of statistical signal processing. Volume 2, Detection theory</source>             <publisher-loc>Englewood Cliffs (New Jersey)</publisher-loc>             <publisher-name>Prentice-Hall PTR</publisher-name>             <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">672</size>          </element-citation></ref>
<ref id="pbio.1000129-Bendat1"><label>84</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bendat</surname><given-names>JS</given-names></name>
<name name-style="western"><surname>Piersol</surname><given-names>AG</given-names></name>
</person-group>             <year>1986</year>             <source>Random data: analysis and measurement procedures</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Wiley</publisher-name>             <fpage>566</fpage>          </element-citation></ref>
<ref id="pbio.1000129-Srinivasan1"><label>85</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Srinivasan</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Russell</surname><given-names>DP</given-names></name>
<name name-style="western"><surname>Edelman</surname><given-names>GM</given-names></name>
<name name-style="western"><surname>Tononi</surname><given-names>G</given-names></name>
</person-group>             <year>1999</year>             <article-title>Increased synchronization of neuromagnetic responses during conscious perception.</article-title>             <source>J Neurosci</source>             <volume>19</volume>             <fpage>5435</fpage>             <lpage>5448</lpage>          </element-citation></ref>
<ref id="pbio.1000129-Fisher1"><label>86</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fisher</surname><given-names>NI</given-names></name>
</person-group>             <year>1993</year>             <source>Statistical analysis of circular data</source>             <publisher-loc>Cambridge (England)</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name>             <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">277</size>          </element-citation></ref>
<ref id="pbio.1000129-Efron1"><label>87</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Efron</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Tibshirani</surname><given-names>R</given-names></name>
</person-group>             <year>1993</year>             <source>An introduction to the bootstrap</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Chapman &amp; Hall</publisher-name>             <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">436</size>          </element-citation></ref>
</ref-list><glossary><title>Abbreviations</title><def-list><def-item>
<term>MEG</term>
<def>
<p>magnetoencephalography</p>
</def>
</def-item></def-list></glossary>

</back>
</article>
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-00550</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005118</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Algebra</subject><subj-group><subject>Linear algebra</subject><subj-group><subject>Eigenvalues</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Algebra</subject><subj-group><subject>Linear algebra</subject><subj-group><subject>Eigenvectors</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Geometry</subject><subj-group><subject>Tangents</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Signal processing</subject><subj-group><subject>Autocorrelation</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Autocorrelation</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Autocorrelation</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Musculoskeletal system</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Musculoskeletal system</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Condensed matter physics</subject><subj-group><subject>Anisotropy</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Materials science</subject><subj-group><subject>Material properties</subject><subj-group><subject>Anisotropy</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical mechanics</subject><subj-group><subject>Motion</subject><subj-group><subject>Velocity</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Regression analysis</subject><subj-group><subject>Linear regression analysis</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Regression analysis</subject><subj-group><subject>Linear regression analysis</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Error Correction and the Structure of Inter-Trial Fluctuations in a Redundant Movement Task</article-title>
<alt-title alt-title-type="running-head">Error Correction and the Structure of Inter-Trial Fluctuations</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>John</surname> <given-names>Joby</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Dingwell</surname> <given-names>Jonathan B.</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Cusumano</surname> <given-names>Joseph P.</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Department of Engineering Science and Mechanics, The Pennsylvania State University, University Park, Pennsylvania, United States of America</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Kinesiology and Health Education, The University of Texas at Austin, Austin, Texas, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Diedrichsen</surname> <given-names>Jörn</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Western University, CANADA</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con">
<p><list list-type="simple"><list-item><p><bold>Conceptualization:</bold> JPC JBD.</p></list-item> <list-item><p><bold>Data curation:</bold> JPC JJ.</p></list-item> <list-item><p><bold>Formal analysis:</bold> JPC JJ.</p></list-item> <list-item><p><bold>Funding acquisition:</bold> JPC JBD.</p></list-item> <list-item><p><bold>Investigation:</bold> JJ.</p></list-item> <list-item><p><bold>Methodology:</bold> JPC JJ.</p></list-item> <list-item><p><bold>Project administration:</bold> JPC JBD.</p></list-item> <list-item><p><bold>Resources:</bold> JPC.</p></list-item> <list-item><p><bold>Software:</bold> JPC JJ.</p></list-item> <list-item><p><bold>Supervision:</bold> JPC JBD.</p></list-item> <list-item><p><bold>Validation:</bold> JPC JBD JJ.</p></list-item> <list-item><p><bold>Visualization:</bold> JJ JPC.</p></list-item> <list-item><p><bold>Writing – original draft:</bold> JJ JPC JBD.</p></list-item> <list-item><p><bold>Writing – review &amp; editing:</bold> JPC JBD JJ.</p></list-item></list></p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">jpcusumano@psu.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>9</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="epub">
<day>19</day>
<month>9</month>
<year>2016</year>
</pub-date>
<volume>12</volume>
<issue>9</issue>
<elocation-id>e1005118</elocation-id>
<history>
<date date-type="received">
<day>4</day>
<month>4</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>25</day>
<month>8</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>John et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005118"/>
<abstract>
<p>We study inter-trial movement fluctuations exhibited by human participants during the repeated execution of a virtual shuffleboard task. Focusing on skilled performance, theoretical analysis of a previously-developed general model of inter-trial error correction is used to predict the temporal and geometric structure of variability near a goal equivalent manifold (GEM). The theory also predicts that the goal-level error scales linearly with intrinsic body-level noise via the <italic>total body-goal sensitivity</italic>, a new derived quantity that illustrates how task performance arises from the interaction of active error correction and passive sensitivity properties along the GEM. Linear models estimated from observed fluctuations, together with a novel application of bootstrapping to the estimation of dynamical and correlation properties of the inter-trial dynamics, are used to experimentally confirm all predictions, thus validating our model. In addition, we show that, unlike “static” variability analyses, our dynamical approach yields results that are independent of the coordinates used to measure task execution and, in so doing, provides a new set of task coordinates that are intrinsic to the error-regulation process itself.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>During the repeated execution of precision movement tasks, humans face two formidable challenges from the motor system itself: dimensionality and noise. Human motor performance involves biomechanical, neuromotor, and perceptual degrees of freedom far in excess of those theoretically needed to prescribe typical goal-directed tasks. At the same time, noise is present in the human body across multiple scales of observation. This high-dimensional and stochastic character of biological movement is the fundamental source of variability ubiquitously observed during task execution. However, it is becoming clear that these two challenges are not merely impediments to be overcome, but rather hold a key to understanding how humans maintain motor performance under changing circumstances, such as those caused by fatigue, injury, or aging. In this work, by studying skilled human participants as they play a virtual shuffleboard game, we demonstrate the fundamental importance of adopting a dynamical perspective when analyzing the motor variability observed over many trials. Using this dynamical approach, we can not only study the geometry of observed inter-trial variability, but can also theoretically describe and experimentally characterize how it is temporally generated and regulated. Furthermore, our theoretical framework and model-based data analysis approach helps to unify previous variability analysis approaches based on stability, correlation, control theory, or task manifolds alone. This conceptual unification supports the idea that such seemingly disparate features of motor variability arise from a single, relatively simple underlying neurophysiological process of motor regulation.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000090</institution-id>
<institution>Congressionally Directed Medical Research Programs</institution>
</institution-wrap>
</funding-source>
<award-id>W81XWH-11-2-0222</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Dingwell</surname> <given-names>Jonathan B.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000090</institution-id>
<institution>Congressionally Directed Medical Research Programs</institution>
</institution-wrap>
</funding-source>
<award-id>W81XWH-11-2-0222</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Cusumano</surname> <given-names>Joseph P.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>0625764</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Cusumano</surname> <given-names>Joseph P.</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by Congressionally Directed Medical Research Programs (cdmrp.army.mil) contract #W81XWH-11-2-0222 (JBD and JPC); National Science Foundation (nsf.gov) grant #0625764 (JJ and JPC). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="11"/>
<table-count count="1"/>
<page-count count="30"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are included in the Supporting Information File.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>During the repeated execution of goal-directed movements, statistical variability is always observed from one trial to the next, and this motor variability has long been a major focus of movement neuroscience [<xref ref-type="bibr" rid="pcbi.1005118.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref003">3</xref>]. It is generally believed that these inter-trial fluctuations contain crucial information about how the neuromotor system organizes itself to meet task requirements in the face of physical constraints, external perturbations, and motor noise [<xref ref-type="bibr" rid="pcbi.1005118.ref004">4</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref009">9</xref>]. Indeed, there is increasing evidence that inherent biological noise, which is present at multiple scales from the level of motor units down to the level of genes, may play a crucial physiological function in the nervous system [<xref ref-type="bibr" rid="pcbi.1005118.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref011">11</xref>]. However, the process by which this multiscale noise comes to be expressed as variability at the organismic level is still far from completely understood.</p>
<p>There is an excess of body-level degrees of freedom over those needed to specify the outcome of a typical goal-directed movement, and it is natural to expect this redundancy to affect the structure of observed variability. A number of data analysis approaches [<xref ref-type="bibr" rid="pcbi.1005118.ref012">12</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref014">14</xref>] have been developed to examine the effect of this redundancy using <italic>task manifolds</italic>, which are surfaces in a suitably-defined space of biomechanical observables, or “body states” (e.g., joint kinematic variables), that contains all possible task solutions. By definition, every point in a task manifold corresponds to a body state that results in perfect task execution, and so, as a consequence, only body-level deviations away from the manifold result in error at the goal level.</p>
<p>Originally inspired by ideas from research in redundant robotics, uncontrolled manifold (UCM) analysis [<xref ref-type="bibr" rid="pcbi.1005118.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref017">17</xref>] assumes that the task manifold is defined at each instant along a given movement trajectory, and in typical applications takes the task’s goal to be represented by the average movement in a time-normalized set of trials. The ratios of normalized variances orthogonal and tangent to a candidate manifold are then used to identify possible “control variables”, with the expectation that there should be a larger variance along the manifold than normal to it. In a similar vein, motor learning has been studied by statistically decomposing observed body-level variability into tolerance, noise, and covariation (TNC) empirical “costs”, [<xref ref-type="bibr" rid="pcbi.1005118.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref018">18</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref020">20</xref>], all three of which are defined with respect to a task manifold. In contrast with UCM analysis, the TNC approach conceives of the task manifold as existing in a minimal space of variables needed to specify task execution (e.g., the position and velocity of a ball at release when throwing at a target). In addition to using its covariation cost to characterize the alignment of body-level variability with the task manifold, TNC analysis crucially relates the goal-level variability to error at the body level via its tolerance cost.</p>
<p>This relationship between body and goal-level variability was the initial focus of a sensitivity analysis method based on the goal equivalent manifold (GEM) concept [<xref ref-type="bibr" rid="pcbi.1005118.ref014">14</xref>]. Like TNC, the GEM analysis defines its task manifold using only a minimal set of variables needed for task specification, however it makes direct use of an explicit <italic>goal function</italic> that serves as a hypothesis on the task strategy being used. The zeros of the goal function give body states yielding perfect task execution, and the set of all such solutions then gives the GEM. In addition to defining the GEM, the goal function provides a theoretical definition of the “passive” sensitivity (i.e., sensitivity independent of any applied control) to body-level disturbances, via the singular values of the goal function’s Jacobian matrix [<xref ref-type="bibr" rid="pcbi.1005118.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref021">21</xref>].</p>
<p>While the initial GEM-based sensitivity analysis was useful for describing the geometrical structure of observed variability and quantifying motor performance, like the UCM and TNC approaches it did not provide an analysis of the <italic>temporal</italic> structure of observed inter-trial fluctuations. This limitation was addressed by subsequent developments that incorporated optimal control ideas with the GEM to create a dynamical, model-based data analysis framework. Optimal control in the presence of redundancy has been proposed as a theoretical basis for models of the neuromotor system [<xref ref-type="bibr" rid="pcbi.1005118.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref023">23</xref>], and the minimum intervention principle (MIP) [<xref ref-type="bibr" rid="pcbi.1005118.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref024">24</xref>] posits that little or no control will be exerted along the task manifold, since to do so would entail a waste of control effort. The expanded GEM data analysis framework allows one to create theoretical models of inter-trial fluctuations that can be used for hypothesis testing against movement data from human participants [<xref ref-type="bibr" rid="pcbi.1005118.ref025">25</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref027">27</xref>].</p>
<p>This initial work has demonstrated the central importance of taking a dynamical approach when analyzing motor variability. A fundamental feature of variability highlighted by these studies is that inter-trial fluctuations are found to be <italic>dynamically</italic> anisotropic with respect to the GEM [<xref ref-type="bibr" rid="pcbi.1005118.ref025">25</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref029">29</xref>]: that is, it is found that the local stability and correlation properties are congruent with the local GEM geometry, with greater stability and lower temporal correlation being associated with the components of time series transverse to the GEM, and lower stability and greater correlation for times series components along the GEM. A similar directionality in correlation properties has been found in a study of skill acquisition [<xref ref-type="bibr" rid="pcbi.1005118.ref030">30</xref>]. However, such studies have tended to examine these dynamical properties in isolation, and it is not completely clear how the various temporal properties (e.g., local stability multipliers, lag-1 correlations, etc.) relate, if at all, to the purely geometrical features of inter-trial variability arising from the task manifold itself (e.g. variance ratios, passive sensitivity). In particular, it remains an open question whether these various features of inter-trial variability should be considered as manifestations of unique neurophysiological phenomena each in their own right, or if, conversely, they are epiphenomena that naturally arise from a single, underlying regulatory process. In this paper we present evidence that supports the latter, more parsimonious interpretation.</p>
<p>To this end, we examine the performance of human participants as they play a virtual shuffleboard game. We chose shuffleboard for this study because it is among the simplest tasks exhibiting task-level redundancy, and is thus both mathematically and experimentally tractable. As such, it serves as a “model problem” for a much broader class of goal-directed tasks which can be expected to exhibit similar variability characteristics. Observed inter-trial fluctuations are modeled as the output of the perception-action system as participants attempt to hit the target in each trial by correcting error in the previous trial. We focus on skilled performance, and, starting with a previously-developed general model for inter-trial error correction [<xref ref-type="bibr" rid="pcbi.1005118.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>], we present a theoretical analysis using the shuffleboard task as an illustrative example. The analysis yields theoretical predictions about the geometrical and temporal structure of inter-trial variability, culminating in a prediction of how GEM geometry, passive sensitivity, and active error correction combine to yield task performance. Specifically, we show that the scaling of the root mean square (RMS) error at the target is determined by the <italic>total body-goal sensitivity</italic>, which is, in effect, a total “gain” mapping body-level fluctuations to the goal level.</p>
<p>We also address a critical technical issue that arises when experimentally testing our theoretical predictions. For skilled performance, the local geometric stability properties of the fluctuations play a fundamental role, with such properties being determined theoretically by an eigenanalysis of a linearized model. Unfortunately, numerical estimates of eigenvalues and eigenvectors are known to be highly sensitive to errors in the matrix estimate [<xref ref-type="bibr" rid="pcbi.1005118.ref031">31</xref>], which are themselves unavoidable when the matrix is found using regression on experimental data. This problem is compounded by the relatively small data sets available in typical human subjects experiments. In this paper we present a new method for estimating all of our dynamical quantities based on bootstrapping [<xref ref-type="bibr" rid="pcbi.1005118.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref034">34</xref>], which allows us to estimate the complete underlying probability distribution for each quantity considered, resulting in the most robust demonstration to date of the degree to which dynamical anisotropy is present in inter-trial movement data. Furthermore, this data analysis allows us to confirm the theoretical performance scaling prediction to high precision, not only showing how the individual participants performed in this particular task, but also validating the many assumptions underlying our theoretical derivation.</p>
<p>Studies of variability using task solution manifolds typically assume that they are embedded in a space of variables with identical physical dimension, such as, for example, joint angles [<xref ref-type="bibr" rid="pcbi.1005118.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref035">35</xref>], muscle activation [<xref ref-type="bibr" rid="pcbi.1005118.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref037">37</xref>], or finger forces [<xref ref-type="bibr" rid="pcbi.1005118.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref039">39</xref>]. Such situations have tended to obscure a fundamental difficulty if one intends to make inferences based on the relative magnitude of fluctuations normal and tangent to any hypothesized manifold: namely, that multivariate statistics are not invariant under coordinate transformations. This issue was recently recognized in the context of movement variability analysis [<xref ref-type="bibr" rid="pcbi.1005118.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref040">40</xref>], but is a well-known problem in multivariate statistics. Indeed, the widespread utility of principal component analysis [<xref ref-type="bibr" rid="pcbi.1005118.ref041">41</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref042">42</xref>] is based in part on the fact that correlations between variables can be completely removed with properly selected linear coordinate transformations.</p>
<p>It is clearly highly desirable that the inferences we make about the motor system be invariant under coordinate transformations. While it is possible to normalize the variables and make the data dimensionless, such an approach does not completely resolve the scaling issue because the choice of the normalizing constant is, in most cases, arbitrary. This problem becomes even more acute when the task manifold resides in a space composed of different physical quantities, for example positions and velocities. Given the central role played by local geometric stability in our approach, we are able to exploit the well-known fact that such dynamical properties are invariants that do not depend on the coordinates used [<xref ref-type="bibr" rid="pcbi.1005118.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref044">44</xref>]. We therefore show that our approach provides a coordinate-independent characterization of the variability observed in our experiments, suggesting that the local geometric stability analysis of inter-trial fluctuations provides a new set of task coordinates that are intrinsic to the error regulation process itself.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<p>This section begins with a discussion of the key concepts and models that theoretically ground our approach, and that culminate in a set of four experimental hypotheses. With this theoretical background as foundation, we then describe our experimental virtual shuffleboard game, the experimental protocol, and our data analysis methods.</p>
<sec id="sec003">
<title>Ethics Statement</title>
<p>All participants provided informed consent, as approved by the Institutional Review Board at The Pennsylvania State University.</p>
</sec>
<sec id="sec004">
<title>The Shuffleboard Task and GEM</title>
<p>
<xref ref-type="fig" rid="pcbi.1005118.g001">Fig 1</xref> shows a schematic of a theoretical shuffleboard game. The entire game takes place along a straight line. Starting the puck at <italic>x</italic> = 0, the shuffleboard cue is accelerated from rest while in contact with the puck. Thereafter, the cue decelerates and, when the contact force between it and the puck reaches zero, the puck is released with position and velocity <italic>x</italic> and <italic>v</italic>, respectively. Once released, the puck slides on the board and is decelerated by the force of Coulomb friction, with kinetic coefficient <italic>μ</italic>, between the board and the puck. The puck eventually comes to rest at <italic>x</italic> = <italic>x</italic><sub><italic>f</italic></sub>. The goal-level error, <italic>e</italic> = <italic>x</italic><sub><italic>f</italic></sub> − <italic>L</italic>, is the distance between the final puck position and the target.</p>
<fig id="pcbi.1005118.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Schematic of a shuffleboard task: the shuffleboard cue pushes the puck from rest and releases it at a position <italic>x</italic> with a velocity <italic>v</italic> when the contact force between puck and cue decreases to zero.</title>
<p>Thereafter, the puck decelerates due to the Coulomb friction force between the puck and the board, and eventually comes to rest at <italic>x</italic><sub><italic>f</italic></sub>. The target is at a distance <italic>L</italic> from the initial position and the goal-level error is <italic>e</italic> = <italic>x</italic><sub><italic>f</italic></sub> − <italic>L</italic>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.g001" xlink:type="simple"/>
</fig>
<p>Elementary Newtonian mechanics gives the equation of motion for the puck after release as <inline-formula id="pcbi.1005118.e001"><alternatives><graphic id="pcbi.1005118.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>¨</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mi>μ</mml:mi> <mml:mi>g</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>g</italic> is the gravitational acceleration constant. For arbitrary initial conditions <italic>x</italic> and <italic>v</italic> just after release, and final velocity <italic>v</italic><sub><italic>f</italic></sub> = 0, the equation of motion is easily integrated to give −<italic>v</italic><sup>2</sup> = −2<italic>μg</italic>(<italic>x</italic><sub><italic>f</italic></sub> − <italic>x</italic>). Since perfect execution (hitting the target) requires <italic>e</italic> = <italic>x</italic><sub><italic>f</italic></sub> − <italic>L</italic> = 0, we then obtain a goal function for the task as
<disp-formula id="pcbi.1005118.e002"><alternatives><graphic id="pcbi.1005118.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mrow><mml:mi>e</mml:mi> <mml:mo>=</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>v</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mi>v</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:mn>2</mml:mn> <mml:mi>μ</mml:mi> <mml:mi>g</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>-</mml:mo> <mml:mi>L</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula>
Any values of <italic>x</italic> and <italic>v</italic> for which <italic>e</italic> = <italic>f</italic>(<italic>x</italic>, <italic>v</italic>) = 0 result in perfect task execution (zero error at the goal level).</p>
<p>Dimensionless quantities <inline-formula id="pcbi.1005118.e003"><alternatives><graphic id="pcbi.1005118.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>x</mml:mi> <mml:mo>/</mml:mo> <mml:mi>R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005118.e004"><alternatives><graphic id="pcbi.1005118.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:mover accent="true"><mml:mi>v</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>v</mml:mi> <mml:mo>/</mml:mo> <mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mi>g</mml:mi> <mml:mi>R</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1005118.e005"><alternatives><graphic id="pcbi.1005118.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mrow><mml:mover accent="true"><mml:mi>L</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>L</mml:mi> <mml:mo>/</mml:mo> <mml:mi>R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> can be defined for some length scale <italic>R</italic>. Note that the exact value of <italic>R</italic> used in this rescaling has no significant bearing on our results: it was chosen for convenience so that when plotting experimental data the rescaled release position <inline-formula id="pcbi.1005118.e006"><alternatives><graphic id="pcbi.1005118.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>x</mml:mi> <mml:mo>/</mml:mo> <mml:mi>R</mml:mi> <mml:mo>≈</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. For the experiments described in what follows, we took <italic>L</italic> = 200cm and <italic>R</italic> = 20cm, so that the target was located at a distance of <inline-formula id="pcbi.1005118.e007"><alternatives><graphic id="pcbi.1005118.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:mover accent="true"><mml:mi>L</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn>10</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> dimensionless units. Using these rescalings in <xref ref-type="disp-formula" rid="pcbi.1005118.e002">Eq (1)</xref> gives, after rearranging and <italic>dropping tildes</italic>, the goal function in <italic>dimensionless</italic> form as
<disp-formula id="pcbi.1005118.e008"><alternatives><graphic id="pcbi.1005118.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e008" xlink:type="simple"/><mml:math display="block" id="M8"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>v</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:msup><mml:mi>v</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mi>μ</mml:mi></mml:mfrac> <mml:mo>+</mml:mo> <mml:mi>x</mml:mi> <mml:mo>-</mml:mo> <mml:mn>10</mml:mn> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula>
Henceforth we use the dimensionless goal function of <xref ref-type="disp-formula" rid="pcbi.1005118.e008">Eq (2)</xref>.</p>
<p>There are an infinite number of states (<italic>x</italic>, <italic>v</italic>) that are zeros to <xref ref-type="disp-formula" rid="pcbi.1005118.e008">Eq (2)</xref>, corresponding to trials that hit the target perfectly. In this simple case, we can solve for this set analytically, and find, as shown in <xref ref-type="fig" rid="pcbi.1005118.g002">Fig 2</xref>, that it forms a 1D goal equivalent manifold (GEM)
<disp-formula id="pcbi.1005118.e009"><alternatives><graphic id="pcbi.1005118.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e009" xlink:type="simple"/><mml:math display="block" id="M9"><mml:mrow><mml:mi mathvariant="script">G</mml:mi> <mml:mo>=</mml:mo> <mml:mfenced close="}" open="{" separators=""><mml:mspace width="0.166667em"/><mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>v</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo>|</mml:mo> <mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:msup><mml:mi>v</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mi>μ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>10</mml:mn> <mml:mo>-</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/></mml:mfenced> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula>
which has the shape of a parabola in the (<italic>x</italic>, <italic>v</italic>) plane. Since the performance is completely determined by the values of <italic>x</italic> and <italic>v</italic> at release, we take as our body state <bold>x</bold> = (<italic>x</italic>, <italic>v</italic>)<sup><sans-serif>T</sans-serif></sup> (where the superscript <sans-serif>T</sans-serif> denotes the transpose). Note that the goal function <italic>f</italic>(<bold>x</bold>) ≠ 0 for “strategies” <bold>x</bold> that are not exactly on the GEM: for this task, this value is identical to the goal-level error, <italic>e</italic>.</p>
<fig id="pcbi.1005118.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Typical GEM (solid curve) for the shuffleboard task, obtained as zeros of the goal function <xref ref-type="disp-formula" rid="pcbi.1005118.e008">Eq (2)</xref>, plotted in the dimensionless (<italic>x</italic>, <italic>v</italic>) body state space.</title>
<p>Dashed curves indicate ±10% constant error contours at the goal (as a percentage of distance to the goal). For this particular plot, <italic>μ</italic> ≈ 0.016. Also shown are the unit vectors tangent and normal to the GEM, <inline-formula id="pcbi.1005118.e010"><alternatives><graphic id="pcbi.1005118.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005118.e011"><alternatives><graphic id="pcbi.1005118.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, near a representative operating point <bold>x</bold>* (Eqs <xref ref-type="disp-formula" rid="pcbi.1005118.e019">(5)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005118.e024">(6)</xref>): small deviations along <inline-formula id="pcbi.1005118.e012"><alternatives><graphic id="pcbi.1005118.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula> do not cause error at the target (i.e., they are <italic>goal equivalent</italic>), while deviations along <inline-formula id="pcbi.1005118.e013"><alternatives><graphic id="pcbi.1005118.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula> do (i.e., they are <italic>goal relevant</italic>). Note that the distance between contours increases from left to right, indicating a decrease in passive sensitivity (see <xref ref-type="disp-formula" rid="pcbi.1005118.e028">Eq 8</xref>) along the GEM.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.g002" xlink:type="simple"/>
</fig>
<p>The GEM represented in <xref ref-type="fig" rid="pcbi.1005118.g002">Fig 2</xref> exists independently of who or what performs the task. Actuating the shuffleboard cue with a single degree of freedom pneumatic actuator, a robot with tens of degrees of freedom, or a biological organism with thousands of degrees of freedom does not affect the requirements in the (<italic>x</italic>, <italic>v</italic>) body state space needed to hit the target. Furthermore, the GEM has been defined without any consideration of the control that might be applied to correct errors from one trial to the next: even a completely uncontrolled system that randomly assigned values of <italic>x</italic> and <italic>v</italic> for each trial would have the same GEM.</p>
<p>For a skilled participant whose performance is perfect <italic>on average</italic>, we assume that the state will be near the GEM and write <bold>x</bold> = <bold>x</bold>* + <bold>u</bold>, where the operating point <inline-formula id="pcbi.1005118.e014"><alternatives><graphic id="pcbi.1005118.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>x</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>v</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">G</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> represents the average perfect trial on the GEM, and <bold>u</bold> = (<italic>p</italic>, <italic>q</italic>)<sup><sans-serif>T</sans-serif></sup> is a small fluctuation. Substitution into the goal function <xref ref-type="disp-formula" rid="pcbi.1005118.e008">Eq (2)</xref> and linearizing about <bold>u</bold> = (0, 0)<sup><sans-serif>T</sans-serif></sup> then gives
<disp-formula id="pcbi.1005118.e015"><alternatives><graphic id="pcbi.1005118.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e015" xlink:type="simple"/><mml:math display="block" id="M15"><mml:mrow><mml:mi>e</mml:mi> <mml:mspace width="0.222222em"/><mml:mo>=</mml:mo> <mml:mspace width="0.222222em"/><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>v</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>+</mml:mo> <mml:mi>q</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mi>μ</mml:mi></mml:mfrac> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>x</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>+</mml:mo> <mml:mi>p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mn>10</mml:mn> <mml:mspace width="0.222222em"/><mml:mo>≈</mml:mo> <mml:mspace width="0.222222em"/><mml:mfenced close=")" open="(" separators=""><mml:mn>1</mml:mn> <mml:mspace width="0.222222em"/><mml:mspace width="0.222222em"/><mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>v</mml:mi> <mml:mo>*</mml:mo></mml:msup></mml:mrow> <mml:mi>μ</mml:mi></mml:mfrac></mml:mfenced> <mml:mfenced close=")" open="("><mml:mtable><mml:mtr><mml:mtd><mml:mi>p</mml:mi></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mi>q</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mfenced> <mml:mspace width="0.222222em"/><mml:mo>≜</mml:mo> <mml:mspace width="0.222222em"/><mml:mi mathvariant="sans-serif">A</mml:mi> <mml:mi mathvariant="bold">u</mml:mi> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
where <inline-formula id="pcbi.1005118.e016"><alternatives><graphic id="pcbi.1005118.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mrow><mml:mi mathvariant="sans-serif">A</mml:mi> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mi>f</mml:mi></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:mfrac> <mml:mspace width="0.277778em"/><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mi>f</mml:mi></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi>v</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, with derivatives evaluated at (<italic>x</italic>*, <italic>v</italic>*), is the 1 × 2 body-goal variability matrix [<xref ref-type="bibr" rid="pcbi.1005118.ref014">14</xref>] that maps body-level perturbations <bold>u</bold> into goal-level error <italic>e</italic>.</p>
<p>The null space <inline-formula id="pcbi.1005118.e017"><alternatives><graphic id="pcbi.1005118.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mi mathvariant="script">N</mml:mi></mml:math></alternatives></inline-formula> of <sans-serif>A</sans-serif>, defined by <inline-formula id="pcbi.1005118.e018"><alternatives><graphic id="pcbi.1005118.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mi mathvariant="bold">u</mml:mi> <mml:mspace width="0.166667em"/><mml:mo>|</mml:mo> <mml:mspace width="0.166667em"/><mml:mi mathvariant="sans-serif">A</mml:mi> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, contains fluctuations that are <italic>goal equivalent</italic>, i.e., that to leading order have no effect on the goal level error. Using this definition, the unit tangent vector to the GEM is found to be
<disp-formula id="pcbi.1005118.e019"><alternatives><graphic id="pcbi.1005118.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e019" xlink:type="simple"/><mml:math display="block" id="M19"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>v</mml:mi> <mml:mo>*</mml:mo></mml:msup></mml:mrow> <mml:mi>μ</mml:mi></mml:mfrac></mml:mfenced> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mfrac> <mml:mfenced close=")" open="("><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>v</mml:mi> <mml:mo>*</mml:mo></mml:msup></mml:mrow> <mml:mi>μ</mml:mi></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula>
giving the 1D goal-equivalent subspace as <inline-formula id="pcbi.1005118.e020"><alternatives><graphic id="pcbi.1005118.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>=</mml:mo> <mml:mo form="prefix">span</mml:mo> <mml:mo>{</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, which is also the subspace tangent to the GEM at <bold>x</bold>* (again, see <xref ref-type="fig" rid="pcbi.1005118.g002">Fig 2</xref>). In contrast, the row space <inline-formula id="pcbi.1005118.e021"><alternatives><graphic id="pcbi.1005118.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mi mathvariant="script">R</mml:mi></mml:math></alternatives></inline-formula> of <sans-serif>A</sans-serif> contains fluctuations that result in error at the goal and, hence, are <italic>goal relevant</italic>. This 1D space is orthogonal to the GEM, so that <inline-formula id="pcbi.1005118.e022"><alternatives><graphic id="pcbi.1005118.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:mi mathvariant="script">R</mml:mi> <mml:mo>=</mml:mo> <mml:mo form="prefix">span</mml:mo> <mml:mo>{</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1005118.e023"><alternatives><graphic id="pcbi.1005118.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula> is the unit normal to the GEM given by
<disp-formula id="pcbi.1005118.e024"><alternatives><graphic id="pcbi.1005118.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e024" xlink:type="simple"/><mml:math display="block" id="M24"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>v</mml:mi> <mml:mo>*</mml:mo></mml:msup></mml:mrow> <mml:mi>μ</mml:mi></mml:mfrac></mml:mfenced> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mfrac> <mml:mfenced close=")" open="("><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>v</mml:mi> <mml:mo>*</mml:mo></mml:msup></mml:mrow> <mml:mi>μ</mml:mi></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(6)</label></disp-formula>
Given a fluctuation <bold>u</bold> from the operating point <bold>x</bold>*, its goal-relevant and goal-equivalent components are found using the inner products
<disp-formula id="pcbi.1005118.e025"><alternatives><graphic id="pcbi.1005118.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e025" xlink:type="simple"/><mml:math display="block" id="M25"><mml:mrow><mml:msub><mml:mi>u</mml:mi> <mml:mi mathvariant="script">R</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>·</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub> <mml:mspace width="1.em"/><mml:mtext>and</mml:mtext> <mml:mspace width="1.em"/><mml:msub><mml:mi>u</mml:mi> <mml:mi mathvariant="script">N</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>·</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula>
respectively. Using these, one can readily compute from observations the sample standard deviations of goal-relevant and goal-equivalent fluctuations, <inline-formula id="pcbi.1005118.e026"><alternatives><graphic id="pcbi.1005118.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:msub><mml:mi>σ</mml:mi> <mml:mi mathvariant="script">R</mml:mi></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005118.e027"><alternatives><graphic id="pcbi.1005118.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:msub><mml:mi>σ</mml:mi> <mml:mi mathvariant="script">N</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, respectively.</p>
<p>The singular values of the body-goal matrix <sans-serif>A</sans-serif> determine how fluctuations <bold>u</bold> get amplified onto the target [<xref ref-type="bibr" rid="pcbi.1005118.ref014">14</xref>], and so determine the <italic>sensitivity</italic> of the performance to body-level errors. Since the sensitivity depends only on the goal function, it is independent of any specific inter-trial control mechanism, and so is considered to be a <italic>passive</italic> property of the task. For the shuffleboard game, <sans-serif>A</sans-serif> has one singular value <italic>s</italic>, which is given by [<xref ref-type="bibr" rid="pcbi.1005118.ref031">31</xref>]
<disp-formula id="pcbi.1005118.e028"><alternatives><graphic id="pcbi.1005118.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e028" xlink:type="simple"/><mml:math display="block" id="M28"><mml:mrow><mml:mi>s</mml:mi> <mml:mo>=</mml:mo> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>v</mml:mi> <mml:mo>*</mml:mo></mml:msup></mml:mrow> <mml:mi>μ</mml:mi></mml:mfrac></mml:mfenced> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(8)</label></disp-formula>
Thus, the passive sensitivity is a function of the friction coefficient, <italic>μ</italic>, and the speed at the operating point, <italic>v</italic>*, with the latter indicating that <italic>s</italic> is not constant along the GEM. Given <italic>s</italic>, <xref ref-type="disp-formula" rid="pcbi.1005118.e015">Eq (4)</xref> can then be used to obtain the RMS goal-level error as
<disp-formula id="pcbi.1005118.e029"><alternatives><graphic id="pcbi.1005118.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mrow><mml:msub><mml:mi>σ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>s</mml:mi> <mml:msub><mml:mi>σ</mml:mi> <mml:mi mathvariant="script">R</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula>
which is a special case of the general expression obtained in [<xref ref-type="bibr" rid="pcbi.1005118.ref014">14</xref>]. Thus, the passive sensitivity “explains” the goal level error, but only when the goal-relevant fluctuations are taken as given. However, the scale of those fluctuations, <inline-formula id="pcbi.1005118.e030"><alternatives><graphic id="pcbi.1005118.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:msub><mml:mi>σ</mml:mi> <mml:mi mathvariant="script">R</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, is itself determined by the active process of inter-trial error correction.</p>
</sec>
<sec id="sec005">
<title>Modeling Inter-Trial Fluctuations</title>
<p>As discussed previously, the GEM and body-goal sensitivity are passive properties of the task that exist prior to the imposition of any error-correcting control. Here, we “close the loop” on the problem by discussing simple perception-action models of inter-trial error correction. For clarity, we present our modeling framework with a bit more generality than will ultimately be needed. Additional background and details can be found in [<xref ref-type="bibr" rid="pcbi.1005118.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>].</p>
<p>A typical experiment for a goal-directed task with <italic>N</italic> trials results in a time series of the body state variable, <inline-formula id="pcbi.1005118.e031"><alternatives><graphic id="pcbi.1005118.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, and a corresponding time series of goal-level errors, <inline-formula id="pcbi.1005118.e032"><alternatives><graphic id="pcbi.1005118.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>e</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>. We consider these time series to result from the process of error-correction used by participants as they make adjustments after each trial, and model the fluctuation dynamics with update equations of the form [<xref ref-type="bibr" rid="pcbi.1005118.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>]:
<disp-formula id="pcbi.1005118.e033"><alternatives><graphic id="pcbi.1005118.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e033" xlink:type="simple"/><mml:math display="block" id="M33"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi mathvariant="sans-serif">G</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="sans-serif">I</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="sans-serif">N</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mfenced> <mml:mi mathvariant="bold">c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">ν</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(10)</label></disp-formula>
in which: <bold>c</bold>(<bold>x</bold><sub><italic>k</italic></sub>) is an inter-trial, error-correcting controller depending on the current state; <sans-serif>N</sans-serif><sub><italic>k</italic></sub> is a matrix representing signal-dependent noise in the motor outputs [<xref ref-type="bibr" rid="pcbi.1005118.ref045">45</xref>]; and <bold><italic>ν</italic></bold><sub><italic>k</italic></sub> is an additive noise vector representing unmodeled effects from perceptual and neuromotor sources. The diagonal matrix of gains, <sans-serif>G</sans-serif>, is included as a convenient way to detune the model away from optimality when <bold>c</bold> is an optimal controller designed initially with <sans-serif>G</sans-serif> = <sans-serif>I</sans-serif> [<xref ref-type="bibr" rid="pcbi.1005118.ref026">26</xref>].</p>
<p>Error-correcting models with mathematical form similar to <xref ref-type="disp-formula" rid="pcbi.1005118.e033">Eq (10)</xref> have been used to study motor learning [<xref ref-type="bibr" rid="pcbi.1005118.ref046">46</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref048">48</xref>] and to understand the effect of motor noise. These previous efforts have not focused on the role of task level redundancy, or attempted to relate body-level fluctuations to those at some external goal, as we do here. However, in contrast to these previous studies, we do not make reference to hidden internal state variables related, for example, to motor planning, but instead construct our models at the level of experimentally-observable task-relevant kinematic variables. As a consequence, our models cannot be used to disambiguate the effect of noise due to motor planning from that due to motor execution [<xref ref-type="bibr" rid="pcbi.1005118.ref046">46</xref>]. Our focus here is not on how internal “neuronal” state variables are dynamically mapped to kinematic output variables, but rather how the body-level task variables are mapped onto the goal-level task error in the presence of redundancy. Hence, our study takes place at a different level of description than studies aimed at understanding the physiological origin of motor noise and its role in motor learning. Models with the general form of <xref ref-type="disp-formula" rid="pcbi.1005118.e033">Eq (10)</xref> can be viewed as the <italic>between</italic>-trial component of a hierarchical motor regulation scheme that makes error-correcting adjustments to an approximately “feed forward,” <italic>within</italic>-trial component.</p>
<p>Focusing once again on skilled movements, we write <bold>x</bold><sub><italic>k</italic></sub> = <bold>x</bold>* + <bold>u</bold><sub><italic>k</italic></sub> as was done leading up to <xref ref-type="disp-formula" rid="pcbi.1005118.e015">Eq (4)</xref>, where <bold>u</bold><sub><italic>k</italic></sub> are small perturbations from the operating point <bold>x</bold>*. Assuming, in addition, small noise terms <sans-serif>N</sans-serif><sub><italic>k</italic></sub> and <bold><italic>ν</italic></bold><sub><italic>k</italic></sub>, we can linearize the controller <xref ref-type="disp-formula" rid="pcbi.1005118.e033">Eq (10)</xref> [<xref ref-type="bibr" rid="pcbi.1005118.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>] about <bold>u</bold><sub><italic>k</italic></sub> = 0 to obtain:
<disp-formula id="pcbi.1005118.e034"><alternatives><graphic id="pcbi.1005118.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e034" xlink:type="simple"/><mml:math display="block" id="M34"><mml:mrow><mml:msub><mml:mi mathvariant="bold">u</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mi mathvariant="sans-serif">B</mml:mi> <mml:msub><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">ν</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(11)</label></disp-formula>
where the matrix <sans-serif>B</sans-serif> = <sans-serif>I</sans-serif>+<sans-serif>GJ</sans-serif>, and <sans-serif>J</sans-serif> = ∂<bold>c</bold>/∂<bold>x</bold> is the Jacobian of the controller evaluated at <bold>x</bold>*. Note that, to leading order, signal dependent noise does not affect the inter-trial dynamics near the GEM [<xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>]. Thus, small fluctuations are governed by the linear map of <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>, and the eigenvalues and eigenvectors of <sans-serif>B</sans-serif> determine the local dynamic stability properties of the system [<xref ref-type="bibr" rid="pcbi.1005118.ref044">44</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref050">50</xref>]. Specifically, eigenvalues <italic>λ</italic> with magnitude near zero (|<italic>λ</italic>|≈0) indicate that deviations from the GEM are rapidly corrected, whereas positive eigenvalues strictly less than but closer to one (0 ≪ <italic>λ</italic> &lt; 1) indicate that deviations are only weakly corrected (that is, they are allowed to “persist”). Note that values of <italic>λ</italic> &gt; 1 indicate instability, indicating that deviations would continue to grow in successive trials, something that is not expected in experiments. For the shuffleboard task, the body states are 2-dimensional, so that <sans-serif>B</sans-serif> is a 2 × 2 matrix possessing two eigenvalues, {<italic>λ</italic><sub><italic>w</italic></sub>, <italic>λ</italic><sub><italic>s</italic></sub>}, and two eigenvectors, <inline-formula id="pcbi.1005118.e035"><alternatives><graphic id="pcbi.1005118.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mo>{</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>w</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>s</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:math></alternatives></inline-formula>, where the subscripts <italic>w</italic> and <italic>s</italic> indicate weakly and strongly stable directions, as described below. We limit our discussion to the case of real, distinct eigenvalues, which has been found to be sufficient in experimental applications to date.</p>
<p>In [<xref ref-type="bibr" rid="pcbi.1005118.ref026">26</xref>], <bold>c</bold> was found analytically as an optimal controller using different specified cost functions. Because goal-level error was minimized as a cost, the goal function (which, for the current paper, is given by <xref ref-type="disp-formula" rid="pcbi.1005118.e008">Eq 2</xref>) was built into the model, and so the effect of the GEM was explicitly included. In studies of this type, the model is used to generate simulated data, which is then statistically compared to experimental data to “reverse engineer” the controller used by human participants. Furthermore, if one wishes to study local stability properties via <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>, the matrix <sans-serif>B</sans-serif> can, in principle, be obtained analytically by differentiation.</p>
<p>In contrast, in this work we take a simpler, empirical approach: instead of formulating an explicit optimal controller, linear regression is used to estimate the matrix <sans-serif>B</sans-serif> of <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref> directly from the experimental fluctuation data. The eigenstructure of the estimated <sans-serif>B</sans-serif> is then obtained and compared to the geometry of the shuffleboard GEM (<xref ref-type="fig" rid="pcbi.1005118.g002">Fig 2</xref>). Thus, other than the assumption of closeness to an operating point <inline-formula id="pcbi.1005118.e036"><alternatives><graphic id="pcbi.1005118.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">G</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> (i.e., of linearity), the controller is not assumed to to be optimal, nor is the GEM encoded into it in any way. Thus, any structure in the data related to the presence of the GEM is a property of the observed fluctuation dynamics: it has not been imposed by the model.</p>
</sec>
<sec id="sec006">
<title>Relating Fluctuations at Body and Goal Levels</title>
<p>Task manifold methods applied to a variety of motor tasks have shown that the body-level variability observed during skilled task execution will tend to have greater variance along the task manifold than normal to it. Indeed, anisotropy in the variability is typically taken to demonstrate that a hypothesized task manifold is being used to organize motor control [<xref ref-type="bibr" rid="pcbi.1005118.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref016">16</xref>]. Such results are consistent with a generalized interpretation of the UCM hypothesis and the MIP: namely, that while disturbances along the task manifold are not truly “uncontrolled”, they are, at least, more <italic>weakly</italic> controlled than those normal to it. However, movement variability may be “structured” (i.e., may exhibit anisotropy) for biomechanical and/or neurophysiological reasons that are unrelated to control [<xref ref-type="bibr" rid="pcbi.1005118.ref036">36</xref>]. In addition, variance-based analyses are vulnerable to ambiguities related to the coordinate dependence of variability statistics [<xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref040">40</xref>], and by themselves do not provide any insight into how observed fluctuations are dynamically generated and regulated [<xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref051">51</xref>].</p>
<p>A number of researchers have addressed this last limitation by combining task manifold ideas with time series analysis of statistical persistence [<xref ref-type="bibr" rid="pcbi.1005118.ref025">25</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref051">51</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref054">54</xref>], as measured either via detrended fluctuation analysis (DFA) [<xref ref-type="bibr" rid="pcbi.1005118.ref055">55</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref056">56</xref>] or autocorrelations. Generally speaking, a time series exhibits statistical persistence if, given fluctuations in one direction, subsequent fluctuations are likely to be in the same direction. If subsequent fluctuations are likely to be in the opposite direction, the time series is said to be antipersistent, and if subsequent fluctuations are equally likely to be in either direction the time series is non-persistent or, alternatively, uncorrelated. As was shown in [<xref ref-type="bibr" rid="pcbi.1005118.ref025">25</xref>], the coherent interpretation of persistence results requires the consideration of error-correcting control near the task manifold: there is greater statistical persistence along the manifold, where the control is weak, than perpendicular to it, where the control is strong. These types of results are, again, consistent with a generalized interpretation of the MIP [<xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>].</p>
<p>All of the above-cited studies lead us to expect <italic>dynamical</italic> anisotropy in inter-trial fluctuations. That is, the temporal structure of fluctuations should reflect the operation of a controller that strongly acts against goal-relevant deviations by pushing subsequent body-states toward the GEM, while only weakly acting to correct goal-equivalent deviations along the GEM.</p>
<p>Since in this paper we focus on skilled movements, we make direct use of the linearized model <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>. For an ideal MIP controller, the complete absence of control along the GEM would result in neutral stability along it, as well, meaning that one eigenvector of the matrix <sans-serif>B</sans-serif> (<xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>) would be identical to the unit tangent <inline-formula id="pcbi.1005118.e037"><alternatives><graphic id="pcbi.1005118.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, and its associated eigenvalue would be <italic>λ</italic> = 1. However, such a scenario in the presence of motor noise would result in an unbounded random walk along the GEM, something which has yet to be observed in experiments. Thus, we expect the inter-trial dynamics to be slightly perturbed from what one would expect for a perfect MIP controller, giving one <italic>weakly stable</italic> eigenvalue less than, but somewhat close to, 1 (i.e., 0 ≪ <italic>λ</italic><sub><italic>w</italic></sub> &lt; 1) with an associated unit eigenvector <bold>e</bold><sub><italic>w</italic></sub> that is close to <inline-formula id="pcbi.1005118.e038"><alternatives><graphic id="pcbi.1005118.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, but slightly rotated. In contrast, the <italic>strongly stable</italic> eigenvalue, <italic>λ</italic><sub><italic>s</italic></sub>, indicates vigorous correction of deviations off of the GEM, so that |<italic>λ</italic><sub><italic>s</italic></sub>|≈0 and <bold>e</bold><sub><italic>s</italic></sub> is transverse (but not necessarily perpendicular) to the GEM. The general geometry of the situation, in which local stability properties are overlaid on the GEM near an operating point <bold>x</bold>*, is show schematically in <xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref>.</p>
<fig id="pcbi.1005118.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Schematic showing the goal-equivalent (null) space <inline-formula id="pcbi.1005118.e039"><alternatives><graphic id="pcbi.1005118.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:mi mathvariant="script">N</mml:mi></mml:math></alternatives></inline-formula> and goal-relevant (column) space <inline-formula id="pcbi.1005118.e040"><alternatives><graphic id="pcbi.1005118.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:mi mathvariant="script">R</mml:mi></mml:math></alternatives></inline-formula> of fluctuations about an operating point x* on the GEM, and the relative orientation of the weakly (single arrow) and strongly (double arrow) stable subspaces determined by the eigenvectors of a 2 × 2 matrix <sans-serif>B</sans-serif> (<xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>), as given by angles <italic>θ</italic><sub><italic>w</italic></sub> and <italic>θ</italic><sub><italic>s</italic></sub>, respectively.</title>
<p>Also shown are the coordinate axes of the position and velocity fluctuations, <italic>p</italic> and <italic>q</italic>, respectively. Note that <italic>θ</italic><sub><italic>w</italic></sub> is exaggerated for clarity: we expect <italic>θ</italic><sub><italic>w</italic></sub> ≈ 0. The strongly stable direction is transverse, but not necessarily perpendicular, to the GEM.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.g003" xlink:type="simple"/>
</fig>
<p>The fluctuations <bold>u</bold><sub><italic>k</italic></sub> in the original, laboratory coordinates (e.g., representing speed and position for the shuffleboard game) can be transformed into new fluctuations expressed in eigencoordinates via the linear coordinate transformation
<disp-formula id="pcbi.1005118.e041"><alternatives><graphic id="pcbi.1005118.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e041" xlink:type="simple"/><mml:math display="block" id="M41"><mml:mrow><mml:msub><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi mathvariant="sans-serif">E</mml:mi> <mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(12)</label></disp-formula>
where <sans-serif>E</sans-serif> is the matrix containing <inline-formula id="pcbi.1005118.e042"><alternatives><graphic id="pcbi.1005118.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>w</mml:mi></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005118.e043"><alternatives><graphic id="pcbi.1005118.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>s</mml:mi></mml:msub></mml:math></alternatives></inline-formula> as its columns. Note that <sans-serif>E</sans-serif> is not typically an orthogonal matrix because the eigenvectors of <sans-serif>B</sans-serif> are not usually perpendicular. Using this transformation, <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref> becomes
<disp-formula id="pcbi.1005118.e044"><alternatives><graphic id="pcbi.1005118.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e044" xlink:type="simple"/><mml:math display="block" id="M44"><mml:mrow><mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="sans-serif">E</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi mathvariant="sans-serif">B</mml:mi> <mml:mi mathvariant="sans-serif">E</mml:mi> <mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="sans-serif">E</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msub><mml:mi mathvariant="bold-italic">ν</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>≜</mml:mo> <mml:mi mathvariant="sans-serif">Q</mml:mi> <mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold">n</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(13)</label></disp-formula>
where <bold>z</bold> = (<italic>z</italic><sub><italic>w</italic></sub>, <italic>z</italic><sub><italic>s</italic></sub>)<sup><sans-serif>T</sans-serif></sup> are the fluctuations expressed in weak-strong eigencoordinates, the diagonal matrix <sans-serif>Q</sans-serif> = <sans-serif>E</sans-serif><sup>−1</sup> <sans-serif>BE</sans-serif> has <italic>λ</italic><sub><italic>w</italic></sub> and <italic>λ</italic><sub><italic>s</italic></sub> along its diagonal, and <bold>n</bold> = (<italic>n</italic><sub><italic>w</italic></sub>, <italic>n</italic><sub><italic>s</italic></sub>)<sup><sans-serif>T</sans-serif></sup> is the transformed additive noise term. That is, the transformation <xref ref-type="disp-formula" rid="pcbi.1005118.e041">Eq (12)</xref> decouples the dynamics in the weak and strong directions so that <xref ref-type="disp-formula" rid="pcbi.1005118.e044">Eq (13)</xref> can be written as
<disp-formula id="pcbi.1005118.e045"><alternatives><graphic id="pcbi.1005118.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e045" xlink:type="simple"/><mml:math display="block" id="M45"><mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>w</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></alternatives> <label>(14)</label></disp-formula> <disp-formula id="pcbi.1005118.e046"><alternatives><graphic id="pcbi.1005118.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e046" xlink:type="simple"/><mml:math display="block" id="M46"><mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>s</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo></mml:math></alternatives> <label>(15)</label></disp-formula>
in which <italic>z</italic><sub><italic>w</italic>, <italic>k</italic></sub> and <italic>z</italic><sub><italic>s</italic>, <italic>k</italic></sub> are simply the components of <bold>z</bold><sub><italic>k</italic></sub> in the weak and strong directions, respectively. This “diagonalized” form of the system illustrates the action of each eigenvalue on fluctuations in their respective directions: in the absence of noise an eigenvalue close to zero will eliminate a given fluctuation on the very next trial, whereas a positive eigenvalue a bit less than 1 will allow fluctuations to persist over many trials. The decomposition of Eqs <xref ref-type="disp-formula" rid="pcbi.1005118.e045">(14)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005118.e046">(15)</xref> is intrinsic to the fluctuation dynamics created by inter-trial error correction, and so differs significantly from “static” decompositions using, for example, the normal and tangent to the GEM, or principal component analysis [<xref ref-type="bibr" rid="pcbi.1005118.ref042">42</xref>].</p>
<p>From <xref ref-type="disp-formula" rid="pcbi.1005118.e025">Eq (7)</xref> and the transformation <xref ref-type="disp-formula" rid="pcbi.1005118.e041">Eq (12)</xref> we can relate the standard deviations of fluctuations in the goal-relevant and strongly-stable directions as
<disp-formula id="pcbi.1005118.e047"><alternatives><graphic id="pcbi.1005118.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e047" xlink:type="simple"/><mml:math display="block" id="M47"><mml:mrow><mml:msub><mml:mi>u</mml:mi> <mml:mi mathvariant="script">R</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub> <mml:mo>·</mml:mo> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>=</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub> <mml:mo>·</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>z</mml:mi> <mml:mi>w</mml:mi></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>w</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>s</mml:mi></mml:msub></mml:mfenced> <mml:mo>≈</mml:mo> <mml:mi>β</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mspace width="1.em"/><mml:mo>⟹</mml:mo> <mml:mspace width="1.em"/><mml:msub><mml:mi>σ</mml:mi> <mml:mi mathvariant="script">R</mml:mi></mml:msub> <mml:mo>≈</mml:mo> <mml:mi>β</mml:mi> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(16)</label></disp-formula>
where <inline-formula id="pcbi.1005118.e048"><alternatives><graphic id="pcbi.1005118.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e048" xlink:type="simple"/><mml:math display="inline" id="M48"><mml:mrow><mml:mi>β</mml:mi><mml:mtext> </mml:mtext><mml:mo>≜</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub> <mml:mspace width="-0.166667em"/><mml:mo>·</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>s</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mo form="prefix">sin</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> (see <xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref>) and we have assumed, consistent with a generalized MIP, that the weakly stable direction is nearly tangent to the GEM, so that <inline-formula id="pcbi.1005118.e049"><alternatives><graphic id="pcbi.1005118.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e049" xlink:type="simple"/><mml:math display="inline" id="M49"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>w</mml:mi></mml:msub> <mml:mo>≈</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>⇒</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub> <mml:mspace width="-0.166667em"/><mml:mo>·</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>w</mml:mi></mml:msub> <mml:mo>≈</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. Squaring both sides of <xref ref-type="disp-formula" rid="pcbi.1005118.e045">Eq (14)</xref>, taking the ensemble average (as indicated by angle brackets), and assuming that the noise and fluctuations at trial <italic>k</italic> are uncorrelated, yields
<disp-formula id="pcbi.1005118.e050"><alternatives><graphic id="pcbi.1005118.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e050" xlink:type="simple"/><mml:math display="block" id="M50"><mml:mrow><mml:mfenced close="⟩" open="⟨"><mml:msubsup><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>w</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>m</mml:mi> <mml:mi>u</mml:mi></mml:mrow> <mml:mfenced close="⟩" open="⟨"><mml:msubsup><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mo>+</mml:mo> <mml:mfenced close="⟩" open="⟨"><mml:msubsup><mml:mi>n</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mspace width="1.em"/><mml:mo>⟹</mml:mo> <mml:mspace width="1.em"/><mml:msub><mml:mi>σ</mml:mi> <mml:mi>w</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>w</mml:mi></mml:mrow></mml:msub> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>w</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mfrac> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(17)</label></disp-formula>
where <inline-formula id="pcbi.1005118.e051"><alternatives><graphic id="pcbi.1005118.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>w</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>≡</mml:mo> <mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>n</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, and in which we have used the fact that at steady state <inline-formula id="pcbi.1005118.e052"><alternatives><graphic id="pcbi.1005118.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e052" xlink:type="simple"/><mml:math display="inline" id="M52"><mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo> <mml:mo>=</mml:mo> <mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>〉</mml:mo> <mml:mo>≡</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>w</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. A similar calculation with <xref ref-type="disp-formula" rid="pcbi.1005118.e046">Eq (15)</xref> gives
<disp-formula id="pcbi.1005118.e053"><alternatives><graphic id="pcbi.1005118.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e053" xlink:type="simple"/><mml:math display="block" id="M53"><mml:mrow><mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>s</mml:mi></mml:mrow></mml:msub> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mfrac> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(18)</label></disp-formula>
Eqs <xref ref-type="disp-formula" rid="pcbi.1005118.e050">(17)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005118.e053">(18)</xref> show that as the eigenvalues approach 0, the “output” variance of the fluctuations approaches a minimum value equal to the variance of the “input” noise. Conversely, as the eigenvalues approach the stability boundary of 1, the output variance becomes unbounded (i.e., the fluctuations approach the behavior of a random walk).</p>
<p>Finally, substituting from <xref ref-type="disp-formula" rid="pcbi.1005118.e047">Eq (16)</xref> into <xref ref-type="disp-formula" rid="pcbi.1005118.e029">Eq (9)</xref>, using <xref ref-type="disp-formula" rid="pcbi.1005118.e053">Eq (18)</xref>, and rearranging we find
<disp-formula id="pcbi.1005118.e054"><alternatives><graphic id="pcbi.1005118.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e054" xlink:type="simple"/><mml:math display="block" id="M54"><mml:mrow><mml:mfrac><mml:msub><mml:mi>σ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:msub><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mfrac> <mml:mo>≈</mml:mo> <mml:mfrac><mml:mrow><mml:mi>β</mml:mi> <mml:mi>s</mml:mi></mml:mrow> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mfrac><mml:mtext> </mml:mtext><mml:mo>≜</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>s</mml:mi> <mml:mtext>TOT</mml:mtext></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(19)</label></disp-formula>
where <italic>s</italic><sub>TOT</sub> is the <italic>total body-goal sensitivity</italic>, which quantifies how much intrinsic body-level fluctuations are amplified at the goal level. Note that <italic>s</italic><sub>TOT</sub> results from the interaction of the passive sensitivity (via <italic>s</italic>), the local GEM geometry (via <italic>β</italic> = sin<italic>θ</italic><sub><italic>s</italic></sub>) and active control “strength” (via <italic>λ</italic><sub><italic>s</italic></sub>).</p>
</sec>
<sec id="sec007">
<title>Statistical Persistence</title>
<p>Given <italic>z</italic><sub><italic>w</italic></sub> and <italic>z</italic><sub><italic>s</italic></sub> time series from the diagonalized controller of Eqs <xref ref-type="disp-formula" rid="pcbi.1005118.e045">(14)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005118.e046">(15)</xref>, we can compute the normalized lag-1 autocorrelations of the fluctuations in the weak and strong directions as
<disp-formula id="pcbi.1005118.e055"><alternatives><graphic id="pcbi.1005118.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e055" xlink:type="simple"/><mml:math display="block" id="M55"><mml:mrow><mml:msub><mml:mi>R</mml:mi> <mml:mi>w</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mfenced close="⟩" open="⟨" separators=""><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>w</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mspace width="1.em"/><mml:mtext>and</mml:mtext> <mml:mspace width="1.em"/><mml:msub><mml:mi>R</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mfenced close="⟩" open="⟨" separators=""><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(20)</label></disp-formula>
respectively. This provides a simple quantification for the statistical persistence in both directions. However, multiplying <xref ref-type="disp-formula" rid="pcbi.1005118.e045">Eq (14)</xref> by <italic>z</italic><sub><italic>w</italic>, <italic>k</italic></sub>, taking the ensemble average, and assuming the additive noise is uncorrelated with the fluctuations so that 〈(<italic>z</italic><sub><italic>w</italic>, <italic>k</italic></sub>)(<italic>n</italic><sub><italic>w</italic>, <italic>k</italic></sub>)〉 = 0 gives
<disp-formula id="pcbi.1005118.e056"><alternatives><graphic id="pcbi.1005118.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e056" xlink:type="simple"/><mml:math display="block" id="M56"><mml:mrow><mml:mfenced close="⟩" open="⟨" separators=""><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mo>=</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>w</mml:mi></mml:msub> <mml:mfenced close="⟩" open="⟨" separators=""><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mo>≡</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>w</mml:mi></mml:msub> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>w</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(21)</label></disp-formula>
Solving for <italic>λ</italic><sub><italic>w</italic></sub> in the above and comparing it to the definition <italic>R</italic><sub><italic>w</italic></sub>(1) in <xref ref-type="disp-formula" rid="pcbi.1005118.e055">Eq (20)</xref>, we see that <italic>R</italic><sub><italic>w</italic></sub>(1) ≡ <italic>λ</italic><sub><italic>w</italic></sub>. Likewise, a similar calculation with <xref ref-type="disp-formula" rid="pcbi.1005118.e046">Eq (15)</xref> shows <italic>R</italic><sub><italic>s</italic></sub>(1) ≡ <italic>λ</italic><sub><italic>s</italic></sub>. Thus, as a persistence measure the normalized lag-1 autocorrelation does not, theoretically speaking, provide information distinct from the eigenvalues <italic>λ</italic><sub><italic>w</italic></sub> and <italic>λ</italic><sub><italic>s</italic></sub>. We include it here to demonstrate the connection between stability and this simple persistence measure. We use it later, as well, to serve as a consistency check on our experimental eigenvalue estimates.</p>
<p>To test for statistical persistence with a method independent from the eigenanalysis, one can apply detrended fluctuation analysis (DFA) [<xref ref-type="bibr" rid="pcbi.1005118.ref055">55</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref056">56</xref>] with linear detrending to the <italic>z</italic><sub><italic>w</italic></sub> and <italic>z</italic><sub><italic>s</italic></sub> time series. The DFA algorithm yields a positive exponent, <italic>α</italic>, where <italic>α</italic> &lt; 0.5 indicates antipersistence in a time series, <italic>α</italic> &gt; 0.5 indicates persistence and <italic>α</italic> = 0.5 indicates non-persistence. Contrary to its most common use in the literature, in this work we <italic>are not</italic> using DFA to claim that observed fluctuations exhibit <italic>long-range</italic> persistence, but instead employ <italic>α</italic> merely as a convenient overall measure of persistence that, unlike the autocorrelation, does not require consideration of specific lags. Additional discussion regarding the application of DFA to movement variability data can be found in [<xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>], including a review of its vulnerability to false positives when testing for long-range persistence [<xref ref-type="bibr" rid="pcbi.1005118.ref057">57</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref059">59</xref>].</p>
</sec>
<sec id="sec008">
<title>Coordinate Invariance</title>
<p>In this subsection we show how the dynamical analysis of inter-trial fluctuations allows us to characterize observed variability in a way that is insensitive to the choice of coordinates. Starting with some original body state variable <bold>x</bold>, consider a new variable <bold>y</bold> of the same dimension as <bold>x</bold>, with each being related by a general differentiable, invertible coordinate transformation <bold>x</bold> = <bold>g</bold>(<bold>y</bold>). Thus, the operating point expressed for each choice of coordinates is related by <bold>x</bold>* = <bold>g</bold>(<bold>y</bold>*), and we find that small fluctuations are related to lowest order by a linear transformation from:
<disp-formula id="pcbi.1005118.e057"><alternatives><graphic id="pcbi.1005118.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e057" xlink:type="simple"/><mml:math display="block" id="M57"><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">g</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">y</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:mi mathvariant="bold">g</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">y</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi mathvariant="sans-serif">T</mml:mi> <mml:msub><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="1.em"/><mml:mo>⟹</mml:mo> <mml:mspace width="1.em"/><mml:msub><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi mathvariant="sans-serif">T</mml:mi> <mml:msub><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(22)</label></disp-formula>
where <bold>u</bold><sub><italic>k</italic></sub> and <bold>v</bold><sub><italic>k</italic></sub> are the fluctuations expressed in terms of the old and new coordinates, respectively, and <sans-serif>T</sans-serif> is the square Jacobian matrix of the transformation <bold>g</bold> evaluated at <bold>y</bold>*.</p>
<p>Using <xref ref-type="disp-formula" rid="pcbi.1005118.e057">Eq (22)</xref> to substitute for <bold>u</bold><sub><italic>k</italic></sub> into the linearized controller <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref> then gives, in a manner analogous to that used to obtain <xref ref-type="disp-formula" rid="pcbi.1005118.e044">Eq (13)</xref>:
<disp-formula id="pcbi.1005118.e058"><alternatives><graphic id="pcbi.1005118.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e058" xlink:type="simple"/><mml:math display="block" id="M58"><mml:mrow><mml:msub><mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="sans-serif">T</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi mathvariant="sans-serif">B</mml:mi> <mml:mi mathvariant="sans-serif">T</mml:mi> <mml:msub><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msup><mml:mi mathvariant="sans-serif">T</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msub><mml:mi mathvariant="bold-italic">ν</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(23)</label></disp-formula>
Clearly, the matrix <sans-serif>T</sans-serif><sup>−1</sup><sans-serif>BT</sans-serif> on the right-hand side of the above equation is congruent to the original <sans-serif>B</sans-serif>, and so will have the same eigenvalues, and, hence, the same stability properties.</p>
<p>As discussed in [<xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>], the GEM itself is transformed when using the new coordinates. Recall from the discussion prior to <xref ref-type="disp-formula" rid="pcbi.1005118.e019">Eq (5)</xref> that the tangent to the GEM is determined from the null space of the Jacobian to the goal function, <sans-serif>A</sans-serif>. That is, to leading order the fluctuation <bold>u</bold><sub><italic>k</italic></sub> is on the GEM whenever <sans-serif>A</sans-serif><bold>u</bold><sub><italic>k</italic></sub> = 0. However, again using the transformation <xref ref-type="disp-formula" rid="pcbi.1005118.e057">Eq (22)</xref>, we see that <sans-serif>A</sans-serif><bold>u</bold><sub><italic>k</italic></sub> = <sans-serif>AT</sans-serif><bold>v</bold><sub><italic>k</italic></sub>, showing that whenever <bold>u</bold><sub><italic>k</italic></sub> is on the GEM expressed in terms of the original coordinates, <bold>v</bold><sub><italic>k</italic></sub> is on the GEM expressed using the new coordinates. Thus, not only are the stability properties unaffected by coordinate transformations, the eigenvectors and GEM are transformed in a predictable way that preserves the topology near the operating point: that is, while changing coordinates will typically rotate and shear the picture somewhat, the overall arrangement illustrated in <xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref> is preserved.</p>
</sec>
<sec id="sec009">
<title>Experimental Hypotheses</title>
<p>Following the above discussion, we are led to the following four theoretical predictions, presented here as experimental hypotheses, which we here simply state directly. Additional computational details, as required to test the hypotheses, are presented in the Data Analysis section below. As a convenience to the reader, <xref ref-type="table" rid="pcbi.1005118.t001">Table 1</xref> contains a glossary of the key symbols used in stating the hypotheses.</p>
<list list-type="simple">
<list-item>
<p><bold>H1</bold> Consistent with the hypothesis of weak control along the GEM, one of the eigenvectors, <inline-formula id="pcbi.1005118.e059"><alternatives><graphic id="pcbi.1005118.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e059" xlink:type="simple"/><mml:math display="inline" id="M59"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>w</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, of the matrix <sans-serif>B</sans-serif> in <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref> will be nearly tangent to the GEM. That is, the weakly stable subspace, <inline-formula id="pcbi.1005118.e060"><alternatives><graphic id="pcbi.1005118.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e060" xlink:type="simple"/><mml:math display="inline" id="M60"><mml:mrow><mml:mo form="prefix">span</mml:mo> <mml:mo>{</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>w</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, will make an angle with the GEM of <inline-formula id="pcbi.1005118.e061"><alternatives><graphic id="pcbi.1005118.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e061" xlink:type="simple"/><mml:math display="inline" id="M61"><mml:mrow><mml:msub><mml:mi>θ</mml:mi> <mml:mi>w</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mo form="prefix">cos</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>·</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>w</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> (see <xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref>). Furthermore, the corresponding eigenvalue, <italic>λ</italic><sub><italic>w</italic></sub>, will be well above 0, but less than 1 (i.e., 0 ≪ <italic>λ</italic><sub><italic>w</italic></sub> &lt; 1).</p>
</list-item>
<list-item>
<p><bold>H2</bold> In contrast, the fluctuation dynamics transverse to the GEM will be strongly stable: i.e., the eigenvalue <italic>λ</italic><sub><italic>s</italic></sub> satisfies 0 ≈ |<italic>λ</italic><sub><italic>s</italic></sub>| ≪ <italic>λ</italic><sub><italic>w</italic></sub>. The associated eigenvector, <inline-formula id="pcbi.1005118.e062"><alternatives><graphic id="pcbi.1005118.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e062" xlink:type="simple"/><mml:math display="inline" id="M62"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>s</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, and the strongly stable subspace <inline-formula id="pcbi.1005118.e063"><alternatives><graphic id="pcbi.1005118.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e063" xlink:type="simple"/><mml:math display="inline" id="M63"><mml:mrow><mml:mo form="prefix">span</mml:mo> <mml:mo>{</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>s</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, will be transverse (i.e., not tangent) to the GEM, but they need not be normal to it. That is, for <inline-formula id="pcbi.1005118.e064"><alternatives><graphic id="pcbi.1005118.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e064" xlink:type="simple"/><mml:math display="inline" id="M64"><mml:mrow><mml:msub><mml:mi>θ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mo form="prefix">cos</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>·</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>s</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> we expect 0 ≈ <italic>θ</italic><sub><italic>w</italic></sub> ≪ <italic>θ</italic><sub><italic>s</italic></sub> (again, refer to <xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref>).</p>
</list-item>
<list-item>
<p><bold>H3</bold> We expect the statistical persistence properties of the inter-trial fluctuations to be consistent with the stability properties of <bold>H1</bold> and <bold>H2</bold>. That is, the fluctuations in the weakly stable subspace will tend to persist over many trials, whereas those in the strongly stable direction will be corrected rapidly so that what remains is closely approximated by uncorrelated “white noise”. We characterize statistical persistence two ways: via the normalized lag-1 autocorrelation <italic>R</italic>(1), and via the exponent <italic>α</italic> from detrended fluctuation analysis (DFA). From <xref ref-type="disp-formula" rid="pcbi.1005118.e055">Eq (20)</xref> and the subsequent discussion, we expect 0 ≈ |<italic>R</italic><sub><italic>s</italic></sub>(1)| ≪ <italic>R</italic><sub><italic>w</italic></sub>(1), whereas we expect the DFA exponents to satisfy 0.5 ≈ <italic>α</italic><sub><italic>s</italic></sub> ≪ <italic>α</italic><sub><italic>w</italic></sub>.</p>
</list-item>
<list-item>
<p><bold>H4</bold> For skilled performers we expect <inline-formula id="pcbi.1005118.e065"><alternatives><graphic id="pcbi.1005118.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e065" xlink:type="simple"/><mml:math display="inline" id="M65"><mml:mrow><mml:msub><mml:mi>σ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:mo>/</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi mathvariant="script">R</mml:mi></mml:msub> <mml:mo>≈</mml:mo> <mml:mi>s</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1005118.e029">Eq (9)</xref>), where the passive sensitivity <italic>s</italic> is the singular value of <sans-serif>A</sans-serif> at <bold>x</bold>* (<xref ref-type="disp-formula" rid="pcbi.1005118.e028">Eq (8)</xref>), <italic>σ</italic><sub><italic>e</italic></sub> is the standard deviation of goal-level fluctuations (i.e., RMS error), and <inline-formula id="pcbi.1005118.e066"><alternatives><graphic id="pcbi.1005118.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e066" xlink:type="simple"/><mml:math display="inline" id="M66"><mml:msub><mml:mi>σ</mml:mi> <mml:mi mathvariant="script">R</mml:mi></mml:msub></mml:math></alternatives></inline-formula> is the standard deviation of goal-relevant fluctuations (<xref ref-type="disp-formula" rid="pcbi.1005118.e025">Eq (7)</xref>). Combining this with local geometric stability analysis leads to the prediction that the goal-level error will scale with the intrinsic body-level noise according to <xref ref-type="disp-formula" rid="pcbi.1005118.e054">Eq (19)</xref>, repeated here for convenience:
<disp-formula id="pcbi.1005118.e067"><alternatives><graphic id="pcbi.1005118.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e067" xlink:type="simple"/><mml:math display="block" id="M67"><mml:mrow><mml:mfrac><mml:msub><mml:mi>σ</mml:mi> <mml:mi>e</mml:mi></mml:msub> <mml:msub><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mfrac> <mml:mo>≈</mml:mo> <mml:mfrac><mml:mrow><mml:mi>β</mml:mi> <mml:mi>s</mml:mi></mml:mrow> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mfrac><mml:mtext> </mml:mtext><mml:mo>≜</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>s</mml:mi> <mml:mtext>TOT</mml:mtext></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
where <italic>σ</italic><sub><italic>ns</italic></sub> is the RMS value of the component of additive noise <bold><italic>ν</italic></bold> in the strongly-stable direction, <italic>β</italic> = sin(<italic>θ</italic><sub><italic>s</italic></sub>) (<xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref>), and <italic>s</italic> is the passive sensitivity. For the shuffleboard task, <italic>s</italic> = <italic>s</italic>(<italic>μ</italic>), from <xref ref-type="disp-formula" rid="pcbi.1005118.e028">Eq (8)</xref>.</p>
</list-item>
</list>
<table-wrap id="pcbi.1005118.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.t001</object-id>
<label>Table 1</label>
<caption>
<title>Glossary of key symbols used in the statement of hypotheses H1–H4.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005118.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Symbol</th>
<th align="center">Meaning</th>
<th align="center">Where defined</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">
<inline-formula id="pcbi.1005118.e068">
<alternatives>
<graphic id="pcbi.1005118.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e068" xlink:type="simple"/>
<mml:math display="inline" id="M68">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="bold">e</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>t</mml:mi>
</mml:msub>
</mml:math>
</alternatives>
</inline-formula>, <inline-formula id="pcbi.1005118.e069"><alternatives><graphic id="pcbi.1005118.e069g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e069" xlink:type="simple"/><mml:math display="inline" id="M69"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula></td>
<td align="left">Unit vectors tangent and normal to the GEM</td>
<td align="center">Eqs <xref ref-type="disp-formula" rid="pcbi.1005118.e019">(5)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005118.e024">(6)</xref></td>
</tr>
<tr>
<td align="left">
<sans-serif>B</sans-serif>
</td>
<td align="left">2 × 2 matrix of linearized state update equation</td>
<td align="center">
<xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>
</td>
</tr>
<tr>
<td align="left"><italic>λ</italic><sub><italic>w</italic></sub>, <italic>λ</italic><sub><italic>s</italic></sub></td>
<td align="left">Eigenvalues of <sans-serif>B</sans-serif> indicating weak and strong regulation of fluctuations near GEM</td>
<td align="center">
<xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref> ff.</td>
</tr>
<tr>
<td align="left">
<inline-formula id="pcbi.1005118.e070">
<alternatives>
<graphic id="pcbi.1005118.e070g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e070" xlink:type="simple"/>
<mml:math display="inline" id="M70">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="bold">e</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>w</mml:mi>
</mml:msub>
</mml:math>
</alternatives>
</inline-formula>, <inline-formula id="pcbi.1005118.e071"><alternatives><graphic id="pcbi.1005118.e071g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e071" xlink:type="simple"/><mml:math display="inline" id="M71"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>s</mml:mi></mml:msub></mml:math></alternatives></inline-formula></td>
<td align="left">Eigenvectors of <sans-serif>B</sans-serif> showing the weakly and strongly stable directions of inter-trial regulation</td>
<td align="center">
<xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref> ff.</td>
</tr>
<tr>
<td align="left"><italic>θ</italic><sub><italic>w</italic></sub>, <italic>θ</italic><sub><italic>s</italic></sub></td>
<td align="left">Angle between weak and strong eigenvectors of <sans-serif>B</sans-serif> and tangent to the GEM</td>
<td align="center">
<xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref>
</td>
</tr>
<tr>
<td align="left"><italic>R</italic><sub><italic>w</italic></sub>(1), <italic>R</italic><sub><italic>s</italic></sub>(1)</td>
<td align="left">Lag-1 autocorrelations of weak and strong components of the body-level fluctuation time series</td>
<td align="center">
<xref ref-type="disp-formula" rid="pcbi.1005118.e055">Eq (20)</xref>
</td>
</tr>
<tr>
<td align="left"><italic>α</italic><sub><italic>w</italic></sub>, <italic>α</italic><sub><italic>s</italic></sub></td>
<td align="left">DFA exponents of weak and strong components of body-level fluctuation time series</td>
<td align="center">
<xref ref-type="disp-formula" rid="pcbi.1005118.e056">Eq (21)</xref> ff.</td>
</tr>
<tr>
<td align="left">
<sans-serif>A</sans-serif>
</td>
<td align="left">1 × 2 Jacobian of goal function evaluated at mean operating point (the body-goal variability matrix)</td>
<td align="center">
<xref ref-type="disp-formula" rid="pcbi.1005118.e015">Eq (4)</xref>
</td>
</tr>
<tr>
<td align="left"><italic>s</italic></td>
<td align="left">Singular value of <sans-serif>A</sans-serif> (passive sensitivity to fluctuations near the GEM)</td>
<td align="center">
<xref ref-type="disp-formula" rid="pcbi.1005118.e028">Eq (8)</xref>
</td>
</tr>
<tr>
<td align="left"><italic>σ</italic><sub><italic>e</italic></sub></td>
<td align="left">Standard deviation of goal-level fluctuations (RMS task error)</td>
<td align="center">
<xref ref-type="disp-formula" rid="pcbi.1005118.e029">Eq (9)</xref>
</td>
</tr>
<tr>
<td align="left">
<inline-formula id="pcbi.1005118.e072">
<alternatives>
<graphic id="pcbi.1005118.e072g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e072" xlink:type="simple"/>
<mml:math display="inline" id="M72">
<mml:msub>
<mml:mi>σ</mml:mi>
<mml:mi mathvariant="script">R</mml:mi>
</mml:msub>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left">Standard deviation of fluctuations normal to the GEM (RMS goal-relevant fluctuations)</td>
<td align="center">
<xref ref-type="disp-formula" rid="pcbi.1005118.e029">Eq (9)</xref>
</td>
</tr>
<tr>
<td align="left"><italic>σ</italic><sub><italic>ns</italic></sub>, <italic>σ</italic><sub><italic>nw</italic></sub></td>
<td align="left">Standard deviations of the component of additive noise in the strongly and weakly stable directions.</td>
<td align="center"><xref ref-type="disp-formula" rid="pcbi.1005118.e050">Eq (17)</xref> ff.</td>
</tr>
<tr>
<td align="left"><italic>β</italic></td>
<td align="left">sin(<italic>θ</italic><sub><italic>s</italic></sub>)</td>
<td align="center">
<xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref>
</td>
</tr>
<tr>
<td align="left">
<inline-formula id="pcbi.1005118.e073">
<alternatives>
<graphic id="pcbi.1005118.e073g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e073" xlink:type="simple"/>
<mml:math display="inline" id="M73">
<mml:msub>
<mml:mi>s</mml:mi>
<mml:mtext>TOT</mml:mtext>
</mml:msub>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left">Total body-goal sensitivity</td>
<td align="center">
<xref ref-type="disp-formula" rid="pcbi.1005118.e054">Eq (19)</xref>
</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p specific-use="continuation">Hypotheses <bold>H1</bold>–<bold>H3</bold> can be tested directly by examining the eigenstructure of the matrix <sans-serif>B</sans-serif> in <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>. They are dynamical consequences of the more general hypothesis that <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref> is derived from a “GEM aware” controller, and hence strives to eliminate goal-relevant deviations quickly, after only one trial, while allowing goal-equivalent deviations to persist for multiple trials. In contrast, hypothesis <bold>H4</bold> emphasizes how the overall goal-level performance (as measured by <italic>σ</italic><sub><italic>e</italic></sub>) will result from the interaction between the strongly-stable component of the intrinsic “input” noise (measured by <italic>σ</italic><sub><italic>ns</italic></sub>), inter-trial error correction, and passive sensitivity.</p>
<p>The total body-goal sensitivity, <italic>s</italic><sub>TOT</sub>, is an overall “gain” between body-level noise and goal-level error. We expect <italic>λ</italic><sub><italic>s</italic></sub> ≈ 0, and <italic>β</italic> = sin(<italic>θ</italic><sub><italic>s</italic></sub>)&lt;1 (<xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref>). Thus, <inline-formula id="pcbi.1005118.e074"><alternatives><graphic id="pcbi.1005118.e074g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e074" xlink:type="simple"/><mml:math display="inline" id="M74"><mml:mrow><mml:mi>β</mml:mi> <mml:mo>/</mml:mo> <mml:msqrt><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>, which is the “active factor” of <italic>s</italic><sub>TOT</sub> will have a value on the order of unity. In contrast, the “passive factor” of <italic>s</italic><sub>TOT</sub>, which is simply the passive sensitivity <italic>s</italic> (<xref ref-type="disp-formula" rid="pcbi.1005118.e028">Eq (8)</xref>), may be substantially greater than unity. Thus, a somewhat counterintuitive effect of error-correcting control is that the passive sensitivity, which is determined by task properties <italic>independent</italic> from control, may play a dominant role in determining motor performance at the goal level.</p>
</sec>
<sec id="sec010">
<title>Experimental Apparatus and Protocol</title>
<p>
<xref ref-type="fig" rid="pcbi.1005118.g004">Fig 4</xref> shows a schematic representation of the experimental set-up for the shuffleboard game in a virtual environment. The participant was seated in an upright position, and in each trial moved a custom-built input device consisting of a manipulandum affixed to a low friction, single degree of freedom, linear bearing. Participants held the manipulandum with their dominant hand and pushed it in a direction parallel to the ground plane. The apparatus was configured for each participant so that at rest the upper arm was aligned with the midaxillary line and the angle between the upper arm and the forearm was approximately 90°.</p>
<fig id="pcbi.1005118.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Schematic representation of the virtual shuffleboard game.</title>
<p>The participant moves a manipulandum along a linear bearing. Position and acceleration data from the manipulandum is used to move a virtual shuffleboard cue that pushes a puck towards a target in the virtual world. The various parts of of setup are: (1) accelerometer; (2) LVDT (position sensor); (3) linear, low friction bearing; (4) data acquisition board; (5) control computer running LabVIEW (for data acquisition) and C++ modules (for graphics rendering and physics logic); (6) projector; (7) virtual environment projected on a screen.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.g004" xlink:type="simple"/>
</fig>
<p>Each trial started with the puck at <italic>x</italic> = 0 (recall <xref ref-type="fig" rid="pcbi.1005118.g001">Fig 1</xref>). The participant accelerated the manipulandum from rest. Position data was acquired from the manipulandum’s motion and used to generate the motion of a virtual shuffleboard cue in real time, via custom software, which pushed the puck on the virtual court. The release of the puck happened as the cue decelerated and the virtual contact force between the cue and the puck decreased to zero. At the point of release, the position and velocity, <italic>x</italic> and <italic>v</italic>, of the puck were acquired, defining the body state for a given trial. Thereafter, the acquired values of <italic>x</italic> and <italic>v</italic> were used to compute the motion of the puck as it slid on the virtual court and was decelerated by Coulomb friction before coming to rest. The movement of the shuffleboard cue and puck during the entire trial was generated in real time by the control software and projected onto a screen. Participants could see an animated 3D scene showing the movement of the puck on the court as it moved toward a visible target line before coming to a stop. The projector (InFocus LP70+) was located to the right and just behind the participants, approximately 3m from a 1.7m × 1.3m screen, with the settings adjusted for flicker-free images that filled the screen.</p>
<p>The position and velocity data were obtained from two transducers placed on the manipulandum and collected through two 12-bit channels: an accelerometer (ADXL320, Analog Devices, Inc., Norwood, MA) was used to collect acceleration data, which was integrated to provide the velocity; the other channel collected position data from a linear variable displacement transducer (LVDT) (Daytronic Corporation, Dayton, OH). The LVDT was also used to calibrate the accelerometer by scaling the doubly integrated acceleration signal to match the position signal. A National Instruments NIDAQCard-6024E data acquisition card was used to acquire the data to a laptop computer. A virtual instrument written in LabVIEW (National Instruments, Austin, TX) passed the velocity and position information in real time to a C++ program which used the Visualization Toolkit (VTK, <ext-link ext-link-type="uri" xlink:href="http://www.vtk.org" xlink:type="simple">http://www.vtk.org</ext-link>), an open-source graphics library, to render the 3D virtual environment. Both signals were sampled at 5kHz to provide smooth animation in the virtual environment. Even though the virtual environment has no physical units per se, we designed the system so that all VTK representations of lengths matched centimeters in the physical world: the accelerometer and LVDT were calibrated and data was recorded in cm/s<sup>2</sup> and cm, respectively.</p>
<p>We expected the dynamical anisotropy predictions (<bold>H1</bold>–<bold>H3</bold>) to depend primarily on the local geometry of the GEM, and to not, therefore, depend on the friction coefficient <italic>μ</italic>. On the other hand, the scaling prediction, <bold>H4</bold>, depends on <italic>μ</italic> via the passive sensitivity, since <italic>s</italic> = <italic>s</italic>(<italic>μ</italic>) from <xref ref-type="disp-formula" rid="pcbi.1005118.e028">Eq (8)</xref>. Therefore, we had each participant perform the task with two different friction levels in the virtual world, giving a total of eight different participants/conditions. For a given velocity and position at release, the time of motion before the puck stops is inversely proportional to the coefficient of friction. We therefore selected values of <italic>μ</italic> so that the time for a hypothetical ideal trial varied uniformly between 3s and 5s. This ideal trial was defined by a release position of <italic>x</italic> = 0 and release velocity <italic>v</italic> determined from the goal function <xref ref-type="disp-formula" rid="pcbi.1005118.e008">Eq (2)</xref> so that the puck would stop exactly at the target. The resulting set of 8 <italic>μ</italic> values were split into two sets: the lowest 4 gave “low friction” (LF) conditions, and the highest 4 “high friction” (HF) conditions. These different friction conditions gave us inter-trial data sets generated with different passive sensitivity properties, via <xref ref-type="disp-formula" rid="pcbi.1005118.e028">Eq (8)</xref>.</p>
<p>Four healthy, right-handed male participants aged 25, 28, 29 and 33 years (labeled P1–P4) participated in this study. Each participant was randomly assigned one HF and one LF friction condition to perform the shuffleboard task. The participants were instructed to launch the puck so that its center stopped on the target in every trial. Participants had the visual feedback from the 3D scene showing the error from a given trial. The goal-level error was also displayed momentarily on the screen providing a second, more precise, feedback on their performance. All participants were allowed to familiarize themselves with the task and the equipment, and practiced hitting the target until their average error <italic>e</italic> (<xref ref-type="fig" rid="pcbi.1005118.g001">Fig 1</xref>) over 50 trials was less than 10% of the target distance. That is, participants practiced until the average state <inline-formula id="pcbi.1005118.e075"><alternatives><graphic id="pcbi.1005118.e075g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e075" xlink:type="simple"/><mml:math display="inline" id="M75"><mml:mrow><mml:mover><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mover><mml:mi>x</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover><mml:mi>v</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> acquired over 50 trials lay within the error contours of <xref ref-type="fig" rid="pcbi.1005118.g002">Fig 2</xref>. All participants achieved this level of performance within four blocks of 50 trials.</p>
<p>Once the participants achieved the required level of performance, the data collection phase began. The body state <bold>x</bold> = (<italic>x</italic>, <italic>v</italic>)<sup><sans-serif>T</sans-serif></sup> and goal-level error <italic>e</italic> were recorded for each trial. For each of the two friction conditions (LF and HF) the participant was required to perform 500 trials. All of the data was collected over three days: two days each of four 50-trial blocks, with two blocks before noon and two in the afternoon, followed by a day of two 50 trial blocks. Each block took no more than seven minutes and the participant was given up to five minutes of rest between blocks. The last block of P1-HF was incomplete due to an experiment malfunction, so only data from the first 9 blocks (450 trials) were subsequently analyzed; P3-HF had only 350 usable trials due to the entry of an erroneous friction coefficient. Typical inter-trial time series of states <bold>x</bold> = (<italic>x</italic>, <italic>v</italic>)<sup><sans-serif>T</sans-serif></sup> obtained from one participant over 500 trials are shown in <xref ref-type="fig" rid="pcbi.1005118.g005">Fig 5(a)–5(c)</xref>.</p>
<fig id="pcbi.1005118.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Typical data collected from one participant over 500 trials, for a given <italic>μ</italic> value.</title>
<p>Plots (a–c): time series of position, velocity, and error at the target. The data is discrete, but plotted with lines to aid visualization. Plot (d): scatterplot of states <bold>x</bold> = (<italic>x</italic>, <italic>v</italic>)<sup><sans-serif>T</sans-serif></sup> plotted as green dots. Also included for reference are the mean operating point <bold>x</bold>* (white dot), GEM (red curve), and ±10% goal-level error contours (dashed blue lines). The update matrix <sans-serif>B</sans-serif> (<xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>) is estimated from the inter-trial data via linear regression. The strongly (double arrow) and weakly (single arrow) stable subspaces obtained by solving the eigenvalue problem for <sans-serif>B</sans-serif> are shown as black lines. The weakly stable subspace is nearly parallel to the GEM tangent, while the strongly stable is at a much greater transverse angle (see <xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref> for angle definitions).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec011">
<title>Data Analysis</title>
<p>The complete data set for each of the 8 friction conditions (4 participants × 2 conditions each) consisted of time series of release position and velocity, <inline-formula id="pcbi.1005118.e076"><alternatives><graphic id="pcbi.1005118.e076g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e076" xlink:type="simple"/><mml:math display="inline" id="M76"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005118.e077"><alternatives><graphic id="pcbi.1005118.e077g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e077" xlink:type="simple"/><mml:math display="inline" id="M77"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, respectively, and the corresponding error, <inline-formula id="pcbi.1005118.e078"><alternatives><graphic id="pcbi.1005118.e078g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e078" xlink:type="simple"/><mml:math display="inline" id="M78"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>e</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, for each of <italic>N</italic> = 500 trials. The data was rescaled into dimensionless form, as for the goal function of <xref ref-type="disp-formula" rid="pcbi.1005118.e008">Eq (2)</xref>. Note, however, that the stability and persistence properties studied here depend only on the temporal relations between consecutive trials, so the rescaling does not affect the results presented in this paper. Except as noted, all data analyses were performed using Matlab (Mathworks, Natick, MA). All data and software used for this study is contained in Supporting Information <xref ref-type="supplementary-material" rid="pcbi.1005118.s001">S1 Data and Code</xref>.</p>
<p>The sample mean body state <inline-formula id="pcbi.1005118.e079"><alternatives><graphic id="pcbi.1005118.e079g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e079" xlink:type="simple"/><mml:math display="inline" id="M79"><mml:mrow><mml:mover><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mover><mml:mi>x</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover><mml:mi>v</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> over all trials was used to define the operating point used in <xref ref-type="disp-formula" rid="pcbi.1005118.e015">Eq (4)</xref>: that is, we took <inline-formula id="pcbi.1005118.e080"><alternatives><graphic id="pcbi.1005118.e080g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e080" xlink:type="simple"/><mml:math display="inline" id="M80"><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>≡</mml:mo> <mml:mover><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>. Fluctuation time series were then obtained from <inline-formula id="pcbi.1005118.e081"><alternatives><graphic id="pcbi.1005118.e081g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e081" xlink:type="simple"/><mml:math display="inline" id="M81"><mml:mrow><mml:msub><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mover><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>, and <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref> was used to estimate <sans-serif>B</sans-serif> via linear regression. That is, we used ordinary least squares to minimize the single-step mean-square prediction error 〈(<bold>u</bold><sub><italic>k</italic>+1</sub> − <sans-serif>B</sans-serif><bold>u</bold><sub><italic>k</italic></sub>)<sup><sans-serif>T</sans-serif></sup>(<bold>u</bold><sub><italic>k</italic>+1</sub> − <sans-serif>B</sans-serif><bold>u</bold><sub><italic>k</italic></sub>)〉, where, again, the angle brackets denote the ensemble average. A requirement for the use of this straightforward approach to estimation [<xref ref-type="bibr" rid="pcbi.1005118.ref060">60</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref062">62</xref>] is that the state measurement error or “noise” (as distinct from the process noise <bold><italic>ν</italic></bold><sub><italic>k</italic></sub> in <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>) not be too large. While there is no firm cutoff for how much measurement noise becomes problematic, Kantz and Screiber suggest (see [<xref ref-type="bibr" rid="pcbi.1005118.ref062">62</xref>], p. 251 ff.) that ordinary least squares works well as long as the measurement errors are under about 10%. In our case the measurement precision after calibration was approximately 2%, well under the suggested cutoff. Furthermore, we cross validate the estimate of <sans-serif>B</sans-serif> by comparing its eigenvalues against the lag-1 autocorrelation, which is computed independently, as discussed previously following <xref ref-type="disp-formula" rid="pcbi.1005118.e056">Eq (21)</xref>.</p>
<p>The eigenvectors of <sans-serif>B</sans-serif>, <inline-formula id="pcbi.1005118.e082"><alternatives><graphic id="pcbi.1005118.e082g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e082" xlink:type="simple"/><mml:math display="inline" id="M82"><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>w</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>s</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, and their corresponding eigenvalues, {<italic>λ</italic><sub><italic>w</italic></sub>, <italic>λ</italic><sub><italic>s</italic></sub>}, were then obtained as solutions to <inline-formula id="pcbi.1005118.e083"><alternatives><graphic id="pcbi.1005118.e083g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e083" xlink:type="simple"/><mml:math display="inline" id="M83"><mml:mrow><mml:mi mathvariant="sans-serif">B</mml:mi> <mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>λ</mml:mi> <mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>. A typical result of this eigenanalysis is shown in <xref ref-type="fig" rid="pcbi.1005118.g005">Fig 5(d)</xref>. The alignment of the eigenvectors to the GEM was computed using the theoretical tangent vector from <xref ref-type="disp-formula" rid="pcbi.1005118.e019">Eq (5)</xref> (recall the schematic of <xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref>). Because the empirically-determined operating point <inline-formula id="pcbi.1005118.e084"><alternatives><graphic id="pcbi.1005118.e084g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e084" xlink:type="simple"/><mml:math display="inline" id="M84"><mml:mover><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula> was always close to, but never exactly on the GEM, as a check we also computed the eigenvector orientation using the tangent to the error contour passing through the operating point (determined from by <inline-formula id="pcbi.1005118.e085"><alternatives><graphic id="pcbi.1005118.e085g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e085" xlink:type="simple"/><mml:math display="inline" id="M85"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mover><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mover><mml:mi>e</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>f</italic> is the goal function <xref ref-type="disp-formula" rid="pcbi.1005118.e008">Eq (2)</xref>). This was found to give identical results, confirming the closeness of <inline-formula id="pcbi.1005118.e086"><alternatives><graphic id="pcbi.1005118.e086g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e086" xlink:type="simple"/><mml:math display="inline" id="M86"><mml:mover><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula> to the GEM. Together with the alignment information so obtained, the estimated eigenvalues of <sans-serif>B</sans-serif>, which quantify the stability of the inter-trial dynamics, were used to test <bold>H1</bold> and <bold>H2</bold>.</p>
<p>Next, the fluctuation time series <inline-formula id="pcbi.1005118.e087"><alternatives><graphic id="pcbi.1005118.e087g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e087" xlink:type="simple"/><mml:math display="inline" id="M87"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> in the original position-speed coordinates were transformed into time series <inline-formula id="pcbi.1005118.e088"><alternatives><graphic id="pcbi.1005118.e088g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e088" xlink:type="simple"/><mml:math display="inline" id="M88"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi mathvariant="bold">z</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> expressed in eigencoordinates, via the linear coordinate transformation <xref ref-type="disp-formula" rid="pcbi.1005118.e041">Eq (12)</xref>. Following the discussion surrounding Eqs <xref ref-type="disp-formula" rid="pcbi.1005118.e055">(20)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005118.e056">(21)</xref>, statistical persistence in both directions was quantified using the lag-1 autorcorrelations <italic>R</italic><sub><italic>w</italic></sub>(1) and <italic>R</italic><sub><italic>s</italic></sub>(1), as well as the DFA exponents <italic>α</italic><sub><italic>w</italic></sub> and <italic>α</italic><sub><italic>s</italic></sub>. These results allowed us to test <bold>H3</bold>.</p>
<p>To test the scaling relationship of <bold>H4</bold>, the RMS goal-level error <italic>σ</italic><sub><italic>e</italic></sub> was computed directly from the time series, <inline-formula id="pcbi.1005118.e089"><alternatives><graphic id="pcbi.1005118.e089g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e089" xlink:type="simple"/><mml:math display="inline" id="M89"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>e</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>. Using <xref ref-type="disp-formula" rid="pcbi.1005118.e028">Eq (8)</xref>, the value of <italic>μ</italic> for a given set of trials, and the velocity component of the average operating point, <inline-formula id="pcbi.1005118.e090"><alternatives><graphic id="pcbi.1005118.e090g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e090" xlink:type="simple"/><mml:math display="inline" id="M90"><mml:mrow><mml:mover><mml:mi>v</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>≡</mml:mo> <mml:msup><mml:mi>v</mml:mi> <mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, we obtained an estimate of <italic>s</italic>. The values of <italic>β</italic> and <italic>λ</italic><sub><italic>s</italic></sub> were available from the eigenanalysis. For <italic>σ</italic><sub><italic>ns</italic></sub>, we used the estimated <sans-serif>B</sans-serif> and <xref ref-type="disp-formula" rid="pcbi.1005118.e041">Eq (12)</xref> to compute the residual of the regression expressed in eigencoordinates, via <bold>r</bold><sub><italic>k</italic></sub> = <sans-serif>E</sans-serif><sup>−1</sup>(<bold>u</bold><sub><italic>k</italic>+1</sub> − <sans-serif>B</sans-serif><bold>u</bold><sub><italic>k</italic></sub>). We then took <inline-formula id="pcbi.1005118.e091"><alternatives><graphic id="pcbi.1005118.e091g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e091" xlink:type="simple"/><mml:math display="inline" id="M91"><mml:mo>〈</mml:mo> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi></mml:mrow> <mml:mrow><mml:mspace width="0.166667em"/><mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:math></alternatives></inline-formula> as an estimate of <italic>σ</italic><sub><italic>ns</italic></sub>, where <italic>r</italic><sub><italic>s</italic>,<italic>k</italic></sub> is the strongly stable component of <bold>r</bold><sub><italic>k</italic></sub>. Using these estimates to evaluate <xref ref-type="disp-formula" rid="pcbi.1005118.e054">Eq (19)</xref> allowed us to test <bold>H4</bold>.</p>
<p>All of the above analyses depend critically on the eigenvalues and eigenvectors of the matrix <sans-serif>B</sans-serif>. To estimate <sans-serif>B</sans-serif> via regression we require only data from a set of trials, which need not themselves be consecutive, together with the subsequent states that are presumed to follow under the action of <sans-serif>B</sans-serif> via <xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>. To eliminate the spurious “state update” between the last trial in each block and the first trial in the next block, we only consider the first 49 trials within each 50 trial block. In addition, to avoid possible transient “retraining” effects at the beginning of each block, we removed the first 4 trials, leaving 45 trials within each block, for a total of 450 trials per friction condition. Finally, to overcome known problems associated with the sensitivity of eigenvalue and eigenvector estimates to matrix errors [<xref ref-type="bibr" rid="pcbi.1005118.ref031">31</xref>], such as are unavoidable with matrices estimated via regression, we used bootstrapping [<xref ref-type="bibr" rid="pcbi.1005118.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref034">34</xref>] to estimate the various quantities needed to test our hypotheses.</p>
<p>For each iterate of the bootstrap, we selected a uniformly-distributed random sample of 450 states (with replacement) from the 450 available for each friction condition, together with the state from the next trial. In this way, we obtained an ensemble of “current states” (<bold>x</bold><sub><italic>k</italic></sub>) and an ensemble of the corresponding “next states” (<bold>x</bold><sub><italic>k</italic>+1</sub>) that were used to obtain <italic>one</italic> estimate of <sans-serif>B</sans-serif> via linear regression. This estimate of <sans-serif>B</sans-serif> was then used to compute one set of eigenvalues and eigenvectors. The eigenvectors were then used to obtain the fluctuation components in the weakly and strongly stable directions, <italic>z</italic><sub><italic>w</italic></sub> and <italic>z</italic><sub><italic>s</italic></sub>, via the transformation <xref ref-type="disp-formula" rid="pcbi.1005118.e041">Eq (12)</xref>. These allowed us to estimate the lag-1 autocorrelations using <xref ref-type="disp-formula" rid="pcbi.1005118.e055">Eq (20)</xref>. By choosing many such random samples, each resulting in its own estimate of <sans-serif>B</sans-serif>, we were able to generate an empirical probability distribution for all quantities needed to test <bold>H1</bold> and <bold>H2</bold>, and to partially test <bold>H3</bold> using <italic>R</italic>(1). The bootstrapping gave us reliable estimates of mean values together with 95% confidence intervals. For the above results, we used 10000 bootstrap iterates.</p>
<p>Since DFA relies on the proper temporal sequence of an entire data set (not just over a single lag as for the autocorrelation), the sampling procedure outlined above could not be used. In addition, because DFA does not give reliable estimates for small data sets, we concatenated all 10 trial blocks, again with the first four trials removed, and analysed the resulting data set of 460 trials at once. Such a concatenation procedure was shown in an analysis of Parkinsonian gait [<xref ref-type="bibr" rid="pcbi.1005118.ref063">63</xref>], using data sets of 25 strides each, to give results with sufficient accuracy to distinguish Parkinsonian and healthy participants. While perhaps not accurate enough to characterize subtle differences in long-range correlated data sets, as stated earlier this is emphatically <italic>not</italic> our aim here: we merely use DFA to provide a convenient, lag-independent measure of statistical persistence, which we checked against the lag-1 autocorrelation for consistency. For this paper, once the eigenvectors were found within each iterate of the bootstrap, the entire time series of fluctuations was transformed into eigencoordinates, again via <xref ref-type="disp-formula" rid="pcbi.1005118.e041">Eq (12)</xref>. The DFA exponents, <italic>α</italic><sub><italic>w</italic></sub> and <italic>α</italic><sub><italic>s</italic></sub>, for the two eigencoordinate fluctuations were then obtained, allowing us to complete the test of <bold>H3</bold>. To reduce the computation time required to carry out 10000 DFA calculations for each friction condition, we used a version of the algorithm written in C [<xref ref-type="bibr" rid="pcbi.1005118.ref064">64</xref>], that was then called from Matlab.</p>
<p>Finally, to test <bold>H4</bold>, another variant of the bootstrap was used. In each bootstrap iteration, 450 samples with replacement were drawn and used to estimate <italic>σ</italic><sub><italic>e</italic></sub>, <italic>σ</italic><sub><italic>ns</italic></sub>, <italic>s</italic>, <italic>β</italic> and <italic>λ</italic><sub><italic>s</italic></sub>, as needed for <xref ref-type="disp-formula" rid="pcbi.1005118.e054">Eq (19)</xref>; this was done for all 8 friction conditions. Within this bootstrap iteration, regression was then used to estimate the parameters <italic>a</italic> and <italic>b</italic> of a fit <italic>σ</italic><sub><italic>e</italic></sub>/<italic>σ</italic><sub><italic>ns</italic></sub> = <italic>as</italic><sub>TOT</sub> + <italic>b</italic>: following <xref ref-type="disp-formula" rid="pcbi.1005118.e054">Eq (19)</xref>, we expected <italic>a</italic> ≈ 1 and <italic>b</italic> ≈ 0. Thus, after repeating this process 10000 times, we obtained estimates and confidence intervals for the slope <italic>a</italic> and y-intercept <italic>b</italic>, as required to test <bold>H4</bold>.</p>
</sec>
</sec>
<sec id="sec012" sec-type="results">
<title>Results</title>
<p>
<xref ref-type="fig" rid="pcbi.1005118.g006">Fig 6</xref> shows empirical probability density functions (EPDFs), obtained using bootstrapping, for the eigenvalues {<italic>λ</italic><sub><italic>w</italic></sub>, <italic>λ</italic><sub><italic>s</italic></sub>} of the matrix <sans-serif>B</sans-serif> (<xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>). We see that in all cases they satisfy 0 ≈ |<italic>λ</italic><sub><italic>s</italic></sub>| ≪ <italic>λ</italic><sub><italic>w</italic></sub> &lt; 1. In aggregate, across all participants (P1–P4) and friction conditions, we found <italic>λ</italic><sub><italic>s</italic></sub> = −0.03 [−0.24, 0.14] and <italic>λ</italic><sub><italic>w</italic></sub> = 0.76 [0.62, 0.90], where here and throughout the stated estimate is the aggregate mean, and the closed interval represents the aggregate 95% confidence interval (CI). The orientation of the eigenvectors is shown in <xref ref-type="fig" rid="pcbi.1005118.g007">Fig 7</xref>, which plots the EPDFs for the angles <inline-formula id="pcbi.1005118.e092"><alternatives><graphic id="pcbi.1005118.e092g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e092" xlink:type="simple"/><mml:math display="inline" id="M92"><mml:mrow><mml:msub><mml:mi>θ</mml:mi> <mml:mi>w</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mo form="prefix">cos</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>w</mml:mi></mml:msub> <mml:mo>·</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1005118.e093"><alternatives><graphic id="pcbi.1005118.e093g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e093" xlink:type="simple"/><mml:math display="inline" id="M93"><mml:mrow><mml:msub><mml:mi>θ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mo form="prefix">cos</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>s</mml:mi></mml:msub> <mml:mo>·</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. We see that, for all participants/conditions, the weakly stable eigenvector was very close to the tangent, and the strongly stable eigenvector made a larger transverse angle with it, so that 0 ≈ |<italic>θ</italic><sub><italic>w</italic></sub>| ≪ <italic>θ</italic><sub><italic>s</italic></sub>. Specifically, we found <italic>θ</italic><sub><italic>w</italic></sub> = 0.90° [−2.36°, 3.99°] and <italic>θ</italic><sub><italic>s</italic></sub> = 79.75° [20.66°, 144.75°]. We note that the orientation of the weakly stable subspace is tightly regulated to be near the GEM’s tangent (i.e., its CI is small, spanning less than 7°), whereas the orientation of the strongly stable subspace is not tightly regulated (its CI spans over 124°). The aggregate values of the matrix components of <sans-serif>B</sans-serif> were found as <sans-serif>B</sans-serif>(1, 1) = 0.76 [0.62, 0.90], <sans-serif>B</sans-serif>(1, 2) = −0.26 [−2.03, 1.19], <sans-serif>B</sans-serif>(2, 1) = −0.01 [−0.04, 0.03], and <sans-serif>B</sans-serif>(2, 2) = −0.03 [−0.25, 0.14]. Using the mean matrix components as a simple consistency check, we found values of <italic>λ</italic><sub><italic>w</italic></sub> and <italic>λ</italic><sub><italic>s</italic></sub> equal to the means obtained via bootstrapping, above.</p>
<fig id="pcbi.1005118.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Empirical probability density functions (EPDFs) obtained via bootstrapping for eigenvalues <italic>λ</italic><sub><italic>w</italic></sub> (red) and <italic>λ</italic><sub><italic>s</italic></sub> (blue) of <sans-serif>B</sans-serif> (<xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>), each plotted vs. participant/condition.</title>
<p>We see that 0 ≈ <italic>λ</italic><sub><italic>s</italic></sub> ≪ <italic>λ</italic><sub><italic>w</italic></sub> in all cases (aggregate mean <italic>λ</italic><sub><italic>s</italic></sub> = −0.03 with 95% CI of [−0.24, 0.14] and <italic>λ</italic><sub><italic>w</italic></sub> = 0.76 with 95% CI of [0.62, 0.90]), indicating much more vigorous inter-trial control in the strong direction than in the weak. Bootstrapping was carried out using 10000 random samples of 450 trials each, with replacement, from the complete data set, with the final and first four trials removed from each 50 trial block. The solid lines in the horizontal plane shows the aggregate mean value, and the dashed lines indicate the aggregate 95% CI, as reported above.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.g006" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005118.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.g007</object-id>
<label>Fig 7</label>
<caption>
<title>EPDFs for the angles <italic>θ</italic><sub><italic>w</italic></sub> (red) and <italic>θ</italic><sub><italic>s</italic></sub> (blue) between the eigenvectors <inline-formula id="pcbi.1005118.e094"><alternatives><graphic id="pcbi.1005118.e094g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e094" xlink:type="simple"/><mml:math display="inline" id="M94"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>w</mml:mi></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005118.e095"><alternatives><graphic id="pcbi.1005118.e095g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e095" xlink:type="simple"/><mml:math display="inline" id="M95"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>s</mml:mi></mml:msub></mml:math></alternatives></inline-formula> of <sans-serif>B</sans-serif>, respectively, and the unit tangent <inline-formula id="pcbi.1005118.e096"><alternatives><graphic id="pcbi.1005118.e096g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005118.e096" xlink:type="simple"/><mml:math display="inline" id="M96"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1005118.e019">Eq (5)</xref>), each plotted vs. participant/condition. All other figure details are as in <xref ref-type="fig" rid="pcbi.1005118.g006">Fig 6</xref>.</title>
<p>We see that in all cases 0 ≈ |<italic>θ</italic><sub><italic>w</italic></sub>| ≪ <italic>θ</italic><sub><italic>s</italic></sub> (<italic>θ</italic><sub><italic>w</italic></sub> = 0.90° [−2.36°, 3.99°] and <italic>θ</italic><sub><italic>s</italic></sub> = 79.75° [20.66°, 144.75°]). The orientation of the weakly stable subspace was found to be nearly tangent to the GEM, with a small range of variation, whereas the strongly stable subspace made a much greater angle with the GEM and varied substantially. Together with the results of <xref ref-type="fig" rid="pcbi.1005118.g006">Fig 6</xref>, these results confirm hypotheses <bold>H1</bold> and <bold>H2</bold>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.g007" xlink:type="simple"/>
</fig>
<p>The results shown in Figs <xref ref-type="fig" rid="pcbi.1005118.g006">6</xref> and <xref ref-type="fig" rid="pcbi.1005118.g007">7</xref> strongly support hypotheses <bold>H1</bold> and <bold>H2</bold>. We found that the component of the inter-trial dynamics directed along the strongly stable subspace acted to quickly correct deviations off of the GEM that caused goal-level errors. For example, for the estimated mean value <italic>λ</italic><sub><italic>s</italic></sub> = −0.03, <xref ref-type="disp-formula" rid="pcbi.1005118.e046">Eq (15)</xref> shows that a deviation transverse to the GEM would be, in the absence of noise, reduced to 3% of its initial magnitude after only one trial. In contrast, the dynamics in the weakly stable subspace did not rapidly correct deviations that were approximately tangent the GEM, and which therefore had little effect on error at the target. For the mean value of <italic>λ</italic><sub><italic>w</italic></sub> = 0.76, <xref ref-type="disp-formula" rid="pcbi.1005118.e045">Eq (14)</xref> shows that, in the absence of noise, 9 iterates would be required to reduce an initial deviation to less than 10% of its initial value.</p>
<p>In <xref ref-type="fig" rid="pcbi.1005118.g008">Fig 8</xref> we show the EPDFs obtained for the normalized lag-1 autocorrelations of fluctuations in the two eigendirections, for all friction participants/conditions. We find in all cases that 0 ≈ |<italic>R</italic><sub><italic>s</italic></sub>(1)| ≪ <italic>R</italic><sub><italic>w</italic></sub>(1). Specifically, we estimate <italic>R</italic><sub><italic>s</italic></sub>(1) = −0.03 [−0.24, 0.14] and <italic>R</italic><sub><italic>w</italic></sub>(1) = 0.76 [0.64, 0.88]. These results indicate that the trial-to-trial fluctuations in the weakly stable direction show greater persistence than those in the strongly stable direction. Furthermore, the strong control results in fluctuations that are close to uncorrelated white noise (since <italic>R</italic><sub><italic>s</italic></sub>(1) ≈ 0). As anticipated in the discussion following <xref ref-type="disp-formula" rid="pcbi.1005118.e056">Eq (21)</xref>, these results are nearly identical to the local stability results in <xref ref-type="fig" rid="pcbi.1005118.g006">Fig 6</xref>. The EPDFs obtained for the DFA exponents <italic>α</italic><sub><italic>w</italic></sub> and <italic>α</italic><sub><italic>s</italic></sub> for fluctuations in the weakly and strongly stable subspaces, respectively, are shown in <xref ref-type="fig" rid="pcbi.1005118.g009">Fig 9</xref>. We found <italic>α</italic><sub><italic>s</italic></sub> = 0.52 [0.44, 0.59] and <italic>α</italic><sub><italic>w</italic></sub> = 0.99 [0.89, 1.16]. Thus, in all cases 0.5 ≈ <italic>α</italic><sub><italic>s</italic></sub> ≪ <italic>α</italic><sub><italic>w</italic></sub>, showing substantial persistence between successive fluctuations in the weakly stable direction, and nearly uncorrelated fluctuations in the strongly stable direction. Thus, the persistence results of Figs <xref ref-type="fig" rid="pcbi.1005118.g008">8</xref> and <xref ref-type="fig" rid="pcbi.1005118.g009">9</xref> are consistent with each other and, taken together, strongly confirm <bold>H3</bold>.</p>
<fig id="pcbi.1005118.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.g008</object-id>
<label>Fig 8</label>
<caption>
<title>EPDFs for the normalized lag-1 autocorrelations <italic>R</italic><sub><italic>w</italic></sub>(1) (red) and <italic>R</italic><sub><italic>s</italic></sub>(1) (blue) for fluctuations in the weakly and strongly stable subspaces (<xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref>), respectively, plotted vs. participants/conditions.</title>
<p>All other figure details are as in <xref ref-type="fig" rid="pcbi.1005118.g006">Fig 6</xref>. We find in all cases that 0 ≈ |<italic>R</italic><sub><italic>s</italic></sub>(1)| ≪ <italic>R</italic><sub><italic>w</italic></sub>(1) (<italic>R</italic><sub><italic>s</italic></sub>(1) = −0.03 [−0.24, 0.14] and <italic>R</italic><sub><italic>w</italic></sub>(1) = 0.76 [0.64, 0.88]). The results show strong positive correlation between successive fluctuations in the weakly stable direction, which is nearly tangent to the GEM (<xref ref-type="fig" rid="pcbi.1005118.g007">Fig 7</xref>), indicating that fluctuations persisted over multiple trials. In contrast, the strongly stable fluctuations were close to being uncorrelated, consistent with the action of strong control transverse to the GEM.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.g008" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005118.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.g009</object-id>
<label>Fig 9</label>
<caption>
<title>EPDFs for the DFA exponents <italic>α</italic><sub><italic>w</italic></sub> (red) and <italic>α</italic><sub><italic>s</italic></sub> (blue) for fluctuations in the weakly and strongly stable subspaces (<xref ref-type="fig" rid="pcbi.1005118.g003">Fig 3</xref>), respectively, plotted vs. participants/conditions.</title>
<p>These calculations were carried out on the entire data set of fluctuations expressed in eigencoordinates, obtained via <xref ref-type="disp-formula" rid="pcbi.1005118.e041">Eq (12)</xref> within each of 10000 bootstrap iterations. We found in all cases that 0.5 ≈ <italic>α</italic><sub><italic>s</italic></sub> ≪ <italic>α</italic><sub><italic>w</italic></sub> (<italic>α</italic><sub><italic>s</italic></sub> = 0.52 [0.44, 0.59] and <italic>α</italic><sub><italic>w</italic></sub> = 0.99 [0.89, 1.16]). The results indicate substantial persistence between successive fluctuations in the weakly stable direction, which is nearly tangent to the GEM (<xref ref-type="fig" rid="pcbi.1005118.g007">Fig 7</xref>), and nearly uncorrelated fluctuations in the strongly stable direction. These results, together with those of <xref ref-type="fig" rid="pcbi.1005118.g008">Fig 8</xref>, strongly confirm <bold>H3</bold>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.g009" xlink:type="simple"/>
</fig>
<p>Finally, <xref ref-type="fig" rid="pcbi.1005118.g010">Fig 10</xref> illustrates how the variability ratio <italic>σ</italic><sub><italic>e</italic></sub>/<italic>σ</italic><sub><italic>ns</italic></sub>, which represents an empirical “gain” between intrinsic body-level noise and goal-level variability, was found to linearly scale with the total body-goal sensitivity <italic>s</italic><sub>TOT</sub> (<xref ref-type="disp-formula" rid="pcbi.1005118.e054">Eq (19)</xref>). The light gray dots in the plot represent values obtained by bootstrapping: one such point was generated for all 8 friction conditions and linear regression was applied within each of 10000 iterations. This process yielded estimates for the slope, <italic>a</italic> = 0.99 [0.93, 1.03], and y-intercept, <italic>b</italic> = 0.21 [−0.98, 1.52]. The resulting aggregate fit had an <italic>R</italic><sup>2</sup> of 0.996. As a check, we used all 8 × 10000 points at once for a single linear fit; this did not change the fit parameters or the <italic>R</italic><sup>2</sup> value. The figure also includes the average values obtained for each participant/condition, computed independently by bootstrapping, together with error bars representing 95% CIs. The uneven size of the error bars, especially in the horizontal direction, reflects the nonlinearity of <italic>s</italic><sub>TOT</sub>, particularly the factor of <italic>β</italic> = sin(<italic>θ</italic><sub><italic>s</italic></sub>). We see that in each case the mean points fall very near the linear fit, indicating that the scaling relationship held not only in aggregate, but for each participant/condition individually. Indeed, similar fits done for each participant independently yielded <italic>R</italic><sup>2</sup> estimates of 0.962, 0.991, 0.979 and 0.992, values not meaningfully different from the overall value. Thus, we concluded that for all participants/conditions <xref ref-type="disp-formula" rid="pcbi.1005118.e054">Eq (19)</xref> holds, confirming hypothesis <bold>H4</bold>.</p>
<fig id="pcbi.1005118.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Plot of the variability ratio <italic>σ</italic><sub><italic>e</italic></sub>/<italic>σ</italic><sub><italic>ns</italic></sub> vs. total body-goal sensitivity <italic>s</italic><sub>TOT</sub> (see <xref ref-type="disp-formula" rid="pcbi.1005118.e054">Eq (19)</xref>).</title>
<p>The light gray dots represent all values obtained by bootstrapping. One such point was generated for all 8 friction conditions within each of 10000 bootstrap iterations, and then linear regression gave estimates of the slope <italic>a</italic> and y-intercept <italic>b</italic>, yielding EPDFs for both. We found <italic>a</italic> = 0.99 [0.93, 1.03] and <italic>b</italic> = 0.21 [−0.98, 1.52], showing that <italic>σ</italic><sub><italic>e</italic></sub>/<italic>σ</italic><sub><italic>ns</italic></sub> ≈ <italic>s</italic><sub>TOT</sub>, which confirms hypothesis <bold>H4</bold>. The dashed line is plotted using the bootstrap mean values of <italic>a</italic> and <italic>b</italic>; <italic>R</italic><sup>2</sup> = 0.996 for the fit. Also shown for reference are the average values for each participant/condition individually, obtained via bootstrapping, with error bars indicating 95% CIs. These average values fall very close to the fit line.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.g010" xlink:type="simple"/>
</fig>
<p>We conclude this section with an illustration of how our approach overcomes the potential interpretive ambiguity stemming from the coordinate dependence of variance [<xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref040">40</xref>]. As discussed when presenting Eqs <xref ref-type="disp-formula" rid="pcbi.1005118.e057">(22)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005118.e058">(23)</xref>, the dynamical analysis carried out here yields quantities that are intrinsic to the observed temporal fluctuations, and hence are coordinate invariant. As a demonstration of this invariance, and its advantage in analyzing motor variability, we constructed a “worst case” coordinate transformation similar in form to <xref ref-type="disp-formula" rid="pcbi.1005118.e041">Eq (12)</xref>. However, in this case we defined new fluctuation coordinates <bold>q</bold> = (<italic>q</italic><sub>1</sub>, <italic>q</italic><sub>2</sub>)<sup><sans-serif>T</sans-serif></sup> via <bold>u</bold> = <sans-serif>P</sans-serif><bold>q</bold>, where the matrix <sans-serif>P</sans-serif> was obtained from principal component analysis [<xref ref-type="bibr" rid="pcbi.1005118.ref042">42</xref>], as follows: let <sans-serif>P</sans-serif> = <sans-serif>SC</sans-serif>, in which <sans-serif>C</sans-serif> is a matrix with columns composed of the eigenvectors (i.e., the principal components) of the fluctuation covariance 〈<bold>uu</bold><sup><sans-serif>T</sans-serif></sup>〉, and <sans-serif>S</sans-serif> is a diagonal matrix with the square root of the inverse principal values, 1/<italic>σ</italic><sub>1</sub> and 1/<italic>σ</italic><sub>2</sub>, along its diagonal. The result of applying this transformation is that both of the new coordinates <italic>q</italic><sub>1</sub> and <italic>q</italic><sub>2</sub> have identical variance, and hence the variance “cloud” in the (<italic>q</italic><sub>1</sub>, <italic>q</italic><sub>2</sub>) plane is isotropic by construction (i.e., the variance ellipse is a circle).</p>
<p>
<xref ref-type="fig" rid="pcbi.1005118.g011">Fig 11</xref> shows what happens when we apply this transformation to typical data from a single participant and friction condition. In <xref ref-type="fig" rid="pcbi.1005118.g011">Fig 11(a)</xref> we see the original data and the local stability results estimated from it, whereas in <xref ref-type="fig" rid="pcbi.1005118.g011">Fig 11(b)</xref> we see the equivalent analysis carried out on the transformed data. The eigenvalues obtained are identical in both cases, since the original matrix, <sans-serif>B</sans-serif> (<xref ref-type="disp-formula" rid="pcbi.1005118.e034">Eq (11)</xref>), and the transformed matrix, <sans-serif>P</sans-serif><sup>−1</sup><sans-serif>BP</sans-serif>, are congruent. Furthermore, as discussed following <xref ref-type="disp-formula" rid="pcbi.1005118.e058">Eq (23)</xref>, the transformed eigenvectors maintain their qualitative relationship with the transformed GEM: that is, the weakly stable subspace is nearly tangent to the GEM, whereas the strongly stable subspace is transverse to the GEM at a much greater angle. Thus, in both cases 0 ≈ <italic>θ</italic><sub><italic>w</italic></sub> ≪ <italic>θ</italic><sub><italic>s</italic></sub> so that the local stability picture is qualitatively unchanged by the coordinate transformation, and can be used to test a candidate GEM in either case. In sharp contrast, using the shape of the variance ellipse to identify the GEM location works reasonably well for <xref ref-type="fig" rid="pcbi.1005118.g011">Fig 11(a)</xref>, but clearly fails for the case shown in <xref ref-type="fig" rid="pcbi.1005118.g011">Fig 11(b)</xref>. Indeed, using an approach similar to that used to create <xref ref-type="fig" rid="pcbi.1005118.g011">Fig 11(b)</xref>, one can change the shape of the variance ellipse at will, while in all cases maintaining the proper qualitative relationship between the GEM and the weakly and strongly stable subspaces.</p>
<fig id="pcbi.1005118.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005118.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Illustration of the coordinate invariance of fluctuation dynamics near the GEM: (a) results for data in original (<italic>x</italic>, <italic>v</italic>) coordinates, showing an anisotropic variance ellipse (dashed line) with principal axes equal to the square root of the principal values; (b) results for data transformed using rescaled principal coordinates (<italic>q</italic><sub>1</sub>, <italic>q</italic><sub>2</sub>), showing an isotropic variance ellipse (i.e., a circle).</title>
<p>Both figures contain the same data (green dots), GEM (red line), and strongly stable (double arrow) and weakly stable (single arrow) subspaces (black lines). We see that the local stability analysis consistently represents the organization of control around the GEM, whereas the ratio of variances normal and tangent to the GEM clearly fails to identify the GEM location in plot (b).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.g011" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec013" sec-type="conclusions">
<title>Discussion</title>
<p>Understanding how humans are able to perform accurate and repeatable goal-directed movements in the presence of inherent biological noise [<xref ref-type="bibr" rid="pcbi.1005118.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref011">11</xref>] and neuromotor redundancy [<xref ref-type="bibr" rid="pcbi.1005118.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref024">24</xref>] has been a critical goal of neuroscience research (e.g., [<xref ref-type="bibr" rid="pcbi.1005118.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref048">48</xref>]) since the pioneering work of Bernstein [<xref ref-type="bibr" rid="pcbi.1005118.ref001">1</xref>]. In recent years, studies addressing this question have focused on using either task manifold ideas to address redundancy (e.g., [<xref ref-type="bibr" rid="pcbi.1005118.ref012">12</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref014">14</xref>]), or time series analysis methods to study temporal correlation structure (e.g., [<xref ref-type="bibr" rid="pcbi.1005118.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref051">51</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref055">55</xref>]).</p>
<p>However, these often divergent perspectives have not yet been fully unified into a comprehensive theoretical framework, and it remains an open question whether these various aspects of inter-trial variability represent distinct neurophysiological phenomena, or can be traced back to a single underlying motor regulation process. The work in this paper expands on previous efforts [<xref ref-type="bibr" rid="pcbi.1005118.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>] suggesting that such a unification can be achieved by considering the inter-trial dynamics of fluctuations near a task’s goal equivalent manifold (GEM). These studies have shown that a fundamental feature of such inter-trial fluctuations is that they are dynamically anisotropic in a manner that respects the local geometry of the GEM [<xref ref-type="bibr" rid="pcbi.1005118.ref025">25</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref029">29</xref>], an observation supported by work carried out from different task manifold perspectives [<xref ref-type="bibr" rid="pcbi.1005118.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref065">65</xref>].</p>
<p>Using a custom-built interactive virtual environment, we studied the variability exhibited by skilled participants as they carried out repeated trials of a simple shuffleboard game. The experiments were used to test theoretical predictions obtained from a new analysis, presented in this paper, of a previously-developed general model for inter-trial error correction [<xref ref-type="bibr" rid="pcbi.1005118.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>]. The assumption of skilled performance, for which body states will remain close to the GEM, yields a simple linear inter-trial control model. The further empirically-supported assumption that inter-trial error correction satisfies a generalized interpretation of the minimum intervention principle (MIP), together with an analysis of geometric stability, yielded theoretical predictions about the geometrical and temporal structure of inter-trial variability, showing analytically how body-level variability generates variability at the goal level. In particular, we showed that the assumptions underlying our analysis give rise to a new scaling relationship (<xref ref-type="disp-formula" rid="pcbi.1005118.e054">Eq (19)</xref>), which introduces the total body-goal sensitivity, <italic>s</italic><sub>TOT</sub>, a quantity showing how intrinsic goal-relevant fluctuations at the body level are mapped into fluctuations at the goal level. This relationship provides a unification of task manifold, control theoretic, and dynamical (time series) perspectives by showing specifically how the GEM geometry, passive sensitivity, and active error correction combine to yield task performance.</p>
<p>The predictions resulting from our analysis were summarized in the form of four experimental hypothesis, which were tested using data from four participants playing the shuffleboard game. To demonstrate the generality of the dynamical anisotropy predictions (<bold>H1</bold>–<bold>H3</bold>), and, more importantly, to allow us to tease apart active and passive effects in task performance as specified by the scaling prediction <bold>H4</bold>, we had each participant perform the task with two different friction levels, giving a total of eight different participants/conditions. All of our hypotheses were very strongly confirmed: in all cases, the difference between local stability and correlation properties in the weakly and strongly stable directions was just as predicted by theory (Figs <xref ref-type="fig" rid="pcbi.1005118.g006">6</xref>–<xref ref-type="fig" rid="pcbi.1005118.g009">9</xref>), confirming <bold>H1</bold>–<bold>H3</bold>; and the goal-level performance scaled as predicted across all participants and friction conditions (<xref ref-type="fig" rid="pcbi.1005118.g010">Fig 10</xref>), confirming <bold>H4</bold>.</p>
<p>Given the nature of <bold>H4</bold>, which concerns the scaling relationship <xref ref-type="disp-formula" rid="pcbi.1005118.e054">Eq (19)</xref> and therefore depends on all assumptions used in its derivation, these experimental results do more than characterize the behavior for these particular participants executing this particular task. Rather, they serve to validate our general model for inter-trial error-correcting control near the GEM. Thus, while this work does not make any direct ties to underlying physiological mechanisms, our results indicate that the combined geometrical and temporal structure of observed fluctuations can be explained by a single, relatively simple process. This supports the idea that one need not posit separate neurophysiological mechanisms for controlling such disparate features as the geometric distribution of trials about the GEM, the stability of inter-trial fluctuations, and the goal-level performance, but, rather, that all such behaviors arise from a single, unified process of error regulation in the presence of task-level redundancy.</p>
<p>Another contribution of this paper is the introduction of statistical bootstrapping [<xref ref-type="bibr" rid="pcbi.1005118.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref034">34</xref>] to the analysis of movement variability data. Using this approach, we were able to estimate the underlying probability distribution for quantities required by each hypothesis (e.g., eigenvalues, correlations, etc.), thus demonstrating that the predicted dynamical anisotropy is very highly significant in each case individually (Figs <xref ref-type="fig" rid="pcbi.1005118.g006">6</xref>–<xref ref-type="fig" rid="pcbi.1005118.g009">9</xref>), without the need for conventional significance testing. Furthermore, this data analysis allowed us to confirm the theoretical performance scaling prediction (<xref ref-type="fig" rid="pcbi.1005118.g010">Fig 10</xref>) to high precision, thus demonstrating that task performance was largely determined by passive sensitivity, which in this case was a function of the friction condition (<xref ref-type="disp-formula" rid="pcbi.1005118.e028">Eq (8)</xref>). This theoretical prediction is perhaps counterintuitive, because the passive sensitivity is determined entirely by the task’s goal function (<xref ref-type="disp-formula" rid="pcbi.1005118.e008">Eq (2)</xref>), <italic>independent</italic> from any consideration of control. However, this behavior occurs precisely because error-correcting control strongly compresses variability onto the GEM. Thus, as shown theoretically by using <xref ref-type="disp-formula" rid="pcbi.1005118.e053">Eq (18)</xref> in <xref ref-type="disp-formula" rid="pcbi.1005118.e047">Eq (16)</xref> (with the understanding that <italic>λ</italic><sub><italic>s</italic></sub> ≈ 0, as shown in <xref ref-type="fig" rid="pcbi.1005118.g006">Fig 6</xref>), the scale of goal-relevant fluctuations is minimized, taking a value proportional to the scale of the strongly-stable component of the intrinsic noise. Therefore, for skilled participants, the resulting performance (as measured by the RMS error at the goal) is largely determined by the passive sensitivity, which is a property of the task as defined by the goal function.</p>
<p>Finally, as shown in our theoretical discussion and demonstrated with our experimental data, the dynamical approach used for this study yields results that are invariant under quite general (differentiable and invertible) coordinate transformations, something that is not true for variability analyses based only on the spatial distribution of body states near a given task manifold. Even in the “worst case” scenario for which coordinates are chosen that render the variability cloud isotropic, so that it contains <italic>no</italic> information about the location of the GEM, as shown in <xref ref-type="fig" rid="pcbi.1005118.g011">Fig 11</xref>, the dynamical approach yields correct information about the structure of inter-trial fluctuations. Thus, our data analysis methods resolve the persistent problem of coordinate dependence of variability measures [<xref ref-type="bibr" rid="pcbi.1005118.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref040">40</xref>]. This suggests that the dynamical coordinates, as obtained via the transformation <xref ref-type="disp-formula" rid="pcbi.1005118.e041">Eq (12)</xref>, provide a set of objective, canonical coordinates for the study of inter-trial variability: that is, they represent coordinates that are intrinsic to the regulatory process responsible for inter-trial error correction.</p>
<p>These findings again highlight the critical importance of considering fluctuation dynamics [<xref ref-type="bibr" rid="pcbi.1005118.ref025">25</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref051">51</xref>–<xref ref-type="bibr" rid="pcbi.1005118.ref054">54</xref>] in both theoretical and experimental studies aimed at understanding the neuromuscular control of complex movements. While time series analyses alone can yield important descriptive information, in the absence of any underlying model they often have limited explanatory power. Recent efforts have seen the use of time series analyses to interpret model outputs and/or predictions [<xref ref-type="bibr" rid="pcbi.1005118.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref048">48</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref066">66</xref>]. These efforts have yielded findings qualitatively similar to ours, and consistent with our interpretations of inter-trial variabilty presented both here and elsewhere [<xref ref-type="bibr" rid="pcbi.1005118.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref029">29</xref>]. Even though these efforts have focused on motor learning, which we do not, conceptually there is a strong affinity between these papers and the work presented here. In [<xref ref-type="bibr" rid="pcbi.1005118.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref066">66</xref>], van Beers and colleagues used simple linear models with direct error feedback to analyze task performance when reaching to a point [<xref ref-type="bibr" rid="pcbi.1005118.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref066">66</xref>] or a line [<xref ref-type="bibr" rid="pcbi.1005118.ref054">54</xref>]. Their lag-1 autocorrelation analyses for the redundant task of reaching to a line showed strong statistical persistence along the target line and uncorrelated fluctuations perpendicular to it, precisely as we would theoretically predict and very similar to our own findings (our Figs <xref ref-type="fig" rid="pcbi.1005118.g008">8</xref> and <xref ref-type="fig" rid="pcbi.1005118.g009">9</xref>). In parallel work, Abe &amp; Sternad [<xref ref-type="bibr" rid="pcbi.1005118.ref030">30</xref>] also obtained similar results applying both lag-1 autocorrelation and DFA analyses to van Beers’ model of the same task. Both studies thus independently support the experimental results presented here.</p>
<p>The analytical formalisms presented in the present paper, however, add several important extensions to these experimental observations. First, here we tie these time series analysis approaches directly to the stability properties of the dynamical system that generates the observed fluctuations, as determined by its eigenvalues and eigenvectors (Figs <xref ref-type="fig" rid="pcbi.1005118.g006">6</xref> and <xref ref-type="fig" rid="pcbi.1005118.g007">7</xref>). Second, by formally defining the task in terms of a goal function (<xref ref-type="disp-formula" rid="pcbi.1005118.e008">Eq (2)</xref>), we are able to show analytically (<xref ref-type="disp-formula" rid="pcbi.1005118.e054">Eq (19)</xref>) how active and passive properties of the task interact to affect goal level fluctuations, a theoretical prediction that we test and confirm experimentally (<xref ref-type="fig" rid="pcbi.1005118.g010">Fig 10</xref>). Finally, van Beers’ model accounts only for the correction of goal-relevant errors, that is, of body-level fluctuations perpendicular to the GEM, and thus implements an ideal MIP-based controller with no control acting along the task manifold. However, as we have shown in previous work using models derived using a stochastic optimal control framework [<xref ref-type="bibr" rid="pcbi.1005118.ref025">25</xref>], and as discussed here and demonstrated experimentally by us [<xref ref-type="bibr" rid="pcbi.1005118.ref028">28</xref>] and others [<xref ref-type="bibr" rid="pcbi.1005118.ref036">36</xref>], such “pure” MIP controllers are not observed experimentally: that is, we find that the fluctuations along the GEM do not exhibit an unbounded random walk. Furthermore, our approach allows us to demonstrate this deviation from ideal MIP behavior geometrically, as well as in terms of stability and correlation properties. A conclusion of our work is that, while the control observed experimentally is congruent with the task manifold, it is not perfectly aligned with it: instead, the direction of “minimum intervention” (i.e., of weakest control) is close to, but not exactly tangent to the GEM. Nor is the direction of strongest control necessarily perpendicular to the GEM. One possible interpretation of these observations is that there are other competing costs, beyond simple error correction, that are at play during repeated task execution.</p>
<p>Other recent attempts to connect temporal analyses to task manifold geometry [<xref ref-type="bibr" rid="pcbi.1005118.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005118.ref051">51</xref>] have similarly supported our experimental findings, but have not directly shown how such results can be predicted from a general model-based analysis, as the current work does. Dingwell et al. [<xref ref-type="bibr" rid="pcbi.1005118.ref027">27</xref>] applied lag-1 correlation analyses to a redundant reaching task, but did not directly connect those experimental analyses back to any underlying computational model. Rácz &amp; Valero-Cuevas [<xref ref-type="bibr" rid="pcbi.1005118.ref051">51</xref>] used DFA analyses on data from a redundant, 3-finger grasping task to provide an experimental demonstration of the need to consider control as acting across both spatial and temporal domains. However, their work again did not provide mathematical theory able to explain and predict the observed behaviors. Nevertheless, in spite of these differences in experimental and/or computational approaches, each of the studies described above obtained findings consistent with our conclusion that the diverse geometrical and temporal aspects of inter-trial variability likely derive from a single underlying motor regulation process.</p>
<p>Our approach fully integrates task manifold geometry with ideas from control and dynamical systems theory, and thereby can be used to explain the structure of observed motor variability from a model-based, theoretical perspective. The theory and methods presented in this paper are quite general, and should be applicable to the study of skilled motor performance for a wide range of discrete, or discretizable, tasks. That said, general application can be expected to encounter difficulties, especially for tasks in which the relevant body and/or goal variables are high-dimensional (so that visualizing the GEM is difficult, if not impossible), as well as for tasks in which the goal function and GEM are not readily available in analytical form. In such cases, the basic theory will have to be used to formulate suitable, purely abstract, computational methods.</p>
<p>The assumption of skilled motor behavior, which implies that all fluctuations are near the GEM, permitted us to employ linear mathematics in our study. Without this linearity, it would have been much more difficult to make such precise, analytically-derived predictions. However, we did not impose linearity as a mere analytical convenience. On the contrary, our results show that a linear model of “GEM-aware” error correction captures key facets of the observed variability structure with substantial accuracy. The main aims of this paper were to robustly demonstrate the nature of dynamic anisotropy, to show how task performance is generated by the interaction of the GEM geometry and inter-trial error correction, and to demonstrate that such an approach yields results that are not sensitive to the coordinates chosen. As such, our focus on the steady state (i.e., learned) behavior of the inter-trial regulation system was appropriate. But this does not mean that the models and methods presented here would not have value for studies related to motor learning. Indeed, as discussed at some length above, models with a very similar mathematical structure have been used to precisely that end. From a dynamical systems perspective, our approach treats skilled movements as a “stochastic attractor” of the more general perception-action system engaged in motor learning. A logical point of departure for future work aimed at extending our methods to motor learning would be to study how the the “transient” portion of the a learning data set approaches the “steady-state” local geometrical structure uncovered using the methods of this paper. While such explorations would no doubt pose multiple challenges, in principle the theoretical concepts presented here could be extended to address questions of learning and/or adaptation, topics that we see as interesting aims of future work.</p>
</sec>
<sec id="sec014">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1005118.s001" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005118.s001" xlink:type="simple">
<label>S1 Data and Code</label>
<caption>
<title>A compressed folder containing all data and software used for this study.</title>
<p>(ZIP)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1005118.ref001">
<label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Bernstein</surname> <given-names>NA</given-names></name>. <source>The Coordination and Regulation of Movement</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Pergamon Press</publisher-name>; <year>1967</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref002">
<label>2</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Newell</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Corcos</surname> <given-names>DM</given-names></name>, editors. <source>Variability and Motor Control</source>. <publisher-loc>Champaign, IL</publisher-loc>: <publisher-name>Human Kinetics</publisher-name>; <year>1993</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref003">
<label>3</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Davids</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Benett</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Newell</surname> <given-names>K</given-names></name>, editors. <source>Movement System Variability</source>. <publisher-loc>Champaign, IL</publisher-loc>: <publisher-name>Human Kinetics</publisher-name>; <year>2006</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Latash</surname> <given-names>M</given-names></name>. <article-title>There is no motor redundancy in human movements. There is motor abundance</article-title>. <source>Motor Control</source>. <year>2000</year>;<volume>4</volume>:<fpage>259</fpage>–<lpage>260</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1123/mcj.4.3.259" xlink:type="simple">10.1123/mcj.4.3.259</ext-link></comment> <object-id pub-id-type="pmid">10970151</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van Emmerik</surname> <given-names>REA</given-names></name>, <name name-style="western"><surname>van Wegen</surname> <given-names>EEH</given-names></name>. <article-title>On the Functional Aspects of Variability in Postural Control</article-title>. <source>Exercise and Sport Sciences Reviews</source>. <year>2002</year>;<volume>30</volume>(<issue>4</issue>):<fpage>177</fpage>. <object-id pub-id-type="pmid">12398115</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Davids</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Glazier</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Araújo</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Bartlett</surname> <given-names>R</given-names></name>. <article-title>Movement Systems as Dynamical Systems: The functional role of variability and its implications for Sports Medicine</article-title>. <source>Sports Medicine</source>. <year>2003</year>;<volume>33</volume>(<issue>4</issue>):<fpage>245</fpage>–<lpage>260</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.2165/00007256-200333040-00001" xlink:type="simple">10.2165/00007256-200333040-00001</ext-link></comment> <object-id pub-id-type="pmid">12688825</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stein</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Gossen</surname> <given-names>ER</given-names></name>, <name name-style="western"><surname>Jones</surname> <given-names>KE</given-names></name>. <article-title>Neuronal Variability: Noise or Part of the Signal?</article-title> <source>Nature Reviews Neuroscience</source>. <year>2005</year>;<volume>6</volume>:<fpage>389</fpage>–<lpage>397</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn1668" xlink:type="simple">10.1038/nrn1668</ext-link></comment> <object-id pub-id-type="pmid">15861181</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Osborne</surname> <given-names>LC</given-names></name>, <name name-style="western"><surname>Lisberger</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>A Sensory Source for Motor Variation</article-title>. <source>Nature</source>. <year>2005</year>;<volume>437</volume>:<fpage>412</fpage>–<lpage>416</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature03961" xlink:type="simple">10.1038/nature03961</ext-link></comment> <object-id pub-id-type="pmid">16163357</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Faisal</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Selen</surname> <given-names>LPJ</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>. <article-title>Noise in the nervous system</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2008</year>;<volume>9</volume>(<issue>4</issue>):<fpage>292</fpage>–<lpage>303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2258" xlink:type="simple">10.1038/nrn2258</ext-link></comment> <object-id pub-id-type="pmid">18319728</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Eldar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Elowitz</surname> <given-names>MB</given-names></name>. <article-title>Functional roles for noise in genetic circuits</article-title>. <source>Nature</source>. <year>2010</year>;<volume>467</volume>(<issue>7312</issue>):<fpage>167</fpage>–<lpage>173</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature09326" xlink:type="simple">10.1038/nature09326</ext-link></comment> <object-id pub-id-type="pmid">20829787</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McDonnell</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Ward</surname> <given-names>LM</given-names></name>. <article-title>The benefits of noise in neural systems: bridging theory and experiment</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2011</year>;<volume>12</volume>(<issue>7</issue>):<fpage>415</fpage>–<lpage>426</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn3061" xlink:type="simple">10.1038/nrn3061</ext-link></comment> <object-id pub-id-type="pmid">21685932</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Scholz</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Schöner</surname> <given-names>G</given-names></name>. <article-title>The Uncontrolled Manifold Concept: Identifying Control Variables for a Functional Task</article-title>. <source>Experimental Brain Research</source>. <year>1999</year>;<volume>126</volume>(<issue>3</issue>):<fpage>289</fpage>–<lpage>305</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s002210050738" xlink:type="simple">10.1007/s002210050738</ext-link></comment> <object-id pub-id-type="pmid">10382616</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Müller</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Sternad</surname> <given-names>D</given-names></name>. <article-title>Decomposition of Variability in the Execution of Goal-Oriented Tasks: Three Components of Skill Improvement</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>. <year>2004</year>;<volume>30</volume>(<issue>1</issue>):<fpage>212</fpage>–<lpage>233</lpage>. <object-id pub-id-type="pmid">14769078</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cusumano</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Cesari</surname> <given-names>P</given-names></name>. <article-title>Body-goal variability mapping in an Aiming Task</article-title>. <source>Journal of Biological Cybernetics</source>. <year>2006</year>;<volume>94</volume>(<issue>5</issue>):<fpage>367</fpage>–<lpage>379</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-006-0052-1" xlink:type="simple">10.1007/s00422-006-0052-1</ext-link></comment> <object-id pub-id-type="pmid">16501988</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Scholz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Schöner</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Latash</surname> <given-names>M</given-names></name>. <article-title>Identifying the control structure of multijoint coordination during pistol shooting</article-title>. <source>Experimental Brain Research</source>. <year>2000</year>;<volume>135</volume>:<fpage>382</fpage>–<lpage>404</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s002210000540" xlink:type="simple">10.1007/s002210000540</ext-link></comment> <object-id pub-id-type="pmid">11146817</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Latash</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Scholz</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Schöner</surname> <given-names>G</given-names></name>. <article-title>Motor Control Strategies Revealed in the Structure of Motor Variability</article-title>. <source>Exercise &amp; Sport Sciences Reviews</source>. <year>2002</year>;<volume>30</volume>(<issue>1</issue>):<fpage>26</fpage>–<lpage>31</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schöner</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Scholz</surname> <given-names>JP</given-names></name>. <article-title>Analyzing Variance in Multi-Degree-of-Freedom Movements: Uncovering Structure Versus Extracting Correlations</article-title>. <source>Motor Control</source>. <year>2007</year>;<volume>11</volume>(<issue>3</issue>):<fpage>259</fpage>–<lpage>275</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1123/mcj.11.3.259" xlink:type="simple">10.1123/mcj.11.3.259</ext-link></comment> <object-id pub-id-type="pmid">17715459</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cohen</surname> <given-names>RG</given-names></name>, <name name-style="western"><surname>Sternad</surname> <given-names>D</given-names></name>. <article-title>Variability in motor learning: relocating, channeling and reducing noise</article-title>. <source>Experimental Brain Research</source>. <year>2009</year>;<volume>193</volume>(<issue>1</issue>):<fpage>69</fpage>–<lpage>83</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00221-008-1596-1" xlink:type="simple">10.1007/s00221-008-1596-1</ext-link></comment> <object-id pub-id-type="pmid">18953531</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ranganathan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Newell</surname> <given-names>KM</given-names></name>. <article-title>Influence of Motor Learning on Utilizing Path Redundancy</article-title>. <source>Neuroscience Letters</source>. <year>2010</year>;<volume>469</volume>(<issue>3</issue>):<fpage>416</fpage>–<lpage>420</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neulet.2009.12.041" xlink:type="simple">10.1016/j.neulet.2009.12.041</ext-link></comment> <object-id pub-id-type="pmid">20035835</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sternad</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Abe</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Müller</surname> <given-names>H</given-names></name>. <article-title>Neuromotor noise, error tolerance and velocity-dependent costs in skilled performance</article-title>. <source>PLoS Computational Biology</source>. <year>2011</year>;<volume>7</volume>(<issue>9</issue>):<fpage>e1002159</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002159" xlink:type="simple">10.1371/journal.pcbi.1002159</ext-link></comment> <object-id pub-id-type="pmid">21966262</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref021">
<label>21</label>
<mixed-citation publication-type="other" xlink:type="simple">John J, Cusumano JP. Inter-Trial Dynamics of Repeated Skilled Movements. In: Proceedings of the ASME International Design Engineering Technical Conference &amp; Information in Engineering Conference, Vol. 1 Pts. A–C; 2008. p. 707–716.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Scott</surname> <given-names>SH</given-names></name>. <article-title>Optimal Feedback Control and the Neural Basis of Volitional Motor Control</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2004</year>;<volume>5</volume>(<issue>7</issue>):<fpage>532</fpage>–<lpage>546</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn1427" xlink:type="simple">10.1038/nrn1427</ext-link></comment> <object-id pub-id-type="pmid">15208695</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Todorov</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>. <article-title>Optimal feedback control as a theory of motor coordination</article-title>. <source>Nature Neuroscience</source>. <year>2002</year>;<volume>5</volume>(<issue>11</issue>):<fpage>1226</fpage>–<lpage>1235</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn963" xlink:type="simple">10.1038/nn963</ext-link></comment> <object-id pub-id-type="pmid">12404008</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Todorov</surname> <given-names>E</given-names></name>. <article-title>Optimality principles in sensorimotor control</article-title>. <source>Nature Neuroscience</source>. <year>2004</year>;<volume>7</volume>(<issue>9</issue>):<fpage>907</fpage>–<lpage>915</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1309" xlink:type="simple">10.1038/nn1309</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dingwell</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Cusumano</surname> <given-names>JP</given-names></name>. <article-title>Re-interpreting detrended fluctuation analyses of stride-to-stride variability in human walking</article-title>. <source>Gait &amp; Posture</source>. <year>2010</year>;<volume>32</volume>(<issue>3</issue>):<fpage>348</fpage>–<lpage>353</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.gaitpost.2010.06.004" xlink:type="simple">10.1016/j.gaitpost.2010.06.004</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dingwell</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>John</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Cusumano</surname> <given-names>JP</given-names></name>. <article-title>Do Humans Optimally Exploit Redundancy to Control Step Variability in Walking?</article-title> <source>PLoS Computational Biology</source>. <year>2010</year>;<volume>6</volume>(<issue>7</issue>):<fpage>185</fpage>–<lpage>205</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dingwell</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Smallwood</surname> <given-names>RF</given-names></name>, <name name-style="western"><surname>Cusumano</surname> <given-names>JP</given-names></name>. <article-title>Trial-to-trial dynamics and learning in a generalized, redundant reaching task</article-title>. <source>Journal of Neurophysiology</source>. <year>2013</year>;<volume>109</volume>(<issue>1</issue>):<fpage>225</fpage>–<lpage>237</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00951.2011" xlink:type="simple">10.1152/jn.00951.2011</ext-link></comment> <object-id pub-id-type="pmid">23054607</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cusumano</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Dingwell</surname> <given-names>JB</given-names></name>. <article-title>Movement variability near goal equivalent manifolds: Fluctuations, control, and model-based analysis</article-title>. <source>Human Movement Science</source>. <year>2013</year>;<volume>32</volume>(<issue>5</issue>):<fpage>899</fpage>–<lpage>923</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.humov.2013.07.019" xlink:type="simple">10.1016/j.humov.2013.07.019</ext-link></comment> <object-id pub-id-type="pmid">24210574</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cusumano</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Mahoney</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Dingwell</surname> <given-names>JB</given-names></name>. <article-title>The Dynamical Analysis of Inter-Trial Fluctuations Near Goal Equivalent Manifolds</article-title>. <source>Advances in Experimental Medicine and Biology</source>. <year>2014</year>;<volume>826</volume>:<fpage>125</fpage>–<lpage>145</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/978-1-4939-1338-1_9" xlink:type="simple">10.1007/978-1-4939-1338-1_9</ext-link></comment> <object-id pub-id-type="pmid">25330889</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Abe</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Sternad</surname> <given-names>D</given-names></name>. <article-title>Directionality in Distribution and Temporal Structure of Variability in Skill Acquisition</article-title>. <source>Frontiers in Human Neuroscience</source>. <year>2013</year>;<volume>7</volume>(<issue>225</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnhum.2013.00225" xlink:type="simple">10.3389/fnhum.2013.00225</ext-link></comment> <object-id pub-id-type="pmid">23761742</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref031">
<label>31</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Golub</surname> <given-names>GH</given-names></name>, <name name-style="western"><surname>Van Loan</surname> <given-names>CF</given-names></name>. <source>Matrix Computations</source>. <publisher-loc>Baltimore, MD</publisher-loc>: <publisher-name>The John Hopkins University Press</publisher-name>; <year>1996</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Akman</surname> <given-names>OE</given-names></name>, <name name-style="western"><surname>Broomhead</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Clement</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Abadi</surname> <given-names>R</given-names></name>. <article-title>Nonlinear time series analysis of jerk congenital nystagmus</article-title>. <source>Journal of Computational Neuroscience</source>. <year>2006</year>;<volume>21</volume>(<issue>2</issue>):<fpage>153</fpage>–<lpage>170</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-006-7816-4" xlink:type="simple">10.1007/s10827-006-7816-4</ext-link></comment> <object-id pub-id-type="pmid">16732490</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref033">
<label>33</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Press</surname> <given-names>WH</given-names></name>, <name name-style="western"><surname>Teukolsky</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Vetterling</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Flannery</surname> <given-names>BP</given-names></name>. <source>Numerical Recipes in C: The Art of Scientific Computing</source>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>1992</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref034">
<label>34</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Efron</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>RJ</given-names></name>. <chapter-title>An Introduction to the Bootstrap</chapter-title>. <source>vol. 57 of CRC Monographs on Statistics &amp; Applied Probability</source>. <publisher-loc>Boca Raton, FL</publisher-loc>: <publisher-name>Chapman &amp; Hall</publisher-name>; <year>1994</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Domkin</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Laczko</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Jaric</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Johansson</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Latsh</surname> <given-names>M</given-names></name>. <article-title>Structure of joint variability in bimanual pointing task</article-title>. <source>Experimental Brain Research</source>. <year>2002</year>;<volume>143</volume>:<fpage>11</fpage>–<lpage>23</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00221-001-0944-1" xlink:type="simple">10.1007/s00221-001-0944-1</ext-link></comment> <object-id pub-id-type="pmid">11907686</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Valero-Cuevas</surname> <given-names>FJ</given-names></name>, <name name-style="western"><surname>Venkadesan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Todorov</surname> <given-names>E</given-names></name>. <article-title>Structured variability of muscle activations supports the minimal intervention principle of motor control</article-title>. <source>Journal of neurophysiology</source>. <year>2009</year>;<volume>102</volume>(<issue>1</issue>):<fpage>59</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.90324.2008" xlink:type="simple">10.1152/jn.90324.2008</ext-link></comment> <object-id pub-id-type="pmid">19369362</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Krishnamoorthy</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Latash</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Scholz</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Zatsiorsky</surname> <given-names>VM</given-names></name>. <article-title>Muscle synergies during shifts of the center of pressure by standing persons</article-title>. <source>Experimental brain research</source>. <year>2003</year>;<volume>152</volume>(<issue>3</issue>):<fpage>281</fpage>–<lpage>292</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00221-003-1574-6" xlink:type="simple">10.1007/s00221-003-1574-6</ext-link></comment> <object-id pub-id-type="pmid">12904934</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Latash</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Scholz</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Danion</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Schoner</surname> <given-names>G</given-names></name>. <article-title>Structure of motor variability in marginally redundant multifinger force production tasks</article-title>. <source>Experimental Brain Research</source>. <year>2001</year>;<volume>141</volume>(<issue>2</issue>):<fpage>153</fpage>–<lpage>165</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s002210100861" xlink:type="simple">10.1007/s002210100861</ext-link></comment> <object-id pub-id-type="pmid">11713627</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kang</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Shinohara</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Zatsiorsky</surname> <given-names>VM</given-names></name>, <name name-style="western"><surname>Latash</surname> <given-names>ML</given-names></name>. <article-title>Learning multi-finger synergies: an uncontrolled manifold analysis</article-title>. <source>Experimental Brain Research</source>. <year>2004</year>;<volume>157</volume>(<issue>3</issue>):<fpage>336</fpage>–<lpage>350</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00221-004-1850-0" xlink:type="simple">10.1007/s00221-004-1850-0</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sternad</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Park</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>Müller</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Hogan</surname> <given-names>N</given-names></name>. <article-title>Coordinate Dependence of Variability Analysis</article-title>. <source>PLoS Computational Biology</source>. <year>2010</year>;<volume>6</volume>(<issue>4</issue>):<fpage>e1000751</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000751" xlink:type="simple">10.1371/journal.pcbi.1000751</ext-link></comment> <object-id pub-id-type="pmid">20421930</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref041">
<label>41</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Jolliffe</surname> <given-names>IT</given-names></name>. <source>Principal Component Analysis</source>. <edition>2nd ed</edition>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2002</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref042">
<label>42</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Mardia</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Kent</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Bibby</surname> <given-names>JM</given-names></name>. <source>Multivariate Analysis</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Academic Press</publisher-name>; <year>1979</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref043">
<label>43</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Guckenheimer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Holmes</surname> <given-names>P</given-names></name>. <chapter-title>Nonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields</chapter-title>. <source>vol. 42 of Applied Mathematical Sciences</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>; <year>1997</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref044">
<label>44</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Hirsch</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Smale</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Devaney</surname> <given-names>RL</given-names></name>. <source>Differential Equations, Dynamical Systems and an Introduction to Chaos</source>. <edition>3rd ed</edition>. <publisher-loc>Waltham, MA</publisher-loc>: <publisher-name>Elsevier</publisher-name>; <year>2004</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Harris</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>. <article-title>Signal-Dependent Noise Determines Motor Planning</article-title>. <source>Nature</source>. <year>1998</year>;<volume>394</volume>(<issue>6695</issue>):<fpage>780</fpage>–<lpage>784</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/29528" xlink:type="simple">10.1038/29528</ext-link></comment> <object-id pub-id-type="pmid">9723616</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van Beers</surname> <given-names>RJ</given-names></name>. <article-title>Motor Learning Is Optimally Tuned to the Properties of Motor Noise</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>63</volume>(<issue>3</issue>):<fpage>406</fpage>–<lpage>417</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2009.06.025" xlink:type="simple">10.1016/j.neuron.2009.06.025</ext-link></comment> <object-id pub-id-type="pmid">19679079</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Burge</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>. <article-title>The statistical determinants of adaptation rate in human reaching</article-title>. <source>Journal of Vision</source>. <year>2008</year>;<volume>8</volume>(<issue>4</issue>):<fpage>1</fpage>–<lpage>19</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/8.4.20" xlink:type="simple">10.1167/8.4.20</ext-link></comment> <object-id pub-id-type="pmid">18484859</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Diedrichsen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hashambhoy</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Rane</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Shadmehr</surname> <given-names>R</given-names></name>. <article-title>Neural Correlates of Reach Errors</article-title>. <source>The Journal of Neuroscience</source>. <year>2005</year>;<volume>25</volume>(<issue>43</issue>):<fpage>9919</fpage>–<lpage>9931</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1874-05.2005" xlink:type="simple">10.1523/JNEUROSCI.1874-05.2005</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref049">
<label>49</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Verhulst</surname> <given-names>F</given-names></name>. <chapter-title>Nonlinear Differential Equations and Dynamical Systems</chapter-title>. <edition>2nd ed</edition>. <source>Universitext</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>; <year>1996</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref050">
<label>50</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Khalil</surname> <given-names>HK</given-names></name>. <source>Nonlinear systems</source>. <edition>3rd ed</edition>. <publisher-loc>New Jersey</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>; <year>2002</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rácz</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Valero-Cuevas</surname> <given-names>F</given-names></name>. <article-title>Spatio-temporal analysis reveals active control of both task-relevant and task-irrelevant variables</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2013</year>;<volume>7</volume>(<issue>155</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2013.00155" xlink:type="simple">10.3389/fncom.2013.00155</ext-link></comment> <object-id pub-id-type="pmid">24312045</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Terrier</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dériaz</surname> <given-names>O</given-names></name>. <article-title>Persistent and anti-persistent pattern in stride-to-stride variability of treadmill walking: Influence of rhythmic auditory cueing</article-title>. <source>Human Movement Science</source>. <year>2012</year>;<volume>31</volume>(<issue>6</issue>):<fpage>1585</fpage>–<lpage>1597</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.humov.2012.05.004" xlink:type="simple">10.1016/j.humov.2012.05.004</ext-link></comment> <object-id pub-id-type="pmid">23164626</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Terrier</surname> <given-names>P</given-names></name>. <article-title>Step-to-Step Variability in Treadmill Walking: Influence of Rhythmic Auditory Cueing</article-title>. <source>PLoS ONE</source>. <year>2012</year>;<volume>7</volume>(<issue>10</issue>):<fpage>e47171</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0047171" xlink:type="simple">10.1371/journal.pone.0047171</ext-link></comment> <object-id pub-id-type="pmid">23056604</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van Beers</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Brenner</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Smeets</surname> <given-names>JBJ</given-names></name>. <article-title>Random walk of motor planning in task-irrelevant dimensions</article-title>. <source>Journal of Neurophysiology</source>. <year>2013</year>;<volume>109</volume>(<issue>4</issue>):<fpage>969</fpage>–<lpage>977</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00706.2012" xlink:type="simple">10.1152/jn.00706.2012</ext-link></comment> <object-id pub-id-type="pmid">23175799</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hausdorff</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Peng</surname> <given-names>CK</given-names></name>, <name name-style="western"><surname>Ladin</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>JY</given-names></name>, <name name-style="western"><surname>Goldberger</surname> <given-names>AL</given-names></name>. <article-title>Is Walking a Random Walk? Evidence for Long-Range Correlations in Stride Interval of Human Gait</article-title>. <source>Journal of Applied Physiology</source>. <year>1995</year>;<volume>78</volume>(<issue>1</issue>):<fpage>349</fpage>–<lpage>358</lpage>. <object-id pub-id-type="pmid">7713836</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Peng</surname> <given-names>CK</given-names></name>, <name name-style="western"><surname>Buldyrev</surname> <given-names>SV</given-names></name>, <name name-style="western"><surname>Goldberger</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Havlin</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sciortino</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Simons</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Long-Range Correlations in Nucleotide Sequences</article-title>. <source>Nature</source>. <year>1992</year>;<volume>356</volume>(<issue>6365</issue>):<fpage>168</fpage>–<lpage>170</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/356168a0" xlink:type="simple">10.1038/356168a0</ext-link></comment> <object-id pub-id-type="pmid">1301010</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Delignières</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Torre</surname> <given-names>K</given-names></name>. <article-title>Fractal Dynamics of Human Gait: A Reassessment of the 1996 Data of Hausdorff et al</article-title>. <source>Journal of Applied Physiology</source>. <year>2009</year>;<volume>106</volume>(<issue>4</issue>):<fpage>1272</fpage>–<lpage>1279</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/japplphysiol.90757.2008" xlink:type="simple">10.1152/japplphysiol.90757.2008</ext-link></comment> <object-id pub-id-type="pmid">19228991</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Maraun</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Rust</surname> <given-names>HW</given-names></name>, <name name-style="western"><surname>Timmer</surname> <given-names>J</given-names></name>. <article-title>Tempting Long-Memory: On the Interpretation of DFA Results</article-title>. <source>Nonlinear Processes in Geophysics</source>. <year>2004</year>;<volume>11</volume>(<issue>4</issue>):<fpage>495</fpage>–<lpage>503</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5194/npg-11-495-2004" xlink:type="simple">10.5194/npg-11-495-2004</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gao</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Tung</surname> <given-names>WW</given-names></name>, <name name-style="western"><surname>Cao</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Sarshar</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Roychowdhury</surname> <given-names>VP</given-names></name>. <article-title>Assessment of Long-Range Correlation in Time Series: How to Avoid Pitfalls</article-title>. <source>Physical Review E</source>. <year>2006</year>;<volume>73</volume>:<fpage>016117</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.73.016117" xlink:type="simple">10.1103/PhysRevE.73.016117</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref060">
<label>60</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Marple</surname> <given-names>SL</given-names> <suffix>Jr</suffix></name>. <source>Digital Spectral Analysis with Applications</source>. <publisher-loc>Englewood Cliffs, NJ</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>; <year>1987</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref061">
<label>61</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Shumway</surname> <given-names>RH</given-names></name>, <name name-style="western"><surname>Stoffer</surname> <given-names>DS</given-names></name>. <source>Time Series Analysis and Its Applications</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2000</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref062">
<label>62</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Kantz</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Schreiber</surname> <given-names>T</given-names></name>. <source>Nonlinear Time Series Analysis</source>. <edition>2nd ed</edition>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>2004</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005118.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kirchner</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schubert</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Liebherr</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Haas</surname> <given-names>CT</given-names></name>. <article-title>Detrended Fluctuation Analysis and Adaptive Fractal Analysis of Stride Time Data in Parkinson’s Disease: Stitching Together Short Gait Trials</article-title>. <source>PLoS ONE</source>. <year>2014</year>;<volume>9</volume>(<issue>1</issue>):<fpage>e85787</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0085787" xlink:type="simple">10.1371/journal.pone.0085787</ext-link></comment> <object-id pub-id-type="pmid">24465708</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Peng</surname> <given-names>CK</given-names></name>, <name name-style="western"><surname>Havlin</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Stanley</surname> <given-names>HE</given-names></name>, <name name-style="western"><surname>Goldberger</surname> <given-names>AL</given-names></name>. <article-title>Quantification of Scaling Exponents and Crossover Phenomena in Nonstationary Heartbeat Time Series</article-title>. <source>Chaos</source>. <year>1995</year>;<volume>5</volume>(<issue>1</issue>):<fpage>82</fpage>–<lpage>87</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1063/1.166141" xlink:type="simple">10.1063/1.166141</ext-link></comment> <object-id pub-id-type="pmid">11538314</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Verrel</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Pradon</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Vuillerme</surname> <given-names>N</given-names></name>. <article-title>Persistence of Motor-Equivalent Postural Fluctuations during Bipedal Quiet Standing</article-title>. <source>PLoS ONE</source>. <year>2012</year>;<volume>7</volume>(<issue>10</issue>):<fpage>e48312</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0048312" xlink:type="simple">10.1371/journal.pone.0048312</ext-link></comment> <object-id pub-id-type="pmid">23110228</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005118.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van Beers</surname> <given-names>RJ</given-names></name>. <article-title>How Does Our Motor System Determine Its Learning Rate?</article-title> <source>PLoS ONE</source>. <year>2012</year>;<volume>7</volume>(<issue>11</issue>):<fpage>e49373</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0049373" xlink:type="simple">10.1371/journal.pone.0049373</ext-link></comment> <object-id pub-id-type="pmid">23152899</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
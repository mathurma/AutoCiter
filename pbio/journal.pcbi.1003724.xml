<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-13-01946</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003724</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group><subj-group><subject>Cognitive neuroscience</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Unsupervised Feature Learning Improves Prediction of Human Brain Activity in Response to Natural Images</article-title>
<alt-title alt-title-type="running-head">Feature Learning to Better Predict Brain Activity</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Güçlü</surname><given-names>Umut</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>van Gerven</surname><given-names>Marcel A. J.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
</contrib-group>
<aff id="aff1"><addr-line>Radboud University Nijmegen, Donders Institute for Brain, Cognition and Behaviour, Nijmegen, Netherlands</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Kriegeskorte</surname><given-names>Nikolaus</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Medical Research Council, United Kingdom</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">u.guclu@donders.ru.nl</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: UG MAJvG. Performed the experiments: UG. Analyzed the data: UG. Contributed reagents/materials/analysis tools: UG MAJvG. Wrote the paper: UG MAJvG.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>8</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>7</day><month>8</month><year>2014</year></pub-date>
<volume>10</volume>
<issue>8</issue>
<elocation-id>e1003724</elocation-id>
<history>
<date date-type="received"><day>5</day><month>11</month><year>2013</year></date>
<date date-type="accepted"><day>28</day><month>4</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Güçlü, van Gerven</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Encoding and decoding in functional magnetic resonance imaging has recently emerged as an area of research to noninvasively characterize the relationship between stimulus features and human brain activity. To overcome the challenge of formalizing what stimulus features should modulate single voxel responses, we introduce a general approach for making directly testable predictions of single voxel responses to statistically adapted representations of ecologically valid stimuli. These representations are learned from unlabeled data without supervision. Our approach is validated using a parsimonious computational model of (i) how early visual cortical representations are adapted to statistical regularities in natural images and (ii) how populations of these representations are pooled by single voxels. This computational model is used to predict single voxel responses to natural images and identify natural images from stimulus-evoked multiple voxel responses. We show that statistically adapted low-level sparse and invariant representations of natural images better span the space of early visual cortical representations and can be more effectively exploited in stimulus identification than hand-designed Gabor wavelets. Our results demonstrate the potential of our approach to better probe unknown cortical representations.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>An important but difficult problem in contemporary cognitive neuroscience is to find what stimulus features best drive responses in the human brain. The conventional approach to solve this problem is to use descriptive encoding models that predict responses to stimulus features that are known a priori. In this study, we introduce an alternative to this approach that is independent of a priori knowledge. Instead, we use a normative encoding model that predicts responses to stimulus features that are learned from unlabeled data. We show that this normative encoding model learns sparse, topographic and invariant stimulus features from tens of thousands of grayscale natural image patches without supervision, and reproduces the population behavior of simple and complex cells. We find that these stimulus features significantly better drive blood-oxygen-level dependent hemodynamic responses in early visual areas than Gabor wavelets–the fundamental building blocks of the conventional approach. Our approach will improve our understanding of how sensory information is represented beyond early visual areas since it can theoretically find what stimulus features best drive responses in other sensory areas.</p>
</abstract>
<funding-group><funding-statement>The first author was supported by the Huygens Scholarship Programme of the Netherlands organisation for international cooperation in higher education (<ext-link ext-link-type="uri" xlink:href="http://www.nuffic.nl/" xlink:type="simple">http://www.nuffic.nl/</ext-link>) and the Academy Assistants Programme of the Royal Netherlands Academy of Arts and Sciences (<ext-link ext-link-type="uri" xlink:href="http://www.knaw.nl/" xlink:type="simple">http://www.knaw.nl/</ext-link>). No further funding was received for this study. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="12"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>An important goal of contemporary cognitive neuroscience is to characterize the relationship between stimulus features and human brain activity. This relationship can be studied from two distinct but complementary perspectives of encoding and decoding <xref ref-type="bibr" rid="pcbi.1003724-Dayan1">[1]</xref>. The encoding perspective is concerned with how certain aspects of the environment are stored in the brain and uses models that predict brain activity in response to certain stimulus features. Conversely, the decoding perspective uses models that predict specific stimulus features from stimulus-evoked brain activity and is concerned with how specific aspects of the environment are retrieved from the brain.</p>
<p>Stimulus-response relationships have been extensively studied in computational neuroscience to understand the information contained in individual or ensemble neuronal responses, based on different coding schemes <xref ref-type="bibr" rid="pcbi.1003724-Brown1">[2]</xref>. The invasive nature of the measurement techniques of these studies has restricted human subjects to particular patient populations <xref ref-type="bibr" rid="pcbi.1003724-Quiroga1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Pasley1">[4]</xref>. However, with the advent of functional magnetic resonance imaging (fMRI), encoding and decoding in fMRI has made it possible to noninvasively characterize the relationship between stimulus features and human brain activity via localized changes in blood-oxygen-level dependent (BOLD) hemodynamic responses to sensory or cognitive stimulation <xref ref-type="bibr" rid="pcbi.1003724-Naselaris1">[5]</xref>.</p>
<p>Encoding models that predict single voxel responses to certain stimulus features typically comprise two main components. The first component is a (non)linear transformation from a stimulus space to a feature space. The second component is a (non)linear transformation from the feature space to a voxel space. Encoding models can be used to test alternative hypotheses about what a voxel represents since any encoding model embodies a specific hypothesis about what stimulus features modulate the response of the voxel <xref ref-type="bibr" rid="pcbi.1003724-Naselaris1">[5]</xref>. Furthermore, encoding models can be converted to decoding models that predict specific stimulus features from stimulus-evoked multiple voxel responses. In particular, decoding models can be used to determine the specific class from which the stimulus was drawn (i.e. classification) <xref ref-type="bibr" rid="pcbi.1003724-Haxby1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Kamitani1">[7]</xref>, identify the correct stimulus from a set of novel stimuli (i.e. identification) <xref ref-type="bibr" rid="pcbi.1003724-Kay1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Mitchell1">[9]</xref> or create a literal picture of the stimulus (i.e. reconstruction) <xref ref-type="bibr" rid="pcbi.1003724-Thirion1">[10]</xref>–<xref ref-type="bibr" rid="pcbi.1003724-Schoenmakers1">[12]</xref>.</p>
<p>The conventional approach to encoding and decoding makes use of feature spaces that are typically hand-designed by theorists or experimentalists <xref ref-type="bibr" rid="pcbi.1003724-Kay1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Mitchell1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Miyawaki1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Naselaris2">[13]</xref>–<xref ref-type="bibr" rid="pcbi.1003724-Kay2">[16]</xref>. However, this approach is prone to the influence of subjective biases and restricted to a priori hypotheses. As a result, it severely restricts the scope of alternative hypotheses that can be formulated about what a voxel represents. This restriction is evident by a paucity of models that adequately characterize extrastriate visual cortical voxels.</p>
<p>A recent trend in models of visual population codes has been the adoption of natural images for the characterization of voxels that respond to visual stimulation <xref ref-type="bibr" rid="pcbi.1003724-Kay1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Naselaris2">[13]</xref>. The motivation behind this trend is that natural images admit multiple feature spaces such as low-level edges, mid-level edge junctions, high-level object parts and complete objects that can modulate single voxel responses <xref ref-type="bibr" rid="pcbi.1003724-Naselaris1">[5]</xref>. Implicit about this motivation is the assumption that the brain is adapted to the statistical regularities in the environment <xref ref-type="bibr" rid="pcbi.1003724-Barlow1">[17]</xref> such as those in natural images <xref ref-type="bibr" rid="pcbi.1003724-Olshausen1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Bell1">[19]</xref>. At the same time, recent developments in theoretical neuroscience and machine learning have shown that normative and predictive models of natural image statistics learn statistically adapted representations of natural images. As a result, they predict statistically adapted visual cortical representations, based on different coding principles. Some of these predictions have been shown to be similar to what is found in the primary visual cortex such as topographically organized simple and complex cell receptive fields <xref ref-type="bibr" rid="pcbi.1003724-Hyvrinen1">[20]</xref>.</p>
<p>Building on previous studies of visual population codes and natural image statistics, we introduce a general approach for making directly testable predictions of single voxel responses to statistically adapted representations of ecologically valid stimuli. To validate our approach, we use a parsimonious computational model that comprises two main components (<xref ref-type="fig" rid="pcbi-1003724-g001">Figure 1</xref>). The first component is a nonlinear feature model that transforms raw stimuli to stimulus features. In particular, the feature model learns the transformation from unlabeled data without supervision. The second component is a linear voxel model that transforms the stimulus features to voxel responses. We use an fMRI data set of voxel responses to natural images that were acquired from the early visual areas (i.e. V1, V2 and V3) of two subjects (i.e. S1 and S2) <xref ref-type="bibr" rid="pcbi.1003724-Kay3">[21]</xref>. We show that the encoding and decoding performance of this computational model is significantly better than that of a hand-designed Gabor wavelet pyramid (GWP) model of phase-invariant complex cells. The software that implements our approach is provided at <ext-link ext-link-type="uri" xlink:href="http://www.ccnlab.net/research/" xlink:type="simple">http://www.ccnlab.net/research/</ext-link>.</p>
<fig id="pcbi-1003724-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003724.g001</object-id><label>Figure 1</label><caption>
<title>Encoding model.</title>
<p>The encoding model predicts single voxel responses to images by nonlinearly transforming the images to complex cell responses and linearly transforming the complex cell responses to the single voxel responses. For example, the encoding model predicts a voxel response to a 128<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e001" xlink:type="simple"/></inline-formula>128 image <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e002" xlink:type="simple"/></inline-formula> as follows: Each of the 16 non-overlapping 32<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e003" xlink:type="simple"/></inline-formula>32 patches of the image <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e004" xlink:type="simple"/></inline-formula> is first vectorized, preprocessed and linearly transformed to 625 simple cell responses, i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e005" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e006" xlink:type="simple"/></inline-formula> is a vectorized and preprocessed patch. Energies of the simple cells that are in each of the 625 partially overlapping 5<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e007" xlink:type="simple"/></inline-formula>5 neighborhoods are then locally pooled, i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e008" xlink:type="simple"/></inline-formula>, and nonlinearly transformed to one complex cell response, i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e009" xlink:type="simple"/></inline-formula>. Next, 10000 complex cell responses are linearly transformed to the voxel response, i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e010" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e011" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e012" xlink:type="simple"/></inline-formula>. The feature transformations are learned from unlabeled data. The voxel transformations are learned from feature-transformed stimulus-response pairs.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003724.g001" position="float" xlink:type="simple"/></fig></sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Feature models</title>
<p>To learn the feature transformation, we used a two-layer sparse coding (SC) model of 625 simple (i.e. first layer) and 625 complex (i.e. second layer) cells <xref ref-type="bibr" rid="pcbi.1003724-Hyvrinen2">[22]</xref>. Concretely, the simple cells were first arranged on a square grid graph that had circular boundary conditions. The weights between the simple and complex cells were then fixed such that each complex cell locally pooled the energies of 25 simple cells in a 5<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e013" xlink:type="simple"/></inline-formula>5 neighborhood. There were a total of 625 partially overlapping neighborhoods that were centered around the 625 simple cells. Next, the weights between the input and the simple cells were estimated from 50000 patches of size 32<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e014" xlink:type="simple"/></inline-formula>32 pixels by maximizing the sparseness of the locally pooled simple cell energies. Each simple cell was fully connected to the input (i.e. patch of size 32<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e015" xlink:type="simple"/></inline-formula>32 pixels). The patches were randomly sampled from the 1750 images of size 128<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e016" xlink:type="simple"/></inline-formula>128 pixels in the estimation set. To maximize the sparseness, the energy function (i.e. square nonlinearity) encourages the simple cell responses to be similar within the neighborhoods while the sparsity function (i.e. convex nonlinearity) encourages the locally pooled simple cell energies to be thinly dispersed across the neighborhoods. As a result, the simple cells that are in the same neighborhood have simultaneous activation and similar preferred parameters. Since the neighborhoods overlap, the preferred parameters of the simple and complex cells change smoothly across the grid graph. Finally, the complex cell responses of the SC model were defined as a static nonlinear function of the locally pooled simple cell energies after model estimation (i.e. total of 625 complex cell responses per patch of size 32<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e017" xlink:type="simple"/></inline-formula>32 pixels and 10000 complex cell responses per image of size 128<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e018" xlink:type="simple"/></inline-formula>128 pixels). The SC model learned topographically organized, spatially localized, oriented and bandpass simple and complex cell receptive fields that were similar to those found in the primary visual cortex (<xref ref-type="fig" rid="pcbi-1003724-g002">Figure 2A</xref>) <xref ref-type="bibr" rid="pcbi.1003724-Hubel1">[23]</xref>–.</p>
<fig id="pcbi-1003724-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003724.g002</object-id><label>Figure 2</label><caption>
<title>Simple cell receptive fields.</title>
<p>(A) Simple cell receptive fields of the SC model. Each square is of size 32<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e019" xlink:type="simple"/></inline-formula>32 pixels and shows the inverse weights between the input and a simple cell. The receptive fields were topographically organized, spatially localized, oriented and bandpass, similar to those found in the primary visual cortex. (B) Simple cell receptive fields of the GWP model. Each square is of size 128<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e020" xlink:type="simple"/></inline-formula>128 pixels and shows an even-symmetric Gabor wavelet. The grids show the locations of the remaining Gabor wavelets that were used. The receptive fields spanned eight orientations and six spatial frequencies.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003724.g002" position="float" xlink:type="simple"/></fig>
<p>To establish a baseline, we used a GWP model <xref ref-type="bibr" rid="pcbi.1003724-Jones1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Daugman1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Lee1">[28]</xref> of 10921 phase-invariant complex cells <xref ref-type="bibr" rid="pcbi.1003724-Kay1">[8]</xref>. Variants of this model were used in a series of seminal encoding and decoding studies <xref ref-type="bibr" rid="pcbi.1003724-Kay1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Naselaris2">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Nishimoto1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Kay2">[16]</xref>. Note that the fMRI data set was the same as that in <xref ref-type="bibr" rid="pcbi.1003724-Kay1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Naselaris2">[13]</xref>. Concretely, the GWP model was a hand-designed population of quadrature-phase Gabor wavelets that spanned a range of locations, orientations and spatial frequencies (<xref ref-type="fig" rid="pcbi-1003724-g002">Figure 2B</xref>). Each wavelet was fully connected to the input (i.e. image of size 128<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e021" xlink:type="simple"/></inline-formula>128 pixels). The complex cell responses of the GWP model were defined as a static nonlinear function of the pooled energies of the quadrature-phase wavelets that had the same location, orientation and spatial frequency (i.e. total of 10921 complex cell responses per image of size 128<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e022" xlink:type="simple"/></inline-formula>128 pixels).</p>
</sec><sec id="s2b">
<title>Voxel models</title>
<p>To learn the voxel transformation, we used regularized linear regression. The voxel models were estimated from the 1750 feature-transformed stimulus-response pairs in the estimation set by minimizing the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e023" xlink:type="simple"/></inline-formula> penalized least squares loss function. The combination of a voxel model with the complex cells of the SC and GWP models resulted in two encoding models (i.e. SC2 and GWP2 models). The SC2 model linearly pooled the 10000 complex cell responses of the SC model. The GWP2 model linearly pooled the 10921 complex cell responses of the GWP model.</p>
</sec><sec id="s2c">
<title>Receptive fields</title>
<p>We first analyzed the receptive fields of the SC model (i.e. simple and complex cell receptive fields). The preferred phase, location, orientation and spatial frequency of the simple and complex cells were quantified as the corresponding parameters of Gabor wavelets that were fit to their receptive fields. The preferred parameter maps of the simple and complex cells were constructed by arranging their preferred parameters on the grid graph (<xref ref-type="fig" rid="pcbi-1003724-g003">Figure 3</xref>). Most adjacent simple and complex cells had similar location, orientation and spatial frequency preference, whereas they had different phase preference. In agreement with <xref ref-type="bibr" rid="pcbi.1003724-Hyvrinen2">[22]</xref>, the preferred phase, location and orientation maps reproduced some of the salient features of the columnar organization of the primary visual cortex such as lack of spatial structure <xref ref-type="bibr" rid="pcbi.1003724-DeAngelis1">[29]</xref>, retinotopy <xref ref-type="bibr" rid="pcbi.1003724-Hubel2">[30]</xref> and pinwheels <xref ref-type="bibr" rid="pcbi.1003724-Blasdel1">[31]</xref>, respectively. In contrast to <xref ref-type="bibr" rid="pcbi.1003724-Hyvrinen2">[22]</xref>, the preferred spatial frequency maps failed to reproduce cytochrome oxidase blobs <xref ref-type="bibr" rid="pcbi.1003724-Tootell1">[32]</xref>. The preferred phase map of the simple cells suggests that the complex cells are more invariant to phase and location than the simple cells since the complex cells pooled the energies of the simple cells that had different phase preference. To verify the invariance that is suggested by the preferred phase map of the simple cells, the population parameter tuning curves of the simple and complex cells were constructed by fitting Gaussian functions to the median of their responses to Gabor wavelets that had different parameters (<xref ref-type="fig" rid="pcbi-1003724-g004">Figure 4</xref>). Like the simple cells, most complex cells were selective to orientation (i.e. standard deviation of 21.8° versus 22.9°) and spatial frequency (i.e. standard deviation of 0.52 versus 0.54 in normalized units). Unlike the simple cells, most complex cells were more invariant to phase (i.e. standard deviation of 50.0° versus 158.1°) and location (i.e. standard deviation of 3.70 pixels versus 5.86 pixels). Therefore, they optimally responded to Gabor wavelets that had a specific orientation and spatial frequency, regardless of their phase and exact position.</p>
<fig id="pcbi-1003724-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003724.g003</object-id><label>Figure 3</label><caption>
<title>Preferred parameter maps of the SC model.</title>
<p>The phase, location, orientation and spatial frequency preference of the simple and complex cells were quantified as the corresponding parameters of Gabor wavelets that were fit to their receptive fields. Each pixel in a parameter map shows the corresponding preferred parameter of a simple or complex cell. The adjacent simple and complex cells had similar location, orientation and spatial frequency preference but different phase preference.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003724.g003" position="float" xlink:type="simple"/></fig><fig id="pcbi-1003724-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003724.g004</object-id><label>Figure 4</label><caption>
<title>Population parameter tuning curves of the SC model.</title>
<p>The population phase, location, orientation and spatial frequency tunings of the simple (solid lines) and complex cells (dashed lines) were quantified by fitting Gaussian functions to the median of their responses to Gabor wavelets that had different parameters. Each curve shows the median of their responses as a function of change in their preferred parameter. The complex cells were more invariant to phase and location than the simple cells.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003724.g004" position="float" xlink:type="simple"/></fig>
<p>We then analyzed the receptive fields of the SC2 model (i.e. voxel receptive fields). The eccentricity and size of the receptive fields were quantified as the mean and standard deviation of two-dimensional Gaussian functions that were fit to the voxel responses to point stimuli at different locations, respectively. The orientation and spatial frequency tuning of the receptive fields were taken to be the voxel responses to sine-wave gratings that spanned a range of orientations and spatial frequencies. While the eccentricity, size and orientation tuning varied across voxels, most voxels were tuned to relatively high spatial frequencies (<xref ref-type="fig" rid="pcbi-1003724-g005">Figure 5A</xref> and <xref ref-type="fig" rid="pcbi-1003724-g005">Figure 5B</xref>). The mean predicted voxel responses to sine-wave gratings that had oblique orientations were higher than those that had cardinal orientations and this difference decreased with spatial frequency (<xref ref-type="fig" rid="pcbi-1003724-g005">Figure 5C</xref>). While this result is in contrast to those of the majority of previous single-unit recording and fMRI studies <xref ref-type="bibr" rid="pcbi.1003724-Mansfield1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Furmanski1">[34]</xref>, it is in agreement with those of <xref ref-type="bibr" rid="pcbi.1003724-Swisher1">[35]</xref>. In line with <xref ref-type="bibr" rid="pcbi.1003724-Dumoulin1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Smith1">[37]</xref>, the receptive field size systematically increased from V1 to V3 and from low receptive field eccentricity to high receptive field eccentricity (<xref ref-type="fig" rid="pcbi-1003724-g006">Figure 6</xref>). The properties of the GWP2 model were similar to those in <xref ref-type="bibr" rid="pcbi.1003724-Kay1">[8]</xref>. The relationship between the receptive field parameters (i.e. size, eccentricity, area) of the GWP2 model were the same as those of the SC2 model. However, the GWP2 model did not have a large orientation bias.</p>
<fig id="pcbi-1003724-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003724.g005</object-id><label>Figure 5</label><caption>
<title>Receptive fields of the SC2 model.</title>
<p>The parameter tuning varied across the voxels and had a bias for high spatial frequencies and oblique orientations. (A) Two-dimensional Gaussian functions that were fit to the responses of three representative voxels to point stimuli at different locations. (B) Responses of three representative voxels to sine-wave gratings that spanned a range of orientations and spatial frequencies. (C) Mean responses across the voxels to sine-wave gratings that spanned a range of orientations and spatial frequencies.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003724.g005" position="float" xlink:type="simple"/></fig><fig id="pcbi-1003724-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003724.g006</object-id><label>Figure 6</label><caption>
<title>Receptive field size of the SC2 model as a function of receptive field eccentricity of the SC2 model and area.</title>
<p>The eccentricity and size of the receptive fields were quantified as the mean and standard deviation of two-dimensional Gaussian functions that were fit to the voxel responses to point stimuli at different locations, respectively. The receptive field size systematically increased from low to high receptive field eccentricity and from area V1 to V3. Error bars show <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e024" xlink:type="simple"/></inline-formula>1 SEM across the voxels (bootstrapping method).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003724.g006" position="float" xlink:type="simple"/></fig></sec><sec id="s2d">
<title>Encoding</title>
<p>The encoding performance of the SC2 and GWP2 models was defined as the coefficient of determination (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e025" xlink:type="simple"/></inline-formula>) between the observed and predicted voxel responses to the 120 images in the validation set across the two subjects. The performance of the SC2 model was found to be significantly higher than that of the GWP2 model (binomial test, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e026" xlink:type="simple"/></inline-formula>). <xref ref-type="fig" rid="pcbi-1003724-g007">Figures 7A and 7B</xref> compare the performance of the models across the voxels that survived an <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e027" xlink:type="simple"/></inline-formula> threshold of 0.1. The mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e028" xlink:type="simple"/></inline-formula> of the SC2 model systematically decreased from 0.28 across 28% of the voxels in V1 to 0.21 across 11% of the voxels in V3. In contrast, the mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e029" xlink:type="simple"/></inline-formula> of the GWP2 model systematically decreased from 0.24 across 24% of the voxels in V1 to 0.16 across 6% of the voxels in V3. <xref ref-type="fig" rid="pcbi-1003724-g007">Figure 7C</xref> compares the performance of the models in each voxel. More than 71% of the voxels that did not survive the threshold in each area and more than 92% of the voxels that survived the threshold in each area were better predicted by the SC2 model than the GWP2 model. These results suggest that statistically adapted low-level sparse representations of natural images better span the space of early visual cortical representations than the Gabor wavelets.</p>
<fig id="pcbi-1003724-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003724.g007</object-id><label>Figure 7</label><caption>
<title>Encoding performance of the SC2 and GWP2 models.</title>
<p>The encoding performance was defined as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e030" xlink:type="simple"/></inline-formula> between the observed and predicted voxel responses to the 120 images in the validation set across the two subjects. The encoding performance of the SC2 model was significantly higher than that of the GWP2 model. (A) Prediction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e031" xlink:type="simple"/></inline-formula> across the voxels that survived the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e032" xlink:type="simple"/></inline-formula> threshold of 0.1. (B) Mean prediction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e033" xlink:type="simple"/></inline-formula> across the voxels that survived the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e034" xlink:type="simple"/></inline-formula> threshold of 0.1. Error bars show <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e035" xlink:type="simple"/></inline-formula>1 SEM across the voxels (bootstrapping method). (C) Prediction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e036" xlink:type="simple"/></inline-formula> in each voxel.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003724.g007" position="float" xlink:type="simple"/></fig></sec><sec id="s2e">
<title>Decoding</title>
<p>The decoding performance of the SC2 and GWP2 models was defined as the accuracy of identifying the 120 images in the validation set from a set of 9264 candidate images. The set of candidate images contained the 120 images in the validation set and the 9144 images in the Caltech 101 data set <xref ref-type="bibr" rid="pcbi.1003724-FeiFei1">[38]</xref>. Note that the set of candidate images was ten- to hundred-fold larger than the sets in <xref ref-type="bibr" rid="pcbi.1003724-Kay1">[8]</xref> but comparable to the largest set in <xref ref-type="bibr" rid="pcbi.1003724-Vu1">[15]</xref>. The performance of the SC2 model was found to be significantly higher than that of the GWP2 model (binomial test, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e037" xlink:type="simple"/></inline-formula>). <xref ref-type="fig" rid="pcbi-1003724-g008">Figure 8</xref> compares the performance of the models. The mean accuracy of the SC2 model across the subjects was 61%. In contrast, the mean accuracy of the GWP2 model across the subjects was 49%. The chance-level accuracy was 0.01%. These results suggest that statistically adapted low-level sparse representations of natural images can be more effectively exploited in stimulus identification than the Gabor wavelets.</p>
<fig id="pcbi-1003724-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003724.g008</object-id><label>Figure 8</label><caption>
<title>Decoding performance of the SC2 and GWP2 models.</title>
<p>The decoding performance was defined as the accuracy of identifying the 120 images in the validation set from a set of 9264 candidate images. The decoding performance of the SC2 model was significantly higher than that of the GWP2 model. Error bars show <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e038" xlink:type="simple"/></inline-formula>1 SEM across the images in the validation set (bootstrapping method). A more detailed figure that shows the identified images is provided at <ext-link ext-link-type="uri" xlink:href="http://www.ccnlab.net/research/" xlink:type="simple">http://www.ccnlab.net/research/</ext-link>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003724.g008" position="float" xlink:type="simple"/></fig></sec><sec id="s2f">
<title>Spatial invariance</title>
<p>In principle, the SC2 and GWP2 models should have some degree of spatial invariance since they linearly pooled the responses of the complex cells that displayed insensitivity to local stimulus position. Spatial invariance is of particular importance for decoding since a reliable decoder should be able to identify a stimulus, regardless of its exact position. Furthermore, a difference between the degree of spatial invariance of the models can be a contributing factor to the difference between their performance. To analyze the spatial invariance of the models, we evaluated their encoding and decoding performance after translating the images in the validation set by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e039" xlink:type="simple"/></inline-formula> (i.e. approximately the standard deviation of the population location tuning curves of the complex cells of the SC model) in a random dimension (<xref ref-type="fig" rid="pcbi-1003724-g009">Figure 9</xref>). The encoding and decoding performance of the models was found to decrease after the translations. Unlike the encoding performance of the GWP2 model, that of the SC2 model decreased less in V3 than V1. This result suggests greater spatial invariance in V3 than V1. The difference between the mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e040" xlink:type="simple"/></inline-formula> of the models across the voxels that survived the threshold before the translations increased from 0.05 to 0.11. The difference between the mean accuracy of the models across the subjects increased from 12% to 24%. These results suggest that the SC2 model is more tolerant to local translations in stimulus position than the GWP2 model.</p>
<fig id="pcbi-1003724-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003724.g009</object-id><label>Figure 9</label><caption>
<title>Mean prediction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e041" xlink:type="simple"/></inline-formula> and identification accuracy of the SC2 and GWP2 models after (a) and before (b) translating the images in the validation set by 0.8° in a random dimension.</title>
<p>The SC2 model was more invariant than the GWP2 model and its invariance increased from V1 to V3. (A) Mean prediction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e042" xlink:type="simple"/></inline-formula> across the voxels that survived the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e043" xlink:type="simple"/></inline-formula> threshold of 0.1 in the case of (b). Error bars show <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e044" xlink:type="simple"/></inline-formula>1 SEM across the voxels (bootstrapping method). (B) Identification accuracy. Error bars show <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e045" xlink:type="simple"/></inline-formula>1 SEM across the images in the validation set (bootstrapping method).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003724.g009" position="float" xlink:type="simple"/></fig></sec><sec id="s2g">
<title>Control models</title>
<p>Since the SC2 and GWP2 models had different nonlinearities (i.e. pooling and static nonlinearity), a direct evaluation of the contribution of their components (i.e. representations and nonlinearities) to the difference between their encoding performance was not possible. Therefore, we estimated two control models that pooled the same static nonlinear function of the simple cell responses of the SC and GWP models. The static nonlinear function was a compressive nonlinearity (i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e046" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e047" xlink:type="simple"/></inline-formula> is a simple cell response). The compressive nonlinearity roughly accounts for insensitivities by increasing responses to a stimulus that is not entirely within a receptive field <xref ref-type="bibr" rid="pcbi.1003724-Kay4">[39]</xref>. The simple cell responses were defined as the linear responses of the first layer of the SC model and the even-symmetric Gabor wavelets. While the performance of the compressive nonlinear SC model was significantly higher than that of the compressive nonlinear GWP model, the difference between the performance of the compressive nonlinear models was significantly lower than that of the SC2 and GWP2 models (<xref ref-type="fig" rid="pcbi-1003724-g010">Figure 10</xref>). This result suggests that both the representations and the nonlinearities of the SC2 model contribute to the difference between the encoding performance of the SC2 and GWP2 models.</p>
<fig id="pcbi-1003724-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003724.g010</object-id><label>Figure 10</label><caption>
<title>Mean prediction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e048" xlink:type="simple"/></inline-formula> of the linear one-layer (l), compressive nonlinear one-layer (cn) and nonlinear two-layer (2) SC and GWP models across the voxels that survived the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e049" xlink:type="simple"/></inline-formula> threshold of 0.1 in the case of (2).</title>
<p>The mean prediction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e050" xlink:type="simple"/></inline-formula> of the linear one-layer models were below the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e051" xlink:type="simple"/></inline-formula> threshold of 0.1. The mean prediction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e052" xlink:type="simple"/></inline-formula> of the nonlinear SC models were significantly better than those of the nonlinear GWP models. The compressive nonlinearity and the nonlinear second layer increased the mean prediction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e053" xlink:type="simple"/></inline-formula> of the linear and compressive nonlinear models, respectively. The nonlinear second layer increased the mean prediction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e054" xlink:type="simple"/></inline-formula> of the compressive nonlinear SC model more than it increased that of the compressive nonlinear GWP model. The error bars show <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e055" xlink:type="simple"/></inline-formula>1 SEM across the voxels (bootstrapping method).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003724.g010" position="float" xlink:type="simple"/></fig>
<p>To verify the contribution of the nonlinearities to the individual encoding performance of the SC2 and GWP2 models, we estimated two more control models that pooled a linear function of the simple cell responses of the SC and GWP models. We used linear models since they retain selectivities that are discarded by nonlinearities. We found that the performance of the linear models were significantly lower than that of the compressive nonlinear, SC2 and GWP2 models (<xref ref-type="fig" rid="pcbi-1003724-g010">Figure 10</xref>). This result confirms the contribution of the nonlinearities that introduced the insensitivities to the individual encoding performance of the SC2 and GWP2 models.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>This study addresses the question of how to model feature spaces to better predict brain activity. We introduced a general approach for making directly testable predictions of single voxel responses to statistically adapted representations of ecologically valid stimuli. Our approach relies on unsupervised learning of a feature model followed by supervised learning of a voxel model. To benchmark our approach against the conventional approach that makes use of predefined feature spaces, we compared a two-layer sparse coding model of simple and complex cells with a Gabor wavelet pyramid model of phase-invariant complex cells. While the GWP model is the fundamental building block of many state-of-the-art encoding and decoding models, the GWP2 model was found to be significantly outperformed by the SC2 model. We used control models to determine the contribution of the different components of the SC2 and GWP2 models to this performance difference. Analyses revealed that the SC2 model better accounts for both the representations and the nonlinearities of the voxels in the early visual areas than the GWP2 model. Given that the representations of the SC2 model are qualitatively similar to those of the GWP model, their contribution to this performance difference suggests that the SC model automatically learns an optimal set of spatially localized, oriented and bandpass representations that better span the space of early visual cortical representations since it adapts to the same statistical regularities in the environment as the brain is assumed to be adapted to <xref ref-type="bibr" rid="pcbi.1003724-Hyvrinen1">[20]</xref>.</p>
<p>Our approach eliminates the need for predefining feature spaces. However, the SC model does have a number of free parameters (e.g. patch size, number of simple and complex cells, etc.) that must either be specified by hand or using model selection methods such as cross-validation. Because of computational considerations, we used the same free parameters as those in <xref ref-type="bibr" rid="pcbi.1003724-Hyvrinen2">[22]</xref>. While the choice of these free parameters can influence what the SC model can learn, the SC2 model was shown to outperform the GWP2 model even without cross-validation. Next to cross-validation, other methods that also infer these free parameters can further improve the performance of the SC2 model. One method is to first estimate voxel receptive fields using any approach and then use these estimates as free parameters (e.g. voxel receptive field eccentricity as patch size) of voxel-specific feature models. Another method is to use more sophisticated nonparametric Bayesian sparse factor models <xref ref-type="bibr" rid="pcbi.1003724-Knowles1">[40]</xref> that can simultaneously learn sparse representations while inferring their number. Furthermore, our approach included only feedforward projections such that representations and responses were solely determined by stimuli. However, taking top-down modulatory effects into account is essential to adequately characterize how sensory information is represented and processed in the brain. For example, attention has been shown to warp semantic representations across the human brain <xref ref-type="bibr" rid="pcbi.1003724-ukur1">[41]</xref>, and prior expectations have been shown to bias sensory representations in visual cortex <xref ref-type="bibr" rid="pcbi.1003724-Kok1">[42]</xref>. Extensions of our approach that include feedback projections can be used to address the question of how representations and responses are influenced by top-down processes.</p>
<p>Further extensions of our approach can be used to probe mid- to high-level extrastriate visual cortical representations in a fully automated manner. In particular, the SC model can be replaced by highly nonlinear multi-layer statistical models of natural images that learn hierarchical feature spaces (i.e. deep learning <xref ref-type="bibr" rid="pcbi.1003724-Bengio1">[43]</xref>). Some of the feature spaces that are learned by these models such as mid-level edge junctions have been shown to match well with neural response functions in area V2 <xref ref-type="bibr" rid="pcbi.1003724-Lee2">[44]</xref>. Models that learn even higher-level representations such as high-level object parts <xref ref-type="bibr" rid="pcbi.1003724-Lee3">[45]</xref> or complete objects <xref ref-type="bibr" rid="pcbi.1003724-Le1">[46]</xref> can be used to probe extrastriate visual cortical representations. For example, heterogenous hierarchical convolutional neural networks have been shown to predict the representational dissimilarity matrices that characterize representations in human inferior temporal gyrus <xref ref-type="bibr" rid="pcbi.1003724-Yamins1">[47]</xref>. Similar models have been shown to learn feature spaces that are admitted by stimulus sets other than natural images, both within the visual modality (e.g. natural movies <xref ref-type="bibr" rid="pcbi.1003724-Le2">[48]</xref>) as well as in other modalities (e.g. auditory or somatosensory <xref ref-type="bibr" rid="pcbi.1003724-Saxe1">[49]</xref>). These models can be used to probe cortical representations in different sensory modalities.</p>
<p>One approach to estimate deep models is to maximize the likelihood of all layers at the same time. However, this approach is not scalable and requires the computation of intractable partition functions that are impossible to integrate analytically and computationally expensive to integrate numerically. Nevertheless, methods such as score-matching <xref ref-type="bibr" rid="pcbi.1003724-Hyvrinen3">[50]</xref> and noise-contrastive estimation <xref ref-type="bibr" rid="pcbi.1003724-Gutmann1">[51]</xref> have been used to estimate unnormalized nonlinear multi-layer statistical models of natural images <xref ref-type="bibr" rid="pcbi.1003724-Kster1">[52]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Gutmann2">[53]</xref>. An alternative approach is to use models such as deep belief networks that comprise multiple layers of restricted Boltzmann machines. These models can be scaled by convolution <xref ref-type="bibr" rid="pcbi.1003724-Lee3">[45]</xref> and estimated by maximizing the likelihood of one layer at a time, using the output of each layer as input for the subsequent layer <xref ref-type="bibr" rid="pcbi.1003724-Hinton1">[54]</xref>. Importantly, generative models such as deep belief networks make it possible to sample stimuli based on internal network states. Conditioning these internal network states on stimulus-evoked brain activity results in a generative approach to decoding. For example, we have previously shown that a deep belief network that comprise multiple layers of conditional restricted Boltzmann machines can reconstruct handwritten digits by sampling from the model after conditioning it on stimulus-evoked multiple voxel responses <xref ref-type="bibr" rid="pcbi.1003724-vanGerven1">[55]</xref>.</p>
<p>While introducing a new approach to probe cortical representations, this study complements other developments in encoding and decoding. For example, encoding models that involve computations to account for contrast saturation or heterogeneous contrast energy were shown to improve prediction of single voxel responses to visual stimuli <xref ref-type="bibr" rid="pcbi.1003724-Kay2">[16]</xref>. At the same time, these modeling efforts go hand in hand with developments in fMRI such as the improvements in contrast-to-noise ratio and spatial resolution that are facilitated by increases in magnetic field strength <xref ref-type="bibr" rid="pcbi.1003724-Duyn1">[56]</xref>. For example, spatial features of orientation-selective columns in humans were demonstrated by using high-field fMRI <xref ref-type="bibr" rid="pcbi.1003724-Yacoub1">[57]</xref>. Jointly, such developments can provide novel insights into how cortical representations are learned, encoded and transformed.</p>
<p>In conclusion, we introduced a general approach that improves prediction of human brain activity in response to natural images. Our approach primarily relies on unsupervised learning of transformations of raw stimuli to representations that span the space of cortical representations. These representations can also be effectively exploited in stimulus classification, identification or reconstruction. Taken together, unsupervised feature learning heralds new ways to characterize the relationship between stimulus features and human brain activity.</p>
</sec><sec id="s4" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Data</title>
<p>We used the fMRI data set <xref ref-type="bibr" rid="pcbi.1003724-Kay3">[21]</xref> that was originally published in <xref ref-type="bibr" rid="pcbi.1003724-Kay1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Naselaris2">[13]</xref>. Briefly, the data set contained 1750 and 120 stimulus-response pairs of two subjects (i.e. S1 and S2) in the estimation and validation sets, respectively. The stimulus-response pairs consisted of grayscale natural images of size 128<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e056" xlink:type="simple"/></inline-formula>128 pixels and stimulus-evoked peak BOLD hemodynamic responses of 5512 (S1) and 5275 (S2) voxels in the early visual areas (i.e. V1, V2 and V3). The details of the experimental procedures are presented in <xref ref-type="bibr" rid="pcbi.1003724-Kay1">[8]</xref>.</p>
</sec><sec id="s4b">
<title>Problem statement</title>
<sec id="s4b1">
<title>Encoding</title>
<p>Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e057" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e058" xlink:type="simple"/></inline-formula> be a stimulus-response pair where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e059" xlink:type="simple"/></inline-formula> is a vector of pixels in a grayscale natural image, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e060" xlink:type="simple"/></inline-formula> is a vector of voxel responses. The parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e061" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e062" xlink:type="simple"/></inline-formula> denote the number of pixels and voxels, respectively. Given <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e063" xlink:type="simple"/></inline-formula>, we are interested in the problem of predicting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e064" xlink:type="simple"/></inline-formula>: <disp-formula id="pcbi.1003724.e065"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e065" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e066" xlink:type="simple"/></inline-formula> is the predicted response to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e067" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e068" xlink:type="simple"/></inline-formula> is the encoding distribution of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e069" xlink:type="simple"/></inline-formula> given <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e070" xlink:type="simple"/></inline-formula>. The function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e071" xlink:type="simple"/></inline-formula> nonlinearly transforms <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e072" xlink:type="simple"/></inline-formula> from the stimulus space to the feature space, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e073" xlink:type="simple"/></inline-formula> linearly transforms <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e074" xlink:type="simple"/></inline-formula> from the feature space to the voxel space.</p>
</sec><sec id="s4b2">
<title>Decoding</title>
<p>Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e075" xlink:type="simple"/></inline-formula> be a set of images that contains <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e076" xlink:type="simple"/></inline-formula>. Given <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e077" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e078" xlink:type="simple"/></inline-formula>, we are interested in the problem of identifying <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e079" xlink:type="simple"/></inline-formula>: <disp-formula id="pcbi.1003724.e080"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e080" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e081" xlink:type="simple"/></inline-formula> is the identified image from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e082" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e083" xlink:type="simple"/></inline-formula> is the Pearson product-moment correlation coefficient between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e084" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e085" xlink:type="simple"/></inline-formula>.</p>
<p>Solving the encoding and decoding problems requires the definition and estimation of a feature model <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e086" xlink:type="simple"/></inline-formula> followed by a voxel model <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e087" xlink:type="simple"/></inline-formula>.</p>
</sec></sec><sec id="s4c">
<title>Feature model</title>
<sec id="s4c1">
<title>Model definition</title>
<p>Following <xref ref-type="bibr" rid="pcbi.1003724-Hyvrinen2">[22]</xref>, we summarize the definition of the SC model. We start by defining a single-layer statistical generative model of whitened grayscale natural image patches. Assuming that a patch is generated by a linear superposition of latent variables that are non-Gaussian (in particular, sparse) and mutually independent, we first use independent component analysis to define the model by a linear transformation of independent components of the patch: <disp-formula id="pcbi.1003724.e088"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e088" xlink:type="simple"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e089" xlink:type="simple"/></inline-formula> is a vector of pixels in the patch, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e090" xlink:type="simple"/></inline-formula> is a mixing matrix, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e091" xlink:type="simple"/></inline-formula> is a vector of the components of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e092" xlink:type="simple"/></inline-formula> such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e093" xlink:type="simple"/></inline-formula>. The parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e094" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e095" xlink:type="simple"/></inline-formula> denote the number of pixels and components, respectively. We then define <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e096" xlink:type="simple"/></inline-formula> by inverting the linear system that is defined by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e097" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003724.e098"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e098" xlink:type="simple"/><label>(4)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e099" xlink:type="simple"/></inline-formula> is an unmixing matrix such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e100" xlink:type="simple"/></inline-formula>. We constrain <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e101" xlink:type="simple"/></inline-formula> to be orthonormal and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e102" xlink:type="simple"/></inline-formula> to have unit variance such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e103" xlink:type="simple"/></inline-formula> are uncorrelated and unique, up to a multiplicative sign. Next, we define the joint probability of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e104" xlink:type="simple"/></inline-formula> by the product of the marginal probabilities of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e105" xlink:type="simple"/></inline-formula> since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e106" xlink:type="simple"/></inline-formula> are assumed to be independent:<disp-formula id="pcbi.1003724.e107"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e107" xlink:type="simple"/><label>(5)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e108" xlink:type="simple"/></inline-formula> are peaked at zero and have high kurtosis since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e109" xlink:type="simple"/></inline-formula> are assumed to be sparse.</p>
<p>While one of the assumptions of the model is that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e110" xlink:type="simple"/></inline-formula> are independent, their estimates are only maximally independent. As a result, residual dependencies remain between the estimates of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e111" xlink:type="simple"/></inline-formula>. We continue by modeling the nonlinear correlations of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e112" xlink:type="simple"/></inline-formula> since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e113" xlink:type="simple"/></inline-formula> are constrained to be linearly uncorrelated. In particular, we assume that the locally pooled energies of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e114" xlink:type="simple"/></inline-formula> are sparse. Without loss of generality, we first arrange <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e115" xlink:type="simple"/></inline-formula> on a square grid graph that has circular boundary conditions. We then define the locally pooled energies of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e116" xlink:type="simple"/></inline-formula> by the sum of the energies of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e117" xlink:type="simple"/></inline-formula> that are in the same neighborhood: <disp-formula id="pcbi.1003724.e118"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e118" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e119" xlink:type="simple"/></inline-formula> is a vector of the locally pooled energies of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e120" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e121" xlink:type="simple"/></inline-formula> is a neighborhood matrix such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e122" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e123" xlink:type="simple"/></inline-formula> pools the energy of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e124" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e125" xlink:type="simple"/></inline-formula> otherwise. Next, we redefine <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e126" xlink:type="simple"/></inline-formula> in terms of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e127" xlink:type="simple"/></inline-formula> to model both layers:<disp-formula id="pcbi.1003724.e128"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e128" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e129" xlink:type="simple"/></inline-formula> is a convex function. Concretely, we use <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e130" xlink:type="simple"/></inline-formula>.</p>
<p>In a neural interpretation, simple and complex cell responses can be defined as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e131" xlink:type="simple"/></inline-formula> and a static nonlinear function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e132" xlink:type="simple"/></inline-formula>, respectively. Concretely, we use <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e133" xlink:type="simple"/></inline-formula> to define the complex cell responses after we estimate the model.</p>
</sec><sec id="s4c2">
<title>Model estimation</title>
<p>We use a modified gradient ascent method to estimate the model by maximizing the log-likelihood of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e134" xlink:type="simple"/></inline-formula> (equivalently, the sparseness of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e135" xlink:type="simple"/></inline-formula> given a set of patches: <disp-formula id="pcbi.1003724.e136"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e136" xlink:type="simple"/><label>(8)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e137" xlink:type="simple"/></inline-formula> is an approximation of the log-likelihood of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e138" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e139" xlink:type="simple"/></inline-formula> is the set of patches. At each iteration, we first find the gradient of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e140" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003724.e141"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e141" xlink:type="simple"/><label>(9)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e142" xlink:type="simple"/></inline-formula> is the Hadamard (element-wise) product. We then project it onto the tangent space of the constrained space <xref ref-type="bibr" rid="pcbi.1003724-Edelman1">[58]</xref>:<disp-formula id="pcbi.1003724.e143"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e143" xlink:type="simple"/><label>(10)</label></disp-formula>Next, we use backtracking line search to choose a step size by reducing it geometrically with a rate from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e144" xlink:type="simple"/></inline-formula> until the Armijo-Goldstein condition holds <xref ref-type="bibr" rid="pcbi.1003724-Boyd1">[59]</xref>. Finally, we update <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e145" xlink:type="simple"/></inline-formula> and find its nearest orthogonal matrix: <disp-formula id="pcbi.1003724.e146"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e146" xlink:type="simple"/><label>(11)</label></disp-formula><disp-formula id="pcbi.1003724.e147"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e147" xlink:type="simple"/><label>(12)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e148" xlink:type="simple"/></inline-formula> is the step size.</p>
</sec></sec><sec id="s4d">
<title>Voxel model</title>
<sec id="s4d1">
<title>Model definition</title>
<p>We start by defining a model for each voxel. Assuming that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e149" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e150" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e151" xlink:type="simple"/></inline-formula>, we use linear regression to define the models by a weighted sum of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e152" xlink:type="simple"/></inline-formula>: <disp-formula id="pcbi.1003724.e153"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e153" xlink:type="simple"/><label>(13)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e154" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4d2">
<title>Model estimation</title>
<p>We estimate the model using ridge regression: <disp-formula id="pcbi.1003724.e155"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e155" xlink:type="simple"/><label>(14)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e156" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e157" xlink:type="simple"/></inline-formula> is an estimation set, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e158" xlink:type="simple"/></inline-formula> is a complexity parameter that controls the amount of regularization. The parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e159" xlink:type="simple"/></inline-formula> denotes the number of stimulus-response pairs in the estimation set. We obtain <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e160" xlink:type="simple"/></inline-formula> as:<disp-formula id="pcbi.1003724.e161"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e161" xlink:type="simple"/><label>(15)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e162" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e163" xlink:type="simple"/></inline-formula>. Since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e164" xlink:type="simple"/></inline-formula>, we solve the problem in a rotated coordinate system in which only the first N coordinates of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e165" xlink:type="simple"/></inline-formula> are nonzero <xref ref-type="bibr" rid="pcbi.1003724-Hastie1">[60]</xref>, <xref ref-type="bibr" rid="pcbi.1003724-Murphy1">[61]</xref>. We first factorize <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e166" xlink:type="simple"/></inline-formula> using the singular value decomposition:<disp-formula id="pcbi.1003724.e167"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e167" xlink:type="simple"/><label>(16)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e168" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e169" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e170" xlink:type="simple"/></inline-formula>. The columns of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e171" xlink:type="simple"/></inline-formula>, the diagonal entries of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e172" xlink:type="simple"/></inline-formula> and the columns of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e173" xlink:type="simple"/></inline-formula> are the left-singular vectors, the singular values and the right-singular vectors of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e174" xlink:type="simple"/></inline-formula>, respectively. We then reobtain <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e175" xlink:type="simple"/></inline-formula> as:<disp-formula id="pcbi.1003724.e176"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e176" xlink:type="simple"/><label>(17)</label></disp-formula>where division is defined element-wise. The rotation reduces the complexity of the problem from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e177" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e178" xlink:type="simple"/></inline-formula>. To choose the optimal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e179" xlink:type="simple"/></inline-formula>, we perform hyperparameter optimization using grid search guided by a generalized cross-validation approximation to leave-one-out cross-validation <xref ref-type="bibr" rid="pcbi.1003724-Hastie1">[60]</xref>. We define a grid by first sampling the effective degrees of freedom of the ridge regression fit from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e180" xlink:type="simple"/></inline-formula> since its parameter space is bounded from above. The effective degrees of freedom of the ridge regression fit is defined as:</p>
<p><disp-formula id="pcbi.1003724.e181"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e181" xlink:type="simple"/><label>(18)</label></disp-formula>We then use Newton's method to solve <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e182" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e183" xlink:type="simple"/></inline-formula>. Once the grid is defined, we choose the optimal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e184" xlink:type="simple"/></inline-formula> that minimizes the generalized cross-validation error: <disp-formula id="pcbi.1003724.e185"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003724.e185" xlink:type="simple"/><label>(19)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e186" xlink:type="simple"/></inline-formula> is the grid, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e187" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e188" xlink:type="simple"/></inline-formula> given a particular <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e189" xlink:type="simple"/></inline-formula>.</p>
</sec></sec><sec id="s4e">
<title>Encoding and decoding</title>
<p>In the case of the SC model, each randomly sampled or non-overlapping patch was transformed to its principal components such that 625 components with the largest variance were retained and whitened prior to model estimation and validation. After the images were feature transformed, they were z-scored. The SC model of 625 simple and 625 complex cells was estimated from 50000 patches of size 32<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e190" xlink:type="simple"/></inline-formula>32 pixels that were randomly sampled from the 1750 images of size 128<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e191" xlink:type="simple"/></inline-formula>128 pixels in the estimation set. The details of the GWP model are presented in <xref ref-type="bibr" rid="pcbi.1003724-Kay1">[8]</xref>. The SC2 and GWP2 models were estimated from the 1750 feature-transformed stimulus-response pairs in the estimation set.</p>
<p>Voxel responses to an image of size 128<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e192" xlink:type="simple"/></inline-formula>128 pixels were predicted as follows. In the case of the SC model, each 16 non-overlapping patch of size 32<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003724.e193" xlink:type="simple"/></inline-formula>32 pixels of the image were first transformed to the complex cell responses of the SC model (i.e. total of 625 complex cell responses per patch and 10000 complex cell responses per image). The 10000 complex cell responses of the SC model were then transformed to the voxel responses of the SC2 model. In the case of the GWP model, the image was first transformed to the complex cell responses of the GWP model (i.e. total of 10921 complex cell responses per image). The 10921 complex cell responses of the GWP model were then transformed to the voxel responses of the GWP2 model. The encoding performance was defined as the coefficient of determination between the observed and predicted voxel responses to the 120 images in the validation set across the two subjects.</p>
<p>A target image was identified from a set of candidate images as follows. Prior to identification, 500 voxels were selected without using the target image. The selected voxels were those whose responses were predicted best. The target image was identified as the candidate image such that the observed voxel responses to the target image were most correlated with the predicted voxel responses to the candidate image (i.e. highest Pearson product-moment correlation coefficient between observed and predicted voxel responses). The decoding performance was defined as the accuracy of identifying the 120 images in the validation set from the set of 9264 candidate images. The set of candidate images contained the 120 images in the validation set and the 9144 images in the Caltech 101 data set <xref ref-type="bibr" rid="pcbi.1003724-FeiFei1">[38]</xref>.</p>
</sec></sec></body>
<back><ref-list>
<title>References</title>
<ref id="pcbi.1003724-Dayan1"><label>1</label>
<mixed-citation publication-type="other" xlink:type="simple">Dayan P, Abbott LF (2005) Theoretical Neuroscience: Computational And Mathematical Modeling of Neural Systems. Cambridge: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Brown1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brown</surname><given-names>EN</given-names></name>, <name name-style="western"><surname>Kass</surname><given-names>RE</given-names></name>, <name name-style="western"><surname>Mitra</surname><given-names>PP</given-names></name> (<year>2004</year>) <article-title>Multiple neural spike train data analysis: State-of-the-art and future challenges</article-title>. <source>Nat Neurosci</source> <volume>7</volume>: <fpage>456</fpage>–<lpage>461</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Quiroga1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Quiroga</surname><given-names>RQ</given-names></name>, <name name-style="western"><surname>Reddy</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Kreiman</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Fried</surname><given-names>I</given-names></name> (<year>2005</year>) <article-title>Invariant visual representation by single neurons in the human brain</article-title>. <source>Nature</source> <volume>435</volume>: <fpage>1102</fpage>–<lpage>1107</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Pasley1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pasley</surname><given-names>BN</given-names></name>, <name name-style="western"><surname>David</surname><given-names>SV</given-names></name>, <name name-style="western"><surname>Mesgarani</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Flinker</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Reconstructing speech from human auditory cortex</article-title>. <source>PLoS Biol</source> <volume>10</volume>: <fpage>e1001251</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Naselaris1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Naselaris</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Kay</surname><given-names>KN</given-names></name>, <name name-style="western"><surname>Nishimoto</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2011</year>) <article-title>Encoding and decoding in fMRI</article-title>. <source>Neuroimage</source> <volume>56</volume>: <fpage>400</fpage>–<lpage>410</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Haxby1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name>, <name name-style="western"><surname>Gobbini</surname><given-names>MI</given-names></name>, <name name-style="western"><surname>Furey</surname><given-names>ML</given-names></name>, <name name-style="western"><surname>Ishai</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Schouten</surname><given-names>JL</given-names></name>, <etal>et al</etal>. (<year>2001</year>) <article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title>. <source>Science</source> <volume>293</volume>: <fpage>2425</fpage>–<lpage>2430</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Kamitani1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kamitani</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Tong</surname><given-names>F</given-names></name> (<year>2005</year>) <article-title>Decoding the visual and subjective contents of the human brain</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>679</fpage>–<lpage>685</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Kay1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kay</surname><given-names>KN</given-names></name>, <name name-style="western"><surname>Naselaris</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Prenger</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2008</year>) <article-title>Identifying natural images from human brain activity</article-title>. <source>Nature</source> <volume>452</volume>: <fpage>352</fpage>–<lpage>355</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Mitchell1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mitchell</surname><given-names>TM</given-names></name>, <name name-style="western"><surname>Shinkareva</surname><given-names>SV</given-names></name>, <name name-style="western"><surname>Carlson</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Chang</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Malave</surname><given-names>VL</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Predicting human brain activity associated with the meanings of nouns</article-title>. <source>Science</source> <volume>320</volume>: <fpage>1191</fpage>–<lpage>1195</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Thirion1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thirion</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Duchesnay</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Hubbard</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Dubois</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Poline</surname><given-names>JB</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Inverse retinotopy: Inferring the visual content of images from brain activation patterns</article-title>. <source>Neuroimage</source> <volume>33</volume>: <fpage>1104</fpage>–<lpage>1116</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Miyawaki1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miyawaki</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Uchida</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Yamashita</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Sato</surname><given-names>Ma</given-names></name>, <name name-style="western"><surname>Morito</surname><given-names>Y</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Visual image reconstruction from human brain activity using a combination of multiscale local image decoders</article-title>. <source>Neuron</source> <volume>60</volume>: <fpage>915</fpage>–<lpage>929</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Schoenmakers1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schoenmakers</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Barth</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Heskes</surname><given-names>T</given-names></name>, <name name-style="western"><surname>van Gerven</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Linear reconstruction of perceived images from human brain activity</article-title>. <source>Neuroimage</source> <volume>83</volume>: <fpage>951</fpage>–<lpage>961</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Naselaris2"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Naselaris</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Prenger</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Kay</surname><given-names>KN</given-names></name>, <name name-style="western"><surname>Oliver</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2009</year>) <article-title>Bayesian reconstruction of natural images from human brain activity</article-title>. <source>Neuron</source> <volume>63</volume>: <fpage>902</fpage>–<lpage>915</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Nishimoto1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nishimoto</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Vu</surname><given-names>AT</given-names></name>, <name name-style="western"><surname>Naselaris</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Benjamini</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Yu</surname><given-names>B</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Reconstructing visual experiences from brain activity evoked by natural movies</article-title>. <source>Curr Biol</source> <volume>21</volume>: <fpage>1641</fpage>–<lpage>1646</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Vu1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vu</surname><given-names>VQ</given-names></name>, <name name-style="western"><surname>Ravikumar</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Naselaris</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Kay</surname><given-names>KN</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Encoding and decoding V1 fMRI responses to natural images with sparse nonparametric models</article-title>. <source>Ann Appl Stat</source> <volume>5</volume>: <fpage>1159</fpage>–<lpage>1182</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Kay2"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kay</surname><given-names>KN</given-names></name>, <name name-style="western"><surname>Winawer</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Rokem</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Mezer</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Wandell</surname><given-names>BA</given-names></name> (<year>2013</year>) <article-title>A two-stage cascade model of BOLD responses in human visual cortex</article-title>. <source>PLoS Comput Biol</source> <volume>9</volume>: <fpage>e1003079</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Barlow1"><label>17</label>
<mixed-citation publication-type="other" xlink:type="simple">Barlow HW (1961) Possible principles underlying the transformations of sensory messages. In: Rosenblith WA, editor, Sensory communication, Cambridge: MIT Press. pp. 217–234.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Olshausen1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>1996</year>) <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source> <volume>381</volume>: <fpage>607</fpage>–<lpage>609</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Bell1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>1997</year>) <article-title>The “independent components” of natural scenes are edge filters</article-title>. <source>Vision Res</source> <volume>37</volume>: <fpage>3327</fpage>–<lpage>3338</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Hyvrinen1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name> (<year>2010</year>) <article-title>Statistical models of natural images and cortical visual representation</article-title>. <source>Top Cogn Sci</source> <volume>2</volume>: <fpage>251</fpage>–<lpage>264</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Kay3"><label>21</label>
<mixed-citation publication-type="other" xlink:type="simple">Kay KN, Naselaris T, Gallant JL (2011). fMRI of human visual areas in response to natural images. CRCNS.org.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Hyvrinen2"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hoyer</surname><given-names>PO</given-names></name> (<year>2001</year>) <article-title>A two-layer sparse coding model learns simple and complex cell receptive fields and topography from natural images</article-title>. <source>Vision Res</source> <volume>41</volume>: <fpage>2413</fpage>–<lpage>2423</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Hubel1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hubel</surname><given-names>DH</given-names></name>, <name name-style="western"><surname>Wiesel</surname><given-names>TN</given-names></name> (<year>1968</year>) <article-title>Receptive fields and functional architecture of monkey striate cortex</article-title>. <source>J Physiol</source> <volume>195</volume>: <fpage>215</fpage>–<lpage>243</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-DeValois1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Valois</surname><given-names>RL</given-names></name>, <name name-style="western"><surname>Albrecht</surname><given-names>DG</given-names></name>, <name name-style="western"><surname>Thorell</surname><given-names>LG</given-names></name> (<year>1982</year>) <article-title>Spatial frequency selectivity of cells in macaque visual cortex</article-title>. <source>Vision Res</source> <volume>22</volume>: <fpage>545</fpage>–<lpage>559</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Jones1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jones</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Palmer</surname><given-names>LA</given-names></name> (<year>1987</year>) <article-title>An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex</article-title>. <source>J Neurophysiol</source> <volume>58</volume>: <fpage>1233</fpage>–<lpage>1258</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Parker1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Parker</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Hawken</surname><given-names>MJ</given-names></name> (<year>1988</year>) <article-title>Two-dimensional spatial structure of receptive fields in monkey striate cortex</article-title>. <source>J Opt Soc Am A Opt Image Sci Vis</source> <volume>5</volume>: <fpage>598</fpage>–<lpage>605</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Daugman1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daugman</surname><given-names>JG</given-names></name> (<year>1985</year>) <article-title>Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters</article-title>. <source>J Opt Soc Am A</source> <volume>2</volume>: <fpage>1160</fpage>–<lpage>1169</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Lee1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname><given-names>TS</given-names></name> (<year>1996</year>) <article-title>Image representation using 2D Gabor wavelets</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> <volume>18</volume>: <fpage>959</fpage>–<lpage>971</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-DeAngelis1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>DeAngelis</surname><given-names>GC</given-names></name>, <name name-style="western"><surname>Ghose</surname><given-names>GM</given-names></name>, <name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name> (<year>1999</year>) <article-title>Functional micro-organization of primary visual cortex: Receptive field analysis of nearby neurons</article-title>. <source>J Neurosci</source> <volume>19</volume>: <fpage>4046</fpage>–<lpage>4064</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Hubel2"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hubel</surname><given-names>DH</given-names></name>, <name name-style="western"><surname>Wiesel</surname><given-names>TN</given-names></name> (<year>1977</year>) <article-title>Ferrier lecture: Functional architecture of macaque monkey visual cortex</article-title>. <source>Proc R Soc Lond B Biol Sci</source> <volume>198</volume>: <fpage>1</fpage>–<lpage>59</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Blasdel1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blasdel</surname><given-names>G</given-names></name> (<year>1992</year>) <article-title>Orientation selectivity, preference, and continuity in monkey striate cortex</article-title>. <source>J Neurosci</source> <volume>12</volume>: <fpage>3139</fpage>–<lpage>3161</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Tootell1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tootell</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Silverman</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hamilton</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Switkes</surname><given-names>E</given-names></name>, <name name-style="western"><surname>De Valois</surname><given-names>R</given-names></name> (<year>1988</year>) <article-title>Functional anatomy of macaque striate cortex. V. Spatial frequency</article-title>. <source>J Neurosci</source> <volume>8</volume>: <fpage>1610</fpage>–<lpage>1624</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Mansfield1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mansfield</surname><given-names>RJW</given-names></name> (<year>1974</year>) <article-title>Neural basis of orientation perception in primate vision</article-title>. <source>Science</source> <volume>186</volume>: <fpage>1133</fpage>–<lpage>1135</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Furmanski1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Furmanski</surname><given-names>CS</given-names></name>, <name name-style="western"><surname>Engel</surname><given-names>SA</given-names></name> (<year>2000</year>) <article-title>An oblique effect in human primary visual cortex</article-title>. <source>Nat Neurosci</source> <volume>3</volume>: <fpage>535</fpage>–<lpage>536</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Swisher1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Swisher</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Gatenby</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Gore</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Wolfe</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Moon</surname><given-names>CH</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Multiscale pattern analysis of orientation-selective activity in the primary visual cortex</article-title>. <source>J Neurosci</source> <volume>30</volume>: <fpage>325</fpage>–<lpage>330</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Dumoulin1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dumoulin</surname><given-names>SO</given-names></name>, <name name-style="western"><surname>Wandell</surname><given-names>BA</given-names></name> (<year>2008</year>) <article-title>Population receptive field estimates in human visual cortex</article-title>. <source>Neuroimage</source> <volume>39</volume>: <fpage>647</fpage>–<lpage>660</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Smith1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Singh</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Williams</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Greenlee</surname><given-names>M</given-names></name> (<year>2001</year>) <article-title>Estimating receptive field size from fMRI data in human striate and extrastriate visual cortex</article-title>. <source>Cereb Cortex</source> <volume>11</volume>: <fpage>1182</fpage>–<lpage>1190</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-FeiFei1"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fei-Fei</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Fergus</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Perona</surname><given-names>P</given-names></name> (<year>2007</year>) <article-title>Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories</article-title>. <source>Comput Vis Image Underst</source> <volume>106</volume>: <fpage>59</fpage>–<lpage>70</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Kay4"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kay</surname><given-names>KN</given-names></name>, <name name-style="western"><surname>Winawer</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Mezer</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Wandell</surname><given-names>BA</given-names></name> (<year>2013</year>) <article-title>Compressive spatial summation in human visual cortex</article-title>. <source>J Neurophysiol</source> <volume>110</volume>: <fpage>481</fpage>–<lpage>494</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Knowles1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knowles</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Ghahramani</surname><given-names>Z</given-names></name> (<year>2011</year>) <article-title>Nonparametric Bayesian sparse factor models</article-title>. <source>Ann Appl Stat</source> <volume>5</volume>: <fpage>1534</fpage>–<lpage>1552</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-ukur1"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Çukur</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Nishimoto</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Huth</surname><given-names>AG</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2013</year>) <article-title>Attention during natural vision warps semantic representation across the human brain</article-title>. <source>Nat Neurosci</source> <volume>16</volume>: <fpage>763</fpage>–<lpage>770</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Kok1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kok</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Brouwer</surname><given-names>GJ</given-names></name>, <name name-style="western"><surname>van Gerven</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>de Lange</surname><given-names>FP</given-names></name> (<year>2013</year>) <article-title>Prior expectations bias sensory representations in visual cortex</article-title>. <source>J Neurosci</source> <volume>33</volume>: <fpage>16275</fpage>–<lpage>16284</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Bengio1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bengio</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Courville</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Vincent</surname><given-names>P</given-names></name> (<year>2013</year>) <article-title>Representation learning: A review and new perspectives</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> <volume>35</volume>: <fpage>1798</fpage>–<lpage>1828</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Lee2"><label>44</label>
<mixed-citation publication-type="other" xlink:type="simple">Lee H, Ekanadham C, Ng A (2007) Sparse deep belief net model for visual area V2. In: Neural Information Processing Systems.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Lee3"><label>45</label>
<mixed-citation publication-type="other" xlink:type="simple">Lee H, Grosse R, Ranganath R, Ng AY (2009) Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In: International Conference on Machine Learning.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Le1"><label>46</label>
<mixed-citation publication-type="other" xlink:type="simple">Le Q, Ranzato M, Monga R, Devin M, Chen K, <etal>et al</etal>.. (2012) Building high-level features using large scale unsupervised learning. In: International Conference on Machine Learning.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Yamins1"><label>47</label>
<mixed-citation publication-type="other" xlink:type="simple">Yamins DLK, Hong H, Cadieu CF, Solomon EA, Seibert D, <etal>et al</etal>.. (2014) Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proc Natl Acad Sci U S A.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Le2"><label>48</label>
<mixed-citation publication-type="other" xlink:type="simple">Le QV, Zou WY, Yeung SY, Ng AY (2011) Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis. In: Conference on Computer Vision and Pattern Recognition.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Saxe1"><label>49</label>
<mixed-citation publication-type="other" xlink:type="simple">Saxe AM, Bhand M, Mudur R, Suresh B, Ng AY (2011) Unsupervised learning models of primary cortical receptive fields and receptive field plasticity. In: Neural Information Processing Systems.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Hyvrinen3"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name> (<year>2005</year>) <article-title>Estimation of non-normalized statistical models by score matching</article-title>. <source>J Mach Learn Res</source> <volume>6</volume>: <fpage>695</fpage>–<lpage>709</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Gutmann1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gutmann</surname><given-names>MU</given-names></name>, <name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name> (<year>2012</year>) <article-title>Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics</article-title>. <source>J Mach Learn Res</source> <volume>13</volume>: <fpage>307</fpage>–<lpage>361</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Kster1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Köster</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name> (<year>2010</year>) <article-title>A two-layer model of natural stimuli estimated with score matching</article-title>. <source>Neural Comput</source> <volume>22</volume>: <fpage>2308</fpage>–<lpage>2333</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Gutmann2"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gutmann</surname><given-names>MU</given-names></name>, <name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name> (<year>2013</year>) <article-title>A three-layer model of natural image statistics</article-title>. <source>J Physiol Paris</source> <volume>107</volume>: <fpage>369</fpage>–<lpage>398</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Hinton1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hinton</surname><given-names>GE</given-names></name>, <name name-style="western"><surname>Osindero</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Teh</surname><given-names>YW</given-names></name> (<year>2006</year>) <article-title>A fast learning algorithm for deep belief nets</article-title>. <source>Neural Comput</source> <volume>18</volume>: <fpage>1527</fpage>–<lpage>1554</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-vanGerven1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Gerven</surname><given-names>MAJ</given-names></name>, <name name-style="western"><surname>de Lange</surname><given-names>FP</given-names></name>, <name name-style="western"><surname>Heskes</surname><given-names>T</given-names></name> (<year>2010</year>) <article-title>Neural decoding with hierarchical generative models</article-title>. <source>Neural Comput</source> <volume>22</volume>: <fpage>3127</fpage>–<lpage>3142</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Duyn1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Duyn</surname><given-names>JH</given-names></name> (<year>2012</year>) <article-title>The future of ultra-high field MRI and fMRI for study of the human brain</article-title>. <source>Neuroimage</source> <volume>62</volume>: <fpage>1241</fpage>–<lpage>1248</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Yacoub1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yacoub</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Harel</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Uğurbil</surname><given-names>K</given-names></name> (<year>2008</year>) <article-title>High-field fMRI unveils orientation columns in humans</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>105</volume>: <fpage>10607</fpage>–<lpage>10612</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Edelman1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Edelman</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Arias</surname><given-names>TA</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>ST</given-names></name> (<year>1998</year>) <article-title>The geometry of algorithms with orthogonality constraints</article-title>. <source>SIAM J Matrix Anal A</source> <volume>20</volume>: <fpage>303</fpage>–<lpage>353</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Boyd1"><label>59</label>
<mixed-citation publication-type="other" xlink:type="simple">Boyd S, Vandenberghe L (2004) Convex Optimization. Cambridge: Cambridge University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Hastie1"><label>60</label>
<mixed-citation publication-type="other" xlink:type="simple">Hastie T, Tibshirani R, Friedman J (2009) The Elements of Statistical Learning: Data Mining, Inference, and Prediction. New York: Springer.</mixed-citation>
</ref>
<ref id="pcbi.1003724-Murphy1"><label>61</label>
<mixed-citation publication-type="other" xlink:type="simple">Murphy KP (2012) Machine Learning: A Probabilistic Perspective. Cambridge: MIT Press.</mixed-citation>
</ref>
</ref-list></back>
</article>
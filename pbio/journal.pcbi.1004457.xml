<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-00300</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004457</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Efficient Characterization of Parametric Uncertainty of Complex (Bio)chemical Networks</article-title>
<alt-title alt-title-type="running-head">Efficient Characterization of Parametric Uncertainty</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Schillings</surname> <given-names>Claudia</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="fn" rid="currentaff001"><sup>¤a</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Sunnåker</surname> <given-names>Mikael</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Stelling</surname> <given-names>Jörg</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Schwab</surname> <given-names>Christoph</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Seminar for Applied Mathematics, ETH Zürich, Zürich, Switzerland</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Biosystems Science and Engineering and SIB Swiss Institute of Bioinformatics, ETH Zürich, Zürich, Switzerland</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Maranas</surname> <given-names>Costas D.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>The Pennsylvania State University, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: CSchw JS CSchi MS. Performed the experiments: CSchi MS. Analyzed the data: CSchw JS CSchi MS. Contributed reagents/materials/analysis tools: CSchi MS. Wrote the paper: CSchw JS CSchi MS.</p>
</fn>
<fn fn-type="current-aff" id="currentaff001">
<label>¤a</label>
<p>Current address: Mathematics Institute, University of Warwick, Coventry, United Kingdom</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">christoph.schwab@sam.math.ethz.ch</email> (CS), <email xlink:type="simple">joerg.stelling@bsse.ethz.ch</email> (JS)</corresp>
</author-notes>
<pub-date pub-type="collection">
<month>8</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>28</day>
<month>8</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>8</issue>
<elocation-id>e1004457</elocation-id>
<history>
<date date-type="received">
<day>22</day>
<month>2</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>20</day>
<month>7</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Schillings et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004457" xlink:type="simple"/>
<abstract>
<p>Parametric uncertainty is a particularly challenging and relevant aspect of systems analysis in domains such as systems biology where, both for inference and for assessing prediction uncertainties, it is essential to characterize the system behavior globally in the parameter space. However, current methods based on local approximations or on Monte-Carlo sampling cope only insufficiently with high-dimensional parameter spaces associated with complex network models. Here, we propose an alternative deterministic methodology that relies on sparse polynomial approximations. We propose a deterministic computational interpolation scheme which identifies most significant expansion coefficients adaptively. We present its performance in kinetic model equations from computational systems biology with several hundred parameters and state variables, leading to numerical approximations of the parametric solution on the entire parameter space. The scheme is based on adaptive Smolyak interpolation of the parametric solution at judiciously and adaptively chosen points in parameter space. As Monte-Carlo sampling, it is “non-intrusive” and well-suited for massively parallel implementation, but affords higher convergence rates. This opens up new avenues for large-scale dynamic network analysis by enabling scaling for many applications, including parameter estimation, uncertainty quantification, and systems design.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>In various scientific domains, in particular in systems biology, dynamic mathematical models of increasing complexity are being developed and analyzed to study biochemical reaction networks. A major challenge in dealing with such models is the uncertainty in parameters such as kinetic constants; how to efficiently and precisely quantify the effects of parametric uncertainties on systems behavior remains a question. Addressing this computational challenge for large systems, with good scaling up to hundreds of species and kinetic parameters, is important for many forward (e.g., uncertainty quantification) and inverse (e.g., system identification) problems. Here, we propose a sparse, deterministic adaptive interpolation method tailored to high-dimensional parametric problems that allows for fast, deterministic computational analysis of large biochemical reaction networks. The method is based on adaptive Smolyak interpolation of the parametric solution at judiciously chosen points in high-dimensional parameter space, combined with adaptive time-stepping for the actual numerical simulation of the network dynamics. It is “non-intrusive” and well-suited both for massively parallel implementation and for use in standard (systems biology) toolboxes.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by the Swiss Initiative for Systems Biology SystemsX.ch evaluated by the Swiss National Science Foundation (RTD project YeastX; to MS and JS) and by the European Research Council (ERC) under ERC AdG 247277 (to CSchi and CSchw). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="4"/>
<table-count count="0"/>
<page-count count="16"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<disp-quote><p>This is a <italic>PLOS Computational Biology</italic> Methods paper</p></disp-quote>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Chemical reaction networks (CRNs) form the basis for analyzing, for instance, cell signaling processes because they capture how molecular species such as proteins interact through reactions, for example, to form larger macromolecular complexes. In the limit of (sufficiently) high copy numbers of the molecular species when stochasticity can be ignored [<xref ref-type="bibr" rid="pcbi.1004457.ref001">1</xref>], the dynamic behavior of a CRN is described by a <italic>parametric</italic>, nonlinear deterministic system of ODEs of the form (see, e.g., [<xref ref-type="bibr" rid="pcbi.1004457.ref002">2</xref>] and references therein):
<disp-formula id="pcbi.1004457.e001"><alternatives><graphic id="pcbi.1004457.e001g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e001"/><mml:math id="M1" display="block" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mspace width="1pt"/><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:math></alternatives> <label>(1)</label></disp-formula>
where <inline-formula id="pcbi.1004457.e002"><alternatives><graphic id="pcbi.1004457.e002g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e002"/><mml:math id="M2" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mspace width="0.167em"/><mml:mo>∈</mml:mo> <mml:mo>𝓢</mml:mo> <mml:mo>=</mml:mo> <mml:mi>I</mml:mi> <mml:msubsup><mml:mi>R</mml:mi> <mml:mrow><mml:mo>≥</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:msub><mml:mi>n</mml:mi> <mml:mi>x</mml:mi></mml:msub></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is the vector of the non-negative concentrations of the <italic>n</italic><sub><italic>x</italic></sub> molecular species that depend on time <italic>t</italic>, <italic>f</italic>(<italic>x</italic>(<italic>t</italic>), <italic>u</italic>(<italic>t</italic>),<bold>p</bold>) is a system of <italic>n</italic><sub><italic>x</italic></sub> functions that model the rate of change of the species concentrations depending on the current system state <italic>x</italic>(<italic>t</italic>) and on the parameter vector <inline-formula id="pcbi.1004457.e003"><alternatives><graphic id="pcbi.1004457.e003g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e003"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mtext mathvariant="bold">p </mml:mtext><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:mtext> </mml:mtext><mml:mi>I</mml:mi><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> of dimension <italic>n</italic><sub><italic>p</italic></sub> which equals the number of kinetic parameters (physical constants) associated with the biochemical reactions. The inputs <inline-formula id="pcbi.1004457.e004"><alternatives><graphic id="pcbi.1004457.e004g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e004"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mrow><mml:mi>u</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mspace width="0.167em"/><mml:mo>∈</mml:mo> <mml:mi>I</mml:mi> <mml:msup><mml:mi>R</mml:mi> <mml:msub><mml:mi>n</mml:mi> <mml:mi>u</mml:mi></mml:msub></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> may be time-varying, for example, when external stimuli to signaling networks are being considered. The initial conditions are given by <italic>x</italic><sub>0</sub>. Here, we follow the notational conventions of the application domain; the mathematical literature usually denotes states and parameters by <italic>x</italic> and <italic>y</italic>, respectively. For CRNs, specifically, the right-hand-side <italic>f</italic>(<italic>x</italic>(<italic>t</italic>), <italic>u</italic>(<italic>t</italic>),<bold>p</bold>) can be decomposed into two contributions: the stoichiometric matrix <inline-formula id="pcbi.1004457.e005"><alternatives><graphic id="pcbi.1004457.e005g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e005"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi> <mml:mo>∈</mml:mo> <mml:mi>I</mml:mi> <mml:msup><mml:mi>R</mml:mi> <mml:mrow><mml:msub><mml:mi>n</mml:mi> <mml:mi>x</mml:mi></mml:msub> <mml:mo>×</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> that encodes how species participate in reactions (its entries correspond to the relative number of molecules of each of the <italic>n</italic><sub><italic>x</italic></sub> species being consumed or produced by each of the <italic>n</italic><sub><italic>r</italic></sub> reactions), and the vector of <italic>n</italic><sub><italic>r</italic></sub> reaction rates, or fluxes, <inline-formula id="pcbi.1004457.e006"><alternatives><graphic id="pcbi.1004457.e006g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e006"/><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:mi>v</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>x</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>,</mml:mo> <mml:mtext mathvariant="bold">p</mml:mtext> <mml:mo stretchy="false">)</mml:mo> <mml:mspace width="0.167em"/><mml:mo>∈</mml:mo> <mml:mi>I</mml:mi> <mml:msubsup><mml:mi>R</mml:mi> <mml:mrow><mml:mo>≥</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:msub><mml:mi>n</mml:mi> <mml:mi>r</mml:mi></mml:msub></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>Using ODE models <xref ref-type="disp-formula" rid="pcbi.1004457.e001">Eq (1)</xref> to analyze cellular networks is challenging, in particular, because <italic>n</italic><sub><italic>p</italic></sub> is large and the parameter values are usually unknown. For instance, enzyme kinetic parameter values are distributed over several orders of magnitude [<xref ref-type="bibr" rid="pcbi.1004457.ref003">3</xref>], making it often difficult to ascertain even rough estimates when the parameter values cannot be determined experimentally. In practice, parameter values need to be estimated from experimental observations such as time-course data of species concentrations, which typically involves solving computationally expensive global optimization problems [<xref ref-type="bibr" rid="pcbi.1004457.ref004">4</xref>]. In addition, mainly due to limited measurement capabilities and a still prevailing shortage of quantitative experimental data, most of the established (systems biology) models have ‘sloppy’ parameters. That is, their values are not sufficiently constrained by the data used for estimation, or some parameters are even redundant, for a given set of measurement data. These parametric uncertainties may propagate to large uncertainties in model predictions [<xref ref-type="bibr" rid="pcbi.1004457.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1004457.ref006">6</xref>]. In parameter estimation and uncertainty quantification, one needs to determine how the system behavior <italic>x</italic>(<italic>t</italic>) depends on the parameters <bold>p</bold>, ideally on the entire (physically feasible) parameter space. While local evaluations in parameter space may suffice in certain cases, for instance, methods for Bayesian inference of model parameters and topologies [<xref ref-type="bibr" rid="pcbi.1004457.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004457.ref008">8</xref>] are global by design, making the last aspect a critical requirement.</p>
<p>In systems biology (most of the ensuing considerations apply beyond systems biology), two broad classes of approaches to computational quantification of parametric uncertainty can be distinguished. So-called <italic>local methods</italic> rely on parameter sensitivities
<disp-formula id="pcbi.1004457.e007"><alternatives><graphic id="pcbi.1004457.e007g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e007"/><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mtext mathvariant="bold">p</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext mathvariant="bold">p</mml:mtext><mml:mo>=</mml:mo><mml:msub><mml:mtext mathvariant="bold">p</mml:mtext><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula>
that provide first-order approximations of the systems’ behavior when the <italic>k</italic>-th parameter, <italic>p</italic><sub><italic>k</italic></sub>, has small variations around the nominal parameter set <inline-formula id="pcbi.1004457.e008"><alternatives><graphic id="pcbi.1004457.e008g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e008"/><mml:math id="M8" display="inline" overflow="scroll"><mml:msub><mml:mtext mathvariant="bold">p</mml:mtext><mml:mn>0</mml:mn></mml:msub><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. Parameter sensitivities allow for an assessment of, for instance, metabolic network behavior in response to small parametric perturbations [<xref ref-type="bibr" rid="pcbi.1004457.ref009">9</xref>]. However, as systems biology models are typically highly non-linear, and calibrations to noisy data may access parameter values that are far from <bold>p</bold><sub>0</sub>, the scope of local approximations is limited. For example, the response of the two-dimensional example model shown in <xref ref-type="fig" rid="pcbi.1004457.g001">Fig 1A</xref> appears ‘simple’, but a first-order approximation of the response becomes increasingly inaccurate with increasing distance from the nominal parameter set (<xref ref-type="fig" rid="pcbi.1004457.g001">Fig 1B</xref>).</p>
<fig id="pcbi.1004457.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004457.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Example model.</title>
<p><bold>A:</bold> The function <italic>f</italic>(<italic>x</italic>, <italic>y</italic>) = <italic>exp</italic>(<italic>x</italic>) + <italic>y</italic> plotted in the region −1 ≤ <italic>x</italic>, <italic>y</italic> ≤ 1. <bold>B:</bold> Absolute difference between the original function (<bold>A</bold>) and the first order approximation <inline-formula id="pcbi.1004457.e009"><alternatives><graphic id="pcbi.1004457.e009g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e009"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>y</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>≈</mml:mo> <mml:mi>f</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn> <mml:mo stretchy="false">)</mml:mo> <mml:mo>+</mml:mo> <mml:msub><mml:mrow> <mml:mi>x</mml:mi> <mml:mfrac><mml:mrow><mml:mo>∂</mml:mo> <mml:mrow><mml:mi>f</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>y</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mo>∂</mml:mo> <mml:mi>x</mml:mi></mml:mrow></mml:mfrac> <mml:mo stretchy="true">∣</mml:mo></mml:mrow> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mrow> <mml:mi>y</mml:mi> <mml:mfrac><mml:mrow><mml:mo>∂</mml:mo> <mml:mrow><mml:mi>f</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>y</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mo>∂</mml:mo> <mml:mi>y</mml:mi></mml:mrow></mml:mfrac> <mml:mo stretchy="true">∣</mml:mo></mml:mrow> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>x</mml:mi> <mml:mo>+</mml:mo> <mml:mi>y</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. <bold>C:</bold> Outline of the algorithm for the proposed adaptive sparse interpolation method. <bold>D:</bold> The 11 interpolation points computed by the Smolyak algorithm for five (<italic>k</italic> = 0…4) iterations for an error tolerance of 5 × 10<sup>−8</sup>. Possible Smolyak grid points up to the same level of hierarchy are shown as black dots. <bold>E:</bold> Absolute difference between the original function (<bold>A</bold>) and the Smolyak approximation based on the interpolation points in (<bold>D</bold>), computed for 441 uniformly distributed points in −1 ≤ <italic>x</italic>, <italic>y</italic> ≤ 1.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004457.g001"/>
</fig>
<p><italic>Sampling-based methods</italic>, in contrast, attempt to cover the entire parameter space. For large networks, high-dimensional parameter spaces need to be explored, and due to the so-called “curse of dimensionality” [<xref ref-type="bibr" rid="pcbi.1004457.ref010">10</xref>], this entails sample numbers (and thus, computation time) that increase exponentially with the dimension of the parameter space. In addition, limited prior knowledge on parameter regimes and location of disconnected regions in parameter space often limit targeted or adaptive sampling strategies. State of the art Monte-Carlo methods have been reported to cope with up to 50 model parameters [<xref ref-type="bibr" rid="pcbi.1004457.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004457.ref011">11</xref>], but present CRN models in systems biology may have several hundred parameters [<xref ref-type="bibr" rid="pcbi.1004457.ref012">12</xref>]. Hence, not only for the efficient computational forward and Bayesian inversion analysis of large-scale models representing entire cells [<xref ref-type="bibr" rid="pcbi.1004457.ref013">13</xref>], but also for pathway models [<xref ref-type="bibr" rid="pcbi.1004457.ref014">14</xref>], efficient computational methods with mathematically founded, favorable scaling of work versus accuracy with respect to the model size are lacking.</p>
<p>One possible avenue for developing more efficient computational methods consists of exploiting specific features of the application domain (models), which proved successful for determining local parameter sensitivities [<xref ref-type="bibr" rid="pcbi.1004457.ref015">15</xref>]. For CRN models which arise in systems biology such as <xref ref-type="disp-formula" rid="pcbi.1004457.e001">Eq (1)</xref>, one can exploit that many cellular reaction networks are only weakly connected. This is reflected in <italic>sparse</italic> (but not block diagonalizable) stoichiometric matrices <italic>N</italic>, and in the scale-free structure of many large-scale networks that comprise a few hubs with many connections, whereas most species have few connections [<xref ref-type="bibr" rid="pcbi.1004457.ref016">16</xref>]. In addition, if one considers only mass-action kinetics, the reaction rates can be written as
<disp-formula id="pcbi.1004457.e010"><alternatives><graphic id="pcbi.1004457.e010g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e010"/><mml:math id="M10" display="block" overflow="scroll"><mml:mrow><mml:mi>v</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo form="prefix">diag</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>ρ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi>O</mml:mi> <mml:mi>u</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1004457.e011"><alternatives><graphic id="pcbi.1004457.e011g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e011"/><mml:math id="M11" display="inline" overflow="scroll"><mml:mrow><mml:mi>O</mml:mi> <mml:mo>∈</mml:mo> <mml:msup><mml:mo>ℕ</mml:mo> <mml:mrow><mml:msub><mml:mi>n</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mo>×</mml:mo> <mml:msub><mml:mi>n</mml:mi> <mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> defines the input-to-rate mapping and <italic>ρ</italic>(<italic>x</italic>(<italic>t</italic>)) is a vector of monomials in the states <italic>x</italic>(<italic>t</italic>) [<xref ref-type="bibr" rid="pcbi.1004457.ref017">17</xref>], revealing an overall <italic>affine parameter dependence</italic> of <italic>f</italic>(<italic>x</italic>(<italic>t</italic>), <italic>u</italic>(<italic>t</italic>),<bold>p</bold>).</p>
<p>Here, we propose a novel, adaptive deterministic computational methodology for handling parametric uncertainty for high dimensional parameter spaces with particular attention to large, parametric nonlinear dynamical systems in CRN models. We exploit recent mathematical results [<xref ref-type="bibr" rid="pcbi.1004457.ref018">18</xref>] stating that responses of systems models with <italic>sparse</italic> and <italic>affine</italic> dependence on these parameters can be captured by sequences of polynomial approximations such that the approximated responses converge to the exact responses with rates that are independent of the dimensions of the parameter and state space. The presently proposed approach adaptively exploits this sparsity. It provably allows to adaptively scan system responses across the entire, high-dimensional parameter space with less instances of (possibly costly) forward simulations than with sampling methods to reach prescribed numerical accuracies of the responses. It also allows to build parsimonious parametric surrogate models that are valid over the entire parameter space. To demonstrate our methodology’s performance, we apply it to three published systems biology models, where the numerical results support the theoretical prediction of dimension-independent convergence rates beyond the rate 1/2 for Monte-Carlo sampling methods.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec003">
<title>Overview</title>
<p>We propose an adaptive deterministic algorithm that relies on constructing sparse interpolation and quadrature grids in high-dimensional parameter spaces as outlined in <xref ref-type="fig" rid="pcbi.1004457.g001">Fig 1C</xref>. It relies on so-called Smolyak sparse grids [<xref ref-type="bibr" rid="pcbi.1004457.ref019">19</xref>] that exploit that for functions in high dimensions, not all parameter points are equally important to approximate the function. The Smolyak method can employ different sequences of univariate quadrature formulae; here, we focus on the generation of grid points using the Clenshaw-Curtis method (CC; see <xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref> for details). Correspondingly, the principle of our adaptive Smolyak sparse grids method is to start from a single parameter point and to iteratively evaluate the effect of adding neighboring points in certain directions of the parameter space, until we fall below a predefined numerical error tolerance. Note that here and in the following, ‘error tolerance’ refers to numerical accuracy and not to model properties such as robustness. This principle is illustrated in <xref ref-type="fig" rid="pcbi.1004457.g001">Fig 1D</xref> for the two-dimensional example model, where <italic>k</italic> denotes the iteration. In particular, the directions in which the most points are added correspond to the parameters for which the model is the most responsive. Once the points to be added (‘activated’) are determined for one iteration, simulations to determine the function values are independent of each other, allowing for a parallelization of computations. Note, that the effect of adding points in more than one parameter space direction simultaneously is not evaluated, since this is (often) computationally intractable. However, for certain functions such as the example model, the approximation resulting from few (five, in this case) iterations may be highly accurate over the entire domain in parameter space (<xref ref-type="fig" rid="pcbi.1004457.g001">Fig 1E</xref>). In the following, we focus on why subsets of CRN models allow for sparse interpolation and quadrature with dimension-independent convergence (numerical error tolerance) properties, and for mathematical details we refer the reader to the <xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref> and to [<xref ref-type="bibr" rid="pcbi.1004457.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1004457.ref020">20</xref>]. Note also that an implementation of the method (for model 1 discussed in the Results section) is available as <xref ref-type="supplementary-material" rid="pcbi.1004457.s002">S1 File</xref>.</p>
</sec>
<sec id="sec004">
<title>Models with mass-action kinetics</title>
<p>We consider models of the form of <xref ref-type="disp-formula" rid="pcbi.1004457.e001">Eq (1)</xref> with reactions based on mass-action kinetics. For physically realistic reactions with at most two educts and a bounded parameter domain, this implies: <inline-formula id="pcbi.1004457.e012"><alternatives><graphic id="pcbi.1004457.e012g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e012"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>v</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mtext mathvariant="bold">p</mml:mtext> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>x</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>+</mml:mo> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>n</mml:mi> <mml:mi>u</mml:mi></mml:msub></mml:msubsup> <mml:msub><mml:mi>o</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>u</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mi>x</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:msub><mml:mi>x</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>n</mml:mi> <mml:mi>u</mml:mi></mml:msub></mml:msubsup> <mml:msub><mml:mi>o</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>u</mml:mi> <mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, <italic>j</italic> = 1, …, <italic>n</italic><sub><italic>r</italic></sub>, for some given indices (depending on j) <italic>l</italic>, <italic>m</italic> ∈ [1, …, <italic>n</italic><sub><italic>x</italic></sub>], where the parameters <italic>p</italic><sub><italic>j</italic></sub> ≥ 0 and <italic>p</italic><sub><italic>j</italic></sub> ∈ [<italic>a</italic><sub><italic>j</italic></sub>, <italic>b</italic><sub><italic>j</italic></sub>]. To save space we write <italic>x</italic> ≔ <italic>x</italic>(<italic>t</italic>) and <italic>u</italic> ≔ <italic>u</italic>(<italic>t</italic>). The right-hand-side of the ODE for state variable <italic>x</italic><sub><italic>i</italic></sub>, <italic>i</italic> ∈ [1, …, <italic>n</italic><sub><italic>x</italic></sub>], is:
<disp-formula id="pcbi.1004457.e013"><alternatives><graphic id="pcbi.1004457.e013g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e013"/><mml:math id="M13" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>,</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>≥</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:munder> <mml:msub><mml:mi>n</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>v</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>≥</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:munder> <mml:msub><mml:mi>n</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>p</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>≥</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:munder> <mml:msub><mml:mi>n</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>n</mml:mi> <mml:mi>u</mml:mi></mml:msub></mml:munderover> <mml:msub><mml:mi>o</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>u</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula>
where <italic>n</italic><sub><italic>ij</italic></sub> and <italic>o</italic><sub><italic>ij</italic></sub> are the elements on row <italic>i</italic> and column <italic>j</italic> of <italic>N</italic> and <italic>O</italic>, respectively. For models of the form of <xref ref-type="disp-formula" rid="pcbi.1004457.e013">Eq (3)</xref>, the solution <italic>x</italic>(<italic>t</italic>,<bold>p</bold>) may be approximated with a <italic>surrogate model</italic> based on truncated polynomial expansions in parameter space.</p>
</sec>
<sec id="sec005">
<title>Parameter scaling</title>
<p>The adaptive sparse quadrature approach requires parameter ranges that are of unit size, and symmetric about zero. To this end, we rescale the parameters by an affine reparametrization: <inline-formula id="pcbi.1004457.e014"><alternatives><graphic id="pcbi.1004457.e014g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e014"/><mml:math id="M14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>p</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow> <mml:mn>2</mml:mn></mml:mfrac> <mml:msub><mml:mover><mml:mi>p</mml:mi> <mml:mo accent="true">~</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow> <mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1004457.e015"><alternatives><graphic id="pcbi.1004457.e015g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e015"/><mml:math id="M15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>p</mml:mi> <mml:mo accent="true">~</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub> <mml:mo>∈</mml:mo> <mml:mo stretchy="false">[</mml:mo> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Then, with <inline-formula id="pcbi.1004457.e016"><alternatives><graphic id="pcbi.1004457.e016g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e016"/><mml:math id="M16" display="inline" overflow="scroll"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>:</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mo>:</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>ρ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></alternatives></inline-formula>, denoting by <italic>n</italic><sub>:<italic>j</italic></sub> the jth column of <italic>N</italic>, <xref ref-type="disp-formula" rid="pcbi.1004457.e013">Eq (3)</xref> takes the form:
<disp-formula id="pcbi.1004457.e017"><alternatives><graphic id="pcbi.1004457.e017g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e017"/><mml:math id="M17" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>ρ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:msub><mml:mi>o</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>︸</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mo>:</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:munder></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
where the last two terms summarized by <italic>ϕ</italic><sub><italic>i</italic>0</sub>(<italic>x</italic>, <italic>u</italic>) are independent of the model parameters. The domain of the parameters is then given by the Cartesian product <inline-formula id="pcbi.1004457.e018"><alternatives><graphic id="pcbi.1004457.e018g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e018"/><mml:math id="M18" display="inline" overflow="scroll"><mml:mi>U</mml:mi><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mn>1</mml:mn></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>.</p>
</sec>
<sec id="sec006">
<title>Adaptive Smolyak sparse grids</title>
<p>Assume an infinite number of terms in <xref ref-type="disp-formula" rid="pcbi.1004457.e017">Eq (4)</xref>. Now let <italic>σ</italic> be the maximal value of <italic>s</italic> for which <inline-formula id="pcbi.1004457.e019"><alternatives><graphic id="pcbi.1004457.e019g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e019"/><mml:math id="M19" display="inline" overflow="scroll"><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>∞</mml:mi></mml:msubsup><mml:mrow><mml:mo>∣</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msup><mml:mo>∣</mml:mo><mml:mi>s</mml:mi></mml:msup><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:mstyle></mml:math></alternatives></inline-formula> holds, where <italic>L</italic><sub><italic>j</italic></sub> is the Lipschitz constant of <italic>ϕ</italic><sub><italic>j</italic></sub> (i.e., <inline-formula id="pcbi.1004457.e020"><alternatives><graphic id="pcbi.1004457.e020g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e020"/><mml:math id="M20" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mo stretchy="false">‖</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>x</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>−</mml:mo> <mml:msub><mml:mi>ϕ</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:msup><mml:mi>x</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo stretchy="false">)</mml:mo> <mml:mo stretchy="false">‖</mml:mo></mml:mrow> <mml:mrow><mml:mo stretchy="false">‖</mml:mo> <mml:mi>x</mml:mi> <mml:mo>−</mml:mo> <mml:msup><mml:mi>x</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo stretchy="false">‖</mml:mo></mml:mrow></mml:mfrac> <mml:mo>≤</mml:mo> <mml:msub><mml:mi>L</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> for ∀<italic>x</italic> ∈ <italic>U</italic>(<italic>x</italic>′), where <italic>U</italic>(<italic>x</italic><sub>0</sub>) is the neighborhood of any feasible state vector <italic>x</italic><sub>0</sub>). The approximation error (difference between the original model and the computational surrogate model) is then bounded by <italic>CM</italic><sup>−<italic>r</italic></sup>, where <italic>M</italic> denotes the number of forward simulations, <inline-formula id="pcbi.1004457.e021"><alternatives><graphic id="pcbi.1004457.e021g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e021"/><mml:math id="M21" display="inline" overflow="scroll"><mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>σ</mml:mi></mml:mfrac> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and 0 &lt; <italic>σ</italic> &lt; 1 and <italic>C</italic> &gt; 0 is a constant that is independent of the system size [<xref ref-type="bibr" rid="pcbi.1004457.ref018">18</xref>]. Furthermore, the Lipschitz constants for <italic>ϕ</italic><sub><italic>j</italic></sub>(<italic>x</italic>) can be made arbitrarily small by adjusting the distance between <italic>a</italic><sub><italic>j</italic></sub> and <italic>b</italic><sub><italic>j</italic></sub> due to the rescaling of the parameter range. The performance of the adaptive Smolyak method typically improves once we constrain admissible parameter ranges to small neighborhoods near nominal values.</p>
<p>For CRN models the number of reaction terms in <xref ref-type="disp-formula" rid="pcbi.1004457.e013">Eq (3)</xref> is finite, but possibly (very) large. Then the error bound <italic>CM</italic><sup>−<italic>r</italic></sup> obtained in [<xref ref-type="bibr" rid="pcbi.1004457.ref018">18</xref>] in the infinite-dimensional case is valid, with <italic>C</italic> and <italic>r</italic> independent of the system size. Importantly, the <italic>convergence rate</italic> <italic>r</italic> is independent of the dimension of the parameter space (the number of model parameters). It depends only on the sparsity <italic>σ</italic> ∈ (0,1) afforded by a system’s kinetic description. Here, the term <italic>sparsity</italic> does <italic>not</italic> refer to sparsity in the CRN connectivity graph, but to the frequency of appearance of large coefficients in (generalized) polynomial chaos expansions (‘gpc’ expansions, for short) of the parametric systems’ responses; it is mathematically encapsulated as “<italic>p</italic>-summability of the gpc coefficient sequence”. This has recently been established for high-dimensional CRN models based on mass-action kinetics [<xref ref-type="bibr" rid="pcbi.1004457.ref018">18</xref>]. There, a large number of “almost” decoupled subsystems increases sparsity in polynomial expansions of parametrized system responses, which is favorable for performance of our adaptive Smolyak algorithms. This convergence rate should be compared to that of conventional tensor product interpolation methods, which decreases with the dimension <italic>n</italic><sub><italic>p</italic></sub> of the parameter space. For illustration, consider the following linear model (see [<xref ref-type="bibr" rid="pcbi.1004457.ref020">20</xref>] for numerical experiments):
<disp-formula id="pcbi.1004457.e022"><alternatives><graphic id="pcbi.1004457.e022g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e022"/><mml:math id="M22" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi> <mml:mi>x</mml:mi></mml:mrow> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>∞</mml:mi></mml:munderover> <mml:msub><mml:mi>p</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msup><mml:mi>j</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>s</mml:mi></mml:mrow></mml:msup> <mml:mi>x</mml:mi> <mml:mo>+</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula>
where <italic>s</italic> &gt; 1, and the number of parameters is infinite. By comparing <xref ref-type="disp-formula" rid="pcbi.1004457.e022">Eq (5)</xref> to <xref ref-type="disp-formula" rid="pcbi.1004457.e013">Eq (3)</xref> we have that: <italic>ϕ</italic><sub><italic>j</italic></sub>(<italic>x</italic>) = <italic>j</italic><sup>−<italic>s</italic></sup> <italic>x</italic>. Therefore the Lipschitz constant <italic>L</italic><sub><italic>j</italic></sub> for <italic>ϕ</italic><sub><italic>j</italic></sub>(<italic>x</italic>) is <italic>j</italic><sup>−<italic>s</italic></sup>, and:
<disp-formula id="pcbi.1004457.e023"><alternatives><graphic id="pcbi.1004457.e023g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e023"/><mml:math id="M23" display="block" overflow="scroll"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>∞</mml:mi></mml:munderover> <mml:msup><mml:mrow><mml:mo>|</mml:mo> <mml:msub><mml:mi>L</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>|</mml:mo></mml:mrow> <mml:mi>σ</mml:mi></mml:msup> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>∞</mml:mi></mml:munderover> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>j</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>s</mml:mi></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>σ</mml:mi></mml:msup> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>∞</mml:mi></mml:munderover> <mml:msup><mml:mi>j</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>s</mml:mi> <mml:mi>σ</mml:mi></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(6)</label></disp-formula>
It is well known that the series <inline-formula id="pcbi.1004457.e024"><alternatives><graphic id="pcbi.1004457.e024g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e024"/><mml:math id="M24" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mo>∞</mml:mo></mml:msubsup> <mml:msup><mml:mi>j</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>q</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> converges for <italic>q</italic> &gt; 1 [<xref ref-type="bibr" rid="pcbi.1004457.ref021">21</xref>]. Therefore the sum in <xref ref-type="disp-formula" rid="pcbi.1004457.e023">Eq (6)</xref> converges for <italic>sσ</italic> &gt; 1 and for <inline-formula id="pcbi.1004457.e025"><alternatives><graphic id="pcbi.1004457.e025g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e025"/><mml:math id="M25" display="inline" overflow="scroll"><mml:mrow><mml:mi>σ</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>s</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. Note that the larger the value of <italic>s</italic>, the smaller the potential values of <italic>σ</italic>, and the larger the convergence rate: <inline-formula id="pcbi.1004457.e026"><alternatives><graphic id="pcbi.1004457.e026g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e026"/><mml:math id="M26" display="inline" overflow="scroll"><mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>σ</mml:mi></mml:mfrac> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
</sec>
<sec id="sec007">
<title>Surrogate models</title>
<p>With the final surrogate model, we can compute the expected value (and possibly higher moments) for modeled system properties. Typically, system properties that have not been (or cannot be) experimentally measured are of interest. The expected value of a quantity Φ(<bold>p</bold>), in the rescaled parameter region <italic>U</italic>, reads:
<disp-formula id="pcbi.1004457.e027"><alternatives><graphic id="pcbi.1004457.e027g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e027"/><mml:math id="M27" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>U</mml:mi></mml:msub> <mml:mo>Φ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>|</mml:mo> <mml:mi>D</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>U</mml:mi></mml:msub> <mml:mo>Φ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi>D</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi>D</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula>
where <italic>D</italic> are the experimental data, <italic>p</italic>(<bold>p</bold>∣<italic>D</italic>) is the posterior distribution given data <italic>D</italic>, <italic>p</italic>(<italic>D</italic>∣<bold>p</bold>) is the likelihood, and <italic>p</italic>(<bold>p</bold>) is the prior distribution. We assume additive, Gaussian observation noise. The measurement model for <italic>K</italic> experimental observables and <italic>n</italic><sub><italic>t</italic></sub> time instances is of the form: <italic>y</italic> = <italic>h</italic>(<bold>p</bold>) + <italic>η</italic>, <italic>η</italic> ∼ 𝓝(0,Γ). The likelihood then takes the form of a (inverse) covariance-scaled least squares functional <inline-formula id="pcbi.1004457.e028"><alternatives><graphic id="pcbi.1004457.e028g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e028"/><mml:math id="M28" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>∣</mml:mo><mml:mtext mathvariant="bold">p</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mtext> </mml:mtext><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∏</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mtext mathvariant="bold">p</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mtext mathvariant="bold">p</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></alternatives></inline-formula>, where <italic>y</italic><sub><italic>k</italic></sub> ∈ <italic>D</italic> is the data at observation time <italic>t</italic><sub><italic>k</italic></sub>. Marginalizing over the parameter space, we compute the evidence <italic>p</italic>(<italic>D</italic>) as
<disp-formula id="pcbi.1004457.e029"><alternatives><graphic id="pcbi.1004457.e029g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e029"/><mml:math id="M29" display="block" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>D</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>U</mml:mi></mml:msub> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>D</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>U</mml:mi></mml:msub> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>D</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(8)</label></disp-formula></p>
<p>Such an explicit computation of the evidence is computationally inexpensive for surrogate models based on sparse gpc approximations (it may not be necessary for all applications, however). Sparsity in the parametric solution of <xref ref-type="disp-formula" rid="pcbi.1004457.e001">Eq (1)</xref>, with the right-hand-side defined in <xref ref-type="disp-formula" rid="pcbi.1004457.e013">Eq (3)</xref>, implies sparsity in the parametric posterior distribution. Hence, the integral in <xref ref-type="disp-formula" rid="pcbi.1004457.e029">Eq (8)</xref> (and <xref ref-type="disp-formula" rid="pcbi.1004457.e027">Eq (7)</xref>) computed with an output-adapted sparse grid with <italic>M</italic> points converges with rate <italic>CM</italic><sup>−<italic>r</italic></sup> where <italic>C</italic> &gt; 0 and <italic>r</italic> depends only on the sparsity <italic>σ</italic>, as discussed above. This should be compared to the Monte Carlo approach (e.g. [<xref ref-type="bibr" rid="pcbi.1004457.ref022">22</xref>]). Here, the expected value of Φ(<bold>p</bold>) is estimated by the finite sample average
<disp-formula id="pcbi.1004457.e030"><alternatives><graphic id="pcbi.1004457.e030g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e030"/><mml:math id="M30" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow> <mml:mo>≔</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>M</mml:mi></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:mo>Φ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">p</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula>
where the sequence of parameter samples <bold>p</bold><sub><italic>i</italic></sub>, <italic>i</italic> = 1, …, <italic>M</italic> is i.i.d drawn from the posterior distribution <italic>p</italic>(<bold>p</bold>∣<italic>D</italic>) (e.g., see the randomized Metropolis-Hastings Markov chain Monte Carlo (MH-MCMC) method [<xref ref-type="bibr" rid="pcbi.1004457.ref023">23</xref>]). The asymptotic convergence rate of the sample average <xref ref-type="disp-formula" rid="pcbi.1004457.e030">Eq (9)</xref> as the number <italic>M</italic> of samples (i.e., the number of forward simulations) tends to ∞ is bounded by
<disp-formula id="pcbi.1004457.e031"><alternatives><graphic id="pcbi.1004457.e031g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e031"/><mml:math id="M31" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>∥</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>∥</mml:mo></mml:mrow> <mml:msup><mml:mi>L</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:msub> <mml:mo>≤</mml:mo> <mml:msup><mml:mi>M</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:msub><mml:mrow><mml:mo>∥</mml:mo> <mml:mo>Φ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∥</mml:mo></mml:mrow> <mml:msup><mml:mi>L</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(10)</label></disp-formula>
The (mean square w.r.t. the prior) convergence rate 1/2 (to be distinguished from the actual computational work, which increases linearly with the number of parameters) <xref ref-type="disp-formula" rid="pcbi.1004457.e031">Eq (10)</xref> is also independent of the dimension of the parameter space. However, this rate is low (at most = 0.5, implying in particular that error reduction by a factor 1/2 mandates four times as much work) compared to the convergence rate afforded by the adaptive Smolyak process.</p>
</sec>
</sec>
<sec id="sec008" sec-type="results">
<title>Results</title>
<p>To validate the implementation of the dimension-adaptive Smolyak algorithm and to quantify its performance for CRN models, we applied it to three published systems biology models that range from small-scale to one of the highest-dimensional current models using <italic>in silico</italic> generated data.</p>
<sec id="sec009">
<title>Model 1: Glucose uptake in yeast</title>
<p>The availability of nutrients plays a major role for the survival, growth, and proliferation of microorganisms such as the yeast <italic>Saccharomyces cerevisiae</italic>. Glucose specifically is imported into the cells and directly processed in the glycolytic pathway. Yeast prefers glucose over other carbon sources such as fructose and mannose and it therefore possesses intricate mechanisms for glucose sensing. However, the initial mechanisms for glucose sensing and activation have often turned out to be more difficult to elucidate than downstream components and their functions [<xref ref-type="bibr" rid="pcbi.1004457.ref024">24</xref>].</p>
<p>A predictive model of glycolysis would therefore be of great interest and efforts have already been made in this direction [<xref ref-type="bibr" rid="pcbi.1004457.ref025">25</xref>]. However, although the stoichiometric properties of glycolysis are well characterized, the kinetics of individual reactions are difficult to infer. A model for the first steps of glycolysis, characterized by facilitated diffusion of glucose into <italic>S. cerevisiae</italic> cells, has been presented in [<xref ref-type="bibr" rid="pcbi.1004457.ref026">26</xref>]. In a detailed version of this model with 9 states and 10 parameters, which serves as our small-scale test case, glucose import is inhibited by glucose-6-phosphate (G6P) (see <xref ref-type="fig" rid="pcbi.1004457.g002">Fig 2A</xref>, <xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref> for details, and <xref ref-type="supplementary-material" rid="pcbi.1004457.s002">S1 File</xref> for an implementation of the adaptive Smolyak method for this model).</p>
<fig id="pcbi.1004457.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004457.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Analysis of the glucose model.</title>
<p><bold>A:</bold> Model for glucose uptake in <italic>S. cerevisiae</italic> cells. Protein E transports glucose (Glc) between the external (e) and internal (i) regions of the cell membrane. Glucose-6-phosphate (G6P) inhibits the uptake of intracellular glucose at the membrane. Model parameters such as association (<italic>k</italic><sub><italic>i</italic></sub>) and dissociation (<italic>k</italic><sub>−<italic>i</italic></sub>) constants are indicated next to the corresponding reaction arrows. <bold>B:</bold> Estimated maximal (absolute) errors in the interpolation (Clenshaw-Curtis, CC) over three state variables (external and internal glucose, and G6P), and over time, w.r.t. the number of ODE solves in the parameter region ±0.25<bold>p</bold><sub>0</sub> (normal space). <bold>C:</bold> Absolute error over time for the first order (FO) approximation and the sparse grid (CC) solution, from comparisons to the exact ODE solution at a randomly chosen parameter point in ±0.25<bold>p</bold><sub>0</sub> (normal space). The result is representative in the investigated parameter region (cf. <xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref>). Approximation errors (log<sub>10</sub>) for external glucose are represented by blue (CC) and black (FO) diamonds, and for G6P by blue (CC) and black (FO) squares. <bold>D:</bold> Estimated maximal (absolute) errors in the normalization constant for Bayesian inference for the same settings as in (<bold>B</bold>). <bold>E:</bold> Comparison of convergence rates for the adaptive Smolyak approach (green) and MH-MCMC (black). For MH-MCMC the normalized error was computed as the maximal (absolute) error between approximation and exact solution (approximated by 100.000 samples), at the time points in (<bold>C</bold>), for the six state variables involving transporter E (<bold>A</bold>). The red (blue) line indicates a convergence rate of 0.5 (1.2). <bold>F:</bold> Computed index sets for ≈ 700 iterations of the adaptive Smolyak algorithm for interpolation (CC, ±0.25 ⋅ <bold>p</bold><sub>0</sub>), w.r.t. the 10 model parameters. Each dot represents an increased number of grid points in the direction of the corresponding parameter and the color indicates the order of the interpolation formula: black = 1; green = 2; red = 3. <bold>G:</bold> Activation of indices (that is, number of grid points) per parameter direction, normalized by the number of iterations. Parameter identifiers correspond to (<bold>F</bold>) and (<bold>A</bold>), respectively.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004457.g002"/>
</fig>
<p>In the <italic>forward analysis</italic>, we focused on the effects of changes in parameters on the dynamics of metabolite concentrations (internal and external glucose, internal G6P) that can be measured with state of the art experimental methods such as mass spectrometry [<xref ref-type="bibr" rid="pcbi.1004457.ref027">27</xref>]. The adaptive Smolyak interpolation of the corresponding model states shows a convergence rate of 1 with respect to the number of ODE solves needed (<xref ref-type="fig" rid="pcbi.1004457.g002">Fig 2B</xref>; see also <xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref>) to achieve the given accuracy (2 × 10<sup>−5</sup>) in terms of the difference between the original and surrogate model uniformly over the parameter space. To investigate how the accuracy of our algorithm compares to a first-order approximation, we conducted a local sensitivity analysis and observed a gain in accuracy of two orders of magnitude, at comparable work (<xref ref-type="fig" rid="pcbi.1004457.g002">Fig 2C</xref> and <xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref>).</p>
<p>Importantly, with the Smolyak method it is also possible to efficiently compute other system characteristics on the entire parameter domain with a prescribed accuracy. We conducted numerical studies on the <italic>inverse problem</italic> in the context of Bayesian parameter estimation. In the glucose model, such estimation may aim at identifying the concentration of individual carrier complexes over time, which are significantly more difficult to measure with available experimental methods. For Bayesian inference, the adaptive Smolyak algorithm shows a similar convergence behavior as in the forward problem (<xref ref-type="fig" rid="pcbi.1004457.g002">Fig 2D</xref>). However, for some levels of noise in the artificial data we observe a slightly worse convergence rate (approximately 0.65 over 10<sup>5</sup> ODE solves; <xref ref-type="fig" rid="pcbi.1004457.g002">Fig 2E</xref>), because parameter sets with high posterior probability constitute a small part of the total parameter space. We also compared these results to those obtained from running a Metropolis-Hastings Markov chain Monte Carlo (MH-MCMC) algorithm on the same data, resulting in the same posterior distributions and showing that our implementation is accurate. Notably this was achieved with significantly less computational effort than with MH-MCMC (<xref ref-type="fig" rid="pcbi.1004457.g002">Fig 2E</xref>). These results indicate the potential of the Smolyak algorithm for the efficient forward analysis and Bayesian inversion. However, the difference in performance between the algorithms can be expected to be significantly larger for high-dimensional applications.</p>
<p>Finally, we focused on the biological interpretation of the numerical results with respect to the mechanisms for glucose transport that are most relevant (under our particular choices of observations for the forward problem and the selected domain in parameter space). <xref ref-type="fig" rid="pcbi.1004457.g002">Fig 2F</xref> shows the activation of indices (grid points) per parameter dimension in the forward problem. Visually, it is apparent that different parameters required different numbers of interpolation points and interpolation orders. We quantified this behavior by an index activation, that is, the total order of active interpolants normalized by the number of iterations. While overall the index activation is rather homogeneous (<xref ref-type="fig" rid="pcbi.1004457.g002">Fig 2G</xref>), the approximation of the model behavior depends substantially less on parameters <italic>k</italic><sub>3</sub> and <italic>k</italic><sub>−3</sub>, which relate to the forward and backward directions of the reaction for binding of intracellular G6P to the glucose bound carrier (E-Glc) at the inner region of the cell membrane (see <xref ref-type="fig" rid="pcbi.1004457.g002">Fig 2A</xref>). This reaction is part of a hypothesized inhibition of glucose transport by G6P [<xref ref-type="bibr" rid="pcbi.1004457.ref026">26</xref>], indicating that the reaction may not exist in reality (under the conditions assumed for the numerical analysis). In contrast to first-order sensitivity analysis, this result is not pertinent to a nominal model parametrization only. More generally, this indicates that the proposed Smolyak sparse grid method can be employed for the detailed analysis of parameter dependencies (and eventual model order reduction) of systems biology models.</p>
</sec>
<sec id="sec010">
<title>Model 2: Epidermal growth factor receptor (EGFR) signaling</title>
<p>To investigate how our method performs for larger, more typical current systems biology models, we applied it to a model of the EGFR pathway response for the first two minutes upon EGF stimulation [<xref ref-type="bibr" rid="pcbi.1004457.ref028">28</xref>]. This model was used to explain why EGFR phosphorylation peaks at ≈ 30s and returns to low levels at 1–2 min after stimulation, whereas the phosphorylation of other key proteins increases monotonically. Briefly, the model captures short-term signaling induced by EGF in an ‘upstream’ set of reactions leading from EGFR—EGF binding to active (phosphorylated) EGFR dimers. The interactions of the active receptor with its cytoplasmic target proteins consists of three coupled cycles of reactions involving Grb2, Shc, and PLC<italic>γ</italic>, respectively. Theses cycles feed downstream signaling to targets such as Ras and PI3K [<xref ref-type="bibr" rid="pcbi.1004457.ref028">28</xref>].</p>
<p>The model has 50 kinetic parameters, whose values were determined based on previous reports and biochemical considerations, leading to a reasonable description of the experimental observations [<xref ref-type="bibr" rid="pcbi.1004457.ref028">28</xref>]. To identify potential targets for external modification of the pathway behavior (e.g., through drugs), it is interesting to investigate the sensitivity of the pathway response to the kinetic parameters. In [<xref ref-type="bibr" rid="pcbi.1004457.ref028">28</xref>], the system behavior in response to parametric perturbations was reported to be stable “over a wide range of values”, but in the analysis all rate-constants were simultaneously multiplied by a constant factor (×2), which only leads to a “scaling of the time”. With our method, it is possible to investigate the response to variations in any combination of the parameters. This is a major advantage, since information about the importance of parameters and all the possible response patterns is generated.</p>
<p>The estimated error of the adaptive Smolyak interpolation suggests for this problem a convergence rate of 0.75 with respect to the number <italic>M</italic> of ODE solves needed (<xref ref-type="fig" rid="pcbi.1004457.g003">Fig 3A</xref>). This rather moderate (but still superior to Monte-Carlo sampling) rate results from near isotropic refinement of the sparse interpolant in the 50-dimensional parameter space. This is indicated by the sets of activated indices for the adaptive Smolyak algorithm (<xref ref-type="fig" rid="pcbi.1004457.g003">Fig 3B</xref>), where virtually all parameter dimensions require higher-order approximations. Over extended parameter domains, we again find that our method yields results that are approximately two orders of magnitude more accurate than those obtained by first-order parameter sensitivities (<xref ref-type="fig" rid="pcbi.1004457.g003">Fig 3C</xref>).</p>
<fig id="pcbi.1004457.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004457.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Analysis of the EGFR model.</title>
<p><bold>A:</bold> Estimated maximal absolute error for the adaptive interpolation for states 1–23 with respect to the number of ODE solves (Smolyak, CC, in the region ±0.25 ⋅ <bold>p</bold><sub>0</sub>, normal space), <bold>B:</bold> Computed index sets for 4000 iterations of the adaptive Smolyak algorithm for interpolation (CC, ±0.25 ⋅ <bold>p</bold><sub>0</sub>), w.r.t. the 50 model parameters. Each black dot represents an increased number of grid points in the direction of the corresponding parameter. <bold>C:</bold> Maximal absolute errors for the 23 state variables for sparse grids (blue) and FO approximation (black). <bold>D:</bold> Illustration of dependencies of averaged squared changes in model states (<italic>χ</italic><sup>2</sup>(<italic>p</italic>)) as a function of a single parameter <italic>p</italic>. A quadratic approximation of the model response to parameter changes around the nominal point (red) can lead to large inaccuracies compared to the exact response when model responses are not symmetric (case 1), or when the local and global behavior are very different (case 2). <bold>E:</bold> Comparison of rank-ordered characterizations of parameter influences by quadratic approximation (eigenvalues of the Hessian matrix) and by the sparse grid method (index activation, as in <xref ref-type="fig" rid="pcbi.1004457.g002">Fig 2G</xref>). Pearson’s correlation <italic>ρ</italic> and corresponding P-value are given at the top; red dots highlight the seven most influential parameters identified by sparse grids. <bold>F:</bold> Sloppiness of model parameters as evaluated by the eigenvalues of the Hessian matrix (quadratic approximation at the nominal point) and by the activation frequency of indices (sparse grid computation). In both cases, distributions were centered by the mean in <italic>log</italic><sub>10</sub> space.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004457.g003"/>
</fig>
<p>The isotropic refinement for sparse grids questions earlier beliefs on generally ‘sloppy’ models in systems biology and in other domains [<xref ref-type="bibr" rid="pcbi.1004457.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1004457.ref029">29</xref>] that essentially relied on computing local parameter sensitivities. The analysis of ‘sloppy’ models uses a quadratic approximation of the average squared changes in the model states <italic>χ</italic><sup>2</sup>(<bold>p</bold>) at a nominal parameter point. More specifically, the metric for parameter influences proposed are the absolute eigenvalues <italic>λ</italic> of the (quadratic) Hessian matrix; high (low) eigenvalues indicate influential (non-influential) parameters. As illustrated in <xref ref-type="fig" rid="pcbi.1004457.g003">Fig 3D</xref>, however, compared to the exact <italic>χ</italic><sup>2</sup>(<bold>p</bold>) that can be computed with our proposed algorithm, the quadratic approximation may be inaccurate when the model response is asymmetric, or when it changes qualitatively distant from the nominal parameter point. The rank-ordered metrics (eigenvalues <italic>λ</italic> for the quadratic approximation and index activation for the sparse grids, respectively) for the EGFR signaling model correlate significantly, but only poorly (Pearson rank correlation <italic>ρ</italic> = 0.29, <italic>P</italic> = 0.04; <xref ref-type="fig" rid="pcbi.1004457.g003">Fig 3E</xref>). The most influential parameters identified by the adaptive Smolyak method, however, yield a biologically consistent interpretation. These parameters pertain to receptor autophosphorylation and dephosphorylation (<italic>k</italic><sub>3</sub>, <italic>V</italic><sub>4</sub>, and <italic>K</italic><sub>4</sub> in the notation of [<xref ref-type="bibr" rid="pcbi.1004457.ref028">28</xref>]) as well as active receptor interactions with its direct binding partners Shc (<italic>k</italic><sub>13</sub> and <italic>k</italic><sub>15</sub>) and PLC<italic>γ</italic> (<italic>k</italic><sub>5</sub> and <italic>k</italic><sub>7</sub>). This indicates that control of active receptor by (auto)phosphorylation dominates the model behavior. In contrast, the quadratic approximation would allocate the control to upstream receptor- ligand interactions (<italic>k</italic><sub>1</sub>, <italic>k</italic><sub>−1</sub>, <italic>k</italic><sub>2</sub>, <italic>k</italic><sub>−2</sub> are associated with the largest absolute eigenvalues). We find another suggested characteristic of ‘sloppy’ models, namely that eigenvalues spread across many decades [<xref ref-type="bibr" rid="pcbi.1004457.ref005">5</xref>], also in the EGFR model, but global analysis with a narrowly distributed spectrum of index activations (<xref ref-type="fig" rid="pcbi.1004457.g003">Fig 3F</xref>) again questions the accuracy of local approximations, and interpretations thereof.</p>
<p>Finally, in the Bayesian inverse problem, which consists of computing the conditional expectation of the first state, unbound EGF, under given (artificial) noisy, observational data, the convergence rate was improved to approximately 1 (<xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref>). The improved convergence rate compared to the MH-MCMC method shows the potential of the proposed, adaptive Smolyak approach in particular for larger CRN models with several hundreds of state and parameter variables. We attribute a decrease in the convergence rate for larger parameter variations in the EGFR model (see <xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref>) to the more pronounced impact of nonlinearities in the model. In practical applications such as the Bayesian inference of pathway topologies for EGRF signaling in [<xref ref-type="bibr" rid="pcbi.1004457.ref008">8</xref>] using models of similar size, however, we expect substantial gains in performance compared to sampling-based methods.</p>
</sec>
<sec id="sec011">
<title>Model 3: Coupled signaling pathways</title>
<p>To investigate how the adaptive sparse Smolyak method performs in high-dimensional parameter spaces we analyzed a model of the epidermal growth factor (EGF) and heregulin (HRG) activated response in the mammalian ErbB signaling pathways and in the MAPK and Akt cascades [<xref ref-type="bibr" rid="pcbi.1004457.ref014">14</xref>]. Briefly, the model, formulated entirely in mass-action kinetics, can be seen as a substantial extension of the EGFR model [<xref ref-type="bibr" rid="pcbi.1004457.ref028">28</xref>] above. It encompasses all four receptor species (ErbB1-4) and their complex interactions explicitly. Degradation pathways via endosomes are represented as well as downstream signaling through the mitogenic Ras/MAPK and the pro-survival PI3K/Akt pathways. Especially the detailed modeling of combinatorial interactions between and at receptor species lead to a model that encompasses 500 states and 229 parameters, making it one of the most complex systems biology models developed to date. In [<xref ref-type="bibr" rid="pcbi.1004457.ref014">14</xref>], the authors focused again on short-term signaling, and they found that first-order parameter sensitivities are highly context (molecular feature and stimulation condition) specific. However, the model parameters were estimated in a region 2.5 orders below and above the nominal values in log-space. Due to the challenges of parameter identification in high-dimensional, nonlinear ODE models, Chen et al. [<xref ref-type="bibr" rid="pcbi.1004457.ref014">14</xref>] took a pragmatic approach: model parameters were repeatedly estimated, and patterns in the optimization results were then used to infer model properties in order to cope with the issue of identifying parameters in large parameter spaces, as well as the non-identifiability of the model given the experimental data. However, such an approach does not guarantee that the results represent true model properties—they could be strongly biased.</p>
<p>A detailed sensitivity analysis of this model revealed extreme parameter sensitivities (up to 10<sup>15</sup>), which is summarized in the <italic>sensitivity profile</italic> <xref ref-type="fig" rid="pcbi.1004457.g004">Fig 4A</xref>. The sensitivity profile is an indicator for the sensitivity of the model w.r.t. each parameter, computed as the maximum absolute value of the sensitivity, at the nominal parameter point, over states and time. Such high sensitivity values render a computational forward analysis, as well as Bayesian inference, infeasible even for moderate parameter variations. To cope with such sensitivities, we therefore initially restricted the range of investigated values for each parameter to ±0.01 of the nominal parameter point (<bold>p</bold><sub>0</sub>). In this region we observe a similar convergence behavior for the adaptive Smolyak interpolation and quadrature as for the two smaller models (<xref ref-type="fig" rid="pcbi.1004457.g004">Fig 4B</xref>). For the computational forward analysis, a gain in accuracy of two orders compared to the first-order approximation and a convergence rate of 1.5 can be achieved (see <xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref>). While we refrain from interpretation of the computational results because of the ill-conditioned model, these performance measures indicate that the proposed adaptive Smolyak method can also make large-scale systems biology models amenable to improved (Bayesian) parameter identification.</p>
<fig id="pcbi.1004457.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004457.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Analysis of coupled signaling pathways.</title>
<p><bold>A:</bold> Sensitivity profile: maximum of the derivative of each state variable w.r.t. each of the parameters (<inline-formula id="pcbi.1004457.e032"><alternatives><graphic id="pcbi.1004457.e032g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004457.e032"/><mml:math id="M32" display="inline" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>n</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>j</mml:mi><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math></alternatives></inline-formula>) for all simulated time points and for all 500 state variables. <bold>B:</bold> Estimated maximal absolute error for the adaptive interpolation for all 500 state variables with respect to the number of ODE solves in the region <bold>p</bold><sub>0</sub> ± 0.01<bold>p</bold><sub>0</sub>. Error curves for adaptively expanded regions show a similar trend (see <xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref>).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004457.g004"/>
</fig>
<p>We next generated noisy observational data of Akt, Erk, and ErbB phosphorylation at three to four time points for a parameter point in the investigated region. The estimated error of the algorithm indicates a convergence rate of 1–1.5 for the normalization constant of the Bayesian posterior (see <xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref>). In this computation, the adaptive Smolyak algorithm identifies the indices with the largest estimated contribution to the quantity of interest, which can be used in subsequent steps to adaptively enlarge the scanned parameter regions for the less-significant parameters. Hence, we propose the following heuristic strategy for adaptations of the parameter domain: we simply enlarge the parameter variations for all parameters not activated at the current stage of the algorithm. In analyzing model 3, many of the parameters were never activated by the algorithm, indicating that parameter ranges can be made even larger (arbitrarily large for redundant parameters not affecting the response variables). As shown in <xref ref-type="supplementary-material" rid="pcbi.1004457.s001">S1 Text</xref>, we obtained promising results with our heuristic strategy, despite the underlying model’s sensitivity issues. We are not aware that sampling-based analysis of a systems biology model of the present scope has ever been achieved.</p>
</sec>
</sec>
<sec id="sec012" sec-type="conclusions">
<title>Discussion</title>
<p>We propose a sparse, adaptive interpolation scheme for the efficient deterministic computational treatment of parametric uncertainty in complex, nonlinear systems. The methodology is particularly suitable for nonlinear parametric CRN models which commonly appear in computational systems and cell biology. Our numerical analysis of three CRN models that represent the scope of (current) model complexity indicates that the error convergence rate of our method is generically superior to that of Monte Carlo methods, in terms of the number of forward simulations required to reach a prescribed error tolerance. Moreover, MC approaches converge only in mean-square (cf. <xref ref-type="disp-formula" rid="pcbi.1004457.e031">Eq (10)</xref>), whereas the presently proposed methodology delivers “worst-case”, sup-norm convergence rates.</p>
<p>As expected, the efficiency of our method increases when many parameters contribute insignificantly to the model response. When the feasible parameter ranges are narrowed to small neighborhoods of the nominal value due to high sensitivities, our adaptive sparse tensor sampling scheme is superior to the widely used (local) first-order approximations. Also for “well-behaved” models that are equally sensitive to all parameters we observe a higher convergence rate with the Smolyak based approach. In our test problems, the proposed method consistently achieves relative numerical accuracy of five to seven decimals in typical quantities of interest in prediction and Bayesian inference for CRNs. While this accuracy may be considered excessive given the often substantial levels of measurement uncertainty in available data, we assert that <italic>high, certified relative numerical accuracy</italic> is necessary to clearly distinguish computational (e.g., numerical) errors from modeling errors (e.g., erroneous hypotheses on the CRN or on kinetic rate laws), and measurement noise. Our analysis of the EGFR model, for example, demonstrated that numerical parameter dependencies with certified accuracy imply a biological interpretation of sensitive network parts that is different from low-order approximations without such guarantees. Moreover, the postulated prevalence of ‘sloppy’ models in systems biology may need re-evaluation in the light of our findings of nearly isotropic model responses to parameter changes.</p>
<p>Our adaptive Smolyak interpolation method also has several other attractive features. Our method as well as MCMC will exactly characterize parametric dependencies in the limit of infinite samples or grid points. However, unlike MCMC, the sparse interpolation process provides a <italic>reduced surrogate model</italic> upon termination. This model can be quickly evaluated at additional parameter points. Already for moderate-sized models, such as the ERK model, the proposed sparse grid evaluation uses 28 times less CPU time than the ODE solver. Since the surrogate model is based on tensorized polynomial expansions, the computation of distribution moments via (Smolyak) integration of the surrogate model over the parameter space is trivial, thereby overcoming a common computational bottleneck of Bayesian analysis. For example, future work could consider Bayesian parameter estimation for the coupled signaling model to increase the model’s realism.</p>
<p>Further improvements of our Smolyak based method could focus on a systematic approach for increasing the feasible range of parameter values. We took first steps in this direction in the analysis of model 3, where the parameter ranges were iteratively extended, with promising results. Another interesting direction is to construct reduced models in an automated fashion, based on sensitivity analysis and quasi-steady state approximations, in different parts of the parameter space. The glucose model provided one example of this approach, identifying mechanisms that are potentially not relevant for overall glucose transport kinetics. The reduced models could then be analyzed in greater detail, e.g. in larger parameter ranges than the original model.</p>
<p>Our proposed methodology can extend the range of (biochemical) models that are amenable to computational analysis, and thereby the complexity of cellular networks that can be addressed with mathematical models. More generally, recent mathematical results on sparsity in gpc expansions of the parametric system responses for affine-parametric models predict that the proposed methodology can achieve convergence rates larger than 1/2 in terms of the number of forward simulations, free from the so-called “curse of dimensionality” [<xref ref-type="bibr" rid="pcbi.1004457.ref018">18</xref>]. Sparsity in polynomial chaos expansions of parametric responses due to sparse connectivity patterns in model descriptions appears also in nonlinear models of complex systems in other applications. Our presently proposed methodology for their efficient computational analysis extends, therefore, beyond CRNs from systems biology.</p>
</sec>
<sec id="sec013">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004457.s001" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004457.s001" mimetype="application/pdf" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Supplementary Data.</title>
<p>Detailed methods description, mathematical models analyzed, and additional numerical results.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004457.s002" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004457.s002" mimetype="application/x-compressed" xlink:type="simple">
<label>S1 File</label>
<caption>
<title>Supplementary File.</title>
<p>Implementation of the adaptive Smolyak sparse grid method for the glucose model (model 1).</p>
<p>(GZ)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1004457.ref001">
<label>1</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gillespie</surname> <given-names>DT</given-names></name> (<year>2009</year>) <article-title>Deterministic limit of stochastic chemical kinetics</article-title>. <source>J Phys Chem B</source> <volume>113</volume>: <fpage>1640</fpage>–<lpage>1644</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/jp806431b" xlink:type="simple">10.1021/jp806431b</ext-link></comment> <object-id pub-id-type="pmid">19159264</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref002">
<label>2</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Chen</surname> <given-names>WW</given-names></name>, <name name-style="western"><surname>Niepel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sorger</surname> <given-names>PK</given-names></name> (<year>2010</year>) <article-title>Classic and contemporary approaches to modeling biochemical reactions</article-title>. <source>Genes Dev</source> <volume>24</volume>: <fpage>1861</fpage>–<lpage>1875</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1101/gad.1945410" xlink:type="simple">10.1101/gad.1945410</ext-link></comment> <object-id pub-id-type="pmid">20810646</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref003">
<label>3</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Bar-Even</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Noor</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Savir</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Liebermeister</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Davidi</surname> <given-names>D</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>The moderately efficient enzyme: evolutionary and physicochemical trends shaping enzyme parameters</article-title>. <source>Biochemistry</source> <volume>50</volume>: <fpage>4402</fpage>–<lpage>4410</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/bi2002289" xlink:type="simple">10.1021/bi2002289</ext-link></comment> <object-id pub-id-type="pmid">21506553</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref004">
<label>4</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Balsa-Canto</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Banga</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Egea</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Fernandez-Villaverde</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>de Hijas-Liste</surname> <given-names>GM</given-names></name> (<year>2012</year>) <article-title>Global optimization in systems biology: stochastic methods and their applications</article-title>. <source>Adv Exp Med Biol</source> <volume>736</volume>: <fpage>409</fpage>–<lpage>424</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/978-1-4419-7210-1_24" xlink:type="simple">10.1007/978-1-4419-7210-1_24</ext-link></comment> <object-id pub-id-type="pmid">22161343</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref005">
<label>5</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gutenkunst</surname> <given-names>RN</given-names></name>, <name name-style="western"><surname>Waterfall</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Casey</surname> <given-names>FP</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Myers</surname> <given-names>CR</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Universally sloppy parameter sensitivities in systems biology models</article-title>. <source>PLoS Comput Biol</source> <volume>3</volume>: <fpage>1871</fpage>–<lpage>1878</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.0030189" xlink:type="simple">10.1371/journal.pcbi.0030189</ext-link></comment> <object-id pub-id-type="pmid">17922568</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref006">
<label>6</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Transtrum</surname> <given-names>MK</given-names></name>, <name name-style="western"><surname>Machta</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Sethna</surname> <given-names>JP</given-names></name> (<year>2011</year>) <article-title>Geometry of nonlinear least squares with applications to sloppy models and optimization</article-title>. <source>Phys Rev E Stat Nonlin Soft Matter Phys</source> <volume>83</volume>: <fpage>036701</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.83.036701" xlink:type="simple">10.1103/PhysRevE.83.036701</ext-link></comment> <object-id pub-id-type="pmid">21517619</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref007">
<label>7</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wilkinson</surname> <given-names>DJ</given-names></name> (<year>2007</year>) <article-title>Bayesian methods in bioinformatics and computational systems biology</article-title>. <source>Brief Bioinform</source> <volume>8</volume>: <fpage>109</fpage>–<lpage>116</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bib/bbm007" xlink:type="simple">10.1093/bib/bbm007</ext-link></comment> <object-id pub-id-type="pmid">17430978</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref008">
<label>8</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Xu</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Vyshemirsky</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Gormand</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>von Kriegsheim</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Girolami</surname> <given-names>M</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Inferring signaling pathway topologies from multiple perturbation measurements of specific biochemical species</article-title>. <source>Sci Signal</source> <volume>3</volume>: <fpage>ra20</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/scisignal.2000517" xlink:type="simple">10.1126/scisignal.2000517</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref009">
<label>9</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Liebermeister</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Klipp</surname> <given-names>E</given-names></name> (<year>2005</year>) <article-title>Biochemical networks with uncertain parameters</article-title>. <source>IEE Proceedings Systems Biology</source> <volume>152</volume>: <fpage>97</fpage>–<lpage>107</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1049/ip-syb:20045033" xlink:type="simple">10.1049/ip-syb:20045033</ext-link></comment> <object-id pub-id-type="pmid">16986274</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref010">
<label>10</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wasilkowski</surname> <given-names>GW</given-names></name>, <name name-style="western"><surname>Wozniakowski</surname> <given-names>H</given-names></name> (<year>1995</year>) <article-title>Explicit cost bounds of algorithms for multivariate tensor product problems</article-title>. <source>Journal of Complexity</source> <volume>11</volume>: <fpage>1</fpage>–<lpage>56</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1006/jcom.1995.1001" xlink:type="simple">10.1006/jcom.1995.1001</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref011">
<label>11</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Zamora-Sillero</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Hafner</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ibig</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Stelling</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>A</given-names></name> (<year>2011</year>) <article-title>Efficient characterization of high-dimensional parameter spaces for systems biology</article-title>. <source>BMC Syst Biol</source> <volume>5</volume>: <fpage>142</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1752-0509-5-142" xlink:type="simple">10.1186/1752-0509-5-142</ext-link></comment> <object-id pub-id-type="pmid">21920040</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref012">
<label>12</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Li</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Donizelli</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rodriguez</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dharuri</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Endler</surname> <given-names>L</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>BioModels Database: An enhanced, curated and annotated resource for published quantitative kinetic models</article-title>. <source>BMC Syst Biol</source> <volume>4</volume>: <fpage>92</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1752-0509-4-92" xlink:type="simple">10.1186/1752-0509-4-92</ext-link></comment> <object-id pub-id-type="pmid">20587024</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref013">
<label>13</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Karr</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Sanghvi</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Macklin</surname> <given-names>DN</given-names></name>, <name name-style="western"><surname>Gutschow</surname> <given-names>MV</given-names></name>, <name name-style="western"><surname>Jacobs</surname> <given-names>JM</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>A whole-cell computational model predicts phenotype from genotype</article-title>. <source>Cell</source> <volume>150</volume>: <fpage>389</fpage>–<lpage>401</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cell.2012.05.044" xlink:type="simple">10.1016/j.cell.2012.05.044</ext-link></comment> <object-id pub-id-type="pmid">22817898</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref014">
<label>14</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Chen</surname> <given-names>WW</given-names></name>, <name name-style="western"><surname>Schoeberl</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Jasper</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Niepel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Nielsen</surname> <given-names>UB</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Input-output behavior of ErbB signaling pathways as revealed by a mass action model trained against dynamic data</article-title>. <source>Molecular Systems Biology</source> <volume>5</volume>: <fpage>239</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/msb.2008.74" xlink:type="simple">10.1038/msb.2008.74</ext-link></comment> <object-id pub-id-type="pmid">19156131</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref015">
<label>15</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gonnet</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dimopoulos</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Widmer</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Stelling</surname> <given-names>J</given-names></name> (<year>2012</year>) <article-title>A specialized ODE integrator for the efficient computation of parameter sensitivities</article-title>. <source>BMC Syst Biol</source> <volume>6</volume>: <fpage>46</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1752-0509-6-46" xlink:type="simple">10.1186/1752-0509-6-46</ext-link></comment> <object-id pub-id-type="pmid">22607742</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref016">
<label>16</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Barabási</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Oltvai</surname> <given-names>Z</given-names></name> (<year>2004</year>) <article-title>Network biology: understanding the cell’s functional organization</article-title>. <source>Nat Rev Genetics</source> <volume>5</volume>: <fpage>101</fpage>–<lpage>13</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrg1272" xlink:type="simple">10.1038/nrg1272</ext-link></comment> <object-id pub-id-type="pmid">14735121</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref017">
<label>17</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Conradi</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Flockerzi</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Raisch</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Stelling</surname> <given-names>J</given-names></name> (<year>2007</year>) <article-title>Subnetwork analysis reveals dynamic features of complex (bio)chemical networks</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>104</volume>: <fpage>19175</fpage>–<lpage>19180</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0705731104" xlink:type="simple">10.1073/pnas.0705731104</ext-link></comment> <object-id pub-id-type="pmid">18042723</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref018">
<label>18</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hansen</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schwab</surname> <given-names>C</given-names></name> (<year>2013</year>) <article-title>Sparse adaptive approximation of high dimensional parametric initial value problems</article-title>. <source>Vietnam Journal of Mathematics</source> <volume>41</volume>: <fpage>181</fpage>–<lpage>215</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10013-013-0011-9" xlink:type="simple">10.1007/s10013-013-0011-9</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref019">
<label>19</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Smolyak</surname> <given-names>S</given-names></name> (<year>1963</year>) <article-title>Quadrature and interpolation formulas for tensor products of certain classes of functions</article-title>. <source>Sov Math Dokl</source> <volume>4</volume>: <fpage>240</fpage>–<lpage>243</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004457.ref020">
<label>20</label>
<mixed-citation xlink:type="simple" publication-type="other">Hansen M, Schillings C, Schwab C (2014) Sparse approximation algorithms for high dimensional parametric initial value problems. Proc of the Fifth International Conference on High Performance Scientific Computing 2012, Hanoi, Vietnam.</mixed-citation>
</ref>
<ref id="pcbi.1004457.ref021">
<label>21</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Råde</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Westergren</surname> <given-names>B</given-names></name> (<year>1998</year>) <source>Mathematics Handbook: For Science and Engineering</source>. <publisher-name>Studentlitteratur</publisher-name>. URL <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://books.google.ch/books?id=CPxjPwAACAAJ">http://books.google.ch/books?id=CPxjPwAACAAJ</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1004457.ref022">
<label>22</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Ristic</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Arulampalam</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Gordon</surname> <given-names>N</given-names></name> (<year>2004</year>) <article-title>Beyond the Kalman Filter: Particle Filters for Tracking Applications</article-title>. <source>Artech House radar library</source>. <publisher-name>Artech House</publisher-name>. URL <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="http://books.google.ch/books?id=zABIY--qk2AC">http://books.google.ch/books?id=zABIY--qk2AC</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1004457.ref023">
<label>23</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Chib</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Greenberg</surname> <given-names>E</given-names></name> (<year>1995</year>) <article-title>Understanding the Metropolis-Hastings algorithm</article-title>. <source>The American Statistician</source> <volume>49</volume>: <fpage>327</fpage>–<lpage>335</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/00031305.1995.10476177" xlink:type="simple">10.1080/00031305.1995.10476177</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref024">
<label>24</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rolland</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Winderickx</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Thevelein</surname> <given-names>JM</given-names></name> (<year>2002</year>) <article-title>Glucose-sensing and-signalling mechanisms in yeast</article-title>. <source>FEMS yeast research</source> <volume>2</volume>: <fpage>183</fpage>–<lpage>201</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1567-1364.2002.tb00084.x" xlink:type="simple">10.1111/j.1567-1364.2002.tb00084.x</ext-link></comment> <object-id pub-id-type="pmid">12702307</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref025">
<label>25</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Teusink</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Passarge</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Reijenga</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Esgalhado</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>van der Weijden</surname> <given-names>CC</given-names></name>, <etal>et al</etal>. (<year>2000</year>) <article-title>Can yeast glycolysis be understood in terms of in vitro kinetics of the constituent enzymes? Testing biochemistry</article-title>. <source>European Journal of Biochemistry</source> <volume>267</volume>: <fpage>5313</fpage>–<lpage>5329</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1046/j.1432-1327.2000.01527.x" xlink:type="simple">10.1046/j.1432-1327.2000.01527.x</ext-link></comment> <object-id pub-id-type="pmid">10951190</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref026">
<label>26</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Rizzi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Theobald</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Querfurth</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Rohrhirsch</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Baltes</surname> <given-names>M</given-names></name>, <etal>et al</etal>. (<year>1996</year>) <article-title>In vivo investigations of glucose transport in Saccharomyces cerevisiae</article-title>. <source>Biotechnology and Bioengineering</source> <volume>49</volume>: <fpage>316</fpage>–<lpage>327</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/(SICI)1097-0290(19960205)49:3%3C316::AID-BIT10%3E3.0.CO;2-C" xlink:type="simple">10.1002/(SICI)1097-0290(19960205)49:3%3C316::AID-BIT10%3E3.0.CO;2-C</ext-link></comment> <object-id pub-id-type="pmid">18623583</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref027">
<label>27</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Heinemann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sauer</surname> <given-names>U</given-names></name> (<year>2010</year>) <article-title>Systems biology of microbial metabolism</article-title>. <source>Curr Opin Microbiol</source> <volume>13</volume>: <fpage>337</fpage>–<lpage>343</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.mib.2010.02.005" xlink:type="simple">10.1016/j.mib.2010.02.005</ext-link></comment> <object-id pub-id-type="pmid">20219420</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref028">
<label>28</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Kholodenko</surname> <given-names>BN</given-names></name>, <name name-style="western"><surname>Demin</surname> <given-names>OV</given-names></name>, <name name-style="western"><surname>Moehren</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Hoek</surname> <given-names>JB</given-names></name> (<year>1999</year>) <article-title>Quantification of short term signaling by the epidermal growth factor receptor</article-title>. <source>J Biol Chem</source> <volume>274</volume>: <fpage>30169</fpage>–<lpage>30181</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1074/jbc.274.42.30169" xlink:type="simple">10.1074/jbc.274.42.30169</ext-link></comment> <object-id pub-id-type="pmid">10514507</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004457.ref029">
<label>29</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Machta</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Chachra</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Transtrum</surname> <given-names>MK</given-names></name>, <name name-style="western"><surname>Sethna</surname> <given-names>JP</given-names></name> (<year>2013</year>) <article-title>Parameter space compression underlies emergent theories and predictive models</article-title>. <source>Science</source> <volume>342</volume>: <fpage>604</fpage>–<lpage>607</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1238723" xlink:type="simple">10.1126/science.1238723</ext-link></comment> <object-id pub-id-type="pmid">24179222</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
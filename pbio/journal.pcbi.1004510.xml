<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004510</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-00603</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Deconstructing Interocular Suppression: Attention and Divisive Normalization</article-title>
<alt-title alt-title-type="running-head">Interocular Suppression, Attention and Normalization</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Li</surname>
<given-names>Hsin-Hung</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Carrasco</surname>
<given-names>Marisa</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Heeger</surname>
<given-names>David J.</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Department of Psychology, New York University, New York, New York, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Center for Neural Science, New York University, New York, New York, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Bethge</surname>
<given-names>Matthias</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Tübingen and Max Planck Institute for Biologial Cybernetics, GERMANY</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: HHL MC DJH. Performed the experiments: HHL. Analyzed the data: HHL. Wrote the paper: HHL MC DJH.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">david.heeger@nyu.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>30</day>
<month>10</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="collection">
<month>10</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>10</issue>
<elocation-id>e1004510</elocation-id>
<history>
<date date-type="received">
<day>13</day>
<month>4</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>20</day>
<month>8</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Li et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004510" xlink:type="simple"/>
<abstract>
<p>In interocular suppression, a suprathreshold monocular target can be rendered invisible by a salient competitor stimulus presented in the other eye. Despite decades of research on interocular suppression and related phenomena (e.g., binocular rivalry, flash suppression, continuous flash suppression), the neural processing underlying interocular suppression is still unknown. We developed and tested a computational model of interocular suppression. The model included two processes that contributed to the strength of interocular suppression: divisive normalization and attentional modulation. According to the model, the salient competitor induced a stimulus-driven attentional modulation selective for the location and orientation of the competitor, thereby increasing the gain of neural responses to the competitor and reducing the gain of neural responses to the target. Additional suppression was induced by divisive normalization in the model, similar to other forms of visual masking. To test the model, we conducted psychophysics experiments in which both the size and the eye-of-origin of the competitor were manipulated. For small and medium competitors, behavioral performance was consonant with a change in the response gain of neurons that responded to the target. But large competitors induced a contrast-gain change, even when the competitor was split between the two eyes. The model correctly predicted these results and outperformed an alternative model in which the attentional modulation was eye specific. We conclude that both stimulus-driven attention (selective for location and feature) and divisive normalization contribute to interocular suppression.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>In interocular suppression, a visible target presented in one eye can be rendered invisible by a competing image (the competitor) presented in the other eye. This phenomenon is a striking demonstration of the discrepancy between physical inputs to the visual system and perception, and it also allows neuroscientists to study how perceptual systems regulate competing information. Interocular suppression has been explained by mutually suppressive interactions (modeled by divisive normalization) between neurons that respond differentially to the two eyes. Attention, which selects relevant information in natural viewing condition, has also been found to play a role in interocular suppression. But the specific role of attentional modulation is still an open question. In this study, we proposed a computational model of interocular suppression integrating both attentional modulation and divisive normalization. By modeling the hypothetical neural responses and fitting the model to psychophysical data, we showed that interocular suppression involves an attentional modulation selective for the orientation of the competitor, and covering the spatial extent of the competitor. We conclude that both attention and divisive normalization contribute to interocular suppression, and that their impacts are distinguishable.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by National Institutes of Health - National Eye Institute (R01-EY019693; <ext-link ext-link-type="uri" xlink:href="https://www.nei.nih.gov" xlink:type="simple">https://www.nei.nih.gov</ext-link>) to DJH and MC. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="5"/>
<page-count count="26"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The perception of a brief target stimulus presented to one eye is suppressed by the simultaneous presentation of a dissimilar competitor stimulus to the other eye. This phenomenon, called interocular suppression, can be so strong that it renders the (otherwise easily visible) target invisible [<xref rid="pcbi.1004510.ref001" ref-type="bibr">1</xref>–<xref rid="pcbi.1004510.ref003" ref-type="bibr">3</xref>, reviewed in <xref rid="pcbi.1004510.ref004" ref-type="bibr">4</xref>]. It has been hypothesized that normalization [<xref rid="pcbi.1004510.ref005" ref-type="bibr">5</xref>, <xref rid="pcbi.1004510.ref006" ref-type="bibr">6</xref>] contributes to the neural processing underlying interocular suppression [<xref rid="pcbi.1004510.ref007" ref-type="bibr">7</xref>–<xref rid="pcbi.1004510.ref010" ref-type="bibr">10</xref>], in which the responses of a neuron tuned to the target are divided by the responses of a population of other neurons (the normalization pool), including those that respond to the competitor. The competitor increases the responses of the normalization pool which suppresses responses to the target, similar to scaling the contrast of the target (i.e., changing the contrast gain of neurons that respond to the target).</p>
<p>There is also evidence that interocular suppression depends on attention, along with normalization. Ling and Blake [<xref rid="pcbi.1004510.ref011" ref-type="bibr">11</xref>] measured the detectability of a small monocular target in the presence of dichoptic competitors of different sizes. They found changes in behavioral performance implying that a large competitor induced a change in the contrast gain of neurons that responded to the target, whereas a small competitor induced a response-gain change (a change of the asymptotic response). The dependence on competitor size was analogous to that observed when manipulating spatial attention [<xref rid="pcbi.1004510.ref012" ref-type="bibr">12</xref>, <xref rid="pcbi.1004510.ref013" ref-type="bibr">13</xref>]. Using an adaptation method, Ling and Blake further inferred that the response-gain modulation of the small competitor was absent when attention was withdrawn from the stimuli. Thus Ling and Blake [<xref rid="pcbi.1004510.ref011" ref-type="bibr">11</xref>] concluded that attention plays a major role in modulating competition in interocular suppression.</p>
<p>Whereas it has been proposed that attentional modulation plays a critical role in interocular suppression [<xref rid="pcbi.1004510.ref011" ref-type="bibr">11</xref>], it is unknown what type(s) of attention modulates the competition between the target and the competitor. Attention helps prioritize behaviorally relevant stimuli. In this study, we considered the role of spatial–, feature—and eye-based attention in interocular suppression. Attention can be driven by two different sources: goal driven—voluntary attention in response to task instructions that has a sustained effect (also known as endogenous attention), and stimulus-driven—involuntary attention in response to the abrupt onset of a salient stimulus (known as exogenous attention when elicited transiently by a brief stimulus). In this study, we used the terms goal driven and stimulus driven, instead of the terms endogenous and exogenous, because the stimulus was presented at fixation and its duration was not brief (1.5 s). When being deployed, attention can boost information at a given location (spatial attention [<xref rid="pcbi.1004510.ref013" ref-type="bibr">13</xref>–<xref rid="pcbi.1004510.ref018" ref-type="bibr">18</xref>]) or modulate the sensitivity of the sensory channels selective for relevant features; e.g., one of several orientations, motion directions, or colors (feature-based attention [<xref rid="pcbi.1004510.ref019" ref-type="bibr">19</xref>–<xref rid="pcbi.1004510.ref025" ref-type="bibr">25</xref>]). In addition, some studies have reported that, unbeknownst to the observer, attention can be eye specific [<xref rid="pcbi.1004510.ref026" ref-type="bibr">26</xref>,<xref rid="pcbi.1004510.ref027" ref-type="bibr">27</xref>].</p>
<p>We investigated the neural processing underlying interocular suppression using a combination of computational modeling and psychophysics. Our empirical results supported a model in which both attentional modulation and divisive normalization contributed to interocular suppression, and in which the effects of attention and normalization were clearly distinguishable from one another. Attention, in the best-fit model, was stimulus-driven, selective for both feature (orientation) and spatial location, but was not eye specific. Divisive normalization, on the other hand, can account for the change of contrast-gain modulation when the eye-of-origin of the stimuli was manipulated.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="sec003">
<title>Ethical statement</title>
<p>The experiment was conducted with the written consent of each observer and the experimental protocols were approved by the University Committee on Activities involving Human Subjects at New York University.</p>
</sec>
<sec id="sec004">
<title>Psychophysics</title>
<p>Four observers (1 female and 3 males) participated in the main psychophysics experiment. All observers had normal or corrected-to-normal vision.</p>
<p>Stimuli consisted of band-pass filtered noise patches (1–6 cpd, 10° orientation bandwidth centered at 45° tilted clockwise from vertical), with a target presented to one eye (<xref rid="pcbi.1004510.g001" ref-type="fig">Fig 1</xref>, top row) and an orthogonal competitor presented to the other eye (<xref rid="pcbi.1004510.g001" ref-type="fig">Fig 1</xref>, middle rows; small, medium, and large competitors) or split between eyes (<xref rid="pcbi.1004510.g001" ref-type="fig">Fig 1</xref>, bottom row; split competitor). We chose the parameters to match those used in the previous study by Ling and Blake [<xref rid="pcbi.1004510.ref011" ref-type="bibr">11</xref>]. Target contrast varied from trial-to-trial in a randomly shuffled order, and the competitor contrast was fixed on every trial (23% RMS contrast). The different competitor configurations were interleaved in a randomly shuffled order within each block of trials. Each observer performed at least 50 trials for each of 45 conditions (a combination of nine target contrast levels and five types of competitors). The target and the small competitor were 1.5° in diameter, and the medium and large competitors were 2.5° and 8°, respectively. The split competitor (<xref rid="pcbi.1004510.g001" ref-type="fig">Fig 1</xref>, bottom row) had the same overall size as the large competitor except that it was segmented into two regions: the center (same size as the small competitor) was presented to the competitor eye while the surround was presented to the target eye. The two subregions of the split competitor combined as a uniform large stimulus when fused. The apertures of all the stimuli were smoothed with a Gaussian. The fixation point and a black circular fusion frame (9° x 9°) were presented to both eyes throughout the experiment to stabilize the alignment of the images presented to the two eyes. Stimuli were presented on a calibrated CRT monitor (75 Hz) positioned 57 cm from the observers. Observers viewed the screen through prism glasses, and a black cardboard septum ensured that the stimuli presented on the left half of the monitor were visible only to observer’s left eye and vice versa.</p>
<fig id="pcbi.1004510.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Stimuli.</title>
<p>Band-pass filtered noise patches (1–6 cpd, 10° orientation bandwidth). Top row, a target presented to one eye. Middle rows, orthogonal competitors presented to the other eye. Bottom row, split competitor, parts of which were presented to each eye. Fixation point and black circular fusion frame were presented to both eyes throughout the experiment to stabilize the fixation and vergence so that the images presented to the two eyes would be aligned. In the main experiment, the right eye was the target eye and the left eye was the competitor eye. Two observers participated in additional experimental sessions in which the left eye was the target eye and the right eye was the competitor eye (See Psychophysics in <xref rid="sec002" ref-type="sec">Methods and Materials</xref>).</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.g001" position="float" xlink:type="simple"/>
</fig>
<p>Observers performed an orientation-discrimination task on the target (<xref rid="pcbi.1004510.g002" ref-type="fig">Fig 2</xref>). Each trial started with the target presented monocularly (to the target eye) for 2 s. The competitor was then added to the other eye, or to both eyes (for the split competitor). Typically, the competitor was dominant for a period of time following its onset [<xref rid="pcbi.1004510.ref001" ref-type="bibr">1</xref>]. One second after competitor onset, the target orientation changed either clockwise or counter clockwise (4°) for 500 ms and then both the target and the competitor disappeared from the screen. Observers reported the orientation change, clockwise or counterclockwise, by pressing one of two buttons. Psychometric functions—discriminability (<italic>d</italic>') versus target contrast—were measured for each observer and for each competitor configuration. This procedure, also known as onset flash suppression, allowed us to measure the visibility of the target when the target was suppressed and the competitor was dominant. Presenting the target and the competitor simultaneously (with simultaneous onset) and briefly, as in a masking experiment, would lead to a fused percept of the target and the competitor [<xref rid="pcbi.1004510.ref028" ref-type="bibr">28</xref>], unlike the strong competition of the two images observed in our experiment.</p>
<fig id="pcbi.1004510.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Example Trial Sequence.</title>
<p>The target was first presented alone monocularly for 2 seconds followed by an abrupt onset of the competitor in the other eye. This onset-flash suppression procedure ensured that the competitor dominated the percept for a period of time following its onset. One second after the competitor onset, the target changed its orientation (4° clockwise or counterclockwise; for illustration purposes the orientation change is more pronounced here). Observers reported the direction of the orientation change by pressing one of two buttons.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.g002" position="float" xlink:type="simple"/>
</fig>
<p>These parameters and procedures followed those in Ling and Blake’s experiments [<xref rid="pcbi.1004510.ref011" ref-type="bibr">11</xref>] except for two differences. First, we used a shorter interval (1 s) between the onset of the competitor and the orientation change of the target than the 2 s interval they used. In a pilot study, we found that the target reappeared frequently during the longer 2 s interval (unlike Ling and Blake, perhaps due to individual differences in temporal dynamics of interocular competition), which made it difficult to measure the suppression induced by the competitor. Second, we added the split competitor configuration which was critical for distinguishing between two alternative models.</p>
<p>In the main experiment, we presented the target to the observer’s right eye (the target eye) and the competitor, except the surround of the split competitor, to the observer’s left eye (the competitor eye), across all conditions. Two observers participated in additional experimental sessions in which three conditions (no competitor, large competitor and split competitor) were tested and the target eye and competitor eye were swapped: the target was presented to the left eye and the competitors (except the surround of the split competitor) were presented to the right eye. All the experimental procedures and parameters were the same as those used in the main experiment.</p>
</sec>
<sec id="sec005">
<title>Descriptive model</title>
<p>Psychometric functions were fit with Naka-Rushton functions to evaluate how different competitors influenced the visibility of the target:
<disp-formula id="pcbi.1004510.e001">
<alternatives>
<graphic id="pcbi.1004510.e001g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e001" xlink:type="simple"/>
<mml:math display="block" id="M1" overflow="scroll">
<mml:mrow><mml:mi>d</mml:mi><mml:mo>′</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mo>′</mml:mo><mml:mi>m</mml:mi></mml:msub><mml:mfrac><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mn>50</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where <italic>d</italic>'(<italic>c</italic>) was the behavioral performance as a function of target contrast, <italic>d</italic>'<sub><italic>m</italic></sub> was the asymptotic performance at the highest contrast, and <italic>c</italic><sub>50</sub> was the semi-saturation constant determining the contrast level at which <italic>d</italic>' reached half the asymptotic performance. A change in <italic>c</italic><sub>50</sub> represented a contrast-gain change, and a change in <italic>d</italic>'<sub><italic>m</italic></sub> indicated a response-gain change. The exponent <italic>n</italic> determined the slope of the function, and was constrained to have the same value for all competitor configurations. Allowing the slopes of the psychometric functions to vary across conditions yielded similar results that supported the same conclusions: the slopes were statistically indistinguishable across conditions, and the improvement of the goodness of fit was very subtle (<italic>R</italic><sup>2</sup> improved by only 1.3%, on average across observers, and had a cost of adding five free parameters).</p>
<p>The statistical significances of the changes in contrast gain (<italic>c</italic><sub>50</sub>) and response gain (<italic>d</italic>'<sub><italic>m</italic></sub>) were evaluated by a bootstrapping procedure. For each observer, we randomly resampled individual psychophysical trials with replacement to generate a bootstrapped data-set. Psychometric functions in the bootstrapped data-set were refit by Naka-Rushton functions. We then computed the differences between the group-averaged (across four observers) <italic>c</italic><sub>50</sub> and <italic>d</italic>'<sub><italic>m</italic></sub> values obtained in the different competitor conditions. This procedure was repeated 2000 times to test whether the differences in <italic>c</italic><sub>50</sub> and <italic>d</italic>'<sub><italic>m</italic></sub> values deviated significantly from zero. The statistical test and the confidence intervals of the estimated parameters for individual observers were obtained by the same procedure.</p>
</sec>
<sec id="sec006">
<title>Full model</title>
<p>We developed models to simulate the responses of a population of neurons to the stimuli used in the behavioral experiments (Matlab code is available on our website: <ext-link ext-link-type="uri" xlink:href="http://www.cns.nyu.edu/heegerlab/" xlink:type="simple">http://www.cns.nyu.edu/heegerlab/</ext-link>). Each model had two neural populations: one preferred the stimuli presented in the left eye and the other preferred the stimuli in the right eye (<xref rid="pcbi.1004510.g003" ref-type="fig">Fig 3</xref> and <xref rid="pcbi.1004510.t001" ref-type="table">Table 1</xref>). For each of the neural populations, we simulated a 2-dimensional array of neurons, with orientation preferences uniformly sampling orientations in steps of 1° and receptive field centers ranging from -20° to 20°. The responses of the neurons (<italic>R</italic>) were determined by three components: the excitatory drive (<italic>E</italic>), the suppressive drive (<italic>S</italic>) and the attentional gain factors (<italic>A</italic>) [<xref rid="pcbi.1004510.ref012" ref-type="bibr">12</xref>]. Responses of the left-eye monocular neurons were computed by the following equation (the details of each component in the equation are listed in <xref rid="pcbi.1004510.t001" ref-type="table">Table 1</xref>):
<disp-formula id="pcbi.1004510.e002">
<alternatives>
<graphic id="pcbi.1004510.e002g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e002" xlink:type="simple"/>
<mml:math display="block" id="M2" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:msub><mml:mi>S</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
where <italic>x</italic> and <italic>θ</italic> represented the receptive field centers and preferred orientations of the neurons in the population, <italic>n</italic> was the exponent that controlled the slope of the neural contrast-response functions, <italic>w</italic><sub><italic>I</italic></sub> was the interocular normalization weight, and <italic>σ</italic> was a constant that determined the semi-saturation contrast. The value of <italic>w</italic><sub><italic>I</italic></sub> determined the contribution of inputs from the other eye to the normalization pool. The value of <italic>σ</italic> determined the contrast at which the neural responses saturated. The current model and parameterization only generated neural responses in positive numbers. We did not implement rectification or thresholding in <xref rid="pcbi.1004510.e002" ref-type="disp-formula">Eq 2</xref> because we did not simulate the effect of spiking threshold or neural responses below the baseline (zero in our case).</p>
<fig id="pcbi.1004510.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Model.</title>
<p><bold>A</bold>. The model simulates the firing rates of two populations of monocular neurons, responsive to stimuli presented to each of the two eyes, with a range of receptive field locations and orientation preferences. Depicted is an example of the feature-specific (FS) model, in which the two monocular neural populations share the same attentional gain factors, and stimulus-driven attention is selective for the orientation and size of the competitor. Bottom row, example stimuli. Target presented to right eye and large competitor presented to the left eye. Second row (from the bottom), excitatory drive. Simulated neurons are arranged in each panel according to their receptive field center (horizontal position) and preferred orientation (vertical position). Brightness at each location in the image corresponds to the excitatory drive to a single neuron. Third row, attentional gain factors. The attentional gains determine the strength of the attentional modulation as a function of receptive field center and orientation preference. Mid-gray indicates a value of 1, white indicates a value larger than 1 (attentional enhancement), and black indicates a value smaller than 1 (attentional suppression). Fourth row, suppressive drive computed from the product of the excitatory drive and the attention gain factors, and then pooled over space and orientation (see panel B), and across the two eyes (light gray arrows). Top row, output firing rates. The excitatory drive is multiplied by the attention gain factors and divided by the suppressive drive. <bold>B</bold>. The suppression kernel. The suppressive drive is pooled over space and orientation by convolving the attention-modulated excitatory drive with the suppression kernel.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.g003" position="float" xlink:type="simple"/>
</fig>
<table-wrap id="pcbi.1004510.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.t001</object-id>
<label>Table 1</label> <caption><title>Equations and parameter values for each of the components of the two models.</title></caption>
<alternatives>
<graphic id="pcbi.1004510.t001g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.t001" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Model component</th>
<th align="left" rowspan="1" colspan="1">Equation</th>
<th align="left" rowspan="1" colspan="1">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Suppressive drive</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004510.e003"><alternatives><graphic id="pcbi.1004510.e003g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e003" xlink:type="simple"/><mml:math display="inline" id="M3" overflow="scroll"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:msubsup><mml:mi>E</mml:mi><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula></td>
<td align="left" rowspan="1" colspan="1">* denotes convolution. <italic>K</italic><sub><italic>s</italic></sub> is the suppression kernel. The attention gain factors, <italic>A</italic><sub><italic>x</italic></sub> and <italic>A</italic><sub><italic>v</italic></sub>, and the excitatory drive <inline-formula id="pcbi.1004510.e004"><alternatives><graphic id="pcbi.1004510.e004g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e004" xlink:type="simple"/><mml:math display="inline" id="M4" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> were point-by-point multiplied.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Suppression kernel</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004510.e005"><alternatives><graphic id="pcbi.1004510.e005g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e005" xlink:type="simple"/><mml:math display="inline" id="M5" overflow="scroll"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>σ</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula><break/><inline-formula id="pcbi.1004510.e006"><alternatives><graphic id="pcbi.1004510.e006g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e006" xlink:type="simple"/><mml:math display="inline" id="M6" overflow="scroll"><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><italic>σ</italic><sub>sx</sub> = 6°: width of the spatial suppressive field for iso-orientation stimuli.<break/><italic>τ</italic> = 20°: orientation selectivity of surround suppression. Suppression was broadly tuned (all orientations) for stimuli within a neuron’s receptive field while surround suppression was narrowly tuned to the neuron’s preferred orientation. See <xref rid="pcbi.1004510.g001" ref-type="fig">Fig 1B</xref>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Stimulus-driven attentional gain factors</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004510.e007"><alternatives><graphic id="pcbi.1004510.e007g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e007" xlink:type="simple"/><mml:math display="inline" id="M7" overflow="scroll"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:msubsup><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><italic>w</italic><sub><italic>x</italic></sub>: free parameter that determined the strength of stimulus-driven attentional modulation.<break/>a<sub><italic>θ</italic></sub> and a<sub><italic>x</italic></sub>: vectors representing the extent of feature-based and spatial attention. The attentional gain factors had a baseline of 1. Values larger/smaller than 1 indicated increases/decreases in gain.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Goal-driven attentional gain factors</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004510.e008"><alternatives><graphic id="pcbi.1004510.e008g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e008" xlink:type="simple"/><mml:math display="inline" id="M8" overflow="scroll"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:msubsup><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><italic>w</italic><sub><italic>v</italic></sub>: free parameter that determined the strength of goal-driven attentional modulation.<break/>Both <italic>A</italic><sub><italic>x</italic></sub> and <italic>A</italic><sub><italic>v</italic></sub> involved computation of a<sub><italic>θ</italic></sub> and a<sub><italic>x</italic></sub> but the attended orientation and attended position were different for stimulus-driven and goal-driven attention (see Feature-based attention and Spatial attention below).</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Feature-based attention</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004510.e009"><alternatives><graphic id="pcbi.1004510.e009g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e009" xlink:type="simple"/><mml:math display="inline" id="M9" overflow="scroll"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>{</mml:mo><mml:mtext>cos</mml:mtext><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
<td align="left" rowspan="1" colspan="1">A circular Gaussian (von Mises) profile scaled to range from -0.5 and 0.5.<break/><italic>θ</italic><sub><italic>a</italic></sub>: attended orientation.<break/><italic>k</italic>: extent of feature-based attention. We used <italic>k = 3</italic>, which resulted in a 40° bandwidth (FWHM), similar to that used in previous simulations [<xref rid="pcbi.1004510.ref037" ref-type="bibr">37</xref>].<break/>For stimulus-driven attention, <italic>θ</italic><sub><italic>a</italic></sub> was the orientation of the competitor in the FS model while <italic>a</italic><sub><italic>θ</italic></sub> was uniform (= 1) in the ES model.<break/>For goal-driven attention, <italic>θ</italic><sub><italic>a</italic></sub> was the orientation of the target in both FS and ES models.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Spatial attention</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004510.e010"><alternatives><graphic id="pcbi.1004510.e010g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e010" xlink:type="simple"/><mml:math display="inline" id="M10" overflow="scroll"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><italic>p</italic>: tradeoff between the spatial extent and the magnitude of attentional modulation. If <italic>p</italic> = 1, spatial attention had a fixed volume, decreasing in magnitude when its spatial extent increased. If <italic>p</italic> = 0, the spatial extent was independent of the magnitude of the attentional gain at the attended position <italic>x</italic><sub><italic>a</italic></sub>.<break/><italic>σ</italic><sub><italic>ax</italic></sub>: spatial extent of spatial attention.<break/>For goal-driven attention, these parameters were fixed: <italic>σ</italic><sub><italic>ax</italic></sub> = 60° and <italic>p</italic> = 0.<break/>For stimulus-driven attention, <italic>p</italic> was a free parameter and <italic>σ</italic><sub><italic>ax</italic></sub> was equal to the size of the competitor.</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>The excitatory drive was determined by each neuron’s receptive field center and preferred orientation. The spatial excitatory field of each simulated neuron was a Gaussian with 1.5° standard deviation and the orientation tuning was a Gaussian with 48° FWHM (full width at half maximum), approximating the values reported for macaque primary visual cortex [<xref rid="pcbi.1004510.ref029" ref-type="bibr">29</xref>]. The suppressive drive was computed by pooling the excitatory drives of neurons with a range of receptive field centers and orientation preferences (See suppressive drive and suppression kernel in <xref rid="pcbi.1004510.t001" ref-type="table">Table 1</xref> and <xref rid="pcbi.1004510.g001" ref-type="fig">Fig 1</xref>). Suppression was broadly tuned (all orientations) for stimuli within a neuron’s receptive field whereas surround suppression was narrowly tuned to the neuron’s preferred orientation, mimicking electrophysiological findings [<xref rid="pcbi.1004510.ref030" ref-type="bibr">30</xref>,<xref rid="pcbi.1004510.ref031" ref-type="bibr">31</xref>]. To compute the neural responses, the excitatory drive of each neuron was multiplied by its attentional gain factor [<xref rid="pcbi.1004510.ref012" ref-type="bibr">12</xref>] and then divided by its suppressive drive [<xref rid="pcbi.1004510.ref005" ref-type="bibr">5</xref>,<xref rid="pcbi.1004510.ref006" ref-type="bibr">6</xref>,<xref rid="pcbi.1004510.ref012" ref-type="bibr">12</xref>,<xref rid="pcbi.1004510.ref032" ref-type="bibr">32</xref>]. Each neuron in the population had its own attentional gain factor that depended on the attentional state (i.e., the attended spatial position and the attended orientation) in particular experimental conditions. Two sources of attentional modulation were considered: <italic>A</italic><sub><italic>x</italic></sub> was the stimulus-driven attentional modulation induced by the competitor and <italic>A</italic><sub><italic>v</italic></sub> was the goal-driven attentional modulation induced by the demands of the orientation-discrimination task.</p>
<p>According to the model, both attention and normalization contributed to interocular suppression. First, the presence of the competitor induced stimulus-driven attentional modulation increasing the attentional gains of neurons tuned to the competitor and reducing the gains of neurons tuned to the target. Following Ling and Blake [<xref rid="pcbi.1004510.ref011" ref-type="bibr">11</xref>], this attentional modulation was responsible for the shift from a response-gain change to a contrast-gain change with increasing competitor size. Second, the competitor contributed directly to the normalization pool, weighted by the interocular normalization weight (<italic>w</italic><sub><italic>I</italic></sub> in <xref rid="pcbi.1004510.e002" ref-type="disp-formula">Eq 2</xref>). This interocular normalization caused contrast-gain changes for all competitors, regardless of their size.</p>
<sec id="sec007">
<title>Stimulus-driven attentional modulation</title>
<p>We considered two possible ways to model the stimulus-driven attention induced by the competitor. Interocular divisive normalization was implemented in the same way in both models.</p>
<p>In the feature-specific model (FS model), the attentional gains were larger for neurons tuned to the orientation of the competitor and smaller for neurons tuned to other orientations (<xref rid="pcbi.1004510.g004" ref-type="fig">Fig 4C</xref>). The attentional gains had a spatial extent (<italic>σ</italic><sub><italic>αx</italic></sub> in <xref rid="pcbi.1004510.t001" ref-type="table">Table 1</xref>) matching that of the competitor. The same attentional gain factors were applied to the right-eye and the left-eye neural populations.</p>
<fig id="pcbi.1004510.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Model fits for data from Ling and Blake (2012).</title>
<p><bold>A and B</bold>. FS and ES model fits. Filled dots, psychophysical performance averaged across observers. Curves, best fits by each of the two models (parameter values reported in <xref rid="pcbi.1004510.t002" ref-type="table">Table 2</xref>). <bold>C and D</bold>. The competitor-driven attentional gain factors estimated by the FS and ES models. <bold>E and F</bold>. The task-driven attentional gain factors estimated by the two models.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.g004" position="float" xlink:type="simple"/>
</fig>
<p>In the eye-specific model (ES model), the attentional gains were larger for monocular neurons corresponding to the eye to which the competitor was presented, and smaller for neurons driven by the target eye (<xref rid="pcbi.1004510.g004" ref-type="fig">Fig 4D</xref>). The spatial extent of the attentional modulation was determined by the size of the competitor (as in the FS model), but there was no feature-based modulation in this model. For a given spatial location, the gain was increased by a multiplicative factor in one eye and reduced by the same multiplicative factor in the other eye.</p>
<p>Although the ES model may seem less plausible <italic>a priori</italic>, there is evidence for eye-specific attentional modulation. When non-perceptual artifacts are controlled, observers have no access to information about the eye-of-origin of a stimulus [<xref rid="pcbi.1004510.ref033" ref-type="bibr">33</xref>]. A few studies, however, have reported that eye-of-origin might impact attention unbeknownst to the observers. For example, visual search has been reported to be more efficient when the target and distractors were presented to different eyes [<xref rid="pcbi.1004510.ref027" ref-type="bibr">27</xref>]. It has also been reported that a monocular target under continuous flash suppression was more likely to become visible when observers simultaneously tracked a monocular stimulus presented to the target eye compared to when they tracked a stimulus presented to the other eye [<xref rid="pcbi.1004510.ref026" ref-type="bibr">26</xref>].</p>
<p>For both FS and ES model, a free parameter <italic>p</italic> controlled the trade-off between the spatial extent and the magnitude of the stimulus-driven attentional gain factors (see Spatial attention in <xref rid="pcbi.1004510.t001" ref-type="table">Table 1</xref>). We also tested a compound model by fitting it to our data. In this model, the stimulus-driven attention had both feature-specific and eye-specific components (Supporting Information, <xref rid="pcbi.1004510.s001" ref-type="supplementary-material">S1 Text</xref>).</p>
</sec>
<sec id="sec008">
<title>Goal-driven attentional modulation</title>
<p>In addition to the stimulus-driven attentional modulation induced by the competitor, both the FS and ES models included goal-driven attentional modulation induced by the task demands. Specifically, the attentional gains were larger for neurons tuned to the orientation of the target and the gains were smaller for neurons tuned to the orientation of the competitor (<xref rid="pcbi.1004510.g004" ref-type="fig">Fig 4E and 4F</xref>). This goal-driven feature-based attention was included in the models because it has been reported that observers deploy attention to orientation channels tuned to (or neighboring) the target orientation when performing a fine-grain orientation-discrimination task and when detecting a target superimposed with a high-contrast mask [<xref rid="pcbi.1004510.ref034" ref-type="bibr">34</xref>–<xref rid="pcbi.1004510.ref037" ref-type="bibr">37</xref>]. The spatial extent of the goal-driven attentional gain factors was assumed to be very wide in both models because both neuroimaging [<xref rid="pcbi.1004510.ref038" ref-type="bibr">38</xref>,<xref rid="pcbi.1004510.ref039" ref-type="bibr">39</xref>] and psychophysical [<xref rid="pcbi.1004510.ref040" ref-type="bibr">40</xref>,<xref rid="pcbi.1004510.ref041" ref-type="bibr">41</xref>] findings suggest that task-driven, feature-based attention spreads across space, influencing the neural responses or behavioral performance corresponding to uncued locations.</p>
</sec>
</sec>
<sec id="sec009">
<title>Full model statistics</title>
<p>To fit the simulated neural responses to the psychophysics data, performance accuracy, <italic>d</italic>', was assumed to be proportional to the response of the neuron that was most responsive to the target (eye-of origin, orientation preference, and RF center). That is, we assumed additive, independent, and identically distributed (IID) noise [<xref rid="pcbi.1004510.ref042" ref-type="bibr">42</xref>]. We used a free parameter <italic>σ</italic><sub><italic>n</italic></sub>, representing the magnitude of the noise, to relate behavioral performance (<italic>d</italic>') to the underlying neural responses. A change in response gain of the underlying neuronal responses thereby yielded a proportional scaling of the psychometric function and a change in contrast gain of the underlying neuronal responses yielded a proportional horizontal shift (on the log contrast axis) of the psychometric function. This interpretation of our behavioral results depended on the assumption of additive IID noise. However, given that the neurons homogeneously represent the sensory parameters and the tuning curve is invariant to contrast, an alternative model with Poisson noise and a maximum-likelihood decision rule would yield the same results; the performance (<italic>d</italic>') of an orientation decoder is proportional to the mean firing rate of the neuron within the neural population that is tuned for the mean stimulus orientation [<xref rid="pcbi.1004510.ref043" ref-type="bibr">43</xref>,<xref rid="pcbi.1004510.ref044" ref-type="bibr">44</xref>].</p>
<p>For both the FS and ES models, there were seven free parameters (See <xref rid="pcbi.1004510.t002" ref-type="table">Table 2</xref>), and the MATLAB fmincon function was used to search for the best (least-squares) fit. All seven free parameters were fitted across all the conditions. The values of <italic>w</italic><sub><italic>x</italic></sub>, <italic>w</italic><sub><italic>v</italic></sub> and <italic>p</italic> were constrained so that the attentional gain factors (<italic>A</italic><sub><italic>x</italic></sub> and <italic>A</italic><sub><italic>v</italic></sub>) were non-negative. The only parameter that changed with different conditions was <italic>σ</italic><sub><italic>αx</italic></sub>, which controlled the spatial extent of spatial attention (see <xref rid="pcbi.1004510.t001" ref-type="table">Table 1</xref>). Both FS and ES models assumed that the spatial spread of stimulus-driven attention was determined by the competitor size so we set <italic>σ</italic><sub><italic>αx</italic></sub> to be the same as the width of the competitor (i.e., <italic>σ</italic><sub><italic>αx</italic></sub> was not a free parameter in the model fit). Confidence intervals for each of the free parameters were estimated by a bootstrapping procedure. Specifically, we randomly resampled individual psychophysical trials with replacement to generate a resampled data-set, which was refit with each of the models, and this procedure of resampling and refitting was repeated 2000 times to generate bootstrap distributions of the best-fit parameter values.</p>
<table-wrap id="pcbi.1004510.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.t002</object-id>
<label>Table 2</label> <caption><title>Best-fit parameter values for data from Ling and Blake (2012).</title></caption>
<alternatives>
<graphic id="pcbi.1004510.t002g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.t002" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Parameter</th>
<th align="left" rowspan="1" colspan="1">FS model</th>
<th align="left" rowspan="1" colspan="1">ES model</th>
<th align="left" rowspan="1" colspan="1">Description</th>
</tr>
<tr>
<th align="left" rowspan="1" colspan="1"/>
<th align="left" rowspan="1" colspan="1">best-fit value [68% confidence interval]</th>
<th align="left" rowspan="1" colspan="1">best-fit value [68% confidence interval]</th>
<th align="left" rowspan="1" colspan="1"/>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>n</italic></td>
<td align="left" rowspan="1" colspan="1">2.16<break/>[1.96 2.31]</td>
<td align="left" rowspan="1" colspan="1">2.01<break/>[1.94 2.30]</td>
<td align="left" rowspan="1" colspan="1">Exponent of the neural contrast response function</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>σ</italic></td>
<td align="left" rowspan="1" colspan="1">0.0020<break/>[0.0019 0.004]</td>
<td align="left" rowspan="1" colspan="1">0.0019<break/>[0.0018 0.004]</td>
<td align="left" rowspan="1" colspan="1">Constant term of the suppressive drive</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w</italic><sub><italic>I</italic></sub></td>
<td align="left" rowspan="1" colspan="1">0.80<break/>[0.18 0.94]</td>
<td align="left" rowspan="1" colspan="1">0.80<break/>[0.06 0.94]</td>
<td align="left" rowspan="1" colspan="1">Interocular normalization weight</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w</italic><sub><italic>x</italic></sub></td>
<td align="left" rowspan="1" colspan="1">4.70<break/>[4.69 4.95]<break/>(1.00, 0.13, 0.20, 0.35)</td>
<td align="left" rowspan="1" colspan="1">2.41<break/>[2.34 2.49]<break/>(1.00, 0.15, 0.28, 0.50)</td>
<td align="left" rowspan="1" colspan="1">Magnitude of stimulus-driven attentional modulation</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w</italic><sub><italic>v</italic></sub></td>
<td align="left" rowspan="1" colspan="1">5.03<break/>[4.95 5.02]<break/>(2.00)</td>
<td align="left" rowspan="1" colspan="1">4.99<break/>[4.90 5.00]<break/>(2.00)</td>
<td align="left" rowspan="1" colspan="1">Magnitude of goal-driven attentional modulation</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>p</italic></td>
<td align="left" rowspan="1" colspan="1">0.17<break/>[0.16 0.35]</td>
<td align="left" rowspan="1" colspan="1">0.31<break/>[0.18 0.41]</td>
<td align="left" rowspan="1" colspan="1">Trade-off between the magnitude and the spatial extent of the attentional gains</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>σ</italic><sub><italic>n</italic></sub></td>
<td align="left" rowspan="1" colspan="1">3.11<break/>[2.62 3.08]<break/></td>
<td align="left" rowspan="1" colspan="1">2.95<break/>[2.61 3.07]<break/></td>
<td align="left" rowspan="1" colspan="1">Magnitude of the noise<break/></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>R</italic><sup>2</sup></td>
<td align="left" rowspan="1" colspan="1">96.6%</td>
<td align="left" rowspan="1" colspan="1">95.9%</td>
<td align="left" rowspan="1" colspan="1"/>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>For each parameter, we report the best-fit value and the 68% confidence interval obtained by a bootstrapping procedure. The value of <italic>σ</italic> is reported in units of excitatory drive (see <xref rid="pcbi.1004510.e002" ref-type="disp-formula">Eq 2</xref>). In the row of <italic>w</italic><sub><italic>x</italic></sub>, we also report the stimulus-driven attentional gain factor of the neuron tuned to the target in the no-, small-, medium- and large-competitor conditions (corresponding to the four values in the parenthesis respectively). In the row of <italic>w</italic><sub><italic>v</italic></sub>, the goal-driven attentional gain factor of the neuron tuned to the target is reported too. Its value is the same across conditions because the spatial spread of goal-driven attention was constant across competitors (see details in <xref rid="pcbi.1004510.t001" ref-type="table">Table 1</xref>).</p></fn>
</table-wrap-foot>
</table-wrap>
<p>We used cross-validation for model comparison. The raw data (a list of trials from each individual observer) were permuted and partitioned into a training set and test set, and the group-averaged psychometric functions were then computed for both the training set and the test set. Each model was fit to the training set to determine the best-fit parameters. These parameter values were then compared with the test set, i.e., by computing the coefficient of determination (<italic>R</italic><sup>2</sup>) which represented the goodness-of-fit of each model to the test set. The coefficient of determination was computed for the FS model (<inline-formula id="pcbi.1004510.e011"><alternatives><graphic id="pcbi.1004510.e011g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e011" xlink:type="simple"/><mml:math display="inline" id="M11" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>) and for the ES model (<inline-formula id="pcbi.1004510.e012"><alternatives><graphic id="pcbi.1004510.e012g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e012" xlink:type="simple"/><mml:math display="inline" id="M12" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>), and the difference between the two values (<inline-formula id="pcbi.1004510.e013"><alternatives><graphic id="pcbi.1004510.e013g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e013" xlink:type="simple"/><mml:math display="inline" id="M13" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>) was taken as an index for model comparison. This procedure was repeated 2000 times to obtain a distribution of <inline-formula id="pcbi.1004510.e014"><alternatives><graphic id="pcbi.1004510.e014g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.e014" xlink:type="simple"/><mml:math display="inline" id="M14" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> values. The FS model was considered to outperform ES model if this distribution was significantly (95% of the distribution) larger than zero, and the ES model was considered as the better model if the distribution was significantly smaller than zero. The model fit and the model comparison were performed on the group averaged data consisting of 11079 trials pooled across observers and conditions. In a complementary analysis, we also used maximum-likelihood estimation and Bayesian information criterion to compare the models (Supporting Information, <xref rid="pcbi.1004510.s002" ref-type="supplementary-material">S2 Text</xref>).</p>
<p>To assess whether there was parameter redundancy, we numerically computed the Hessian matrix (i.e., the second derivatives with respect to the model parameters) of the best-fit model, and used singular value decomposition to compute the rank of the matrix. A full-rank Hessian matrix indicated that the parameters in the model were not redundant [<xref rid="pcbi.1004510.ref045" ref-type="bibr">45</xref>].</p>
</sec>
</sec>
<sec id="sec010" sec-type="results">
<title>Results</title>
<sec id="sec011">
<title>Both models fit Ling and Blake (2012)</title>
<p>To investigate the role of attention and normalization in interocular suppression, we developed computational models to simulate the responses of a population of neurons, and fit the models to published psychophysical measurements [<xref rid="pcbi.1004510.ref011" ref-type="bibr">11</xref>]. Ling and Blake [<xref rid="pcbi.1004510.ref011" ref-type="bibr">11</xref>] reported changes in behavioral performance implying that a large competitor induced a change in the contrast gain of neurons that responded to the target, whereas a small competitor induced a response-gain change. Two models were considered as candidates. In the feature-specific (FS) model, the onset of the competitor induced stimulus-driven attentional modulation that increased the gain of neurons that preferred the competitor orientation, and reduced the gain of neurons that responded preferentially to the target orientation. In the eye-specific (ES) model, stimulus-driven attentional modulation increased the gain of neurons that responded preferentially to inputs from the eye to which the competitor was presented, and reduced the gain of neurons that responded to the target eye. In both models, the stimulus-driven attentional modulation was complemented by goal-driven attentional modulation that increased the gain of neurons that preferred the target orientation, and reduced the gain of neurons that preferred the competitor orientation. This goal-driven attention component was task-specific, enabling the simulated observer to discriminate the target orientation more accurately. Divisive normalization also contributed to interocular suppression in both models.</p>
<p>Both models were able to explain the suppression induced by the competitor in Ling and Blake’s data (<xref rid="pcbi.1004510.g004" ref-type="fig">Fig 4</xref>). The models were fit to the data to determine best-fit values for the model parameters including the magnitudes of the stimulus-driven and goal-driven attentional modulations, and the interocular normalization weight (<xref rid="pcbi.1004510.t002" ref-type="table">Table 2</xref>). There was no evidence for a difference between the goodness of fit of the two models (p = 0.45; see <xref rid="sec002" ref-type="sec">Materials and Methods</xref>, Full model statistics).</p>
<p>According to both models, behavioral performance depended on competitor size because the onset of the competitor induced stimulus-driven attentional modulation with a spatial extent determined by competitor size (<xref rid="pcbi.1004510.g004" ref-type="fig">Fig 4C and 4D</xref>). The parameter <italic>p</italic> (<xref rid="pcbi.1004510.t002" ref-type="table">Table 2</xref>) represented the tradeoff between the magnitude and spatial extent of the stimulus-driven attentional gain factors. A value of <italic>p</italic> close to 1 would have indicated that the sum of the attentional gain factors was constant when size varied, i.e., a complete trade-off between size and magnitude. The best-fit values were 0.17 and 0.31 for the FS and ES models, respectively, indicating a partial trade-off between size and magnitude. Due to this tradeoff, in addition to the spatial extent of attention, the values of the (stimulus-driven) attentional gain factors also changed with the size of the competitor (see the values reported in the parenthesis under <italic>w</italic><sub><italic>x</italic></sub> in <xref rid="pcbi.1004510.t002" ref-type="table">Table 2</xref>). The model fit also showed a significant role of goal-driven attention (<italic>w</italic><sub><italic>v</italic></sub> in <xref rid="pcbi.1004510.t002" ref-type="table">Table 2</xref>) which increased the gain of neurons tuned to the target orientation and reduced the gain of neurons tuned to the competitor orientation (<xref rid="pcbi.1004510.g004" ref-type="fig">Fig 4E and 4F</xref>).</p>
<p>The interocular normalization weight <italic>w</italic><sub><italic>I</italic></sub> was around 0.8 for both FS and ES models (<xref rid="pcbi.1004510.t002" ref-type="table">Table 2</xref>), implying nearly equal divisive normalization from stimuli presented to either eye. However, the confidence interval for this parameter value covered a wide range from 0 to 1. There was no evidence of parameter redundancy in the model fits because the Hessian matrices were full rank (see Full model statistics in <xref rid="sec002" ref-type="sec">Materials and Methods</xref>). However, the interpretation of interocular normalization weights could be difficult because the eye-of-origin of the competitor was not manipulated in Ling and Blake’s experiment, and the magnitude of the interocular divisive normalization did not solely depend on this parameter but also on the goal-driven attentional modulation which could reduce the gain of the responses evoked by the competitor. The role of interocular divisive normalization and how it influenced the predicted psychometric functions became clearer when the eye-of-origin of the competitor was manipulated in our psychophysics experiment.</p>
</sec>
<sec id="sec012">
<title>Distinguishing between the two models with the split competitor</title>
<p>To distinguish the FS model and the ES model, we replicated Ling and Blake’s (2012) psychophysics experiment and added a critical new condition with a split competitor. The split competitor (<xref rid="pcbi.1004510.g001" ref-type="fig">Fig 1</xref>, bottom row) had the same overall size as the large competitor except that it was segmented into two regions: the center (same size as the small competitor) was presented to the competitor eye whereas the surround was presented to the target eye. The two subregions of the split competitor were perceived as a single large grating when fused. The FS model predicted that the split competitor would cause a contrast-gain change like the large competitor; according to this model, the split competitor induced the same attentional modulation as that driven by the large competitor because the attentional gain factors were blind to the eye-of-origin of the stimuli. The ES model predicted that the split competitor would cause a response-gain change like the small and medium competitors; according to this model, the split competitor induced less attention in the center region of the target eye (because the center of the competitor was presented to the other eye) and more attention in the surround region of the target eye (because the surround of the competitor was presented to the target eye). In addition, we predicted that the split competitor condition would constrain the best-fit value of the interocular normalization weight <italic>w</italic><sub><italic>I</italic></sub> because the large competitor and the split competitor had the same overall size but differed in presentation to the two eyes.</p>
<sec id="sec013">
<title>Descriptive model</title>
<p>The split competitor shifted the psychometric function commensurate with a contrast-gain change, like the large competitor (<xref rid="pcbi.1004510.g005" ref-type="fig">Fig 5</xref>). A descriptive fit to the data confirmed that the split competitor changed the contrast-gain parameter <italic>c</italic><sub>50</sub> (<italic>p</italic>&lt;0.001, bootstrap test; see <xref rid="sec002" ref-type="sec">Materials and Methods</xref>, Descriptive model statistics) without reliably changing asymptotic performance <italic>d</italic>'<sub><italic>m</italic></sub> (<italic>p</italic> = 0.214). These results were consistent across observers (change in <italic>d</italic>'<sub><italic>m</italic></sub>: <italic>p</italic>&gt;0.1 for all observers; change in <italic>c</italic><sub>50</sub>: <italic>p</italic>&lt;0.05 for S1,S2 and S4; <italic>p</italic> = 0.07 for S3; bootstrap tests). For the other conditions, our results were consistent with those reported by Ling and Blake (2012): the small and medium competitors induced response-gain changes (both <italic>p</italic>&lt;0.001), and the large competitor induced a contrast-gain change (<italic>p</italic>&lt;0.001) without reliably changing asymptotic performance (<italic>p</italic> = 0.112).</p>
<fig id="pcbi.1004510.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Descriptive model fits.</title>
<p><bold>A</bold>. Psychometric functions for each individual observer. Filled dots, psychophysical performance. Curves, best fit Naka-Rushton functions. <bold>B</bold>. Best-fit <italic>c</italic><sub>50</sub> and <italic>d</italic>'<sub><italic>m</italic></sub> parameter values for each individual observer. Error bars, bootstrapped 95% confidence intervals.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.g005" position="float" xlink:type="simple"/>
</fig>
<p>The split competitor and large competitor masked the target by comparable amounts, on average. The best-fit values for the contrast-gain change parameter <italic>c</italic><sub>50</sub> were statistically indistinguishable between these two conditions (<italic>p</italic> = 0.271). There were, however, notable individual differences in the best-fit values for <italic>c</italic><sub>50</sub>. For observer S4, the shift in <italic>c</italic><sub>50</sub> was larger for the large competitor than the split competitor (<italic>p</italic>&lt;0.01, bootstrap test). Observer S1 showed the opposite: larger <italic>c</italic><sub>50</sub> shift for the split-competitor (<italic>p</italic>&lt;0.05, bootstrap test). For the other two observers, there was no evidence for a difference.</p>
</sec>
<sec id="sec014">
<title>Full model</title>
<p>The FS model outperformed the ES model (<xref rid="pcbi.1004510.g006" ref-type="fig">Fig 6</xref>). Both models captured the contrast-gain change for the large competitor and the response-gain change for the small competitor. However, the ES model underestimated performance for the split competitor and over-estimated performance for the medium competitor. Statistical comparison between the model fits was done with cross validation, randomly resampling from the data 2000 times (see <xref rid="sec002" ref-type="sec">Materials and Methods</xref>, Full model statistics). The FS model provided a consistently better fit than the ES model (P&lt;0.0005; see <xref rid="sec002" ref-type="sec">Materials and Methods</xref>, Full model statistics). Indeed, for all 2000 re-sampled datasets, the <italic>R</italic><sup>2</sup> values obtained with the FS model were larger than those obtained with the ES model. When we applied maximum likelihood estimation and used Bayesian information criterion as the index for model comparison, we again found that the FS model was superior to the ES model (Supporting Information, <xref rid="pcbi.1004510.s002" ref-type="supplementary-material">S2 Text</xref>).</p>
<fig id="pcbi.1004510.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Full model fits.</title>
<p><bold>A</bold> and <bold>B</bold>. FS and ES model fits. Filled dots, psychophysical performance averaged across observers. Error bars represents ±1 SEM. Curves are the best-fit <italic>d</italic>'(<italic>c</italic>) by each of the two models (parameter values reported in <xref rid="pcbi.1004510.t003" ref-type="table">Table 3</xref>). <bold>C and D</bold>. Stimulus-driven attentional gain factors for the split-competitor condition, estimated by each of the two models. The stimulus-driven attentional gain factors for the other conditions and the goal-driven attentional gain factors are similar to those reported in <xref rid="pcbi.1004510.g004" ref-type="fig">Fig 4</xref>.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.g006" position="float" xlink:type="simple"/>
</fig>
<p>We also considered a compound model in which stimulus-driven attention had both feature-specific and eye-specific components. We did not find notable improvement by including both components in the model. In the best-fit parameters, the magnitude of the eye-specific attentional modulation was reduced to a value close to zero (Supporting Information, <xref rid="pcbi.1004510.s001" ref-type="supplementary-material">S1 Text</xref>).</p>
<p>The best-fit parameter values for the new data set were generally compatible with those for the Ling and Blake (2012) data set (compare Tables <xref rid="pcbi.1004510.t002" ref-type="table">2</xref> and <xref rid="pcbi.1004510.t003" ref-type="table">3</xref>). One exception was that the trade-off parameter <italic>p</italic> for the ES model had a larger value for our data (0.707, 68% CI: [0.704 0.856]) than for Ling and Blake’s data (0.312, 95% CI: [0.175 0.412]). When <italic>p</italic> was fixed at the best-fit values for Ling and Blake’s data (<xref rid="pcbi.1004510.t002" ref-type="table">Table 2</xref>), the ES model provided an even worse fit to the split competitor condition, because it predicted an even larger response-gain change, similar to that observed for the small competitor. The best-fit values of <italic>p</italic> for the FS model were indistinguishable between the two data sets. As expected, when the split competitor was included, the data constrained the estimated <italic>w</italic><sub><italic>I</italic></sub> to have a narrower range (CI of <italic>w</italic><sub><italic>I</italic></sub> in FS model: [0.460 1.043], <xref rid="pcbi.1004510.t003" ref-type="table">Table 3</xref>) compared to the previous model fit (CI of <italic>w</italic><sub><italic>I</italic></sub> in FS model: [0.175 0.940], <xref rid="pcbi.1004510.t002" ref-type="table">Table 2</xref>).</p>
<table-wrap id="pcbi.1004510.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.t003</object-id>
<label>Table 3</label> <caption><title>Best-fit parameter values for group-averaged data.</title></caption>
<alternatives>
<graphic id="pcbi.1004510.t003g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.t003" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Parameter</th>
<th align="left" rowspan="1" colspan="1">FS model</th>
<th align="left" rowspan="1" colspan="1">ES model</th>
<th align="left" rowspan="1" colspan="1">Description</th>
</tr>
<tr>
<th align="left" rowspan="1" colspan="1"/>
<th align="left" rowspan="1" colspan="1">best-fit value [68% confidence interval]</th>
<th align="left" rowspan="1" colspan="1">best-fit value [68% confidence interval]</th>
<th align="left" rowspan="1" colspan="1"/>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>n</italic></td>
<td align="left" rowspan="1" colspan="1">1.95<break/>[1.84 2.08]</td>
<td align="left" rowspan="1" colspan="1">1.85<break/>[1.72 1.95]</td>
<td align="left" rowspan="1" colspan="1">Exponent of the neural contrast response function</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>σ</italic></td>
<td align="left" rowspan="1" colspan="1">0.0016<break/>[0.0015 0.0033]</td>
<td align="left" rowspan="1" colspan="1">0.0016<break/>[0.0015 0.0032]</td>
<td align="left" rowspan="1" colspan="1">Constant term of the suppressive drive</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w<sub>I</sub></italic></td>
<td align="left" rowspan="1" colspan="1">0.67<break/>[0.46 1.04]</td>
<td align="left" rowspan="1" colspan="1">1.08<break/>[0.87 1.03]</td>
<td align="left" rowspan="1" colspan="1">Interocular normalization weight</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w<sub>x</sub></italic></td>
<td align="left" rowspan="1" colspan="1">4.24<break/>[4.10 4.34]<break/>(1.00, 0.20, 0.26, 0.36, 0.36)</td>
<td align="left" rowspan="1" colspan="1">2.46<break/>[2.37 2.57]<break/>(1.00, 0.26, 0.49, 0.77, 0.77)</td>
<td align="left" rowspan="1" colspan="1">Magnitude of stimulus-driven attentional modulation</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w<sub>v</sub></italic></td>
<td align="left" rowspan="1" colspan="1">5.03<break/>[5.01 5.03]<break/>(2.01)</td>
<td align="left" rowspan="1" colspan="1">4.90<break/>[4.82 4.93]<break/>(1.98)</td>
<td align="left" rowspan="1" colspan="1">Magnitude of goal-driven attentional modulation</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>p</italic></td>
<td align="left" rowspan="1" colspan="1">0.13<break/>[0.11 0.22]</td>
<td align="left" rowspan="1" colspan="1">0.71<break/>[0.70 0.86]</td>
<td align="left" rowspan="1" colspan="1">Trade-off between the magnitude and the spatial extent of the attentional gains</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>σ<sub>n</sub></italic></td>
<td align="left" rowspan="1" colspan="1">2.92<break/>[2.75 3.08]</td>
<td align="left" rowspan="1" colspan="1">2.82<break/>[2.59 2.93]</td>
<td align="left" rowspan="1" colspan="1">Magnitude of the noise</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>R</italic><sup>2</sup></td>
<td align="left" rowspan="1" colspan="1">97.1%</td>
<td align="left" rowspan="1" colspan="1">94.8%</td>
<td align="left" rowspan="1" colspan="1"/>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001"><p>For each parameter, we report the best-fit value and the 68% confidence interval obtained by a bootstrapping procedure. The value of <italic>σ</italic> is reported in units of excitatory drive (see <xref rid="pcbi.1004510.e002" ref-type="disp-formula">Eq 2</xref>). In the row of <italic>w</italic><sub><italic>x</italic></sub>, we also report the stimulus-driven attentional gain factor of the neuron tuned to the target in the no-, small-, medium-, large- and split-competitor conditions (corresponding to the five values in the parenthesis, respectively). In the row of <italic>w</italic><sub><italic>v</italic></sub>, the goal-driven attentional gain factor of the neuron tuned to the target is reported too. This value is the same across conditions because the spatial spread of goal-driven attention did not change with competitor (see details in <xref rid="pcbi.1004510.t001" ref-type="table">Table 1</xref>).</p></fn>
</table-wrap-foot>
</table-wrap>
<p>The individual differences in the amount of suppression induced by the split competitor (in comparison to that induced by the large competitor) were accounted for by individual differences in the interocular normalization weight <italic>w</italic><sub><italic>I</italic></sub>. The FS model was fit to the data from each observer individually to determine the best-fit parameter values (<xref rid="pcbi.1004510.t004" ref-type="table">Table 4</xref>). For observers S2 and S3, who exhibited roughly the same suppression for the large and split competitors, the best-fit values for <italic>w</italic><sub><italic>I</italic></sub> were close to 1. The <italic>w</italic><sub><italic>I</italic></sub> value was much larger than 1 for observer S4, who exhibited a stronger contrast-gain change for the large competitor than the split competitor. The <italic>w</italic><sub><italic>I</italic></sub> value was much smaller than 1 for observer S1, who exhibited a weaker contrast-gain change for the large competitor than the split competitor.</p>
<table-wrap id="pcbi.1004510.t004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.t004</object-id>
<label>Table 4</label> <caption><title>Best-fit parameter values for individual observers.</title></caption>
<alternatives>
<graphic id="pcbi.1004510.t004g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.t004" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Parameter</th>
<th align="left" rowspan="1" colspan="1">S1</th>
<th align="left" rowspan="1" colspan="1">S2</th>
<th align="left" rowspan="1" colspan="1">S3</th>
<th align="left" rowspan="1" colspan="1">S4</th>
<th align="left" rowspan="1" colspan="1">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>n</italic></td>
<td align="char" char="." rowspan="1" colspan="1">2.15</td>
<td align="char" char="." rowspan="1" colspan="1">2.21</td>
<td align="char" char="." rowspan="1" colspan="1">1.67</td>
<td align="char" char="." rowspan="1" colspan="1">2.22</td>
<td align="left" rowspan="1" colspan="1">Exponent of the neural contrast response function</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>σ</italic></td>
<td align="char" char="." rowspan="1" colspan="1">0.0019</td>
<td align="char" char="." rowspan="1" colspan="1">0.0018</td>
<td align="char" char="." rowspan="1" colspan="1">0.0014</td>
<td align="char" char="." rowspan="1" colspan="1">0.0016</td>
<td align="left" rowspan="1" colspan="1">Constant term of the suppressive drive</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w<sub>I</sub></italic></td>
<td align="char" char="." rowspan="1" colspan="1">0.01</td>
<td align="char" char="." rowspan="1" colspan="1">1.08</td>
<td align="char" char="." rowspan="1" colspan="1">1.15</td>
<td align="char" char="." rowspan="1" colspan="1">3.81</td>
<td align="left" rowspan="1" colspan="1">Interocular normalization weight</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w<sub>x</sub></italic></td>
<td align="char" char="." rowspan="1" colspan="1">4.62</td>
<td align="char" char="." rowspan="1" colspan="1">4.50</td>
<td align="char" char="." rowspan="1" colspan="1">2.96</td>
<td align="char" char="." rowspan="1" colspan="1">4.89</td>
<td align="left" rowspan="1" colspan="1">Magnitude of stimulus-driven attentional modulation</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w<sub>v</sub></italic></td>
<td align="char" char="." rowspan="1" colspan="1">4.65</td>
<td align="char" char="." rowspan="1" colspan="1">5.03</td>
<td align="char" char="." rowspan="1" colspan="1">5.02</td>
<td align="char" char="." rowspan="1" colspan="1">5.03</td>
<td align="left" rowspan="1" colspan="1">Magnitude of goal-driven attentional modulation</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>p</italic></td>
<td align="char" char="." rowspan="1" colspan="1">0.26</td>
<td align="char" char="." rowspan="1" colspan="1">0.20</td>
<td align="char" char="." rowspan="1" colspan="1">0.24</td>
<td align="char" char="." rowspan="1" colspan="1">0.12</td>
<td align="left" rowspan="1" colspan="1">Trade-off between the magnitude and the spatial extent of the attentional gains</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>σ<sub>n</sub></italic></td>
<td align="char" char="." rowspan="1" colspan="1">3.10</td>
<td align="char" char="." rowspan="1" colspan="1">3.26</td>
<td align="char" char="." rowspan="1" colspan="1">2.49</td>
<td align="char" char="." rowspan="1" colspan="1">3.18</td>
<td align="left" rowspan="1" colspan="1">Magnitude of the noise</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>R</italic><sup>2</sup></td>
<td align="char" char="." rowspan="1" colspan="1">91.7%</td>
<td align="char" char="." rowspan="1" colspan="1">94.6%</td>
<td align="char" char="." rowspan="1" colspan="1">91.3%</td>
<td align="char" char="." rowspan="1" colspan="1">89.2%</td>
<td align="left" rowspan="1" colspan="1"/>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t004fn001"><p>The value of <italic>σ</italic> is reported in units of excitatory drive (see <xref rid="pcbi.1004510.e002" ref-type="disp-formula">Eq 2</xref>).</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="sec015">
<title>Eye-of-origin modulates the magnitude of contrast gain</title>
<p>In the experiment above, we always presented the target in the observer’s right eye. To further investigate the role of eye-of-origin and its relation with the interocular normalization weight parameter <italic>w</italic><sub><italic>I</italic></sub>, two observers (S1 and S4), who showed very different contrast gain changes in the large- and split-competitor conditions, participated in additional experimental sessions in which the target was presented to the left eye and the competitors were presented to the right eye (except the surround of the split competitor). The no-competitor, large-competitor and split-competitor conditions were tested. The comparison between the modulations induced by the large competitor and the split competitor could reveal the role of eye-of-origin because these two conditions had the same overall (perceived) competitor size, and the only difference between the two competitors was how the competitor was distributed between the two eyes.</p>
<p>When the target eye and competitor eye were swapped, both split competitor and large competitor still induced a contrast gain change (large competitor: <italic>p</italic>&lt;0.001, split competitor: <italic>p</italic>&lt;0.01, bootstrap test) without modulating the response gain (large competitor: <italic>p</italic> = 0.69, split competitor: <italic>p</italic> = 0.46, bootstrap test) (<xref rid="pcbi.1004510.g007" ref-type="fig">Fig 7</xref>, left column). S1, who originally showed stronger contrast gain modulation in the split-competitor condition, now had stronger modulation in the large-competitor condition (<italic>p</italic>&lt;0.05, bootstrap test; Figs <xref rid="pcbi.1004510.g005" ref-type="fig">5</xref> and <xref rid="pcbi.1004510.g007" ref-type="fig">7</xref>). For S4, the large competitor generated stronger suppression than the split competitor in the original experiment, but the suppressive effects of the two conditions became indistinguishable when the target eye and competitor eye were swapped (<italic>p</italic> = 0.10, bootstrap test).</p>
<fig id="pcbi.1004510.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Descriptive model fits.</title>
<p><bold>A</bold>. Psychometric functions for two individual observers who participated in additional experimental sessions, in which the target was presented to the left eye and the competitor presented to the right eye. The corresponding data for right-eye targets are the same as the data reported in <xref rid="pcbi.1004510.g005" ref-type="fig">Fig 5</xref>. Filled dots, psychophysical performance. Curves, best fit Naka-Rushton functions. <bold>B</bold>. Best-fit <italic>c</italic><sub>50</sub> and <italic>d</italic>'<sub><italic>m</italic></sub> parameter values for each individual observer. LE represents left-eye target, and RE represents right-eye target. Error bars, bootstrapped 95% confidence intervals.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.g007" position="float" xlink:type="simple"/>
</fig>
<p>When fitting the FS model to individual data, <italic>w</italic><sub><italic>I</italic></sub> again reflected these individual differences. For S1, <italic>w</italic><sub><italic>I</italic></sub> changed from 0.01 (<xref rid="pcbi.1004510.t004" ref-type="table">Table 4</xref>) to 1.98 (<xref rid="pcbi.1004510.t005" ref-type="table">Table 5</xref>). For S4, <italic>w</italic><sub><italic>I</italic></sub> reduced from 3.81 to 0.71. The increase of <italic>w</italic><sub><italic>I</italic></sub> indicated stronger suppression induced by the stimulus presented in the competitor eye than in the target eye. The change of <italic>w</italic><sub><italic>I</italic></sub> value in the model fit followed the results that after swapping the eye-of-origin, the large competitor (which was presented entirely in the competitor eye) became more suppressive for S1 and less suppressive for S4. The fitted value of <italic>p</italic> was larger in <xref rid="pcbi.1004510.t005" ref-type="table">Table 5</xref> than that in <xref rid="pcbi.1004510.t004" ref-type="table">Table 4</xref>. However, the value of this parameter should be interpreted with care. In the model fitting process of the main experiment, we found that the value of <italic>p</italic> was mainly determined by the amount of response gain reduction observed in the small and medium competitors (for example, a larger trade off between the magnitude of attentional modulation and the spatial spread of attention would let the response gain of the medium competitor be closer to that of the large competitor, and vice versa). Here, we only fit the no competitor, large competitor and split competitor conditions. None of these conditions exhibited response gain modulation, so the data might not have constrained the value of <italic>p</italic>. To determine if this was the case, we assessed the Hessian matrix of the best-fit model, for each subject. While the Hessian matrices were full rank, the eigenvectors corresponding to the smallest eigenvalues had a large projection (0.64 for S1 and -0.85 for S4) on parameter <italic>p</italic>, implying that this parameter was not as well-constrained as the other parameters.</p>

<table-wrap id="pcbi.1004510.t005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004510.t005</object-id>
<label>Table 5</label> <caption><title>Best-fit parameter values for individual observers.</title></caption>
<alternatives>
<graphic id="pcbi.1004510.t005g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004510.t005" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Parameter</th>
<th align="left" rowspan="1" colspan="1">S1</th>
<th align="left" rowspan="1" colspan="1">S4</th>
<th align="left" rowspan="1" colspan="1">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>n</italic></td>
<td align="left" rowspan="1" colspan="1">2.69 (2.76)</td>
<td align="left" rowspan="1" colspan="1">2.71 (2.92)</td>
<td align="left" rowspan="1" colspan="1">Exponent of the neural contrast response function</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>σ</italic></td>
<td align="left" rowspan="1" colspan="1">0.002 (0.002)</td>
<td align="left" rowspan="1" colspan="1">0.002 (0.002)</td>
<td align="left" rowspan="1" colspan="1">Constant term of the suppressive drive</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w<sub>I</sub></italic></td>
<td align="left" rowspan="1" colspan="1">1.98 (0.83)</td>
<td align="left" rowspan="1" colspan="1">0.71 (0.12)</td>
<td align="left" rowspan="1" colspan="1">Interocular normalization weight</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w<sub>x</sub></italic></td>
<td align="left" rowspan="1" colspan="1">3.31 (fixed: 4.62)</td>
<td align="left" rowspan="1" colspan="1">2.63 (fixed: 4.89)</td>
<td align="left" rowspan="1" colspan="1">Magnitude of stimulus-driven attentional modulation</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w<sub>v</sub></italic></td>
<td align="left" rowspan="1" colspan="1">5.03 (5.04)</td>
<td align="left" rowspan="1" colspan="1">5.01 (5.04)</td>
<td align="left" rowspan="1" colspan="1">Magnitude of goal-driven attentional modulation</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>p</italic></td>
<td align="left" rowspan="1" colspan="1">0.80 (fixed: 0.26)</td>
<td align="left" rowspan="1" colspan="1">0.67 (fixed: 0.12)</td>
<td align="left" rowspan="1" colspan="1">Trade-off between the magnitude and the spatial extent of the attentional gains</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>σ<sub>n</sub></italic></td>
<td align="left" rowspan="1" colspan="1">3.45 (3.52)</td>
<td align="left" rowspan="1" colspan="1">3.52 (3.63)</td>
<td align="left" rowspan="1" colspan="1">Magnitude of the noise</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>R</italic><sup>2</sup></td>
<td align="left" rowspan="1" colspan="1">95.3% (94.7%)</td>
<td align="left" rowspan="1" colspan="1">97.0% (95.9%)</td>
<td align="left" rowspan="1" colspan="1"/>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t005fn001"><p>FS model was fit to the individual data in which the target eye and competitor eye were swapped. The values in the parenthesis are the fitted values by a constrained model in which the <italic>w</italic><sub><italic>x</italic></sub> and <italic>p</italic> are fixed at the values reported in the main experiment.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>We fixed the parameters related to stimulus-driven attention, <italic>w</italic><sub><italic>x</italic></sub> and <italic>p</italic>, at the values reported in the main experiment and fit the model again (parenthesis in <xref rid="pcbi.1004510.t005" ref-type="table">Table 5</xref>). We found that the FS model could still account for the data, and the <italic>R</italic><sup>2</sup> only decreased by 0.59% and 1.14% for S1 and S4 respectively. The change of <italic>w</italic><sub><italic>I</italic></sub> due to swapping the eye-of-origin was in the same direction as the original model fit (increase for S1 and decrease for S4 compared to the main experiment).</p>
</sec>
</sec>
<sec id="sec016" sec-type="conclusions">
<title>Discussion</title>
<p>We proposed a computational model integrating attentional modulation and divisive normalization to explain the contrast-gain and response-gain modulation in interocular suppression. The form of interocular suppression (contrast- versus response-gain change) depended on the size of the competitor (not the eye to which it was presented), thereby supporting a model in which attention was selective for the orientation and spatial location of the competitor, not the eye-of-origin of the competitor. The eye-of-origin of the competitor influenced only the magnitude of the contrast-gain change, which the model accounted for with interocular divisive normalization.</p>
<sec id="sec017">
<title>Stimulus-driven feature-based attention</title>
<p>In the normalization model, the responses of a visual neuron are modulated by both the neuron’s preferred stimulus and the visual context formed by the presence of other stimuli [<xref rid="pcbi.1004510.ref006" ref-type="bibr">6</xref>]. Several models of visual attention have suggested that the effect of attention can be modeled within the framework of normalization [<xref rid="pcbi.1004510.ref046" ref-type="bibr">46</xref>–<xref rid="pcbi.1004510.ref048" ref-type="bibr">48</xref>]. In the present study, we followed the normalization model of attention proposed by Reynolds and Heeger [<xref rid="pcbi.1004510.ref012" ref-type="bibr">12</xref>]. This model correctly predicts that endogenous and exogenous spatial attention cause contrast-gain and response-gain changes, evident in the psychometric functions, when the spatial extent of attention is manipulated [<xref rid="pcbi.1004510.ref013" ref-type="bibr">13</xref>], and response-gain changes when the featural extent of attention is manipulated [<xref rid="pcbi.1004510.ref037" ref-type="bibr">37</xref>].</p>
<p>In the present experiment, the competitor elicited an abrupt visual onset and thus stimulus-driven attention [<xref rid="pcbi.1004510.ref025" ref-type="bibr">25</xref>,<xref rid="pcbi.1004510.ref049" ref-type="bibr">49</xref>–<xref rid="pcbi.1004510.ref052" ref-type="bibr">52</xref>]. According to the model, stimulus-driven attention influences behavioral performance even when it opposes task demands (in this case, monitoring the orientation of the target), and implies that the bottom-up inputs have a considerable impact on the deployment of feature-based attention. This is different from most previous studies, in which feature-based attention was presumed, or manipulated, as a top-down process controlled voluntarily by observers [<xref rid="pcbi.1004510.ref024" ref-type="bibr">24</xref>,<xref rid="pcbi.1004510.ref034" ref-type="bibr">34</xref>,<xref rid="pcbi.1004510.ref039" ref-type="bibr">39</xref>,<xref rid="pcbi.1004510.ref053" ref-type="bibr">53</xref>].</p>
<p>The stimulus-driven, feature-based attention seems to have properties different from goal-driven feature-based attention. For example, the spatial extent of the stimulus-driven feature-based attention was constrained by the size of the competitor stimulus. In contrast, previous studies have found that goal-driven feature-based attention spreads across space [<xref rid="pcbi.1004510.ref038" ref-type="bibr">38</xref>–<xref rid="pcbi.1004510.ref040" ref-type="bibr">40</xref>, also see <xref rid="pcbi.1004510.ref054" ref-type="bibr">54</xref>,<xref rid="pcbi.1004510.ref055" ref-type="bibr">55</xref>]. The partial trade-off that we observed between the magnitude of stimulus-driven attention and its spatial extent is consistent with the idea of limited attentional resources [<xref rid="pcbi.1004510.ref016" ref-type="bibr">16</xref>,<xref rid="pcbi.1004510.ref024" ref-type="bibr">24</xref>,<xref rid="pcbi.1004510.ref056" ref-type="bibr">56</xref>].</p>
<p>One study also found a significant influence of bottom-up inputs on feature-based attention by showing a reduction of reaction time when the pre-cue and the target to be discriminated were in the same color compared to when they were different [<xref rid="pcbi.1004510.ref025" ref-type="bibr">25</xref>]. The authors reported that this featural effect can spread across space, but only when the cue was presented in one of the potential target locations and not when it was presented in a target-irrelevant location. To explain the results of the present experiment, we infer that stimulus-driven feature-based attention followed the size of the competitor even when it extended beyond the task-relevant target location. The difference between our and Lin et al.’s [<xref rid="pcbi.1004510.ref025" ref-type="bibr">25</xref>] results might be due to the discrepancy of the experimental designs between the two studies. The response time measure used by Lin et al. could be influenced by the target’s visibility, the speed of information processing and/or criteria changes [<xref rid="pcbi.1004510.ref057" ref-type="bibr">57</xref>,<xref rid="pcbi.1004510.ref058" ref-type="bibr">58</xref>]. On the other hand, in the present study, we focused on the visibility of the target by using <italic>d</italic>' as the index.</p>
<p>Feature-based attention with benefits for attended features and costs for unattended features reported in our model is consistent with previous behavioral [<xref rid="pcbi.1004510.ref040" ref-type="bibr">40</xref>] and neurophysiological [<xref rid="pcbi.1004510.ref059" ref-type="bibr">59</xref>] studies. Even though the increases and reductions in attention gain were linked together in our model, we are agnostic as to whether they share a unified mechanism. Multi-unit recordings in FEF and V4 in monkeys [<xref rid="pcbi.1004510.ref060" ref-type="bibr">60</xref>] and human EEG experiments [<xref rid="pcbi.1004510.ref061" ref-type="bibr">61</xref>] have shown that such increases and reductions in attention gain occur with different time courses.</p>
<p>Our psychophysical results and model comparison showed that the attentional modulation in interocular suppression was better described by a feature-specific rather than an eye-specific modulation. Solely based on our results, we can not conclude that attention is unable to modulate eye-specific information. Previous studies proposing eye-based attention found that manipulating the eye-of-origin of the stimuli [<xref rid="pcbi.1004510.ref027" ref-type="bibr">27</xref>], or the eye-of-origin of the image to be attentively tracked [<xref rid="pcbi.1004510.ref026" ref-type="bibr">26</xref>], can influence observers’ performance in a visual task. However, in our experiment and computational model, we also identified a source of suppression, in addition to attention, whose strength depended on the eye-of-origin of the stimuli (see Interocular divisive normalization below). Many studies [<xref rid="pcbi.1004510.ref002" ref-type="bibr">2</xref>,<xref rid="pcbi.1004510.ref007" ref-type="bibr">7</xref>,<xref rid="pcbi.1004510.ref009" ref-type="bibr">9</xref>,<xref rid="pcbi.1004510.ref062" ref-type="bibr">62</xref>] have also shown that the magnitude of suppressive interactions between multiple stimuli can be changed by simply manipulating eye-of-origin (presented simultaneously either in the same eye or different eyes). Future studies should establish whether the eye-based attention effects reported earlier are distinguishable from this eye-dependent suppression.</p>
</sec>
<sec id="sec018">
<title>Goal-driven attention</title>
<p>The goal-driven component of attention in our model is similar to that in previous models of feature-based attention in orientation discrimination tasks [<xref rid="pcbi.1004510.ref023" ref-type="bibr">23</xref>,<xref rid="pcbi.1004510.ref035" ref-type="bibr">35</xref>–<xref rid="pcbi.1004510.ref037" ref-type="bibr">37</xref>]. Indeed, there is evidence that feature-based attention also modulates interocular suppression [<xref rid="pcbi.1004510.ref063" ref-type="bibr">63</xref>]. Because goal-driven attention was the same for all of the stimulus conditions, it could not account for the dependence of competitor size on interocular suppression. In preliminary fits to Ling and Blake’s data set, we found that without goal-driven attention the interocular normalization weight <italic>w</italic><sub><italic>I</italic></sub> was forced to take an extremely small value. However, a <italic>w</italic><sub><italic>I</italic></sub> value close to zero predicted that the split competitor should induce a much stronger contrast-gain change than any of the other competitors, contrary to what we observed (Figs <xref rid="pcbi.1004510.g005" ref-type="fig">5</xref>, <xref rid="pcbi.1004510.g006" ref-type="fig">6</xref> and <xref rid="pcbi.1004510.g007" ref-type="fig">7</xref>). Including goal-driven, feature-based attention is, consequently, in accordance with the feature-based attention literature and allows a unified model that can fit the results of both experiments.</p>
<p>Other studies have modeled the demands of the task by including a weighting function at the decoding or decision stage of processing [<xref rid="pcbi.1004510.ref064" ref-type="bibr">64</xref>–<xref rid="pcbi.1004510.ref066" ref-type="bibr">66</xref>]. We acknowledge that the goal-driven gain factors in our current model might be replaced by multiple stages of information processing, and this could be the reason why the goal-driven gain factors estimated by the model were so strong that they greatly reduced the response of the task-irrelevant orientations (<xref rid="pcbi.1004510.g004" ref-type="fig">Fig 4E</xref>).</p>
</sec>
<sec id="sec019">
<title>Interocular divisive normalization</title>
<p>We found, for some individuals, that moving a portion of the competitor to the other eye (changing the stimulus from large competitor to split competitor) can influence the magnitude of contrast-gain change without influencing the response gain. This pattern held when the target eye and competitor eye were swapped so that the target was presented to the left eye and the competitors were presented to the right eye (<xref rid="pcbi.1004510.g007" ref-type="fig">Fig 7</xref>). These results provided evidence that a source of the suppression from the competitor is eye-specific and it causes a change in contrast gain, consistent with previous neuroimaging [<xref rid="pcbi.1004510.ref009" ref-type="bibr">9</xref>] and psychophysics [<xref rid="pcbi.1004510.ref008" ref-type="bibr">8</xref>] studies on cross-orientation dichoptic masking.</p>
<p>In the current model, the interocular normalization weight <italic>w</italic><sub><italic>I</italic></sub> reflected individual differences in the magnitude of the contrast-gain change induced by the large and the split competitors: increasing the value of <italic>w</italic><sub><italic>I</italic></sub> caused the large competitor to become more suppressive compared to the split competitor. The individual variation in the magnitude of interocular divisive normalization was consistent with previous studies reporting individual variations in the strength and the temporal dependency of dichoptic masking [<xref rid="pcbi.1004510.ref007" ref-type="bibr">7</xref>,<xref rid="pcbi.1004510.ref062" ref-type="bibr">62</xref>]. There seem to be multiple factors influencing the magnitude of <italic>w</italic><sub><italic>I</italic></sub>: Individual differences in eye dominance are well documented for normal observers [<xref rid="pcbi.1004510.ref067" ref-type="bibr">67</xref>, <xref rid="pcbi.1004510.ref068" ref-type="bibr">68</xref>]. In the present experiment, if an observer had a significant imbalance in eye dominance, moving a portion of the competitor from the weaker eye to the stronger eye should have resulted in greater divisive suppression of the target. In addition, after swapping the target eye and the competitor eye, the competitor (either the large or the split competitor) that generated stronger suppression should have also switched (to the split or to the large competitor, respectively). We observed this pattern for subject S1, but not for S4 (<xref rid="pcbi.1004510.g007" ref-type="fig">Fig 7</xref>). Thus, the magnitude of interocular normalization can not be solely explained by eye dominance. The model fits (S1 and S4 in Tables <xref rid="pcbi.1004510.t004" ref-type="table">4</xref> and <xref rid="pcbi.1004510.t005" ref-type="table">5</xref>) indicated that the interocular suppression weight from left- to right- eye was not equal to the weight from right- to left- eye, and thus <italic>w</italic><sub><italic>I</italic></sub> not only varied across observers but also varied according to which eye was the target eye (and which eye was the competitor eye). The parameter <italic>w</italic><sub><italic>I</italic></sub> can actually be considered to be two separate parameters: <italic>w</italic><sub><italic>LR</italic></sub> in <xref rid="pcbi.1004510.t004" ref-type="table">Table 4</xref> and <italic>w</italic><sub><italic>RL</italic></sub> in <xref rid="pcbi.1004510.t005" ref-type="table">Table 5</xref>, such that <italic>w</italic><sub><italic>LR</italic></sub> represents the strength of interocular divisive normalization contributed by the left-eye competitor to the right-eye neural population, and vice versa for <italic>w</italic><sub><italic>RL</italic></sub>.</p>
</sec>
<sec id="sec020">
<title>Dissociable roles of attention and normalization</title>
<p>There has been some controversy as to whether interocular suppression occurs in early visual cortex when attention is controlled. Whereas one study reported an absence of interocular suppression in V1 [<xref rid="pcbi.1004510.ref069" ref-type="bibr">69</xref>], two studies reported significant interocular suppression even when attention was diverted away from the stimuli [<xref rid="pcbi.1004510.ref009" ref-type="bibr">9</xref>,<xref rid="pcbi.1004510.ref010" ref-type="bibr">10</xref>]. According to the current model, both divisive normalization and attentional modulation contribute to interocular suppression. We demonstrated that these two components contributing to interocular suppression can be distinguished. Attentional modulation depended on the feature and size of the competitor resulting in a response-gain change for large competitors and a contrast-gain change for small competitors. Interocular divisive normalization depended on the eye-of-origin of the competitor resulting in contrast-gain changes of different magnitude for the large and split competitors.</p>
</sec>
<sec id="sec021">
<title>Comparison with previous models and model limitations</title>
<p>Previous psychophysics studies [<xref rid="pcbi.1004510.ref007" ref-type="bibr">7</xref>,<xref rid="pcbi.1004510.ref008" ref-type="bibr">8</xref>] investigated the suppression induced by dichoptic masks with orientation orthogonal to the target and the same size as the target. It was found that the mask elevated detection threshold of the target and the data were fitted by a model with interocular divisive normalization [<xref rid="pcbi.1004510.ref007" ref-type="bibr">7</xref>]. When a large range of target contrasts were tested, a contrast gain modulation was reported in a contrast detection task [<xref rid="pcbi.1004510.ref008" ref-type="bibr">8</xref>]. Such a pure contrast gain modulation is different from the suppression effect reported here. The discrepancy might be due to the fact that the interocular suppression was measured in distinct perceptual states. Our study used onset-flash suppression to ensure that the target was suppressed by the dominant competitors. This is different from the procedures used by Baker et al. [<xref rid="pcbi.1004510.ref007" ref-type="bibr">7</xref>,<xref rid="pcbi.1004510.ref008" ref-type="bibr">8</xref>], in which the target and the mask were presented simultaneously and briefly (from 25 ms to 400 ms). These parameters are known to generate a perceptual state of fusion (of the target and the mask) before the initiation of strong interocular competition [<xref rid="pcbi.1004510.ref028" ref-type="bibr">28</xref>].</p>
<p>Single-cell electrophysiological recordings have found mixed results regarding the suppression induced by dichoptic masks. Some reported predominately response gain modulation [<xref rid="pcbi.1004510.ref070" ref-type="bibr">70</xref>], and some reported a mixture of contrast gain and response gain modulation varying across neurons [<xref rid="pcbi.1004510.ref071" ref-type="bibr">71</xref>]. These experiments were conducted on anesthetized and paralyzed cats and one should be careful when linking these results with neuroimaging and psychophysics on humans. A series of studies have reported strong dependency between the animals’ states and the response of neurons in primary visual cortex including visually evoked response [<xref rid="pcbi.1004510.ref072" ref-type="bibr">72</xref>], magnitude and correlation of noise [<xref rid="pcbi.1004510.ref073" ref-type="bibr">73</xref>] and suppressive connections [<xref rid="pcbi.1004510.ref074" ref-type="bibr">74</xref>]. Electrophysiological and neuroimaging studies on monkeys and humans have shown divergent results when probing the neural correlate of interocular suppression in V1, either with the same or different types of neural signal and measurement [reviewed in <xref rid="pcbi.1004510.ref004" ref-type="bibr">4</xref>]. Attentional state is a critical factor when comparing the results across experiments because interocular suppression is dependent on attentional state [<xref rid="pcbi.1004510.ref011" ref-type="bibr">11</xref>,<xref rid="pcbi.1004510.ref075" ref-type="bibr">75</xref>,<xref rid="pcbi.1004510.ref076" ref-type="bibr">76</xref>].</p>
<p>Two human neuroimaging studies [<xref rid="pcbi.1004510.ref009" ref-type="bibr">9</xref>,<xref rid="pcbi.1004510.ref010" ref-type="bibr">10</xref>] reported dichoptic masking effects in V1 and showed that the suppression could be accounted for by divisive normalization. These experiments used a central attention task to control observers’ attention at fixation. This is generally consistent with the prediction of the current model that if attention is withdrawn from the stimuli, the competitor will only generate a contrast gain change which can be accounted by interocular divisive normalization. Single-cell recording [<xref rid="pcbi.1004510.ref077" ref-type="bibr">77</xref>] and psychophysical [<xref rid="pcbi.1004510.ref007" ref-type="bibr">7</xref>] studies have shown that the origins of the suppression contributed by monocular and dichoptic masks can be distinguished by manipulating the spatiotemporal properties of the mask or by testing the adaptability of the mask. In the current model, the stimuli presented either in the same or different eyes can suppress the neurons through normalization. We did not aim to address the particular neural pathways that support the normalization in the same eye or across eyes; normalization might occur at different stages of neural processing and it might be implemented by different neural mechanisms [<xref rid="pcbi.1004510.ref006" ref-type="bibr">6</xref>].</p>
<p>In dichoptic masking studies, interocular suppression can be reduced by adding matched images, with either non-zero [<xref rid="pcbi.1004510.ref078" ref-type="bibr">78</xref>] or zero [<xref rid="pcbi.1004510.ref079" ref-type="bibr">79</xref>] disparity, in the two eyes. In contrast, in our experiment, presenting the split competitor to both eyes did not increase the correspondence between the images in the two eyes. Likewise, adding binocular fusion markers to manipulate the correspondence between the images in the two eyes did not change the size-dependent interocular suppression [<xref rid="pcbi.1004510.ref011" ref-type="bibr">11</xref>].</p>
<p>In binocular rivalry, it has been reported that a large stimulus presented to one eye has shorter dominance durations than that of a small stimulus presented simultaneously to the other eye [<xref rid="pcbi.1004510.ref080" ref-type="bibr">80</xref>], similar to the size effect reported here. We are agnostic about whether the surface-boundary account proposed by Ooi and He [<xref rid="pcbi.1004510.ref080" ref-type="bibr">80</xref>] to explain this binocular rivalry result could be used to model the contrast-gain and response-gain modulation in our experiments and the absence of response-gain modulation by the small competitor under withdrawn attention reported by Ling and Blake [<xref rid="pcbi.1004510.ref011" ref-type="bibr">11</xref>].</p>
<p>In addition to the onset-flash suppression used in this study, various related methods have been used to probe the interocular interactions regulating competing information from the two eyes, e.g., binocular rivalry [<xref rid="pcbi.1004510.ref081" ref-type="bibr">81</xref>], generalized flash suppression [<xref rid="pcbi.1004510.ref002" ref-type="bibr">2</xref>], and continuous flash suppression [<xref rid="pcbi.1004510.ref003" ref-type="bibr">3</xref>]. Our model does not attempt to account for these various perceptual phenomena. For example, in continuous flash suppression, presenting a static target with a dynamic competitor gives rise to a depth of suppression much stronger than most of the other methods of interocular suppression. How such manipulations increase the dominance duration is beyond the scope of present study. Even so, it is likely that these distinct perceptual phenomena share common neural processes [<xref rid="pcbi.1004510.ref008" ref-type="bibr">8</xref>,<xref rid="pcbi.1004510.ref082" ref-type="bibr">82</xref>]. Further research is required to investigate whether the model proposed here, including divisive normalization, as well as spatial- and feature-selective attention, can be extended to explain this wide range of perceptual phenomena.</p>
</sec>
</sec>
<sec id="sec022">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004510.s001" xlink:href="info:doi/10.1371/journal.pcbi.1004510.s001" mimetype="application/pdf" position="float" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Compound model.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004510.s002" xlink:href="info:doi/10.1371/journal.pcbi.1004510.s002" mimetype="application/pdf" position="float" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Model comparison by maximum likelihood estimation and Bayesian information criterion.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Sam Ling and Randolph Blake for sharing the data of their experiment reported in Ling and Blake, 2012.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004510.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wolfe</surname> <given-names>JM</given-names></name> (<year>1984</year>) <article-title>Reversing ocular dominance and suppression in a single flash</article-title>. <source>Vision research</source> <volume>24</volume>: <fpage>471</fpage>–<lpage>478</lpage>. <object-id pub-id-type="pmid">6740966</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilke</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Logothetis</surname> <given-names>NK</given-names></name>, <name name-style="western"><surname>Leopold</surname> <given-names>DA</given-names></name> (<year>2003</year>) <article-title>Generalized flash suppression of salient visual targets</article-title>. <source>Neuron</source> <volume>39</volume>: <fpage>1043</fpage>–<lpage>1052</lpage>. <object-id pub-id-type="pmid">12971902</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsuchiya</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name> (<year>2005</year>) <article-title>Continuous flash suppression reduces negative afterimages</article-title>. <source>Nature neuroscience</source> <volume>8</volume>: <fpage>1096</fpage>–<lpage>1101</lpage>. <object-id pub-id-type="pmid">15995700</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sterzer</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Stein</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ludwig</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Rothkirch</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hesselmann</surname> <given-names>G</given-names></name> (<year>2014</year>) <article-title>Neural processing of visual information under interocular suppression: a critical review</article-title>. <source>Frontiers in Psychology</source> <volume>5</volume>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name> (<year>1992</year>) <article-title>Normalization of cell responses in cat striate cortex</article-title>. <source>Visual neuroscience</source> <volume>9</volume>: <fpage>181</fpage>–<lpage>197</lpage>. <object-id pub-id-type="pmid">1504027</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name> (<year>2012</year>) <article-title>Normalization as a canonical neural computation</article-title>. <source>Nature Reviews Neuroscience</source> <volume>13</volume>: <fpage>51</fpage>–<lpage>62</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baker</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Meese</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Summers</surname> <given-names>RJ</given-names></name> (<year>2007</year>) <article-title>Psychophysical evidence for two routes to suppression before binocular summation of signals in human vision</article-title>. <source>Neuroscience</source> <volume>146</volume>: <fpage>435</fpage>–<lpage>448</lpage>. <object-id pub-id-type="pmid">17346895</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baker</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Graf</surname> <given-names>EW</given-names></name> (<year>2009</year>) <article-title>On the relation between dichoptic masking and binocular rivalry</article-title>. <source>Vision research</source> <volume>49</volume>: <fpage>451</fpage>–<lpage>459</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2008.12.002" xlink:type="simple">10.1016/j.visres.2008.12.002</ext-link></comment> <object-id pub-id-type="pmid">19124036</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Moradi</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name> (<year>2009</year>) <article-title>Inter-ocular contrast normalization in human visual cortex</article-title>. <source>Journal of Vision</source> <volume>9</volume>: <fpage>13</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yuval-Greenberg</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name> (<year>2013</year>) <article-title>Continuous flash suppression modulates cortical activity in early visual cortex</article-title>. <source>The Journal of Neuroscience</source> <volume>33</volume>: <fpage>9635</fpage>–<lpage>9643</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4612-12.2013" xlink:type="simple">10.1523/JNEUROSCI.4612-12.2013</ext-link></comment> <object-id pub-id-type="pmid">23739960</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ling</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Blake</surname> <given-names>R</given-names></name> (<year>2012</year>) <article-title>Normalization regulates competition for visual awareness</article-title>. <source>Neuron</source> <volume>75</volume>: <fpage>531</fpage>–<lpage>540</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.05.032" xlink:type="simple">10.1016/j.neuron.2012.05.032</ext-link></comment> <object-id pub-id-type="pmid">22884335</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reynolds</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name> (<year>2009</year>) <article-title>The normalization model of attention</article-title>. <source>Neuron</source> <volume>61</volume>: <fpage>168</fpage>–<lpage>185</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2009.01.002" xlink:type="simple">10.1016/j.neuron.2009.01.002</ext-link></comment> <object-id pub-id-type="pmid">19186161</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Herrmann</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Montaser-Kouhsari</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name> (<year>2010</year>) <article-title>When size matters: attention affects performance by contrast or response gain</article-title>. <source>Nature neuroscience</source> <volume>13</volume>: <fpage>1554</fpage>–<lpage>1559</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2669" xlink:type="simple">10.1038/nn.2669</ext-link></comment> <object-id pub-id-type="pmid">21057509</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nakayama</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Mackeben</surname> <given-names>M</given-names></name> (<year>1989</year>) <article-title>Sustained and transient components of focal visual attention</article-title>. <source>Vision research</source> <volume>29</volume>: <fpage>1631</fpage>–<lpage>1647</lpage>. <object-id pub-id-type="pmid">2635486</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lu</surname> <given-names>Z-L</given-names></name>, <name name-style="western"><surname>Dosher</surname> <given-names>BA</given-names></name> (<year>2000</year>) <article-title>Spatial attention: Different mechanisms for central and peripheral temporal precues?</article-title> <source>Journal of Experimental Psychology: Human Perception and Performance</source> <volume>26</volume>: <fpage>1534</fpage>. <object-id pub-id-type="pmid">11039483</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pestilli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2005</year>) <article-title>Attention enhances contrast sensitivity at cued and impairs it at uncued locations</article-title>. <source>Vision research</source> <volume>45</volume>: <fpage>1867</fpage>–<lpage>1875</lpage>. <object-id pub-id-type="pmid">15797776</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Giordano</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>McElree</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2009</year>) <article-title>On the automaticity and flexibility of covert attention: A speed-accuracy trade-off analysis</article-title>. <source>Journal of Vision</source> <volume>9</volume>: <fpage>30</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/9.3.30" xlink:type="simple">10.1167/9.3.30</ext-link></comment> <object-id pub-id-type="pmid">19757969</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barbot</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2012</year>) <article-title>Differential effects of exogenous and endogenous attention on second-order texture contrast sensitivity</article-title>. <source>Journal of Vision</source> <volume>12</volume>: <fpage>6</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lankheet</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Verstraten</surname> <given-names>FA</given-names></name> (<year>1995</year>) <article-title>Attentional modulation of adaptation to two-component transparent motion</article-title>. <source>Vision research</source> <volume>35</volume>: <fpage>1401</fpage>–<lpage>1412</lpage>. <object-id pub-id-type="pmid">7645269</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Treue</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Trujillo</surname> <given-names>JCM</given-names></name> (<year>1999</year>) <article-title>Feature-based attention influences motion processing gain in macaque visual cortex</article-title>. <source>Nature</source> <volume>399</volume>: <fpage>575</fpage>–<lpage>579</lpage>. <object-id pub-id-type="pmid">10376597</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saenz</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Buracas</surname> <given-names>GT</given-names></name>, <name name-style="western"><surname>Boynton</surname> <given-names>GM</given-names></name> (<year>2003</year>) <article-title>Global feature-based attention for motion and color</article-title>. <source>Vision research</source> <volume>43</volume>: <fpage>629</fpage>–<lpage>637</lpage>. <object-id pub-id-type="pmid">12604099</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baldassi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Verghese</surname> <given-names>P</given-names></name> (<year>2005</year>) <article-title>Attention to locations and features: Different top-down modulation of detector weights</article-title>. <source>Journal of Vision</source> <volume>5</volume>: <fpage>7</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ling</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2009</year>) <article-title>How spatial and feature-based attention affect the gain and tuning of population responses</article-title>. <source>Vision research</source> <volume>49</volume>: <fpage>1194</fpage>–<lpage>1204</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2008.05.025" xlink:type="simple">10.1016/j.visres.2008.05.025</ext-link></comment> <object-id pub-id-type="pmid">18590754</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2011</year>) <article-title>Visual attention: The past 25 years</article-title>. <source>Vision research</source> <volume>51</volume>: <fpage>1484</fpage>–<lpage>1525</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2011.04.012" xlink:type="simple">10.1016/j.visres.2011.04.012</ext-link></comment> <object-id pub-id-type="pmid">21549742</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lin</surname> <given-names>JY</given-names></name>, <name name-style="western"><surname>Hubert-Wallander</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Murray</surname> <given-names>SO</given-names></name>, <name name-style="western"><surname>Boynton</surname> <given-names>GM</given-names></name> (<year>2011</year>) <article-title>Rapid and reflexive feature-based attention</article-title>. <source>Journal of vision</source> <volume>11</volume>: <fpage>12</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Jiang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>He</surname> <given-names>S</given-names></name> (<year>2012</year>) <article-title>Voluntary attention modulates processing of eye-specific visual information</article-title>. <source>Psychological science</source> <volume>23</volume>: <fpage>254</fpage>–<lpage>260</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0956797611424289" xlink:type="simple">10.1177/0956797611424289</ext-link></comment> <object-id pub-id-type="pmid">22301519</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhaoping</surname> <given-names>L</given-names></name> (<year>2008</year>) <article-title>Attention capture by eye of origin singletons even without awareness s—A hallmark of a bottom-up saliency map in the primary visual cortex</article-title>. <source>Journal of Vision</source> <volume>8</volume>: <fpage>1</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wolfe</surname> <given-names>JM</given-names></name> (<year>1983</year>) <article-title>Influence of spatial frequency, luminance, and duration on binocular rivalry and abnormal fusion of briefly presented dichoptic stimuli</article-title>. <source>Perception</source> <volume>12</volume>: <fpage>447</fpage>–<lpage>456</lpage>. <object-id pub-id-type="pmid">6672740</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graf</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Kohn</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Jazayeri</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name> (<year>2011</year>) <article-title>Decoding the activity of neuronal populations in macaque primary visual cortex</article-title>. <source>Nature neuroscience</source> <volume>14</volume>: <fpage>239</fpage>–<lpage>245</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2733" xlink:type="simple">10.1038/nn.2733</ext-link></comment> <object-id pub-id-type="pmid">21217762</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Freeman</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Ohzawa</surname> <given-names>I</given-names></name> (<year>1994</year>) <article-title>Length and width tuning of neurons in the cat's primary visual cortex</article-title>. <source>Journal of Neurophysiology</source> <volume>71</volume>: <fpage>347</fpage>–<lpage>374</lpage>. <object-id pub-id-type="pmid">8158236</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cavanaugh</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Bair</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name> (<year>2002</year>) <article-title>Nature and interaction of signals from the receptive field center and surround in macaque V1 neurons</article-title>. <source>Journal of neurophysiology</source> <volume>88</volume>: <fpage>2530</fpage>–<lpage>2546</lpage>. <object-id pub-id-type="pmid">12424292</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name> (<year>1994</year>) <article-title>Summation and division by neurons in primate visual cortex</article-title>. <source>Science</source> <volume>264</volume>: <fpage>1333</fpage>–<lpage>1336</lpage>. <object-id pub-id-type="pmid">8191289</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wolfe</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Franzel</surname> <given-names>SL</given-names></name> (<year>1988</year>) <article-title>Binocularity and visual search</article-title>. <source>Perception &amp; Psychophysics</source> <volume>44</volume>: <fpage>81</fpage>–<lpage>93</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Larsson</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2007</year>) <article-title>Feature-based attention modulates orientation-selective responses in human visual cortex</article-title>. <source>Neuron</source> <volume>55</volume>: <fpage>313</fpage>–<lpage>323</lpage>. <object-id pub-id-type="pmid">17640531</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Navalpakkam</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Itti</surname> <given-names>L</given-names></name> (<year>2007</year>) <article-title>Search goal tunes visual features optimally</article-title>. <source>Neuron</source> <volume>53</volume>: <fpage>605</fpage>–<lpage>617</lpage>. <object-id pub-id-type="pmid">17296560</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Scolari</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Serences</surname> <given-names>JT</given-names></name> (<year>2009</year>) <article-title>Adaptive allocation of attentional gain</article-title>. <source>The Journal of Neuroscience</source> <volume>29</volume>: <fpage>11933</fpage>–<lpage>11942</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5642-08.2009" xlink:type="simple">10.1523/JNEUROSCI.5642-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19776279</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Herrmann</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2012</year>) <article-title>Feature-based attention enhances performance by increasing response gain</article-title>. <source>Vision research</source> <volume>74</volume>: <fpage>10</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2012.04.016" xlink:type="simple">10.1016/j.visres.2012.04.016</ext-link></comment> <object-id pub-id-type="pmid">22580017</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saenz</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Buracas</surname> <given-names>GT</given-names></name>, <name name-style="western"><surname>Boynton</surname> <given-names>GM</given-names></name> (<year>2002</year>) <article-title>Global effects of feature-based attention in human visual cortex</article-title>. <source>Nature neuroscience</source> <volume>5</volume>: <fpage>631</fpage>–<lpage>632</lpage>. <object-id pub-id-type="pmid">12068304</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Serences</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Boynton</surname> <given-names>GM</given-names></name> (<year>2007</year>) <article-title>Feature-based attentional modulations in the absence of direct visual stimulation</article-title>. <source>Neuron</source> <volume>55</volume>: <fpage>301</fpage>–<lpage>312</lpage>. <object-id pub-id-type="pmid">17640530</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>White</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2011</year>) <article-title>Feature-based attention involuntarily and simultaneously improves visual performance across locations</article-title>. <source>Journal of Vision</source> <volume>11</volume>: <fpage>15</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Mance</surname> <given-names>I</given-names></name> (<year>2011</year>) <article-title>Constant spread of feature-based attention across the visual field</article-title>. <source>Vision research</source> <volume>51</volume>: <fpage>26</fpage>–<lpage>33</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2010.09.023" xlink:type="simple">10.1016/j.visres.2010.09.023</ext-link></comment> <object-id pub-id-type="pmid">20887745</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pestilli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Gardner</surname> <given-names>JL</given-names></name> (<year>2011</year>) <article-title>Attentional enhancement via selection and pooling of early sensory responses in human visual cortex</article-title>. <source>Neuron</source> <volume>72</volume>: <fpage>832</fpage>–<lpage>846</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.09.025" xlink:type="simple">10.1016/j.neuron.2011.09.025</ext-link></comment> <object-id pub-id-type="pmid">22153378</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jazayeri</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name> (<year>2006</year>) <article-title>Optimal representation of sensory information by neural populations</article-title>. <source>Nature neuroscience</source> <volume>9</volume>: <fpage>690</fpage>–<lpage>696</lpage>. <object-id pub-id-type="pmid">16617339</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pestilli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Ling</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2009</year>) <article-title>A population-coding model of attention's influence on contrast response: Estimating neural effects from psychophysical data</article-title>. <source>Vision research</source> <volume>49</volume>: <fpage>1144</fpage>–<lpage>1153</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2008.09.018" xlink:type="simple">10.1016/j.visres.2008.09.018</ext-link></comment> <object-id pub-id-type="pmid">18926845</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gimenez</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Viallefont</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Catchpole</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Choquet</surname> <given-names>Rm</given-names></name>, <name name-style="western"><surname>Morgan</surname> <given-names>BJ</given-names></name> (<year>2004</year>) <article-title>Methods for investigating parameter redundancy</article-title>. <source>Animal Biodiversity and Conservation</source> <volume>27</volume>: <fpage>561</fpage>–<lpage>572</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ghose</surname> <given-names>GM</given-names></name> (<year>2009</year>) <article-title>Attentional modulation of visual responses by flexible input gain</article-title>. <source>Journal of neurophysiology</source> <volume>101</volume>: <fpage>2089</fpage>–<lpage>2106</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.90654.2008" xlink:type="simple">10.1152/jn.90654.2008</ext-link></comment> <object-id pub-id-type="pmid">19193776</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JH</given-names></name> (<year>2009</year>) <article-title>A normalization model of attentional modulation of single unit responses</article-title>. <source>PLoS One</source> <volume>4</volume>: <fpage>e4651</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0004651" xlink:type="simple">10.1371/journal.pone.0004651</ext-link></comment> <object-id pub-id-type="pmid">19247494</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boynton</surname> <given-names>GM</given-names></name> (<year>2009</year>) <article-title>A framework for describing the effects of attention on visual responses</article-title>. <source>Vision research</source> <volume>49</volume>: <fpage>1129</fpage>–<lpage>1143</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2008.11.001" xlink:type="simple">10.1016/j.visres.2008.11.001</ext-link></comment> <object-id pub-id-type="pmid">19038281</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Posner</surname> <given-names>MI</given-names></name> (<year>1980</year>) <article-title>Orienting of attention</article-title>. <source>Quarterly journal of experimental psychology</source> <volume>32</volume>: <fpage>3</fpage>–<lpage>25</lpage>. <object-id pub-id-type="pmid">7367577</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jonides</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Yantis</surname> <given-names>S</given-names></name> (<year>1988</year>) <article-title>Uniqueness of abrupt visual onset in capturing attention</article-title>. <source>Perception &amp; Psychophysics</source> <volume>43</volume>: <fpage>346</fpage>–<lpage>354</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yantis</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Jonides</surname> <given-names>J</given-names></name> (<year>1990</year>) <article-title>Abrupt visual onsets and selective attention: voluntary versus automatic allocation</article-title>. <source>Journal of Experimental Psychology: Human perception and performance</source> <volume>16</volume>: <fpage>121</fpage>. <object-id pub-id-type="pmid">2137514</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>White</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Lunau</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2014</year>) <article-title>The attentional effects of single cues and color singletons on visual sensitivity</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source> <volume>40</volume>: <fpage>639</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0033775" xlink:type="simple">10.1037/a0033775</ext-link></comment> <object-id pub-id-type="pmid">23875570</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maunsell</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Treue</surname> <given-names>S</given-names></name> (<year>2006</year>) <article-title>Feature-based attention in visual cortex</article-title>. <source>Trends in neurosciences</source> <volume>29</volume>: <fpage>317</fpage>–<lpage>322</lpage>. <object-id pub-id-type="pmid">16697058</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Painter</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Dux</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Travis</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Mattingley</surname> <given-names>JB</given-names></name> (<year>2014</year>) <article-title>Neural responses to target features outside a search array are enhanced during conjunction but not unique-feature search</article-title>. <source>The Journal of Neuroscience</source> <volume>34</volume>: <fpage>3390</fpage>–<lpage>3401</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3630-13.2014" xlink:type="simple">10.1523/JNEUROSCI.3630-13.2014</ext-link></comment> <object-id pub-id-type="pmid">24573295</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>White</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Rolfs</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2013</year>) <article-title>Adaptive deployment of spatial and feature-based attention before saccades</article-title>. <source>Vision research</source> <volume>85</volume>: <fpage>26</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2012.10.017" xlink:type="simple">10.1016/j.visres.2012.10.017</ext-link></comment> <object-id pub-id-type="pmid">23147690</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alvarez</surname> <given-names>GA</given-names></name>, <name name-style="western"><surname>Franconeri</surname> <given-names>SL</given-names></name> (<year>2007</year>) <article-title>How many objects can you track?: Evidence for a resource-limited attentive tracking mechanism</article-title>. <source>Journal of Vision</source> <volume>7</volume>: <fpage>14</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McElree</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>1999</year>) <article-title>The temporal dynamics of visual search: evidence for parallel processing in feature and conjunction searches</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source> <volume>25</volume>: <fpage>1517</fpage>. <object-id pub-id-type="pmid">10641310</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>McElree</surname> <given-names>B</given-names></name> (<year>2001</year>) <article-title>Covert attention accelerates the rate of visual information processing</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>98</volume>: <fpage>5363</fpage>–<lpage>5367</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Martinez-Trujillo</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Treue</surname> <given-names>S</given-names></name> (<year>2004</year>) <article-title>Feature-based attention increases the selectivity of population responses in primate visual cortex</article-title>. <source>Current Biology</source> <volume>14</volume>: <fpage>744</fpage>–<lpage>751</lpage>. <object-id pub-id-type="pmid">15120065</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gregoriou</surname> <given-names>GG</given-names></name>, <name name-style="western"><surname>Gotts</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Zhou</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Desimone</surname> <given-names>R</given-names></name> (<year>2009</year>) <article-title>High-frequency, long-range coupling between prefrontal and visual cortex during attention</article-title>. <source>science</source> <volume>324</volume>: <fpage>1207</fpage>–<lpage>1210</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1171402" xlink:type="simple">10.1126/science.1171402</ext-link></comment> <object-id pub-id-type="pmid">19478185</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Andersen</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Müller</surname> <given-names>M</given-names></name> (<year>2010</year>) <article-title>Behavioral performance follows the time course of neural facilitation and suppression during cued shifts of feature-selective attention</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>107</volume>: <fpage>13878</fpage>–<lpage>13882</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meese</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Hess</surname> <given-names>RF</given-names></name> (<year>2004</year>) <article-title>Low spatial frequencies are suppressively masked across spatial scale, orientation, field position, and eye of origin</article-title>. <source>Journal of Vision</source> <volume>4</volume>: <fpage>2</fpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Spering</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Carrasco</surname> <given-names>M</given-names></name> (<year>2012</year>) <article-title>Similar effects of feature-based attention on motion perception and pursuit eye movements at different levels of awareness</article-title>. <source>The Journal of Neuroscience</source> <volume>32</volume>: <fpage>7594</fpage>–<lpage>7601</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0355-12.2012" xlink:type="simple">10.1523/JNEUROSCI.0355-12.2012</ext-link></comment> <object-id pub-id-type="pmid">22649238</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Regan</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Beverley</surname> <given-names>K</given-names></name> (<year>1985</year>) <article-title>Postadaptation orientation discrimination</article-title>. <source>JOSA A</source> <volume>2</volume>: <fpage>147</fpage>–<lpage>155</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Purushothaman</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Bradley</surname> <given-names>DC</given-names></name> (<year>2004</year>) <article-title>Neural population code for fine perceptual decisions in area MT</article-title>. <source>Nature neuroscience</source> <volume>8</volume>: <fpage>99</fpage>–<lpage>106</lpage>. <object-id pub-id-type="pmid">15608633</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jazayeri</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name> (<year>2007</year>) <article-title>A new perceptual illusion reveals mechanisms of sensory decoding</article-title>. <source>Nature</source> <volume>446</volume>: <fpage>912</fpage>–<lpage>915</lpage>. <object-id pub-id-type="pmid">17410125</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mapp</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Ono</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Barbeito</surname> <given-names>R</given-names></name> (<year>2003</year>) <article-title>What does the dominant eye dominate? A brief and somewhat contentious review</article-title>. <source>Perception &amp; Psychophysics</source> <volume>65</volume>: <fpage>310</fpage>–<lpage>317</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004510.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Porac</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Coren</surname> <given-names>S</given-names></name> (<year>1976</year>) <article-title>The dominant eye</article-title>. <source>Psychological bulletin</source> <volume>83</volume>: <fpage>880</fpage>. <object-id pub-id-type="pmid">794902</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Watanabe</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Cheng</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Murayama</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Ueno</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Asamizuya</surname> <given-names>T</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Attention but not awareness modulates the BOLD signal in the human V1 during binocular suppression</article-title>. <source>Science</source> <volume>334</volume>: <fpage>829</fpage>–<lpage>831</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1203161" xlink:type="simple">10.1126/science.1203161</ext-link></comment> <object-id pub-id-type="pmid">22076381</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Peterson</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Thompson</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Duong</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Freeman</surname> <given-names>RD</given-names></name> (<year>2005</year>) <article-title>Cross-orientation suppression: monoptic and dichoptic mechanisms are different</article-title>. <source>Journal of neurophysiology</source> <volume>94</volume>: <fpage>1645</fpage>–<lpage>1650</lpage>. <object-id pub-id-type="pmid">15843483</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sengpiel</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Baddeley</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Freeman</surname> <given-names>TC</given-names></name>, <name name-style="western"><surname>Harrad</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Blakemore</surname> <given-names>C</given-names></name> (<year>1998</year>) <article-title>Different mechanisms underlie three inhibitory phenomena in cat area 17</article-title>. <source>Vision research</source> <volume>38</volume>: <fpage>2067</fpage>–<lpage>2080</lpage>. <object-id pub-id-type="pmid">9797967</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haider</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>H√§usser</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name> (<year>2013</year>) <article-title>Inhibition dominates sensory responses in the awake cortex</article-title>. <source>Nature</source> <volume>493</volume>: <fpage>97</fpage>–<lpage>100</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature11665" xlink:type="simple">10.1038/nature11665</ext-link></comment> <object-id pub-id-type="pmid">23172139</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ecker</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Berens</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Cotton</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Subramaniyan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Denfield</surname> <given-names>GH</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>State dependence of noise correlations in macaque primary visual cortex</article-title>. <source>Neuron</source> <volume>82</volume>: <fpage>235</fpage>–<lpage>248</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.02.006" xlink:type="simple">10.1016/j.neuron.2014.02.006</ext-link></comment> <object-id pub-id-type="pmid">24698278</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref074"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ayaz</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Saleem</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Sch√∂lvinck</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Carandini</surname> <given-names>M</given-names></name> (<year>2013</year>) <article-title>Locomotion controls spatial integration in mouse visual cortex</article-title>. <source>Current Biology</source> <volume>23</volume>: <fpage>890</fpage>–<lpage>894</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2013.04.012" xlink:type="simple">10.1016/j.cub.2013.04.012</ext-link></comment> <object-id pub-id-type="pmid">23664971</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref075"><label>75</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Jamison</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Engel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>He</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>He</surname> <given-names>S</given-names></name> (<year>2011</year>) <article-title>Binocular rivalry requires visual attention</article-title>. <source>Neuron</source> <volume>71</volume>: <fpage>362</fpage>–<lpage>369</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.05.035" xlink:type="simple">10.1016/j.neuron.2011.05.035</ext-link></comment> <object-id pub-id-type="pmid">21791293</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref076"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>S-H</given-names></name>, <name name-style="western"><surname>Blake</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name> (<year>2007</year>) <article-title>Hierarchy of cortical responses underlying binocular rivalry</article-title>. <source>Nature neuroscience</source> <volume>10</volume>: <fpage>1048</fpage>–<lpage>1054</lpage>. <object-id pub-id-type="pmid">17632508</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref077"><label>77</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sengpiel</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Vorobyov</surname> <given-names>V</given-names></name> (<year>2005</year>) <article-title>Intracortical origins of interocular suppression in the visual cortex</article-title>. <source>The Journal of Neuroscience</source> <volume>25</volume>: <fpage>6394</fpage>–<lpage>6400</lpage>. <object-id pub-id-type="pmid">16000630</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref078"><label>78</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McKee</surname> <given-names>SP</given-names></name>, <name name-style="western"><surname>Bravo</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>DG</given-names></name>, <name name-style="western"><surname>Legge</surname> <given-names>GE</given-names></name> (<year>1994</year>) <article-title>Stereo matching precedes dichoptic masking</article-title>. <source>Vision research</source> <volume>34</volume>: <fpage>1047</fpage>–<lpage>1060</lpage>. <object-id pub-id-type="pmid">8160414</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref079"><label>79</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meese</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Hess</surname> <given-names>RF</given-names></name> (<year>2005</year>) <article-title>Interocular suppression is gated by interocular feature matching</article-title>. <source>Vision research</source> <volume>45</volume>: <fpage>9</fpage>–<lpage>15</lpage>. <object-id pub-id-type="pmid">15571734</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref080"><label>80</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ooi</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>He</surname> <given-names>ZJ</given-names></name> (<year>2006</year>) <article-title>Binocular rivalry and surface-boundary processing</article-title>. <source>Perception</source> <volume>35</volume>: <fpage>581</fpage>. <object-id pub-id-type="pmid">16836052</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref081"><label>81</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blake</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Logothetis</surname> <given-names>NK</given-names></name> (<year>2002</year>) <article-title>Visual competition</article-title>. <source>Nature Reviews Neuroscience</source> <volume>3</volume>: <fpage>13</fpage>–<lpage>21</lpage>. <object-id pub-id-type="pmid">11823801</object-id></mixed-citation></ref>
<ref id="pcbi.1004510.ref082"><label>82</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsuchiya</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Gilroy</surname> <given-names>LA</given-names></name>, <name name-style="western"><surname>Blake</surname> <given-names>R</given-names></name> (<year>2006</year>) <article-title>Depth of interocular suppression associated with continuous flash suppression, flash suppression, and binocular rivalry</article-title>. <source>Journal of Vision</source> <volume>6</volume>: <fpage>6</fpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">09-PLCB-RA-0832R4</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000759</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience/Animal Cognition</subject><subject>Neuroscience/Theoretical Neuroscience</subject></subj-group></article-categories><title-group><article-title>How Informative Are Spatial CA3 Representations Established by the Dentate Gyrus?</article-title><alt-title alt-title-type="running-head">Sparse Mossy Fibers Help Set Up CA3 Memories</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Cerasti</surname><given-names>Erika</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Treves</surname><given-names>Alessandro</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>SISSA, Cognitive Neuroscience Sector, Trieste, Italy</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Kavli Institute for Systems Neuroscience and Centre for the Biology of Memory, NTNU, Trondheim, Norway</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Graham</surname><given-names>Lyle J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">Université Paris Descartes, Centre National de la Recherche Scientifique, France</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">cerasti@sissa.it</email></corresp>
<fn fn-type="con"><p>Analyzed the data: EC. Wrote the paper: EC AT. Carried out the mathematical analysis of the model and the computer simulations: EC. Designed the model, participated in its analysis and supervised the simulations: AT.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>4</month><year>2010</year></pub-date><pub-date pub-type="epub"><day>29</day><month>4</month><year>2010</year></pub-date><volume>6</volume><issue>4</issue><elocation-id>e1000759</elocation-id><history>
<date date-type="received"><day>14</day><month>7</month><year>2009</year></date>
<date date-type="accepted"><day>24</day><month>3</month><year>2010</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2010</copyright-year><copyright-holder>Cerasti, Treves</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>In the mammalian hippocampus, the dentate gyrus (DG) is characterized by sparse and powerful unidirectional projections to CA3 pyramidal cells, the so-called mossy fibers. Mossy fiber synapses appear to duplicate, in terms of the information they convey, what CA3 cells already receive from entorhinal cortex layer II cells, which project both to the dentate gyrus and to CA3. Computational models of episodic memory have hypothesized that the function of the mossy fibers is to enforce a new, well separated pattern of activity onto CA3 cells, to represent a new memory, prevailing over the interference produced by the traces of older memories already stored on CA3 recurrent collateral connections. Can this hypothesis apply also to spatial representations, as described by recent neurophysiological recordings in rats? To address this issue quantitatively, we estimate the amount of information DG can impart on a new CA3 pattern of spatial activity, using both mathematical analysis and computer simulations of a simplified model. We confirm that, also in the spatial case, the observed sparse connectivity and level of activity are most appropriate for driving memory storage – and not to initiate retrieval. Surprisingly, the model also indicates that even when DG codes just for space, much of the information it passes on to CA3 acquires a non-spatial and episodic character, akin to that of a random number generator. It is suggested that further hippocampal processing is required to make full spatial use of DG inputs.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>The CA3 region at the core of the hippocampus, a structure crucial to memory formation, presents one striking anatomical feature. Its neurons receive many thousands of weak inputs from other sources, but only a few tens of very strong inputs from the neurons in the directly preceding region, the dentate gyrus. It had been proposed that such sparse connectivity helps the dentate gyrus to drive CA3 activity during the storage of new memories, but why it needs to be so sparse had remained unclear. Recent recordings of neuronal activity in the dentate gyrus (Leutgeb, et al. 2007) show the firing maps of granule cells of rodents engaged in exploration: the few cells active in a given environment, about 3% of the total, present multiple firing fields. Following these findings, we could now construct a network model that addresses the question quantitatively. Both mathematical analysis and computer simulations of the model show that, while the memory system would function also otherwise, connections as sparse as those observed make it function optimally, in terms of the bits of information new memories contain. Much of this information, we show, is encoded however in a difficult format, suggesting that other regions of the hippocampus, until now with no clear role, may contribute to decode it.</p>
</abstract><funding-group><funding-statement>This work was partially supported by the EU Spacebrain grant. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="16"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>The hippocampus presents the same organizaton across mammals, and distinct ones in reptiles and in birds. A most prominent and intriguing feature of the mammalian hippocampus is the dentate gyrus (DG). As reviewed in <xref ref-type="bibr" rid="pcbi.1000759-Treves1">[1]</xref>, the dentate gyrus is positioned as a sort of intermediate station in the information flow between the entorhinal cortex and the CA3 region of the hippocampus proper. Since CA3 receives also direct, <italic>perforant path</italic> connections from entorhinal cortex, the DG inputs to CA3, called <italic>mossy fibers</italic>, appear to essentially duplicate the information that CA3 can already receive directly from the source. What may be the function of such a duplication?</p>
<p>Within the view that the <italic>recurrent</italic> CA3 network operates as an autoassociative memory <xref ref-type="bibr" rid="pcbi.1000759-McNaughton1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Rolls1">[3]</xref>, it has been suggested that the mossy fibers (MF) inputs are those that drive the storage of new representations, whereas the perforant path (PP) inputs relay the cue that initiates the retrieval of a previously stored representation, through <italic>attractor dynamics</italic>, due largely to recurrent connections (RC). Such a proposal is supported by a mathematical model which allows a rough estimate of the amount of information, in bits, that different inputs may impart to a new CA3 representation <xref ref-type="bibr" rid="pcbi.1000759-Treves2">[4]</xref>. That model, however, is formulated in the Marr <xref ref-type="bibr" rid="pcbi.1000759-Marr1">[5]</xref> framework of <italic>discrete</italic> memory states, each of which is represented by a single activity configuration or firing pattern.</p>
<p>Conversely, the prediction that MF inputs may be important for storage and not for retrieval has received tentative experimental support from experiments with spatial tasks, either the Morris water maze <xref ref-type="bibr" rid="pcbi.1000759-Lassalle1">[6]</xref> or a dry maze <xref ref-type="bibr" rid="pcbi.1000759-Lee1">[7]</xref>. Two-dimensional spatial representations, to be compatible with the attractor dynamics scenario, require a multiplicity of memory states, which approximate a 2D continuous manifold, isomorphic to the spatial environment to be represented. Moreover, there has to be of course a multiplicity of manifolds, to represent distinct environments with complete remapping from one to the other <xref ref-type="bibr" rid="pcbi.1000759-Leutgeb1">[8]</xref>. Attractor dynamics then occurs along the dimensions locally orthogonal to each manifold, as in the simplified “multi-chart” model <xref ref-type="bibr" rid="pcbi.1000759-Samsonovich1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Battaglia1">[10]</xref>, whereas tangentially one expects marginal stability, allowing for small signals related to the movement of the animal, reflecting changing sensory cues as well as path integration, to displace a “bump” of activity on the manifold, as appropriate <xref ref-type="bibr" rid="pcbi.1000759-Samsonovich1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Stringer1">[11]</xref>.</p>
<p>Although the notion of a really continuous attractor manifold appears as a limit case, which can only be approximated by a network of finite size <xref ref-type="bibr" rid="pcbi.1000759-Tsodyks1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Hamaguchi1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Papp1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Roudi1">[15]</xref>, even the limit case raises the issue of how a 2D attractor manifold can be established. In the rodent hippocampus, the above theoretical suggestion and experimental evidence point at a dominant role of the dentate gyrus, but it has remained unclear how the dentate gyrus, with its MF projections to CA3, can drive the establishment not just of a discrete pattern of activity, as envisaged by <xref ref-type="bibr" rid="pcbi.1000759-Treves2">[4]</xref>, but of an entire spatial representation, in its full 2D glory. This paper reports the analysis of a simplified mathematical model aimed at addressing this issue in a quantitative, information theoretical fashion.</p>
<p>Such an analysis would have been difficult even only a few years ago, before the experimental discoveries that largely clarified, in the rodent, the nature of the spatial representations in the regions that feed into CA3. First, roughly half of the entorhinal PP inputs, those coming from layer II of the <italic>medial</italic> portion of entorhinal cortex, were found to be often in the form of <italic>grid cells</italic>, i.e. units that are activated when the animal is in one of multiple regions, arranged on a regular triangular grid <xref ref-type="bibr" rid="pcbi.1000759-Hafting1">[16]</xref>. Second, the sparse activity earlier described in DG granule cells <xref ref-type="bibr" rid="pcbi.1000759-Jung1">[17]</xref> was found to be concentrated on cells also with multiple fields, but irregularly arranged in the environment <xref ref-type="bibr" rid="pcbi.1000759-Leutgeb2">[18]</xref>. These discoveries can now inform a simplified mathematical model, which would have earlier been based on ill-defined assumptions. Third, over the last decade <italic>neurogenesis</italic> in the adult dentate gyrus has been established as a quantitatively constrained but still significant phenomenon, stimulating novel ideas about its functional role <xref ref-type="bibr" rid="pcbi.1000759-Aimone1">[19]</xref>. The first and third of these phenomena will be considered in extended versions of our model, to be analysed elsewhere; here, we focus on the role of the multiple DG place fields in establishing novel CA3 representations.</p>
<sec id="s1a">
<title>A simplified mathematical model</title>
<p>The complete model considers the firing rate of a CA3 pyramidal cell, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e001" xlink:type="simple"/></inline-formula>, to be determined by the firing rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e002" xlink:type="simple"/></inline-formula> of other cells in CA3, which influence it through RC connections; by the firing rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e003" xlink:type="simple"/></inline-formula> of DG granule cells, which feed into it through MF connections; by the firing rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e004" xlink:type="simple"/></inline-formula> of layer II pyramidal cells in entorhinal cortex (medial and lateral), which project to CA3 through PP axons; and by various feedforward and feedback inhibitory units. A most important simplification is that the fine temporal dynamics, e.g. on theta and gamma time scales, is neglected altogether, so that with “firing rate” we mean an average over a time of order the theta period, a hundred <italic>msec</italic> or so. Very recent evidence indicates, in fact, that only one of two competing spatial representations tends to be active in CA3 within each theta period [Jezek et al, SfN abstract, 2009]. Information coding over shorter time scales would require anyway a more complex analysis, which is left to future refinements of the model.</p>
<p>For the different systems of connections, we assume the existence of anatomical synapses between any two cells to be represented by fixed binary matrices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e005" xlink:type="simple"/></inline-formula> taking 0 or 1 values, whereas the efficacy of those synapses to be described by matrices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e006" xlink:type="simple"/></inline-formula>. Since they have been argued to have a minor influence on coding properties and storage capacity <xref ref-type="bibr" rid="pcbi.1000759-Treves3">[20]</xref>, consistent with the diffuse spatial firing of inhibitory interneurons <xref ref-type="bibr" rid="pcbi.1000759-Wilson1">[21]</xref>, the effect of inhibition and of the current threshold for activating a cell are summarized into a subtractive term, of which we denote with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e007" xlink:type="simple"/></inline-formula> the mean value across CA3 cells, and with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e008" xlink:type="simple"/></inline-formula> the deviation from the mean for a particular cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e009" xlink:type="simple"/></inline-formula>.</p>
<p>Assuming finally a simple threshold-linear activation function <xref ref-type="bibr" rid="pcbi.1000759-Treves4">[22]</xref> for the relation between the activating current and the output firing rate, we write<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e010" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e011" xlink:type="simple"/></inline-formula> indicates taking the sum inside the brackets if positive in value, and zero if negative, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e012" xlink:type="simple"/></inline-formula> is a gain factor. The firing rates of the various populations are all assumed to depend on the position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e013" xlink:type="simple"/></inline-formula> of the animal, and the notation is chosen to minimize differences with our previous analyses of other components of the hippocampal system (e.g. <xref ref-type="bibr" rid="pcbi.1000759-Treves4">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Kropff1">[23]</xref>).</p>
</sec><sec id="s1b">
<title>The storage of a new representation</title>
<p>When the animal is exposed to a new environment, we make the drastic modelling assumption that the new CA3 representation be driven solely by MF inputs, while PP and RC inputs provide interfering information, reflecting the storage of previous representations on those synaptic systems, i.e., noise. Such “noise” can in fact act as an undesired signal and bring about the retrieval of a previous, “wrong” representation, an interesting process which is not however analysed here. We reabsorb the mean of such noise into the mean of the “threshold+inhibition” term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e014" xlink:type="simple"/></inline-formula> and similarly for the deviation from the mean. We use the same symbols for the new variables incorporating RC and PP interference, but removing in both cases the “<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e015" xlink:type="simple"/></inline-formula>” sign, thus writing<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e016" xlink:type="simple"/><label>(2)</label></disp-formula>where the gain has been set to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e017" xlink:type="simple"/></inline-formula>, without loss of generality, by an appropriate choice of the units in which to measure <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e018" xlink:type="simple"/></inline-formula> (pure numbers) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e019" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e020" xlink:type="simple"/></inline-formula>).</p>
<p>As for the MF inputs, we consider a couple of simplified models that capture the essential finding by <xref ref-type="bibr" rid="pcbi.1000759-Leutgeb2">[18]</xref>, of the irregularly arranged multiple fields, as well as the observed low activity level of DG granule cells <xref ref-type="bibr" rid="pcbi.1000759-Chawla1">[24]</xref>, while retaining the mathematical simplicity that favours an analytical treatment. We thus assume that only a randomly selected fraction <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e021" xlink:type="simple"/></inline-formula> of the granule cells are active in a new environment, of size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e022" xlink:type="simple"/></inline-formula>, and that those units are active in a variable number <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e023" xlink:type="simple"/></inline-formula> of locations, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e024" xlink:type="simple"/></inline-formula> drawn from a distribution with mean <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e025" xlink:type="simple"/></inline-formula>. In model A, which we take as our reference, the distribution is taken to be Poisson (the data reported by Leutgeb et al <xref ref-type="bibr" rid="pcbi.1000759-Leutgeb2">[18]</xref> are fit very well by a Poisson distribution with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e026" xlink:type="simple"/></inline-formula>, but their sampling is limited). In model B, which we use as a variant, the distribution is taken to be exponential (this better describes the results of the simulations in <xref ref-type="bibr" rid="pcbi.1000759-Si1">[25]</xref>, though that simple model may well be inappropriate). Therefore, in either model, the firing rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e027" xlink:type="simple"/></inline-formula> of DG unit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e028" xlink:type="simple"/></inline-formula> is a combination of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e029" xlink:type="simple"/></inline-formula> gaussian “bumps”, or fields, of equal effective size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e030" xlink:type="simple"/></inline-formula> and equal height <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e031" xlink:type="simple"/></inline-formula>, centered at random points <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e032" xlink:type="simple"/></inline-formula> in the new environment<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e033" xlink:type="simple"/><label>(3)</label></disp-formula></p>
<p>The informative inputs driving the firing of a CA3 pyramidal cell, during storage of a new representation, result therefore from a combination of three distributions, in the model. The first, Poisson but close to normal, determines the MF connectivity, that is how it is that each CA3 unit receives only a few tens of connections out of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e034" xlink:type="simple"/></inline-formula> granule cells (in the rat), whereby <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e035" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e036" xlink:type="simple"/></inline-formula>. The second, Poisson, determines which of the DG units presynaptic to a CA3 unit is active in the new environment, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e037" xlink:type="simple"/></inline-formula>. The third, either Poisson or exponential (and see model C below), determines how many fields an active DG unit has in the new environment. Note that in the rat <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e038" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1000759-Amaral1">[26]</xref> whereas <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e039" xlink:type="simple"/></inline-formula>, even when considering presumed newborn neurons <xref ref-type="bibr" rid="pcbi.1000759-Chawla1">[24]</xref>. As a result, the total number of active DG units presynaptic to a given CA3 unit, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e040" xlink:type="simple"/></inline-formula>, is of order one, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e041" xlink:type="simple"/></inline-formula>, so that the second Poisson distribution effectively dominates over the first, and the number of active MF impinging on a CA3 unit can approximately be taken to be itself a Poisson variable with mean <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e042" xlink:type="simple"/></inline-formula>. As a qualification to such an approximation, one has to consider that different CA3 pyramidal cells, among the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e043" xlink:type="simple"/></inline-formula> present in the rat (on each side), occasionally receive inputs from the <italic>same</italic> active DG granule cells, but rarely, as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e044" xlink:type="simple"/></inline-formula>, hence the pool of active units <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e045" xlink:type="simple"/></inline-formula> is only one order of magnitude smaller than the population of receiving units <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e046" xlink:type="simple"/></inline-formula>.</p>
<p>In a further simplification, we consider the MF synaptic weights to be uniform in value, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e047" xlink:type="simple"/></inline-formula>. This assumption, like those of equal height and width of the DG firing fields, is convenient for the analytical treatment but not necessary for the simulations. It will be relaxed later, in the computer simulations addressing the effect of MF synaptic plasticity.</p>
<p>The new representation is therefore taken to be established by an informative signal coming from the dentate gyrus<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e048" xlink:type="simple"/><label>(4)</label></disp-formula>modulated, independently for each CA3 unit, by a noise term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e049" xlink:type="simple"/></inline-formula>, reflecting recurrent and perforant path inputs as well as other sources of variability, and which we take to be normally distributed with zero mean and standard deviation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e050" xlink:type="simple"/></inline-formula>.</p>
<p>The position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e051" xlink:type="simple"/></inline-formula> of the animal determines the firing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e052" xlink:type="simple"/></inline-formula> of DG units, which in turn determine the probability distribution for the firing rate of any given CA3 pyramidal unit<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e053" xlink:type="simple"/></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e054" xlink:type="simple"/></disp-formula>is the integral of the gaussian noise up to given signal-to-noise ratio<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e055" xlink:type="simple"/></disp-formula>and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e056" xlink:type="simple"/></inline-formula> is Heaviside's function vanishing for negative values of its argument. The first term, multiplying Dirac's <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e057" xlink:type="simple"/></inline-formula>, expresses the fact that negative activation values result in zero firing rates, rather than negative rates.</p>
<p>Note that the resulting sparsity, i.e. how many of the CA3 units end up firing significantly at each position, which is a main factor affecting memory storage <xref ref-type="bibr" rid="pcbi.1000759-Wilson1">[21]</xref>, is determined by the threshold <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e058" xlink:type="simple"/></inline-formula>, once the other parameters have been set. The approach taken here is to assume that the system requires the new representation to be sparse and regulates the threshold accordingly. We therefore set the sparsity parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e059" xlink:type="simple"/></inline-formula>, in broad agreement with experimental data <xref ref-type="bibr" rid="pcbi.1000759-Papp1">[14]</xref>, and adjust <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e060" xlink:type="simple"/></inline-formula> (as shown, for the mathematical analysis, in the third section of the <xref ref-type="sec" rid="s4">Methods</xref>).</p>
<p>The distribution of fields per DG unit is given in model A by the Poisson form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e061" xlink:type="simple"/></disp-formula>in model B by the exponential form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e062" xlink:type="simple"/></disp-formula>and we also consider, as another variant, model C, where each DG unit has one and only one field<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e063" xlink:type="simple"/></disp-formula></p>
</sec><sec id="s1c">
<title>Assessing spatial information content</title>
<p>In the model, spatial position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e064" xlink:type="simple"/></inline-formula> is represented by CA3 units, whose activity is informed about position by the activity of DG units. The activity of each DG unit is determined independently of others by its place fields<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e065" xlink:type="simple"/></disp-formula>with<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e066" xlink:type="simple"/></disp-formula>where each contributing field is a gaussian bump<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e067" xlink:type="simple"/></disp-formula>The Mutual Information <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e068" xlink:type="simple"/></inline-formula> quantifies the efficiency with which CA3 activity codes for position, on average, as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e069" xlink:type="simple"/><label>(5)</label></disp-formula>where the outer brackets <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e070" xlink:type="simple"/></inline-formula> indicate that the average is not just over the noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e071" xlink:type="simple"/></inline-formula>, as usual in the estimation of mutual information, but also, in our case, over the <italic>quenched</italic>, i.e. constant but unknown values of the microscopic quantities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e072" xlink:type="simple"/></inline-formula>, the connectivity matrix, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e073" xlink:type="simple"/></inline-formula>, the number of fields per active unit, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e074" xlink:type="simple"/></inline-formula>, their centers. For given values of the quenched variables, the total entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e075" xlink:type="simple"/></inline-formula> and the (average) equivocation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e076" xlink:type="simple"/></inline-formula> are defined as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e077" xlink:type="simple"/><label>(6)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e078" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e079" xlink:type="simple"/></inline-formula> is the area of the given environment; the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e080" xlink:type="simple"/></inline-formula>s are intended in base 2, to yield information values in bits.</p>
<p>The estimation of the mutual information can be approached analytically directly from these formulas, using the replica trick (see <xref ref-type="bibr" rid="pcbi.1000759-Mezard1">[27]</xref>), as shown by <xref ref-type="bibr" rid="pcbi.1000759-Samengo1">[28]</xref> and <xref ref-type="bibr" rid="pcbi.1000759-DelPrete1">[29]</xref>, and briefly described in the first section of the <xref ref-type="sec" rid="s4">Methods</xref>. As in those two studies, however, here too we are only able to complete the derivation in the limit of low signal-to-noise, or more precisely of limited variation, across space, of the signal-to-noise around its mean, that is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e081" xlink:type="simple"/></inline-formula>. In this case we obtain, to first order in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e082" xlink:type="simple"/></inline-formula>, an expression that can be shown to be equivalent to<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e083" xlink:type="simple"/><label>(8)</label></disp-formula>where we use the notation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e084" xlink:type="simple"/></inline-formula> (cp. <xref ref-type="bibr" rid="pcbi.1000759-DelPrete1">[29]</xref>, Eqs.17, 45).</p>
<p>Being limited to the first order in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e085" xlink:type="simple"/></inline-formula>, the expression above can be obtained in a straightforward manner by directly expanding the logarithms, in the large noise limit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e086" xlink:type="simple"/></inline-formula>, in the simpler formula quantifying the information conveyed by a single CA3 unit<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e087" xlink:type="simple"/><label>(9)</label></disp-formula></p>
<p>This single-unit formula cannot quantify the higher-order contributions in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e088" xlink:type="simple"/></inline-formula>, which decrease the information conveyed by a population in which some of the units inevitably convey some of the same information. The replica derivation, instead, in principle would allow one to take into proper account such correlated selectivity, which ultimately results in the information conveyed by large CA3 populations not scaling up linearly with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e089" xlink:type="simple"/></inline-formula>, and saturating instead once enough CA3 units have been sampled, as shown in related models by <xref ref-type="bibr" rid="pcbi.1000759-Samengo1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-DelPrete1">[29]</xref>. In our case however the calculation of e.g. the second order terms in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e090" xlink:type="simple"/></inline-formula> is further complicated by the fact that different CA3 units receive inputs coming from partially overlapping subsets of DG units. This may cause saturation at a lower level, once all DG units have been effectively sampled. The interested reader can follow the derivation sketched in the <xref ref-type="sec" rid="s4">Methods</xref>.</p>
<p>Having to take, in any case, the large noise limit implies that the resulting formula is not really applicable to neuronally plausible values of the parameters, but only to the uninteresting case in which DG units impart very little information onto CA3 units. Therefore we use only the single-unit formula, and resort to computer simulations to assess the effects of correlated DG inputs. The second and third sections of the <xref ref-type="sec" rid="s4">Methods</xref> indicate how to obtain numerical results by evaluating the expression in Eq. 9.</p>
<p>Computer simulations can be used to estimate the information present in samples of CA3 units of arbitrary size, and at arbitrary levels of noise, but at the price of an indirect <italic>decoding</italic> procedure. A decoding step is required because the dimensionality of the space spanned by the CA3 activity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e091" xlink:type="simple"/></inline-formula> is too high. It increases in fact exponentially with the number <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e092" xlink:type="simple"/></inline-formula> of neurons sampled, as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e093" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e094" xlink:type="simple"/></inline-formula> is the number of possible responses of each neuron. The decoding method we use, described in the fourth section of the <xref ref-type="sec" rid="s4">Methods</xref>, leads to two different types of information estimates, based on either the full or reduced localization matrix. The difference between the two, and between them and the analytical estimate, is illustrated under <xref ref-type="sec" rid="s2">Results</xref> and further discussed at the end of the paper.</p>
</sec></sec><sec id="s2">
<title>Results</title>
<p>The essential mechanism described by the model is very simple, as illustrated in <xref ref-type="fig" rid="pcbi-1000759-g001">Fig. 1</xref>. CA3 units which happen to receive a few DG overlapping fields combine them in a resulting field of their own, that can survive thresholding. The devil is in the quantitative details: what proportion of CA3 cells express place fields, how large are the fields, and how strong are the fields compared with the noise, all factors that determine the information contained in the spatial representation. Note that a given CA3 unit can express multiple fields.</p>
<fig id="pcbi-1000759-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.g001</object-id><label>Figure 1</label><caption>
<title>Network scheme.</title>
<p>The DG-CA3 system indicating examples of the fields attributed to DG units and of those resulting in CA3 units, the connectivity between the two populations, and the noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e095" xlink:type="simple"/></inline-formula> that replaces, in the model, also the effect of recurrent connections in CA3.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.g001" xlink:type="simple"/></fig>
<p>It is convenient to discuss such quantitative details with reference to a standard set of parameters. Our model of reference is a network of DG units with fields represented by Gaussian-like functions of space, with the number of fields per each DG units given by a Poisson distribution with mean value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e096" xlink:type="simple"/></inline-formula>, and parameters as specified in <xref ref-type="table" rid="pcbi-1000759-t001">Table 1</xref>.</p>
<table-wrap id="pcbi-1000759-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.t001</object-id><label>Table 1</label><caption>
<title>Parameters: Values used in the standard version of the model.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1000759-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.t001" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">Parameter</td>
<td align="left" colspan="1" rowspan="1">Symbol</td>
<td align="left" colspan="1" rowspan="1">Standard Value</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">probability a DG unit is active in one environment</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e097" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">0.033</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">number of DG inputs to a CA3 unit</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e098" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">50</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">mean number of fields per active DG unit</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e099" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">1.7</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">mean number of fields activating a CA3 unit</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e100" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e101" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">strength of MF inputs</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e102" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">1, otherwise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e103" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">noise affecting CA3 activity</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e104" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">1 (in units in which <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e105" xlink:type="simple"/></inline-formula>)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">sparsity of CA3 activity</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e106" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">0.1</td>
</tr>
</tbody>
</table></alternatives></table-wrap>
<p>In general, the stronger the mean DG input, the more it dominates over the noise, and also the higher the threshold has to be set in CA3 to make the pattern of activity as sparse as required, by fixing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e107" xlink:type="simple"/></inline-formula>. To control for the trivial advantage of a higher signal-to-noise, we perform comparisons in which it is kept fixed, by adjusting e.g. the MF synaptic strength <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e108" xlink:type="simple"/></inline-formula>.</p>
<sec id="s2a">
<title>Multiple input cells vs. multiple fields per cell</title>
<p>The first parameter we considered is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e109" xlink:type="simple"/></inline-formula>, the average number of fields for each DG unit, in light of the recent finding that DG units active in a restricted environment are more likely to have multiple fields than CA3 units, and much more often than expected, given their weak probability of being active <xref ref-type="bibr" rid="pcbi.1000759-Leutgeb2">[18]</xref>. We wondered whether receiving multiple fields from the same input units would be advantageous for CA3, and if so whether there is an optimal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e110" xlink:type="simple"/></inline-formula> value. We therefore estimated the mutual information when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e111" xlink:type="simple"/></inline-formula> varies and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e112" xlink:type="simple"/></inline-formula>, the total mean number of DG fields that each CA3 cell receives as input, is kept fixed, by varying <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e113" xlink:type="simple"/></inline-formula> correspondigly. As shown in <xref ref-type="fig" rid="pcbi-1000759-g002">Fig. 2</xref>, varying <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e114" xlink:type="simple"/></inline-formula> in this manner makes very little difference in the bits conveyed by each CA3 cell. This figure reports the results of computer simulations, that illustrate also the dependence of the mutual information on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e115" xlink:type="simple"/></inline-formula>, the number of cells sampled. The dependence is sub-linear, but rather smooth, with significant fluctuations from sample-to-sample which are largely averaged out in the graph. The different lines correspond to different distributions of the input DG fields among active DG cells projecting to CA3, that is different combinations of values for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e116" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e117" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e118" xlink:type="simple"/></inline-formula> kept constant; these different distributions do not affect much the information in the representation.</p>
<fig id="pcbi-1000759-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.g002</object-id><label>Figure 2</label><caption>
<title>The exact multiplicity of fields in DG units is irrelevant.</title>
<p>Information about position plotted versus the number of CA3 units, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e119" xlink:type="simple"/></inline-formula> from which it is decoded, with the mean number of fields in the input to each CA3 unit constant at the value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e120" xlink:type="simple"/></inline-formula>. Different lines correspond to a different mean number of fields per DG input units, balanced by different mean number of input units per CA3 unit. Inset: analytical estimate of the information per CA3 unit, from numerically integrating Eq. 9.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.g002" xlink:type="simple"/></fig>
<p>The analytical estimate of the information per CA3 unit confirms that there is no dependence on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e121" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1000759-g002">Fig. 2</xref>, inset). This is not a trivial result, as it would be if only the parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e122" xlink:type="simple"/></inline-formula> entered the analytical expression. Instead, the second section of the <xref ref-type="sec" rid="s4">Methods</xref> shows that the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e123" xlink:type="simple"/></inline-formula> of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e124" xlink:type="simple"/></inline-formula>-field decomposition depend separately on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e125" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e126" xlink:type="simple"/></inline-formula>, so the fact that the two separate dependencies almost cancel out in a single dependence on their product, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e127" xlink:type="simple"/></inline-formula>, is remarkable. Moreover, such analytical estimate of the information conveyed by one unit does not match the first datapoints, for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e128" xlink:type="simple"/></inline-formula>, extracted from the computer simulation; it is not higher, as might have been expected considering that the simulation requires an additional information loosing decoding step, but lower, by over a factor of 2. The finding that the analytical estimate differs from, and is in fact much lower than, the slope parameter extracted from the simulations, after the decoding step, is further discussed below. Despite their incongruity in absolute values, neither the estimate derived from the simulations nor the analytical estimate have separate dependencies on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e129" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e130" xlink:type="simple"/></inline-formula>, as shown in <xref ref-type="fig" rid="pcbi-1000759-g002">Fig. 2</xref>.</p>
</sec><sec id="s2b">
<title>More MF connections, but weaker</title>
<p>Motivated by the striking sparsity of MF connections, compared to the thousands of RC and PP synaptic connections impinging on CA3 cells in the rat, we have then tested the effect of changing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e131" xlink:type="simple"/></inline-formula> without changing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e132" xlink:type="simple"/></inline-formula>. In order to vary the mean number of DG units that project to a single CA3 unit, while keeping constant the total mean input strength, assumed to be an independent biophysically constrained parameter, we varied inversely to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e133" xlink:type="simple"/></inline-formula> the synaptic strength parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e134" xlink:type="simple"/></inline-formula>. As shown in <xref ref-type="fig" rid="pcbi-1000759-g003">Fig. 3</xref>, the information presents a maximum at some intermediate value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e135" xlink:type="simple"/></inline-formula>, which is observed both in simulations and in the analytical estimate, despite the fact that again they differ by more than a factor of two.</p>
<fig id="pcbi-1000759-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.g003</object-id><label>Figure 3</label><caption>
<title>A sparse MF connectivity is optimal, but not too sparse.</title>
<p>Left: information plotted versus the number of CA3 cells, with different colors for different values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e136" xlink:type="simple"/></inline-formula>. Dots represent information values obtained from simulations, while curves are exponentially saturating fits to the data points, as described in <xref ref-type="sec" rid="s4">Methods</xref>. Right: plot of the two parameters of the fit curves. Main figure: slope parameter describing the slope of the linear part of the curve (for low <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e137" xlink:type="simple"/></inline-formula>), constrasted with the analytical estimate of the term proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e138" xlink:type="simple"/></inline-formula> (Eq.9); inset: total information parameter, describing the saturation level reached by the curve.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.g003" xlink:type="simple"/></fig>
<p>Again we find that the analytical estimate differs from, and is in fact much lower than, the slope parameter extracted from the simulations, after the decoding ste. Both measures, however, show that the standard model is not indifferent to how sparse are the MF connections. If they are very sparse, most CA3 units receive no inputs from active DG units, and the competition induced by the sparsity constraint tends to be won, at any point in space, by those few CA3 units that are receiving input from just one active DG unit. The resulting mapping is effectively one-to-one, unit-to-unit, and this is not optimal information-wise, because too few CA3 units are active – many of them in fact have multiple fields (<xref ref-type="fig" rid="pcbi-1000759-g004">Fig. 4</xref>, right), reflecting the multiple fields of their “parent” units in DG. As <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e139" xlink:type="simple"/></inline-formula> increases (with a corresponding decrease in MF synaptic weight), the units that win the competition tend to be those that summate inputs from two or more concurrently active DG units. The mapping ceases to be one-to-one, and this increases the amount of information, up to a point. When <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e140" xlink:type="simple"/></inline-formula> is large enough that CA3 units begin to sample more effectively DG activity, those that win the competition tend to be the “happy few” that happen to summate several active DG inputs, and this tends to occur at only one place in the environment. As a result, an ever smaller fraction of CA3 units have place fields, and those tend to have just one, often very irregular, as shown in <xref ref-type="fig" rid="pcbi-1000759-g004">Fig. 4</xref>, right. From that point on, the information in the representation decreases monotonically. The optimal MF connectivity is then in the range which maximizes the fraction of CA3 units that have a field in the newly learned environment, at a value, roughly one third, broadly consistent with experimental data (see e.g. <xref ref-type="bibr" rid="pcbi.1000759-Leutgeb3">[30]</xref>).</p>
<fig id="pcbi-1000759-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.g004</object-id><label>Figure 4</label><caption>
<title>Information vs. connectivity.</title>
<p>Left: Examples of CA3 firing rate maps for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e141" xlink:type="simple"/></inline-formula> (top row); <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e142" xlink:type="simple"/></inline-formula> (middle) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e143" xlink:type="simple"/></inline-formula> (bottom); Right: Histogram that shows the fraction of CA3 units active somewhere in the environment, left, and the fraction of active CA3 units with more than one field, right, for different <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e144" xlink:type="simple"/></inline-formula> values.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.g004" xlink:type="simple"/></fig>
<p>It is important to emphasize that what we are reporting is a quantitative effect: the underlying mechanism is always the same, the random summation of inputs from active DG units. DG in the model effectively operates as a sort of random number generator, whatever the values of the various parameters. How informative are the CA3 representations established by that random number generator, however, depends on the values of the parameters.</p>
</sec><sec id="s2c">
<title>Other DG field distribution models</title>
<p>We repeated the simulations using other models for the DG fields distribution, the exponential (model B) and the single field one (model C), and the results are similar to those obtained for model A: the information has a maximum when varying <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e145" xlink:type="simple"/></inline-formula> on its own, and is instead roughly constant if the parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e146" xlink:type="simple"/></inline-formula> is held constant (by varying <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e147" xlink:type="simple"/></inline-formula> inversely to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e148" xlink:type="simple"/></inline-formula>). <xref ref-type="fig" rid="pcbi-1000759-g005">Fig. 5</xref> reports the comparison, as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e149" xlink:type="simple"/></inline-formula> varies, between models A and B, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e150" xlink:type="simple"/></inline-formula>, and model C, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e151" xlink:type="simple"/></inline-formula>, so that in this latter case the inputs are 1/1.7 times weaker (we did not compensate by multiplying <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e152" xlink:type="simple"/></inline-formula> by 1.7). Information measures are obtained by decoding several samples of 10 units, averaging and dividing by 10, and not by extracting the fit parameters. As one can see, the lower mean input for model C leads to lower information values, but the trend with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e153" xlink:type="simple"/></inline-formula> is the same in all three models. This further indicates that the multiplicity of fields in DG units, as well as its exact distribution, is of no major consequence, if comparisons are made keeping constant the mean number of fields in the input to a CA3 unit.</p>
<fig id="pcbi-1000759-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.g005</object-id><label>Figure 5</label><caption>
<title>Information vs. connectivity.</title>
<p>Information plotted versus different values of connectivity between DG and CA3. Solid lines are all from simulations (localization information from samples of 10 units, divided by 10), as follows: for the blue line, the distribution defining the number of fields in DG cells is Poisson (model A); for the green line, it is exponential (model B); and for the red line, each DG active unit has one field only (model C).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.g005" xlink:type="simple"/></fig></sec><sec id="s2d">
<title>Sparsity of DG activity</title>
<p>We study also how the level of DG activity affects the information flow. We choose diffferent values for the probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e154" xlink:type="simple"/></inline-formula> that a single DG unit fires in the given environment, and again we adjust the synaptic weight <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e155" xlink:type="simple"/></inline-formula> to keep the mean DG input per CA3 cell constant across the comparisons.</p>
<p>Results are simular to those obtained varying the sparsity of the MF connections (<xref ref-type="fig" rid="pcbi-1000759-g006">Fig. 6</xref>). Indeed, the analytical estimate in the two conditions would be exactly the same, within the approximation with which we compute it, because the two parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e156" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e157" xlink:type="simple"/></inline-formula> enter the calculation in equivalent form, as a product. The actual difference between the two parameters stems from the fact that increasing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e158" xlink:type="simple"/></inline-formula>, CA3 units end up sampling more and more the same limited population of active DG units, while increasing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e159" xlink:type="simple"/></inline-formula> this population increases in size. This difference can only be appreciated from the simulations, which however show that the main effect remains the same: an information maximum for rather sparse DG activity (and sparse MF connections), The subtle difference between varying the two parameters can be seen better in the saturation information value: with reference to the standard case, in the center of the graph in the inset, to the right increasing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e160" xlink:type="simple"/></inline-formula> leads to more information than increasing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e161" xlink:type="simple"/></inline-formula>, while to the left the opposite is the case, as expected.</p>
<fig id="pcbi-1000759-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.g006</object-id><label>Figure 6</label><caption>
<title>Sparse DG activity is effective at driving CA3.</title>
<p>Left: Information plotted versus the number of CA3 units, different colors correspond to different values for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e162" xlink:type="simple"/></inline-formula>. Dots represent information values obtained from simulations, while the curves are exponentially saturating fits to the data points, as described in <xref ref-type="sec" rid="s4">Methods</xref>. Right: Plot of the two parameters of the fits. Main figure: slope parameter describing the slope of the linear part of the information curve (for low <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e163" xlink:type="simple"/></inline-formula>); inset: total information parameter describing the saturation level reached by the information - both are contrasted with the corresponding measures (dashed lines) obtained varying <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e164" xlink:type="simple"/></inline-formula> instead of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e165" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.g006" xlink:type="simple"/></fig></sec><sec id="s2e">
<title>Full and simplified decoding procedures</title>
<p>As noted above, we find that the analytical estimate of the information per unit is always considerably lower than the slope parameter of the fit to the measures extracted from the simulations, contrary to expectations, since the latter require an additional decoding step, which implies some loss of information. We also find, however, that the measures of mutual information that we extract from the simulations are strongly dependent on the method used, in the decoding step, to construct the “localization matrix”, i.e. the matrix which compiles the frequency with which the virtual rat was decoded as being in position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e166" xlink:type="simple"/></inline-formula> when it was actually in position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e167" xlink:type="simple"/></inline-formula>. All measures reported so far, from simulations, are obtained constructing what we call the <italic>full</italic> localization matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e168" xlink:type="simple"/></inline-formula> which, if the square environment is discretized into <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e169" xlink:type="simple"/></inline-formula> spatial bins, is a large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e170" xlink:type="simple"/></inline-formula> matrix, which requires of order 160,000 decoding events to be effectively sampled. We run simulations with trajectories of 400,000 steps, and additionally corrected the information measures to avoid the limited sampling bias <xref ref-type="bibr" rid="pcbi.1000759-Treves5">[31]</xref>.</p>
<p>An alternative, that allows extracting unbiased measures from much shorter simulations, is to construct a simplified matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e171" xlink:type="simple"/></inline-formula>, which averages over decoding events with the same vector displacement between actual and decoded positions. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e172" xlink:type="simple"/></inline-formula> is easily constructed on the torus we used in all simulations, and being a much smaller <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e173" xlink:type="simple"/></inline-formula> matrix it is effectively sampled in just a few thousand steps.</p>
<p>The two decoding procedures, given that the simplified matrix is the shifted average of the rows of the full matrix, might be expected to yield similar measures, but they do not, as shown in <xref ref-type="fig" rid="pcbi-1000759-g007">Fig. 7</xref>. The simplified matrix, by assuming translation invariance of the errors in decoding, is unable to quantify the information implicitly present in the full distribution of errors around each actual position. Such errors are of an “episodic” nature: the local view from position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e174" xlink:type="simple"/></inline-formula> might happen to be similar to that from position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e175" xlink:type="simple"/></inline-formula>, hence neural activity reflecting in part local views might lead to confuse the two positions, but this does not imply that another position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e176" xlink:type="simple"/></inline-formula> has anything in common with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e177" xlink:type="simple"/></inline-formula>. Our little network model captures this discrepancy, in showing, in <xref ref-type="fig" rid="pcbi-1000759-g007">Fig. 7</xref>, that for any actual position there are a few selected position that are likely to be erroneously decoded from the activity of a given sample of units; when constructing instead the translationally invariant simplified matrix, all average errors are distributed smoothly around the correct position (zero error), in a roughly Gaussian bell. The upper right panel in <xref ref-type="fig" rid="pcbi-1000759-g007">Fig. 7</xref> shows that such episodic information always prevails, whatever the connectivity, i.e. in all three parameter regimes illustrated in <xref ref-type="fig" rid="pcbi-1000759-g004">Fig. 4</xref>. The lower right panel in <xref ref-type="fig" rid="pcbi-1000759-g007">Fig. 7</xref> compares, instead, the entropies of the decoded positions with the two matrices, conditioned on the actual position – that is, the <italic>equivocation</italic> values. Unlike the mutual information, such equivocation is much higher for the simplified matrix; for this matrix, it is simply a measure of how widely displaced are decoded positions, with respect to the actual positions, represented at the center of the square; and for small samples of units, which are not very informative, the “displacement” entropy approaches that of a flat distribution of decoded positions, i.e. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e178" xlink:type="simple"/></inline-formula> <italic>bits</italic>. For larger samples, which enable better localization, the simplified localization matrix begins to be clustered in a Gaussian bell around zero displacement, so that the equivocation gradually decreases (the list of displacements, with their frequencies, is computed for each sample, and it is the equivocation, not the list itself, which is averaged across samples). In contrast, the entropy of each row of the full localization matrix, i.e. the entropy of decoded positions conditioned on any actual position, is lower, and also decreasing more steeply with sample size; it differs from the full entropy, in fact, by the mutual information between decoded and actual positions, which <italic>increases</italic> with sample size. The two equivocation measures therefore both add up to the two mutual information measures to yield the same full entropy of about 8.64 bits (a bit less in the case of the full matrix, where the sampling is more limited), and thus serve as controls that the difference in mutual information is not due, for example, to inaccuracy. As a third crucial control, we calculated also the average conditional entropy of the full localization matrix, when the matrix is averaged across samples of a given size: the resulting entropy is virtually identical to the displacement entropy (which implies instead an average of the full matrix across rows, i.e. across actual positions). This indicates that different samples of units express distinct episodic content at each location, such that averaging across samples is equivalent to averaging across locations.</p>
<fig id="pcbi-1000759-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.g007</object-id><label>Figure 7</label><caption>
<title>Localization matrices.</title>
<p>Left: the rows of the full matrix represent the actual positions of the virtual rat while its columns represent decoded positions (the full matrix is actually <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e179" xlink:type="simple"/></inline-formula>); three examples of rows are shown, rendered here as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e180" xlink:type="simple"/></inline-formula> squares, all from decoding by a given sample of 10 units. The simplified matrix is a single <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e181" xlink:type="simple"/></inline-formula> matrix obtained (from the same sample) as the average of the full matrix taking into account traslation invariance. Right, top: the two procedures lead to large quantitative differences in information (here, the measures from samples of 10 units, divided by 10, from the full matrix, cyan, and from the simplified matrix, black), but with the same dependence on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e182" xlink:type="simple"/></inline-formula>. Right, bottom: The conditional entropies of the full and simplified localization matrices (cyan and black, dashed) in both cases add up to the respective mutual information measure (cyan and black, solid) to give the full entropy of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e183" xlink:type="simple"/></inline-formula> <italic>bits</italic> (green line). The conditional entropy calculated from the full matrix averaged across samples (red, dashed) is equivalent to that calculated from the displacements, for each sample (black, dashed).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.g007" xlink:type="simple"/></fig>
<p>Apparently, also the analytical estimate is unable to capture the spatial information implicit in such “episodic” errors, as its values are well below those obtained with the full matrix, and somewhat above those obtained with the simplified matrix (consistent with some loss with decoding). One may wonder how can the information from the full localization matrix (which also requires a decoding step) be higher than the decoding-free analytical estimate, without violating the basic information processing theorem. The solution to the riddle, as we understand it, is subtle: when decoding, one takes essentially a maximum likelihood estimate, assigning a unique decoded position per trial, or time step. This leads to a “quantized” localization matrix, which in general tends to have substantially higher information content than the “smoothed” matrix based on probabilities <xref ref-type="bibr" rid="pcbi.1000759-Rolls2">[32]</xref>. In the analytical derivation there is no concept of trial, time step or maximal likelihood, and the matrix expresses smoothly varying probabilities. The more technical implications are discussed further at the end of the <xref ref-type="sec" rid="s4">Methods</xref>. These differences do not alter the other results of our study, since they affect the height of the curves, not their shape, however they have important implications. The simplified matrix has the advantage of requiring much less data, i.e. less simulation time, but also less real data if applied to neurophysiological recordings, than the full matrix, and in most situations it might be the only feasible measure of spatial information (the analytical estimate is not available of course for real data). So in most cases it is only practical to measure spatial information with methods that, our model suggests, miss out much of the information present in neuronal activity, what we may refer to as “dark information”, not easily revealed. One might conjecture that the prevalence of dark information is linked to the random nature of the spatial code established by DG inputs. It might be that additional stages of hippocampal processing, either with the refinement of recurrent CA3 connections or in CA1, are instrumental in making dark information more transparent.</p>
</sec><sec id="s2f">
<title>Effect of learning on the mossy fibers</title>
<p>While the results reported this far assume that MF weights are fixed, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e184" xlink:type="simple"/></inline-formula>, we have also conducted a preliminary analysis of how the amount of spatial information in CA3 might change as a consequence of plasticity on the mossy fibers. In an extension of the standard model, we allow the weights of the connections between DG and CA3 to change with a model “Hebbian” rule. This is not an attempt to capture the nature of MF plasticity, which is not NMDA-dependent and might not be associative <xref ref-type="bibr" rid="pcbi.1000759-Nicoll1">[33]</xref>, but only the adoption of a simple plasticity model that we use in other simulations. At each time step (that corresponds to a different place in space) weights are taken to change as follows:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e185" xlink:type="simple"/><label>(10)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e186" xlink:type="simple"/></inline-formula> is a plasticity factor that regulates the amount of learning. Modifying in this way the MF weights has the general effect of increasing information values, so that they approach saturation levels for lower number of CA3 cells; in particular this is true for the information extracted from both full and simplified matrices. In <xref ref-type="fig" rid="pcbi-1000759-g008">Fig. 8</xref>, the effect of such “learning” is shown for different values of the parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e187" xlink:type="simple"/></inline-formula>, as a function of connectivity.</p>
<fig id="pcbi-1000759-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.g008</object-id><label>Figure 8</label><caption>
<title>Information vs. connectivity for different levels of learning.</title>
<p>Information is plotted as a function of the connectivity level between DG and CA3, different colors correspond to different values of the learning factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e188" xlink:type="simple"/></inline-formula>. Simulations run for 100,000 training steps, during a fraction <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e189" xlink:type="simple"/></inline-formula> of which each postsynaptic units is strongly activated, and its incoming weights liable to be modified. The <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e190" xlink:type="simple"/></inline-formula> values tested hence span the range from minor modification of the existing weight, for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e191" xlink:type="simple"/></inline-formula>, to major restructuring of all available weights for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e192" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.g008" xlink:type="simple"/></fig>
<p>We see that allowing for this type of plasticity on mossy fibers leads to shift the maximum of information as a function of the connectivity level. The structuring of the weights effectively results in the selection of favorite input connections, for each CA3 unit, among a pool of availables ones; the remaining strong connections are a subset of those “anatomically” present originally. It is logical, then, that starting with a larger pool of connnections, among which to pick the “right” ones, leads to more information than starting with few connections, which further decrease in effective number with plasticity. We expect better models of the details of MF plasticity to preserve this main effect.</p>
<p>A further effect of learning, along with the disappearance of some CA3 fields and the strengthening of others, is the refinement of their shape, as illustrated in <xref ref-type="fig" rid="pcbi-1000759-g009">Fig. 9</xref>. It is likely that also this effect will be observed even when using more biologically accurate models of MF plasticity.</p>
<fig id="pcbi-1000759-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.g009</object-id><label>Figure 9</label><caption>
<title>MF plasticity can suppress, enlarge and in general refine CA3 place fields.</title>
<p>The place fields of five example units are shown before plasticity is turned on (top row) and after 100,000 steps with a large plasticity factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e193" xlink:type="simple"/></inline-formula> (bottom row). The rounding and regularization of the fields was observed also for several other units in the simulation.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.g009" xlink:type="simple"/></fig></sec><sec id="s2g">
<title>Retrieval abilities</title>
<p>Finally, all simulations reported so far involved a full complement of DG inputs at each time step in the simulation. We have also tested the ability of the MF network to <italic>retrieve</italic> a spatial representation when fed with a degraded input signal, with and without MF plasticity. The input is degraded, in our simulation, simply by turning on only a given fraction, randomly selected, of the DG units that would normally be active in the environment. The information extracted after decoding by a sample of units (in <xref ref-type="fig" rid="pcbi-1000759-g010">Fig. 10</xref>, 10 units) is then contrasted with the size of the cue itself. In the absence of MF plasticity, there is obviously no real retrieval process to talk about, and the DG-CA3 network simply relays partial information. When Hebbian plasticity is turned on, the expectation from similar network models (see e.g. <xref ref-type="bibr" rid="pcbi.1000759-Treves6">[34]</xref>, <xref ref-type="fig" rid="pcbi-1000759-g009">Fig. 9</xref>) is that there would be some pattern completion, i.e. some tendency for the network to express nearly complete output information when the input is partial, resulting in a more sigmoidal input-output curve (the exact shape of the curve depends of course also on the particular measure used).</p>
<fig id="pcbi-1000759-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.g010</object-id><label>Figure 10</label><caption>
<title>Information reconstructed from a degraded input signal.</title>
<p>Slope parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e194" xlink:type="simple"/></inline-formula> of the information curve as a function of the percentage of the DG input that CA3 receives. Inset: the same plot for the total information parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e195" xlink:type="simple"/></inline-formula>. The same training protocol was run as for <xref ref-type="fig" rid="pcbi-1000759-g008">Figs. 8</xref>–<xref ref-type="fig" rid="pcbi-1000759-g009">9</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.g010" xlink:type="simple"/></fig>
<p>It is apparent from <xref ref-type="fig" rid="pcbi-1000759-g010">Fig. 10</xref> that while, in the absence of plasticity, both parameters characterizing the information that can be extracted from CA3 grow roughly linearly with the size of the cue, with plasticity the growth is supralinear. This amounts to the statement that the beneficial effects of plasticity require a full cue to be felt – the conceptual opposite to pattern completion, the process of integrating a partial cue using information stored on modified synaptic weights. This result suggests that the sparse MF connectivity is sub-optimal for the associative storage that leads to pattern completion, a role that current perspectives ascribe instead to perforant path and recurrent connections to CA3. The role of the mossy fibers, even if plastic, may be limited to the establishment of new spatial representations.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>Ours is a minimal model, which by design overlooks several of the elements likely to play an important role in the functions of the dentate gyrus - perhaps foremost, neurogenesis <xref ref-type="bibr" rid="pcbi.1000759-Kuhn1">[35]</xref>. Nevertheless, by virtue of its simplicity, the model helps clarify a number of quantitative issues that are important in refining a theoretical perspective of how the dentate gyrus may work.</p>
<p>First, the model indicates that the recently discovered multiplicity of place fields by active dentate granule cells <xref ref-type="bibr" rid="pcbi.1000759-Leutgeb2">[18]</xref> might be just a “fact of life”, with no major computational implications for dentate information processing. Still, requiring that active granule cells express multiple fields seems to lead, in another simple network model (of how dentate activity may result from entorhinal cortex input <xref ref-type="bibr" rid="pcbi.1000759-Si1">[25]</xref>), to the necessity of inputs coming from <italic>lateral</italic> EC, as well as from <italic>medial</italic> EC. The lateral EC inputs need not carry any spatial information but help to select the DG cells active in one environment. Thus the multiplicity of DG fields refines the computational constraints on the operation of hippocampal circuits.</p>
<p>Second, the model shows that, assuming a fixed total MF input strength on CA3 units, it is beneficial in information terms for the MF connectivity to be very sparse; but not vanishingly sparse. The optimal number of anatomical MF connections on CA3 units, designated as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e196" xlink:type="simple"/></inline-formula> in the model, depends somewhat on the various parameters (the noise in the system, how sparse is the activity in DG and CA3, etc.) and it may increase slightly when taking MF plasticity into account, but it appears within the range of the number, 46, reported for the rat by <xref ref-type="bibr" rid="pcbi.1000759-Amaral1">[26]</xref>. It will be interesting to see whether future measures of MF connectivity in other species correspond to those “predicted” by our model once the appropriate values of the other parameters are also experimentally measured and inserted into the model. A similar set of consideration applies to the fraction of granule cells active in a given environment, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e197" xlink:type="simple"/></inline-formula>, which in the model plays a similar, though not completely identical, role to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e198" xlink:type="simple"/></inline-formula> in determining information content.</p>
<p>Third, the model confirms that the sparse MF connections, even when endowed with associative plasticity, are not appropriate as devices to store associations between input and output patterns of activity – they are just too sparse. This reinforces the earlier theoretical view <xref ref-type="bibr" rid="pcbi.1000759-McNaughton1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Treves2">[4]</xref>, which was not based however on an analysis of spatial representations, that the role of the dentate gyrus is in establishing new CA3 representations and not in associating them to representations expressed elsewhere in the system. Availing itself of more precise experimental paramaters, and based on the spatial analysis, the current model can refine the earlier theoretical view and correct, for example, the notion that “detonator” synapses, firing CA3 cells on a one-to-one basis, would be optimal for the mossy fiber system. The optimal situation turns out to be the one in which CA3 units are fired by the combination of a couple of DG input units, although this is only a statistical statement. Whatever the exact distribution of the number of coincident inputs to CA3, DG can be seen as a sort of <italic>random pattern generator</italic>, that sets up a CA3 pattern of activity without any structure that can be related to its anatomical lay-out <xref ref-type="bibr" rid="pcbi.1000759-Redish1">[36]</xref>, or to the identity of the entorhinal cortex units that have activated the dentate gyrus. As with random number generators in digital computers, once the product has been spit out, the exact process that led to it can be forgotten. This is consistent with experimental evidence that inactivating MF transmission or lesioning the DG does not lead to hippocampal memory impairments once the information has already been stored, but leads to impairments in the storage of new information <xref ref-type="bibr" rid="pcbi.1000759-Lassalle1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Lee1">[7]</xref>. The inability of MF connection to subserve pattern completion is also consistent with suggestive evidence from imaging studies with human subjects <xref ref-type="bibr" rid="pcbi.1000759-Bakker1">[37]</xref>.</p>
<p>Fourth, and more novel, our findings imply that a substantial fraction of the information content of a spatial CA3 representation, over half when sampling limited subsets of CA3 units, can neither be extracted through the simplified method which assumes translation invariance, nor assessed through the analytical method (which anyway requires an underlying model of neuronal firing, and is hence only indirectly applicable to real neuronal data). This large fraction of the information content is only extracted through the time-consuming construction of the full localization matrix. To avoid the limited sampling bias <xref ref-type="bibr" rid="pcbi.1000759-Panzeri1">[38]</xref> this would require, in our hands, the equivalent of a ten hour session of recording from a running rat (!), with a square box sampled in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e199" xlink:type="simple"/></inline-formula> spatial bins. We have hence labeled this large fraction as <italic>dark information</italic>, which requires a special effort to reveal. Although we know little of how the real system decodes its own activity, e.g. in downstream neuronal populations, we may hypothesize that the difficulty at extracting dark information affects the real system as well, and that successive stages of hippocampal processing have evolved to address this issue. If so, qualitatively this could be characterized as the representation established in CA3 being <italic>episodic</italic>, i.e. based on an effectively random process that is functionally forgotten once completed, and later processing, e.g. in CA1, may be thought to gradually endow the representations with their appropriate continuous spatial character. Another network model, intended to elucidate how CA1 could operate in this respect, is the object of our on-going analysis.</p>
<p>The model analysed here does not include neurogenesis, a most striking dentate phenomenon, and thus it cannot comment on several intriguing models that have been put forward about the role of neurogenesis in the adult mammalian hippocampus <xref ref-type="bibr" rid="pcbi.1000759-Aimone2">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Becker1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Wiskott1">[41]</xref>. Nevertheless, presenting a simple and readily expandable model of dentate operation can facilitate the development of further models that address neurogenesis, and help interpret puzzling experimental observations. For example, the idea that once matured newborn cells may temporally “label” memories of episodes occurring over a few weeks <xref ref-type="bibr" rid="pcbi.1000759-Kee1">[42]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Ge1">[43]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Buzzetti1">[44]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Tashiro1">[45]</xref> has been weakened by the observation that apparently even young adult-born cells, which are not that many <xref ref-type="bibr" rid="pcbi.1000759-Tashiro1">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-Cameron1">[46]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-McDonald1">[47]</xref>, are very sparsely active, perhaps only a factor of two or so more active than older granule cells <xref ref-type="bibr" rid="pcbi.1000759-Chawla1">[24]</xref>. Maybe such skepticism should be reconsidered, and the issue reanalysed using a quantitative model like ours. One could then investigate the notion that the new cells link together, rather than separating, patterns of activity with common elements (such as the temporal label). To do that clearly requires extending the model to include a description not only of neurogenesis, but also of plasticity within DG itself <xref ref-type="bibr" rid="pcbi.1000759-McHugh1">[48]</xref> and of its role in the establishment of successive representations one after the other.</p>
</sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<sec id="s4a">
<title>Replica calculation</title>
<sec id="s4a1">
<title>Estimation of the equivocation</title>
<p>Calculating the equivocation from its definition in Eq.7 is straightforward, thanks to the simplifying assumption of independent noise in CA3 units. We get<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e200" xlink:type="simple"/><label>(11)</label></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e201" xlink:type="simple"/></disp-formula>although the spatial integral remains to be carried out.</p>
</sec><sec id="s4a2">
<title>Estimation of the entropy</title>
<p>For the entropy, Eq.6, the calculation is more complicated. Starting from<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e202" xlink:type="simple"/></disp-formula>we remove the logarithm using the replica trick (see <xref ref-type="bibr" rid="pcbi.1000759-Mezard1">[27]</xref>)<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e203" xlink:type="simple"/><label>(12)</label></disp-formula>which can be rewritten (Nadal and Parga <xref ref-type="bibr" rid="pcbi.1000759-Nadal1">[49]</xref> have shown how to use the replica trick in the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e204" xlink:type="simple"/></inline-formula> limit, a suggestion used in <xref ref-type="bibr" rid="pcbi.1000759-Treves7">[50]</xref> to analyse information transfer in the CA3-CA1 system)<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e205" xlink:type="simple"/><label>(13)</label></disp-formula>using the spatial averages, defined for an arbitrary real-valued number <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e206" xlink:type="simple"/></inline-formula> of replicas<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e207" xlink:type="simple"/><label>(14)</label></disp-formula>where we have defined a quantity dependent on both the number <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e208" xlink:type="simple"/></inline-formula> of replicas and on the position in space, later to be integrated over, of each replica <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e209" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e210" xlink:type="simple"/></disp-formula>We need therefore to carry out integrals over the firing rate of each CA3 unit, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e211" xlink:type="simple"/></inline-formula>, in order to estimate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e212" xlink:type="simple"/></inline-formula>, while keeping in mind that in the end we want to take <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e213" xlink:type="simple"/></inline-formula>. Carrying out the integrals yields a below-threshold and an above-threshold term<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e214" xlink:type="simple"/><label>(15)</label></disp-formula>where we have defined the quantities<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e215" xlink:type="simple"/><label>(16)</label></disp-formula>and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e216" xlink:type="simple"/></inline-formula>, while <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e217" xlink:type="simple"/></inline-formula>.</p>
<p>One might think that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e218" xlink:type="simple"/></inline-formula>, hence in the product over cells, that defines the entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e219" xlink:type="simple"/></inline-formula>, the only terms that survive in the limit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e220" xlink:type="simple"/></inline-formula> would just be the summed single-unit contributions obtained from the first derivatives with respect to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e221" xlink:type="simple"/></inline-formula>. This is not true, however, as taking the replica limit produces the counterintuitive effect that replica-tensor products of terms, which individually disappear for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e222" xlink:type="simple"/></inline-formula>, only vanish to first order in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e223" xlink:type="simple"/></inline-formula>, as shown by <xref ref-type="bibr" rid="pcbi.1000759-DelPrete1">[29]</xref>. The replica method is therefore able, in principle, to quantify the effect of correlations among units, expressed in entropy terms stemming from the product of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e224" xlink:type="simple"/></inline-formula> across units.</p>
<p>Briefly, one has<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e225" xlink:type="simple"/><label>(17)</label></disp-formula>where the first two rows come from the term below threshold, and the last two from the one above threshold. Then, following <xref ref-type="bibr" rid="pcbi.1000759-DelPrete1">[29]</xref>,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e226" xlink:type="simple"/><label>(18)</label></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e227" xlink:type="simple"/><label>(19)</label></disp-formula> and where we have considered that in the limit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e228" xlink:type="simple"/></inline-formula> we have <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e229" xlink:type="simple"/></inline-formula> appear in all terms of finite weight.</p>
<p>The products between the matrices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e230" xlink:type="simple"/></inline-formula> attached to each CA3 unit generate the higher order terms in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e231" xlink:type="simple"/></inline-formula>. Calculating them in our case, in which different CA3 units can receive partially overlapping inputs from DG units, is extremely complex (see <xref ref-type="bibr" rid="pcbi.1000759-DelPrete2">[51]</xref>, where information transmission across a network is also considered), and we do not pursue here the analysis of such higher order terms. One can retrieve the result of the TG model in Ref. <xref ref-type="bibr" rid="pcbi.1000759-DelPrete1">[29]</xref> by taking the further limit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e232" xlink:type="simple"/></inline-formula>, which implies <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e233" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e234" xlink:type="simple"/></inline-formula>. A further subtlety is that, in taking the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e235" xlink:type="simple"/></inline-formula> limit, there is a single replica, say <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e236" xlink:type="simple"/></inline-formula>, which is counted <italic>once</italic> in the limit, but also several <italic>different</italic> replicas, denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e237" xlink:type="simple"/></inline-formula>, whose weights vanish, but which remain to determine e.g. the terms proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e238" xlink:type="simple"/></inline-formula> emerging from the derivatives. Thus, in the very last term of Eq. 17, one has to derive <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e239" xlink:type="simple"/></inline-formula> with respect to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e240" xlink:type="simple"/></inline-formula> to produce the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e241" xlink:type="simple"/></inline-formula> term of Eq. 19, which is absent in <xref ref-type="bibr" rid="pcbi.1000759-DelPrete1">[29]</xref> because it vanishes with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e242" xlink:type="simple"/></inline-formula>. In the off-diagonal terms of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e243" xlink:type="simple"/></inline-formula> matrix there are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e244" xlink:type="simple"/></inline-formula> entries dependent on replicas <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e245" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e246" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e247" xlink:type="simple"/></inline-formula> entries dependent on replicas <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e248" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e249" xlink:type="simple"/></inline-formula>.</p>
<p>Focusing now solely on terms of order <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e250" xlink:type="simple"/></inline-formula>, note that the term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e251" xlink:type="simple"/></inline-formula> is effectively a <italic>spatial signal</italic>. In the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e252" xlink:type="simple"/></inline-formula> limit it can be rewritten, using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e253" xlink:type="simple"/></inline-formula> for the single surviving replica, as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e254" xlink:type="simple"/></disp-formula>This allows us to derive, to order <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e255" xlink:type="simple"/></inline-formula>, our result for the spatial information content, Eq. 8.</p>
<p>Note that when the threshold of each unit tends to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e256" xlink:type="simple"/></inline-formula>, and therefore its mean activation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e257" xlink:type="simple"/></inline-formula>, our units behave as threshold-less linear units with gaussian noise, and the information they convey tends to<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e258" xlink:type="simple"/><label>(20)</label></disp-formula>which is simply expressed in terms of a spatial signal-to-noise ratio, and coincides with the results in Refs. <xref ref-type="bibr" rid="pcbi.1000759-Samengo1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1000759-DelPrete1">[29]</xref>.</p>
</sec></sec><sec id="s4b">
<title><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e259" xlink:type="simple"/></inline-formula>-Field decomposition</title>
<p>Eqs. 8 and 9 simply sum equivalent average contributions from each CA3 unit. Each such contribution can then be calculated as a series in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e260" xlink:type="simple"/></inline-formula>, the number of DG fields feeding into the CA3 unit. One can in fact write, for example,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e261" xlink:type="simple"/></disp-formula>where in each term there are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e262" xlink:type="simple"/></inline-formula> active DG units, indexed by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e263" xlink:type="simple"/></inline-formula>, presynaptic to CA3 unit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e264" xlink:type="simple"/></inline-formula>, and each has <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e265" xlink:type="simple"/></inline-formula> fields (including the possibility that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e266" xlink:type="simple"/></inline-formula>), indexed by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e267" xlink:type="simple"/></inline-formula>. A similar expansion can be written for the other terms. One then realizes that the spatial component reduces to integrals that depend solely on the total number of fields <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e268" xlink:type="simple"/></inline-formula>, no matter how many DG active units they come from, and the expansion can be rearranged into an expansion in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e269" xlink:type="simple"/></inline-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e270" xlink:type="simple"/><label>(21)</label></disp-formula>where one of the components in each term is, for example,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e271" xlink:type="simple"/><label>(22)</label></disp-formula>with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e272" xlink:type="simple"/></inline-formula> the mean signal-to-noise at position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e273" xlink:type="simple"/></inline-formula> produced by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e274" xlink:type="simple"/></inline-formula> fields, from no matter how many DG units. The numerical coefficient <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e275" xlink:type="simple"/></inline-formula>, instead, stems from the combination of the distribution for the number of fields for each presynaptic DG unit active in the environment, which differs between models A, B and C, and the Poisson distribution for the number of such units<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e276" xlink:type="simple"/></disp-formula>The sum extends in principle to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e277" xlink:type="simple"/></inline-formula>, but in practice it can be truncated after checking that successive terms give vanishing contributions. The appropriate truncation point obviously depends on the mean number of fields <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e278" xlink:type="simple"/></inline-formula>, as well as on the model distribution of fields per unit. Note that the first few terms (e.g. for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e279" xlink:type="simple"/></inline-formula>) may give negative but not necessarily negligible contributions if the effective threshold <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e280" xlink:type="simple"/></inline-formula> is high.</p>
<p>For model A,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e281" xlink:type="simple"/></disp-formula>and combining the two Poisson series one finds<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e282" xlink:type="simple"/><label>(23)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e283" xlink:type="simple"/></inline-formula> and the other <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e284" xlink:type="simple"/></inline-formula> are the polynomials<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e285" xlink:type="simple"/></disp-formula>given by the modified Khayyam-Tartaglia recursion relation<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e286" xlink:type="simple"/></disp-formula>and where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e287" xlink:type="simple"/></inline-formula>.</p>
<p>For model B,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e288" xlink:type="simple"/></disp-formula>and combining the Poisson with the exponential series one finds<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e289" xlink:type="simple"/><label>(24)</label></disp-formula>where again <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e290" xlink:type="simple"/></inline-formula>, while the other <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e291" xlink:type="simple"/></inline-formula> are the distinct polynomials<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e292" xlink:type="simple"/></disp-formula>given by the further modified Khayyam-Tartaglia recursion relation<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e293" xlink:type="simple"/></disp-formula>and where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e294" xlink:type="simple"/></inline-formula>.</p>
<p>For model C,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e295" xlink:type="simple"/></disp-formula>there is no parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e296" xlink:type="simple"/></inline-formula> (i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e297" xlink:type="simple"/></inline-formula>), and one simply finds<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e298" xlink:type="simple"/><label>(25)</label></disp-formula>Note that in the limit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e299" xlink:type="simple"/></inline-formula>, when the mean input per CA3 unit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e300" xlink:type="simple"/></inline-formula> remains finite, for both models A and B one finds<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e301" xlink:type="simple"/></disp-formula>which is equivalent to Eq. 25, in line with the fact that both models A and B reduce, in the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e302" xlink:type="simple"/></inline-formula> limit, to single-field distributions, but even units with single fields become vanishingly rare, so formally one has to scale up the mean number of active presynaptic units, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e303" xlink:type="simple"/></inline-formula>, to keep <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e304" xlink:type="simple"/></inline-formula> finite and establish the correct comparison to model C.</p>
</sec><sec id="s4c">
<title>Sparsity and threshold</title>
<p>The analytical relation between the threshold <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e305" xlink:type="simple"/></inline-formula> of CA3 units and the sparsity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e306" xlink:type="simple"/></inline-formula> of the layer is obtained starting from the formula defining the sparsity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e307" xlink:type="simple"/></inline-formula> (see below) which can be rewritten<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e308" xlink:type="simple"/><label>(26)</label></disp-formula>Since in the analytical calculation we have <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e309" xlink:type="simple"/></inline-formula> as parameter, this equation can be taken as a relation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e310" xlink:type="simple"/></inline-formula> which has to be inverted to allow a comparison with the simulations, which are run controlling the sparsity level at a predefined level (in our case <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e311" xlink:type="simple"/></inline-formula>) and adjusting the threshold parameter accordingly. The inversion requires using the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e312" xlink:type="simple"/></inline-formula>-field decomposition and numerical integration. A graphical example of the numerical relation is given in <xref ref-type="fig" rid="pcbi-1000759-g011">Fig. 11</xref>.</p>
<fig id="pcbi-1000759-g011" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000759.g011</object-id><label>Figure 11</label><caption>
<title>Sparsity-threshold relation.</title>
<p>The sparsity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e313" xlink:type="simple"/></inline-formula> of CA3 layer vs. the threshold <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e314" xlink:type="simple"/></inline-formula> of CA3 units, from the numerical integration of Eq. 26. Different lines correspond to different degrees of connectivity between DG and CA3.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.g011" xlink:type="simple"/></fig></sec><sec id="s4d">
<title>Simulations</title>
<p>The mathematical model described above was simulated with a network of 15000 DG cells and 500 CA3 cells. A virtual rat explores a continuous two dimensional space, intended to represent a <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e315" xlink:type="simple"/></inline-formula> square environment but realized as a torus, with periodic boundary conditions. For the numerical estimation of mutal information, the environment is discretized in a grid of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e316" xlink:type="simple"/></inline-formula> locations, whereas trajectories are in continuous space, but in discretized time steps. In each time step (intended to correspond to roughly <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e317" xlink:type="simple"/></inline-formula>, half a theta cycle) the virtual rat moves half a grid unit (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e318" xlink:type="simple"/></inline-formula>) in a direction similar to the direction of the previous time step, with a small amount of noise. To allow construction of a full localization matrix with good statistics, simulations are run for typically 400,000 time steps (while for the simplified translationally invariant matrix 5,000 steps would be sufficient). The space has periodic boundary conditions, as in a torus, to avoid border effects; the longest possible distance between any two locations is hence equal to 14.1 grid units, or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e319" xlink:type="simple"/></inline-formula>.</p>
<sec id="s4d1">
<title>DG place fields</title>
<p>After assigning a number of firing fields for each DG units, according to the distributions of models A, B and C, we assign to each field a randomly chosen center. The shape of the field is then given by a Gaussian bell with that center. The tails of the Gausssian function are truncated to zero when the distance from the center is larger than a fixed radius <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e320" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e321" xlink:type="simple"/></inline-formula> the ratio between the area of the field and the environment area <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e322" xlink:type="simple"/></inline-formula>. In the standard model, only about 3 percent of the DG units on average are active in a given environment, in agreement with experimental findings <xref ref-type="bibr" rid="pcbi.1000759-Chawla1">[24]</xref>; i.e. the DG firing probability is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e323" xlink:type="simple"/></inline-formula>. The firing of DG units is not affected by noise, nor by any further threshold. Peak firing is conventionally set, in the center of the field, at the value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e324" xlink:type="simple"/></inline-formula>, but DG units can fire at higher levels if they are assigned two or more overlapping fields.</p>
</sec><sec id="s4d2">
<title>CA3 activation</title>
<p>CA3 units fire according to Eq. 2: the firing of a CA3 unit is a linear function of the total incoming DG input, distorted by a noise term. This term is taken from a gaussian distribution centered on zero, with variance <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e325" xlink:type="simple"/></inline-formula>, and it changes for each unit and each time step. A threshold is imposed in the simulations to model the action of inhibition, hypothesizing that it serves to adjust the sparsity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e326" xlink:type="simple"/></inline-formula> of CA3 activity to its required value. The sparsity is defined as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e327" xlink:type="simple"/></disp-formula>and it is fixed to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e328" xlink:type="simple"/></inline-formula>. This implies that the activity of the CA3 cells population is under tight inhibitory control.</p>
</sec><sec id="s4d3">
<title>The decoding procedure and information extraction</title>
<p>At each time step, the firing vector of a set of CA3 units is compared to all the average vectors recorded at each position in the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e329" xlink:type="simple"/></inline-formula> grid, for the same sample, in a test trial (these are called template vectors). The comparison is made calculating the Euclidean distance between the current vector and each template, and the position of the closest template is taken to be the decoded position at that time step, for that sample. This procedure has been termed maximum likelihood Euclidean distance decoding <xref ref-type="bibr" rid="pcbi.1000759-Rolls2">[32]</xref>. The frequency of each pair of decoded and real positions are compiled in a so-called “confusion matrix”, or localization matrix, that reflects the ensemble of conditional probabilities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e330" xlink:type="simple"/></inline-formula> for that set of units. Should decoding “work” in a perfect manner, in the sense of always detecting the correct position in space of the virtual rat, the confusion matrix would be the identity matrix. From the confusion matrix obtained at the end of the simulation, the amount of information is extracted, and plotted versus the number of CA3 units present in the set. We averaged extensively over CA3 samples, as there are large fluctuations from sample to sample, i.e. for each given number of CA3 units we randomly picked several different groups of CA3 units and then averaged the mutual information values obtained. In all the results reported we averaged also over 3–4 simulation run with a different random number generator, i.e. over different trajectories. The same procedure leading to the information curve was repeated for different values of the parameters. In all the information measures we reported, we also corrected for the limited sampling bias, as discussed by <xref ref-type="bibr" rid="pcbi.1000759-Treves5">[31]</xref>. In our case of spatial information, the bias is essentially determined by the spatial binning we used (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e331" xlink:type="simple"/></inline-formula>) and by the decoding method <xref ref-type="bibr" rid="pcbi.1000759-Panzeri2">[52]</xref>.</p>
<p>One should note the maximum likelihood decoding procedure to better understand the discrepancy between the information estimated from simulations (with the procedure based on the full matrix) and that calculated analytically. The analytical calculation distinguishes in a clear-cut manner so called <italic>annealed</italic> variables, which are interpreted as “fast” noise and are averaged in computing the relation between position and neuronal activity, and so called <italic>quenched</italic> variables, which are interpreted as frozen disorder and are averaged over only later, in computing average the entropy, free-energy or mutual information <xref ref-type="bibr" rid="pcbi.1000759-Mezard1">[27]</xref>. In using maximum likelihood decoding, instead, the localization matrix that relates actual and decoding position effectively averages only trial-to-trial variability, i.e. the noise that occurs on intermediate time scales. The variability on genuinely fast time scales is suppressed, in fact, by the maximum likelihood operation, which acts as a sort of temporal low pass filter with a cut-off time equal to one time step. This suppression of part of the annealed noise leads to larger information values extracted from the simulations, and hence to the notion of “dark” information. In the real system, the spiking nature of neuronal activity may induce a similar cut-off, although its quantitative relation to the one-time-step cut-off in the simulations (here intended to be half a theta cycle) remains to be firmly established.</p>
</sec><sec id="s4d4">
<title>Fitting</title>
<p>We fit the information curves obtained in simulations to exponentially saturating curves as a function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e332" xlink:type="simple"/></inline-formula> in order to get the values of the two most relevant parameter that describe their shape: the initial slope <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e333" xlink:type="simple"/></inline-formula> (i.e. the average information conveyed by the activity of individual units) and the total amount of information <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e334" xlink:type="simple"/></inline-formula> (i.e. the asymptotic saturation value). The function we used for the fit is the following<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000759.e335" xlink:type="simple"/><label>(27)</label></disp-formula>In most cases the fit was in excellent agreement with individual data points, as expected on the basis of previous analyses <xref ref-type="bibr" rid="pcbi.1000759-Samengo1">[28]</xref>.</p>
</sec></sec></sec></body>
<back>
<ack>
<p>We had valuable discussion with Jill Leutgeb, Bailu Si and Federico Stella.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1000759-Treves1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Tashiro</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Witter</surname><given-names>MP</given-names></name>
<name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name>
</person-group>             <year>2008</year>             <article-title>What is the mammalian dentate gyrus good for?</article-title>             <source>Neuroscience</source>             <volume>154</volume>             <fpage>1155</fpage>             <lpage>1172</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-McNaughton1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name>
<name name-style="western"><surname>Morris</surname><given-names>RGM</given-names></name>
</person-group>             <year>1987</year>             <article-title>Hippocampal synaptic enhancement and information storage within a distributed memory system.</article-title>             <source>Trends Neurosci</source>             <volume>10</volume>             <fpage>408</fpage>             <lpage>415</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Rolls1"><label>3</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name>
</person-group>             <year>1989</year>             <article-title>Functions of neuronal networks in the hippocampus and neocortex in memory.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Byrne</surname><given-names>JH</given-names></name>
<name name-style="western"><surname>Berry</surname><given-names>WO</given-names></name>
</person-group>             <source>Neural Models of Plasticity: Experimental and Theoretical Approaches</source>             <publisher-loc>San Diego</publisher-loc>             <publisher-name>Academic Press</publisher-name>             <fpage>240</fpage>             <lpage>265</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Treves2"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name>
</person-group>             <year>1992</year>             <article-title>Computational constraints suggest the need for two distinct input systems to the hippocampal CA3 network.</article-title>             <source>Hippocampus</source>             <volume>2</volume>             <fpage>189</fpage>             <lpage>199</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Marr1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Marr</surname><given-names>D</given-names></name>
</person-group>             <year>1971</year>             <article-title>Simple memory: A theory for archicortex.</article-title>             <source>Philos Trans R Soc Lond B Biol Sci</source>             <volume>262</volume>             <fpage>23</fpage>             <lpage>81</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Lassalle1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lassalle</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Bataille</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Halley</surname><given-names>H</given-names></name>
</person-group>             <year>2000</year>             <article-title>Reversible inactivation of the hippocampal mossy fiber synapses in mice impairs spatial learning, but neither consolidation nor memory retrieval, in the Morris navigation task.</article-title>             <source>Neurobiol Learn Mem</source>             <volume>73</volume>             <fpage>243</fpage>             <lpage>257</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Lee1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lee</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Kesner</surname><given-names>RP</given-names></name>
</person-group>             <year>2004</year>             <article-title>Encoding versus retrieval of spatial memory: Double dissociation between the dentate gyrus and the perforant path inputs into CA3 in the dorsal hippocampus.</article-title>             <source>Hippocampus</source>             <volume>14</volume>             <fpage>66</fpage>             <lpage>76</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Leutgeb1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Leutgeb</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Leutgeb</surname><given-names>JK</given-names></name>
<name name-style="western"><surname>Barnes</surname><given-names>CA</given-names></name>
<name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name>
<name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name>
<etal/></person-group>             <year>2005</year>             <article-title>Independent codes for spatial and episodic memory in hippocampal neuronal ensembles.</article-title>             <source>Science</source>             <volume>309</volume>             <fpage>619</fpage>             <lpage>623</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Samsonovich1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Samsonovich</surname><given-names>A</given-names></name>
<name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name>
</person-group>             <year>1997</year>             <article-title>Path integration and cognitive mapping in a continuous attractor neural network model.</article-title>             <source>J Neurosci</source>             <volume>17</volume>             <fpage>5900</fpage>             <lpage>5920</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Battaglia1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Battaglia</surname><given-names>FP</given-names></name>
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
</person-group>             <year>1998</year>             <article-title>Attractor neural networks storing multiple space representations: A model for hippocampal place fields.</article-title>             <source>Phys Rev E</source>             <volume>58</volume>             <fpage>7738</fpage>             <lpage>7753</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Stringer1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stringer</surname><given-names>MS</given-names></name>
<name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name>
</person-group>             <year>2002</year>             <article-title>Invariant object recognition in the visual system with novel views of 3D objects.</article-title>             <source>Neural Comput</source>             <volume>14</volume>             <fpage>2585</fpage>             <lpage>2596</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Tsodyks1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Sejnowski</surname><given-names>T</given-names></name>
</person-group>             <year>1995</year>             <article-title>Associative memory and hippocampal place cells.</article-title>             <source>Int J Neural Syst</source>             <volume>6</volume>             <fpage>81</fpage>             <lpage>86</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Hamaguchi1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hamaguchi</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Hatchett</surname><given-names>JPL</given-names></name>
</person-group>             <year>2006</year>             <article-title>Analytic solution of neural network with disordered lateral inhibition.</article-title>             <source>Phys Rev E Stat Nonlin Soft Matter Phys</source>             <volume>73</volume>             <fpage>art. 051104</fpage>          </element-citation></ref>
<ref id="pcbi.1000759-Papp1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Papp</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Witter</surname><given-names>MP</given-names></name>
<name name-style="western"><surname>A. Treves</surname><given-names>A</given-names></name>
</person-group>             <year>2007</year>             <article-title>The CA3 network as a memory store for spatial representations.</article-title>             <source>Learn Mem</source>             <volume>14</volume>             <fpage>732</fpage>             <lpage>744</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Roudi1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Roudi</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
</person-group>             <year>2008</year>             <article-title>Representing where along with what information in a model of a cortical patch.</article-title>             <source>PLoS Comput Biol</source>             <volume>4</volume>             <fpage>e1000012</fpage>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000012" xlink:type="simple">10.1371/journal.pcbi.1000012</ext-link></comment>          </element-citation></ref>
<ref id="pcbi.1000759-Hafting1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hafting</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Fyhn</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Molden</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Moser</surname><given-names>MB</given-names></name>
<name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name>
</person-group>             <year>2005</year>             <article-title>Microstructure of a spatial map in the entorhinal cortex.</article-title>             <source>Science</source>             <volume>436</volume>             <fpage>801</fpage>             <lpage>806</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Jung1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Jung</surname><given-names>MW</given-names></name>
<name name-style="western"><surname>Wiener</surname><given-names>SI</given-names></name>
<name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name>
</person-group>             <year>1994</year>             <article-title>Comparison of spatial firing characteristics of units in dorsal and ventral hippocampus of the rat.</article-title>             <source>J Neurosci</source>             <volume>14</volume>             <fpage>7347</fpage>             <lpage>7356</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Leutgeb2"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Leutgeb</surname><given-names>JK</given-names></name>
<name name-style="western"><surname>Leutgeb</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Moser</surname><given-names>MB</given-names></name>
<name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name>
</person-group>             <year>2007</year>             <article-title>Pattern separation in the dentate gyrus and CA3 of the hippocampus.</article-title>             <source>Science</source>             <volume>315</volume>             <fpage>961</fpage>             <lpage>966</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Aimone1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Aimone</surname><given-names>JB</given-names></name>
<name name-style="western"><surname>Wiskott</surname><given-names>L</given-names></name>
</person-group>             <year>2008</year>             <article-title>Computational modeling of neurogenesis.</article-title>             <source>Adult Neurogenesis</source>             <volume>52</volume>             <fpage>463</fpage>             <lpage>481</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Treves3"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name>
</person-group>             <year>1991</year>             <article-title>What determines the capacity of autoassociative memories in the brain?</article-title>             <source>Network: Computation in Neural Systems</source>             <volume>2</volume>             <fpage>371</fpage>             <lpage>397</lpage>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/0954-898X/2/4/004" xlink:type="simple">10.1088/0954-898X/2/4/004</ext-link></comment>          </element-citation></ref>
<ref id="pcbi.1000759-Wilson1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wilson</surname><given-names>MA</given-names></name>
<name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name>
</person-group>             <year>1993</year>             <article-title>Dynamics of the hippocampal ensemble code for space.</article-title>             <source>Science</source>             <volume>261</volume>             <fpage>1055</fpage>             <lpage>1058</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Treves4"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
</person-group>             <year>1990</year>             <article-title>Graded-response neurons and information encodings in autoassociative memories.</article-title>             <source>Phys Rev A Gen Phys</source>             <volume>42</volume>             <fpage>2418</fpage>             <lpage>2430</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Kropff1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kropff</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
</person-group>             <year>2008</year>             <article-title>The emergence of grid cells: Intelligent design or just adaptation?</article-title>             <source>Hippocampus</source>             <volume>18</volume>             <fpage>1256</fpage>             <lpage>1269</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Chawla1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Chawla</surname><given-names>MK</given-names></name>
<name name-style="western"><surname>Guzowski</surname><given-names>JF</given-names></name>
<name name-style="western"><surname>Ramirez-Amaya</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Lipa</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Hoffman</surname><given-names>KL</given-names></name>
<etal/></person-group>             <year>2005</year>             <article-title>Sparse, environmentally selective expression of arc rna in the upper blade of the rodent fascia dentata by brief spatial experience.</article-title>             <source>Hippocampus</source>             <volume>15</volume>             <fpage>579</fpage>             <lpage>586</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Si1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Si</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
</person-group>             <year>2009</year>             <article-title>The role of competitive learning in the generation of DG fields from EC inputs.</article-title>             <source>Cogn Neurodyn</source>             <volume>3</volume>             <fpage>119</fpage>             <lpage>187</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Amaral1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Amaral</surname><given-names>DG</given-names></name>
<name name-style="western"><surname>Ishizuka</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Claiborne</surname><given-names>B</given-names></name>
</person-group>             <year>1990</year>             <article-title>Neurons, numbers and the hippocampal network.</article-title>             <source>Prog Brain Res</source>             <volume>83</volume>             <fpage>1</fpage>             <lpage>11</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Mezard1"><label>27</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mezard</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Parisi</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Virasoro</surname></name>
</person-group>             <year>1986</year>             <source>Spin glasses and beyond</source>             <publisher-name>World Scientific</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000759-Samengo1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Samengo</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
</person-group>             <year>2000</year>             <article-title>Representational capacity of a set of independent neurons.</article-title>             <source>Phys Rev E Stat Nonlin Soft Matter Phys</source>             <volume>63</volume>             <fpage>art. 011910, 2000</fpage>          </element-citation></ref>
<ref id="pcbi.1000759-DelPrete1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>DelPrete</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
</person-group>             <year>2001</year>             <article-title>Theoretical model of neuronal population coding of stimuli with both continuous and discrete dimensions.</article-title>             <source>Phys Rev E Stat Nonlin Soft Matter Phys</source>             <volume>64</volume>             <fpage>art. 021912, Jul 2001</fpage>          </element-citation></ref>
<ref id="pcbi.1000759-Leutgeb3"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Leutgeb</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Leutgeb</surname><given-names>JK</given-names></name>
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Moser</surname><given-names>MB</given-names></name>
<name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name>
</person-group>             <year>2004</year>             <article-title>Distinct ensemble codes in hippocampal areas CA3 and CA1.</article-title>             <source>Science</source>             <volume>305</volume>             <fpage>1295</fpage>             <lpage>1298</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Treves5"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Panzeri</surname><given-names>S</given-names></name>
</person-group>             <year>1995</year>             <article-title>The upward bias in measures of information derived from limited data samples.</article-title>             <source>Neural Comput</source>             <volume>2</volume>             <fpage>399</fpage>             <lpage>407</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Rolls2"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name>
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Tovee</surname><given-names>MJ</given-names></name>
</person-group>             <year>1997</year>             <article-title>The representational capacity of the distributed encoding of information provided by populations of neurons in primate temporal visual cortex.</article-title>             <source>Exp Brain Res</source>             <volume>114</volume>             <fpage>149</fpage>             <lpage>162</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Nicoll1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nicoll</surname><given-names>RA</given-names></name>
<name name-style="western"><surname>Schmitz</surname><given-names>D</given-names></name>
</person-group>             <year>2005</year>             <article-title>Synaptic plasticity at hippocampal mossy fibre synapses.</article-title>             <source>Nat Rev Neurosci</source>             <volume>6</volume>             <fpage>863</fpage>             <lpage>876</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Treves6"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
</person-group>             <year>2004</year>             <article-title>Computational constraints between retrieving the past and predicting the future, and the CA3-CA1 differentiation.</article-title>             <source>Hippocampus</source>             <volume>14</volume>             <fpage>539</fpage>             <lpage>556</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Kuhn1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kuhn</surname><given-names>HG</given-names></name>
<name name-style="western"><surname>Dickinson-Anson</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Gage</surname><given-names>FH</given-names></name>
</person-group>             <year>1996</year>             <article-title>Neurogenesis in the dentate gyrus of the adult rat: age-related decrease of neuronal progenitor proliferation.</article-title>             <source>J Neurosci</source>             <volume>16</volume>             <fpage>2027</fpage>             <lpage>2033</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Redish1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name>
<name name-style="western"><surname>Battaglia</surname><given-names>FP</given-names></name>
<name name-style="western"><surname>Chawla</surname><given-names>MK</given-names></name>
<name name-style="western"><surname>Ekstrom</surname><given-names>AD</given-names></name>
<name name-style="western"><surname>Gerrard</surname><given-names>JL</given-names></name>
<etal/></person-group>             <year>2001</year>             <article-title>Independence of firing correlates of anatomically proximate hippocampal pyramidal cell.</article-title>             <source>J Neurosci</source>             <volume>21: RC134</volume>             <fpage>1</fpage>             <lpage>6</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Bakker1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bakker</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Kirwan</surname><given-names>CB</given-names></name>
<name name-style="western"><surname>Miller</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Stark</surname><given-names>CEL</given-names></name>
</person-group>             <year>2008</year>             <article-title>Pattern separation in the human hippocampal CA3 and dentate gyrus.</article-title>             <source>Science</source>             <volume>319</volume>             <fpage>1640</fpage>             <lpage>1642</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Panzeri1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Panzeri</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
</person-group>             <year>1996</year>             <article-title>Analytical estimates of limited sampling biases in different information measures.</article-title>             <source>Network: Computation in Neural Systems</source>             <volume>7</volume>             <fpage>87</fpage>             <lpage>107</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Aimone2"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Aimone</surname><given-names>JB</given-names></name>
<name name-style="western"><surname>Wiles</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Gage</surname><given-names>FH</given-names></name>
</person-group>             <year>2006</year>             <article-title>Potential role for adult neurogenesis in the encoding of time in new memories.</article-title>             <source>Nat Neurosci</source>             <volume>9</volume>             <fpage>723</fpage>             <lpage>727</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Becker1"><label>40</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Becker</surname><given-names>S</given-names></name>
</person-group>             <year>2005</year>             <article-title>A computational principle for hippocampal learning and neurogenesis.</article-title>             <source>Hippocampus</source>             <volume>15</volume>             <fpage>722</fpage>             <lpage>738</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Wiskott1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wiskott</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Rasch</surname><given-names>MJ</given-names></name>
<name name-style="western"><surname>Kempermann</surname><given-names>G</given-names></name>
</person-group>             <year>2006</year>             <article-title>A functional hypothesis for adult hippocampal neurogenesis: Avoidance of catastrophic interference in the dentate gyrus.</article-title>             <source>Hippocampus</source>             <volume>16</volume>             <fpage>329</fpage>             <lpage>343</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Kee1"><label>42</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kee</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Teixeira</surname><given-names>CM</given-names></name>
<name name-style="western"><surname>Wang</surname><given-names>AH</given-names></name>
<name name-style="western"><surname>Frankland</surname><given-names>PW</given-names></name>
</person-group>             <year>2007</year>             <article-title>Preferential incorporation of adult-generated granule cells into spatial memory networks in the dentate gyrus.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <fpage>355</fpage>             <lpage>362</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Ge1"><label>43</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ge</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Yang</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Hsu</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Ming</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Song</surname><given-names>H</given-names></name>
</person-group>             <year>2007</year>             <article-title>A critical period for enhanced synaptic plasticity in newly generated neurons of the adult brain.</article-title>             <source>Neuron</source>             <volume>54</volume>             <fpage>559</fpage>             <lpage>566</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Buzzetti1"><label>44</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Buzzetti</surname><given-names>RA</given-names></name>
<name name-style="western"><surname>Marrone</surname><given-names>DF</given-names></name>
<name name-style="western"><surname>Schaner</surname><given-names>MJ</given-names></name>
<name name-style="western"><surname>Chawla</surname><given-names>MK</given-names></name>
<name name-style="western"><surname>Bohanick</surname><given-names>JD</given-names></name>
<etal/></person-group>             <year>2007</year>             <article-title>Do dentate gyrus granule cells tag time-specific experiences?</article-title>             <source>Soc Neurosci Abstr</source>             <volume>744</volume>             <fpage>16</fpage>          </element-citation></ref>
<ref id="pcbi.1000759-Tashiro1"><label>45</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tashiro</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Makino</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Gage</surname><given-names>FH</given-names></name>
</person-group>             <year>2007</year>             <article-title>Experience-specific functional modification of the dentate gyrus through adult neurogenesis: A critical period during an immature stage.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>3252</fpage>             <lpage>3259</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Cameron1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cameron</surname><given-names>HA</given-names></name>
<name name-style="western"><surname>Mckay</surname><given-names>RDG</given-names></name>
</person-group>             <year>2001</year>             <article-title>Adult neurogenesis produces a large pool of new granule cells in the dentate gyrus.</article-title>             <source>J Comp Neurol</source>             <volume>435</volume>             <fpage>406</fpage>             <lpage>417</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-McDonald1"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>McDonald</surname><given-names>HY</given-names></name>
<name name-style="western"><surname>Wojtowicz</surname><given-names>JM</given-names></name>
</person-group>             <year>2005</year>             <article-title>Dynamics of neurogenesis in the dentate gyrus of adult rats.</article-title>             <source>Neurosci Lett</source>             <volume>385</volume>             <fpage>70</fpage>             <lpage>75</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-McHugh1"><label>48</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>McHugh</surname><given-names>TJ</given-names></name>
<name name-style="western"><surname>Jones</surname><given-names>MW</given-names></name>
<name name-style="western"><surname>Quinn</surname><given-names>JJ</given-names></name>
<name name-style="western"><surname>Balthasar</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Coppari</surname><given-names>R</given-names></name>
<etal/></person-group>             <year>2007</year>             <article-title>Dentate gyrus nmda receptors mediate rapid pattern separation in the hippocampal network.</article-title>             <source>Science</source>             <volume>317</volume>             <fpage>94</fpage>             <lpage>99</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-Nadal1"><label>49</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nadal</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Parga</surname><given-names>N</given-names></name>
</person-group>             <year>1993</year>             <article-title>Information processing by a perceptron in an unsupervised learning task.</article-title>             <source>Network: Computation in Neural Systems</source>             <volume>4</volume>             <fpage>295</fpage>             <lpage>312</lpage>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/0954-898X/4/3/004" xlink:type="simple">10.1088/0954-898X/4/3/004</ext-link></comment>          </element-citation></ref>
<ref id="pcbi.1000759-Treves7"><label>50</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
</person-group>             <year>1995</year>             <article-title>Quantitative estimate of the information relayed by the schaffer collaterals.</article-title>             <source>J Comput Neurosci</source>             <volume>2</volume>             <fpage>259</fpage>             <lpage>272</lpage>          </element-citation></ref>
<ref id="pcbi.1000759-DelPrete2"><label>51</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>DelPrete</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
</person-group>             <year>2002</year>             <article-title>Replica symmetric evaluation of the information transfer in a two-layer network in the presence of continuous and discrete stimuli.</article-title>             <source>Phys Rev E Stat Nonlin Soft Matter Phys</source>             <volume>65</volume>             <fpage>art. 041918</fpage>          </element-citation></ref>
<ref id="pcbi.1000759-Panzeri2"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Panzeri</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Schultz</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name>
</person-group>             <year>1999</year>             <article-title>On decoding the responses of a population of neurons from short time windows.</article-title>             <source>Neural Comput</source>             <volume>11</volume>             <fpage>1553</fpage>             <lpage>1577</lpage>          </element-citation></ref>
</ref-list>

</back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="publisher">pbio</journal-id><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="doi">10.1371/journal.pbio.0040120</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computational Biology</subject>
          <subject>Neuroscience</subject>
        </subj-group>
        <subj-group subj-group-type="System Taxonomy">
          <subject>Mammals</subject>
          <subject>Vertebrates</subject>
          <subject>Animals</subject>
        </subj-group>
      </article-categories><title-group><article-title>A Model of the Ventral Visual System Based on Temporal Stability and Local Memory</article-title><alt-title alt-title-type="running-head">A Model of the Ventral Visual System</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Wyss</surname>
            <given-names>Reto</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>König</surname>
            <given-names>Peter</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Verschure</surname>
            <given-names>Paul F. M. J</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1">
				<label>1</label><addr-line>Institute of Neuroinformatics, University/ETH Zürich, Zürich, Switzerland
			</addr-line></aff><aff id="aff2">
				<label>2</label><addr-line>Institute of Cognitive Science, University Osnabrück, Neurobiopsychologie, Osnabrück, Germany
			</addr-line></aff><aff id="aff3">
				<label>3</label><addr-line>Computation and Neural Systems, California Institute of Technology, Division of Biology, Pasadena, California, United States of America
			</addr-line></aff><aff id="aff4">
				<label>4</label><addr-line>ICREA and Technology Department, University Pompeu Fabra, Barcelona, Spain
			</addr-line></aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Abbott</surname>
            <given-names>Larry</given-names>
          </name>
          <role>Academic Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Columbia University, 
				
				
			United States of America</aff><author-notes>
        <corresp id="cor1">* To whom correspondence should be addressed. E-mail: <email xlink:type="simple">pkoenig@uos.de</email></corresp>
        <fn fn-type="con" id="n1">
          <p>
					 RW, PK, and PFMJV conceived and designed the experiments. RW performed the experiments and analyzed the data. RW, PK, and PFMJV wrote the paper.
				</p>
        </fn>
      <fn fn-type="conflict">
        <p>
				 The authors have declared that no competing interests exist.
			</p>
      </fn></author-notes><pub-date pub-type="ppub">
        <month>5</month>
        <year>2006</year>
      </pub-date><pub-date pub-type="epub">
        <day>18</day>
        <month>4</month>
        <year>2006</year>
      </pub-date><volume>4</volume><issue>5</issue><elocation-id>e120</elocation-id><history>
        <date date-type="received">
          <day>13</day>
          <month>4</month>
          <year>2005</year>
        </date>
        <date date-type="accepted">
          <day>14</day>
          <month>2</month>
          <year>2006</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2006</copyright-year><copyright-holder>Wyss et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article page="e161" related-article-type="companion" vol="4" xlink:href="info:doi/10.1371/journal.pbio.0040161" xlink:title="synopsis" xlink:type="simple">
				<article-title>Just a Few Computational Principles Generate a Realistic Model of the Brain's Visual System</article-title>
			</related-article><abstract>
        <p>The cerebral cortex is a remarkably homogeneous structure suggesting a rather generic computational machinery. Indeed, under a variety of conditions, functions attributed to specialized areas can be supported by other regions. However, a host of studies have laid out an ever more detailed map of functional cortical areas. This leaves us with the puzzle of whether different cortical areas are intrinsically specialized, or whether they differ mostly by their position in the processing hierarchy and their inputs but apply the same computational principles. Here we show that the computational principle of optimal stability of sensory representations combined with local memory gives rise to a hierarchy of processing stages resembling the ventral visual pathway when it is exposed to continuous natural stimuli. Early processing stages show receptive fields similar to those observed in the primary visual cortex. Subsequent stages are selective for increasingly complex configurations of local features, as observed in higher visual areas. The last stage of the model displays place fields as observed in entorhinal cortex and hippocampus. The results suggest that functionally heterogeneous cortical areas can be generated by only a few computational principles and highlight the importance of the variability of the input signals in forming functional specialization.</p>
      </abstract><abstract abstract-type="toc">
        <p>A robot-controlled camera feeds natural stimuli into an unsupervised computational model that constructs a hierarchy of processing stages resembling the ventral visual pathway, from primary visual cortex up to entorhinal cortex.</p>
      </abstract><funding-group><funding-statement>
					This work was supported by the Swiss National Science Foundation (RW) and the EU/BBW (IST-2000–28127, 01.0208–1 [PK]).
				</funding-statement></funding-group></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>The processing of visual information is a fundamental computational task for the brain involving various cortical and subcortical regions. Starting at the retina and thalamus, visual information passes through a series of hierarchically organized cortical regions eventually reaching higher cognitive structures such as the hippocampus [<xref ref-type="bibr" rid="pbio-0040120-b001">1</xref>]. Experimental studies have shown that the different levels of the ventral visual hierarchy form increasingly complex and specific representations of the visual input such as three-dimensional objects and faces in the inferotemporal cortex (IT) [<xref ref-type="bibr" rid="pbio-0040120-b002">2</xref>–<xref ref-type="bibr" rid="pbio-0040120-b005">5</xref>] and an allocentric representation of space in entorhinal cortex [<xref ref-type="bibr" rid="pbio-0040120-b006">6</xref>] and hippocampus [<xref ref-type="bibr" rid="pbio-0040120-b007">7</xref>]. This process is accompanied by an increasing degree of invariance to various stimulus properties [<xref ref-type="bibr" rid="pbio-0040120-b008">8</xref>]. Thus, the ventral visual stream presents itself as a hierarchical system with widely varying properties at different processing levels.
			</p>
      <p>In recent years, different models of the ventral visual system have been proposed that aim to account for these properties [<xref ref-type="bibr" rid="pbio-0040120-b009">9</xref>–<xref ref-type="bibr" rid="pbio-0040120-b013">13</xref>]. Although most of these theoretical studies emphasize the important role of learning for the adaptation of a visual system, it is often limited to certain stages of processing only or performed on artificial stimuli, both with respect to their temporal and spatial properties. Furthermore, none of these models considers levels of the visual hierarchy as high as the entorhinal cortex or hippocampus. In a complementary line of research, theoretical studies have shown that prominent computational properties of the primary visual cortex can be described by means of so-called objective functions. Important examples are optimally sparse representations resembling simple cells [<xref ref-type="bibr" rid="pbio-0040120-b014">14</xref>–<xref ref-type="bibr" rid="pbio-0040120-b016">16</xref>] and optimally stable representations giving rise to complex cells [<xref ref-type="bibr" rid="pbio-0040120-b011">11</xref>,
				<xref ref-type="bibr" rid="pbio-0040120-b017">17</xref>–<xref ref-type="bibr" rid="pbio-0040120-b019">19</xref>]. It remains unresolved, however, whether objective functions can describe general principles underlying cortical organization. Here we show that the objective of optimal stability of sensory representations combined with local memory can generate a hierarchy of cortical-like processing stages resembling the ventral visual pathway. This model visual hierarchy is generated on the basis of visual stimuli encountered by a mobile robot exploring a complex real-world environment. We show that the receptive fields at the lowest level of the hierarchy share properties with those observed in the primary visual cortex, that higher levels are selective for complex configurations, as observed in the IT, and that the last stage of the model ventral visual system displays place fields as observed in entorhinal cortex and hippocampus [<xref ref-type="bibr" rid="pbio-0040120-b007">7</xref>]. These results suggest that a substantial part of the visual system can be understood based on a small number of principles.
			</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <p>We investigate the adaptation and specialization of areas in a hierarchically organized visual processing stream using both a real-world robot, as well as a simulated virtual approximation (see 
				<xref ref-type="sec" rid="s4">Materials and Methods</xref>). The agents are embedded in a complex environment, and a camera mounted on the robot provides continuous input to the neural network (<xref ref-type="fig" rid="pbio-0040120-g001">Figure 1</xref>A). The model of the visual system consists of five areas each comprising units with both intra-area and feed-forward inter-area connections (<xref ref-type="fig" rid="pbio-0040120-g001">Figure 1</xref>B). The convergence of the feed-forward connectivity increases while moving up the hierarchy, similar to that observed in the visual pathway [<xref ref-type="bibr" rid="pbio-0040120-b001">1</xref>]. These feed-forward connections are subject to online unsupervised learning optimizing a temporal stability objective while the intra-area connections serve the decorrelation of the states of one area. In addition, all units are leaky integrators providing them with a local transient memory trace. The data analysis focuses on the learning and network dynamics and a comparison of the response properties of neurons at different levels of the hierarchy with their respective counterparts in the real brain.
			</p>
      <fig id="pbio-0040120-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0040120.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>The Micro-Robot Khepera and the Neural Network Structure Used for Sensory Processing</title>
          <p>(A) A camera mounted on top of the cylindrical body provides the visual input that is processed by our model of the ventral visual system. The infra-red (IR) sensors are used for obstacle avoidance during exploration of a real-world office environment within an arena of approximately 31 × 22 cm<sup>2</sup>.
					</p>
          <p>(B) Diagram showing the hierarchical network comprising five levels of identical computational units. Units are arranged uniformly within a two-dimensional square lattice, and their number per level decreases with a constant factor of 0.5 moving up the hierarchy. Each efferent unit receives input from a topographically aligned square region within the afferent level (red connectivity) and connects laterally to all the units in the same level with which it shares feed-forward input (blue connectivity). The average relative size of a unit's feed-forward arbor within the afferent level (as given in percentages), and consequently also the lateral degree of connectivity, increases with the hierarchical level and reaches 100% for the units at the highest level. The input to the network has a resolution of 16 × 16 pixels.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.g001" xlink:type="simple"/>
      </fig>
      <p>Exposing the network to the visual input provided by the mobile robot, we observe that after approximately 6 ·10<sup>6</sup> time steps (66 h of real-time, with a frame rate of 25 Hz) the stability of all levels has converged (<xref ref-type="fig" rid="pbio-0040120-g002">Figure 2</xref>). In addition, the model shows that the reorganization of the levels, in terms of their stability, follows the hierarchical order of the system, i.e., higher levels enhance their stability only after their afferent levels have reached a certain level of stable representations. After convergence, units at different processing levels show characteristic differences in their response properties. In particular, cells at the first level show orientation selectivity confirming previous results [<xref ref-type="bibr" rid="pbio-0040120-b019">19</xref>,
				<xref ref-type="bibr" rid="pbio-0040120-b020">20</xref>] (unpublished data). In the following, we analyze the response properties of the cells at different levels with respect to the orientation and position of the robot within the environment (<xref ref-type="fig" rid="pbio-0040120-g003">Figure 3</xref>A). Both the view dependence and the size of the region where activity can be elicited varies significantly with respect to the hierarchical level (one-way ANOVA, F(4,491) = 30.6, 128.3, respectively, 
				<italic>p</italic> ≪ .001). The view dependence of the units increases from the first to the third level on average by 16% and subsequently decreases and reaches its minimum at the last level, 32% below the first level (<xref ref-type="fig" rid="pbio-0040120-g003">Figure 3</xref>B). In contrast, the size of the regions in which individual units are activated decreases monotonically (<xref ref-type="fig" rid="pbio-0040120-g003">Figure 3</xref>C). On average, units at the first level are responsive within 52% of the environment. In contrast, units at the highest level only cover 24% of the environment. In order to control for an increasing fragmentation of the representations, we also measure the compactness of the responsive region, which does not change significantly across the hierarchical levels (<xref ref-type="fig" rid="pbio-0040120-g003">Figure 3</xref>D, F(4,491) = 1.28, p &gt; 0.2). In summary, these results show that our model captures pertinent properties of the ventral visual stream. The response properties of units at early stages are selective to low-level features. Such features are visible from many different positions within the environment and the responsive regions tend to be large and selective for the orientation of the robot. At intermediate stages, each unit responds specifically to a particular view from a region of limited size, similar to landmarks, leading to a high orientation selectivity. Higher levels learn to associate neighboring “landmark” views, rendering small, compact responsive regions. At the highest level, these “landmark” representations are combined into an allocentric representation of space: a place field that is highly selectively for the robot being at a certain position within the environment irrespective of its orientation [<xref ref-type="bibr" rid="pbio-0040120-b007">7</xref>,
				<xref ref-type="bibr" rid="pbio-0040120-b021">21</xref>].
			</p>
      <fig id="pbio-0040120-g002" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0040120.g002</object-id>
        <label>Figure 2</label>
        <caption>
          <title>The Stability Objective as a Function of Time for the Five Different Cortical Levels</title>
          <p>After an initial phase, within which the transients due to initial conditions have decayed, learning is initiated after 10,000 time steps.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.g002" xlink:type="simple"/>
      </fig>
      <fig id="pbio-0040120-g003" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0040120.g003</object-id>
        <label>Figure 3</label>
        <caption>
          <title>Response Properties of Units with Respect to Behavioral Space</title>
          <p>(A) Responses of two-example units per hierarchical level with respect to the robot's position (left column) and its orientation (right column). The response maps show responses of cells averaged across the robot's orientation where the black contour (responsive region) identifies the 50% level of the maximal response. The polar plot shows the mean ±SD of the unit's activity within the black region with respect to 16 equally spaced orientations covering 360°. Both response maps and polar plots are normalized to the maximal response of the units across space or orientation, respectively. (B and C) Boxplots of the view, dependence, size, and compactness of the responsive regions versus the hierarchical level of the units. The blue box represents the upper and lower quartiles. The median is indicated by the red horizontal line whereas the extent of the remaining data is given by the vertical whiskers. The view dependence is measured as the CV of the response of a unit across orientations for a fixed position, averaged across the responsive region. The size of the responsive region is normalized to the size of the environment. The compactness is given by the ratio between the true perimeter of the 50% contour and the perimeter of a disc with equal area.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.g003" xlink:type="simple"/>
      </fig>
      <p>The receptive field (RF) sizes of the feed-forward projections are bounded by the synaptic arbors of the cells at the different levels of the hierarchy. Optimizing the weights of these synapses, however, may result in different effective RF sizes. Therefore, we subsequently compare the optimized hierarchy to a reference network where all the weights are fixed to one. For this purpose, we approximate the two-subunit energy detectors by single linear units whereas the pair of weights associated to each pre-synaptic cell is replaced by a single weight 
				<inline-formula id="pbio-0040120-ex001"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040120.ex001" xlink:type="simple"/></inline-formula>. Using this linearization, we can project unit activations from higher levels back down to the input level, yielding an approximation of their effective RF with respect to the input. Interpreting the resulting activation as a two-dimensional distribution of mass, we compute its normalized inertial tensor 
				<italic>I</italic>. The two eigenvalues of 
				<italic>I</italic> correspond to the two principal axes of the distribution, and therefore yield a measure for the effective RF size. Comparing the optimized to the reference network, we find that the relative difference in the effective RF sizes amounts on average to −23%, −4%, +4%, +7%, and +8% for the five levels, respectively. Thus, while the optimization leads to smaller RF sizes than expected in the lower two levels, the higher levels can increase their effective RFs by converging to nonhomogeneous weight distributions.
			</p>
      <p>While early visual areas have been found to preferentially respond to simple oriented gratings, various studies have also reported a selectivity for increasingly complex shapes in subsequent levels of processing [<xref ref-type="bibr" rid="pbio-0040120-b022">22</xref>]. In the following we attempt a qualitative comparison with these results, exposing the first two levels of our model hierarchy to five simple stimuli, each composed of two bars of equal length in different spatial arrangements (see 
				<xref ref-type="fig" rid="pbio-0040120-g004">Figure 4</xref>). For the first four stimuli, the bars are catenated to form an angle of 45°, 90°, 135°, and 180°, respectively. The fifth stimulus consists of two parallel bars. The stimuli are presented at all possible positions and 12 different orientations within the input space. For each unit, the preferred stimulus, for which it responds maximally, is determined. While the units in the first level of the hierarchy show a preference for grating-like parallel bars (68%, 
				<xref ref-type="fig" rid="pbio-0040120-g004">Figure 4</xref>, left), the selectivity of the units at the second level is more distributed (<xref ref-type="fig" rid="pbio-0040120-g004">Figure 4</xref>, right). In particular, the majority of units do prefer stimuli 1–4, in which the two bars are catenated at different angles (74%). This is in accordance with experimental results, which report that cells in higher visual areas such as V2 or V4 do show an increased selectivity for curvature and corner-like shapes [<xref ref-type="bibr" rid="pbio-0040120-b022">22</xref>,
				<xref ref-type="bibr" rid="pbio-0040120-b023">23</xref>].
			</p>
      <fig id="pbio-0040120-g004" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0040120.g004</object-id>
        <label>Figure 4</label>
        <caption>
          <title>Response Preferences</title>
          <p>The first two levels of the hierarchy are exposed to five different stimuli, each composed of two bars of equal length in different spatial arrangements (see text). Each stimulus is presented at all possible positions and 12 different orientations within the input space (16 × 16 pixels, the width of the bars is one pixel). All units are assigned to one of the five stimuli for which they respond maximally. The particular position/orientation for which this maximal response is achieved is not considered. The individual distributions of response preferences for the first level units (
						<italic>n</italic> = 256) and second level units (
						<italic>n</italic> = 128) is shown in the two histograms, respectively.
					</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.g004" xlink:type="simple"/>
      </fig>
      <p>Learning-feature preferences based on a principle of optimal stability run counter to the intuition that biological systems are geared for fast reaction. However, we have to differentiate the behavioral timescale, the stability of visual features, and how fast these are processed by the sensory system. To further elucidate this distinction we investigated the dynamics of cells at the highest level with respect to a modified input stream. Visual stimuli recorded by the moving robot were related to its trajectory and place fields of the cells investigated. We cut the video stream, deleting sections where the robot was moving from an area of low average activity of a considered cell (&lt; 25% of maximum) toward an area of high average activity (&gt; 75% of maximum). The resulting video thus contains sudden jumps from low to high average activity of a particular cell. In 
				<xref ref-type="fig" rid="pbio-0040120-g005">Figure 5</xref> we compare the resulting dynamics to the processing of unmodified videos. The scatter plot demonstrates that processing of rapidly changing stimuli by the network is fast, most often a few time steps only. The dynamics of the complete system is dominated by the behavioral timescale, slower by a factor of two. Thus, the system rapidly processes learned optimally stable features.
			</p>
      <fig id="pbio-0040120-g005" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0040120.g005</object-id>
        <label>Figure 5</label>
        <caption>
          <title>Network Dynamics</title>
          <p>For each unit at the highest level of the hierarchy, the input frames for which the average response of the unit lies between 25% and 75% of the maximum has been removed from the input stream. Subsequently, the resulting rise time, which is the number of time steps required for a unit to traverse the interval between its 25% and 75% level of maximal response, is plotted versus the rise time under normal input conditions. The ratio “rise time” : “rise time with gap” is 2.1 ± 1.9 (mean ± SD, 
						<italic>n</italic> = 226).
					</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.g005" xlink:type="simple"/>
      </fig>
      <p>To evaluate our hypothesis that the highest level of our model forms place fields, we assessed whether these allow an accurate reconstruction of the position of the robot. We use a standard Bayesian framework for position reconstruction [<xref ref-type="bibr" rid="pbio-0040120-b024">24</xref>]. Half of the responses recorded over 10<sup>5</sup> time steps from units at the last hierarchical level serve to acquire the distribution of posterior probabilities 
				<italic>P</italic>(
				<bold>A</bold>|
				<bold>x</bold>) where 
				<bold>x</bold> is the position of the robot within the environment, and 
				<bold>A</bold> a vector containing the responses 
				<italic>A<sub>i</sub>
				</italic> of the individual cells. The other half is used for testing the quality of reconstruction. According to Bayes rule, 
				<italic>P</italic>(
				<bold>x</bold>|
				<bold>A</bold>) ∝ 
				<italic>P</italic>(
				<bold>A</bold>|
				<bold>x</bold>)
				<bold>P</bold>(
				<bold>x</bold>), where 
				<bold>P</bold>(
				<bold>x</bold>) is the probability of the robot to be at a certain position within the environment. The most likely position of the robot is then given by ◯ = argmax<sub>x</sub>
				<italic>P</italic>(
				<bold>x</bold>|
				<bold>A</bold>). Applying this procedure to the responses of the different levels in the processing hierarchy yields a monotonically decreasing reconstruction error when moving from lower to higher levels (<xref ref-type="fig" rid="pbio-0040120-g006">Figure 6</xref>). In particular we find that responses of the units at the fifth level allow a highly accurate position reconstruction with an average error of 0.08 ± 0.08 (mean ± SD, in units of the length of the long side of the environment). In addition, we analyzed the spatial distribution of reconstruction errors, which shows that reconstruction is good for the central part and becomes poorer around the border of the environment (
				<xref ref-type="supplementary-material" rid="sg001">Figure S1</xref>). Thus, these allocentric representations at the highest level allow a reconstruction of the position of the behaving system with an accuracy equivalent to that observed in reconstructions based on the responses of hippocampal place cells [<xref ref-type="bibr" rid="pbio-0040120-b024">24</xref>].
			</p>
      <fig id="pbio-0040120-g006" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0040120.g006</object-id>
        <label>Figure 6</label>
        <caption>
          <title>Position Reconstruction</title>
          <p>The position of the robot is reconstructed using the responses of the 
						<italic>N<sub>l</sub>
						</italic> = 2<sup>9−
							<italic>l</italic>
						</sup> units in the different levels 
						<italic>l</italic> = 1…5 of the processing hierarchy using a standard Bayesian framework (see text). The reconstruction error, defined as the Euclidean distance between the true and the reconstructed position, is shown as a function of the hierarchical level. The error bars indicate the standard deviation from the mean.
					</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.g006" xlink:type="simple"/>
      </fig>
      <p>An important property of place fields in the hippocampus is their response to changes in the environment [<xref ref-type="bibr" rid="pbio-0040120-b021">21</xref>,
				<xref ref-type="bibr" rid="pbio-0040120-b025">25</xref>]. For instance, it was shown by stretching a rectangular arena along its principle axes that localization and shape of place fields in rat hippocampus are controlled by the distance to the walls and surrounding landmarks [<xref ref-type="bibr" rid="pbio-0040120-b026">26</xref>]. As a comparison we perform the same manipulations using a virtual environment (<xref ref-type="fig" rid="pbio-0040120-g007">Figure 7</xref>A). After learning in the small square environment, the network connectivity is frozen and exposed to three test environments (<xref ref-type="fig" rid="pbio-0040120-g007">Figure 7</xref>B–<xref ref-type="fig" rid="pbio-0040120-g007">7</xref>D). We observe that the place fields depend on the robot's distance from one or more of the four surrounding walls in close analogy with the experimental data. Furthermore, three main effects with respect to the stretching of the environment can be distinguished. The place cells either keep a fixed distance to one wall, split into two subfields, or stretch along the direction the environment is stretched. The units shown in 
				<xref ref-type="fig" rid="pbio-0040120-g007">Figure 7</xref>B and 
				<xref ref-type="fig" rid="pbio-0040120-g007">7</xref>C both stretch vertically while maintaining a fixed shape and distance to the right wall. The unit shown in 
				<xref ref-type="fig" rid="pbio-0040120-g007">Figure 7</xref>C is selective for a certain distance from both top and bottom walls as well as from the left wall, such that the place field is split in the vertical and stretched in the horizontal direction. These results match the properties of neurons observed in the hippocampus and suggest that optimally stable representations capture important aspects of representations in entorhinal cortex and hippocampus.
			</p>
      <fig id="pbio-0040120-g007" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0040120.g007</object-id>
        <label>Figure 7</label>
        <caption>
          <title>Environmental Manipulations</title>
          <p>(A) The virtual robot environment consists of a square arena of comparable relative size to the real-world setup and surrounding objects, e.g., a large wall along one side of the arena and a cylinder next to one of the opposite corners. This environment is stretched along either or both directions indicated by the red arrows by a factor of 1.5.</p>
          <p>(B–D) Response map of three example units that have been acquired in the original environment—small square, lower left map in (B–D)—and subsequently tested in three variants of the original environment, i.e., stretched along the vertical and/or horizontal directions. For each unit, the intensity scale of all four response maps is normalized to the maximal response of all environments.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.g007" xlink:type="simple"/>
      </fig>
      <p>To assess the properties of cortical representations at higher stages of the visual hierarchy, such as the IT, image scrambling has been successfully used in both experimental [<xref ref-type="bibr" rid="pbio-0040120-b027">27</xref>,
				<xref ref-type="bibr" rid="pbio-0040120-b028">28</xref>] as well as theoretical [<xref ref-type="bibr" rid="pbio-0040120-b012">12</xref>] studies. Here we apply this scrambling method to perform a similar analysis on our intermediate level of the hierarchy, i.e., the “landmark” cells at the third level. Those cells do qualify best for IT-like cells, not only due to their relative position within our visual hierarchy, but also because they show maximal view selectivity (<xref ref-type="fig" rid="pbio-0040120-g003">Figure 3</xref>B). We freeze the weights in the network after learning the real-world environment and subsequently perform four different tests with input streams spatially scrambled at four different scales (<xref ref-type="fig" rid="pbio-0040120-g008">Figure 8</xref>A). We observe that the average activity decreases monotonically relative to control (<xref ref-type="fig" rid="pbio-0040120-g008">Figure 8</xref>B), suggesting that these units are selective for complex visual features characterized at multiple spatial scales. This result is compatible with recent experimental studies [<xref ref-type="bibr" rid="pbio-0040120-b027">27</xref>,
				<xref ref-type="bibr" rid="pbio-0040120-b028">28</xref>] that have shown a similar characteristic relationship between the spatial scale of scrambling and the degradation of the responses in IT.
			</p>
      <fig id="pbio-0040120-g008" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0040120.g008</object-id>
        <label>Figure 8</label>
        <caption>
          <title>Input Scrambling</title>
          <p>(A) The original image shows the environment as it is perceived by the camera mounted on top of the robot. The normal image is the downscaled 16 × 16 pixel version that serves as the input to the proposed network model. The four subsequent images show the same input image scrambled by increasing degrees, i.e., by randomly permuting 2 × 2, 4 × 4, 8 × 8, or 16 × 16 blocks of equal size.</p>
          <p>(B) Average response of the units at the third level of the hierarchy for a normal visual input as well as the four different scales of spatial scrambling.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.g008" xlink:type="simple"/>
      </fig>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>We have presented a hierarchical model of an input processing-pathway that is constructed from uniform cortex-like neuronal elements. The local learning rule that modifies the synapses of the feed-forward connections between subsequent levels optimizes the receptive fields to extract smoothly varying features in their afferent input. This model, when exposed to a continuous stream of visual inputs derived from a camera mounted on a mobile robot, develops receptive fields that resemble those observed in the ventral visual pathway. At the highest level of the hierarchy, we observed receptive field properties similar to place fields in the entorhinal cortex and hippocampus. Responses of cells at this level allowed an accurate reconstruction of the position of the robot. Moreover, the model shows a specific change in its response to scrambled stimuli similar to what has been observed in the rhesus monkey.</p>
      <p>Every hierarchical neural network model should incorporate nonlinear transfer functions. Otherwise, the hierarchy could in principle be collapsed to one equivalent single layer. However, the choice of such a transfer function is largely unconstrained. Riesenhuber and Poggio [<xref ref-type="bibr" rid="pbio-0040120-b012">12</xref>], for instance, proposed the max-function (L<sup>∞</sup>-norm) to pool over lower-level feature detectors in order to gain invariances while maintaining feature specificity. Here, in contrast, we have used a saturating energy detector, which in the nonsaturating region corresponds to an L<sup>2</sup>-norm. This particular choice is inspired by a previous study, where not only the feed-forward connections but also the degree of nonlinearity was subject to the optimization procedure [<xref ref-type="bibr" rid="pbio-0040120-b029">29</xref>]. In accordance with experimental findings [<xref ref-type="bibr" rid="pbio-0040120-b030">30</xref>], this theoretical study has shown that most units converge toward an L<sup>2</sup>-norm. In addition, it has been reported that this choice of nonlinearity combined with optimization for temporal stability leads to the formation of units that are optimally invariant while highly feature selective [<xref ref-type="bibr" rid="pbio-0040120-b020">20</xref>].
			</p>
      <p>One of the appealing aspects of using objective functions to model cortical architectures is that they propose a small set of computational principles underlying cortical and subcortical processing in the visual and auditory system [<xref ref-type="bibr" rid="pbio-0040120-b016">16</xref>]. As such, this approach facilitates the investigation of the basic question of how the relatively uniform anatomical structure of the cerebral cortex can generate a highly diverse set of functional and physiological properties [<xref ref-type="bibr" rid="pbio-0040120-b031">31</xref>,
				<xref ref-type="bibr" rid="pbio-0040120-b032">32</xref>]. Many years back, Lashley tried to capture this issue with his concept of equipotentiality [<xref ref-type="bibr" rid="pbio-0040120-b033">33</xref>]. Although the original interpretation of Lashley is highly controversial [<xref ref-type="bibr" rid="pbio-0040120-b034">34</xref>], it does highlight that the computational principles underlying cortical circuits are at least partially modality- and area-independent [<xref ref-type="bibr" rid="pbio-0040120-b035">35</xref>,
				<xref ref-type="bibr" rid="pbio-0040120-b036">36</xref>]. For instance, it has been shown that routing projections from the retina to the auditory pathway leads to the development of cells in the auditory cortex with properties similar to those found in primary visual cortex [<xref ref-type="bibr" rid="pbio-0040120-b037">37</xref>]. Similarly, an fMRI study with blind human subjects has shown that cortical regions that are normally involved in processing visual information are activated verbal-memory tasks as well as braille reading [<xref ref-type="bibr" rid="pbio-0040120-b038">38</xref>]. While these results suggest a generic computational architecture across modalities, it is unclear whether the same holds for different levels of processing within one modality. The model proposed here shows that generic computational principles, temporal stability, and local memory, can underlie the generation of different levels of processing within one modality and that the variability in functional organization can be accounted for in terms of the statistics of the inputs each level is exposed to.
			</p>
    </sec>
    <sec id="s4">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>Experimental setup</title>
        <p>We performed the real-world experiments using the Khepera robot K-Team, Lausanne, Switzerland (<xref ref-type="fig" rid="pbio-0040120-g001">Figure 1</xref>A). The simulated agent was implemented in C++ using the Open Graphics Library. The robots randomly explore an environment that consists of a rectangular arena confined by walls and surrounding objects/cues. For the real-world robot, these cues are present in the office environment within which the experiments are performed. For the simulated robot, the cues are well-defined objects, i.e., a black wall and a black cylinder (<xref ref-type="fig" rid="pbio-0040120-g007">Figure 7</xref>A). The environments are explored using a random sequence of translations (maximum 0.25 environment lengths/s) and rotations (maximum 90 °/s) combined with obstacle avoidance at the walls. At each point in time, the robot switches its behavior from translation to rotation or vice versa with a probability of 0.1. As soon as an obstacle is detected by the infrared sensors arranged around the cylindrical body of the robot (<xref ref-type="fig" rid="pbio-0040120-g001">Figure 1</xref>A), the robot turns away until the obstacle is no longer sensed. A camera with a view-angle of 100° (120° for the virtual environment) provides the visual stimulus of 16 × 16 pixels. This image is passed through edge-detection before it is presented to the network model described next. The position as well as the orientation of the real-world robot was tracked using a second CCD camera mounted above the arena.
				</p>
      </sec>
      <sec id="s4b">
        <title>Network</title>
        <p>The network consists of a hierarchy of five levels with intralevel connections and purely feed-forward processing between levels. Each level 
					<italic>l</italic> = 1...5 is represented by a lattice of 
					<italic>N<sub>l</sub>
					</italic> = 2<sup>9−
						<italic>l</italic>
					</sup> identical computational units. Each unit comprises a two-subunit energy detector [<xref ref-type="bibr" rid="pbio-0040120-b020">20</xref>,
					<xref ref-type="bibr" rid="pbio-0040120-b029">29</xref>,
					<xref ref-type="bibr" rid="pbio-0040120-b039">39</xref>]. The activity of a unit 
					<italic>i</italic> at time 
					<italic>t</italic> and level 
					<italic>l</italic> is given by
				</p>
        <p>
					<disp-formula id="pbio-0040120-e001"><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.e001" xlink:type="simple"/></disp-formula>
				</p>
        <p>where 
					<italic>f</italic>(
					<italic>x</italic>) = 1 − 
					<italic>e</italic><sup>−
						<italic>x</italic><sup>2</sup></sup> is the unit's nonlinear, saturating activation function. The weight vectors 
					<inline-formula id="pbio-0040120-ex002"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040120.ex002" xlink:type="simple"/></inline-formula> characterize the linear feed-forward mapping of the two subunits, respectively. The vector 
					<inline-formula id="pbio-0040120-ex003"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040120.ex003" xlink:type="simple"/></inline-formula>(
					<italic>t</italic>) represents the main input to the hierarchy (
					<italic>l</italic> = 1) or the output 
					<inline-formula id="pbio-0040120-ex004"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040120.ex004" xlink:type="simple"/></inline-formula><sub>
						<italic>l</italic>−1
					</sub>(
					<italic>t</italic>) of the afferent level (
					<italic>l</italic> &gt; 1). The latter is computed from the level's activity according to the following equation:
				</p>
        <p>
					<disp-formula id="pbio-0040120-e002"><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.e002" xlink:type="simple"/></disp-formula>
				</p>
        <p>where</p>
        <p>
					<disp-formula id="pbio-0040120-e003"><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.e003" xlink:type="simple"/></disp-formula>
				</p>
        <p>〈·〉
					<italic><sub>t</sub>
					</italic> is the temporal average and var
					<italic><sub>t</sub>
					</italic>(·) the variance over time. Thus, the output is a running average of the activity, mean-corrected and normalized to unit variance. This leaky integration over time, with a time-constant of 
					<italic>τ<sub>l</sub>
					</italic> = 2
					<italic><sup>l</sup>
					</italic> time steps, constitutes the local memory of each unit.
				</p>
        <p>The feed-forward connectivity between the levels of the hierarchy are chosen such that the relative arbor within the afferent level increases while moving up the hierarchy. For this purpose, the units in the different levels are arranged in three three-dimensional lattices. All units in a level then receive input from a subset of units of equal size, geometrically aligned with respect to the first two dimensions of the lattices such that an even coverage of the afferent level is achieved (see 
					<xref ref-type="table" rid="pbio-0040120-t001">Table 1</xref>).
				</p>
        <table-wrap id="pbio-0040120-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.0040120.t001</object-id><label>Table 1</label><caption>
            <p>Feed-Forward Network Connectivity</p>
          </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.t001" xlink:type="simple"/></table-wrap>
        <p>In contrast to the feed-forward mapping between levels, the intralevel connections do not directly influence a unit's activity but merely exchange learning signals between units. These learning signals serve to decorrelate the representations formed within a level and are directly derived from the objective function described below.</p>
      </sec>
      <sec id="s4c">
        <title>Optimization</title>
        <p>The system is using an online learning algorithm as opposed to batch learning and therefore all the statistics are computed continuously using running averages, with a characteristic time-constant of a 1000 time steps. The weight vectors 
					<inline-formula id="pbio-0040120-ex005"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040120.ex005" xlink:type="simple"/></inline-formula> are subject to unsupervised learning which aims to maximize the objective function 
					<italic>ψ<sub>l</sub>
					</italic> for each level, using standard gradient ascent.
				</p>
        <p>
					<disp-formula id="pbio-0040120-e004"><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.e004" xlink:type="simple"/></disp-formula>
				</p>
        <p>where 
					<inline-formula id="pbio-0040120-ex006"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040120.ex006" xlink:type="simple"/></inline-formula> is the temporal correlation between units 
					<italic>i</italic> and 
					<italic>j,</italic> i.e.,
				</p>
        <p>
					<disp-formula id="pbio-0040120-e005"><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0040120.e005" xlink:type="simple"/></disp-formula>
				</p>
        <p>cov
					<italic><sub>t</sub>
					</italic> (·,·) is the covariance over time.
				</p>
        <p>The first term of the objective function becomes small for signals varying smoothly/slowly over time with respect to the timescale given by 
					<inline-formula id="pbio-0040120-ex007"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040120.ex007" xlink:type="simple"/></inline-formula> time steps. In order to prevent the trivial solution 
					<inline-formula id="pbio-0040120-ex008"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040120.ex008" xlink:type="simple"/></inline-formula>, this term incorporates a division by the unit's variance. Minimizing the second term forces pairs of units to become maximally decorrelated. Please note that in contrast to the first term of the objective, which solely incorporates information local to each unit 
					<inline-formula id="pbio-0040120-ex009"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040120.ex009" xlink:type="simple"/></inline-formula>, the decorrelation term requires information from two units 
					<inline-formula id="pbio-0040120-ex010"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040120.ex010" xlink:type="simple"/></inline-formula> and 
					<inline-formula id="pbio-0040120-ex011"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.0040120.ex011" xlink:type="simple"/></inline-formula> for 
					<italic>i</italic> ≠ 
					<italic>j</italic>. This information is exchanged through the lateral connectivity within a level, whereas its extent determines which pairs of units are decorrelated (<xref ref-type="fig" rid="pbio-0040120-g001">Figure 1</xref>B). In our experiments, we chose to decorrelate all pairs of units that share common feed-forward input. The last term implements a form of regularization that aims to reduce the average activity of each unit. The relative importance of the three terms is controlled by the parameters 
					<italic>β</italic>, 
					<italic>Γ</italic> ≥ 0. For 
					<italic>β</italic> ≪ 1, the first term dominates such that the units' activity become maximally stable while being strongly correlated. For 
					<italic>β</italic> ≫ 1, the units' activities become well-decorrelated but fail to extract the stable features from their input. Thus, 
					<italic>β</italic> must be chosen between these extreme cases to allow an optimal balance between the two first terms of the objective. The particular choice for 
					<italic>Γ</italic> was found to be less critical. For all the experiments presented in this study, we used 
					<italic>β</italic> = 5/
					<italic>N<sub>l</sub>
					</italic> and 
					<italic>Γ</italic> = 20/
					<italic>N<sub>l</sub>
					</italic> where 
					<italic>N<sub>l</sub>
					</italic> is the number of units in level 
					<italic>l</italic>.
				</p>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="sg001" mimetype="application/pdf" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0040120.sg001" xlink:type="simple">
        <label>Figure S1</label>
        <caption>
          <title>Spatial Distribution of Reconstruction Error</title>
          <p>The position of the robot is reconstructed based on the responses from the 16 units at the highest level of the hierarchy. The resulting reconstruction error is color-coded as a function of the position within the environment. The reconstruction quality is good in large parts of the central region of the environment and becomes poorer at the borders. The latter is due to two issues: 1) the extreme border regions of the environment are not visited as often such that the estimation of the posterior probabilities becomes less accurate leading to large errors; 2) when the robot faces the wall around the border of the environment, its visual stimulus is dominated by the wall, which looks identical from different positions. This leads to perceptual singularities (i.e., same perception for different locations), yielding similar network activation patterns which can result in large reconstruction errors.</p>
          <p>(2 KB PDF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank Konrad Körding for valuable discussions concerning all aspects of objective functions and Armin Duff and Fabian Roth for general discussions.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pbio-0040120-b001">
        <label>1</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Felleman</surname>
              <given-names>DJ</given-names>
            </name>
            <name name-style="western">
              <surname>van Essen</surname>
              <given-names>DC</given-names>
            </name>
          </person-group>
          <article-title>Distributed hierarchical processing in the primate cerebral cortex.</article-title>
          <source>Cereb Cortex</source>
          <year>1991</year>
          <volume>1</volume>
          <fpage>1</fpage>
          <lpage>47</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b002">
        <label>2</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Hubel</surname>
              <given-names>DH</given-names>
            </name>
            <name name-style="western">
              <surname>Wiesel</surname>
              <given-names>TN</given-names>
            </name>
          </person-group>
          <article-title>Receptive fields, binocular interaction and functional architecture in the cat's visual cortex.</article-title>
          <source>J Physiol</source>
          <year>1962</year>
          <volume>160</volume>
          <fpage>106</fpage>
          <lpage>154</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b003">
        <label>3</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Tanaka</surname>
              <given-names>K</given-names>
            </name>
          </person-group>
          <article-title>Representation of visual features of objects in the inferotemporal cortex.</article-title>
          <source>Neural Netw</source>
          <year>1996</year>
          <volume>9</volume>
          <fpage>1459</fpage>
          <lpage>1475</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b004">
        <label>4</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Epstein</surname>
              <given-names>R</given-names>
            </name>
            <name name-style="western">
              <surname>Kanwisher</surname>
              <given-names>N</given-names>
            </name>
          </person-group>
          <article-title>A cortical representation of the local visual environment.</article-title>
          <source>Nature</source>
          <year>1998</year>
          <volume>392</volume>
          <fpage>598</fpage>
          <lpage>601</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b005">
        <label>5</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Kreiman</surname>
              <given-names>G</given-names>
            </name>
            <name name-style="western">
              <surname>Koch</surname>
              <given-names>C</given-names>
            </name>
            <name name-style="western">
              <surname>Fried</surname>
              <given-names>I</given-names>
            </name>
          </person-group>
          <article-title>Category-specific visual responses of single neurons in the human medial temporal lobe.</article-title>
          <source>Nat Neurosci</source>
          <year>2000</year>
          <volume>3</volume>
          <fpage>946</fpage>
          <lpage>953</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b006">
        <label>6</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Fyhn</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Molden</surname>
              <given-names>S</given-names>
            </name>
            <name name-style="western">
              <surname>Witter</surname>
              <given-names>MP</given-names>
            </name>
            <name name-style="western">
              <surname>Moser</surname>
              <given-names>EI</given-names>
            </name>
            <name name-style="western">
              <surname>Moser</surname>
              <given-names>MB</given-names>
            </name>
          </person-group>
          <article-title>Spatial representation in the entorhinal cortex.</article-title>
          <source>Science</source>
          <year>2004</year>
          <volume>305</volume>
          <fpage>1258</fpage>
          <lpage>1264</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b007">
        <label>7</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>O'Keefe</surname>
              <given-names>J</given-names>
            </name>
            <name name-style="western">
              <surname>Nadel</surname>
              <given-names>L</given-names>
            </name>
          </person-group>
          <source>The hippocampus as a cognitive map</source>
          <year>1978</year>
          <publisher-loc>Oxford</publisher-loc>
          <publisher-name>Clarendon Press</publisher-name>
          <page-count count="570"/>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b008">
        <label>8</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Ito</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Tamura</surname>
              <given-names>H</given-names>
            </name>
            <name name-style="western">
              <surname>Fujita</surname>
              <given-names>I</given-names>
            </name>
            <name name-style="western">
              <surname>Tanaka</surname>
              <given-names>K</given-names>
            </name>
          </person-group>
          <article-title>Size and position invariance of neuronal responses in monkey inferotemporal cortex.</article-title>
          <source>J Neurophysiol</source>
          <year>1995</year>
          <volume>73</volume>
          <fpage>218</fpage>
          <lpage>226</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b009">
        <label>9</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Fukushima</surname>
              <given-names>K</given-names>
            </name>
          </person-group>
          <article-title>Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position.</article-title>
          <source>Biol Cybern</source>
          <year>1980</year>
          <volume>36</volume>
          <fpage>193</fpage>
          <lpage>202</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b010">
        <label>10</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Wallis</surname>
              <given-names>G</given-names>
            </name>
          </person-group>
          <article-title>Using spatio-temporal correlations to learn invariant object recognition.</article-title>
          <source>Neural Netw</source>
          <year>1996</year>
          <volume>9</volume>
          <fpage>1513</fpage>
          <lpage>1519</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b011">
        <label>11</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Wallis</surname>
              <given-names>G</given-names>
            </name>
            <name name-style="western">
              <surname>Rolls</surname>
              <given-names>ET</given-names>
            </name>
          </person-group>
          <article-title>Invariant face and object recognition in the visual system.</article-title>
          <source>Prog Neurobiol</source>
          <year>1997</year>
          <volume>51</volume>
          <fpage>167</fpage>
          <lpage>194</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b012">
        <label>12</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Riesenhuber</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Poggio</surname>
              <given-names>T</given-names>
            </name>
          </person-group>
          <article-title>Hierarchical models of object recognition in cortex.</article-title>
          <source>Nat Neursci</source>
          <year>1999</year>
          <volume>2</volume>
          <fpage>1019</fpage>
          <lpage>1025</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b013">
        <label>13</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Wersing</surname>
              <given-names>H</given-names>
            </name>
            <name name-style="western">
              <surname>Körner</surname>
              <given-names>E</given-names>
            </name>
          </person-group>
          <article-title>Learning optimized features for hierarchical models of invariant object recognition.</article-title>
          <source>Neural Comput</source>
          <year>2003</year>
          <volume>15</volume>
          <fpage>1559</fpage>
          <lpage>1588</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b014">
        <label>14</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Barlow</surname>
              <given-names>HB</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name name-style="western">
              <surname>Rosenblith</surname>
              <given-names>W</given-names>
            </name>
          </person-group>
          <article-title>Possible principles underlying the transformation of sensory messages.</article-title>
          <source>Sensory Communication</source>
          <year>1961</year>
          <publisher-loc>Cambridge (Massachusetts)</publisher-loc>
          <publisher-name>MIT Press</publisher-name>
          <fpage>336</fpage>
          <lpage>360</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b015">
        <label>15</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Olshausen</surname>
              <given-names>BA</given-names>
            </name>
            <name name-style="western">
              <surname>Field</surname>
              <given-names>DJ</given-names>
            </name>
          </person-group>
          <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images.</article-title>
          <source>Nature</source>
          <year>1996</year>
          <volume>381</volume>
          <fpage>607</fpage>
          <lpage>609</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b016">
        <label>16</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Lewicki</surname>
              <given-names>MS</given-names>
            </name>
          </person-group>
          <article-title>Efficient coding of natural sounds.</article-title>
          <source>Nat Neurosci</source>
          <year>2002</year>
          <volume>5</volume>
          <fpage>356</fpage>
          <lpage>363</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b017">
        <label>17</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Földiak</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Learning invariance from transformation seqeuences.</article-title>
          <source>Neural Comput</source>
          <year>1991</year>
          <volume>3</volume>
          <fpage>194</fpage>
          <lpage>200</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b018">
        <label>18</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Becker</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Implicit learning in 3D object recognition: The importance of temporal context.</article-title>
          <source>Neural Comput</source>
          <year>1999</year>
          <volume>11</volume>
          <fpage>347</fpage>
          <lpage>374</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b019">
        <label>19</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Wiskott</surname>
              <given-names>L</given-names>
            </name>
            <name name-style="western">
              <surname>Sejnowski</surname>
              <given-names>TJ</given-names>
            </name>
          </person-group>
          <article-title>Slow feature analysis: Unsupervised learning of invariances.</article-title>
          <source>Neural Comput</source>
          <year>2002</year>
          <volume>14</volume>
          <fpage>715</fpage>
          <lpage>770</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b020">
        <label>20</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Körding</surname>
              <given-names>KP</given-names>
            </name>
            <name name-style="western">
              <surname>Kayser</surname>
              <given-names>C</given-names>
            </name>
            <name name-style="western">
              <surname>Einhäuser</surname>
              <given-names>W</given-names>
            </name>
            <name name-style="western">
              <surname>König</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>How are complex cell properties adapted to the statistics of natural stimuli?</article-title>
          <source>J Neurophysiol</source>
          <year>2004</year>
          <volume>91</volume>
          <fpage>206</fpage>
          <lpage>212</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b021">
        <label>21</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Muller</surname>
              <given-names>RU</given-names>
            </name>
            <name name-style="western">
              <surname>Kubie</surname>
              <given-names>JL</given-names>
            </name>
          </person-group>
          <article-title>The effects of changes in the environment on the spatial firing of hippocampal complex-spike cells.</article-title>
          <source>J Neurosci</source>
          <year>1987</year>
          <volume>7</volume>
          <fpage>1951</fpage>
          <lpage>1968</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b022">
        <label>22</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Hegde</surname>
              <given-names>J</given-names>
            </name>
            <name name-style="western">
              <surname>Van Essen</surname>
              <given-names>DC</given-names>
            </name>
          </person-group>
          <article-title>Selectivity for complex shapes in primate visual area v2.</article-title>
          <source>J Neurosci</source>
          <year>2000</year>
          <volume>20</volume>
          <fpage>RC61</fpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b023">
        <label>23</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Pasupathy</surname>
              <given-names>A</given-names>
            </name>
            <name name-style="western">
              <surname>Connor</surname>
              <given-names>CE</given-names>
            </name>
          </person-group>
          <article-title>Responses to contour features in macaque area v4. J.</article-title>
          <source>Neurophysiol</source>
          <year>1999</year>
          <volume>82</volume>
          <fpage>2490</fpage>
          <lpage>2502</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b024">
        <label>24</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Zhang</surname>
              <given-names>K</given-names>
            </name>
            <name name-style="western">
              <surname>Ginzburg</surname>
              <given-names>I</given-names>
            </name>
            <name name-style="western">
              <surname>McNaughton</surname>
              <given-names>BL</given-names>
            </name>
            <name name-style="western">
              <surname>Sejnowski</surname>
              <given-names>TJ</given-names>
            </name>
          </person-group>
          <article-title>Interpreting neuronal population activity by reconstruction: Unified framework with application in hippocampal place cells.</article-title>
          <source>J Neurophysiol</source>
          <year>1998</year>
          <volume>79</volume>
          <fpage>1017</fpage>
          <lpage>1044</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b025">
        <label>25</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Bostock</surname>
              <given-names>E</given-names>
            </name>
            <name name-style="western">
              <surname>Muller</surname>
              <given-names>R</given-names>
            </name>
            <name name-style="western">
              <surname>Kubie</surname>
              <given-names>JL</given-names>
            </name>
          </person-group>
          <article-title>Experience-dependent modifications of hippocampal place cell firing.</article-title>
          <source>Hippocampus</source>
          <year>1991</year>
          <volume>1</volume>
          <fpage>193</fpage>
          <lpage>205</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b026">
        <label>26</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>O'Keefe</surname>
              <given-names>J</given-names>
            </name>
            <name name-style="western">
              <surname>Burgess</surname>
              <given-names>N</given-names>
            </name>
          </person-group>
          <article-title>Geometric determinants of the place fields of hippocampal neurons.</article-title>
          <source>Nature</source>
          <year>1996</year>
          <volume>381</volume>
          <fpage>425</fpage>
          <lpage>428</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b027">
        <label>27</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Vogels</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <article-title>Categorization of complex visual images by rhesus monkeys. Part 2: Single-cell study.</article-title>
          <source>Eur J Neurosci</source>
          <year>1999</year>
          <volume>11</volume>
          <fpage>1239</fpage>
          <lpage>1255</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b028">
        <label>28</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Rainer</surname>
              <given-names>G</given-names>
            </name>
            <name name-style="western">
              <surname>Augath</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Trinath</surname>
              <given-names>T</given-names>
            </name>
            <name name-style="western">
              <surname>Logothetis</surname>
              <given-names>NK</given-names>
            </name>
          </person-group>
          <article-title>The effect of image scrambling on visual cortical bold activity in the anesthetized monkey.</article-title>
          <source>Neuroimage</source>
          <year>2002</year>
          <volume>16</volume>
          <fpage>607</fpage>
          <lpage>616</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b029">
        <label>29</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Kayser</surname>
              <given-names>C</given-names>
            </name>
            <name name-style="western">
              <surname>Körding</surname>
              <given-names>KP</given-names>
            </name>
            <name name-style="western">
              <surname>König</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Learning the nonlinearity of neurons from natural visual stimuli.</article-title>
          <source>Neural Comput</source>
          <year>2003</year>
          <volume>15</volume>
          <fpage>1751</fpage>
          <lpage>1759</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b030">
        <label>30</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Lau</surname>
              <given-names>B</given-names>
            </name>
            <name name-style="western">
              <surname>Stanley</surname>
              <given-names>GB</given-names>
            </name>
            <name name-style="western">
              <surname>Dan</surname>
              <given-names>Y</given-names>
            </name>
          </person-group>
          <article-title>Computational subunits of visual cortical neurons revealed by artificial neural networks.</article-title>
          <source>Proc Natl Acad Sci U S A</source>
          <year>2002</year>
          <volume>99</volume>
          <fpage>8974</fpage>
          <lpage>8979</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b031">
        <label>31</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Douglas</surname>
              <given-names>RJ</given-names>
            </name>
            <name name-style="western">
              <surname>Martin</surname>
              <given-names>KAC</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name name-style="western">
              <surname>Shepherd</surname>
              <given-names>GM</given-names>
            </name>
          </person-group>
          <article-title>Neocortex.</article-title>
          <source>The Synaptic Organization of the Brain</source>
          <year>1990</year>
          <publisher-loc>Oxford</publisher-loc>
          <publisher-name>Oxford University Press</publisher-name>
          <fpage>389</fpage>
          <lpage>438</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b032">
        <label>32</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Douglas</surname>
              <given-names>RJ</given-names>
            </name>
            <name name-style="western">
              <surname>Martin</surname>
              <given-names>KA</given-names>
            </name>
          </person-group>
          <article-title>Neuronal circuits of the neocortex.</article-title>
          <source>Annu Rev Neurosci</source>
          <year>2004</year>
          <volume>27</volume>
          <fpage>419</fpage>
          <lpage>451</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b033">
        <label>33</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Orbach</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <source>The neuropsychological theories of Lashley and Hebb</source>
          <year>1998</year>
          <publisher-loc>Lanham (Maryland)</publisher-loc>
          <publisher-name>University Press of America</publisher-name>
          <page-count count="395"/>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b034">
        <label>34</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Mundale</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Concepts of localization: Balkanization in the brain.</article-title>
          <source>Brain Mind</source>
          <year>2002</year>
          <volume>3</volume>
          <fpage>313</fpage>
          <lpage>330</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b035">
        <label>35</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Sur</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Leamy</surname>
              <given-names>CA</given-names>
            </name>
          </person-group>
          <article-title>Development and plasticity of cortical areas and networks.</article-title>
          <source>Nat Rev Neurosci</source>
          <year>2001</year>
          <volume>2</volume>
          <fpage>251</fpage>
          <lpage>262</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b036">
        <label>36</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Liegeois</surname>
              <given-names>F</given-names>
            </name>
            <name name-style="western">
              <surname>Connelly</surname>
              <given-names>A</given-names>
            </name>
            <name name-style="western">
              <surname>Cross</surname>
              <given-names>JH</given-names>
            </name>
            <name name-style="western">
              <surname>Boyd</surname>
              <given-names>SG</given-names>
            </name>
            <name name-style="western">
              <surname>Gadian</surname>
              <given-names>DG</given-names>
            </name>
            <name name-style="western">
              <surname>Vargha-Khadem</surname>
              <given-names>F</given-names>
            </name>
            <name name-style="western">
              <surname>Baldeweg</surname>
              <given-names>T</given-names>
            </name>
          </person-group>
          <article-title>Language reorganization in children with early-onset lesions of the left hemisphere: An fMRI study.</article-title>
          <source>Brain</source>
          <year>2004</year>
          <volume>127</volume>
          <issue>Part 6</issue>
          <fpage>1229</fpage>
          <lpage>1236</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b037">
        <label>37</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Sur</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Garraghty</surname>
              <given-names>PE</given-names>
            </name>
            <name name-style="western">
              <surname>Roe</surname>
              <given-names>AW</given-names>
            </name>
          </person-group>
          <article-title>Experimentally induced visual projections into auditory thalamus and cortex.</article-title>
          <source>Science</source>
          <year>1988</year>
          <volume>242</volume>
          <fpage>1437</fpage>
          <lpage>1441</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b038">
        <label>38</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Amedi</surname>
              <given-names>A</given-names>
            </name>
            <name name-style="western">
              <surname>Raz</surname>
              <given-names>N</given-names>
            </name>
            <name name-style="western">
              <surname>Pianka</surname>
              <given-names>P</given-names>
            </name>
            <name name-style="western">
              <surname>Malach</surname>
              <given-names>R</given-names>
            </name>
            <name name-style="western">
              <surname>Zohary</surname>
              <given-names>E</given-names>
            </name>
          </person-group>
          <article-title>Early “visual” cortex activation correlates with superior verbal memory performance in the blind.</article-title>
          <source>Nat Neursci</source>
          <year>2003</year>
          <volume>6</volume>
          <fpage>758</fpage>
          <lpage>766</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0040120-b039">
        <label>39</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Adelson</surname>
              <given-names>EH</given-names>
            </name>
            <name name-style="western">
              <surname>Bergen</surname>
              <given-names>JR</given-names>
            </name>
          </person-group>
          <article-title>Spatiotemporal energy models for the perception of motion.</article-title>
          <source>J Opt Soc Am A Opt Image Sci Vis</source>
          <year>1985</year>
          <volume>2</volume>
          <fpage>284</fpage>
          <lpage>299</lpage>
        </nlm-citation>
      </ref>
    </ref-list>
    <glossary>
      <title>Abbreviations</title>
      <def-list>
        <def-item>
          <term>IT</term>
          <def>
            <p>inferotemporal cortex</p>
          </def>
        </def-item>
        <def-item>
          <term>RF</term>
          <def>
            <p>receptive field</p>
          </def>
        </def-item>
      </def-list>
    </glossary>
    
  </back>
</article>
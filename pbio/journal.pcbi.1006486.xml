<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006486</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-02050</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Discrete mathematics</subject><subj-group><subject>Combinatorics</subject><subj-group><subject>Permutation</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Bioassays and physiological analysis</subject><subj-group><subject>Electrophysiological techniques</subject><subj-group><subject>Brain electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain mapping</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Clinical medicine</subject><subj-group><subject>Clinical neurophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject><subj-group><subject>Normal distribution</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Bioassays and physiological analysis</subject><subj-group><subject>Electrophysiological techniques</subject><subj-group><subject>Brain electrophysiology</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-related potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain electrophysiology</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-related potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain electrophysiology</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-related potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain electrophysiology</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-related potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain mapping</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-related potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Clinical medicine</subject><subj-group><subject>Clinical neurophysiology</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-related potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-related potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-related potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical data</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research design</subject><subj-group><subject>Experimental design</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Artificial intelligence</subject><subj-group><subject>Machine learning</subject><subj-group><subject>Support vector machines</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Multivariate classification of neuroimaging data with nested subclasses: Biased accuracy and implications for hypothesis testing</article-title>
<alt-title alt-title-type="running-head">Multivariate classification of neuroimaging data with nested subclasses</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2485-2374</contrib-id>
<name name-style="western">
<surname>Jamalabadi</surname> <given-names>Hamidreza</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Alizadeh</surname> <given-names>Sarah</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Schönauer</surname> <given-names>Monika</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4859-8000</contrib-id>
<name name-style="western">
<surname>Leibold</surname> <given-names>Christian</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff006"><sup>6</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Gais</surname> <given-names>Steffen</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Medical Psychology and Behavioral Neurobiology, University of Tübingen, Tübingen, Germany</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Bernstein Center for Computational Neuroscience, Ludwig-Maximilians-Universität München, Planegg-Martinsried, Germany</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>IMPRS for Cognitive and Systems Neuroscience, University of Tübingen, Tübingen, Germany</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Department of Psychiatry, Division for Translational Psychiatry, University of Tübingen, Tübingen, Germany</addr-line></aff>
<aff id="aff005"><label>5</label> <addr-line>Department of Psychology, Ludwig-Maximilians-Universität München, München, Germany</addr-line></aff>
<aff id="aff006"><label>6</label> <addr-line>Department of Biology II, Ludwig-Maximilians-Universität München, Planegg-Martinsried, Germany</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Jbabdi</surname> <given-names>Saad</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Oxford University, UNITED KINGDOM</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">steffen.gais@uni-tuebingen.de</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>27</day>
<month>9</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="collection">
<month>9</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>9</issue>
<elocation-id>e1006486</elocation-id>
<history>
<date date-type="received">
<day>11</day>
<month>12</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>3</day>
<month>9</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Jamalabadi et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006486"/>
<abstract>
<p>Biological data sets are typically characterized by high dimensionality and low effect sizes. A powerful method for detecting systematic differences between experimental conditions in such multivariate data sets is multivariate pattern analysis (MVPA), particularly pattern classification. However, in virtually all applications, data from the classes that correspond to the conditions of interest are not homogeneous but contain subclasses. Such subclasses can for example arise from individual subjects that contribute multiple data points, or from correlations of items within classes. We show here that in multivariate data that have subclasses nested within its class structure, these subclasses introduce systematic information that improves classifiability beyond what is expected by the size of the class difference. We analytically prove that this subclass bias systematically inflates correct classification rates (CCRs) of linear classifiers depending on the number of subclasses as well as on the portion of variance induced by the subclasses. In simulations, we demonstrate that subclass bias is highest when between-class effect size is low and subclass variance high. This bias can be reduced by increasing the total number of subclasses. However, we can account for the subclass bias by using permutation tests that explicitly consider the subclass structure of the data. We illustrate our result in several experiments that recorded human EEG activity, demonstrating that parametric statistical tests as well as typical trial-wise permutation fail to determine significance of classification outcomes correctly.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>When data are analyzed using multivariate pattern classification, any systematic similarities between subsets of trials (e.g. shared physical properties among a subgroup of stimuli, trials belonging to the same session or subject, etc.) form distinct nested subclasses within each class. Pattern classification is sensitive to this kind of structure in the data and uses such groupings to increase classification accuracies even when data from both conditions are sampled from the same distribution, i.e. the null hypothesis is true. Here, we show that the bias is higher for larger subclass variances and that it is directly related to the number of subclasses and the intraclass correlation (ICC). Because the increased classification accuracy in such data sets is not based on class differences, the null distribution should be adjusted to account for this type of bias. To do so, we propose to use blocked permutation testing on subclass levels and show that it can confine the false positive rate to the predefined α-levels.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>Deutsche Forschungsgemeinschaft</institution>
</funding-source>
<award-id>GA730/3-1</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Gais</surname> <given-names>Steffen</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>Bundesministerium für Bildung und Forschung (BMBF)</institution>
</funding-source>
<award-id>01EO0901</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Gais</surname> <given-names>Steffen</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution>Bundesministerium für Bildung und Forschung (BMBF)</institution>
</funding-source>
<award-id>01GQ1004A</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4859-8000</contrib-id>
<name name-style="western">
<surname>Leibold</surname> <given-names>Christian</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This study was supported by Deutsche Forschungsgemeinschaft (DFG) grant number GA730/3-1 (<ext-link ext-link-type="uri" xlink:href="http://www.dfg.de/en/" xlink:type="simple">http://www.dfg.de/en/</ext-link>) and Bundesministerium für Bildung und Forschung (BMBF) grant number 01EO0901 (<ext-link ext-link-type="uri" xlink:href="http://www.bmbf.de/en/" xlink:type="simple">www.bmbf.de/en/</ext-link>) received by SG and also BMBF grant number 01GQ1004A received by CL. Publication supported by Deutsche Forschungsgemeinschaft and Open Access Publishing Fund of University of Tübingen. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="5"/>
<table-count count="0"/>
<page-count count="18"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-10-09</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data and code used in this paper are available on Open Science Framework (DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/FVXU3" xlink:type="simple">10.17605/OSF.IO/FVXU3</ext-link>).</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Multivariate pattern analysis (MVPA) combined with cross-validation and permutation testing allows the use of machine learning algorithms to detect differences between classes of data for statistical hypothesis testing and is frequently used in neuroscience [<xref ref-type="bibr" rid="pcbi.1006486.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1006486.ref003">3</xref>] and bioinformatics [<xref ref-type="bibr" rid="pcbi.1006486.ref004">4</xref>–<xref ref-type="bibr" rid="pcbi.1006486.ref006">6</xref>]. Whereas classical statistical approaches search for individual features in a data set that allow to distinguish two experimental conditions, MVPA analyzes data sets as a whole, searching for distinguishing multi-dimensional patterns. Therefore, it can provide increased sensitivity compared to classical multiple-univariate testing methods in high-dimensional data sets [<xref ref-type="bibr" rid="pcbi.1006486.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1006486.ref009">9</xref>]. In a typical application of MVPA, a classifier, e.g. a linear support vector machine (SVM), is trained to distinguish different classes (e.g. different experimental conditions, different groups of patients, etc.) on one part of a data set. Then, the classifier is tested on the remaining data. This results in a certain percentage of accurate classifications (correct classification rate [CCR]). To improve accuracy of CCR estimation, a cross-validation procedure is used, which assures that all parts of the data are used for training as well as testing on repeated iterations of the analysis. If the CCR lies significantly above the level expected by chance (e.g. 50% for a two-class problem), it can be concluded that a difference between classes exists.</p>
<p>In the context of classical hypothesis testing, univariate hypotheses are usually phrased in terms of differences of mean values. In a multivariate context, this translates to differences in class centroids. However, using MVPA for hypothesis testing can have a specific vulnerability compared with classical univariate methods if the data have a class-unrelated substructure. Elements that form a subclass (e.g. repeated stimuli in an experiment) share features that are specific to the subclass but not to the class. In univariate statistics, these features average out and contribute to the normal distribution of values. They therefore affect results only minimally. In a multidimensional space, however, subclasses can form distinguishable clusters [<xref ref-type="bibr" rid="pcbi.1006486.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1006486.ref011">11</xref>]. A classifier can learn to separate one or several of these clusters based on their distinguishing features instead of on those features shared by all elements of the class. This impedes the use of classifiers for testing general hypotheses regarding class differences.</p>
<p>In particular, when different subclasses are nested within the classes, the obtained classification accuracies can be systematically higher than the expected chance level, even when data of both classes are sampled from the same distribution, i.e. the null hypothesis is true. This is especially problematic because the goal of MVPA is to extract class-related structure from the data and to better understand underlying mechanisms rather than to enhance classification accuracy per se [<xref ref-type="bibr" rid="pcbi.1006486.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1006486.ref012">12</xref>]. A simplified two-dimensional example of a data set with nested subclasses is illustrated in <xref ref-type="fig" rid="pcbi.1006486.g001">Fig 1</xref>. Here, classes A and B each contain four distinguishable nested subclasses. The average CCR is above 50% (here: 70.9%, <xref ref-type="fig" rid="pcbi.1006486.g001">Fig 1a</xref>) although no systematic differences between classes A and B exist, i.e. centroids and variances of class A and B are identical. Without the presence of subclasses, the expected value of the CCR should be 50% for a two-class linear classification [<xref ref-type="bibr" rid="pcbi.1006486.ref002">2</xref>]. Importantly however, the simple presence of structure due to the subclasses, which is completely unrelated to the classes themselves, allows higher classification rates (<xref ref-type="fig" rid="pcbi.1006486.g001">Fig 1b and 1c</xref>). In this example, separability of eight subclasses along two feature dimensions leads to an average CCR of 71.1% over all possible random attributions of subclasses to classes A and B (<xref ref-type="fig" rid="pcbi.1006486.g001">Fig 1b</xref>). As we will show below, this behavior can be observed to a varying degree in every data set in which classes consist of distinct subclasses (e.g. types of stimuli, groups of subjects, multiple recording sessions, blocks of fMRI recording, temporally correlated trials, etc.). We will present simulations as well as analytical results that show that MVPA with linear classifiers systematically produces inflated accuracies when applied to data containing nested subclasses.</p>
<fig id="pcbi.1006486.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006486.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Classification accuracy in data with subclasses can exceed chance level even if data are randomly attributed to two conditions.</title>
<p>(a) Center: An exemplary data set with 4 subclasses per class (blue and red). Although classes have almost identical multivariate means (represented by two filled circles in the center), classification of this data set with LDA using 2-fold cross-validation leads to 70.9% classification accuracy. Surrounding plots show five possible random assignments of subclasses to two new classes (“closed-symbol” versus “open-symbol”), if each new class has two subclasses from original classes (blue and red). (b) The data set in the center of (a) can be randomly divided into two new “closed-symbol” versus “open-symbol” classes of 4 subclasses in 18 ways <inline-formula id="pcbi.1006486.e001"><alternatives><graphic id="pcbi.1006486.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mo>(</mml:mo> <mml:msup><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:mrow><mml:mfrac linethickness="0pt"><mml:mrow><mml:mn>4</mml:mn></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>). The table shows all 18 possible configurations with their respective CCRs. Each cell in the table shows the four random subclasses assigned to the newly built “closed-symbol” class (the remaining symbols will belong to the “open-symbol” class) and their corresponding classification accuracy. Note that only few of these random assignments show close to chance level CCRs. The average CCR for all 18 possible randomizations is 71.1%. (c) Simulating 2000 data sets with the same structure as in (a), i.e. two classes, each with four subclasses, identical centroids and variances, results in a null distribution with a mean CCR of 68.7%. Since these data sets are sampled from identical distributions, these classification accuracies represent the empirical null distribution for the data set shown in the center of (a).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006486.g001" xlink:type="simple"/>
</fig>
<p>There are three sources of variance that are of interest in the present considerations [<xref ref-type="bibr" rid="pcbi.1006486.ref013">13</xref>], which describe a multilevel model that can be specified as follows: <italic>y</italic><sub><italic>ijk</italic></sub> = <italic>C</italic><sub><italic>i</italic></sub> + <italic>S</italic><sub><italic>ij</italic></sub> + <italic>ϵ</italic><sub><italic>ijk</italic></sub>. <italic>y</italic><sub><italic>ijk</italic></sub> are individual measurements, e.g. physiological brain responses to certain stimuli. <italic>C</italic><sub><italic>i</italic>∈[1,2]</sub> represents the class centroids, e.g. the influence of an experimental manipulation, the difference between patient and control group, or the responses to different conditions. <italic>S</italic><sub><italic>ij</italic></sub> are the centroids of the <italic>j</italic><sup><italic>th</italic></sup> subclass within class <italic>i</italic> and represent the vector from the class centroid to the subclass centroid. The variance <inline-formula id="pcbi.1006486.e002"><alternatives><graphic id="pcbi.1006486.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> of the set of centroids reflects differences that are class-unrelated [<xref ref-type="bibr" rid="pcbi.1006486.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006486.ref015">15</xref>]. <italic>ϵ</italic><sub><italic>ijk</italic></sub> reflects the deviation from the subclass mean arising from the within-class error variance <inline-formula id="pcbi.1006486.e003"><alternatives><graphic id="pcbi.1006486.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>W</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and represents e.g. measurement noise. In classical statistics, it has been demonstrated that failing to accommodate for the effect of non-zero subclass variance can produce large false positive rates [<xref ref-type="bibr" rid="pcbi.1006486.ref016">16</xref>] and the ratio of subclass-to-trial-variance, defined as the intraclass correlation (<inline-formula id="pcbi.1006486.e004"><alternatives><graphic id="pcbi.1006486.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mi>I</mml:mi> <mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow> <mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:mspace width="2pt"/><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>W</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>), determines the extent to which subclass variation affects statistical conclusions [<xref ref-type="bibr" rid="pcbi.1006486.ref016">16</xref>]. Because it is usually difficult to separate the influence of subclasses from the main class effects [<xref ref-type="bibr" rid="pcbi.1006486.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1006486.ref018">18</xref>], experiments and statistical analyses must be designed to avoid these confounds. In the present paper, we will investigate the boundary conditions and consequences of this phenomenon when using linear classifiers and describe a method to circumvent false positive results.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Practical Example 1: Biased accuracy in hierarchically nested subclasses</title>
<p>The following example illustrates how a nested factor can influence the expected classification accuracy in an experiment that investigates the EEG responses to the visual presentation of digits and letters [<xref ref-type="bibr" rid="pcbi.1006486.ref010">10</xref>]. The experiment was performed by 19 healthy subjects. All participants were right-handed, between 18 and 30 years old, native German speakers and non-smokers. Subjects underwent EEG recording in two different sessions at two different days while performing a short-term memory task with digits from 0 to 9 and 10 consonant letters, which were selected randomly but remained the same for all the subjects. During each trial of the encoding phase, participants were instructed to memorize strings of 7 digits or 7 letters that were presented sequentially. Each stimulus was shown on a black screen for 100 ms with an inter-stimulus interval of 1 s. After a 4-s maintenance interval, a probe item was presented, and subjects were asked if it had been in the sequence of stimuli. For each stimulus, 18 presentations were used. EEG was recorded using an active 128-channel Ag/AgCl-electrode system (ActiCap, Brain products, Gilching, Germany) with 1 kHz sampling frequency and a high-pass filter of 0.1 Hz. Electrodes were placed according to the extended international 10–20 electrode system.</p>
<p>Here we were interested in whether digits and letters could be distinguished based on the encoding phase of event-related potentials (ERPs). EEG data were low-pass filtered offline at 40 Hz and divided into epochs of one second, starting 50 ms before to 950 ms post stimulus onset. Artefact rejection was done in a semiautomatic process using custom MATLAB scripts based on overall power, extreme amplitude changes, and muscle artefacts. Artefact thresholds were automatically detected based on the variance of the data and manually confirmed upon visual inspection of parameter distributions and of the raw data. Epochs containing artefacts were removed from the data set, channels that contained too many epochs with artefacts were removed and spherically interpolated using routines provided by EEGLAB [<xref ref-type="bibr" rid="pcbi.1006486.ref019">19</xref>].</p>
<p>To decode brain activity, we classified single-trial EEG using a linear support vector machine (SVM) with 2-fold cross-validation. A 2-fold cross-validation was used, because the resulting classification accuracies have the same mean as other cross-validation schemes but a lower variance. When testing for significance against a null distribution obtained with randomization tests, 2-fold cross-validation therefore has a higher statistical power [<xref ref-type="bibr" rid="pcbi.1006486.ref002">2</xref>]. As input to the classifier, we used the 1-s ERP response of all 128 channels. The classifier was trained and tested within each subject and session. This procedure resulted in a mean classification accuracy of 54.2% over all subjects and sessions. Using trial-wise permutation with 1000 random repetitions to determine the null distribution, 16 out of 38 sessions had classification accuracies significantly above 50% (p &lt; 0.05). Combined over all sessions [<xref ref-type="bibr" rid="pcbi.1006486.ref003">3</xref>] the group level 90% confidence interval [CI] is [49.3%, 50.7%].</p>
<p>However, the example in <xref ref-type="fig" rid="pcbi.1006486.g001">Fig 1</xref> suggests that the classifier might detect only local features of the distinct stimuli (10 digits, 10 letters), which represent 20 subclasses, instead of a generalizable difference between digits and letters. The significant findings in this case could not be interpreted in the sense that the EEG reflects a systematic difference in brain processing of digits and letters, but only in the sense that at least one of the stimuli evokes a distinctive ERP signal. In case both subclass and class effects are present, the CCR will be higher than it could have been expected if only a class effect was present. To quantify this bias, we determined the null distribution of classification accuracies for data with intact subclass structure, but without information about the main classes. To do so, data is permuted in a way that keeps subclasses together but still assigns random class labels, thus effectively removing any class-related information (<xref ref-type="fig" rid="pcbi.1006486.g002">Fig 2a</xref>). This procedure uses permutation at the subclass level instead of the usual trial-level randomization [<xref ref-type="bibr" rid="pcbi.1006486.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1006486.ref020">20</xref>]. Trial-level permutation treats every trial as an independent observation and removes class-related as well as other structure from the data. This will result in the null distribution of the data assuming that no systematic relation between trials exists. However, if the data contain subclasses, trials within these subclasses are systematically related. To control for the influence of this structure at the subclass level, the dependencies at the subclass level must be kept intact while removing class-level information [<xref ref-type="bibr" rid="pcbi.1006486.ref020">20</xref>].</p>
<fig id="pcbi.1006486.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006486.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Nested subclass structure biases classification accuracy. This bias can be observed using a block permutation strategy.</title>
<p>(a) The flowchart of adjusted permutation test for an exemplary data set with 6 subclasses per class. To cancel the main effect, we build two new classes of <italic>α</italic> and <italic>β</italic> each containing exactly half of the subclasses from A (A<sub>1</sub>, A<sub>2</sub>, …) and B (B<sub>1</sub>, B<sub>2</sub>, …). <italic>A</italic>\<italic>α</italic><sub><italic>h</italic></sub> and <italic>B</italic>\<italic>β</italic><sub><italic>h</italic></sub> show the complement of <italic>α</italic><sub><italic>h</italic></sub> and <italic>β</italic><sub><italic>h</italic></sub>. We build the null distribution by classifying data from newly built classes of <italic>C</italic><sub>1</sub> and <italic>C</italic><sub>2</sub>. The classification accuracy of <italic>A</italic> versus <italic>B</italic> is then compared to this distribution. Importantly, since this procedure preserves the subclass effect, the mean of adjusted null distribution lies beyond 50% if data subclass variance is greater than zero (see <xref ref-type="fig" rid="pcbi.1006486.g003">Fig 3</xref> for details). (b) Data from Practical Example 1 show subclasses formed by trials belonging to distinct digits and letters. The histogram shows the null distribution of CCRs and the p-value for one subject. (c) Data from Practical Example 2 show subclasses formed by trials belonging to different subjects. The histogram shows the null distribution of CCRs and the p-value.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006486.g002" xlink:type="simple"/>
</fig>
<p>To determine the null distribution, we assign 5 digits and 5 letters to one class and the other 5 digits and 5 letters to the other class. We can draw randomly from <inline-formula id="pcbi.1006486.e005"><alternatives><graphic id="pcbi.1006486.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:msup><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:mrow><mml:mfrac linethickness="0pt"><mml:mrow><mml:mn>10</mml:mn></mml:mrow> <mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mn>31752</mml:mn></mml:math></alternatives></inline-formula> possible permutations of these random assignments if labels of subclasses are distributed between classes in a balanced fashion. Classification results above 50% on average must be related to the subclass structure of the data because class information has been removed. Here, classification over 1000 random permutations results in an average CCR of 50.9% for the two sessions, which deviates significantly from 50% (90% CI: [50.2%, 51.6%]), showing that the subclass variance results in a significant bias (<xref ref-type="fig" rid="pcbi.1006486.g002">Fig 2b</xref>). Using the subject-wise adjusted null distributions, 11 out of 38 sessions remain significantly above chance (<italic>p</italic> &lt; 0.05) compared to 16 sessions without adjustment, showing that using a trial-wise permutation test increases false positive findings considerably.</p>
</sec>
<sec id="sec004">
<title>Practical Example 2: Subject variability as a nested factor</title>
<p>In another data set with nested subclasses, we analyzed ERP responses to the presentation of pictures of faces and houses, a paradigm that is widely accepted to activate distinct brain regions. EEG was recorded from 20 healthy subjects in one session. The procedure was similar to the experiment in Practical Example 1 with the only difference that the working memory task was performed with sequences of 8 pictures of either faces or houses that were randomly selected from a pool of 100 pictures of faces and 100 pictures of houses. EEG recording and preprocessing was done with the same procedure as in Practical Example 1 above. Our aim here was to test whether pictures of faces and houses elicit distinct ERP responses that can be generalized over subjects. We used artefact-free ERPs from 30 presentations of faces to 10 subjects and from 30 presentations of houses to 10 different subjects, resulting in 300 trials per class. We classified the data with linear SVM using 2-fold cross validation resulting in a classification accuracy of 82.4% (see <xref ref-type="fig" rid="pcbi.1006486.g002">Fig 2c</xref>). Because variability of EEG between subjects is larger than the variability across conditions, EEG trials from distinct subjects establish subclasses in this data set. Therefore, following the logic in Practical Example 1, it cannot be assumed that the classification accuracy is solely driven by the effect of the main classes (here faces vs houses). To address this problem, we treated data from different subjects as subclasses and randomized the class assignment by assigning EEG of faces from 5 subjects and 5 houses to one class and the other 5 subjects with presentation of faces and 5 subjects with presentation of houses to the other class. Like in Experiment 1, we can draw randomly from <inline-formula id="pcbi.1006486.e006"><alternatives><graphic id="pcbi.1006486.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:msup><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:mrow><mml:mfrac linethickness="0pt"><mml:mrow><mml:mn>10</mml:mn></mml:mrow> <mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mn>31752</mml:mn></mml:math></alternatives></inline-formula> possible permutations of these random assignments if labels of subclasses are distributed between classes in a balanced fashion. Here, classification over 1000 random permutations results in a null distribution with a mean of 78.5% and a 90% CI of [74.6–82.2%]. This indicates that there are enormous differences between EEG of different subjects, which strongly bias classification accuracy. The main effect of faces and houses still reaches significance (p &lt; 0.045).</p>
</sec>
<sec id="sec005">
<title>Simulating biased classification results in data with nested subclasses</title>
<p>The previous examples showed that CCRs can in practice diverge from the ground truth chance level. To investigate the effect of nested subclasses on classification accuracies systematically, we used synthetically generated data with varying subclass and class variance according to the multilevel model described in introduction. Nested subclasses are subclasses that do not overlap between the two classes (e.g. 10 letters and 10 digits as in Practical Example 1 above). We studied the distribution of CCRs in four series of two-class experiments where each class contained either 2 or 10 subclasses per class and each observation represented one 10- or 100-dimensional measurement. Each data set consisted of 120 observations per class. Data were sampled from normally distributed populations with identical trial variance (<italic>σ</italic><sub><italic>W</italic></sub> = <italic>I</italic>) and varying subclass variance (<italic>σ</italic><sub><italic>S</italic></sub> = <italic>a</italic> × <italic>I</italic>, <italic>a</italic> ∈ [0,0.6]). In addition, we varied the size of the main class-related effect (<italic>σ</italic><sub><italic>C</italic></sub> = <italic>a</italic> × <italic>I</italic>, <italic>a</italic> ∈ [0,0.6]). We classified data from each simulated experiment with linear SVM (with cost parameter <italic>C</italic> = 1) using 2-fold cross-validation. For each set of parameters, we repeated the whole sampling and classification procedure 5000 times to achieve a stable estimate of CCRs (<xref ref-type="fig" rid="pcbi.1006486.g003">Fig 3</xref>).</p>
<fig id="pcbi.1006486.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006486.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Expected CCRs when data contain subclasses.</title>
<p>(a, b) Expected CCRs for 100-dimensional data with a constant trial variance (<italic>σ</italic><sub><italic>W</italic></sub> = <italic>I</italic>) and varying class and subclass variance (<inline-formula id="pcbi.1006486.e007"><alternatives><graphic id="pcbi.1006486.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>C</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006486.e008"><alternatives><graphic id="pcbi.1006486.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) with <italic>K</italic> = 2 and <italic>K</italic> = 10 subclasses per class. (c) Expected CCRs and standard deviations for 100-dimensional data sets with an effect size of zero (<italic>σ</italic><sub><italic>W</italic></sub> = 0). (d, e) Expected CCRs for 10-dimensional data with a constant trial variance (<italic>σ</italic><sub><italic>W</italic></sub> = <italic>I</italic>) and varying class and subclass variance (<inline-formula id="pcbi.1006486.e009"><alternatives><graphic id="pcbi.1006486.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>C</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006486.e010"><alternatives><graphic id="pcbi.1006486.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) with <italic>K</italic> = 2 and <italic>K</italic> = 10 subclasses per class. (f) Expected CCRs and standard deviations for 10-dimensional data sets with an effect size of zero (<italic>σ</italic><sub><italic>W</italic></sub> = 0).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006486.g003" xlink:type="simple"/>
</fig>
<p>If the classes are indistinguishable (i.e. class-related variance <inline-formula id="pcbi.1006486.e011"><alternatives><graphic id="pcbi.1006486.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>C</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is zero, class centroids <italic>C</italic><sub>1</sub> = <italic>C</italic><sub>2</sub>), subclass-effects contribute most strongly to classification accuracy. With increasing between-class variance, the relative influence of subclass variance diminishes (<xref ref-type="fig" rid="pcbi.1006486.g003">Fig 3a and 3d</xref>). A higher number of subclasses also mitigates the influence of the subclass effect (<xref ref-type="fig" rid="pcbi.1006486.g003">Fig 3b and 3e</xref>). From these graphs it is obvious that a high CCR per se does not indicate the presence of class-related information in the data. Rather it is the p-value obtained by comparing the actual CCR with the null distribution of CCRs achieved by removing the class-related variance that should be used as a measure of strength of the main effect. For our simulations, <xref ref-type="fig" rid="pcbi.1006486.g003">Fig 3c and 3f</xref> depict the mean classification accuracies for data sets with no class-related effect but varying levels of subclass-related variance and different numbers of subclasses. It becomes apparent that subclasses bias the CCR expected under the null hypothesis and that this bias is greater in data with fewer subclasses and with more dimensions.</p>
</sec>
<sec id="sec006">
<title>Theory: Inflated accuracy in data with nested subclasses</title>
<p>The simulations in <xref ref-type="fig" rid="pcbi.1006486.g003">Fig 3</xref> show that CCRs depend not only on the difference between the classes, but also on subclass variance and on the number of subclasses. To investigate the implications of this observation in more detail, we develop an analytical description of classification rates when data with subclasses are analyzed using linear classifications. We assume our data set to consist of two sets of <italic>N</italic> × <italic>K</italic> independent random vectors <inline-formula id="pcbi.1006486.e012"><alternatives><graphic id="pcbi.1006486.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:mspace width="2pt"/><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>'</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mi>'</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> where <italic>k</italic>, <italic>k</italic>′ ∈ {1, …, <italic>K</italic>} labels the subclasses and <italic>n</italic>, <italic>n</italic>′ ∈ {1, …, <italic>N</italic>} identifies the sample index in each of the subclasses. The task of the linear classifier is to separate <italic>x</italic> and <italic>y</italic> into two categories. As a model for the linear classifier, we use Linear Discriminant Analysis (LDA). Data distribution within the subclasses is assumed to be Gaussian with variance <inline-formula id="pcbi.1006486.e013"><alternatives><graphic id="pcbi.1006486.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>W</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, the distribution of the subclass means is also assumed to be Gaussian with variance <inline-formula id="pcbi.1006486.e014"><alternatives><graphic id="pcbi.1006486.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and expected values <inline-formula id="pcbi.1006486.e015"><alternatives><graphic id="pcbi.1006486.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. Under these conditions, we determine the expected CCR to be as described in Theorem 1 (<xref ref-type="sec" rid="sec010">Materials and methods</xref>, Appendix A). From this theorem directly follows.</p>
<p>Corollary 1: Classification accuracy for data sets with no main class effect (<inline-formula id="pcbi.1006486.e016"><alternatives><graphic id="pcbi.1006486.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>) depends only on the number of subclasses and the intraclass correlation <italic>ICC</italic>. It can be estimated by <xref ref-type="disp-formula" rid="pcbi.1006486.e017">Eq 1</xref>.</p>
<disp-formula id="pcbi.1006486.e017">
<alternatives>
<graphic id="pcbi.1006486.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e017" xlink:type="simple"/>
<mml:math display="block" id="M17">
<mml:mrow><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>π</mml:mi></mml:mfrac> <mml:mi>a</mml:mi> <mml:mi>r</mml:mi> <mml:mi>c</mml:mi> <mml:mi>t</mml:mi> <mml:mi>a</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mi>K</mml:mi> <mml:mrow><mml:mi>I</mml:mi> <mml:mi>C</mml:mi> <mml:mi>C</mml:mi></mml:mrow></mml:mfrac> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
<p>Proof: see <xref ref-type="sec" rid="sec010">Materials and methods</xref>, Appendix B.</p>
<p>To validate our analytical results, we generated a series of simulations with a total number of 4, 8, or 16 subclasses and varied <italic>ICC</italic>. We classified these data sets with LDA and compared the CCRs with results of <xref ref-type="disp-formula" rid="pcbi.1006486.e017">Eq 1</xref>. <xref ref-type="fig" rid="pcbi.1006486.g004">Fig 4</xref> shows that results of the analytical solution and simulations are compatible. According to Corollary 1 (see <xref ref-type="fig" rid="pcbi.1006486.g004">Fig 4</xref>), estimated CCR is a decreasing function of the number of subclasses (<italic>K</italic>) and an increasing function of subclass variance (<inline-formula id="pcbi.1006486.e018"><alternatives><graphic id="pcbi.1006486.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>). It also shows that for zero effect size, CCR only depends on the intraclass correlation <italic>ICC</italic> and the number of subclasses <italic>K</italic>. Importantly, CCR is 50% only when <italic>ICC</italic> = 0. It is a monotonically increasing function of <italic>ICC</italic> and of <inline-formula id="pcbi.1006486.e019"><alternatives><graphic id="pcbi.1006486.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>.</p>
<fig id="pcbi.1006486.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006486.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Validation of Formula 1.</title>
<p>Expected CCRs for data sets with nested subclasses when the size of main effect is zero once using <xref ref-type="disp-formula" rid="pcbi.1006486.e017">Eq 1</xref> (gray lines) and once using simulated (black lines). The figure confirms that the analytical solution and simulations produce very similar results.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006486.g004" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec007">
<title>Application 1: Biased null distributions to account for inflated accuracy</title>
<p>Since subclass differences inflate classification accuracy, significance tests must take this subclass-related bias into account. To do so, we advocate using a block permutation strategy, which addresses this problem by adjusting the null distribution [<xref ref-type="bibr" rid="pcbi.1006486.ref020">20</xref>] (see Experiments 1 and 2 for two practical examples). To achieve this, we permute class association on the subclass-level instead of the trial level (see <xref ref-type="fig" rid="pcbi.1006486.g002">Fig 2</xref> for illustrated examples of such permutation procedures). Specifically, to remove class-related information, we randomly switch class labels of all trials within each subclass to create randomized classes that are balanced in terms of main class effect (see <xref ref-type="fig" rid="pcbi.1006486.g002">Fig 2a</xref>).</p>
<p>The distribution of CCRs for these relabeled data represents the null distribution with which the actual CCR must be compared. Only if classification accuracy for the real data is higher than that for blocked permuted data, it can be concluded that there is a systematic difference between the classes. If too few subclasses exist to generate a sufficient number of random permutations, we propose to use the group null distribution over subjects or sessions, which can be obtained non-parametrically by testing the mean CCR from data over all the subjects against a null distribution that is obtained by repeatedly averaging randomly sampled CCRs from the subclass-level permutations from each subject [<xref ref-type="bibr" rid="pcbi.1006486.ref003">3</xref>].</p>
</sec>
<sec id="sec008">
<title>Application 2: Significance bias in data with nested subclasses</title>
<p>To systematically study how subclasses affect significance tests, we used the simulated 100-dimensional data sets described above, produced their respective null distributions once using adjusted subclass-wise and once using trial-wise permutation tests, and calculated the expected p-values for varying sizes of class and subclass effects (<xref ref-type="fig" rid="pcbi.1006486.g005">Fig 5a and 5b</xref>). We used the CCR distribution of 5000 simulated data sets with no subclass- and class-effect as the null distribution for trial-wise permutation. For each individual subclass variance, we used the CCR distribution of 5000 simulated data sets with no class effect but with the respective subclass effect as the null distribution for blocked permutation. We define a measure of significance bias (SB) as the normalized difference between the number of statistically significant classification accuracy in data sets with and without subclasses. That is, <inline-formula id="pcbi.1006486.e020"><alternatives><graphic id="pcbi.1006486.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mi>S</mml:mi> <mml:mi>B</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub> <mml:mo>≠</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> where <italic>P</italic> represent the proportion of statistically significant results for a certain value of <italic>σ</italic><sub><italic>S</italic></sub>. In contrast to false positive rates, this value can also be calculated in the presence of an effect, because data sets are simulated, and their true composition is known. <xref ref-type="fig" rid="pcbi.1006486.g005">Fig 5c and 5d</xref> show significance biases for block-wise and trial-wise permutation tests, respectively. Trial-wise permutation results in liberally biased p-values in the presence of subclass effects. On the other hand, block-wise permutation is slightly conservative when subclass variance is high compared with class variance. This is due to classification accuracy being a nonlinear function of class differences (here the combination of class- and subclass effects). Therefore, when the null distribution of data with subclasses is strongly biased by subclass variance, the additional influence of class variance is comparatively smaller, and the procedure will over-adjust and result in a slightly pessimistic p-value.</p>
<fig id="pcbi.1006486.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006486.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Randomization results for data with subclasses (<italic>K</italic> = 10).</title>
<p>(a, b) The area delimited by the dashed rectangle shows the expected p-values for a main effect of zero. Importantly, even when CCRs are strongly biased because of nonzero subclass variance, p-values remain constant for the block-wise randomization test. The trial-wise permutation test fails to remove the bias introduced by subclass variance. Note that even small subclass effects result in falsely positive significance tests (dark grey and black squares for <italic>σ</italic><sub><italic>C</italic></sub> = 0). In the ideal case, the presence of subclass variance should not affect the percentage of significant findings, i.e. p-values should be identical within each column over <italic>σ</italic><sub><italic>C</italic></sub>. However, for increasing values of <italic>σ</italic><sub><italic>S</italic></sub>, trial-wise randomization leads to too many significant results for <italic>σ</italic><sub><italic>C</italic></sub> = 0 whereas subclass-wise permutation leads to a reduced number of significant findings for small values of <italic>σ</italic><sub><italic>C</italic></sub>. (c, d) To illustrate the difference between the number of significant results when subclass variance is not present (dashed rectangle) and when it is present, we calculate normalized difference between the number of data sets with significant p-values and the number of data sets with significant p-values with the same amount of class-variance but without subclasses (significance bias, SB). This value shows that blocked permutation is unbiased for small and sufficiently large class effects and shows only a small conservative bias when subclass variance is substantially larger than class variance. Testing with trial-wise permutation, on the other hand, is too liberal when the class effect is small or null and even a small subclass effect is present. This test therefore leads to a larger number of false positive results.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006486.g005" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec009" sec-type="conclusions">
<title>Discussion</title>
<p>Many neuroscience data sets comprise nested subclasses, either because of requirements of the experimental design (multiple subjects, sessions, recording sites, laboratories etc.) or because of the nature of experimental stimuli [<xref ref-type="bibr" rid="pcbi.1006486.ref016">16</xref>]. We show that these subclasses can induce classifiability and systematically bias classification accuracy even when no actual class-related effect exists. This happens because subclasses have distinct centroids, particularly in high-dimensional space [<xref ref-type="bibr" rid="pcbi.1006486.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1006486.ref021">21</xref>]. These differences can be detected by the classifier, even when they cancel out in the classes as a whole (see <xref ref-type="fig" rid="pcbi.1006486.g001">Fig 1</xref>). We show empirically and analytically that classification accuracies are biased when subclasses are present in the data. We show that block-wise permutation testing on the level of subclasses can provide the correct null distribution for classification rates.</p>
<p>Subclasses can arise for different reasons. If subclasses originate from repeated measures, their effect can be mitigated by either using fewer repetitions and/or a higher number of different measures (stimuli, run, subjects, …). Subclasses are formed by groups of trials with a common covariance that is not related to the class difference under investigation [<xref ref-type="bibr" rid="pcbi.1006486.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1006486.ref017">17</xref>]. This occurs, e.g., when data are gathered in distinct blocks, when there are clusters of trials with similar physical (e.g. color) or cognitive (e.g. concepts, emotions) properties, when trials of data are correlated in time or space, or when trials belong to multiple subjects. Generally, all of these sources of subclass variance can be regarded equally. In univariate analyses, the effects of these subclasses usually cancel out and become irrelevant when subclasses are randomly distributed around the class means. Linear classifiers, however, search for combinations of linear differences that distinguish between classes. Because subclasses have non-continuous effects and are not linearly related to class membership, their influence has to be accounted for in a different way.</p>
<p>Two types of subclasses must be considered. If subclasses originate from repeated measures, their effect can be mitigated by either using fewer repetitions and/or a higher number of different measures (stimuli, run, subjects, …). In that case, however, the effect of subclasses cannot be entirely avoided by design and must be adjusted for during permutation testing. If subclasses pertain to other similarities between subsets of trials, then it must be considered whether these subsets actually belong to a single class or whether they should be included as distinct factors into the experimental design. For example, when I want a classifier to decide whether images of male and female faces differ, a certain classifier might distinguish stimuli by the subclass of females with long hair. Whether a successful classification based on this feature is interpreted as a genuine sex difference or as a confound related to contemporary fashion, depends on the experimenter. On the other hand, if the subclasses are induced by repeated presentation of the same faces, it is obvious that the successful above-chance classification represents a bias and does not support the hypothesis of a visible sex difference. Because this type of artefact does not occur in classical univariate testing, we believe it is important to be particularly attentive to such effects in MVPA.</p>
<p>Subclasses are not the same as classical confounding variables. The latter are usually continuous, normally distributed influence variables that correlate with the class variable as well as with individual features of the data. Classically, such covariates are dealt with by holding them constant across conditions (experimental control), by counterbalancing their influence (selective analysis), or by partialling out their variance through regression (statistical control). Subclasses are categorical confounds that need not correlate (share variance) with either the class variable or any individual feature. Instead, they arise from the multivariate structure introduced by shared covariance between trials. Here, in particular, we discuss nested subclasses, which occur in only one of the classes. Therefore, balancing (e.g. equal number of exemplars per category) and counterbalancing (e.g. making sure that group averages over features are equal) do not remove effects of subclasses as it would in classical statistical approaches that focus on the mean values of individual features.</p>
<p>The problematics of subclasses is a property that distinguishes classifiers, which can detect structure in data, from classical statistics, which concentrates on differences in means. It applies to all modalities of data, not only to EEG data, and depends on their homogeneity, which is determined by, e.g., experimental design, stimuli and subjects to be analyzed. A typical effect that could introduce subclasses in fMRI data is the presence of individual scanning runs. If each run contains only one class, the runs represent subclasses and classification accuracy will be biased.</p>
<p>Given a constant number of subclasses, it is the ratio between trial- and subclass-variance that determines the extent to which the within-subclass covariance affects conclusions from the data. This ratio of trial-to-subclass-variance can be quantified in terms of the intraclass correlation <italic>ICC</italic>. It can be shown that even a small <italic>ICC</italic> = 0.1 can increase the false positive rate to more than 20% when it is expected to be at α = 0.05 [<xref ref-type="bibr" rid="pcbi.1006486.ref016">16</xref>]. When MVPA is employed, the deviation of CCRs from the expected chance levels depends, aside from the number of subclasses, only on <italic>ICC</italic> (see <xref ref-type="sec" rid="sec010">Materials and methods</xref>, Appendix B), and an <italic>ICC</italic> as small as 0.1 can spuriously increase CCR by 10% (see <xref ref-type="fig" rid="pcbi.1006486.g003">Fig 3c</xref>). Given that the average <italic>ICC</italic>s in neuroscience is 0.19 with a range up to 0.74 [<xref ref-type="bibr" rid="pcbi.1006486.ref016">16</xref>], it can be assumed that CCRs in data with subclasses are strongly biased if the bias is not explicitly accounted for. Because parametric tests cannot account for this bias, statistical significance must be determined using the correct permutation procedure. Importantly, in a higher dimensional space, the effect introduced by subclasses accumulates over dimensions and contributes to the distinctness of the subclasses (see <xref ref-type="fig" rid="pcbi.1006486.g003">Fig 3</xref>).</p>
<p>Making subclasses less prominent in the data structure reduces the bias. According to our simulations and the analytical solution in Appendices A and B, this can be achieved in two ways: either by decreasing the subclass variance or by increasing the number of subclasses. While decreasing the subclass variance might be difficult in real-world experiments, increasing the number of subclasses is often a possibility. Although a higher number of subclasses is preferable to a lower number [<xref ref-type="bibr" rid="pcbi.1006486.ref014">14</xref>–<xref ref-type="bibr" rid="pcbi.1006486.ref016">16</xref>], six subclasses already allow reasonable permutation testing. This is because the number of possible block-wise permutation for a data set with <italic>K</italic> nested subclasses per class is <inline-formula id="pcbi.1006486.e021"><alternatives><graphic id="pcbi.1006486.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:msup><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:mrow><mml:mfrac linethickness="0pt"><mml:mrow><mml:mi>K</mml:mi></mml:mrow> <mml:mrow><mml:mi>K</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>. Since <italic>K</italic> = 6 is the minimum number that exceeds 100 permutations, this number of subclasses allows to estimate p-values of up to 0.01.</p>
<p>The CCR is not informative about classification success when cross-validated classification is used for hypothesis testing because it does not provide a measure of statistical significance. A lower CCR might represent a more robust result, showing a higher significance level [<xref ref-type="bibr" rid="pcbi.1006486.ref002">2</xref>]. Moreover, the present simulations and experiments show that in experimental designs with nested subclasses, which are common in the life sciences, systematic dependencies in the data structure that can lead to spuriously high CCRs and null-distributions may no longer be centered on 50%. We therefore suggest that statistical significance should be tested with nonparametric permutation tests that accommodate for the bias in CCR induced by these subclasses. A more diverse range of stimuli can also be used to mitigate the bias and result in more reliable classification results. Importantly, although the results presented in the current manuscript are provided for binary classification problems, they will readily extend to multiclass case if linear classifiers are used within one-versus one or one-versus-all classification schemes [<xref ref-type="bibr" rid="pcbi.1006486.ref022">22</xref>]. This happens because such approaches use a majority voting based on single binary linear classification results, which are themselves inflated should the data set have subclasses. Nevertheless, one should note that the results of this paper are confined to the application of classification in data with nested subclasses. In data sets with crossed designs, because the subclass structure is the same within all subclasses, the subclass information can actually be used to improve classification accuracy [<xref ref-type="bibr" rid="pcbi.1006486.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1006486.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1006486.ref024">24</xref>].</p>
<p>Note that in the case of designs with more than one level of nested subclasses, the proposed technique in the current manuscript can still be employed. A data set with multiple levels of nested subclasses is numerically equivalent to a data set with all subclasses on one level. For instance, let’s assume that a data set, in addition to the main effect has two levels of independent, hierarchically nested subclasses. Such data can be modeled as <italic>y</italic><sub><italic>ijkl</italic></sub> = <italic>C</italic><sub><italic>i</italic></sub> + <italic>S</italic><sub><italic>ij</italic></sub> + <italic>S</italic><sub><italic>ijk</italic></sub> + <italic>ϵ</italic><sub><italic>ijkl</italic></sub> where <italic>y</italic><sub><italic>ijkl</italic></sub> are individual measurements, <italic>C</italic><sub><italic>i</italic>∈[1,2]</sub> represents the class centroids, <italic>S</italic><sub><italic>ij</italic></sub> are the centroids of the <italic>j</italic><sup><italic>th</italic></sup> level-one subclass within class <italic>i</italic> and represents the vector from the class centroid to the subclass centroid, <italic>S</italic><sub><italic>ijk</italic></sub> are the centroids of the <italic>k</italic><sup><italic>th</italic></sup> level-two subclass, which are nested within subclass <italic>S</italic><sub><italic>ij</italic></sub>, and <italic>ϵ</italic><sub><italic>ijkl</italic></sub> reflects the deviation from the subclass mean (<italic>S</italic><sub><italic>ijk</italic></sub>), i.e. measurement noise. Since the sum of two normal distributions is also a normal distribution, the model can be effectively rewritten as <italic>y</italic><sub><italic>ij’l</italic></sub> = <italic>C</italic><sub><italic>i</italic></sub> + <italic>S</italic><sub><italic>ij'</italic></sub> + <italic>ϵ</italic><sub><italic>ij’l</italic></sub> where <italic>S</italic><sub><italic>ij'</italic></sub> = <italic>S</italic><sub><italic>ij</italic></sub> + <italic>S</italic><sub><italic>ijk</italic></sub> (with <inline-formula id="pcbi.1006486.e022"><alternatives><graphic id="pcbi.1006486.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>'</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi> <mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) and j’ = {jk}, which is equivalent to the one discussed above.</p>
<p>An important limitation of the current considerations for linear classification is that we must assume sources of subclasses to be known. To test if data has nested subclasses in its structure, which are not known a priori or overlooked by the experimenters, clustering algorithms might be of use. First, clustering might help identifying unknown and hidden subclasses in the data. If cluster analysis finds significantly different clusters within classes, which do not correspond between classes (nested clusters), then these can be taken into account during permutation testing. Second, it is conceivable that after detecting hidden subclass clusters the cluster-related variance might be removed by subtracting cluster structure in both main classes of the training set separately. Then, for each sample of the test set, the most likely subclass is determined and the same subtraction is applied. However, it remains to be shown first that this procedure does not leak class information into the test set at some point.</p>
<p>It is possible to avoid subclass-related bias by proper cross-validation under some circumstances. One can use subclasses as folds during cross-validation and always leave one subclass per class out. This avoids a transfer of the learned subclass structure from training to test and will remove the corresponding bias. Note, however, that using a trial-wise permutation test will still lead to a wrong estimate of significance levels in this case. Only holding subclass items together during permutation testing results in the correct estimation of the confidence interval. In general, we recommend using split-half cross validation because of its lower variance and higher sensitivity [<xref ref-type="bibr" rid="pcbi.1006486.ref002">2</xref>] and adjusting for subclass bias during permutation testing if necessary. Both cross-validation and permutation are applied independently.</p>
<p>Finally, we want to mention that the suggested permutation procedure is only valid if an equal number of subclasses per class is entered into the analysis. Differences in the number of subclasses, i.e. different homogeneity of classes, can bias results. We also want to point out that linear classification is only one of the many common methods that exploit the multivariate information of a data set. Although a systematic study of subclass effects on those algorithms is beyond the scope of this paper, we believe that similar effects might be found in most classifiers that assume a continuous distribution of feature values.</p>
</sec>
<sec id="sec010" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec011">
<title>Ethics statement</title>
<p>This study was approved by the Ethics Committee of the Department Psychology of the LMU Munich.</p>
</sec>
<sec id="sec012">
<title>Appendix A: Theorem 1</title>
<p>We assume our data set consists of two sets of <italic>N</italic> × <italic>K</italic> independent random vectors <inline-formula id="pcbi.1006486.e023"><alternatives><graphic id="pcbi.1006486.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:mspace width="2pt"/><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mi>'</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mrow><mml:mi>'</mml:mi></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> where <italic>k</italic>, <italic>k</italic>′ ∈ {1, …, <italic>K</italic>} labels the subclasses and <italic>n</italic>, <italic>n</italic>' ∈ {1, …, <italic>N</italic>}identifies the sample index in each of the subclasses. The task of the linear classifier is to separate <italic>x</italic> and <italic>y</italic> into two categories. As a model for the linear classifier, we use LDA. We therefore can map the d-dimensional vectors <inline-formula id="pcbi.1006486.e024"><alternatives><graphic id="pcbi.1006486.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:mspace width="2pt"/><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>'</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mi>'</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> onto the coordinates <inline-formula id="pcbi.1006486.e025"><alternatives><graphic id="pcbi.1006486.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:msubsup><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow> <mml:mrow><mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006486.e026"><alternatives><graphic id="pcbi.1006486.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:msubsup><mml:mrow><mml:mi>η</mml:mi></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>'</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>′</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mspace width="2pt"/></mml:math></alternatives></inline-formula> w.r.t to the axis defined by the difference of the mean values of the two classes. Furthermore, we label the empirical means of the classes as:
<disp-formula id="pcbi.1006486.e027">
<alternatives>
<graphic id="pcbi.1006486.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e027" xlink:type="simple"/>
<mml:math display="block" id="M27">
<mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo> <mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munder> <mml:mrow><mml:msubsup><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow> <mml:mrow><mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow> <mml:mo>,</mml:mo> <mml:msup><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo> <mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munder> <mml:mrow><mml:msubsup><mml:mrow><mml:mi>η</mml:mi></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mi mathvariant="normal">'</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mi mathvariant="normal">'</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>The distributions of within the subclasses is assumed to be Gaussian with variance <inline-formula id="pcbi.1006486.e028"><alternatives><graphic id="pcbi.1006486.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>W</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, the distribution of the subclass means is also assumed to be Gaussian with variance <inline-formula id="pcbi.1006486.e029"><alternatives><graphic id="pcbi.1006486.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and generally different expected values <inline-formula id="pcbi.1006486.e030"><alternatives><graphic id="pcbi.1006486.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. In the case of the two categories are undistinguishable the two are identical (no signal), <inline-formula id="pcbi.1006486.e031"><alternatives><graphic id="pcbi.1006486.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>,. For every realization the means of <italic>μ</italic><sup>(<italic>k</italic>)</sup>, <italic>ν</italic><sup>(<italic>k</italic>')</sup> will be different from <inline-formula id="pcbi.1006486.e032"><alternatives><graphic id="pcbi.1006486.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, and thus we also introduce the empirical means <inline-formula id="pcbi.1006486.e033"><alternatives><graphic id="pcbi.1006486.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, which underlie the estimated signal <inline-formula id="pcbi.1006486.e034"><alternatives><graphic id="pcbi.1006486.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mi>δ</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover></mml:math></alternatives></inline-formula>.</p>
<p>Besides, we can compute the total variance of the data set as:
<disp-formula id="pcbi.1006486.e035">
<alternatives>
<graphic id="pcbi.1006486.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e035" xlink:type="simple"/>
<mml:math display="block" id="M35">
<mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>v</mml:mi> <mml:mi>a</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ξ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>v</mml:mi> <mml:mi>a</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>η</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>v</mml:mi> <mml:mi>a</mml:mi> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>ξ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>&lt;</mml:mo> <mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>&gt;</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mo>&lt;</mml:mo> <mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi> <mml:mo>−</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>&gt;</mml:mo> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>w</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:mspace width="2pt"/><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Under these conditions, assuming that the total variance <italic>σ</italic><sup>2</sup> is constant, the expected CCR for such data can be estimated as:
<disp-formula id="pcbi.1006486.e036">
<alternatives>
<graphic id="pcbi.1006486.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e036" xlink:type="simple"/>
<mml:math display="block" id="M36">
<mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mrow><mml:msubsup><mml:mo stretchy="false">∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi mathvariant="normal">∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msubsup> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>q</mml:mi> <mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mi>i</mml:mi> <mml:mi>g</mml:mi> <mml:mi>n</mml:mi> <mml:mo>(</mml:mo> <mml:mo>(</mml:mo> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow> <mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo> <mml:mi>q</mml:mi> <mml:mo>+</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>δ</mml:mi></mml:mrow> <mml:mo>~</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mrow> <mml:mi>N</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>q</mml:mi></mml:mrow> <mml:mo>)</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>q</mml:mi> <mml:mfrac><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow> <mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>δ</mml:mi></mml:mrow> <mml:mo>~</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mo>(</mml:mo> <mml:mfrac><mml:mrow><mml:mi>q</mml:mi> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>δ</mml:mi></mml:mrow> <mml:mo>~</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>]</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>With <italic>N</italic>(<italic>q</italic>) denoting the normal distribution,<inline-formula id="pcbi.1006486.e037"><alternatives><graphic id="pcbi.1006486.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:mspace width="2pt"/><mml:mi>ρ</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>,<inline-formula id="pcbi.1006486.e038"><alternatives><graphic id="pcbi.1006486.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>δ</mml:mi></mml:mrow> <mml:mo>~</mml:mo></mml:mover> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mfrac><mml:mrow><mml:mi>δ</mml:mi></mml:mrow> <mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac> <mml:msqrt><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow> <mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1006486.e039"><alternatives><graphic id="pcbi.1006486.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:msup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mfrac><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>K</mml:mi></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow> <mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>.</p>
<sec id="sec013">
<title>Proof</title>
<p>For LDA, the Correct Classification Rate (CCR) can be computed as the probability that during testing, a data point of class <italic>x</italic> is on the same side of the classification threshold <inline-formula id="pcbi.1006486.e040"><alternatives><graphic id="pcbi.1006486.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:mi>θ</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula> as the empirical mean <inline-formula id="pcbi.1006486.e041"><alternatives><graphic id="pcbi.1006486.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, and a data point of class <italic>y</italic> is on the opposite side:
<disp-formula id="pcbi.1006486.e042">
<alternatives>
<graphic id="pcbi.1006486.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e042" xlink:type="simple"/>
<mml:math display="block" id="M42">
<mml:mrow><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>&lt;</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mi>ξ</mml:mi> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>η</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>η</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>&lt;</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mi>η</mml:mi></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula></p>
<p>Under the assumption of symmetry between class labels, i.e., <inline-formula id="pcbi.1006486.e043"><alternatives><graphic id="pcbi.1006486.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mi>p</mml:mi> <mml:mi>ξ</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mi>p</mml:mi> <mml:mi>η</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>, equally distributed subclass means, and equally within-class distributions <xref ref-type="disp-formula" rid="pcbi.1006486.e042">Eq (2)</xref> must be symmetrical with respect to exchanging <italic>x</italic> and <italic>y</italic> and thus we can obtain the CCR from
<disp-formula id="pcbi.1006486.e044">
<alternatives>
<graphic id="pcbi.1006486.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e044" xlink:type="simple"/>
<mml:math display="block" id="M44">
<mml:mrow><mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>&lt;</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>Denoting <inline-formula id="pcbi.1006486.e045"><alternatives><graphic id="pcbi.1006486.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:mover accent="true"><mml:mrow><mml:mo>μ</mml:mo></mml:mrow> <mml:mo>→</mml:mo></mml:mover> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mn>1</mml:mn></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>K</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006486.e046"><alternatives><graphic id="pcbi.1006486.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mn>1</mml:mn></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>K</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>, we thus can write
<disp-formula id="pcbi.1006486.e047">
<alternatives>
<graphic id="pcbi.1006486.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e047" xlink:type="simple"/>
<mml:math display="block" id="M47">
<mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mo>∫</mml:mo> <mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:mo stretchy="true">¯</mml:mo></mml:mover> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mspace width="2pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi> <mml:mo>&lt;</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>&lt;</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:mo stretchy="true">¯</mml:mo></mml:mover> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mo>∫</mml:mo> <mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:msubsup><mml:mo>∫</mml:mo> <mml:mi>θ</mml:mi> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>ξ</mml:mi> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi> <mml:mo>|</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>Η</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mspace width="2pt"/><mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>θ</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>ξ</mml:mi> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi> <mml:mo>|</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>Η</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
with <italic>H</italic> denoting the Heaviside step function. Substituing <italic>ξ</italic> = <italic>θ</italic> + <italic>t</italic>, the integrals of <italic>ξ</italic> can be transformed to
<disp-formula id="pcbi.1006486.e048">
<alternatives>
<graphic id="pcbi.1006486.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e048" xlink:type="simple"/>
<mml:math display="block" id="M48">
<mml:mrow><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>∫</mml:mo> <mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>×</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>|</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>Η</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>|</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>Η</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula></p>
<p>The subsample means are independent <inline-formula id="pcbi.1006486.e049"><alternatives><graphic id="pcbi.1006486.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e049" xlink:type="simple"/><mml:math display="inline" id="M49"><mml:mspace width="2pt"/><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mrow><mml:munder><mml:mo stretchy="false">∏</mml:mo> <mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo> <mml:mrow><mml:munder><mml:mo stretchy="false">∏</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mi>'</mml:mi></mml:mrow></mml:munder> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mi>'</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. Moreover, <inline-formula id="pcbi.1006486.e050"><alternatives><graphic id="pcbi.1006486.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e050" xlink:type="simple"/><mml:math display="inline" id="M50"><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi> <mml:mspace width="2pt"/></mml:mrow> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> only affects the integral with its mean <inline-formula id="pcbi.1006486.e051"><alternatives><graphic id="pcbi.1006486.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, and thus <inline-formula id="pcbi.1006486.e052"><alternatives><graphic id="pcbi.1006486.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e052" xlink:type="simple"/><mml:math display="inline" id="M52"><mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:math></alternatives></inline-formula></p>
<p>All distributions are assumed to be Gaussians. We therefore can express all probabilities by Gaussian distribution <italic>G</italic>. In particular
<disp-formula id="pcbi.1006486.e053">
<alternatives>
<graphic id="pcbi.1006486.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e053" xlink:type="simple"/>
<mml:math display="block" id="M53">
<mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi></mml:mrow> <mml:mrow><mml:mover accent="true"><mml:mrow><mml:mo>μ</mml:mo></mml:mrow> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>→</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mfrac> <mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder> <mml:mrow><mml:mi>G</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>ξ</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula></p>
<p>Inserting <xref ref-type="disp-formula" rid="pcbi.1006486.e053">Eq (6)</xref> into <xref ref-type="disp-formula" rid="pcbi.1006486.e048">Eq (5)</xref>, we obtain:
<disp-formula id="pcbi.1006486.e055">
<alternatives>
<graphic id="pcbi.1006486.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e055" xlink:type="simple"/>
<mml:math display="block" id="M55">
<mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>K</mml:mi></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:munder> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:munder><mml:mo>∏</mml:mo> <mml:mi>k</mml:mi></mml:munder> <mml:mi>d</mml:mi> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>×</mml:mo> <mml:mo stretchy="false">[</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:msubsup> <mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>−</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>w</mml:mi></mml:msub></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>+</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>−</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>w</mml:mi></mml:msub></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula></p>
<p>Substituting <inline-formula id="pcbi.1006486.e056"><alternatives><graphic id="pcbi.1006486.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:mi>u</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover> <mml:mspace width="2pt"/></mml:math></alternatives></inline-formula> the integrals over <inline-formula id="pcbi.1006486.e057"><alternatives><graphic id="pcbi.1006486.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e057" xlink:type="simple"/><mml:math display="inline" id="M57"><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>-</mml:mo></mml:mover> <mml:mspace width="2pt"/></mml:math></alternatives></inline-formula> can be combined such that
<disp-formula id="pcbi.1006486.e058">
<alternatives>
<graphic id="pcbi.1006486.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e058" xlink:type="simple"/>
<mml:math display="block" id="M58">
<mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>K</mml:mi></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:munder> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>u</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:munder><mml:mo>∏</mml:mo> <mml:mi>k</mml:mi></mml:munder> <mml:mi>d</mml:mi> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>×</mml:mo> <mml:mo stretchy="false">[</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:mi>u</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>w</mml:mi></mml:msub></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>+</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>u</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>w</mml:mi></mml:msub></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula></p>
<p>Completing squares in the last two Gaussian distributions and integrating over all <italic>μ</italic><sup>(<italic>k</italic>)</sup> with <inline-formula id="pcbi.1006486.e060"><alternatives><graphic id="pcbi.1006486.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e060" xlink:type="simple"/><mml:math display="inline" id="M60"><mml:mi>ϗ</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>, yields
<disp-formula id="pcbi.1006486.e061">
<alternatives>
<graphic id="pcbi.1006486.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e061" xlink:type="simple"/>
<mml:math display="block" id="M61">
<mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>K</mml:mi></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>k</mml:mi></mml:munder> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>u</mml:mi> <mml:mo>∫</mml:mo> <mml:mi>d</mml:mi> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mi>G</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>×</mml:mo> <mml:mi>K</mml:mi> <mml:mo stretchy="false">[</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mi>K</mml:mi> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>K</mml:mi> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>∑</mml:mo> <mml:mo>*</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>×</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:msub><mml:mi>B</mml:mi> <mml:mo>+</mml:mo></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>+</mml:mo> <mml:mi>K</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mi>K</mml:mi> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>K</mml:mi> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>−</mml:mo></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>∑</mml:mo> <mml:mo>*</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>×</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mi>μ</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:msub><mml:mi>B</mml:mi> <mml:mo>−</mml:mo></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
<label>(9)</label>
</disp-formula></p>
<p>With <inline-formula id="pcbi.1006486.e062"><alternatives><graphic id="pcbi.1006486.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e062" xlink:type="simple"/><mml:math display="inline" id="M62"><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mi>K</mml:mi> <mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>w</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:mspace width="2pt"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">Ʃ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mo>(</mml:mo> <mml:mrow><mml:mi>K</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mo>)</mml:mo> <mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>K</mml:mi> <mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub> <mml:mo>/</mml:mo> <mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mspace width="2pt"/><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow> <mml:mrow><mml:mo>±</mml:mo></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mo>±</mml:mo> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>u</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>,</p>
<p>And
<disp-formula id="pcbi.1006486.e063">
<alternatives>
<graphic id="pcbi.1006486.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e063" xlink:type="simple"/>
<mml:math display="block" id="M63">
<mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow> <mml:mrow><mml:mo>±</mml:mo></mml:mrow></mml:msub></mml:mrow> <mml:mo>~</mml:mo></mml:mover> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mo>)</mml:mo> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mo>(</mml:mo> <mml:mo>±</mml:mo> <mml:mi>K</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mi>u</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo> <mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mo>±</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo> <mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>w</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo> <mml:mo>/</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Again, completing squares of the first and third Gaussian distribution results in
<disp-formula id="pcbi.1006486.e064">
<alternatives>
<graphic id="pcbi.1006486.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e064" xlink:type="simple"/>
<mml:math display="block" id="M64">
<mml:mi>G</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>)</mml:mo> <mml:mi>G</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow> <mml:mrow><mml:mo>±</mml:mo></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mi>G</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi> <mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt> <mml:mo>)</mml:mo> <mml:mo>×</mml:mo> <mml:mi>G</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>k</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow> <mml:mrow><mml:mo>±</mml:mo></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup> <mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi> <mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula></p>
<p>With <inline-formula id="pcbi.1006486.e065"><alternatives><graphic id="pcbi.1006486.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e065" xlink:type="simple"/><mml:math display="inline" id="M65"><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi> <mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mi>K</mml:mi> <mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> and
<disp-formula id="pcbi.1006486.e066">
<alternatives>
<graphic id="pcbi.1006486.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e066" xlink:type="simple"/>
<mml:math display="block" id="M66">
<mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow> <mml:mrow><mml:mo>±</mml:mo></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mo>)</mml:mo> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi> <mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mi>K</mml:mi> <mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow> <mml:mrow><mml:mo>±</mml:mo></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi> <mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Solving the integral over <italic>μ</italic><sup>(<italic>k</italic>)</sup> in <xref ref-type="disp-formula" rid="pcbi.1006486.e061">Eq (9)</xref> as a convolution of two Gaussians, we end up at
<disp-formula id="pcbi.1006486.e067">
<alternatives>
<graphic id="pcbi.1006486.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e067" xlink:type="simple"/>
<mml:math display="block" id="M67">
<mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>u</mml:mi> <mml:mo stretchy="false">[</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>u</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mrow><mml:mo>*</mml:mo> <mml:mo>*</mml:mo></mml:mrow></mml:msup> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>×</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>α</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>−</mml:mo> <mml:mi>β</mml:mi> <mml:mi>u</mml:mi> <mml:mo>+</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mo>∑</mml:mo> <mml:mo>*</mml:mo> <mml:mo>*</mml:mo> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>+</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>u</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mrow><mml:mo>*</mml:mo> <mml:mo>*</mml:mo></mml:mrow></mml:msup> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>×</mml:mo> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>α</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:mover accent="true"><mml:mi>ν</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>β</mml:mi> <mml:mi>u</mml:mi> <mml:mo>+</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mo>∑</mml:mo> <mml:mo>*</mml:mo> <mml:mo>*</mml:mo> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
<label>(10)</label>
</disp-formula></p>
<p>With <inline-formula id="pcbi.1006486.e068"><alternatives><graphic id="pcbi.1006486.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e068" xlink:type="simple"/><mml:math display="inline" id="M68"><mml:mi>α</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi> <mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>,<inline-formula id="pcbi.1006486.e069"><alternatives><graphic id="pcbi.1006486.e069g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e069" xlink:type="simple"/><mml:math display="inline" id="M69"><mml:mspace width="2pt"/><mml:mi>β</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi> <mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mspace width="2pt"/><mml:mi>γ</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mn>2</mml:mn> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi> <mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>, and
<disp-formula id="pcbi.1006486.e070">
<alternatives>
<graphic id="pcbi.1006486.e070g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e070" xlink:type="simple"/>
<mml:math display="block" id="M70">
<mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">Ʃ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi> <mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">Ʃ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>K</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mo>)</mml:mo> <mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup> <mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">*</mml:mi> <mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Introducing the signal <inline-formula id="pcbi.1006486.e071"><alternatives><graphic id="pcbi.1006486.e071g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e071" xlink:type="simple"/><mml:math display="inline" id="M71"><mml:mi>δ</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mspace width="2pt"/></mml:math></alternatives></inline-formula> and substituting <italic>ν</italic> = <italic>t</italic> + <italic>u</italic>/2 ∓ <italic>δ</italic> yields
<disp-formula id="pcbi.1006486.e073">
<alternatives>
<graphic id="pcbi.1006486.e073g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e073" xlink:type="simple"/>
<mml:math display="block" id="M73">
<mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mi>∞</mml:mi></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>ν</mml:mi> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ν</mml:mi> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mrow><mml:mo>*</mml:mo> <mml:mo>*</mml:mo></mml:mrow></mml:msup> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>×</mml:mo> <mml:mo stretchy="false">[</mml:mo> <mml:mi>H</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ν</mml:mi> <mml:mo>−</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>δ</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:mi>β</mml:mi> <mml:mi>ν</mml:mi> <mml:mo>−</mml:mo> <mml:mi>δ</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo> <mml:msup><mml:mo>∑</mml:mo> <mml:mrow><mml:mo>*</mml:mo> <mml:mo>*</mml:mo></mml:mrow></mml:msup> <mml:mo>/</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>K</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>+</mml:mo> <mml:mi>H</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ν</mml:mi> <mml:mo>−</mml:mo> <mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:mi>δ</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>−</mml:mo> <mml:mi>β</mml:mi> <mml:mi>ν</mml:mi> <mml:mo>+</mml:mo> <mml:mi>δ</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo> <mml:msup><mml:mo>∑</mml:mo> <mml:mrow><mml:mo>*</mml:mo> <mml:mo>*</mml:mo></mml:mrow></mml:msup> <mml:mo>/</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>K</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo stretchy="false">]</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mi>∞</mml:mi> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>ν</mml:mi> <mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mi>i</mml:mi> <mml:mi>g</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ν</mml:mi> <mml:mo>+</mml:mo> <mml:mi>δ</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:mfrac> <mml:mi>G</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>ν</mml:mi> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mrow><mml:mo>*</mml:mo> <mml:mo>*</mml:mo></mml:mrow></mml:msup> <mml:mo>/</mml:mo> <mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>γ</mml:mi> <mml:mi>ν</mml:mi> <mml:mo>+</mml:mo> <mml:mi>δ</mml:mi></mml:mrow> <mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mo>∑</mml:mo> <mml:mrow><mml:mo>*</mml:mo> <mml:mo>*</mml:mo></mml:mrow></mml:msup> <mml:mo>/</mml:mo> <mml:mi>K</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mn>2</mml:mn> <mml:mo>−</mml:mo> <mml:mi>γ</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>ν</mml:mi> <mml:mo>+</mml:mo> <mml:mi>δ</mml:mi></mml:mrow> <mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mo>∑</mml:mo> <mml:mrow><mml:mo>*</mml:mo> <mml:mo>*</mml:mo></mml:mrow></mml:msup> <mml:mo>/</mml:mo> <mml:mi>K</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mi>∞</mml:mi> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>q</mml:mi> <mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mi>i</mml:mi> <mml:mi>g</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>ρ</mml:mi> <mml:mi>K</mml:mi></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>q</mml:mi> <mml:mo>+</mml:mo> <mml:mover accent="true"><mml:mi>δ</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:mfrac> <mml:mi>N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>q</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>q</mml:mi> <mml:mfrac><mml:mi>ρ</mml:mi> <mml:mi>K</mml:mi></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mover accent="true"><mml:mi>δ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:mfrac></mml:mrow> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>q</mml:mi> <mml:mo>+</mml:mo> <mml:mfrac><mml:mover accent="true"><mml:mi>δ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:mfrac></mml:mrow> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
<label>(11)</label>
</disp-formula></p>
<p>With <italic>N</italic>(<italic>q</italic>) denoting the normal distribution,<inline-formula id="pcbi.1006486.e074"><alternatives><graphic id="pcbi.1006486.e074g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e074" xlink:type="simple"/><mml:math display="inline" id="M74"><mml:mspace width="2pt"/><mml:mi>ρ</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>s</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>,<inline-formula id="pcbi.1006486.e075"><alternatives><graphic id="pcbi.1006486.e075g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e075" xlink:type="simple"/><mml:math display="inline" id="M75"><mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>δ</mml:mi></mml:mrow> <mml:mo>~</mml:mo></mml:mover> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mfrac><mml:mrow><mml:mi>δ</mml:mi></mml:mrow> <mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac> <mml:msqrt><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow> <mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1006486.e076"><alternatives><graphic id="pcbi.1006486.e076g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e076" xlink:type="simple"/><mml:math display="inline" id="M76"><mml:msup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mfrac><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>K</mml:mi></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow> <mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>.</p>
</sec>
</sec>
<sec id="sec014">
<title>Appendix B: Corollary 1</title>
<p>Classification accuracy for data sets with no main effect <inline-formula id="pcbi.1006486.e077"><alternatives><graphic id="pcbi.1006486.e077g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e077" xlink:type="simple"/><mml:math display="inline" id="M77"><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> depends only on number of subclasses and intraclass correlation <italic>ICC</italic> and can be estimated by <inline-formula id="pcbi.1006486.e078"><alternatives><graphic id="pcbi.1006486.e078g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e078" xlink:type="simple"/><mml:math display="inline" id="M78"><mml:mspace width="2pt"/><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:mfrac> <mml:mi>a</mml:mi> <mml:mi>r</mml:mi> <mml:mi>c</mml:mi> <mml:mi>t</mml:mi> <mml:mi>a</mml:mi> <mml:mi>n</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn> <mml:mo>(</mml:mo> <mml:mfrac><mml:mrow><mml:mi>K</mml:mi></mml:mrow> <mml:mrow><mml:mi>I</mml:mi> <mml:mi>C</mml:mi> <mml:mi>C</mml:mi></mml:mrow></mml:mfrac> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>.</p>
<sec id="sec015">
<title>Proof</title>
<p>Substituting for <xref ref-type="disp-formula" rid="pcbi.1006486.e073">Eq 11</xref> with <italic>δ</italic> = 0 and noting that <italic>ICC</italic> = <italic>ρ</italic> we have
<disp-formula id="pcbi.1006486.e079">
<alternatives>
<graphic id="pcbi.1006486.e079g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e079" xlink:type="simple"/>
<mml:math display="block" id="M79">
<mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:munderover><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:mi>d</mml:mi> <mml:mi>q</mml:mi> <mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mi>i</mml:mi> <mml:mi>g</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>ρ</mml:mi> <mml:mi>K</mml:mi></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>q</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:mfrac> <mml:mi>N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>q</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo stretchy="false">[</mml:mo> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>q</mml:mi> <mml:mfrac><mml:mi>ρ</mml:mi> <mml:mi>K</mml:mi></mml:mfrac></mml:mrow> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mi>q</mml:mi> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:munderover><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>−</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:mi>d</mml:mi> <mml:mi>q</mml:mi> <mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mi>i</mml:mi> <mml:mi>g</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>q</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mn>2</mml:mn></mml:mfrac> <mml:mi>N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>q</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>q</mml:mi> <mml:mfrac><mml:mi>ρ</mml:mi> <mml:mi>K</mml:mi></mml:mfrac></mml:mrow> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mi>q</mml:mi> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Noting that <italic>sign</italic>(<italic>q</italic>), <italic>erf</italic>(<italic>q</italic>) are odd functions and <italic>N</italic>(<italic>q</italic>) is and even function of <italic>q</italic>, we have
<disp-formula id="pcbi.1006486.e054">
<alternatives>
<graphic id="pcbi.1006486.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e054" xlink:type="simple"/>
<mml:math display="block" id="M54">
<mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>C</mml:mi> <mml:mi>C</mml:mi> <mml:mi>R</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∫</mml:mo></mml:mstyle> <mml:mn>0</mml:mn> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:mi>d</mml:mi> <mml:mi>q</mml:mi> <mml:mi>N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>q</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>q</mml:mi> <mml:mfrac><mml:mi>ρ</mml:mi> <mml:mi>K</mml:mi></mml:mfrac></mml:mrow> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mi>q</mml:mi> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∫</mml:mo></mml:mstyle> <mml:mn>0</mml:mn> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:mi>d</mml:mi> <mml:mi>q</mml:mi> <mml:mi>N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>q</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>q</mml:mi> <mml:mfrac><mml:mi>ρ</mml:mi> <mml:mi>K</mml:mi></mml:mfrac></mml:mrow> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∫</mml:mo></mml:mstyle> <mml:mn>0</mml:mn> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munderover> <mml:mi>d</mml:mi> <mml:mi>q</mml:mi> <mml:mi>N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>q</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>e</mml:mi> <mml:mi>r</mml:mi> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mi>q</mml:mi> <mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt> <mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>−</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>π</mml:mi></mml:mfrac> <mml:mi>a</mml:mi> <mml:mi>r</mml:mi> <mml:mi>c</mml:mi> <mml:mi>t</mml:mi> <mml:mi>a</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>λ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>−</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>π</mml:mi></mml:mfrac> <mml:mi>a</mml:mi> <mml:mi>r</mml:mi> <mml:mi>c</mml:mi> <mml:mi>t</mml:mi> <mml:mi>a</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>λ</mml:mi> <mml:mi>K</mml:mi></mml:mrow> <mml:mi>ρ</mml:mi></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>π</mml:mi></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>a</mml:mi> <mml:mi>r</mml:mi> <mml:mi>c</mml:mi> <mml:mi>t</mml:mi> <mml:mi>a</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>λ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>a</mml:mi> <mml:mi>r</mml:mi> <mml:mi>c</mml:mi> <mml:mi>t</mml:mi> <mml:mi>a</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mrow><mml:mi>λ</mml:mi> <mml:mi>K</mml:mi></mml:mrow> <mml:mi>ρ</mml:mi></mml:mfrac></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>π</mml:mi></mml:mfrac> <mml:mi>a</mml:mi> <mml:mi>r</mml:mi> <mml:mi>c</mml:mi> <mml:mi>t</mml:mi> <mml:mi>a</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mi>K</mml:mi> <mml:mi>ρ</mml:mi></mml:mfrac> <mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow>
</mml:math>
</alternatives>
<label>(12)</label>
</disp-formula></p>
<p>Note that the closed form of CCR in data sets with no effect size depend only on <italic>ICC</italic> = <italic>ρ</italic> and <italic>K</italic>.</p>
<p>Note that the expected correct classification using LDA for data sets with no effect (<inline-formula id="pcbi.1006486.e059"><alternatives><graphic id="pcbi.1006486.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e059" xlink:type="simple"/><mml:math display="inline" id="M59"><mml:mover accent="true"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover> <mml:mspace width="2pt"/><mml:mo>=</mml:mo> <mml:mspace width="2pt"/><mml:mover accent="true"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>) is an increasing function of subclass variance <inline-formula id="pcbi.1006486.e072"><alternatives><graphic id="pcbi.1006486.e072g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006486.e072" xlink:type="simple"/><mml:math display="inline" id="M72"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow> <mml:mrow><mml:mi>S</mml:mi></mml:mrow> <mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, a decreasing function of number of subclasses <italic>K</italic>, and is 50% only when <italic>ICC</italic> = 0.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1006486.ref001"><label>1</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name>, <name name-style="western"><surname>Connolly</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Guntupalli</surname> <given-names>JS</given-names></name>. <article-title>Decoding Neural Representational Spaces Using Multivariate Pattern Analysis</article-title>. <source>Annu Rev Neurosci</source>. <year>2014</year>;<volume>37</volume>:<fpage>435</fpage>–<lpage>456</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-neuro-062012-170325" xlink:type="simple">10.1146/annurev-neuro-062012-170325</ext-link></comment> <object-id pub-id-type="pmid">25002277</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref002"><label>2</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jamalabadi</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Alizadeh</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Schönauer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Leibold</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Gais</surname> <given-names>S</given-names></name>. <article-title>Classification based hypothesis testing in neuroscience: Below-chance level classification rates and overlooked statistical properties of linear parametric classifiers</article-title>. <source>Hum Brain Mapp</source>. <year>2016</year>;<volume>37</volume>(<issue>5</issue>):<fpage>1842</fpage>–<lpage>1855</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hbm.23140" xlink:type="simple">10.1002/hbm.23140</ext-link></comment> <object-id pub-id-type="pmid">27015748</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref003"><label>3</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stelzer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>R</given-names></name>. <article-title>Statistical inference and multiple testing correction in classification-based multi-voxel pattern analysis (MVPA): random permutations and cluster size control</article-title>. <source>NeuroImage</source>. <year>2013</year>;<volume>65</volume>:<fpage>69</fpage>–<lpage>82</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2012.09.063" xlink:type="simple">10.1016/j.neuroimage.2012.09.063</ext-link></comment> <object-id pub-id-type="pmid">23041526</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref004"><label>4</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guyon</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Weston</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Barnhill</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Vapnik</surname> <given-names>V</given-names></name>. <article-title>Gene selection for cancer classification using support vector machines</article-title>. <source>Mach Learn</source>. <year>2002</year>;<volume>46</volume>(<issue>1–3</issue>):<fpage>389</fpage>–<lpage>422</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006486.ref005"><label>5</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brown</surname> <given-names>MPS</given-names></name>, <name name-style="western"><surname>Grundy</surname> <given-names>WN</given-names></name>, <name name-style="western"><surname>Lin</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Cristianini</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Sugnet</surname> <given-names>CW</given-names></name>, <name name-style="western"><surname>Furey</surname> <given-names>TS</given-names></name>, <etal>et al</etal>. <article-title>Knowledge-based analysis of microarray gene expression data by using support vector machines</article-title>. <source>P Natl Acad Sci USA</source>. <year>2000</year>;<volume>97</volume>(<issue>1</issue>):<fpage>262</fpage>–<lpage>267</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006486.ref006"><label>6</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zien</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ratsch</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Mika</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Scholkopf</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Lengauer</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Muller</surname> <given-names>KR</given-names></name>. <article-title>Engineering support vector machine kernels that recognize translation initiation sites</article-title>. <source>Bioinformatics</source>. <year>2000</year>;<volume>16</volume>(<issue>9</issue>):<fpage>799</fpage>–<lpage>807</lpage>. <object-id pub-id-type="pmid">11108702</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref007"><label>7</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woolgar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Golland</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Bode</surname> <given-names>S</given-names></name>. <article-title>Coping with confounds in multivoxel pattern analysis: what should we do about reaction time differences? A comment on Todd, Nystrom &amp; Cohen 2013</article-title>. <source>NeuroImage</source>. <year>2014</year>;<volume>98</volume>:<fpage>506</fpage>–<lpage>512</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2014.04.059" xlink:type="simple">10.1016/j.neuroimage.2014.04.059</ext-link></comment> <object-id pub-id-type="pmid">24793832</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref008"><label>8</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haynes</surname> <given-names>JD</given-names></name>. <article-title>A Primer on Pattern-Based Approaches to fMRI: Principles, Pitfalls, and Perspectives</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>87</volume>(<issue>2</issue>):<fpage>257</fpage>–<lpage>270</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.05.025" xlink:type="simple">10.1016/j.neuron.2015.05.025</ext-link></comment> <object-id pub-id-type="pmid">26182413</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref009"><label>9</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Norman</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Polyn</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Detre</surname> <given-names>GJ</given-names></name>, <name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name>. <article-title>Beyond mind-reading: multi-voxel pattern analysis of fMRI data</article-title>. <source>Trends Cogn Sci</source> <year>2006</year>;<volume>10</volume>(<issue>9</issue>):<fpage>424</fpage>–<lpage>430</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2006.07.005" xlink:type="simple">10.1016/j.tics.2006.07.005</ext-link></comment> <object-id pub-id-type="pmid">16899397</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref010"><label>10</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alizadeh</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Jamalabadi</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Schönauer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Leibold</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Gais</surname> <given-names>S</given-names></name>. <article-title>Decoding cognitive concepts from neuroimaging data using multivariate pattern analysis</article-title>. <source>Neuroimage</source>. <year>2017</year>;<volume>159</volume>:<fpage>449</fpage>–<lpage>458</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2017.07.058" xlink:type="simple">10.1016/j.neuroimage.2017.07.058</ext-link></comment> <object-id pub-id-type="pmid">28765057</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref011"><label>11</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hohne</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bartz</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Hebart</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Muller</surname> <given-names>KR</given-names></name>, <name name-style="western"><surname>Blankertz</surname> <given-names>B</given-names></name>. <article-title>Analyzing neuroimaging data with subclasses: A shrinkage approach</article-title>. <source>Neuroimage</source>. <year>2016</year>;<volume>124</volume>(<issue>Pt A</issue>):<fpage>740</fpage>–<lpage>751</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2015.09.031" xlink:type="simple">10.1016/j.neuroimage.2015.09.031</ext-link></comment> <object-id pub-id-type="pmid">26407815</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref012"><label>12</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hebart</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Baker</surname> <given-names>CI</given-names></name>. <article-title>Deconstructing multivariate decoding for the study of brain function</article-title>. <source>Neuroimage</source>. <year>2017</year>.</mixed-citation></ref>
<ref id="pcbi.1006486.ref013"><label>13</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Galbraith</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Daniel</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Vissel</surname> <given-names>B</given-names></name>. <article-title>A study of clustered data and approaches to its analysis</article-title>. <source>J Neurosci Methods</source>. <year>2010</year>;<volume>30</volume>(<issue>32</issue>):<fpage>10601</fpage>–<lpage>10608</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006486.ref014"><label>14</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Anderson</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Ter Braak</surname> <given-names>CJF</given-names></name>. <article-title>Permutation tests for multi-factorial analysis of variance</article-title>. <source>J Stat Comput Sim</source>. <year>2003</year>;<volume>73</volume>(<issue>2</issue>):<fpage>85</fpage>–<lpage>113</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006486.ref015"><label>15</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lazic</surname> <given-names>SE</given-names></name>. <article-title>The problem of pseudoreplication in neuroscientific studies: is it affecting your analysis?</article-title> <source>BMC Neurosci</source>. <year>2010</year>;<volume>11</volume>:<fpage>5</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/1471-2202-11-5" xlink:type="simple">10.1186/1471-2202-11-5</ext-link></comment> <object-id pub-id-type="pmid">20074371</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref016"><label>16</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aarts</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Verhage</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Veenvliet</surname> <given-names>JV</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>CV</given-names></name>, <name name-style="western"><surname>van der Sluis</surname> <given-names>S</given-names></name>. <article-title>A solution to dependency: using multilevel analysis to accommodate nested data</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>(<issue>4</issue>):<fpage>491</fpage>–<lpage>496</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3648" xlink:type="simple">10.1038/nn.3648</ext-link></comment> <object-id pub-id-type="pmid">24671065</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref017"><label>17</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Todd</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Nystrom</surname> <given-names>LE</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>Confounds in multivariate pattern analysis: Theory and rule representation case study</article-title>. <source>NeuroImage</source>. <year>2013</year>;<volume>77</volume>:<fpage>157</fpage>–<lpage>165</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.03.039" xlink:type="simple">10.1016/j.neuroimage.2013.03.039</ext-link></comment> <object-id pub-id-type="pmid">23558095</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref018"><label>18</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Malone</surname> <given-names>PS</given-names></name>, <name name-style="western"><surname>Glezer</surname> <given-names>LS</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Jiang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Riesenhuber</surname> <given-names>M</given-names></name>. <article-title>Multivariate Pattern Analysis Reveals Category-Related Organization of Semantic Representations in Anterior Temporal Cortex</article-title>. <source>J Neurosci</source>. <year>2016</year>;<volume>36</volume>(<issue>39</issue>):<fpage>10089</fpage>–<lpage>10096</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1599-16.2016" xlink:type="simple">10.1523/JNEUROSCI.1599-16.2016</ext-link></comment> <object-id pub-id-type="pmid">27683905</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref019"><label>19</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Delorme</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Makeig</surname> <given-names>S</given-names></name>. <article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title>. <source>J Neurosci Methods</source>. <year>2004</year>;<volume>134</volume>(<issue>1</issue>):<fpage>9</fpage>–<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jneumeth.2003.10.009" xlink:type="simple">10.1016/j.jneumeth.2003.10.009</ext-link></comment> <object-id pub-id-type="pmid">15102499</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref020"><label>20</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Winkler</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Webster</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Vidaurre</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Nichols</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>SM</given-names></name>. <article-title>Multi-level block permutation</article-title>. <source>Neuroimage</source>. <year>2015</year>;<volume>123</volume>:<fpage>253</fpage>–<lpage>268</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2015.05.092" xlink:type="simple">10.1016/j.neuroimage.2015.05.092</ext-link></comment> <object-id pub-id-type="pmid">26074200</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref021"><label>21</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fan</surname> <given-names>JQ</given-names></name>, <name name-style="western"><surname>Fan</surname> <given-names>YY</given-names></name>. <article-title>High Dimensional Classification Using Features Annealed Independence Rules</article-title>. <source>Ann Stat</source>. <year>2008</year>;<volume>36</volume>(<issue>6</issue>):<fpage>2605</fpage>–<lpage>2637</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1214/07-AOS504" xlink:type="simple">10.1214/07-AOS504</ext-link></comment> <object-id pub-id-type="pmid">19169416</object-id></mixed-citation></ref>
<ref id="pcbi.1006486.ref022"><label>22</label> <mixed-citation publication-type="other" xlink:type="simple">Tax DM, Duin RP: Using two-class classifiers for multiclass classification. In: Proceedings of 16th International Conference on Pattern Recognition. IEEE; 2002. pp. 124–127.</mixed-citation></ref>
<ref id="pcbi.1006486.ref023"><label>23</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hastie</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>. <article-title>Discriminant analysis by Gaussian mixtures</article-title>. <source>J Roy Stat Soc B Met</source>. <year>1996</year>;<volume>58</volume>(<issue>1</issue>):<fpage>155</fpage>–<lpage>176</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006486.ref024"><label>24</label> <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhu</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Martinez</surname> <given-names>AM</given-names></name>. <article-title>Subclass discriminant analysis</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source>. <year>2006</year>;<volume>28</volume>(<issue>8</issue>):<fpage>1274</fpage>–<lpage>1286</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TPAMI.2006.172" xlink:type="simple">10.1109/TPAMI.2006.172</ext-link></comment> <object-id pub-id-type="pmid">16886863</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
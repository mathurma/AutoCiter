<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.3000290</article-id>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-18-00734</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Amygdala</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Amygdala</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Hippocampus</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Hippocampus</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Semantics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Single neuron function</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Single neuron function</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Cerebral cortex</subject><subj-group><subject>Entorhinal cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Cerebral cortex</subject><subj-group><subject>Entorhinal cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject><subj-group><subject>False memories</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject><subj-group><subject>False memories</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuronal tuning</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Representation of abstract semantic knowledge in populations of human single neurons in the medial temporal lobe</article-title>
<alt-title alt-title-type="running-head">Representations of abstract knowledge by MTL Neurons</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-3969-9782</contrib-id>
<name name-style="western">
<surname>Reber</surname>
<given-names>Thomas P.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Bausch</surname>
<given-names>Marcel</given-names>
</name>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6736-7550</contrib-id>
<name name-style="western">
<surname>Mackay</surname>
<given-names>Sina</given-names>
</name>
<role content-type="http://credit.casrai.org/">Investigation</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Boström</surname>
<given-names>Jan</given-names>
</name>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Elger</surname>
<given-names>Christian E.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Resources</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1305-8028</contrib-id>
<name name-style="western">
<surname>Mormann</surname>
<given-names>Florian</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Department of Epileptology, University of Bonn Medical Centre, Bonn, Germany</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Faculty of Psychology, Swiss Distance University Institute, Brig, Switzerland</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Department of Neurosurgery, University of Bonn Medical Centre, Bonn, Germany</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Malach</surname>
<given-names>Rafael</given-names>
</name>
<role>Academic Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Weizmann Institute of Science, ISRAEL</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">treber@live.com</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>3</day>
<month>6</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<month>6</month>
<year>2019</year>
</pub-date>
<volume>17</volume>
<issue>6</issue>
<elocation-id>e3000290</elocation-id>
<history>
<date date-type="received">
<day>18</day>
<month>9</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>10</day>
<month>5</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Reber et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.3000290"/>
<abstract>
<p>Sensory experience elicits complex activity patterns throughout the neocortex. Projections from the neocortex converge onto the medial temporal lobe (MTL), in which distributed neocortical firing patterns are distilled into sparse representations. The precise nature of these neuronal representations is still unknown. Here, we show that population activity patterns in the MTL are governed by high levels of semantic abstraction. We recorded human single-unit activity in the MTL (4,917 units, 25 patients) while subjects viewed 100 images grouped into 10 semantic categories of 10 exemplars each. High levels of semantic abstraction were indicated by representational similarity analyses (RSAs) of patterns elicited by individual stimuli. Moreover, pattern classifiers trained to decode semantic categories generalised successfully to unseen exemplars, and classifiers trained to decode exemplar identity more often confused exemplars of the same versus different categories. Semantic abstraction and generalisation may thus be key to efficiently distill the essence of an experience into sparse representations in the human MTL. Although semantic abstraction is efficient and may facilitate generalisation of knowledge to novel situations, it comes at the cost of a loss of detail and may be central to the generation of false memories.</p>
</abstract>
<abstract abstract-type="toc">
<p>Single-neuron representations of stimuli in the human medial temporal lobe at the population level are governed by highly abstract semantic principles, but the attendant efficiency and potential for generalization comes at the cost of confusion between related stimuli.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>What is the neuronal code for sensory experience in the human medial temporal lobe (MTL)? Single-cell electrophysiology in the awake human brain during chronic, invasive epilepsy monitoring has previously revealed the existence of so-called concept cells. These cells have been found to increase their firing rate in response to, for example, the famous tennis player ‘Roger Federer’, whether his name is spoken by a computer voice or a picture of him is presented on a computer screen. These neurons thus seem to encode the semantic content of a stimulus, regardless of the sensory modality through which it is delivered. Previous work has predominantly focused on individual neurons that were selected based on their strong response to a particular stimulus using rather conservative statistical criteria. Those studies stressed that concept cells encode a single, concrete concept in an all-or-nothing fashion. Here, we analysed the neuronal code on the level of the entire population of neurons without any preselection. We conducted representational similarity analyses (RSAs) and pattern classification analyses of firing patterns evoked by visual stimuli (for example, a picture of an apple) that could be grouped into semantic categories on multiple levels of abstraction (‘fruit’, ‘food’, ‘natural things’). We found that neuronal activation patterns contain information on higher levels of categorical abstraction rather than just the level of individual exemplars. On the one hand, the neuronal code in the human MTL thus seems well suited to generalise semantic knowledge to new situations; on the other hand, it could also be responsible for the generation of false memories.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung (CH)</institution>
</funding-source>
<award-id>P300P1_161178</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-3969-9782</contrib-id>
<name name-style="western">
<surname>Reber</surname>
<given-names>Thomas P.</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>German Reseearch Council</institution>
</funding-source>
<award-id>SFB1089</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1305-8028</contrib-id>
<name name-style="western">
<surname>Mormann</surname>
<given-names>Florian</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution>Volkswagen Foundation (DE)</institution>
</funding-source>
<award-id>MO930/4-1</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1305-8028</contrib-id>
<name name-style="western">
<surname>Mormann</surname>
<given-names>Florian</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>- Volkswagen Foundation (MO930/4-1) - German Research Council (SFB1089) - Swiss National Science Foundation (P300P1_161178) The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript</funding-statement>
</funding-group>
<counts>
<fig-count count="4"/>
<table-count count="0"/>
<page-count count="17"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-06-13</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data and custom code are available on <ext-link ext-link-type="uri" xlink:href="https://github.com/rebrowski/abstractRepresentationsInMTL.git" xlink:type="simple">https://github.com/rebrowski/abstractRepresentationsInMTL.git</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Cognitive faculties enabling flexible adaption of behaviour are at the heart of the human species’ evolutionary success. Cognition operates on abstract representations of knowledge derived from prior experience [<xref ref-type="bibr" rid="pbio.3000290.ref001">1</xref>]. Abstraction can have two separate but related meanings [<xref ref-type="bibr" rid="pbio.3000290.ref002">2</xref>]. First, formation of a concept in semantic memory requires abstraction in the sense of generalisation across episodes. For example, the concept ‘dog’, a furry animal that barks, is learned by extracting regularities among multiple encounters with various exemplars of dogs. Second, abstraction can also refer to the extraction of meaning from sensory input in a single instance of perception. Abstraction in the latter sense ranges from lower, more concrete levels (e.g., labelling a percept as ‘terrier’) to intermediate levels (‘dog’) and high, superordinate levels (‘animal’). Abstraction both as a cross-episode generalisation and as an extraction of supramodal semantic information from sensory input are in constant interplay and shape episodic and semantic memory representations [<xref ref-type="bibr" rid="pbio.3000290.ref003">3</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref004">4</xref>].</p>
<p>Our knowledge about semantic representations in the human brain is for the most part restricted to the cortex. Putative functional roles of involved neocortical regions correspond to sensory and/or motor features of an encoded concept [<xref ref-type="bibr" rid="pbio.3000290.ref001">1</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref005">5</xref>]. Here, abstract categories such as, for example, living and nonliving things differ with respect to which portions of the neocortex are recruited for their encoding. Due to such macroscopic, topographical organisation of semantic representations in the neocortex, these representations can be investigated with rather coarse imaging techniques such as functional magnetic resonance imaging [<xref ref-type="bibr" rid="pbio.3000290.ref005">5</xref>]. Large strides have also been made in elucidating the neuronal code of object and face recognition along the ventral processing pathway of nonhuman primates leading up to highly abstract representation in monkey inferotemporal cortex and the amygdala [<xref ref-type="bibr" rid="pbio.3000290.ref006">6</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref007">7</xref>]. Next to categorical codes, influential approaches also entail mapping semantic concepts onto a multidimensional, semantic space along dimensions such as living–nonliving or abstract–concrete [<xref ref-type="bibr" rid="pbio.3000290.ref002">2</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref008">8</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref009">9</xref>].</p>
<p>Investigating object recognition and semantic representations at the final stages of the ventral processing pathway in the human medial temporal lobe (MTL), including the amygdala, has been notoriously difficult. Investigation of neuronal representations in the human MTL at the relevant level of detail seems impossible with noninvasive imaging techniques because—unlike the neocortex—most MTL areas lack semantic topographical organisation [<xref ref-type="bibr" rid="pbio.3000290.ref010">10</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref011">11</xref>]. Studies conducted in the setting of invasive epilepsy monitoring using additional microelectrodes to record action potentials of single units have been instrumental for this purpose [<xref ref-type="bibr" rid="pbio.3000290.ref010">10</xref>–<xref ref-type="bibr" rid="pbio.3000290.ref015">15</xref>]. A seminal finding of these studies is that some MTL units responded in a selective and invariant manner to various images of a familiar person and even to their written and spoken name, suggesting that they encode the identity of that person and thus the contents of a concrete semantic concept in an all-or-none fashion [<xref ref-type="bibr" rid="pbio.3000290.ref013">13</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref014">14</xref>]. However, further studies emphasised that MTL neurons can also respond to a wider range of stimuli in graded fashions in which sometimes more abstract semantic relations between stimuli can be identified such as, for example, membership to a broad category [<xref ref-type="bibr" rid="pbio.3000290.ref009">9</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref014">14</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref015">15</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref016">16</xref>]. Thus, rather than all-or-nothing responses to specific concepts, it could be that neurons in the human MTL encode semantic features along continuous dimensions, resulting in ‘semantic tuning curves’. Or as Kornblith and Tsao [<xref ref-type="bibr" rid="pbio.3000290.ref006">6</xref>] put it in the context of face-patches in primate IT, they are ‘[…] <italic>measuring</italic> faces, they are not yet explicitly <italic>classifying</italic> them’.</p>
<p>Previous human single unit studies often preselected units based on rather conservative response criteria, which may have resulted in a potential overestimation of all-or-none responses to individual semantic concepts. In the current study, in contrast, we analyse representations at the level of the entire population of units we record from. By doing so, we investigate how and at what level of abstraction semantic information conveyed by visual input is encoded in activity of single units in the human MTL. In contrast to previous studies, we consistently used the same set of images across sessions and patients, and the images could be grouped at multiple levels of abstraction. This procedure, in combination with a large sample of epileptic patients, allowed us to record neuronal responses for each image in a population of neurons unprecedented in size. Using this procedure, we could characterise and compare the nature of representations and their level of abstraction at a population level for different regions of the MTL.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<p>Subjects (<italic>N</italic> = 25; 59 sessions) were bilaterally implanted with depth electrodes for seizure monitoring in the amygdala, hippocampus, entorhinal cortex, and parahippocampal cortex. Subjects were presented with visual stimuli depicting objects from 10 semantic categories consisting of 10 exemplars each (100 images, 10 trials each). The subjects’ task was to indicate by button press whether a man-made or natural object was depicted. As expected, this task was very easy as reflected by high accuracy (median = 97.62%, IQR = 2.25%) and short reaction times (median = 669 ms, IQR = 146 ms).</p>
<p>We first analysed our data by classifying units into responsive and nonresponsive, according to an established criterion (see Neuronal response test section in Materials and methods) as in previous studies [<xref ref-type="bibr" rid="pbio.3000290.ref012">12</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref013">13</xref>] (Figs <xref ref-type="fig" rid="pbio.3000290.g001">1</xref> and <xref ref-type="fig" rid="pbio.3000290.g002">2</xref>). Our analyses confirm that some units in the MTL respond to only a few stimuli in the set (<xref ref-type="fig" rid="pbio.3000290.g001">Fig 1</xref>). We recorded from a total of 4,917 units, 2,009 of which were classified as single units (41%). In the amygdala, we found 1,392 units (656 single units [47%]), in the hippocampus 1,863 units (706 single units [38%]), in the entorhinal cortex 828 units (328 single units [40%]), and 831 units (319 single units [38%]) in the parahippocampal cortex (<xref ref-type="fig" rid="pbio.3000290.g002">Fig 2B</xref>). A subset of 785 units responded with increased firing rates to at least one of the 100 stimuli (see Neuronal response test section in Materials in methods; <xref ref-type="fig" rid="pbio.3000290.g002">Fig 2B</xref>). Selectivity as determined by the number of response-eliciting stimuli for a given neuron was similar in the entorhinal cortex, amygdala, and hippocampus but was markedly lower in the parahippocampal cortex [<xref ref-type="bibr" rid="pbio.3000290.ref012">12</xref>] (<xref ref-type="fig" rid="pbio.3000290.g002">Fig 2C</xref>). Some units responded very selectively, sometimes to only one of the stimuli in the set (<xref ref-type="fig" rid="pbio.3000290.g001">Fig 1D–1F</xref>). In the amygdala, this was the case in 43% of the responsive units, in the hippocampus 57%, and in the entorhinal cortex 54%. This number was markedly lower in the parahippocampal cortex, namely, 35%. When units responded to multiple stimuli, the response-eliciting stimuli were often from the same semantic category (<xref ref-type="fig" rid="pbio.3000290.g001">Fig 1A–1C</xref> and <xref ref-type="fig" rid="pbio.3000290.g001">1G–1I</xref>).</p>
<fig id="pbio.3000290.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.3000290.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Single neurons respond selectively to a few stimuli in the set.</title>
<p>Each row corresponds to data from one unit. The unit in the first row was recorded in the left anterior hippocampus. Units in rows two and three were recorded in the right amygdala. The three units were recorded in three different patients. (A, D, G) Spike shapes are depicted as temperature-scaled density plots. (B, E, H) Bar height in the histogram indicates the strength of neuronal responses to individual stimuli colour-coded according to superordinate semantic category. (C, F, I) Raster plots (stimulus onset: 0 s) depict the six most significant responses (grey rectangles indicate that the spiking pattern is considered as neuronal response to the stimulus; see Neuronal response test section in Materials and methods). Note that the images displayed here are different from the ones we actually used to prevent ostensible copyright infringement. Data and scripts underlying this figure as well as the image files we actually used are deposited here: <ext-link ext-link-type="uri" xlink:href="https://github.com/rebrowski/abstractRepresentationsInMTL" xlink:type="simple">https://github.com/rebrowski/abstractRepresentationsInMTL</ext-link>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.3000290.g001" xlink:type="simple"/>
</fig>
<fig id="pbio.3000290.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.3000290.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Response probabilities (RPs) and selectivity.</title>
<p>(A) RPs (see Calculation of response probabilities section in Materials and methods) in percent across different categories and anatomical regions. Error bars indicate 95% CIs estimated by a subsampling procedure (see Calculation of response probabilities section in Materials and methods). Asterisks on top of a bar indicate a significant deviation of RP from RP of all other categories in a region (Fisher’s exact test, Bonferroni-corrected <italic>α</italic> = <inline-formula id="pbio.3000290.e001"><alternatives><graphic id="pbio.3000290.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.3000290.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mfrac><mml:mrow><mml:mn>0.05</mml:mn></mml:mrow><mml:mrow><mml:mn>40</mml:mn></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>). (B) Overview of SUs and MUs and their responsiveness to at least one of the stimuli. (C) Cumulative distributions of neuronal response selectivity, that is, the number of response-eliciting images identified per unit, truncated after 35 on the x-axis. Data and scripts underlying this figure are deposited here: <ext-link ext-link-type="uri" xlink:href="https://github.com/rebrowski/abstractRepresentationsInMTL" xlink:type="simple">https://github.com/rebrowski/abstractRepresentationsInMTL</ext-link>. AM, amygdala; CI, confidence interval; EC, entorhinal cortex; HC, hippocampus; MU, multiunit; nr, nonresponding; PHC, parahippocampal cortex; r, responding; RP, response probability; SU, single unit.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.3000290.g002" xlink:type="simple"/>
</fig>
<p>We also calculated the probabilities with which images from a given category elicited a neuronal response, separate for each anatomical region in the MTL. To this aim, we computed the number of significant responses across all units and divided this number by the total number of stimuli and the number of units. Observed response probabilities ranged between approximately 0.25% and 2% across anatomical regions and stimulus categories (<xref ref-type="fig" rid="pbio.3000290.g001">Fig 1D</xref>). Neurons responded more frequently to food stimuli than to stimuli of other categories, which was especially prominent in the amygdala and, to a lesser degree, also in the hippocampus and entorhinal cortex (<xref ref-type="fig" rid="pbio.3000290.g002">Fig 2A</xref>).</p>
<p>Going beyond analyses of responsive versus nonresponding units, we next looked at responses of the whole population of units we recorded from. With these analyses, we find that population activity is determined by abstract, semantic features of the stimuli. We investigated population activity by representational similarity analyses (RSAs) [<xref ref-type="bibr" rid="pbio.3000290.ref009">9</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref017">17</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref018">18</xref>]. To this aim, we quantified each neuronal response to a stimulus using a single <italic>Z</italic> score that expressed average firing across all trials of a stimulus in the 1,000 ms after stimulus onset, normalised using the distribution of baseline firing rates (−500 to 0 ms relative to stimulus onset) across all trials. The population response to a stimulus thus corresponded to a population vector of <italic>Z</italic> scores from all units in a given region. Representational dissimilarity (i.e., distance) between two stimuli was then quantified as 1 − Pearson’s correlation coefficient of their population vectors. Representational dissimilarities are displayed as matrices of colour-coded distance between all pairs of stimuli (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3A–3D</xref>). Representational dissimilarity analyses showed that population firing patterns evoked by stimuli of the same category were more similar than those evoked by stimuli from different categories in all anatomical regions (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3A–3D</xref>; all <italic>p</italic> &lt; 10<sup>−5</sup>; random permutation test, Inference statistics on representational dissimilarity and confusion matrices section in Materials and methods).</p>
<fig id="pbio.3000290.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.3000290.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Abstract semantic features determine representational similarity at the population level.</title>
<p>(A–D) Representational dissimilarity matrices showing the distance between two stimuli quantified as 1 –Pearson’s correlation coefficient <italic>R</italic> for the response activity of all recorded units. (E–H) Exemplars in two-dimensional space derived from multidimensional scaling of dissimilarity. (I–M) Dendrograms generated from automated hierarchical clustering. See <xref ref-type="supplementary-material" rid="pbio.3000290.s003">S3 Fig</xref> for dendrograms spanning the full page width in each region. Data and scripts underlying this figure are deposited here: <ext-link ext-link-type="uri" xlink:href="https://github.com/rebrowski/abstractRepresentationsInMTL" xlink:type="simple">https://github.com/rebrowski/abstractRepresentationsInMTL</ext-link>. AM, amygdala; Bi, birds; Cl, clothes; Co, computer; D1, dimension 1; D2, dimension 2; EC, entorhinal cortex; Fl, flowers; Fr, fruit; Fu, furniture; HC, hippocampus; In (green), insects; In (purple), instruments; MF, manmade food; PHC, parahippocampal cortex; WA, wild animals.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.3000290.g003" xlink:type="simple"/>
</fig>
<p>To elucidate potential principles on higher levels of abstraction, we applied multidimensional scaling (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3E–3H</xref>) and automated hierarchical clustering (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3I–3M</xref>, <xref ref-type="supplementary-material" rid="pbio.3000290.s003">S3 Fig</xref>) to these dissimilarity matrices. Remarkably, inspection of dendrograms obtained from hierarchical clustering revealed that the preconceived assignment of stimuli to superordinate categories was almost perfectly reflected in representational dissimilarity of the recorded population activity in the amygdala and hippocampus (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3I and 3K</xref>). That preconceived categories matched information present in neuronal representations is evidenced by the sorting on the x-axis of the dendrograms. Perfect correspondence between neuronal similarity and category membership is indicated in that all exemplars of a category line up next to one another on the x-axis after sorting according to similarity. This is the case for all but two categories in the amygdala, in which only one exemplar of the ‘computer’ category ends up closer to other exemplars from the ‘musical instruments’ category. A similar pattern of exemplar sorting is evident in the hippocampus, whereas this was not the case in the entorhinal and parahippocampal cortex (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3L and 3M</xref>). RSAs for units that did not show a response according to any of the stimuli in our set (according to the statistical response criterion used in this and previous studies) showed similar patterns of similarity (<xref ref-type="supplementary-material" rid="pbio.3000290.s001">S1 Fig</xref>). Consequently, representational similarities of nonresponding units alone are statistically significantly higher for within- versus between-category pairs (all <italic>p</italic> &lt; 10<sup>−5</sup>; see ‘Inference statistics on representational dissimilarity and confusion matrices’ section in Materials and methods), suggesting that even small variations in firing rate of MTL units contain considerable amounts of information at an abstract, categorical level.</p>
<p>Representations clustered beyond our preconceived categories in a highly abstract but meaningful way. Abstract semantic clusters of representational similarity emerging from neuronal representations are visualised by the dendrograms resulting from hierarchical clustering (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3I–3K</xref>) and by projections of multidimensional scaling onto a two-dimensional space (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3E–3H</xref>). In the amygdala, we saw a food cluster that consisted of all exemplars of man-made food and fruit categories. This food cluster becomes evident in that exemplars from the preconceived categories of ‘man-made food’ and ‘fruit’ are close together in the 2-dimensional projection generated by multidimensional scaling (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3E</xref>). An animal cluster entailed exemplars of wild animals, birds, and insects. The categories of all man-made objects together constituted a further cluster. In the hippocampus, we additionally observed a clear separation between man-made and natural objects. This separation becomes evident when one draws a diagonal from top left to bottom right in <xref ref-type="fig" rid="pbio.3000290.g003">Fig 3F</xref> that almost perfectly separates manmade from natural exemplars. Such clearly semantic principles governing representational similarity at a high level of abstraction were less evident in the entorhinal and parahippocampal cortex.</p>
<p>To assess whether low-level physical image similarity could have been responsible for these findings, we calculated four widely used statistics to compare physical properties of two images, namely, the Euclidean distance, the mean squared error, the peak signal-to-noise value, and the structural similarity index. We then performed analyses analog to the ones shown in <xref ref-type="fig" rid="pbio.3000290.g003">Fig 3</xref> using these image similarity measures (<xref ref-type="supplementary-material" rid="pbio.3000290.s002">S2 Fig</xref>). These analyses showed no emergence of higher-order grouping of images according to abstract semantics as was the case for the neural data (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3</xref>). Therefore, we conclude that low-level physical similarity cannot account for the findings of representation similarity in our neuronal response patterns.</p>
<p>Abstraction comes at a trade-off between generalisation of knowledge to new situations and confusion between similar exemplars. We used the population responses described above to train pattern classifiers (multiclass support vector machine models; see Decoding of stimulus identity and category section in Methods and materials). A classifier was trained on the population responses of half the stimuli per category to predict the category label and was then tested out of sample on population responses of the other half of stimuli. This procedure was repeated 100 times with random divisions of the data into training and test sets. Successful generalisation to untrained stimuli was indicated by highly accurate out-of-sample classification of category labels from population responses (<xref ref-type="fig" rid="pbio.3000290.g004">Fig 4A</xref>; for separate analyses for each subject, collapsing across anatomical regions, see <xref ref-type="supplementary-material" rid="pbio.3000290.s004">S4 Fig</xref>). Generalisation was best using population responses from amygdala units, intermediate using hippocampal and entorhinal units, and lowest using parahippocampal units. Nevertheless, generalisation exceeded chance performance in all MTL regions by far.</p>
<fig id="pbio.3000290.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.3000290.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Pattern classifier algorithms learn abstract semantic information.</title>
<p>(A–E) Classifiers were trained to classify the superordinate category from <italic>Z</italic> scored responses to half of the stimuli per category and tested out of sample on the other half. Classification performance on 100 random divisions of data into training and test set is indicated in box plots (Cohen’s κ). (B–I) Confusion matrices (rows: correct label; columns: predicted label). (F–K) Classifiers were trained on half of the trials per stimulus to predict individual stimulus identity and tested out of sample on the other half of trials. Colour codes extend to maximally 50% (B–E) and 10% (G–K) for display purposes. Values higher than these maxima (for example, squares on the main diagonal) are not resolved in favour of making the patterns in off-diagonal areas more clearly visible. Data and scripts underlying this figure are deposited here: <ext-link ext-link-type="uri" xlink:href="https://github.com/rebrowski/abstractRepresentationsInMTL" xlink:type="simple">https://github.com/rebrowski/abstractRepresentationsInMTL</ext-link>. AM, amygdala; Bi, birds; Cl, clothes; Co, computer; EC, entorhinal cortex; Fl, flowers; Fr, fruit; Fu, furniture; HC, hippocampus; In, insects; In, instruments; MF, manmade food; PHC, parahippocampal cortex; WA, wild animals.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.3000290.g004" xlink:type="simple"/>
</fig>
<p>To assess performance in classifying individual stimuli, we calculated <italic>Z</italic> scored population responses of unit firing for each trial in the same manner as described above. Pattern classification algorithms were then trained on population responses of half of the trials for each stimulus and tested out of sample on the other half. Again, out-of-sample performance was assessed in 100 random divisions of the data into training and test set. Classification performance exceeded chance level in all regions of the MTL (<xref ref-type="fig" rid="pbio.3000290.g004">Fig 4F</xref>). Interestingly, we found a systematic pattern of misclassifications when inspecting confusion matrices (<xref ref-type="fig" rid="pbio.3000290.g004">Fig 4G–4K</xref>). Confusion matrices cross-tabulate the number of classifier outcomes by predicted stimulus label in columns and true stimulus labels in rows. These analyses show that pattern classification algorithms trained to decode individual stimulus identity more often confused stimuli from the same versus different superordinate categories (<xref ref-type="fig" rid="pbio.3000290.g004">Fig 4F–4K</xref>; all regions <italic>p</italic> &lt; 10<sup>−5</sup>, permutation test; see ‘Inference statistics on representational dissimilarity and confusion matrices’ section in Materials and methods; for analogous analyses separately for each subject but collapsing across anatomical regions, see <xref ref-type="supplementary-material" rid="pbio.3000290.s005">S5 Fig</xref>).</p>
</sec>
<sec id="sec003" sec-type="conclusions">
<title>Discussion</title>
<p>Taken together, our results provide a novel perspective on how information is encoded in the human MTL. We demonstrate that despite selective tuning of individual neurons to only a few stimuli in the set, activity at the population level is determined by information with a high degree of semantic abstraction. We find that population activity is similar in response to exemplars of the same category and that response pattern similarity extends to highly abstract semantic categories. Pattern classification results show high levels of semantic abstraction, which, on one hand, can be useful for successful generalisation of knowledge to novel situations. On the other hand, semantic abstraction comes at the cost of confusion between semantically similar stimuli.</p>
<p>With respect to neuronal representations in the MTL, we demonstrate a semantic code that spans multiple layers of abstraction emerging at the population level. This perspective may aid to reconcile disparate findings from previous studies investigating response properties of individual units [<xref ref-type="bibr" rid="pbio.3000290.ref011">11</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref013">13</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref016">16</xref>]. Some have concluded that unit activity encodes concrete concepts such as, for example, a person’s identity [<xref ref-type="bibr" rid="pbio.3000290.ref013">13</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref014">14</xref>]. Others postulate superordinate category membership as a decisive feature driving unit activity [<xref ref-type="bibr" rid="pbio.3000290.ref016">16</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref019">19</xref>]. Our study may reconcile these views as population-level analyses show that encoded information spans across multiple levels of abstraction ranging from the concrete exemplar level to the level of preconceived semantic categories and beyond. Pattern classification analyses demonstrate that information on the exemplar and superordinate categorical level can both be decoded from population activity, whereas categorical information seems predominant. These aspects may not become apparent when looking at response profiles of individual units and underscore the importance of analyses at the population level.</p>
<p>Furthermore, our data refine the view on sparseness of coding in the human MTL. Hallmark human single unit studies suggest that very few concepts drive activity in one single neuron [<xref ref-type="bibr" rid="pbio.3000290.ref013">13</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref014">14</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref020">20</xref>]. In fact, considerably more than 50% of responsive units were found previously to respond to only one out of approximately 100 stimuli [<xref ref-type="bibr" rid="pbio.3000290.ref012">12</xref>]. This is true in the amygdala, hippocampus, and entorhinal cortex, whereas selectivity is lower in the parahippocampal cortex [<xref ref-type="bibr" rid="pbio.3000290.ref012">12</xref>]. These findings led to the conclusion that the MTL uses a very sparse, almost ‘grandmother cell’-like code [<xref ref-type="bibr" rid="pbio.3000290.ref021">21</xref>]. Although some units in our data set indeed only fired in response to one stimulus in the set, the overall selectivity in our study was lower (see <xref ref-type="fig" rid="pbio.3000290.g001">Fig 1F</xref>) than reported earlier [<xref ref-type="bibr" rid="pbio.3000290.ref012">12</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref020">20</xref>]. Previous studies used stimulus sets that were tailored to the patients’ interests, depicting relatives, preferred celebrities, and job- and hobby-related objects [<xref ref-type="bibr" rid="pbio.3000290.ref012">12</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref013">13</xref>]. The aim in these studies was to screen for response-eliciting stimuli using a wide range of different concepts, likely resulting in rather low semantic feature overlap between stimuli. Our current stimulus material had a systematic semantic structure because images were grouped into categories of semantically related exemplars. Assuming that unit activity is determined by a rather narrow ‘semantic tuning curve’, we would indeed expect that neurons fire less selectively when ‘semantic distance’ between stimuli is sufficiently low. Thus, semantic relatedness between stimuli in a set seems likely to influence estimates of sparseness of unit responses in the MTL.</p>
<p>Two previous studies have applied RSAs to single units in the human MTL. First, in 2011, Mormann and colleagues [<xref ref-type="bibr" rid="pbio.3000290.ref017">17</xref>] used RSA in combination with images that could be grouped into 3 categories, namely, persons, animals, and landmarks. This study found that the amygdala is preferentially activated by animal stimuli but did not investigate the semantic nature and level of abstraction in amygdala unit activity. Furthermore, a 2015 paper again by Mormann and colleagues [<xref ref-type="bibr" rid="pbio.3000290.ref018">18</xref>] used RSA to show that units in the amygdala encode face identity rather than gaze direction. Again, analyses focused on the amygdala, and semantic abstraction could not be assessed because stimuli consisted of pictures of faces with gazes pointed in different directions.</p>
<p>Furthermore, the notion of an all-or-nothing response behaviour as implied in earlier studies (for example, [<xref ref-type="bibr" rid="pbio.3000290.ref013">13</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref020">20</xref>]) should be critically reevaluated. Obviously, response behaviour strongly depends on the exact definition of the statistical response criterion employed. Previous studies have used a rather conservative response criterion and tended to regard any activity not meeting this criterion as background noise [<xref ref-type="bibr" rid="pbio.3000290.ref012">12</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref013">13</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref020">20</xref>]. Our analyses demonstrate that even after excluding all neurons that showed statistical responses to any of the presented stimuli, semantic category information is still present in the population activity of the ‘nonresponsive’ neurons. Thus, such subthreshold responses according to this criterion are likely to carry relevant information about the presented stimulus. For example, looking at <xref ref-type="fig" rid="pbio.3000290.g001">Fig 1</xref> A and <xref ref-type="fig" rid="pbio.3000290.g001">1C</xref>, we see such subthreshold responses. Here, the units clearly prefer stimuli from one category (for example, clothing items in case of 1A). Within this category, however, some images drive spiking activity more strongly than others. The jean jacket in <xref ref-type="fig" rid="pbio.3000290.g001">Fig 1A</xref> is the fifth-most response-eliciting stimulus for that unit but falls short of being classified as a response by the criterion we use, as indicated by the absence of a grey box around the respective raster plot. In view of the other response-eliciting stimuli, we would probably conclude that this might be a true but subthreshold response. Arguably, there are some units in the data set for which we find only such subthreshold responses because the near-optimal stimuli for these units were not in our set. It thus seems that these subthreshold units carry a significant amount of categorical information at the population level. Together, these results suggest that neurons do not encode the identity of a concept in an all-or-none fashion but rather that firing patterns may be best described as graded with the assumption of an underlying ‘semantic tuning curve’.</p>
<p>The high levels of abstraction in population activity observed in this study could also suggest a single-unit mechanism in the MTL for the generation of false memories. Classically, false memories are studied by presenting semantically related words for study, for example, ‘giraffe’, ‘lion’, ‘elephant’, or ‘tiger’, followed by a recognition memory test requiring old–new judgments of old words (for example, ‘lion’), as well as new words that were either semantically related (‘leopard’) or unrelated (‘keyboard’) to the studied words [<xref ref-type="bibr" rid="pbio.3000290.ref022">22</xref>]. False memories manifest in more frequent old judgments to new words with high versus low semantic relatedness [<xref ref-type="bibr" rid="pbio.3000290.ref022">22</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref023">23</xref>]. Overlap of recruited neocortical regions corresponds to semantic feature overlap between studied and new words, which, in turn, is correlated with false-memory likelihood [<xref ref-type="bibr" rid="pbio.3000290.ref024">24</xref>]. However, it seems likely that overlap in recruitment of neocortical regions is in fact the consequence of ‘false’ reinstatement initiated by the hippocampus rather than the cause of false memories [<xref ref-type="bibr" rid="pbio.3000290.ref024">24</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref025">25</xref>]. The hippocampus has been shown to be equally active during false and true memories in humans [<xref ref-type="bibr" rid="pbio.3000290.ref026">26</xref>], and optogenetic activation of neurons in the rodent hippocampus has been shown to trigger reinstatement of ‘false’ contextual fear memories [<xref ref-type="bibr" rid="pbio.3000290.ref025">25</xref>]. Our data suggest that confusion between semantically similar stimuli is facilitated by the abstract semantic code utilised by neurons in the hippocampus, and thereby provides a link between human behavioural and functional magnetic resonance imaging versus rodent optogenetic studies of false-memory generation [<xref ref-type="bibr" rid="pbio.3000290.ref022">22</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref024">24</xref>–<xref ref-type="bibr" rid="pbio.3000290.ref026">26</xref>].</p>
<p>The combination of RSA and pattern classification applied to our single neuron data reveals novel insights about the neuronal code for semantics in the MTL. Although we think that the decoding of semantic generalisation (top row of <xref ref-type="fig" rid="pbio.3000290.g004">Fig 4</xref>) and the RSA analyses (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3</xref>) convey similar aspects of the data, the decoding results are by no means a trivial consequence of the RSA analyses. First, the decoding analyses allow for a comparison of decoding accuracy for exemplar versus category decision. Second, the fact that confusions within category are more frequent than those across category offers a mechanistic explanation for the generation of false memories. Both of these points do not become apparent from the RSA results alone. These RSA results, in turn, show higher-order organising principles of semantic information in populations of single neurons in the MTL.</p>
<p>Our study also contributes to the understanding of neuronal representations in the amygdala. We found a preference of amygdala units for stimuli depicting food items, which dovetails with findings of a potential role of the amygdala in modulating food consumption recently reported in rodents [<xref ref-type="bibr" rid="pbio.3000290.ref027">27</xref>] and with views of the role of the amygdala in processing positive and negative value as well as relevance of stimuli [<xref ref-type="bibr" rid="pbio.3000290.ref028">28</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref029">29</xref>]. However, human amygdala units have also been shown to preferably respond to animals [<xref ref-type="bibr" rid="pbio.3000290.ref017">17</xref>], to be involved in processing of faces and parts of faces [<xref ref-type="bibr" rid="pbio.3000290.ref030">30</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref031">31</xref>], and to encode the intensity of emotion in facial expressions [<xref ref-type="bibr" rid="pbio.3000290.ref032">32</xref>]. More generally, the amygdala has been hypothesised to be involved in social cognition [<xref ref-type="bibr" rid="pbio.3000290.ref031">31</xref>]. It is noteworthy that we do not see a preference for stimuli depicting animals in the amygdala as reported by Mormann and colleagues (2011) [<xref ref-type="bibr" rid="pbio.3000290.ref021">21</xref>]. Response probabilities of animal stimuli in our study are comparable to this study (approximately 1%). Mormann and colleagues (2011), however, compared animal stimuli to pictures of persons, landmarks, and objects, which all had significantly lower response probabilities (approximately 0.2%). Thus, we may not see a preference for animals because the categories to which we compare them (for example, food, plants, musical instruments, etc.) are different. It may help to reconcile this broad range of findings to consider that the amygdala is a complex and heterogeneous structure consisting of multiple nuclei involved in a wide range of different functions [<xref ref-type="bibr" rid="pbio.3000290.ref033">33</xref>] and that the exact location of microwires with respect to these nuclei cannot be determined with sufficient accuracy in human subjects.</p>
<p>Finally, our data connect to notions of hierarchical processing within the MTL. Strong tuning to highly abstract semantics has been found in the hippocampus and the amygdala. Both regions receive highly processed, supramodal input [<xref ref-type="bibr" rid="pbio.3000290.ref012">12</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref033">33</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref034">34</xref>]. The use of a highly abstract semantic code appears plausible to aid in attributing value and relevance of stimuli, a function hypothesised to occur in the amygdala [<xref ref-type="bibr" rid="pbio.3000290.ref028">28</xref>]. In the hippocampus, high levels of abstraction may facilitate efficient and sparse representations of large amounts of information encoded in neocortical firing patterns for subsequent encoding of episodic memories [<xref ref-type="bibr" rid="pbio.3000290.ref035">35</xref>–<xref ref-type="bibr" rid="pbio.3000290.ref037">37</xref>]. In contrast, abstract semantic representations were less pronounced in parahippocampal and entorhinal neurons. This finding connects with views that these structures are situated at a lower stage of the processing hierarchy within the MTL [<xref ref-type="bibr" rid="pbio.3000290.ref012">12</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref034">34</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref038">38</xref>]. Here, the parahippocampal cortex acts as an input region for higher MTL regions. Parahippocampal neurons fire earlier, less selectively than in other MTL regions [<xref ref-type="bibr" rid="pbio.3000290.ref012">12</xref>], and display a preference for images with spatial layout of visual input [<xref ref-type="bibr" rid="pbio.3000290.ref010">10</xref>]. Similarly, the entorhinal cortex relays reciprocal connections between hippocampus and neocortex [<xref ref-type="bibr" rid="pbio.3000290.ref034">34</xref>] and has also been found to be involved in spatial processing in humans [<xref ref-type="bibr" rid="pbio.3000290.ref039">39</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref040">40</xref>].</p>
</sec>
<sec id="sec004" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec005">
<title>Participants</title>
<p>A total of 25 epileptic patients (9 female) aged 19 to 62 y (M = 38, SD = 13) were implanted with depth electrodes for chronic seizure monitoring. Their average stay on the monitoring ward was 7 to 10 d.</p>
</sec>
<sec id="sec006">
<title>Ethics statement</title>
<p>The study was approved by the Medical Institutional Review Board of the University of Bonn (accession number 095/10 for single-unit recordings in humans in general and 245/11 for the current paradigm in particular) and adhered to the guidelines of the Declaration of Helsinki. Each patient gave informed written consent.</p>
</sec>
<sec id="sec007">
<title>Task and stimuli</title>
<p>One hundred images from 5 man-made and 5 natural categories of 10 exemplars each were selected as stimuli. The experiment was subdivided into 10 runs. One run entailed sequential presentation of all 100 images in the set in pseudorandom order. A trial entailed the presentation of a blank screen for a variable duration (200–400 ms) and a fixation dot for 300 ms, followed by the image that stayed on screen until the subject responded with a button press. Subjects were instructed to press the left or right arrow key if the image on the screen depicted a man-made or natural object, respectively.</p>
</sec>
<sec id="sec008">
<title>Electrophysiological recordings and spike sorting</title>
<p>Nine microwires (8 high-impedance recording electrodes, 1 low-impedance reference; AdTech, Racine, WI) protruding from the shaft of the depth electrodes were used to record signals from MTL neurons. Signals were amplified and recorded using a Neuralynx ATLAS system (Bozeman, MT). The sampling rate was 32 kHz, and signals were referenced against one of the low-impedance reference electrodes. Spike sorting was performed using wave_clus [<xref ref-type="bibr" rid="pbio.3000290.ref041">41</xref>] in 33 sessions and using Combinato (<ext-link ext-link-type="uri" xlink:href="https://github.com/jniediek/combinato" xlink:type="simple">https://github.com/jniediek/combinato</ext-link>) [<xref ref-type="bibr" rid="pbio.3000290.ref042">42</xref>] in 26 sessions. Different spike-sorting routines were used as the reported paradigm also served as a procedure to screen for response-eliciting stimuli in the morning of a day of testing. Therefore, manual optimisation of spike sorting was performed immediately after recording. The lab as a whole switched to using Combinato for reasons unrelated to the reported research.</p>
<p>A total of 5,033 units resulted from spike sorting, 4,917 of which were recorded in one of the anatomical regions considered (amygdala, hippocampus, entorhinal cortex, and parahippocampal cortex). The number of microwires per patient was on average 71.60 (SD = 21.32) and ranged from 32 to 96. On average, we recorded 1.38 units per microwire (SD = 0.44). These values ranged from 0.41 to 2.24 across all 59 sessions.</p>
</sec>
<sec id="sec009">
<title>Neuronal response test</title>
<p>To determine whether a unit responded with increased spiking activity to one of the stimuli in the set, we calculated a binwise rank-sum test described earlier [<xref ref-type="bibr" rid="pbio.3000290.ref012">12</xref>]. We obtained spike counts in 19 overlapping 100 ms bins ([0:100:1,000] and [50:100:950] ms after stimulus onset) for each trial in which a given image was presented. We computed 19 rank-sum tests, each of which compared the distribution of spike counts of one of the 19 bins against the distribution of spike counts in a baseline interval (−500 to 0 ms) of all trials in a session. The resulting 19 <italic>p</italic>-values were corrected for multiple comparisons using the Simes procedure. A stimulus was classified as eliciting a neuronal response in a unit when one or more of these 19 <italic>p</italic>-values was lower than <italic>α</italic> = 0.001. Furthermore, we considered only increases in firing rates. Also, neuronal responses were only considered as such if at least one spike in the response period was recorded in more than 5 out of the 10 trials per image and if the average firing rate during the response window (0 to 1,000 ms) was above 2 Hz.</p>
</sec>
<sec id="sec010">
<title>Calculation of response probabilities</title>
<p>We counted the neuronal responses across all sessions, separate for superordinate category and anatomical location. To make these values comparable across anatomical regions and with previous work [<xref ref-type="bibr" rid="pbio.3000290.ref017">17</xref>], we calculated response probabilities by normalising these counts to the number of units in an anatomical region and the total number of stimuli presented (100). Response probabilities were calculated for each of the four anatomical regions of interest. They thus represent the empirical probability that a unit in a given anatomical region will respond to a stimulus from a given semantic category.</p>
<p>We obtained measures of dispersion of these response probabilities by using a subsampling procedure. We drew 2,000 random subsamples of 700 units without replacement from each region and derived 95% confidence intervals from the resulting distributions of response probabilities for each category of stimuli.</p>
<p>A Fisher’s exact test on the response probabilities was conducted for each category and each anatomical region. To this aim, data were arranged in a 2 × 2 contingency table of the frequencies of significant and nonsignificant neuronal responses in a superordinate category of interest, and the frequency of significant and nonsignificant neuronal responses in all other superordinate categories.</p>
</sec>
<sec id="sec011">
<title>Representational dissimilarity analyses</title>
<p>To assess the dissimilarity between neuronal representations of stimulus categories, firing rates during the response period (0 to 1,000 ms after stimulus onset) of each stimulus were expressed as <italic>Z</italic> scores using the mean and standard deviation of firing rates in a base line interval ranging from −500 ms to stimulus onset (0) across all trials. These <italic>Z</italic> scores were arranged in a matrix of <italic>N</italic><sub><italic>S</italic></sub> × <italic>N</italic><sub><italic>U</italic></sub>, where <italic>N</italic><sub><italic>U</italic></sub> is the number of units recorded and N<sub>S</sub> the number of stimuli in the set (100). Representational dissimilarity between a pair of stimuli was calculated using 1 –Pearson’s correlation coefficient (1 − <italic>R</italic>) of the vectors of <italic>Z</italic> scores corresponding to the population activity evoked by the two stimuli in a pair [<xref ref-type="bibr" rid="pbio.3000290.ref009">9</xref>,<xref ref-type="bibr" rid="pbio.3000290.ref017">17</xref>]. To assess representational dissimilarity on the level of individual trials, we computed <italic>Z</italic> scores for each trial in the experiment. These <italic>Z</italic> scores were arranged in a matrix of <italic>N</italic><sub><italic>T</italic></sub> × <italic>N</italic><sub><italic>U</italic></sub>, where <italic>N</italic><sub><italic>U</italic></sub> is the number of units recorded and <italic>N</italic><sub><italic>T</italic></sub> the number of trials during the paradigm (1,000).</p>
<p>Hierarchical clustering for dendrograms in <xref ref-type="fig" rid="pbio.3000290.g003">Fig 3</xref> was performed using unweighted average distance method on correlation distances.</p>
</sec>
<sec id="sec012">
<title>Decoding of stimulus identity and category</title>
<p>We used the matrices of <italic>Z</italic> scores described above (<italic>N</italic><sub><italic>T</italic></sub> × <italic>N</italic><sub><italic>U</italic></sub>) to assess pattern classification performance. We used the function <monospace>fitcecoc.m</monospace> from MATLAB’s (MathWorks; <ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com" xlink:type="simple">www.mathworks.com</ext-link>) statistics and machine-learning toolbox. This function was used to train a multiclass, error-correcting output codes model of linear support vector machines for binary choices. Binary support vector machines were specified according to a ‘one versus all’ coding scheme in which for each binary classifier, one class is positive and the rest are negative. The classifier was trained to predict the label of stimulus identity from individual trials (<italic>N</italic><sub><italic>T</italic></sub> × <italic>N</italic><sub><italic>U</italic></sub>). Out-of-sample performance was assessed for 100 pseudorandom divisions of the data into training and test set (50% holdout for test). To test for semantic generalisation to ‘unseen’ members of category, further classifiers were trained on the mean responses (<italic>N</italic><sub><italic>S</italic></sub> × <italic>N</italic><sub><italic>U</italic></sub>) of half of the stimuli to learn category labels and tested on the other half of stimuli. Again, out-of-sample performance was assessed for 100 pseudorandom divisions of the data into training and test set. Classification performance was quantified by <inline-formula id="pbio.3000290.e002"><alternatives><graphic id="pbio.3000290.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.3000290.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>′</mml:mo><mml:mi mathvariant="normal">s</mml:mi><mml:mspace width="0.25em"/><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>, where P<sub>O</sub> is the observed agreement and P<sub>C</sub> is chance agreement. <xref ref-type="supplementary-material" rid="pbio.3000290.s004">S4 Fig</xref> and <xref ref-type="supplementary-material" rid="pbio.3000290.s005">S5 Fig</xref> show these same analyses repeated separately for each subject but collapsing across regions.</p>
</sec>
<sec id="sec013">
<title>Inference statistics on representational dissimilarity and confusion matrices</title>
<p>To assess whether dissimilarity (1 − R) was significantly different within versus across exemplars of superordinate categories, we implemented a label-shuffling procedure. To this aim, we arranged dissimilarity between all pairs of stimuli in matrices of the format <italic>N</italic><sub><italic>S</italic></sub> × <italic>N</italic><sub><italic>U</italic></sub>. Next, we selected a set of indices to the elements in these matrices that correspond to within-category dissimilarity. Another set of indices was selected corresponding to between-category dissimilarity. We then computed a Mann-Whitney U test with the hypothesis that within-category dissimilarity is lower than between-category dissimilarity. From this test we obtained a test statistic (rank-sum) of the original assignments of the labels (within- versus between-category dissimilarity) to the data. We repeated this test 10<sup>5</sup> times with randomly shuffled assignments of labels to the data, that is, indices to the matrix corresponding to within- versus between-category pairs were randomised and hence mostly false. Of these 10<sup>5</sup> tests with random labels, we saved the distribution of resulting test statistics (rank-sums). The reported <italic>p</italic>-values reflect the percentile of the test statistic that got the correct assignments of labels to the data within the distribution of test statistics derived with randomly relabelled data. The same procedure was carried out for the confusion matrices derived from pattern classification. Note that dissimilarity matrices were symmetric, whereas confusion matrices were not. We therefore computed statistics for dissimilarity on the triangular matrices only.</p>
</sec>
<sec id="sec014">
<title>Analyses and stimulus-delivery software</title>
<p>We used MATLAB and its statistics and machine-learning toolbox in combination with custom code for analyses of the data. Spike sorting of 33 sessions was done using wave_clus (<ext-link ext-link-type="uri" xlink:href="http://https://github.com/csn-le/wave_clus" xlink:type="simple">https://github.com/csn-le/wave_clus</ext-link>) [<xref ref-type="bibr" rid="pbio.3000290.ref041">41</xref>]. The remaining 26 sessions were sorted using Combinato [<xref ref-type="bibr" rid="pbio.3000290.ref042">42</xref>] requiring Python (<ext-link ext-link-type="uri" xlink:href="http://www.python.org" xlink:type="simple">www.python.org</ext-link>). We used the psychtoolbox3 (<ext-link ext-link-type="uri" xlink:href="http://www.psythoolbox.org" xlink:type="simple">www.psythoolbox.org</ext-link>) and octave (<ext-link ext-link-type="uri" xlink:href="http://www.gnu.org/octave" xlink:type="simple">www.gnu.org/octave</ext-link>) running on a Debian 8 operating system (<ext-link ext-link-type="uri" xlink:href="http://www.debian.org" xlink:type="simple">www.debian.org</ext-link>) on a standard laptop computer for stimulus delivery. All relevant data and custom code are available on <ext-link ext-link-type="uri" xlink:href="https://github.com/rebrowski/abstractRepresentationsInMTL.git" xlink:type="simple">https://github.com/rebrowski/abstractRepresentationsInMTL.git</ext-link>.</p>
</sec>
</sec>
<sec id="sec015">
<title>Supporting information</title>
<supplementary-material id="pbio.3000290.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.3000290.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Representational similarity of only nonresponding units shows similar patterns as for all units (cf. <xref ref-type="fig" rid="pbio.3000290.g002">Fig 2</xref>).</title>
<p>(A–D) Representational dissimilarity matrices showing the distance between two stimuli quantified as 1 − Pearson’s correlation coefficient (<italic>R</italic>) for the response activity of all recorded units. (E–H) Exemplars in two-dimensional space derived from multidimensional scaling of dissimilarity. (I–M) Dendrograms generated from automated hierarchical clustering. Data and scripts underlying this figure are deposited here: <ext-link ext-link-type="uri" xlink:href="https://github.com/rebrowski/abstractRepresentationsInMTL" xlink:type="simple">https://github.com/rebrowski/abstractRepresentationsInMTL</ext-link>.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.3000290.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.3000290.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Measures of picture similarity were computed for each pair of images and subjected to the same analyses as neuronal similarity (<xref ref-type="fig" rid="pbio.3000290.g003">Fig 3</xref>).</title>
<p>Picture similarities were calculated using the Euclidean distance (A, E, I), the mean squared error (B, F, K), the structural similarity index (ssi) (note that we display the ssi subtracted from the maximal ssi to achieve a measure of distance), and the peak signal-to-noise ratio (psnr) (again, we display max(pnsr) − pnsr to obtain distance rather than similarity). Data and scripts underlying this figure are deposited here: <ext-link ext-link-type="uri" xlink:href="https://github.com/rebrowski/abstractRepresentationsInMTL" xlink:type="simple">https://github.com/rebrowski/abstractRepresentationsInMTL</ext-link>. pnsr, peak signal-to-noise ratio; ssi, structural similarity index.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.3000290.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.3000290.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Dendrograms resulting from automated hierarchical clustering of representational dissimilarity (same as <xref ref-type="fig" rid="pbio.3000290.g002">Fig 2I–2M</xref>).</title>
<p>Data and scripts underlying this figure are deposited here: <ext-link ext-link-type="uri" xlink:href="https://github.com/rebrowski/abstractRepresentationsInMTL" xlink:type="simple">https://github.com/rebrowski/abstractRepresentationsInMTL</ext-link>. AM, amygdala; EC, entorhinal cortex; HC, hippocampus; PHC, parahippocampal cortex.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.3000290.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.3000290.s004" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Semantic generalisation decoding, separately for each subject.</title>
<p>Analog to <xref ref-type="fig" rid="pbio.3000290.g004">Fig 4</xref>. Depicted are confusion matrices of decoding analyses based on data of each individual subject, collapsed across anatomical regions and sessions (see Decoding of stimulus identity and category section in Materials and methods). Decoders were trained to predict the category label of stimuli, trained on data of half of the stimuli in each category. Out-of-sample accuracies in 100 random subdivisions of data into training and test sets for each of the 25 subjects are depicted in the box plots beneath the confusion matrices. Note that boxes of decoding accuracies are above chance level (dotted line, 10%) in all subjects. Successful out-of-sample decoding on new exemplars of the category indicates an abstract semantic code implemented in the neuronal firing of MTL regions. Data and scripts underlying this figure are deposited here: <ext-link ext-link-type="uri" xlink:href="https://github.com/rebrowski/abstractRepresentationsInMTL" xlink:type="simple">https://github.com/rebrowski/abstractRepresentationsInMTL</ext-link>. MTL, medial temporal lobe.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.3000290.s005" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.3000290.s005" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Decoding of stimulus identity from trials per subject.</title>
<p>Analog to <xref ref-type="fig" rid="pbio.3000290.g004">Fig 4</xref>. Depicted are confusion matrices of decoding analyses based on data of each individual subject, collapsed across anatomical regions and sessions (see Decoding of stimulus identity and category section in Materials and methods). Decoders were trained to predict the label of stimuli and trained on data of half of the trials per stimulus. Out-of-sample accuracies in 100 random subdivisions of data into training and test sets for each subject are depicted in the box plots beneath the confusion matrices. Note that boxes of decoding accuracies are above chance (dotted line, 1%) in all subjects and that confusions between stimuli occur more often within rather than across category. Data and scripts underlying this figure are deposited here: <ext-link ext-link-type="uri" xlink:href="https://github.com/rebrowski/abstractRepresentationsInMTL" xlink:type="simple">https://github.com/rebrowski/abstractRepresentationsInMTL</ext-link>.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank K. Hyun Tae and A. Maharjan for help with spike sorting and J. Macke and B. Staresina for comments on the manuscript. We thank all patients for their participation.</p>
</ack>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>MTL</term>
<def><p>medial temporal lobe</p></def>
</def-item>
<def-item><term>RSA</term>
<def><p>representational similarity analysis</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.3000290.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Patterson</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Nestor</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Rogers</surname> <given-names>TT</given-names></name>. <article-title>Where do you know what you know? The representation of semantic knowledge in the human brain</article-title>. <source>Nat Rev Neurosci</source>. <year>2007</year>;<volume>8</volume>: <fpage>976</fpage>–<lpage>987</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn2277" xlink:type="simple">10.1038/nrn2277</ext-link></comment> <object-id pub-id-type="pmid">18026167</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref002"><label>2</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Yee</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Jones</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>McRae</surname> <given-names>K</given-names></name>. <chapter-title>Semantic Memory</chapter-title>. In: <name name-style="western"><surname>Wixted</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Thompson-Schill</surname> <given-names>SL</given-names></name>, editors. <source>The Stevens’ Handbook of Experimental Psychology and Cognitive Neuroscience</source>. <edition>4th ed.</edition> <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>2017</year>.</mixed-citation></ref>
<ref id="pbio.3000290.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kumaran</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>McClelland</surname> <given-names>JL</given-names></name>. <article-title>Generalization through the recurrent interaction of episodic memories: A model of the hippocampal system</article-title>. <source>Psychol Rev</source>. <year>2012</year>;<volume>119</volume>: <fpage>573</fpage>–<lpage>616</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0028681" xlink:type="simple">10.1037/a0028681</ext-link></comment> <object-id pub-id-type="pmid">22775499</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tenenbaum</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Kemp</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Griffiths</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Goodman</surname> <given-names>ND</given-names></name>. <article-title>How to Grow a Mind: Statistics, Structure, and Abstraction</article-title>. <source>Science</source>. <year>2011</year>;<volume>331</volume>: <fpage>1279</fpage>–<lpage>1285</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1192788" xlink:type="simple">10.1126/science.1192788</ext-link></comment> <object-id pub-id-type="pmid">21393536</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huth</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>de Heer</surname> <given-names>WA</given-names></name>, <name name-style="western"><surname>Griffiths</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name>. <article-title>Natural speech reveals the semantic maps that tile human cerebral cortex</article-title>. <source>Nature</source>. <year>2016</year>;<volume>532</volume>: <fpage>453</fpage>–<lpage>458</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature17637" xlink:type="simple">10.1038/nature17637</ext-link></comment> <object-id pub-id-type="pmid">27121839</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kornblith</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tsao</surname> <given-names>DY</given-names></name>. <article-title>How thoughts arise from sights: inferotemporal and prefrontal contributions to vision</article-title>. <source>Curr Opin Neurobiol</source>. <year>2017</year>;<volume>46</volume>: <fpage>208</fpage>–<lpage>218</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2017.08.016" xlink:type="simple">10.1016/j.conb.2017.08.016</ext-link></comment> <object-id pub-id-type="pmid">28942219</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Tsao</surname> <given-names>DY</given-names></name>. <article-title>The Code for Facial Identity in the Primate Brain</article-title>. <source>Cell</source>. <year>2017</year>;<volume>169</volume>: <fpage>1013</fpage>–<lpage>1028</lpage>.e14. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cell.2017.05.011" xlink:type="simple">10.1016/j.cell.2017.05.011</ext-link></comment> <object-id pub-id-type="pmid">28575666</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huth</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Nishimoto</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Vu</surname> <given-names>AT</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name>. <article-title>A Continuous Semantic Space Describes the Representation of Thousands of Object and Action Categories across the Human Brain</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>76</volume>: <fpage>1210</fpage>–<lpage>1224</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2012.10.014" xlink:type="simple">10.1016/j.neuron.2012.10.014</ext-link></comment> <object-id pub-id-type="pmid">23259955</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kriegeskorte</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Mur</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ruff</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bodurka</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Esteky</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Matching Categorical Object Representations in Inferior Temporal Cortex of Man and Monkey</article-title>. <source>Neuron</source>. <year>2008</year>;<volume>60</volume>: <fpage>1126</fpage>–<lpage>1141</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2008.10.043" xlink:type="simple">10.1016/j.neuron.2008.10.043</ext-link></comment> <object-id pub-id-type="pmid">19109916</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mormann</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Kornblith</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Cerf</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ison</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Kraskov</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Tran</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Scene-selective coding by single neurons in the human parahippocampal cortex</article-title>. <source>Proc Natl Acad Sci</source>. <year>2017</year>;<volume>114</volume>: <fpage>1153</fpage>–<lpage>1158</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1608159113" xlink:type="simple">10.1073/pnas.1608159113</ext-link></comment> <object-id pub-id-type="pmid">28096381</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Falco</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Ison</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Quian Quiroga</surname> <given-names>R</given-names></name>. <article-title>Long-term coding of personal and universal associations underlying the memory web in the human brain</article-title>. <source>Nat Commun</source>. <year>2016</year>;<volume>7</volume>: <fpage>13408</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ncomms13408" xlink:type="simple">10.1038/ncomms13408</ext-link></comment> <object-id pub-id-type="pmid">27845773</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mormann</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Kornblith</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Quian Quiroga</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kraskov</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Cerf</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name>, <etal>et al</etal>. <article-title>Latency and selectivity of single neurons indicate hierarchical processing in the human medial temporal lobe</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>: <fpage>8865</fpage>–<lpage>8872</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1640-08.2008" xlink:type="simple">10.1523/JNEUROSCI.1640-08.2008</ext-link></comment> <object-id pub-id-type="pmid">18768680</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Quian Quiroga</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Reddy</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Kreiman</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name>. <article-title>Invariant visual representation by single neurons in the human brain</article-title>. <source>Nature</source>. <year>2005</year>;<volume>435</volume>: <fpage>1102</fpage>–<lpage>1107</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature03687" xlink:type="simple">10.1038/nature03687</ext-link></comment> <object-id pub-id-type="pmid">15973409</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Quian Quiroga</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kraskov</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name>. <article-title>Explicit Encoding of Multimodal Percepts by Single Neurons in the Human Brain</article-title>. <source>Curr Biol</source>. <year>2009</year>;<volume>19</volume>: <fpage>1308</fpage>–<lpage>1313</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2009.06.060" xlink:type="simple">10.1016/j.cub.2009.06.060</ext-link></comment> <object-id pub-id-type="pmid">19631538</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Valdez</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Papesh</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Treiman</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Goldinger</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Steinmetz</surname> <given-names>PN</given-names></name>. <article-title>Distributed Representation of Visual Objects by Single Neurons in the Human Brain</article-title>. <source>J Neurosci</source>. <year>2015</year>;<volume>35</volume>: <fpage>5180</fpage>–<lpage>5186</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1958-14.2015" xlink:type="simple">10.1523/JNEUROSCI.1958-14.2015</ext-link></comment> <object-id pub-id-type="pmid">25834044</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kreiman</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name>. <article-title>Category-specific visual responses of single neurons in the human medial temporal lobe</article-title>. <source>Nat Neurosci</source>. <year>2000</year>;<volume>3</volume>: <fpage>946</fpage>–<lpage>953</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/78868" xlink:type="simple">10.1038/78868</ext-link></comment> <object-id pub-id-type="pmid">10966627</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mormann</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Dubois</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kornblith</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Milosavljevic</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Cerf</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ison</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>A category-specific response to animals in the right human amygdala</article-title>. <source>Nat Neurosci</source>. <year>2011</year>;<volume>14</volume>: <fpage>1247</fpage>–<lpage>1249</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2899" xlink:type="simple">10.1038/nn.2899</ext-link></comment> <object-id pub-id-type="pmid">21874014</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mormann</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Niediek</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Tudusciuc</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Quesada</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Coenen</surname> <given-names>VA</given-names></name>, <name name-style="western"><surname>Elger</surname> <given-names>CE</given-names></name>, <etal>et al</etal>. <article-title>Neurons in the human amygdala encode face identity, but not gaze direction</article-title>. <source>Nat Neurosci</source>. <year>2015</year>;<volume>18</volume>: <fpage>1568</fpage>–<lpage>1570</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4139" xlink:type="simple">10.1038/nn.4139</ext-link></comment> <object-id pub-id-type="pmid">26479589</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kraskov</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Quiroga</surname> <given-names>RQ</given-names></name>, <name name-style="western"><surname>Reddy</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>. <article-title>Local Field Potentials and Spikes in the Human Medial Temporal Lobe are Selective to Image Category</article-title>. <source>J Cogn Neurosci</source>. <year>2007</year>;<volume>19</volume>: <fpage>479</fpage>–<lpage>492</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn.2007.19.3.479" xlink:type="simple">10.1162/jocn.2007.19.3.479</ext-link></comment> <object-id pub-id-type="pmid">17335396</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Waydo</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kraskov</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Quiroga</surname> <given-names>RQ</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>. <article-title>Sparse Representation in the Human Medial Temporal Lobe</article-title>. <source>J Neurosci</source>. <year>2006</year>;<volume>26</volume>: <fpage>10232</fpage>–<lpage>10234</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2101-06.2006" xlink:type="simple">10.1523/JNEUROSCI.2101-06.2006</ext-link></comment> <object-id pub-id-type="pmid">17021178</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Quian Quiroga</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kreiman</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name>. <article-title>Sparse but not ‘Grandmother-cell’ coding in the medial temporal lobe</article-title>. <source>Trends Cogn Sci</source>. <year>2008</year>;<volume>12</volume>: <fpage>87</fpage>–<lpage>91</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2007.12.003" xlink:type="simple">10.1016/j.tics.2007.12.003</ext-link></comment> <object-id pub-id-type="pmid">18262826</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Roediger</surname> <given-names>HL</given-names></name>, <name name-style="western"><surname>McDermott</surname> <given-names>KB</given-names></name>. <article-title>Creating false memories: Remembering words not presented in lists</article-title>. <source>J Exp Psychol Learn Mem Cogn</source>. <year>1995</year>;<volume>21</volume>: <fpage>803</fpage>–<lpage>814</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0278-7393.21.4.803" xlink:type="simple">10.1037/0278-7393.21.4.803</ext-link></comment></mixed-citation></ref>
<ref id="pbio.3000290.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Montefinese</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Zannino</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Ambrosini</surname> <given-names>E</given-names></name>. <article-title>Semantic similarity between old and new items produces false alarms in recognition memory</article-title>. <source>Psychol Res</source>. <year>2015</year>;<volume>79</volume>: <fpage>785</fpage>–<lpage>794</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00426-014-0615-z" xlink:type="simple">10.1007/s00426-014-0615-z</ext-link></comment> <object-id pub-id-type="pmid">25267547</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chadwick</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Anjum</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Kumaran</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Schacter</surname> <given-names>DL</given-names></name>, <name name-style="western"><surname>Spiers</surname> <given-names>HJ</given-names></name>, <name name-style="western"><surname>Hassabis</surname> <given-names>D</given-names></name>. <article-title>Semantic representations in the temporal pole predict false memories</article-title>. <source>Proc Natl Acad Sci</source>. <year>2016</year>;<volume>113</volume>: <fpage>10180</fpage>–<lpage>10185</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1610686113" xlink:type="simple">10.1073/pnas.1610686113</ext-link></comment> <object-id pub-id-type="pmid">27551087</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ramirez</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Lin</surname> <given-names>P-A</given-names></name>, <name name-style="western"><surname>Suh</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Pignatelli</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Redondo</surname> <given-names>RL</given-names></name>, <etal>et al</etal>. <article-title>Creating a False Memory in the Hippocampus</article-title>. <source>Science</source>. <year>2013</year>;<volume>341</volume>: <fpage>387</fpage>–<lpage>391</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1239073" xlink:type="simple">10.1126/science.1239073</ext-link></comment> <object-id pub-id-type="pmid">23888038</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cabeza</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Rao</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Mayer</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Schacter</surname> <given-names>DL</given-names></name>. <article-title>Can medial temporal lobe regions distinguish true from false? An event-related functional MRI study of veridical and illusory recognition memory</article-title>. <source>Proc Natl Acad Sci</source>. <year>2001</year>;<volume>98</volume>: <fpage>4805</fpage>–<lpage>4810</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.081082698" xlink:type="simple">10.1073/pnas.081082698</ext-link></comment> <object-id pub-id-type="pmid">11287664</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Douglass</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Kucukdereli</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Ponserre</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Markovic</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gründemann</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Strobel</surname> <given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Central amygdala circuits modulate food consumption through a positive-valence mechanism</article-title>. <source>Nat Neurosci</source>. <year>2017</year>;advance online publication. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4623" xlink:type="simple">10.1038/nn.4623</ext-link></comment> <object-id pub-id-type="pmid">28825719</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Murray</surname> <given-names>EA</given-names></name>. <article-title>The amygdala, reward and emotion</article-title>. <source>Trends Cogn Sci</source>. <year>2007</year>;<volume>11</volume>: <fpage>489</fpage>–<lpage>497</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2007.08.013" xlink:type="simple">10.1016/j.tics.2007.08.013</ext-link></comment> <object-id pub-id-type="pmid">17988930</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mormann</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Bausch</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Knieling</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name>. <article-title>Neurons in the Human Left Amygdala Automatically Encode Subjective Value Irrespective of Task</article-title>. <source>Cereb Cortex</source>. <year>2017</year>; <fpage>1</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhw362" xlink:type="simple">10.1093/cercor/bhw362</ext-link></comment></mixed-citation></ref>
<ref id="pbio.3000290.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rutishauser</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Tudusciuc</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Mamelak</surname> <given-names>AN</given-names></name>, <name name-style="western"><surname>Ross</surname> <given-names>IB</given-names></name>, <name name-style="western"><surname>Adolphs</surname> <given-names>R</given-names></name>. <article-title>Single-Neuron Correlates of Atypical Face Processing in Autism</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>80</volume>: <fpage>887</fpage>–<lpage>899</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.08.029" xlink:type="simple">10.1016/j.neuron.2013.08.029</ext-link></comment> <object-id pub-id-type="pmid">24267649</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rutishauser</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Mamelak</surname> <given-names>AN</given-names></name>, <name name-style="western"><surname>Adolphs</surname> <given-names>R</given-names></name>. <article-title>The primate amygdala in social perception–insights from electrophysiological recordings and stimulation</article-title>. <source>Trends Neurosci</source>. <year>2015</year>;<volume>38</volume>: <fpage>295</fpage>–<lpage>306</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2015.03.001" xlink:type="simple">10.1016/j.tins.2015.03.001</ext-link></comment> <object-id pub-id-type="pmid">25847686</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tudusciuc</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Mamelak</surname> <given-names>AN</given-names></name>, <name name-style="western"><surname>Ross</surname> <given-names>IB</given-names></name>, <name name-style="western"><surname>Adolphs</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Rutishauser</surname> <given-names>U</given-names></name>. <article-title>Neurons in the human amygdala selective for perceived emotion</article-title>. <source>Proc Natl Acad Sci</source>. <year>2014</year>;<volume>111</volume>: <fpage>E3110</fpage>–<lpage>E3119</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1323342111" xlink:type="simple">10.1073/pnas.1323342111</ext-link></comment> <object-id pub-id-type="pmid">24982200</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>LeDoux</surname> <given-names>J.</given-names></name> <article-title>The amygdala</article-title>. <source>Curr Biol CB</source>. <year>2007</year>;<volume>17</volume>: <fpage>R868</fpage>–<lpage>874</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2007.08.005" xlink:type="simple">10.1016/j.cub.2007.08.005</ext-link></comment> <object-id pub-id-type="pmid">17956742</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lavenex</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Amaral</surname> <given-names>DG</given-names></name>. <article-title>Hippocampal-neocortical interaction: A hierarchy of associativity</article-title>. <source>Hippocampus</source>. <year>2000</year>;<volume>10</volume>: <fpage>420</fpage>–<lpage>430</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/1098-1063(2000)10:4&lt;420::AID-HIPO8&gt;3.0.CO;2-5" xlink:type="simple">10.1002/1098-1063(2000)10:4&lt;420::AID-HIPO8&gt;3.0.CO;2-5</ext-link></comment> <object-id pub-id-type="pmid">10985281</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McClelland</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>McNaughton</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>O’Reilly</surname> <given-names>RC</given-names></name>. <article-title>Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title>. <source>Psychol Rev</source>. <year>1995</year>;<volume>102</volume>: <fpage>419</fpage>–<lpage>457</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.102.3.419" xlink:type="simple">10.1037/0033-295X.102.3.419</ext-link></comment> <object-id pub-id-type="pmid">7624455</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Teyler</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Rudy</surname> <given-names>JW</given-names></name>. <article-title>The hippocampal indexing theory and episodic memory: Updating the index</article-title>. <source>Hippocampus</source>. <year>2007</year>;<volume>17</volume>: <fpage>1158</fpage>–<lpage>1169</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hipo.20350" xlink:type="simple">10.1002/hipo.20350</ext-link></comment> <object-id pub-id-type="pmid">17696170</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rolls</surname> <given-names>ET</given-names></name>. <article-title>Computational analysis of the role of the hippocampus in memory</article-title>. <source>Hippocampus</source>. <year>1994</year>;<volume>4</volume>: <fpage>374</fpage>–<lpage>391</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hipo.450040319" xlink:type="simple">10.1002/hipo.450040319</ext-link></comment> <object-id pub-id-type="pmid">7842058</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reber</surname> <given-names>TP</given-names></name>, <name name-style="western"><surname>Faber</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Niediek</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Boström</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Elger</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Mormann</surname> <given-names>F</given-names></name>. <article-title>Single-neuron correlates of conscious perception in the human medial temporal lobe</article-title>. <source>Curr Biol</source>. <year>2017</year>;<volume>27</volume>: <fpage>2991</fpage>–<lpage>2998</lpage>.e2. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2017.08.025" xlink:type="simple">10.1016/j.cub.2017.08.025</ext-link></comment> <object-id pub-id-type="pmid">28943091</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jacobs</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Weidemann</surname> <given-names>CT</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Solway</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Burke</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>X-X</given-names></name>, <etal>et al</etal>. <article-title>Direct recordings of grid-like neuronal activity in human spatial navigation</article-title>. <source>Nat Neurosci</source>. <year>2013</year>;<volume>16</volume>: <fpage>1188</fpage>–<lpage>1190</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3466" xlink:type="simple">10.1038/nn.3466</ext-link></comment> <object-id pub-id-type="pmid">23912946</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Watrous</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Qasim</surname> <given-names>SE</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Jacobs</surname> <given-names>J</given-names></name>. <article-title>Phase-tuned neuronal firing encodes human contextual representations for navigational goals</article-title>. <source>eLife</source>. <year>2018</year>;<volume>7</volume>: <fpage>e32554</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.32554" xlink:type="simple">10.7554/eLife.32554</ext-link></comment> <object-id pub-id-type="pmid">29932417</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Quian Quiroga</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Nadasdy</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Ben-Shaul</surname> <given-names>Y</given-names></name>. <article-title>Unsupervised spike detection and sorting with wavelets and superparamagnetic clustering</article-title>. <source>Neural Comput</source>. <year>2004</year>;<volume>16</volume>: <fpage>1661</fpage>–<lpage>1687</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089976604774201631" xlink:type="simple">10.1162/089976604774201631</ext-link></comment> <object-id pub-id-type="pmid">15228749</object-id></mixed-citation></ref>
<ref id="pbio.3000290.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niediek</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Boström</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Elger</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Mormann</surname> <given-names>F</given-names></name>. <article-title>Reliable Analysis of Single-Unit Recordings from the Human Brain under Noisy Conditions: Tracking Neurons over Hours</article-title>. <source>PLoS ONE</source>. <year>2016</year>;<volume>11</volume>: <fpage>e0166598</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0166598" xlink:type="simple">10.1371/journal.pone.0166598</ext-link></comment> <object-id pub-id-type="pmid">27930664</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
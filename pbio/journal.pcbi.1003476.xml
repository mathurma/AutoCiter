<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-13-01315</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003476</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject><subject>Sensory systems</subject></subj-group></subj-group><subj-group><subject>Neurophysiology</subject><subj-group><subject>Central nervous system</subject></subj-group></subj-group><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject></subj-group></subj-group><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Social and behavioral sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>A Unified Model of Heading and Path Perception in Primate MSTd</article-title>
<alt-title alt-title-type="running-head">Model of Heading and Path in Primate MSTd</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Layton</surname><given-names>Oliver W.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Browning</surname><given-names>N. Andrew</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Center for Computational Neuroscience and Neural Technology, Boston University, Boston, Massachusetts, United States of America</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Scientific Systems Company Inc. (SSCI), Woburn, Massachusetts, United Sates of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Einhäuser</surname><given-names>Wolfgang</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Philipps-University Marburg, Germany</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">owl@bu.edu</email></corresp>
<fn fn-type="conflict"><p>Dr. Browning is now a paid employee of Scientific Systems Company Inc. (SSCI). Dr. Browning was employed by Boston University while the research for the present work was conducted.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: OWL. Performed the experiments: OWL. Analyzed the data: OWL NAB. Wrote the paper: OWL NAB.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>2</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>20</day><month>2</month><year>2014</year></pub-date>
<volume>10</volume>
<issue>2</issue>
<elocation-id>e1003476</elocation-id>
<history>
<date date-type="received"><day>23</day><month>7</month><year>2013</year></date>
<date date-type="accepted"><day>3</day><month>1</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Layton, Browning</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Self-motion, steering, and obstacle avoidance during navigation in the real world require humans to travel along curved paths. Many perceptual models have been proposed that focus on heading, which specifies the direction of travel along straight paths, but not on path curvature, which humans accurately perceive and is critical to everyday locomotion. In primates, including humans, dorsal medial superior temporal area (MSTd) has been implicated in heading perception. However, the majority of MSTd neurons respond optimally to spiral patterns, rather than to the radial expansion patterns associated with heading. No existing theory of curved path perception explains the neural mechanisms by which humans accurately assess path and no functional role for spiral-tuned cells has yet been proposed. Here we present a computational model that demonstrates how the continuum of observed cells (radial to circular) in MSTd can simultaneously code curvature and heading across the neural population. Curvature is encoded through the spirality of the most active cell, and heading is encoded through the visuotopic location of the center of the most active cell's receptive field. Model curvature and heading errors fit those made by humans. Our model challenges the view that the function of MSTd is heading estimation, based on our analysis we claim that it is primarily concerned with trajectory estimation and the simultaneous representation of both curvature and heading. In our model, temporal dynamics afford time-history in the neural representation of optic flow, which may modulate its structure. This has far-reaching implications for the interpretation of studies that assume that optic flow is, and should be, represented as an instantaneous vector field. Our results suggest that spiral motion patterns that emerge in spatio-temporal optic flow are essential for guiding self-motion along complex trajectories, and that cells in MSTd are specifically tuned to extract complex trajectory estimation from flow.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>Much human and primate psychological and electrophysiological research on visually-guided navigation has focused on heading perception, defined as the instantaneous direction of travel. However, the perception of path of travel, or trajectory, is arguably more important, because it informs in a more general sense whether the observer is on a collision course with moving objects or will intercept a target. In the present article, we describe a theory based on physiological evidence of how primate visual area MSTd may simultaneously and dynamically encode heading and path. The model connects many different sources of data, including psychophysics on human perception of heading and path with and without eye movements, and primate electrophysiological data on path-selective cells in MSTd. We propose neural mechanisms explaining why humans report traveling along curved paths when the display represents a straight path with simulated eye rotations. We predict that perceptual sensitivity to heading and path emerges in primate MSTd through the dynamical and competitive interactions between neurons tuned to the continuum of spiral-radial patterns.</p>
</abstract>
<funding-group><funding-statement>Supported in part by the Office of Naval Research (ONR) (N00014-11-1-0535). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="20"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Gibson noted that animals can navigate about their environment using the changing pattern of light distributions falling on the retina, which is now known as <italic>optic flow</italic> <xref ref-type="bibr" rid="pcbi.1003476-Gibson1">[1]</xref>. Travel parallel to a ground surface, along a straight path, without eye movements or body rotations produces characteristic patterns of optic flow, which Gibson called a “melon-shaped family of curves” (<xref ref-type="fig" rid="pcbi-1003476-g001">Figure 1a</xref>). These flow patterns contain a singularity known as the <italic>focus of expansion (FoE)</italic>. When the path of travel is straight, the optic flow field expands radially and the FoE specifies the direction in which the animal is going (heading). Gibson observed that animals could navigate using optic flow by aligning the FoE with the direction in which the animal wishes to travel.</p>
<fig id="pcbi-1003476-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g001</object-id><label>Figure 1</label><caption>
<title>Exemplar first-order optic flow fields.</title>
<p>(a) Radially expanding optic flow experienced by an observer traveling along a straight path on a ground plane. The optic flow contains the focus of expansion (FoE) singularity on the horizon, which indicates the heading direction. (b) Movement of an observer along a straight path, as in (a), but with a constant amount of rotation added to the first-order optic flow (simulated rotation condition). Human subjects that view displays with simulated rotation report traveling along a circular path. (c) First-order optic flow experienced by an observer traveling on a circular path whose gaze is along heading or tangent to the circular path.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g001" position="float" xlink:type="simple"/></fig>
<p>Since Gibson proposed this strategy for navigation, much psychophysical research has focused on understanding human perception of heading <xref ref-type="bibr" rid="pcbi.1003476-Warren1">[2]</xref>. For the remainder of this article, we define <italic>heading</italic> to refer to the instantaneous direction of travel of an observer, and we define <italic>curvilinear path</italic> as the trajectory of travel, which may be curved. Psychophysical studies of human heading judgments have largely been based on static environments, consisting of dot or textured ground planes or 3D dot clouds. The observer typically travels along a straight path. In such environments, humans accurately judge their heading, within <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e001" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003476-Warren2">[3]</xref>–<xref ref-type="bibr" rid="pcbi.1003476-vandenBerg2">[5]</xref>. Biologically inspired models of human heading perception often make use of depth variations in the visual scene (motion parallax) <xref ref-type="bibr" rid="pcbi.1003476-Rieger1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Hildreth1">[7]</xref> to estimate the observer's heading given a two dimensional (2D) retinal velocity field. Template matching <xref ref-type="bibr" rid="pcbi.1003476-Warren3">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Royden1">[9]</xref>, whereby the retinal optic flow is compared to a number of large-field radial expansion patterns, or a combination of the approaches is also used.</p>
<p>Navigation under natural conditions is more complex than traveling on a straight path without any rotation. When the observer travels along a straight path, factors, such as eye movements and gaze, introduce rotation, which may result in optic flow that is not radially expanding or contracting. Sources of rotation are either considered <italic>retinal</italic> or <italic>extra-retinal</italic> <xref ref-type="bibr" rid="pcbi.1003476-Warren4">[10]</xref>. Rotations that occur through the actions of the observer, such as eye, head, or body movements, are considered extra-retinal, whereas rotations due to path curvature are considered retinal. Research on heading perception during smooth-pursuit eye movements shows that human bias in heading judgments remains constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e002" xlink:type="simple"/></inline-formula> and independent of angular rotation due to eye movement velocities <xref ref-type="bibr" rid="pcbi.1003476-Royden2">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Royden3">[12]</xref>. However, when human subjects fixate (no extra-retinal rotation) and are shown optic flow displays that simulate what would be seen by an observer traveling along a straight path with a constant amount of rotation (<xref ref-type="fig" rid="pcbi-1003476-g001">Figure 1b</xref>), humans make large errors in heading judgments that is proportional to the rate of rotation <xref ref-type="bibr" rid="pcbi.1003476-Royden2">[11]</xref>. This is often referred to as the <italic>simulated rotation condition</italic>, in which the retinal rotation experienced by human observers is due to the simulated eye movements. Subjects typically note the experience of traveling along a curved path and not a straight path with eye rotation (compare <xref ref-type="fig" rid="pcbi-1003476-g001">Figure 1b and 1c</xref>), which is the assumption of the experimenters. The large heading bias in the simulated rotation condition may therefore arise through the reporting of the subject's path rather than heading or ambiguity in the task instructions <xref ref-type="bibr" rid="pcbi.1003476-Ehrlich1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Li1">[14]</xref>. Mathematical analyses indicate that the optic flow experienced by subjects when eye movements are simulated is similar to that experienced traveling on a curved path over the time period of a typical experimental trial <xref ref-type="bibr" rid="pcbi.1003476-Royden4">[15]</xref>. For longer viewing times, the optic flow in the two scenarios diverges and could potentially allow the subjects to disambiguate curved paths from simulated eye rotations.</p>
<p>Electrophysiological evidence suggests that neurons sensitive to radial expansion in MSTd, which are thought to encode heading, demonstrate modulation due to extra-retinal eye signals <xref ref-type="bibr" rid="pcbi.1003476-Bradley1">[16]</xref>–<xref ref-type="bibr" rid="pcbi.1003476-Shenoy2">[18]</xref>. The modest human bias demonstrated by humans while performing eye movements is less than would be expected given the magnitude of the rotations. Assuming MSTd is involved in heading perception, this could be explained by the extra-retinal signals in MSTd imperfectly ‘canceling out’ the rotations. Computational models have employed gain fields in MSTd as the mechanism by which this ‘canceling out’ of rotation may occur <xref ref-type="bibr" rid="pcbi.1003476-Churchland1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Elder1">[20]</xref>.</p>
<p>Animals navigate over complex terrain and the path of travel is rarely straight <xref ref-type="bibr" rid="pcbi.1003476-Rushton1">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Fajen1">[22]</xref>, but few studies have examined human navigation along <italic>curved paths</italic>. Those that do tend to examine human path perception in the context of circular paths <xref ref-type="bibr" rid="pcbi.1003476-Fajen2">[23]</xref>–<xref ref-type="bibr" rid="pcbi.1003476-Saunders2">[28]</xref>. In the present article, if the <italic>path</italic> is not straight, we make the assumption of a circular curved path (<xref ref-type="fig" rid="pcbi-1003476-g001">Figure 1c</xref>). During movement along a curved path, heading and path refer to different characteristics of the observer movement. Heading refers to the instantaneous direction of travel in the world reference frame. From the perspective of the observer, the heading corresponds to the straightaway direction if the curved path were abandoned. Along a circular path, the observer heading is always tangent to circle, aligned in the direction of the clockwise (CW) or counter-clockwise (CCW) traversal. Path corresponds to the fixed curvature trajectory traversed by the observer in world coordinates. Both heading and path are independent of the observer gaze and body orientation.</p>
<p>When traveling along a curved path without eye or body movements, all rotation in the retinal optic flow is due to the path curvature. Research indicates that in environments composed of random dots, humans can accurately judge the curvature of their path in static environments <xref ref-type="bibr" rid="pcbi.1003476-Warren5">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Kim1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Kim2">[30]</xref>. Judgments remain accurate in the presence of independently moving objects <xref ref-type="bibr" rid="pcbi.1003476-Fajen2">[23]</xref>, when the observer gaze or instantaneous heading direction and body orientation are always tangent to the path of travel. This naturally occurs during locomotion. Human judgments of path curvature are not affected by whether the environment is composed of sparse dots, limited lifetime dots, or dense textures <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. However, many studies that investigate curvilinear navigation are confounded by whether subjects report heading or future path <xref ref-type="bibr" rid="pcbi.1003476-Li1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Stone1">[32]</xref>–<xref ref-type="bibr" rid="pcbi.1003476-Li5">[34]</xref>.</p>
<sec id="s1a">
<title>Theories of Path Perception</title>
<p>Existing theories of path perception are a set of heuristics that do not specify the mechanisms by which the path is perceived in the brain. Some theories depend on the active tracking of ‘features’ in the visual scene <xref ref-type="bibr" rid="pcbi.1003476-Warren5">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Lee1">[35]</xref>, while others implicate an extensive cognitive component, such as updating estimates with respect to external reference objects <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Li6">[36]</xref>.</p>
<p>We first summarize the former class of path perception theories. The <italic>passing flow line</italic> hypothesis observes that optic flow integrated over an extended period of time yields a streamline that passes underneath the observer and coincides with the path of travel <xref ref-type="bibr" rid="pcbi.1003476-Lee1">[35]</xref>. This hypothesis assumes that the observer gaze is in the direction of heading and requires the environment to have a textured ground plane passing directly underneath the observer. A related hypothesis proposed by Wann and Swapp, which we call the <italic>vertical vector</italic> hypothesis, notes that if the observer maintains gaze on the destination of travel, the path can be recovered from retinal flow by integrating first-order flow vectors that are vertically aligned <xref ref-type="bibr" rid="pcbi.1003476-Wann1">[37]</xref>. This strategy does not require knowledge of heading. The <italic>vertical flow line</italic> hypothesis posits that the visual system tracks the constellation of vertical optic flow streamlines that exist when the observer fixates a point on the future path. This strategy assumes that humans fixate on their destination while traveling along curvilinear paths. The <italic>reversal boundary</italic> hypothesis notes that the future path of travel coincides with direction reversals or “zero-crossings” in the horizontal motion component once the optic flow has been projected onto the retina <xref ref-type="bibr" rid="pcbi.1003476-Warren5">[27]</xref>; the horizontal motion component of texture inside (outside) the path will be rightward (leftward), or vice versa depending on whether the circle is traversed CW or CCW. While psychophysical evidence suggests that humans are most accurate in judging path curvature when the gaze direction is aligned with the heading, it is not clear how this strategy could tolerate momentary fluctuations in gaze. Warren and colleagues have proposed a <italic>vector normal</italic> hypothesis whereby the center of the circular path can be determined by computing the intersection of the vector normals of two points in the environment <xref ref-type="bibr" rid="pcbi.1003476-Warren5">[27]</xref>. Using the vector normals, knowledge of the circular path center, and the observer's current position, the radius and therefore the curvature of the path of travel can be recovered.</p>
<p>The hypotheses reviewed above suffer from rigid constraints on the environment or observer gaze, and are unlikely to represent general theories of human path perception. The strategies proposed by the passing flow line, vector normal, and vertical vector hypotheses only hold when observers look where they are going—i.e. gaze is along the heading direction. These hypotheses cannot account for activities that presumably depend on the perception of path, such as steering a vehicle <xref ref-type="bibr" rid="pcbi.1003476-Land1">[38]</xref>, for which successful control of navigation accompanies natural changes in gaze <xref ref-type="bibr" rid="pcbi.1003476-Wann1">[37]</xref>. Humans perceive their path of travel in sparse environments composed of small quantities of dots. The boundary reversal hypothesis, however, requires dense optic flow to ascertain the horizontal motion zero-crossing. From a neural computation point of view, it is unclear how the brain could track the context-specific local features proposed by any of the above hypotheses over time.</p>
<p>The following path estimation theories rely on external landmarks in the environment. The <italic>reference object</italic> hypothesis posits that observers either update their position or integrate the change in heading over time with respect to an object embedded in the environment <xref ref-type="bibr" rid="pcbi.1003476-Li6">[36]</xref>. Subjects in the experiments of Li and Cheng were able to judge their future path of travel in the absence of persistent objects in the environment, rendering the reference object hypothesis an incomplete strategy <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. Li and Cheng tested whether humans can integrate the change in heading without a reference object by tracking the “drift” in the FoE over time with gaze remained fixed along a particular axis when the observer travels along the circle without any rotation (Z-axis condition). Subject responses were consistent with the percept of moving along a straight rather than a circular path, making the <italic>FoE drift</italic> hypothesis unlikely <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. Finally, Li and Cheng proposed that observers first estimate heading to established a reference, then estimate the path curvature, which is mathematically defined for a circular path as the ratio between the rotation and translation rates <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. It is not clear if, or how, mechanisms in the brain could perform these operations.</p>
<p>In summary, theories of path perception either treat path perception as independent of heading or depend on its prior estimation. In the present article, we propose a neural model of the primate visual system in which representations of heading and path are determined simultaneously and dynamically interact in the same population of neurons.</p>
</sec><sec id="s1b">
<title>Neurophysiology of Path Perception</title>
<p>Neurons in the primate medial superior temporal area (MST) of the superior temporal sulcus (STS) exhibit tuning in the laboratory to radially expanding optic flow patterns, similar to those experienced by an observer moving forward on a straight path. MSTd cells have therefore been the focus of neurophysiological investigations of the mechanisms underlying visually-guided navigation. MST is the earliest visual area, the fewest synapses away from the retina in the primate dorsal stream, that responds to large field pattern motion. Evidence suggests that MST in monkey is composed of functionally distinct dorsal (MSTd) and ventral (MSTv) regions. Whereas neurons in MSTd exhibit sensitivity to optic flow patterns that occupy areas of the visual field as large as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e003" xlink:type="simple"/></inline-formula>, MSTv neurons have smaller receptive field sizes and are suspected to be involved in the perception of object motion <xref ref-type="bibr" rid="pcbi.1003476-Orban1">[39]</xref>. MSTd neurons demonstrate sensitivity to dot speed <xref ref-type="bibr" rid="pcbi.1003476-Duffy1">[40]</xref> and spatial shifts in FoE position <xref ref-type="bibr" rid="pcbi.1003476-Duffy2">[41]</xref>, and therefore are thought to be involved in heading perception <xref ref-type="bibr" rid="pcbi.1003476-Britten1">[42]</xref>.</p>
<p>Froehler and Duffy have conducted the only neurophysiological study to date that reports the existence of “path selective” neurons in cortex <xref ref-type="bibr" rid="pcbi.1003476-Froehler1">[43]</xref>. Monkeys were placed on a sled in a dark room that contained bright dots on the three walls that were within view. The sled moved CW or CCW along a circular path (<xref ref-type="fig" rid="pcbi-1003476-g002">Figure 2</xref>). The sled was configured not to rotate the body as it traversed the circular path. The monkeys maintained gaze, throughout the trial, on a target that was projected from the sled onto the distal wall. Because the projector was attached to the sled and the monkey was trained to maintain gaze on the target, the fixation point occupied the same position within the monkeys' visual field over time. The optic flow experienced by the monkeys contained no rotation and appeared to radially expand or contract at each instant, with a FoE or focus of contraction (FoC) that ‘drifted’ horizontally during the trial. A monkey traveling once around the circle on the sled therefore viewed a sequence of headings and each had an equivalent at antipodal positions in both the CW and CCW trials. Froehler and Duffy recorded from single neurons in MSTd and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e004" xlink:type="simple"/></inline-formula> elicited differential activity at antipodal positions on the track, where expansion/contraction optic flow patterns were identical. The neurons' response depended on whether the circle was traversed CW or CCW, and as a result the authors claimed these cells demonstrated path selectivity. The authors also found heading selective cells, which fired when the optic flow contained their preferred heading irrespective of the CW or CCW traversal direction, and place selective cells, which responded when the monkey moved to a particular location of the room irrespective of the visual motion pattern. The selectivity of neurons in the sample was distributed along a continuum, ranging from those demonstrating high (path selective) to those demonstrating low (heading selective) CW v.s. CCW differential activity. The mechanisms that underlie how these cells in MSTd respond along a continuum to heading and path were not evaluated by the study.</p>
<fig id="pcbi-1003476-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g002</object-id><label>Figure 2</label><caption>
<title>Experimental paradigm and sample optic flow fields from Froehler and Duffy, who report the existence of path selective neurons in MSTd <xref ref-type="bibr" rid="pcbi.1003476-Froehler1">[43]</xref>.</title>
<p>A monkey seated in a sled traveled CCW (a) or CW (c) along a circular track while maintaining gaze on the distal wall of luminous dots. The body, head, and eye did not rotate so that the monkey always directly faced the distal wall. The monkey therefore experienced radially expanding or contracting optic flow without sources of rotation. (b,d) Instantaneous optic flow experienced by the monkey at different locations along the circular track. In (b) at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e005" xlink:type="simple"/></inline-formula>, the monkey views a radially expanding optic flow while moving CCW when the heading direction is straight ahead, which is the same as the optic flow viewed CW <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e006" xlink:type="simple"/></inline-formula> on the other side of the circle. Between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e007" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e008" xlink:type="simple"/></inline-formula>, the FoE drifts rightward until at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e009" xlink:type="simple"/></inline-formula> it is out of view. At <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e010" xlink:type="simple"/></inline-formula>, the monkey experiences radial contraction.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g002" position="float" xlink:type="simple"/></fig>
<p>In summary, neurons in MSTd demonstrate tuning to optic patterns, similar to those that would be viewed by an observer traveling on a straight path, and may exhibit sensitivity to path in the absence of rotation <xref ref-type="bibr" rid="pcbi.1003476-Froehler1">[43]</xref>. Locomotion along curved paths typically involves rotation, so, if the neurons discovered by Froehler and Duffy are in fact path-selective, it remains unclear how their response patterns would generalize to more natural movement conditions. Our model proposes mechanisms by which the MSTd neurons identified by Froehler and Duffy elicit differential firing rates when the instantaneous visual motion appears the same, yet the monkey moves CW or CCW around the circle. Our analysis integrates the findings with other known properties of MSTd neurons.</p>
</sec><sec id="s1c">
<title>Spiral-Selective MSTd Cells Dynamically Encode Path and Heading Direction</title>
<p>If the primary role of MSTd were to determine heading, most MSTd neurons would be expected to preferentially respond to radial expansion and contraction. While many neurons in MSTd are tuned to such patterns, many others exhibit preferential responses to patterns in a spiral space spanned by radial and center templates (<xref ref-type="fig" rid="pcbi-1003476-g003">Figure 3</xref>). Moreover, neurons in MSTd would be expected to discount retinal rotation, as many appear to do with extra-retinal rotation <xref ref-type="bibr" rid="pcbi.1003476-Bradley1">[16]</xref>. However, Orban and colleagues demonstrated that MSTd neurons tuned to radial expansion did not respond to expansion displays when adding simulated retinal rotation <xref ref-type="bibr" rid="pcbi.1003476-Orban2">[44]</xref>. Therefore, rotation does not appear to be discounted in MSTd neurons when the source is retinal rather than extra-retinal. Graziano and colleagues found that more neurons preferentially responded to CW and CCW spirals than to rotation or contraction, and the tuning curve width and selectivity did not differ across the MSTd population for radial, spiral, and center patterns <xref ref-type="bibr" rid="pcbi.1003476-Graziano1">[45]</xref>. That is, neurons tuned to radial expansion did not exhibit sharper tuning curves than those tuned to spirals. Spiral tuning also appears in neurons in the ventral parietal area (VIP) <xref ref-type="bibr" rid="pcbi.1003476-Schaafsma1">[46]</xref> and area 7a <xref ref-type="bibr" rid="pcbi.1003476-Read1">[47]</xref>, two of the brain regions to which MSTd projects <xref ref-type="bibr" rid="pcbi.1003476-Born1">[48]</xref>. Despite the diversity of tuning in MSTd, no well-defined hypothesis has been proposed for the functional role of MSTd neurons tuned to spiral patterns. Graziano and colleagues speculated that spiral tuning may allow MSTd to detect a rotating moving object or perceive the pattern of motion experienced by walking forward while tracking a point on the ground, however, these hypotheses are unproven.</p>
<fig id="pcbi-1003476-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g003</object-id><label>Figure 3</label><caption>
<title>Spiral space continuum of motion patterns employed in electrophysiological studies to probe cell selectivity to spiral motion.</title>
<p>Sensitivity to radial expansion and center motion is tested by the left and right ends of the continuum, respectively. Spiral patterns exist in between as an interpolation between the radial and center patterns. The spiral space also contains contracting spirals and those with CCW orientations (not shown).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g003" position="float" xlink:type="simple"/></fig>
<p>We claim that selectivity to optic flow across a spiral space continuum simultaneously affords MSTd with sensitivity to the curvature of the path and to the heading direction. When an observer travels along a curvilinear path on a ground plane with a fixed direction of gaze, a spiral-like pattern is experienced and optic flow contains rotation that specifies the path curvature <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. Theoretically, spiral selective neurons should be sensitive to the curvature of their preferred spiral pattern and would therefore be capable of extracting information about the future path. Although the actual representation in the brain is unlikely to resemble an abstractly-defined mathematical spiral space <xref ref-type="bibr" rid="pcbi.1003476-Mineault1">[49]</xref>, we assume that the spiral space selectivity in MSTd spans the continuum between radial and center patterns that has been electrophysiologically tested in numerous studies <xref ref-type="bibr" rid="pcbi.1003476-Orban2">[44]</xref>–<xref ref-type="bibr" rid="pcbi.1003476-Read1">[47]</xref>. Because we developed a neurophysiological model, it is important to constrain the model to constructs that can be verified by data. Since no neurophysiological data exists with more ecological stimuli we would be unable to verify a model design constructed using such templates designed to reflect our intuitive understanding of the ecologically valid space.</p>
<p><xref ref-type="fig" rid="pcbi-1003476-g004">Figure 4</xref> shows a visualization of the proposed functional organization of MSTd. Each cylindrical volume represents a functional MSTd hypercolumn with respect to spiral selectivity. A hypercolumn contains a subpopulation of MSTd neurons that are sensitive to a spectrum of optic flow patterns in spiral space that have receptive fields centered at the same location of visuotopic space. The horizontal (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e011" xlink:type="simple"/></inline-formula>) and vertical (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e012" xlink:type="simple"/></inline-formula>) axes specify the spatial dimensions of the MSTd visuotopic map. Each point in this two-dimensional space indicates tuning to a FoE, FoC, or more generally a center of motion (CoM) in that particular visuotopic location—irrespective of the pattern selectivity. For example, the top-right hypercolumn in <xref ref-type="fig" rid="pcbi-1003476-g004">Figure 4</xref> contains subpopulations of MSTd neurons tuned to motion patterns (e.g. radial expansion, radial contraction, spiral, center) that have the CoM located on the top-right region of the visual field. The axis than spans the depth of the hypercolumn represents the degree of spiral tuning for the subpopulation of neurons that have receptive fields centered at a particular location of the visual field. MSTd neurons may exhibit tuning to CW or CCW spiral patterns that either expand or contract. Spiral patterns smoothly vary in ‘spirality’ between patterns that are radial with no curvature (top and bottom), and those that are centers (left and right). We propose that the ‘spirality’ of the most active subpopulation of neurons in MSTd encodes the curvature of the path, and the two-dimensional visuotopic position of that maximally active subpopulation represents the heading.</p>
<fig id="pcbi-1003476-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g004</object-id><label>Figure 4</label><caption>
<title>Schematic depiction of the model coding of path curvature and heading in MSTd.</title>
<p>Neurons in a model MSTd hypercolumn possess selectivities across a spiral space spanning CW, CCW, radial expansion, radial contraction, and center motion patterns. The length and width dimensions of the schematic MSTd selectivity volume correspond to neurons with 2D visuotopic tuning. Therefore, at every position in the visual field, there is a model MSTd hypercolumn with a full set of units tuned to radial, spiral, and center optic flow patterns. For example, the hypercolumn on the top left corresponds to MSTd units with receptive fields centered on the top left portion of the visual field, which have focus of expansion or center of motion tuning in that location. Travel along a circular path elicits a distribution of activity within the MSTd volume (overlaid heat map). The position of the activity peak across the volume in the spiral space (depth) dimension corresponds to the model path curvature estimate, and the 2D position of the peak in the spatial dimensions (length and width) indicates the estimated heading direction.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g004" position="float" xlink:type="simple"/></fig>
<p>In the simple case of travel along a straight path, we expect neurons tuned to radial expansion to be most active, indicating no path curvature, and we anticipate the peak to spatially coincide with the FoE to indicate the heading. Therefore, the population MSTd response in this example is the same as if there were only neurons selective to radial patterns. In the case of a circular path, we expect the spiral-selective neurons with spiral arms that best match the path curvature to be most active. As reported in several psychophysical studies <xref ref-type="bibr" rid="pcbi.1003476-Royden2">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>, different gaze patterns modulate the rotation present in the optic flow. In the present paper, we test whether the maximal activity of neurons tuned in spiral space maps onto human judgments of path curvature as gaze varies.</p>
<p>We present a dynamical model of primate MSTd that builds on electrophysiological findings and explains a range of human psychophysical data on path and heading perception with and without eye movements. The main goal is to present a mechanistic hypothesis of path perception that provides a unified framework to interpret psychophysical and neurophysiological data on heading and path perception. Our model goes beyond existing heuristics by providing a mathematical description and biologically-plausible implementation that is readily testable. Our analysis and simulations show that the model yields performance similar to humans under different gaze conditions, circular path radii, and eye movement patterns. The model predicts that the neurons reported by Froehler and Duffy obtain their path selectivity through spiral pattern tuning <xref ref-type="bibr" rid="pcbi.1003476-Froehler1">[43]</xref>.</p>
</sec></sec><sec id="s2" sec-type="materials|methods">
<title>Materials and Methods</title>
<p>Our objective was to create a biologically plausible model of the primate visual system that demonstrates the mechanisms by which perception of heading and path may arise from populations and systems of neurons that process optic flow. The model consists of systems of <italic>shunting</italic> differential equations, each of which models the activity neurons in cortex <xref ref-type="bibr" rid="pcbi.1003476-Grossberg1">[50]</xref>. This architecture affords realistic neural temporal and competitive dynamics, including recurrent competition and feedback, gain control, and normalization. By creating a computational model using known functional properties of neurons in the magnocellular pathway of the dorsal stream, we can simultaneously connect neurophysiological mechanisms to human data and our test our hypothesis on diverse types of psychophysical data.</p>
<sec id="s2a">
<title>Model Area Descriptions</title>
<p>The proposed neural model contains three stages that correspond to primate primary visual cortex (V1), medial temporal area (MT), and the dorsal medial superior temporal area (MSTd) (<xref ref-type="fig" rid="pcbi-1003476-g005">Figure 5</xref>). In this paper, we do not model retinal input, but rather use analytical equations to model the vector-based optic flow representation in V1 <xref ref-type="bibr" rid="pcbi.1003476-Layton1">[51]</xref>. A prior version of the model demonstrates how retinal inputs are processed through neural circuits to generate those representations <xref ref-type="bibr" rid="pcbi.1003476-Browning1">[52]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Browning2">[53]</xref></p>
<fig id="pcbi-1003476-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g005</object-id><label>Figure 5</label><caption>
<title>Diagram of model V1-MT-MSTd.</title>
<p>First-order local motion is computed in model V1. Model MT receives projections and spatially pools motion signals from model V1. A extra-retinal eye velocity gain field acts on the afferent signals from model MT in MSTd, which compensates for rotation introduced by pursuit eye movements proportional to the eye movement speed in the direction opposite that of the eye movement. A template match occurs in model MSTd, whereby the similarity is assessed between the afferent motion signal and motion field templates sampled in spiral space. A distance-dependent weighting exponentially discounts vector matches by distance from the template singularity. Finally, neurons selective to different spiral patterns, expansion and contraction, CW and CCW orientations, and 2D visuotopic location compete.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g005" position="float" xlink:type="simple"/></fig><sec id="s2a1">
<title>V1 (Local motion detection)</title>
<p>We generated videos of dots distributed on a ground or frontoparallel plane, which served as input to the model. The videos approximate the visual displays shown to human subjects in psychophysical experiments that assess human heading and path perception. The local motion of the dots was computed according to a planar pin-hole camera model <xref ref-type="bibr" rid="pcbi.1003476-Raudies1">[54]</xref>. The following equation describes first-order optic flow with translation vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e013" xlink:type="simple"/></inline-formula> and rotation vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e014" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003476-LonguetHiggins1">[55]</xref>:<disp-formula id="pcbi.1003476.e015"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003476.e015" xlink:type="simple"/><label>(1)</label></disp-formula>The representation in model V1 computed by <xref ref-type="disp-formula" rid="pcbi.1003476.e015">Eq. 1</xref> describes the instantaneous velocity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e016" xlink:type="simple"/></inline-formula> of each projected dot. In <xref ref-type="disp-formula" rid="pcbi.1003476.e015">Eq. 1</xref>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e017" xlink:type="simple"/></inline-formula> signifies the depth of the projected dot in the world and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e018" xlink:type="simple"/></inline-formula> correspond to the spatial position in the 2D projection plane. Values for the parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e019" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e020" xlink:type="simple"/></inline-formula> varied according to psychophysical conditions, as described in Experimental Descriptions. For simplicity we use a Cartesian representation of space in V1, although prior work has demonstrated how motion can be processed with cortical magnification <xref ref-type="bibr" rid="pcbi.1003476-Elder1">[20]</xref>.</p>
</sec><sec id="s2a2">
<title>MT (Motion pooling)</title>
<p>Model MT units pool the V1 response vectors <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e021" xlink:type="simple"/></inline-formula> component-wise with a Gaussian receptive field kernel <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e022" xlink:type="simple"/></inline-formula>. We configured model MT neurons with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e023" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e024" xlink:type="simple"/></inline-formula>, and radius <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e025" xlink:type="simple"/></inline-formula>, as in previous work to mimic the larger receptive fields in MT compared to V1 <xref ref-type="bibr" rid="pcbi.1003476-Layton1">[51]</xref>. Model MT units respond to large fields of uniform motion and project to MSTd. The pooled model V1 activity in model MT is denoted <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e026" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s2a3">
<title>MSTd (Gain fields, spiral template matching, recurrent competition)</title>
<p>Model MSTd consists of three stages: 1) eye velocity gain fields, 2) template matching in spiral space, and 3) dynamical recurrent competition. When the eye velocity is nonzero (e.g. during a smooth-pursuit eye movement), the extra-retinal signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e027" xlink:type="simple"/></inline-formula> acts presynaptically to MSTd <xref ref-type="bibr" rid="pcbi.1003476-Churchland1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Elder1">[20]</xref>:<disp-formula id="pcbi.1003476.e028"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003476.e028" xlink:type="simple"/><label>(2)</label></disp-formula>In <xref ref-type="disp-formula" rid="pcbi.1003476.e028">Eq. 2</xref>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e029" xlink:type="simple"/></inline-formula> represents the output of model MT and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e030" xlink:type="simple"/></inline-formula> describes the signal after extra-retinal modulation. We simulated the conditions of Cheng and Li, whereby subjects made judgments about their future curvilinear path while visually tracking a horizontally moving target <xref ref-type="bibr" rid="pcbi.1003476-Cheng1">[25]</xref>. Because the target moved at a constant velocity and the experimenters discarded data <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e031" xlink:type="simple"/></inline-formula> from the onset of the eye movement, we set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e032" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e033" xlink:type="simple"/></inline-formula> is proportional to the mean pursuit eye movement speed across subjects in each respective condition. The sign depends on the eye movement direction.</p>
<p>We generated spiral templates that spanned the entire visual field by interpolating radial and center vector field patterns (<xref ref-type="fig" rid="pcbi-1003476-g003">Figure 3</xref>) <xref ref-type="bibr" rid="pcbi.1003476-Grossberg2">[56]</xref>. <xref ref-type="disp-formula" rid="pcbi.1003476.e036">Eq. 3</xref> defines a radial field <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e034" xlink:type="simple"/></inline-formula> and a center field <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e035" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003476.e036"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003476.e036" xlink:type="simple"/><label>(3)</label></disp-formula>Radial expansion and contraction templates are obtained by setting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e037" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e038" xlink:type="simple"/></inline-formula>, respectively. Center templates with CW and CCW orientations are constructed by setting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e039" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e040" xlink:type="simple"/></inline-formula>, respectively. The values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e041" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e042" xlink:type="simple"/></inline-formula> determine the horizontal and vertical spatial offset of the FoE in the radial template and the center of motion (CoM) in the center field. <xref ref-type="disp-formula" rid="pcbi.1003476.e045">Eq. 4</xref> defines a spiral template, and the value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e043" xlink:type="simple"/></inline-formula> determines the degree of <italic>spirality</italic>, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e044" xlink:type="simple"/></inline-formula>.<disp-formula id="pcbi.1003476.e045"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003476.e045" xlink:type="simple"/><label>(4)</label></disp-formula>When <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e046" xlink:type="simple"/></inline-formula>, the template is radial, when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e047" xlink:type="simple"/></inline-formula>, the template is a CW center, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e048" xlink:type="simple"/></inline-formula> is a spiral template for other values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e049" xlink:type="simple"/></inline-formula>.</p>
<p>We created a neural model with 11500 MSTd neurons with motion pattern selectivities determined by the templates in spiral space. The templates were uniformly sampled across the spiral continuum within the visual field <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e050" xlink:type="simple"/></inline-formula>. We configured the spatial offsets <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e051" xlink:type="simple"/></inline-formula> to encompass possible CoM that appeared outside the retinal projection plane in the experiments of Li and Cheng. We found that simulating templates with CoM selectivities far outside the field of view did not impact model performance. This occurred because laminar flow vectors from the template, which are uniform in direction, appear within the field of view and yield poor matches to the optic flow signal. For example, a CCW center template with a CoM selectivity far to the left only responds to uniform vertical motion within the field of view, which does not closely resemble the optic flow experienced while traveling along a curved path. As described below, a model MSTd neuron with weak input from the template matching stage will be suppressed in the competitive dynamics and not affect heading or path curvature estimates produced by the model.</p>
<p>Each model neuron receives afferent signals from model MT, which passes through a template matching stage to assess the degree of similarity between the input signal and model neuron's pattern tuning. The match score at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e052" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e053" xlink:type="simple"/></inline-formula>, for the neuron at location <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e054" xlink:type="simple"/></inline-formula> with preferred spirality <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e055" xlink:type="simple"/></inline-formula> and orientation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e056" xlink:type="simple"/></inline-formula> is computed according to the following inner product:<disp-formula id="pcbi.1003476.e057"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003476.e057" xlink:type="simple"/><label>(5)</label></disp-formula><xref ref-type="disp-formula" rid="pcbi.1003476.e057">Eq. 5</xref> computes an inner product (i.e. cosine similarity) by performing component-wise multiplication, indicated by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e058" xlink:type="simple"/></inline-formula>, between the input optic flow <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e059" xlink:type="simple"/></inline-formula> and the spiral template <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e060" xlink:type="simple"/></inline-formula>. The result is normalized by the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e061" xlink:type="simple"/></inline-formula> norm of the optic flow vector and the vector components are summed. An exponential distance-dependent weighting is applied to give matches near the CoM greater weight and to afford sensitivity to the CoM position within the visual field, which is consistent with known properties of MSTd neurons <xref ref-type="bibr" rid="pcbi.1003476-Duffy2">[41]</xref>. This is followed by a summing over all spatial locations to obtain a scalar match score. Exponential distance dependent weighting has been used in a previous version of the model to balance foveal and peripheral motion components in the grouping of time to contact within an object or surface <xref ref-type="bibr" rid="pcbi.1003476-Browning3">[57]</xref>. The parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e062" xlink:type="simple"/></inline-formula> is set to the reciprocal of the number of dots such that the match score is not biased by the number of vector samples.</p>
<p><xref ref-type="disp-formula" rid="pcbi.1003476.e067">Eq. 6</xref> defines a dynamical competitive network that describes the activation of model MSTd neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e063" xlink:type="simple"/></inline-formula> at spatial location <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e064" xlink:type="simple"/></inline-formula> that is selective to a spiral pattern with spirality <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e065" xlink:type="simple"/></inline-formula> and spiral orientation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e066" xlink:type="simple"/></inline-formula> (CW v.s. CCW):<disp-formula id="pcbi.1003476.e067"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003476.e067" xlink:type="simple"/><label>(6)</label></disp-formula><xref ref-type="disp-formula" rid="pcbi.1003476.e067">Eq. 6</xref> is a recurrent competitive field and is configured as a contrast-enhancing or winner-take-all network <xref ref-type="bibr" rid="pcbi.1003476-Grossberg1">[50]</xref>. Competition between neurons in the network occurs across location and spiral template space. The constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e068" xlink:type="simple"/></inline-formula> is defined as the reciprocal of the membrane time constant of the model neuron and scales how fast the neuron responds, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e069" xlink:type="simple"/></inline-formula> signifies the passive decay rate, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e070" xlink:type="simple"/></inline-formula> is the saturation upper bound of the model neuron. In <xref ref-type="disp-formula" rid="pcbi.1003476.e067">Eq. 6</xref>, the inhibition model neurons receive from others in the network that have different spiral pattern and orientation sensitivities is set to unity weight, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e071" xlink:type="simple"/></inline-formula> differentially weights the spatial competition. <xref ref-type="table" rid="pcbi-1003476-t001">Table 1</xref> summarizes parameters values that were used in configuring the MSTd dynamics. The function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e072" xlink:type="simple"/></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1003476.e067">Eq. 6</xref> is a sigmoidal transfer function defined as<disp-formula id="pcbi.1003476.e073"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003476.e073" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e074" xlink:type="simple"/></inline-formula> indicates the half-wave rectification <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e075" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e076" xlink:type="simple"/></inline-formula> is a threshold on the input from model MT, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e077" xlink:type="simple"/></inline-formula> is a sigmoid shape parameter defining the inflection point.</p>
<table-wrap id="pcbi-1003476-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.t001</object-id><label>Table 1</label><caption>
<title>Parameter values used in simulations.</title>
</caption><alternatives><graphic id="pcbi-1003476-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Parameter</td>
<td align="left" rowspan="1" colspan="1">Value</td>
<td align="left" rowspan="1" colspan="1">Description</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e078" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">1.0</td>
<td align="left" rowspan="1" colspan="1">Inverse cell time constant</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e079" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">3.25</td>
<td align="left" rowspan="1" colspan="1">Passive decay rate</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e080" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">1.0</td>
<td align="left" rowspan="1" colspan="1">Activation upper bound</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e081" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">2.5</td>
<td align="left" rowspan="1" colspan="1">Strength of inhibition from spatial competition</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e082" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">0.01</td>
<td align="left" rowspan="1" colspan="1">MSTd presynaptic threshold</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e083" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">0.07</td>
<td align="left" rowspan="1" colspan="1">Sigmoid shape parameter</td>
</tr>
</tbody>
</table>
</alternatives></table-wrap>
<p>Path curvature <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e084" xlink:type="simple"/></inline-formula> and heading <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e085" xlink:type="simple"/></inline-formula> are computed according to <xref ref-type="disp-formula" rid="pcbi.1003476.e086">Eqs. 8</xref> and <xref ref-type="disp-formula" rid="pcbi.1003476.e087">9</xref>, respectively, by considering the spirality and spatial position that elicited the maximal MSTd subpopulation activation.<disp-formula id="pcbi.1003476.e086"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003476.e086" xlink:type="simple"/><label>(8)</label></disp-formula><disp-formula id="pcbi.1003476.e087"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003476.e087" xlink:type="simple"/><label>(9)</label></disp-formula></p>
<p>Note that the argmax operations defined in <xref ref-type="disp-formula" rid="pcbi.1003476.e086">Eqs. 8</xref>–<xref ref-type="disp-formula" rid="pcbi.1003476.e087">9</xref> are not part of the model computations, and simply allow us to compare the model population activity with judgments made by humans in psychophysical experiments. The MSTd distribution is itself a representation of the confidence that the observer has in the heading direction and path percept. In some senses the distribution itself can be considered a probabalistic read-out, however human subjects were not asked to provide a distribution of confidence over the space so we have no way to validate whether or not our distribution matches human performance. Forcing a decision and taking the maximum likelihood allows us to compare model output against the same forced choice task in humans. We do not claim that the brain decodes information about heading and path distributed across the population in MSTd using maximum likelihood.</p>
<p>Our model does not require the CoM to appear within the field of view to compute heading or path curvature. Model MSTd neurons that possess CoM selectivities outside the field of view estimate heading and path curvature using the available visual information.</p>
<p>All simulations were run on a 8-core 2.66 Ghz Mac Pro with 64 GB of memory using Mathematica 8. Routines involving numerical integration of network dynamics (<xref ref-type="disp-formula" rid="pcbi.1003476.e067">Eq. 6</xref>) and template matching (<xref ref-type="disp-formula" rid="pcbi.1003476.e057">Eq. 5</xref>) were written in C++. Parameter values listed in the text specify those that remained constant throughout all simulations.</p>
</sec></sec><sec id="s2b">
<title>Experimental Descriptions</title>
<p>Unless otherwise noted, all simulation parameters matched those used in the following psychophysical experiment descriptions.</p>
<sec id="s2b1">
<title>Path Perception &amp; Gaze</title>
<p>We simulated the five experimental conditions of Li and Cheng to compare path estimates produced by the model to those produced by human subjects (<xref ref-type="fig" rid="pcbi-1003476-g006">Figure 6</xref>). In the experiment, subjects viewed computer displays that simulated observer travel along a circular path <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. All coordinates are given with respect to a three-dimensional world coordinate system whereby the origin corresponds to the center of the circular path, the observer begins movement at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e088" xlink:type="simple"/></inline-formula>, and the observer's position at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e089" xlink:type="simple"/></inline-formula> is given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e090" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e091" xlink:type="simple"/></inline-formula> represents the radius of the circular path, the observer either moves CW or CCW about the path, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e092" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e093" xlink:type="simple"/></inline-formula> for CCW path traversals and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e094" xlink:type="simple"/></inline-formula> for CW traversals, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e095" xlink:type="simple"/></inline-formula> signifies the rate of traversal around the circle, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e096" xlink:type="simple"/></inline-formula> corresponds to the observer eye height. The observer translation vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e097" xlink:type="simple"/></inline-formula> is given by:<disp-formula id="pcbi.1003476.e098"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003476.e098" xlink:type="simple"/><label>(10)</label></disp-formula>Each trial lasted <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e099" xlink:type="simple"/></inline-formula> during which time the observer traveled <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e100" xlink:type="simple"/></inline-formula> around the circular path. Therefore, we fix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e101" xlink:type="simple"/></inline-formula>. No trial resulted in a traversal greater than a quarter circle. Since the observer motion remained parallel with respect to the XZ plane throughout each trial, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e102" xlink:type="simple"/></inline-formula>. In the experiments of Li and Cheng, the gaze conditions were simulated in the computer display while subjects fixated a stationary fixation cross above the ground plane horizon throughout the trial. Rotation in the optic flow experienced by subjects therefore results from two sources: the curvature of the circular path, and the simulated gaze direction. For example, when a subject fixates a simulated target, rotation occurs due to a combination of gaze and the path curvature. Gaze was simulated to only vary at eye height. Therefore, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e103" xlink:type="simple"/></inline-formula> depended on the gaze condition and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e104" xlink:type="simple"/></inline-formula>.</p>
<fig id="pcbi-1003476-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g006</object-id><label>Figure 6</label><caption>
<title>Observer gaze conditions during travel along a circular path tested in the model from Li and Cheng <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>.</title>
<p>The gaze in each condition is “simulated” within the computer display because human subjects in the experiments of Li and Cheng maintained fixation throughout the trial. We also tested the model on analogous conditions with pursuit eye movements (see <xref ref-type="fig" rid="pcbi-1003476-g008">Figure 8</xref>). (a) <italic>Z-axis condition</italic>. The observer maintains a fixed body, head, and eye orientation, in the direction of the ‘Z axis’, during travel along the circular path. The optic flow field at every instant is radially expansive, and over time the FoE drifts horizontally. (b) <italic>Outside path condition</italic>. Observer gaze was maintained on a target positioned <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e105" xlink:type="simple"/></inline-formula> outside the path. (c) <italic>On path condition</italic>. The observer maintained gaze on a target on the future path positioned <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e106" xlink:type="simple"/></inline-formula> from the initial heading. (d) <italic>Inside path condition</italic>. Observer gaze was maintained on a target positioned <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e107" xlink:type="simple"/></inline-formula> inside the path. (e) <italic>Gaze along heading condition</italic>. Observer gaze is always tangent to the circular path, which is most often the case during human locomotion. Human subjects in the experiments of Li and Cheng underestimated path curvature in the Z axis, outside path, and on path conditions, overestimated path curvature in the inside path condition, and yielded low error in their judgments in the gaze along heading condition.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g006" position="float" xlink:type="simple"/></fig>
<p>Each condition was identical except for the simulated observer gaze (i.e. no eye movements). In the <italic>Z-axis condition</italic>, an observer was simulated to travel on a circular path and gaze remained parallel to the Z-axis (<xref ref-type="fig" rid="pcbi-1003476-g006">Figure 6<italic>a</italic></xref>). The instantaneous vector field contained no rotation, the field at any time appeared to radially expand, and over time the FoE laterally ‘drifted’. Since there was no rotation in the Z-axis condition, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e108" xlink:type="simple"/></inline-formula>. In the <italic>outside path condition</italic>, the simulated gaze was on a target <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e109" xlink:type="simple"/></inline-formula> outside the circular path (<xref ref-type="fig" rid="pcbi-1003476-g006">Figure 6<italic>b</italic></xref>). In this case,<disp-formula id="pcbi.1003476.e110"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003476.e110" xlink:type="simple"/><label>(11)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e111" xlink:type="simple"/></inline-formula> is the position of the target, which was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e112" xlink:type="simple"/></inline-formula> from the observer's initial position (see <xref ref-type="bibr" rid="pcbi.1003476-Layton2">[58]</xref> for derivations). In the <italic>on path condition</italic>, the simulated gaze was on a target <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e113" xlink:type="simple"/></inline-formula> away from the initial heading and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e114" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003476-g006">Figure 6<italic>c</italic></xref>). In the <italic>inside path condition</italic>, the simulated gaze was on a target located <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e115" xlink:type="simple"/></inline-formula> inside the path and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e116" xlink:type="simple"/></inline-formula> is equal in magnitude but not direction to the value in the outside path condition (<xref ref-type="fig" rid="pcbi-1003476-g006">Figure 6<italic>d</italic></xref>). The <italic>gaze along heading condition</italic> is the natural case whereby the observer's gaze was simulated to be aligned and rotate with the body and the observer's heading was always tangent to the path, so <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e117" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003476-g006">Figure 6<italic>e</italic></xref>).</p>
<p>For all path conditions, the observer traveled along circular paths with radii <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e118" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e119" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e120" xlink:type="simple"/></inline-formula>. The environment consisted of 200 dots randomly distributed along a ground plane <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e121" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e122" xlink:type="simple"/></inline-formula> in depth. An analysis of model performance as a function of dot count is shown in Results. We clipped dots that exited the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e123" xlink:type="simple"/></inline-formula> field of view. The computer projector had a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e124" xlink:type="simple"/></inline-formula> refresh rate, so we simulated observer motion across 60 frames of video. At the end of each trial, subjects manipulated a probe a fixed depth away such to intercept the future path, were the trial to continue. Path error was determined by computing the angular difference between the subject response and future path.</p>
<p>To compare model path estimation performance and human psychophysical data, we must map characteristics from the neural population response in MSTd to human perceptual space. The abscissa of the peak along the spiral pattern continuum (<xref ref-type="disp-formula" rid="pcbi.1003476.e086">Eq. 8</xref>), defines a read-out of the model's representation of path curvature. To compute path error in the model, we subtract model path estimates (<xref ref-type="disp-formula" rid="pcbi.1003476.e086">Eq. 8</xref>) in each gaze condition with that yielded in the gaze along heading condition. Comparing path estimates to that obtained in the gaze along heading condition calibrates the model to the situation wherein judgments of path curvature are accurate. This occurs when humans look where they are going, which is often the case during normal locomotion <xref ref-type="bibr" rid="pcbi.1003476-Li2">[26]</xref>. No additional transformation, other than the subtraction, was necessary to fit the psychophysical data.</p>
</sec><sec id="s2b2">
<title>Path Perception &amp; Eye Movements</title>
<p>The experiment of Cheng and Li followed the same paradigm as the preceding study <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>, but introduced real eye rotations through two conditions in which subjects performed smooth-pursuit eye movements to track a horizontally moving target on the computer display <xref ref-type="bibr" rid="pcbi.1003476-Cheng1">[25]</xref>. The <italic>orientation along heading</italic> condition was the same as the gaze along heading condition, except subjects tracked a target moving toward the exterior of the path, which had the effect of linearizing the optic flow <xref ref-type="bibr" rid="pcbi.1003476-Kim3">[59]</xref>. The <italic>orientation along Z-axis</italic> condition was the same as the Z-axis condition, except subjects tracked a target moving toward the interior of the path, which had the effect of adding extra-retinal rotation. The two conditions were configured such that the first-order retinal optic flow appeared the same. In the orientation along heading condition, the mean subject pursuit eye movement speeds were <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e125" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e126" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e127" xlink:type="simple"/></inline-formula> for path rotation rates of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e128" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e129" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e130" xlink:type="simple"/></inline-formula>. In the orientation along Z-axis condition, the mean subject pursuit eye movement speeds were <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e131" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e132" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e133" xlink:type="simple"/></inline-formula> for path rotation rates of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e134" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e135" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e136" xlink:type="simple"/></inline-formula>.</p>
</sec></sec></sec><sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>Path Perception and Gaze</title>
<p><xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7a</xref> depicts the path error obtained in each experimental condition, averaged across the three path curvatures. The random dot displays in model simulations and the human experiments contained 200 dots.</p>
<fig id="pcbi-1003476-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g007</object-id><label>Figure 7</label><caption>
<title>Path errors obtained by the model in the five gaze conditions.</title>
<p>(a) Path error averaged across circular path radius. Positive and negative path errors indicate overestimations and underestimations of path curvature, respectively, and zero path error signifies veridical performance. Both humans and the model underestimated path curvature in the Z axis, outside path, and on path conditions, overestimated path curvature in the inside path condition, and elicited near veridical performance in the gaze along heading condition. (b) Model MSTd activity across spiral pattern selectivity space during an exemplar trial with a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e137" xlink:type="simple"/></inline-formula> path radius for the five gaze conditions. The location of each peak across the spiral continuum determines the model estimate of path curvature. For example, in the Z-axis condition (black), the MSTd activity peak occurs in the subpopulation sensitive to radial expansion (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e138" xlink:type="simple"/></inline-formula>), and therefore the model indicates zero path curvature (straight path). (c) Model path errors (solid lines) compared to human data from Li and Cheng (replotted, dashed lines) in the five gaze conditions as a function of path curvature <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. Model path errors were in good agreement in all gaze conditions with those based on human judgments (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e139" xlink:type="simple"/></inline-formula>), and path error decreased linearly (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e140" xlink:type="simple"/></inline-formula>) with path curvature. Error bars correspond to standard error of the mean (SEM).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g007" position="float" xlink:type="simple"/></fig>
<p>In the <italic>Z-axis condition</italic>, an observer was simulated to travel on a circular path and gaze remained parallel to the Z-axis (<xref ref-type="fig" rid="pcbi-1003476-g006">Figure 6<italic>a</italic></xref>). The instantaneous vector field contained no rotation, the field at any time appeared to radially expand, and over time the FoE laterally ‘drifted’. In the <italic>outside path condition</italic>, the simulated gaze was on a target <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e141" xlink:type="simple"/></inline-formula> outside the circular path (<xref ref-type="fig" rid="pcbi-1003476-g006">Figure 6<italic>b</italic></xref>). In the <italic>on path condition</italic>, the simulated gaze was on a target <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e142" xlink:type="simple"/></inline-formula> away from the initial heading (<xref ref-type="fig" rid="pcbi-1003476-g006">Figure 6<italic>c</italic></xref>). In the <italic>inside path condition</italic>, the simulated gaze was on a target located <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e143" xlink:type="simple"/></inline-formula> inside the path (<xref ref-type="fig" rid="pcbi-1003476-g006">Figure 6<italic>d</italic></xref>). The <italic>gaze along heading condition</italic> is the natural case whereby the observer's gaze was simulated to be aligned and rotate with the body and the observer's heading was always tangent to the path (<xref ref-type="fig" rid="pcbi-1003476-g006">Figure 6<italic>e</italic></xref>).</p>
<p>Positive and negative path errors correspond to overestimations and underestimations of the path curvature, respectively. Zero path error signifies an accurate assessment of path curvature. Mean model path errors agree well with those produced by humans subjects in the experiments of Li and Cheng <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. The model and human subjects on average underestimated the path curvature in the Z-axis, outside path, and on path conditions, overestimated the path curvature in the inside path condition, and accurately judged the path curvature when gaze was aligned with the heading direction.</p>
<p>When optic flow experienced by an observer moving along a curvilinear path is presented to the model, a subpopulation of units in a particular model MSTd hypercolumn becomes most active (<xref ref-type="fig" rid="pcbi-1003476-g004">Figure 4</xref>). Path curvature is coded by the spiral tuning of these most active units in MSTd. The visuotopic tuning of this maximally active subpopulation does not impact the encoding of path curvature. <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7b</xref> plots the peak magnitude of each MSTd unit tuned to a different template in spiral space, irrespective of the unit's tuning in visuotopic space, in the five gaze conditions when the path curvature was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e144" xlink:type="simple"/></inline-formula>. The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e145" xlink:type="simple"/></inline-formula> axis corresponds to the pattern tuning across the spiral space continuum, and the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e146" xlink:type="simple"/></inline-formula> axis shows the maximal activity elicited by units sensitive to a particular optic flow pattern in spiral space, irrespective of its visuotopic tuning. A spirality of 0 signifies a MSTd neuron that is preferentially tuned to radial expansion, a spirality of 1 indicates a tuning to CCW center motion patterns, and intermediate values correspond to preferential responses to CCW spiral patterns. In the <italic>Z-axis</italic> and <italic>outside path</italic> conditions, the maximally active MSTd unit was the one that was sensitive to radial expansion (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e147" xlink:type="simple"/></inline-formula>). The positions of MSTd activity peaks in the <italic>Z-axis</italic> (black) and <italic>outside path</italic> (red) conditions were to the far left of the spiral space continuum. Radially expansion patterns contain no curvature, therefore, the model signals, similar to humans, in the <italic>Z-axis</italic> and <italic>outside path</italic> conditions that the path is straight.</p>
<p>To compute path error from representations of path curvature in the model, we have to ground the spiral continuum into perceptual space. When humans look where they are going, judgments of path curvature are accurate. This is most often the case during normal locomotion <xref ref-type="bibr" rid="pcbi.1003476-Li2">[26]</xref>, so we calibrate the model around the distribution of activity in model MSTd yielded in the natural gaze along heading condition (<xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7b</xref>, blue). We subtracted the spirality of the peak obtained in each condition (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e148" xlink:type="simple"/></inline-formula>) from that obtained in the gaze along heading condition to yield the model path error. We were able to configure the model such that no transformation of the subtraction in spiral space was required to yield the results shown in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7</xref>.</p>
<p>The ordinal positions of peaks shown in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7b</xref> correspond to path errors made by humans in the experiments of Li and Cheng <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. As mentioned above, the MSTd activity peaks in the <italic>Z-axis</italic> and <italic>outside path</italic> conditions are produced by units tuned to radial expansion. These peaks are positioned far to the left compared to the activity peak in the <italic>gaze along heading</italic> condition, indicated by the blue *. Subtraction of the abscissae of the peaks yields large magnitude negative path errors, consistent with the large underestimations of path curvature made by human subjects. The position of the activity peak in the <italic>on path</italic> condition (pink) is closer to that in the <italic>gaze along heading</italic> condition (blue *). This yields a negative path error, albeit lower in magnitude than those produced in the <italic>Z-axis</italic> and <italic>outside path</italic> conditions. Therefore, the model signals an underestimation of path curvature, consistent with the judgments of human subjects.</p>
<p>The bimodality observed in the MSTd activity distributions shown in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7b</xref> arise due to an interaction between the input optic flow, temporal dynamics, and competition in the model. Retinal flow that contains a large amount of rotation (e.g. inside path condition) yields activity peaks in units tuned to spiralities around 1. Conversely, flow that contains a small amount of rotation (e.g. Z-axis condition) yields activity peaks in units tuned to low spiralities around 0. Due to observer gaze, the rotational component in the optic flow changes over time during travel along the circular path. As a result, the activity peaks in model spiral space, such as those shown in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7b</xref>, “move” over time. Subpeaks arise, such as the “ripples” in the green curve, because at one point in the time history, a unit with the corresponding spirality of the subpeaks was most active. Competitive dynamics in the network suppress subpeaks over time. Although peaks in spiral space stabilized in the network, subpeaks were not always completely suppressed by the end of the trial. Because the projected CoM location and rotation in the optic flow vary nonlinearly with time (e.g. <xref ref-type="disp-formula" rid="pcbi.1003476.e110">Eq. 11</xref>), peaks are not always displaced to continuous locations in spiral space. This yields a bimodal distribution. Note that the “valley” between the peaks in the inside path and gaze along heading conditions arose due to the spatio-temporal characteristics of the input optic flow and the MSTd network. Peaks emerged within this region of spiral space when simulating travel along paths with different radii.</p>
<p><xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7c</xref> compares the average path errors produced by the model (solid lines) with those yielded by human subjects (dashed lines) in the five gaze conditions of Li and Cheng <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. Model path error is assessed on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e149" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e150" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e151" xlink:type="simple"/></inline-formula> radii circular paths with curvatures of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e152" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e153" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e154" xlink:type="simple"/></inline-formula>, respectively. Error bars in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7c</xref> correspond to the standard error of the mean (SEM) yielded over 100 simulations of the model. Our model is deterministic, but the random dot positions in the input introduced variance into the results. Model path estimates produced a good fit to those yielded by human subjects in the Z-axis (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e155" xlink:type="simple"/></inline-formula>), outside path (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e156" xlink:type="simple"/></inline-formula>), on path (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e157" xlink:type="simple"/></inline-formula>), inside path (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e158" xlink:type="simple"/></inline-formula>), and gaze along heading (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e159" xlink:type="simple"/></inline-formula>) conditions. Similar to human subjects, the model overestimated path curvature when gaze was inside of the path (green) that had the least curvature (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e160" xlink:type="simple"/></inline-formula>). As the path curvature increased, path curvature estimates in the model converged to those obtained in the gaze along heading condition. In the highest path curvature condition, the model path curvature estimates followed the tendency for humans to largely underestimate the path curvature in the on path, outside path, and Z-axis conditions. Across all conditions, the decrease in path error varied as a linear function of increasing path radius (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e161" xlink:type="simple"/></inline-formula>).</p>
<p>The dynamics in model MSTd explain why humans overestimate path curvature in the gaze inside path condition along paths with larger radii, but yield more accurate estimates when the path radius is small. In the gaze inside path condition (green), a bimodal distribution emerged in model MSTd. The activity peak occurred to the CCW center side of the spectrum, indicated by the green *, and a subpeak occurred closer to the middle of the spiral continuum, indicated by the green <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e162" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7b</xref>). Recall that path error is computed in the model by considering the distance between the peaks obtained in a particular condition and in the gaze along heading condition, indicated by the blue *. As shown in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7b</xref>, a subpeak exists in the gaze along heading condition, indicated by the blue <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e163" xlink:type="simple"/></inline-formula>, which is close to the peak in the gaze inside path condition (green *). When path curvature increases, more rotation is introduced into the optic flow, which changes the distribution of activity in MSTd spiral space. The subpeak in the gaze along heading condition (blue <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e164" xlink:type="simple"/></inline-formula>), becomes dominant and its proximity to the peak in the gaze inside path condition (green *) results in small path errors. Therefore, high path rotation brings the MSTd peaks (blue <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e165" xlink:type="simple"/></inline-formula> and green *) closer together in the gaze inside path and gaze along heading conditions, yielding close to zero path error. The opposite occurs when the path radius increases—the peak in the gaze along heading condition (blue *) shifts leftward in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7b</xref>, yielding larger path error.</p>
</sec><sec id="s3b">
<title>Path Perception and Eye Movements</title>
<p><xref ref-type="fig" rid="pcbi-1003476-g008">Figure 8</xref> plots the results of model simulations of the two experimental conditions of Cheng and Li, in which human subjects performed smooth pursuit eye movements to track a moving target <xref ref-type="bibr" rid="pcbi.1003476-Cheng1">[25]</xref>. Path errors produced by our model fit the human data well in both the orientation along heading (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e166" xlink:type="simple"/></inline-formula>) and orientation along Z axis (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e167" xlink:type="simple"/></inline-formula>) conditions. Model gain fields modulate the optic flow signal proportional to the mean eye tracking speeds of human subjects, which increase with path curvature. Model gain fields modulate the optic flow signal proportional to the mean eye tracking speeds of human subjects, which increase with path curvature. Subjects tracked a target moving in the direction of the drift in FoE position in the orientation along Z-axis condition. The only source of rotation in the optic flow field is that due to pursuit eye-movements, the gain field adds rotation in the opposite direction with a pursuit-speed proportional magnitude, effectively nulling the rotation and producing a translation-only optic flow field. The model increasingly underestimates the path curvature as the curvature increases because the combined effect of rotation due to path curvature, rotation due to eye-movements, and rotation added by the gain-fields is a rotation component of the flow field that is less than would be observed due to path curvature alone. As a result, model path errors are small.</p>
<fig id="pcbi-1003476-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g008</object-id><label>Figure 8</label><caption>
<title>Model path error in conditions that involve smooth pursuit eye movements.</title>
<p>The optic flow that appears on the observer retinal during smooth pursuit of a horizontally moving target is identical in the orientation along heading and orientation along Z-axis conditions. The orientation along heading condition is similar to the gaze along heading condition, except the observer tracks a target that moves in the direction <italic>opposite</italic> of the path curvature. The orientation along Z-axis condition is similar to the Z-axis condition, except the observer tracks a target that moves in the <italic>same</italic> direction of the path curvature. Similar to human subjects, the model yields low path errors for all the path radius conditions because model gain fields compensate in the direction opposite that of the eye movements. The model increasingly underestimates path curvature in the orientation along Z-axis condition, similar to humans.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g008" position="float" xlink:type="simple"/></fig></sec><sec id="s3c">
<title>Heading</title>
<p>In <xref ref-type="fig" rid="pcbi-1003476-g009">Figure 9a</xref>, model heading bias in the outside path, on path, and inside path conditions is compared to that of human subjects in the experiments of Li and Cheng <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. Heading is represented in the model as the preferred 2D visuotopic position of the maximally active MSTd neurons (see <xref ref-type="sec" rid="s2">Materials and Methods</xref>). Positive and negative heading errors correspond to heading judgments biased in the direction of and opposite to the path curvature, respectively. Human heading judgments were slightly biased outside the path in the outside path and on path conditions, and more greatly biased toward the inside of the path in the inside path condition (<xref ref-type="fig" rid="pcbi-1003476-g009">Figure 9a</xref>, red) <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. The model produced similar heading errors, but unlike the human data, model heading estimates were veridical in the outside path condition. This occurred because the model was not sensitive enough to detect differences between the MSTd activity peaks in the Z-axis and outside path conditions (<xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7b</xref>), so the model signals the veridical heading. Neither heading errors produced by the human subjects nor by the model were influenced by the path radius.</p>
<fig id="pcbi-1003476-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g009</object-id><label>Figure 9</label><caption>
<title>Heading errors produced by the model during travel along a circular path.</title>
<p>Positive and negative heading errors indicate bias in heading judgments in the direction of and the direction opposite to the path curvature, respectively. The model and humans produced small negative heading errors in the on path condition, and more substantial positive bias in the inside path condition. The model yielded veridical heading performance in the outside path condition, which occurred because the model is not sensitive enough to differences in the optic flow in the outside path and Z-axis conditions. Heading bias in the model is preserved over time without (b) and with (c) competition in MSTd.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g009" position="float" xlink:type="simple"/></fig>
<p><xref ref-type="fig" rid="pcbi-1003476-g009">Figures 9b–c</xref> depict the temporal evolution of the spatial distribution in MSTd among units sensitive to radial expansion without competition (<xref ref-type="fig" rid="pcbi-1003476-g009">Figures 9b</xref>) and with competition (<xref ref-type="fig" rid="pcbi-1003476-g009">Figures 9c</xref>). The x-axis corresponds to MSTd unit FoE selectivity to particular horizontal locations within the visual field. The simulation is of the Z-axis condition, wherein the instantaneous optic flow is always expanding radially without rotation, and <xref ref-type="fig" rid="pcbi-1003476-g009">Figures 9c</xref> shows the activity of model neurons tuned to radial expansion. The visuotopic positions of the activity peaks in MSTd do not change due to the competition, but the model competitive interactions sharpen the spatial distribution. Any heading bias therefore is preserved in the model through the competition in MSTd.</p>
</sec><sec id="s3d">
<title>Simulated Rotation</title>
<p>In human psychophysical studies that employ a simulated eye rotation condition, the observer moves on a straight path with an added amount of rotation <xref ref-type="bibr" rid="pcbi.1003476-Royden2">[11]</xref>. However, human subjects report the perception of moving along a curved path <xref ref-type="bibr" rid="pcbi.1003476-Royden4">[15]</xref>. We tested whether our model produces similar heading bias to human subjects in the simulated rotation condition, which would offer an mechanistic explanation of the curved path percepts. To compute heading bias, we compared the heading garnered by the model in the gaze along heading condition with that obtained when simulating observer travel along a straight path with added rotation rates between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e168" xlink:type="simple"/></inline-formula>. We simulated travel toward two fronto-parallel planes and otherwise mimicked experiment 2 of Royden et al. <xref ref-type="bibr" rid="pcbi.1003476-Royden2">[11]</xref>. <xref ref-type="fig" rid="pcbi-1003476-g010">Figure 10</xref> depicts model heading bias (blue) for different amounts of simulated rotation fitted by a hyperbolic tangent function (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e169" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e170" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e171" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e172" xlink:type="simple"/></inline-formula>). The red curve in <xref ref-type="fig" rid="pcbi-1003476-g010">Figure 10</xref> shows the hyperbolic tangent function fit (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e173" xlink:type="simple"/></inline-formula>) to mean human data from <xref ref-type="bibr" rid="pcbi.1003476-Royden2">[11]</xref>. The sigmoidal functions fit the human data and model well, and the two were well correlated with one another (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e174" xlink:type="simple"/></inline-formula>). <xref ref-type="fig" rid="pcbi-1003476-g010">Figure 10</xref> shows that heading was biased in the direction of the simulated rotation, which is the same sign of error observed in <xref ref-type="fig" rid="pcbi-1003476-g009">Figure 9a</xref>. Therefore, both the model and humans data exhibit heading bias in the simulated rotation condition, which may explain the curved path percepts in humans.</p>
<fig id="pcbi-1003476-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g010</object-id><label>Figure 10</label><caption>
<title>Heading bias yielded by the model in the simulated rotation condition with rotation rates between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e175" xlink:type="simple"/></inline-formula>.</title>
<p>When human subjects fixate on optic flow displays wherein an observer moves along a straight path with rotation, humans make large heading errors in the direction of the simulated rotation and report the perception of travel along a curved path. The model (blue) produced the same sigmoidal pattern of heading bias as human subjects (red). Both sets of data points were fit well with a hyperbolic tangent function. The similarity between model and human heading bias, suggests the model mechanisms can explain the curved path percept reported by human subjects.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g010" position="float" xlink:type="simple"/></fig></sec><sec id="s3e">
<title>Is Competition in MSTd Necessary?</title>
<p>Our model incorporates competitive dynamics across a spiral space. To determine whether competition across spirality, spiral orientation (CW v.s. CCW), and visuotopic space in model MSTd was necessary to produce path errors comparable to humans, we selectively lesioned certain competitive interactions between model neurons. Path errors were computed by comparing the peak activity in spiral space to that obtained in the gaze along heading condition, as in the unlesioned case. <xref ref-type="fig" rid="pcbi-1003476-g011">Figure 11</xref> compares human and intact model mean path errors with those produced when the three types of competition in the model were lesioned. In all cases, omitting a particular type of competitive interaction in the model resulted in changes in path errors. For instance, lesioning the horizontal spatial interactions between model MSTd neurons resulted in a shift and compression in path error across all path radii: the path errors for the inside path, on path, and gaze along heading conditions converged to the same value for each path radius, and path errors in the Z-axis and outside path conditions converged to a different value. Introducing lesions into model MSTd connections garnered results that did not exhibit the same pattern as human judgments. Human behavioral performance is compatible with the use of competitive interactions between subpopulations of cells in MSTd.</p>
<fig id="pcbi-1003476-g011" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g011</object-id><label>Figure 11</label><caption>
<title>The impact lesions to model MSTd have on path error.</title>
<p>The mean path errors for human subjects and the model from <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7</xref> are plotted on the two leftmost data columns for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e176" xlink:type="simple"/></inline-formula> (a), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e177" xlink:type="simple"/></inline-formula> (b), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e178" xlink:type="simple"/></inline-formula> (c) radius paths. Lesions were introduced in the model MSTd connectivity by zeroing out competitive interactions in spiral space, across spiral orientation, and across 2D space between neurons in MSTd (see <xref ref-type="disp-formula" rid="pcbi.1003476.e067">Eq. 6</xref>). Lesions had a detrimental impact on model performance, and path curvature estimates no longer mapped onto human judgments. The three competitive interactions in model MSTd were necessary to obtain our results.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g011" position="float" xlink:type="simple"/></fig></sec><sec id="s3f">
<title>Different Dot Densities</title>
<p>We tested the model stability and path curvature estimation performance as a function of the number of dots in the scene. The path curvature judgments made by human subjects in the experiments of Li and Cheng <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref> and the model results shown in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7</xref> were derived from environments with 200 dots. <xref ref-type="fig" rid="pcbi-1003476-g012">Figure 12</xref> shows model performance across the path curvature conditions as function of scene dot count. The y axis plots the <italic>path error deviation</italic>, which indicates the relative path error compared to that obtained with 200 dots. Independent of the path radius, the model yields reliable results, with modest mean path error deviations (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e179" xlink:type="simple"/></inline-formula>) even with only 25 dots. Human path curvature judgments have been tested in environments containing different dot densities in conditions that most closely resemble those in the gaze along heading condition, and model produces similar errors to these human data <xref ref-type="bibr" rid="pcbi.1003476-Warren5">[27]</xref>. Path errors in scenes with greater numbers of dots than 200 also yielded low magnitude path error deviations, which indicates that the model results shown in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7</xref> are stable and model parameters did not overfit the human data.</p>
<fig id="pcbi-1003476-g012" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g012</object-id><label>Figure 12</label><caption>
<title>Robustness in model path curvature estimates for scenes containing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e180" xlink:type="simple"/></inline-formula>–<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e181" xlink:type="simple"/></inline-formula>.</title>
<p>The deviation in path errors from those shown in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7</xref> are plotted for path radii of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e182" xlink:type="simple"/></inline-formula> (a), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e183" xlink:type="simple"/></inline-formula> (b), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e184" xlink:type="simple"/></inline-formula> (c), respectively. Deviations in path error were modest, with mean errors falling within <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e185" xlink:type="simple"/></inline-formula> of those depicted in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7</xref>. There were only small deviations in any condition when the scene contained at least <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e186" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g012" position="float" xlink:type="simple"/></fig></sec><sec id="s3g">
<title>Path Selective Neurons</title>
<p><xref ref-type="fig" rid="pcbi-1003476-g013">Figure 13a</xref> shows a model simulation of first-order optic flow experienced by the monkey in the experiments of Froehler and Duffy <xref ref-type="bibr" rid="pcbi.1003476-Froehler1">[43]</xref>. The gaze of the monkey traveling along the circular track was tantamount to that of the Z-axis condition. Therefore, according to traditional theory, and the assumptions of the experimenters, the radial subpopulation of cells in MSTd was expected to be maximally active due to the absence of rotation in the instantaneous optic flow field. However, in our simulations the maximally active model MSTd subpopulation was tuned to spiral patterns rather than those that are radial (dark orange). When the angular rotation rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e187" xlink:type="simple"/></inline-formula> exceeded that used by Froehler and Duffy <xref ref-type="bibr" rid="pcbi.1003476-Froehler1">[43]</xref> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e188" xlink:type="simple"/></inline-formula>), MSTd neurons in the model tuned to spiral patterns remained the most active. When the angular rotation rate was comparable to that used in the <italic>Z-axis</italic> condition of Li and Cheng (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e189" xlink:type="simple"/></inline-formula>), the model neurons selective to radial patterns were most active. Our analysis indicates that temporal accumulation due to the dynamical properties of the MSTd model (<xref ref-type="disp-formula" rid="pcbi.1003476.e067">Eq. 6</xref>) and the distance-dependent weighting (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e190" xlink:type="simple"/></inline-formula>, see <xref ref-type="disp-formula" rid="pcbi.1003476.e057">Eq. 5</xref>) induced a peak shift in spiral space, from neurons sensitive to radial patterns to those sensitive to spirals. As shown in <xref ref-type="fig" rid="pcbi-1003476-g013">Figure 13b</xref>, the temporal accumulation and spatial weightings transform the sequence of radial patterns with a ‘drifting’ FoE into a spiral pattern with a fixed FoE. When the speed around the circle is slower than that of the monkey in the experiments of Froehler and Duffy, the activity in MSTd spiral space is distributed so that the subpopulation of units tuned to radial expansion is most active. At higher speeds around the circle, the position of the MSTd peak shifts so that units sensitive to spiral patterns are most active (<xref ref-type="fig" rid="pcbi-1003476-g013">Figure 13</xref>). The peak shift occurs at higher speeds because the temporal dynamics ‘blur’ the flow fields and the spatial weighting distorts the flow near the FoE. Our analysis suggests that the path selective neurons identified by Froehler and Duffy in MSTd are in fact preferentially tuned to spiral patterns, and the spiral space competition employed in our model can explain the mechanism underlying their path selective properties. We predict that if Froehler and Duffy performed their experiment at slower rotation rates, decreased spatio-temporal accumulation would occur and fewer MSTd neurons would yield a differential CCW versus CW path selectivity. In addition, we predict that if Li and Cheng simulate travel along circular paths at faster rotation rates in the Z-axis condition, subjects would underestimate path curvature to a lesser degree.</p>
<fig id="pcbi-1003476-g013" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003476.g013</object-id><label>Figure 13</label><caption>
<title>Model simulation of the experiment of Froehler and Duffy <xref ref-type="bibr" rid="pcbi.1003476-Froehler1">[43]</xref>.</title>
<p>(a) Responses of the maximally-active model MSTd subpopulations in spiral space as a function of the angular rotation rate (i.e. how fast the circular path is traversed per unit of time). When the angular rotation rate matched that used by Froehler and Duffy (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e191" xlink:type="simple"/></inline-formula>, dark orange), model MSTd neurons most sensitive to spiral patterns were most active. This also occurred when for larger angular rotation rates (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e192" xlink:type="simple"/></inline-formula>). When the angular rotation was set to a comparable rate to that used in the <italic>Z-axis</italic> condition <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e193" xlink:type="simple"/></inline-formula>), model MSTd neurons most sensitive to radial expansion elicited the maximal activation. (b) Simplified model mechanisms that explain why neurons that are sensitive to spirals produced the peak activity in spiral space in the simulation of the Froehler and Duffy experiment, but did not in the simulation of the <italic>Z-axis</italic> condition. Consider the first-order optic flow (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e194" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e195" xlink:type="simple"/></inline-formula>) at two times (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e196" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e197" xlink:type="simple"/></inline-formula>) during the circular path traversal (top row). Template matching in the model is inversely weighted by distance to the FoE or CoM (second row). The third row shows the optimal templates inversely weighted by distance (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e198" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e199" xlink:type="simple"/></inline-formula>). Because model MSTd dynamically integrates afferent signals from model MT, activation due to the input at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e200" xlink:type="simple"/></inline-formula> influences the activation due to the input at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e201" xlink:type="simple"/></inline-formula>. Temporal accumulation in the model can be approximated by considering <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e202" xlink:type="simple"/></inline-formula>, which temporally blends the two weighted fields. This yields a spiral field (bottom row), and explains why model MSTd neurons sensitive to spiral patterns are most active when the angular rotation rate about the circular path is sufficiently large.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003476.g013" position="float" xlink:type="simple"/></fig></sec></sec><sec id="s4">
<title>Discussion</title>
<p>In this article, we present experiments using a computational model of the primate dorsal stream to test our claim that area MSTd can simultaneously code heading and path curvature. We posit that the underlying mechanism involves competition between neurons in MSTd that are sensitive to large field spiral motion patterns. Electrophysiological data support our definition of MSTd spiral tuning space as a continuum, ranging from radial expansion or contraction to CW and CCW center motion patterns (<xref ref-type="fig" rid="pcbi-1003476-g003">Figure 3</xref>). We tested our spiral coding hypothesis through model simulations of observers moving along curvilinear paths, and comparing results to those garnered by studies of human path perception. We simulated the experiments of Li and Cheng, wherein observers viewed displays simulating travel along circular paths with different radii and loci of gaze <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. The model produced similar errors to humans that maintained five different patterns of gaze (<xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7</xref>). This indicates that, similar to human subjects, perception of path curvature is underestimated when gaze is along a fixed direction in the world (along the ‘Z-axis’), outside the path, and on a location down the future path; overestimated with gaze is inside the path; and relatively accurate when gaze changes such that it is always in the heading direction (i.e. tangent to the circle). <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7b</xref> shows that the model explains the human path errors through the rank ordering of activity peaks distributed along the MSTd spiral space sensitivity continuum. Overestimations and underestimations of path curvature occur in the model because each pattern of gaze influenced the retinal rotation differently over time. This shifted activity peaks in MSTd spiral space compared to the peak yielded when the observer was simulated to look where he was going, which commonly occurs during natural locomotion. The steady-state shifts in MSTd population activity compared to the natural gaze along heading gaze condition to which the model is calibrated results in systematic biases in path curvature estimation, similar to human subjects.</p>
<p>The reasons for comparing MSTd activity peaks in spiral space to that obtained in the gaze along heading condition are twofold. First, directing gaze in the direction of the heading naturally occurs in many activities, such as locomotion and driving. Aligning gaze along heading appears to be important for human perception of path because only in this gaze condition did humans accurately assess the path curvature <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. The results of Li and Cheng are supported by a number of similar studies <xref ref-type="bibr" rid="pcbi.1003476-Fajen2">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Saunders1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Warren5">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Saunders2">[28]</xref>. When human mothers carry their infants, statistics during locomotion indicate that gaze is most often maintained within <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e203" xlink:type="simple"/></inline-formula> of the heading direction <xref ref-type="bibr" rid="pcbi.1003476-Raudies2">[60]</xref>. Second, human perception of metric space has been demonstrated to be inaccurate and it therefore would seem more likely that humans perceive path relative to conditions afforded during normal locomotion (i.e. when gaze naturally changes with heading direction) rather than perceiving path in absolute terms. For example, humans exhibit distorted judgments of distance and slant <xref ref-type="bibr" rid="pcbi.1003476-Norman1">[61]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Witt1">[62]</xref>. The rank order of the model MSTd activity peak positions in spiral space followed that of path errors made by human subjects (<xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7</xref>) across different gaze and path curvature conditions. This supports the idea that humans perceive their path of travel by using the pattern of MSTd activity yielded during natural location as a reference for when gaze changes.</p>
<sec id="s4a">
<title>Path Perception in Different Visual Scenes</title>
<p>In the experiments of Li and Cheng, human path errors were not modulated by the structure of the visual scene <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. Our simulations demonstrated that model performance was only modestly impacted by the dot density of the ground plane (<xref ref-type="fig" rid="pcbi-1003476-g012">Figure 12</xref>). This is consistent with the findings of Li and Cheng that denser textured environments did not modulate human path judgments. The robustness of the model results to dot density is also consistent with findings that indicate that path perception does not depend on local features in the environment <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. The stability of path errors across different types of scenes in humans and the model suggests that mechanisms underlying path perception depend on areas such as MSTd that prefer stimulation by large field pattern motion.</p>
<p>Existing studies of path perception have explored path perception during travel along ground planes <xref ref-type="bibr" rid="pcbi.1003476-Saunders1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>. We are unaware of investigations that explored other environmental structures, such as 3D dot clouds and fronto-parallel planes. Model simulations mainly contained ground plane environments due to their natural relevance to human locomotion and the availability of psychophysical data. To investigate the simulated rotation condition with our model, we mimicked the conditions of experiment 2 of Royden et al., which contained two dot fronto-parallel planes <xref ref-type="bibr" rid="pcbi.1003476-Royden2">[11]</xref>. More work needs to be done to assess human path perception in different types of environments.</p>
</sec><sec id="s4b">
<title>Simulated Rotation</title>
<p>The simulated rotation condition of Royden presents an interesting test for the model <xref ref-type="bibr" rid="pcbi.1003476-Royden2">[11]</xref>. We hypothesize that humans perceive that they are traveling along a curved path in the simulated rotation condition due to the activation of spiral-selective neurons in MSTd. Our hypothesis is supported by simulations that demonstrate that spiral-selective units, not those tuned to radial expansion, are maximally active in the simulated rotation condition. Conversely, in the Z-axis condition of Li and Cheng, human subjects responded as if they were traversing a straight path despite actually traveling along a curved path. In this case, model neurons tuned to radial expansion produced the most activity, which signals a lack of path curvature and is consistent with human path errors. In the simulated rotation and Z-axis conditions, the spiral space mechanisms in the model correctly predict the perceived path curvature. This suggests that humans rely on retinal rotation (i.e. rotation not due to extra-retinal sources) to perceive the curvilinear path and that MSTd neuronal tuning to spirals extracts information about path curvature. The large heading biases produced by humans in the presence of retinal rotation <xref ref-type="bibr" rid="pcbi.1003476-Royden2">[11]</xref> is consistent with the finding of Orban and colleagues that MSTd neurons tuned to expansion do not appear to compensate for rotational components in the optic flow field, except when accompanied by an extra-retinal signal <xref ref-type="bibr" rid="pcbi.1003476-Orban2">[44]</xref>.</p>
<p>Interestingly, the environments and rotation rates tested by Li and Cheng and Royden et al. are remarkably similar, yet our model yields different heading bias in each of these experimental conditions reflecting the differences found in humans (compare <xref ref-type="fig" rid="pcbi-1003476-g009">Figure 9a</xref> and <xref ref-type="fig" rid="pcbi-1003476-g010">10</xref>). In particular, experiments 4 and 5 in the Royden et al. study both use ground planes defined by random dot patterns, with rotation rates in the range of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e204" xlink:type="simple"/></inline-formula>. Despite these similarities in the instantaneous optic flow fields, human heading bias reached <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e205" xlink:type="simple"/></inline-formula> in the Royden et al. study and it did not exceed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e206" xlink:type="simple"/></inline-formula> in the experiment of Li and Cheng. The difference in heading bias may be attributed to spatio-temporal differences in the optic flow displays. As a dynamical system, our model responds differently to different spatio-temporal optic flow evolution <xref ref-type="bibr" rid="pcbi.1003476-Royden4">[15]</xref>. Rather than using a ground plane with a uniform dot density similar to that of Royden and colleagues, Li and Cheng distributed dots to maintain a constant density at different depths within the observer's field of view. This manipulation increased motion parallax in the displays, which has been shown to improve the accuracy of heading judgments <xref ref-type="bibr" rid="pcbi.1003476-Li6">[36]</xref>. There were only 220 dots visible at the trial outset in the experiments of Royden and colleagues compared to 300 in the displays of Li and Cheng. Differences in motion parallax and dot density may account for the disparity in heading bias between the two studies.</p>
<p>It is also possible that subjects in the experiments of Royden et al. reported perceived path rather than heading. Our model provides a good quantitative fit to the heading bias in both studies. Only the spatio-temporal structure of the displays used to simulate the studies differed. If we assume that human subjects followed the experimental instructions, then our fit of the data is consistent with the reporting of heading. However, if we assume that subjects attempted to indicate the curvature of their path, then the interpretation of our data fit is incorrect.</p>
</sec><sec id="s4c">
<title>Representation of Path Curvature in MSTd</title>
<p>The activity curves in model MSTd spiral space (<xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7<italic>b</italic></xref>) exhibit different widths and sharpnesses. Because model MSTd was configured as a soft winner-take-all network (<xref ref-type="disp-formula" rid="pcbi.1003476.e067">Eq. 6</xref>), given sufficient time, the network will select a single MSTd unit to be active and all other model neurons will be suppressed through competition. The winning unit signals the path curvature through its pattern selectivity in spiral space. As noted in other computational studies <xref ref-type="bibr" rid="pcbi.1003476-Layton1">[51]</xref>–<xref ref-type="bibr" rid="pcbi.1003476-Browning2">[53]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Browning3">[57]</xref>, broad activation in the network could implicate a greater degree of uncertainty about the path curvature and the dynamical competitive interactions require longer to resolve a high confidence solution. We configured model MSTd with a single set of parameters, but it is possible <italic>in vivo</italic> that different subpopulations exhibit differential response latencies <xref ref-type="bibr" rid="pcbi.1003476-Layton3">[63]</xref>.</p>
<p>As depicted in <xref ref-type="fig" rid="pcbi-1003476-g007">Figure 7b</xref>, simulations of travel along curved paths gives rise to complex distributions of activity across MSTd that are important to how the model encodes heading and path. It is unclear how the brain decodes this information that is distributed across the MSTd population. We believe the population activity is important to heading and path perception, and taking the argmax just provides a simple and straightforward method to assess model performance and properties about the MSTd population. Because competitive dynamics occur while input optic flow signals remain present, a total suppression of the activity of the non-winning units is not guaranteed to occur <xref ref-type="bibr" rid="pcbi.1003476-Layton1">[51]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Layton3">[63]</xref>. The argmax operation allows us to read out information about the most active model unit to understand model performance, and is not part of the model's operation. The winner-take-all mechanism is part to the model's operation, and as indicated by our results (<xref ref-type="fig" rid="pcbi-1003476-g011">Figure 11</xref>), represents an important characteristic of the model that allows it to fit the human data.</p>
<p>We selected spiral templates in the model to resemble the optic flow patterns used in a number of electrophysiological studies <xref ref-type="bibr" rid="pcbi.1003476-Graziano1">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Read1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1003476-Duffy3">[64]</xref> to investigate large motion pattern selectivity in neurons located in MSTd and other areas of the STS. Although electrophysiological studies report tuning in the spiral space that spans radial expansion, contraction, and center fields, actual MSTd neuron receptive fields may exhibit far greater complexity. Pack and colleagues modeled the feedforward subunit structure of MSTd neurons based on single-cell recordings and discovered complicated subunit configurations that deviated from characteristic radial, spiral, and center motion patterns <xref ref-type="bibr" rid="pcbi.1003476-Mineault1">[49]</xref>. Feedback and other types of horizontal connectivity was not modeled, and only <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003476.e207" xlink:type="simple"/></inline-formula> of the MSTd response variance was accounted for, so the actual receptive fields of MSTd units are likely even more complex. MSTd receptive fields may follow the motion statistics experienced by primates during ecological locomotion along a ground surface. For instance, model templates spanned the entire visual field, but ‘ecological templates’ may be biased toward the lower portion of the visual field. The statistics of videos collected from head-mounted cameras on human mothers carrying infants show that the optic flow during locomotion is fairly evenly distributed across expanding, contracting, upward, downward, CW, and CCW motion patterns, with a bias for expansion <xref ref-type="bibr" rid="pcbi.1003476-Raudies2">[60]</xref>. The selectivity of MSTd neurons in the sample of Graziano and colleagues also are biased toward expansive motion patterns. Humans accurately judge heading in environments with many different structures, even with dynamic occlusion, unless the textures become unstructured <xref ref-type="bibr" rid="pcbi.1003476-Kim2">[30]</xref>. Therefore, ecological statistics may be important for guiding the development of MSTd receptive fields.</p>
</sec><sec id="s4d">
<title>Path Selective Cells</title>
<p>In simulating monkey movement along a circular path, we found that the location of the MSTd activity peak in spiral space depended on the speed at which the circular path is traversed. At speeds slower around the circular track than that used by Froehler and Duffy, the optic flow more closely mimicked the Z-axis condition of Li and Cheng <xref ref-type="bibr" rid="pcbi.1003476-Li3">[31]</xref>, and the subpopulation of MSTd neurons tuned to radial expansion was most active—thereby signaling travel along a straight path. However, when the path traversal speed equaled or exceeded that used in the study of Froehler and Duffy <xref ref-type="bibr" rid="pcbi.1003476-Froehler1">[43]</xref>, the activity peak shifted rightward, signaling navigation along a curved path. Our analysis indicates that at a sufficiently fast speed around the track, the motion signal MSTd neurons receive in the experiment of Froehler and Duffy is temporally ‘blurred’ and actually resembles a spiral pattern (<xref ref-type="fig" rid="pcbi-1003476-g013">Figure 13</xref>). Froehler and Duffy did not report testing selectivity to spirals in their sample. Our analysis and simulation results predict that the path selective neurons discovered by Froehler and Duffy were tuned to spirals rather than expansion patterns. We predict that human subjects would produce path curvature judgments consistent with the percept of traveling along a curved path in a psychophysical experiment with the Z-axis gaze condition when the rotation rate along the circle is increased. In this proposed experiment, the model makes the prediction that humans would produce different path errors in the <italic>Z-axis condition</italic>, depending on how much of and the speed at which the circular path is traversed.</p>
<p>Our model results suggest information about future path may be processed in areas as early as MSTd. Path estimation may more fundamentally indicate the functional role of area MSTd in primates.</p>
</sec></sec></body>
<back><ref-list>
<title>References</title>
<ref id="pcbi.1003476-Gibson1"><label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">Gibson JJ (1979) The Ecological Approach To Visual Perception. Psychology Press : 1–174.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Warren1"><label>2</label>
<mixed-citation publication-type="book" xlink:type="simple">Warren WH (1998) The State of Flow. In: Watanabe T, editor, High-level motion processing, Cambridge: MIT Press. pp. 315–358.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Warren2"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Warren</surname><given-names>WHW</given-names></name>, <name name-style="western"><surname>Morris</surname><given-names>MWM</given-names></name>, <name name-style="western"><surname>Kalish</surname><given-names>MM</given-names></name> (<year>1988</year>) <article-title>Perception of translational heading from optical flow</article-title>. <source>Journal of experimental psychology Human perception and performance</source> <volume>14</volume>: <fpage>646</fpage>–<lpage>660</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-vandenBerg1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Berg</surname><given-names>AVA</given-names></name> (<year>1992</year>) <article-title>Robustness of perception of heading from optic flow</article-title>. <source>Vision research</source> <volume>32</volume>: <fpage>1285</fpage>–<lpage>1296</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-vandenBerg2"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Berg</surname><given-names>AV</given-names></name> (<year>1996</year>) <article-title>Judgements of heading</article-title>. <source>Vision research</source> <volume>36</volume>: <fpage>2337</fpage>–<lpage>2350</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Rieger1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rieger</surname><given-names>JHJ</given-names></name>, <name name-style="western"><surname>Lawton</surname><given-names>DTD</given-names></name> (<year>1985</year>) <article-title>Processing differential image motion</article-title>. <source>J Opt Soc Am A</source> <volume>2</volume>: <fpage>354</fpage>–<lpage>360</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Hildreth1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hildreth</surname><given-names>EC</given-names></name> (<year>1992</year>) <article-title>Recovering heading for visually-guided navigation</article-title>. <source>Vision research</source> <volume>32</volume>: <fpage>1177</fpage>–<lpage>1192</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Warren3"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Warren</surname><given-names>WH</given-names></name>, <name name-style="western"><surname>Saunders</surname><given-names>JA</given-names></name> (<year>1995</year>) <article-title>Perceiving heading in the presence of moving objects</article-title>. <source>Perception</source> <volume>24</volume>: <fpage>315</fpage>–<lpage>331</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Royden1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Royden</surname><given-names>CS</given-names></name> (<year>2002</year>) <article-title>Computing heading in the presence of moving objects: a model that uses motion-opponent operators</article-title>. <source>Vision research</source> <volume>42</volume>: <fpage>3043</fpage>–<lpage>3058</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Warren4"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Warren</surname><given-names>WHW</given-names></name>, <name name-style="western"><surname>Hannon</surname><given-names>DJD</given-names></name> (<year>1990</year>) <article-title>Eye movements and optical flow</article-title>. <source>J Opt Soc Am A</source> <volume>7</volume>: <fpage>160</fpage>–<lpage>169</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Royden2"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Royden</surname><given-names>CS</given-names></name>, <name name-style="western"><surname>Crowell</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name> (<year>1994</year>) <article-title>Estimating heading during eye movements</article-title>. <source>Vision research</source> <volume>34</volume>: <fpage>3197</fpage>–<lpage>3214</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Royden3"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Royden</surname><given-names>CS</given-names></name>, <name name-style="western"><surname>Banks</surname><given-names>MSM</given-names></name>, <name name-style="western"><surname>Crowell</surname><given-names>JAJ</given-names></name> (<year>1992</year>) <article-title>The perception of heading during eye movements</article-title>. <source>Nature</source> <volume>360</volume>: <fpage>583</fpage>–<lpage>585</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Ehrlich1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ehrlich</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Beck</surname><given-names>DM</given-names></name>, <name name-style="western"><surname>Crowell</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Freeman</surname><given-names>TC</given-names></name>, <name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name> (<year>1998</year>) <article-title>Depth information and perceived self-motion during simulated gaze rotations</article-title>. <source>Vision research</source> <volume>38</volume>: <fpage>3129</fpage>–<lpage>3145</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Li1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Sweet</surname><given-names>BT</given-names></name>, <name name-style="western"><surname>Stone</surname><given-names>LS</given-names></name> (<year>2006</year>) <article-title>Humans can perceive heading without visual path information</article-title>. <source>Journal of Vision</source> <volume>6</volume>: <fpage>2</fpage>–<lpage>2</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Royden4"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Royden</surname><given-names>CS</given-names></name> (<year>1994</year>) <article-title>Analysis of misperceived observer motion during simulated eye rotations</article-title>. <source>Vision research</source> <volume>34</volume>: <fpage>3215</fpage>–<lpage>3222</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Bradley1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bradley</surname><given-names>DCD</given-names></name>, <name name-style="western"><surname>Maxwell</surname><given-names>MM</given-names></name>, <name name-style="western"><surname>Andersen</surname><given-names>RAR</given-names></name>, <name name-style="western"><surname>Banks</surname><given-names>MSM</given-names></name>, <name name-style="western"><surname>Shenoy</surname><given-names>KVK</given-names></name> (<year>1996</year>) <article-title>Mechanisms of heading perception in primate visual cortex</article-title>. <source>Science</source> <volume>273</volume>: <fpage>1544</fpage>–<lpage>1547</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Shenoy1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shenoy</surname><given-names>KVK</given-names></name>, <name name-style="western"><surname>Bradley</surname><given-names>DCD</given-names></name>, <name name-style="western"><surname>Andersen</surname><given-names>RAR</given-names></name> (<year>1999</year>) <article-title>Inuence of gaze rotation on the visual response of primate MSTd neurons</article-title>. <source>Journal of Neurophysiology</source> <volume>81</volume>: <fpage>2764</fpage>–<lpage>2786</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Shenoy2"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shenoy</surname><given-names>KV</given-names></name> (<year>2002</year>) <article-title>Pursuit Speed Compensation in Cortical Area MSTd</article-title>. <source>Journal of Neurophysiology</source> <volume>88</volume>: <fpage>2630</fpage>–<lpage>2647</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Churchland1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Churchland</surname><given-names>MM</given-names></name>, <name name-style="western"><surname>Priebe</surname><given-names>NJ</given-names></name>, <name name-style="western"><surname>Lisberger</surname><given-names>SG</given-names></name> (<year>2005</year>) <article-title>Comparison of the Spatial Limits on Direction Selectivity in Visual Areas MT and V1</article-title>. <source>Journal of Neurophysiology</source> <volume>93</volume>: <fpage>1235</fpage>–<lpage>1245</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Elder1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elder</surname><given-names>DM</given-names></name>, <name name-style="western"><surname>Grossberg</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Mingolla</surname><given-names>E</given-names></name> (<year>2009</year>) <article-title>A neural model of visually guided steering, obstacle avoidance, and route selection</article-title>. <source>Journal of experimental psychology Human perception and performance</source> <volume>35</volume>: <fpage>1501</fpage>–<lpage>1531</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Rushton1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rushton</surname><given-names>SK</given-names></name>, <name name-style="western"><surname>Harris</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Lloyd</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Wann</surname><given-names>JP</given-names></name> (<year>1998</year>) <article-title>Guidance of locomotion on foot uses perceived target location rather than optic flow</article-title>. <source>Current Biology</source> <volume>8</volume>: <fpage>4</fpage>–<lpage>4</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Fajen1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fajen</surname><given-names>BR</given-names></name>, <name name-style="western"><surname>Warren</surname><given-names>WH</given-names></name> (<year>2007</year>) <article-title>Behavioral dynamics of intercepting a moving target</article-title>. <source>Experimental Brain Research</source> <volume>180</volume>: <fpage>303</fpage>–<lpage>319</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Fajen2"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fajen</surname><given-names>BR</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>NG</given-names></name> (<year>2002</year>) <article-title>Perceiving curvilinear heading in the presence of moving objects</article-title>. <source>Journal of experimental psychology Human perception and performance</source> <volume>28</volume>: <fpage>1100</fpage>–<lpage>1119</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Saunders1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saunders</surname><given-names>JA</given-names></name> (<year>2010</year>) <article-title>View rotation is used to perceive path curvature from optic flow</article-title>. <source>Journal of Vision</source> <volume>10</volume>: <fpage>25</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Cheng1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cheng</surname><given-names>JCK</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>L</given-names></name> (<year>2012</year>) <article-title>Effects of reference objects and extra-retinal information about pursuit eye movements on curvilinear path perception from retinal flow</article-title>. <source>Journal of Vision</source> <volume>12</volume>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Li2"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Cheng</surname><given-names>JCK</given-names></name> (<year>2011</year>) <article-title>Heading but not path or the tau-equalization strategy is used in the visual control of steering toward a goal</article-title>. <source>Journal of Vision</source> <volume>11</volume>: <fpage>20</fpage>–<lpage>20</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Warren5"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Warren</surname><given-names>WH</given-names></name>, <name name-style="western"><surname>Mestre</surname><given-names>DR</given-names></name>, <name name-style="western"><surname>Blackwell</surname><given-names>AW</given-names></name>, <name name-style="western"><surname>Morris</surname><given-names>MW</given-names></name> (<year>1991</year>) <article-title>Perception of circular heading from optical flow</article-title>. <source>Journal of experimental psychology Human perception and performance</source> <volume>17</volume>: <fpage>28</fpage>–<lpage>43</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Saunders2"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saunders</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Ma</surname><given-names>KY</given-names></name> (<year>2011</year>) <article-title>Can observers judge future circular path relative to a target from retinal flow</article-title>? <source>Journal of Vision</source> <volume>11</volume>: <fpage>16</fpage>–<lpage>16</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Kim1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kim</surname><given-names>NG</given-names></name>, <name name-style="western"><surname>Fajen</surname><given-names>BR</given-names></name>, <name name-style="western"><surname>Turvey</surname><given-names>MT</given-names></name> (<year>2000</year>) <article-title>Perceiving circular heading in noncanonical flow fields</article-title>. <source>Journal of experimental psychology Human perception and performance</source> <volume>26</volume>: <fpage>31</fpage>–<lpage>56</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Kim2"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kim</surname><given-names>NG</given-names></name> (<year>2008</year>) <article-title>Dynamic Occlusion and Optical Flow From Corrugated Surfaces</article-title>. <source>Ecological Psychology</source> <volume>20</volume>: <fpage>209</fpage>–<lpage>239</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Li3"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Cheng</surname><given-names>JCK</given-names></name> (<year>2011</year>) <article-title>Perceiving path from optic flow</article-title>. <source>Journal of Vision</source> <volume>11</volume>: <fpage>22</fpage>–<lpage>22</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Stone1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stone</surname><given-names>LS</given-names></name>, <name name-style="western"><surname>Perrone</surname><given-names>JA</given-names></name> (<year>1997</year>) <article-title>Human heading estimation during visually simulated curvilinear motion</article-title>. <source>Vision research</source> <volume>37</volume>: <fpage>573</fpage>–<lpage>590</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Li4"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Warren</surname><given-names>WH</given-names><suffix>Jr</suffix></name> (<year>2004</year>) <article-title>Path perception during rotation: inuence of instructions, depth range, and dot density</article-title>. <source>Vision research</source> <volume>44</volume>: <fpage>1879</fpage>–<lpage>1889</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Li5"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Peng</surname><given-names>X</given-names></name> (<year>2009</year>) <article-title>Inuence of visual path information on human heading perception during rotation</article-title>. <source>Journal of Vision</source> <volume>9</volume>: <fpage>29</fpage>–<lpage>29</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Lee1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname><given-names>DN</given-names></name>, <name name-style="western"><surname>Lishman</surname><given-names>R</given-names></name> (<year>1977</year>) <article-title>Visual control of locomotion</article-title>. <source>Scandinavian Journal of Psychology</source> <volume>18</volume>: <fpage>224</fpage>–<lpage>230</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Li6"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Warren</surname><given-names>WH</given-names></name> (<year>2000</year>) <article-title>Perception of heading during rotation: sufficiency of dense motion parallax and reference objects</article-title>. <source>Vision research</source> <volume>40</volume>: <fpage>3873</fpage>–<lpage>3894</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Wann1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wann</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Swapp</surname><given-names>DK</given-names></name> (<year>2000</year>) <article-title>Why you should look where you are going</article-title>. <source>Nature neuroscience</source> <volume>3</volume>: <fpage>647</fpage>–<lpage>648</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Land1"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Land</surname><given-names>MF</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>DN</given-names></name> (<year>1994</year>) <article-title>Where we look when we steer</article-title>. <source>Nature</source> <volume>369</volume>: <fpage>742</fpage>–<lpage>744</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Orban1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Orban</surname><given-names>GA</given-names></name> (<year>2008</year>) <article-title>Higher Order Visual Processing in Macaque Extrastriate Cortex</article-title>. <source>Physiological Reviews</source> <volume>88</volume>: <fpage>59</fpage>–<lpage>89</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Duffy1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Duffy</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Wurtz</surname><given-names>R</given-names></name> (<year>1997</year>) <article-title>Medial superior temporal area neurons respond to speed patterns in optic flow</article-title>. <source>The Journal of neuroscience</source> <volume>17</volume>: <fpage>2839</fpage>–<lpage>2851</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Duffy2"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Duffy</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Wurtz</surname><given-names>R</given-names></name> (<year>1995</year>) <article-title>Response of monkey MST neurons to optic ow stimuli with shifted centers of motion</article-title>. <source>The Journal of neuroscience</source> <volume>15</volume>: <fpage>5192</fpage>–<lpage>5208</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Britten1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Britten</surname><given-names>KH</given-names></name> (<year>2008</year>) <article-title>Mechanisms of Self-Motion Perception</article-title>. <source>Annual Review of Neuroscience</source> <volume>31</volume>: <fpage>389</fpage>–<lpage>410</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Froehler1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Froehler</surname><given-names>MT</given-names></name>, <name name-style="western"><surname>Duffy</surname><given-names>CJ</given-names></name> (<year>2002</year>) <article-title>Cortical neurons encoding path and place: where you go is where you are</article-title>. <source>Science</source> <volume>295</volume>: <fpage>2462</fpage>–<lpage>2465</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Orban2"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Orban</surname><given-names>GAG</given-names></name>, <name name-style="western"><surname>Lagae</surname><given-names>LL</given-names></name>, <name name-style="western"><surname>Verri</surname><given-names>AA</given-names></name>, <name name-style="western"><surname>Raiguel</surname><given-names>SS</given-names></name>, <name name-style="western"><surname>Xiao</surname><given-names>DD</given-names></name>, <etal>et al</etal>. (<year>1992</year>) <article-title>First-order analysis of optical flow in monkey brain</article-title>. <source>PNAS</source> <volume>89</volume>: <fpage>2595</fpage>–<lpage>2599</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Graziano1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graziano</surname><given-names>MSM</given-names></name>, <name name-style="western"><surname>Andersen</surname><given-names>RAR</given-names></name>, <name name-style="western"><surname>Snowden</surname><given-names>RJR</given-names></name> (<year>1994</year>) <article-title>Tuning of MST neurons to spiral motions</article-title>. <source>The Journal of neuroscience</source> <volume>14</volume>: <fpage>54</fpage>–<lpage>67</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Schaafsma1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schaafsma</surname><given-names>SJS</given-names></name>, <name name-style="western"><surname>Duysens</surname><given-names>JJ</given-names></name> (<year>1996</year>) <article-title>Neurons in the ventral intraparietal area of awake macaque monkey closely resemble neurons in the dorsal part of the medial superior temporal area in their responses to optic ow patterns</article-title>. <source>Journal of Neurophysiology</source> <volume>76</volume>: <fpage>4056</fpage>–<lpage>4068</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Read1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Read</surname><given-names>HLH</given-names></name>, <name name-style="western"><surname>Siegel</surname><given-names>RM</given-names></name> (<year>1997</year>) <article-title>Modulation of responses to optic flow in area 7a by retinotopic and oculomotor cues in monkey</article-title>. <source>Cerebral cortex (New York, NY : 1991)</source> <volume>7</volume>: <fpage>647</fpage>–<lpage>661</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Born1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Born</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Bradley</surname><given-names>D</given-names></name> (<year>2005</year>) <article-title>Structure and function of visual area MT</article-title>. <source>Annual Review of Neuroscience</source> <volume>28</volume>: <fpage>157</fpage>–<lpage>189</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Mineault1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mineault</surname><given-names>PJ</given-names></name>, <name name-style="western"><surname>Khawaja</surname><given-names>FA</given-names></name>, <name name-style="western"><surname>Butts</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Pack</surname><given-names>CC</given-names></name> (<year>2012</year>) <article-title>Hierarchical processing of complex motion along the primate dorsal visual pathway</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>109</volume>: <fpage>E972</fpage>–<lpage>80</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Grossberg1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grossberg</surname><given-names>S</given-names></name> (<year>1973</year>) <article-title>Contour enhancement, short term memory, and constancies in reverberating neural networks</article-title>. <source>Studies in applied Mathematics</source> <volume>52</volume>: <fpage>213</fpage>–<lpage>257</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Layton1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Layton</surname><given-names>OW</given-names></name>, <name name-style="western"><surname>Mingolla</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Browning</surname><given-names>NA</given-names></name> (<year>2012</year>) <article-title>A motion pooling model of visually guided navigation explains human behavior in the presence of independently moving objects</article-title>. <source>Journal of Vision</source> <volume>12</volume>: <fpage>1</fpage>–<lpage>20</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Browning1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Browning</surname><given-names>NA</given-names></name>, <name name-style="western"><surname>Grossberg</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Mingolla</surname><given-names>E</given-names></name> (<year>2009</year>) <article-title>A neural model of how the brain computes heading from optic flow in realistic scenes</article-title>. <source>Cognitive psychology</source> <volume>59</volume>: <fpage>320</fpage>–<lpage>356</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Browning2"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Browning</surname><given-names>NA</given-names></name>, <name name-style="western"><surname>Grossberg</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Mingolla</surname><given-names>E</given-names></name> (<year>2009</year>) <article-title>Cortical dynamics of navigation and steering in natural scenes: Motion-based object segmentation, heading, and obstacle avoidance</article-title>. <source>Neural Networks</source> <volume>22</volume>: <fpage>1383</fpage>–<lpage>1398</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Raudies1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raudies</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Neumann</surname><given-names>H</given-names></name> (<year>2012</year>) <article-title>A review and evaluation of methods estimating ego-motion</article-title>. <source>Computer Vision and Image Understanding</source> <volume>116</volume>: <fpage>606</fpage>–<lpage>633</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-LonguetHiggins1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Longuet-Higgins</surname><given-names>HC</given-names></name>, <name name-style="western"><surname>Prazdny</surname><given-names>K</given-names></name> (<year>1980</year>) <article-title>The interpretation of a moving retinal image</article-title>. <source>Proceedings of the Royal Society of London Series B: Biological Sciences</source> <volume>208</volume>: <fpage>385</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Grossberg2"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grossberg</surname><given-names>SS</given-names></name>, <name name-style="western"><surname>Mingolla</surname><given-names>EE</given-names></name>, <name name-style="western"><surname>Pack</surname><given-names>CC</given-names></name> (<year>1999</year>) <article-title>A neural model of motion processing and visual navigation by cortical area MST</article-title>. <source>Cerebral cortex (New York, NY : 1991)</source> <volume>9</volume>: <fpage>878</fpage>–<lpage>895</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Browning3"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Browning</surname><given-names>NA</given-names></name> (<year>2012</year>) <article-title>A Neural Circuit for Robust Time-to-Contact Estimation Based on Primate MST</article-title>. <source>Neural Computation</source> <volume>24</volume>: <fpage>2946</fpage>–<lpage>63</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Layton2"><label>58</label>
<mixed-citation publication-type="book" xlink:type="simple">Layton OW, Browning NA (2013) The Simultaneous Coding of Heading and Path in Primate MSTd. In: The 2013 International Joint Conference on Neural Networks (IJCNN); 4–9 August 2013; Dallas, Texas, United States of America. Available: <ext-link ext-link-type="uri" xlink:href="http://www.ijcnn2013.org/" xlink:type="simple">http://www.ijcnn2013.org/</ext-link></mixed-citation>
</ref>
<ref id="pcbi.1003476-Kim3"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kim</surname><given-names>NG</given-names></name>, <name name-style="western"><surname>Turvey</surname><given-names>MT</given-names></name> (<year>1999</year>) <article-title>Eye Movements and a Rule for Perceiving Direction of Heading</article-title>. <source>Ecological Psychology</source> <volume>11</volume>: <fpage>233</fpage>–<lpage>248</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Raudies2"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raudies</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Gilmore</surname><given-names>RO</given-names></name>, <name name-style="western"><surname>Kretch</surname><given-names>KS</given-names></name>, <name name-style="western"><surname>Franchak</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Adolph</surname><given-names>KE</given-names></name> (<year>2012</year>) <article-title>Understanding the Development of Motion Processing by Characterizing Optic Flow Experienced by Infants and their Mothers</article-title>. <source>Proceedings of ICDL-EpiRob</source> <volume>2012</volume>: <fpage>1</fpage>–<lpage>6</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Norman1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Norman</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Todd</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Perotti</surname><given-names>VJ</given-names></name>, <name name-style="western"><surname>Tittle</surname><given-names>JS</given-names></name> (<year>1996</year>) <article-title>The visual perception of three-dimensional length</article-title>. <source>Journal of experimental psychology Human perception and performance</source> <volume>1</volume>: <fpage>173</fpage>–<lpage>186</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Witt1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Witt</surname><given-names>JK</given-names></name>, <name name-style="western"><surname>Proffitt</surname><given-names>DR</given-names></name>, <name name-style="western"><surname>Epstein</surname><given-names>W</given-names></name> (<year>2004</year>) <article-title>Perceiving distance: A role of effort and intent</article-title>. <source>Perception</source> <volume>33</volume>: <fpage>577</fpage>–<lpage>590</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Layton3"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Layton</surname><given-names>OW</given-names></name>, <name name-style="western"><surname>Browning</surname><given-names>NA</given-names></name> (<year>2012</year>) <article-title>Recurrent competition explains temporal effects of attention in MSTd</article-title>. <source>Frontiers in Computational Neuroscience</source> <volume>6</volume>: <fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003476-Duffy3"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Duffy</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Wurtz</surname><given-names>R</given-names></name> (<year>1991</year>) <article-title>Sensitivity of MST neurons to optic flow stimuli. I. A continuum of response selectivity to large-field stimuli</article-title>. <source>Journal of Neurophysiology</source> <volume>65</volume>: <fpage>1329</fpage>–<lpage>1345</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>